[Stage: Quantize (No Finetuning)] K=3
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/workspace/Weight_compression/quip-sharp/quantize_llama/quantize_finetune_llama.py", line 15, in <module>
    from lib import codebook, utils
  File "/workspace/Weight_compression/quip-sharp/lib/codebook/__init__.py", line 2, in <module>
    import quiptools_cuda
ModuleNotFoundError: No module named 'quiptools_cuda'
[Stage: Convert to HF format (No Finetuning)] K=3
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/workspace/Weight_compression/quip-sharp/quantize_llama/hfize_llama.py", line 9, in <module>
    from lib import codebook, utils
  File "/workspace/Weight_compression/quip-sharp/lib/codebook/__init__.py", line 2, in <module>
    import quiptools_cuda
ModuleNotFoundError: No module named 'quiptools_cuda'
[Stage: Eval PPL (No Finetuning)] K=3
I0412 06:28:29.666553 2450 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0412 06:28:29.666819 2450 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0412 06:28:29.666871 2450 utils.py:162] NumExpr defaulting to 16 threads.
I0412 06:28:30.030900 2450 config.py:58] PyTorch version 2.4.0 available.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/workspace/Weight_compression/quip-sharp/eval/eval_ppl.py", line 22, in <module>
    from lib.utils import gptq_data_utils
  File "/workspace/Weight_compression/quip-sharp/lib/utils/__init__.py", line 1, in <module>
    from .data_utils import *
  File "/workspace/Weight_compression/quip-sharp/lib/utils/data_utils.py", line 8, in <module>
    from lib import codebook
  File "/workspace/Weight_compression/quip-sharp/lib/codebook/__init__.py", line 2, in <module>
    import quiptools_cuda
ModuleNotFoundError: No module named 'quiptools_cuda'
[Stage: Eval Zero-shot (No Finetuning)] K=3
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/workspace/Weight_compression/quip-sharp/eval/eval_zeroshot.py", line 9, in <module>
    from lm_eval import evaluator, tasks
  File "/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py", line 1, in <module>
    from .evaluator import evaluate, simple_evaluate
  File "/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py", line 12, in <module>
    import lm_eval.api.metrics
  File "/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py", line 12, in <module>
    from lm_eval.api.registry import register_aggregation, register_metric
  File "/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py", line 4, in <module>
    import evaluate as hf_evaluate
  File "/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py", line 29, in <module>
    from .evaluation_suite import EvaluationSuite
  File "/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py", line 10, in <module>
    from ..evaluator import evaluator
  File "/opt/conda/lib/python3.11/site-packages/evaluate/evaluator/__init__.py", line 17, in <module>
    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS
  File "/opt/conda/lib/python3.11/site-packages/transformers/pipelines/__init__.py", line 26, in <module>
    from ..image_processing_utils import BaseImageProcessor
  File "/opt/conda/lib/python3.11/site-packages/transformers/image_processing_utils.py", line 21, in <module>
    from .image_transforms import center_crop, normalize, rescale
  File "/opt/conda/lib/python3.11/site-packages/transformers/image_transforms.py", line 22, in <module>
    from .image_utils import (
  File "/opt/conda/lib/python3.11/site-packages/transformers/image_utils.py", line 58, in <module>
    from torchvision.transforms import InterpolationMode
  File "/opt/conda/lib/python3.11/site-packages/torchvision/__init__.py", line 10, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torchvision/_meta_registrations.py", line 163, in <module>
    @torch.library.register_fake("torchvision::nms")
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/library.py", line 654, in register
    use_lib._register_fake(op_name, func, _stacklevel=stacklevel + 1)
  File "/opt/conda/lib/python3.11/site-packages/torch/library.py", line 154, in _register_fake
    handle = entry.abstract_impl.register(func_to_register, source)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/_library/abstract_impl.py", line 31, in register
    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, "Meta"):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: operator torchvision::nms does not exist
