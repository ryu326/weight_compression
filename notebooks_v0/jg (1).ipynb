{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "cnn_layer = nn.Conv2d(3,32, kernel_size=3, stride=1, padding=0, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN특: weight는 4차원, bias는 1차원\n",
    "print(cnn_layer.weight.size(), cnn_layer.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,32, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.Conv2d(64,128, kernel_size=3, stride=2, padding=1, bias=True))\n",
    "\n",
    "        self.classifier = nn.Linear(8192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.cnn(x)\n",
    "        res = self.classifier(y.flatten())\n",
    "\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim * 3이면 qky 모인거고 dim이면 projection. 모델 이름 지정할 때 dimension 정보를 기입하도록 하자. \n",
    "temp_layer = torch.nn.MultiheadAttention(512, 8, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('in_proj_weight',\n",
       "              tensor([[ 3.7087e-02,  3.6829e-02,  2.8740e-02,  ..., -4.1773e-02,\n",
       "                        4.1802e-02, -4.4891e-02],\n",
       "                      [-3.7101e-06,  5.0186e-02, -2.2051e-02,  ...,  8.9653e-03,\n",
       "                       -2.2123e-02,  9.0223e-04],\n",
       "                      [-9.4668e-03,  3.5802e-02, -2.3630e-02,  ..., -4.4814e-02,\n",
       "                        5.0107e-02,  3.9685e-02],\n",
       "                      ...,\n",
       "                      [-3.5645e-02,  1.4861e-02, -2.3737e-02,  ...,  2.8589e-02,\n",
       "                       -2.9646e-02, -1.6696e-03],\n",
       "                      [ 2.8358e-02, -1.2282e-02, -1.0482e-02,  ...,  4.6022e-02,\n",
       "                        1.5846e-02, -4.8795e-02],\n",
       "                      [-4.8527e-02,  1.0532e-02,  3.1280e-02,  ..., -4.5944e-02,\n",
       "                       -2.9970e-02,  7.2998e-03]])),\n",
       "             ('in_proj_bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('out_proj.weight',\n",
       "              tensor([[ 0.0263, -0.0263,  0.0395,  ..., -0.0121, -0.0113, -0.0005],\n",
       "                      [ 0.0412, -0.0143, -0.0379,  ...,  0.0052,  0.0033, -0.0431],\n",
       "                      [-0.0084, -0.0164,  0.0258,  ...,  0.0367, -0.0252,  0.0191],\n",
       "                      ...,\n",
       "                      [ 0.0267, -0.0108, -0.0116,  ...,  0.0260, -0.0437,  0.0024],\n",
       "                      [-0.0030, -0.0299,  0.0041,  ...,  0.0274, -0.0369, -0.0139],\n",
       "                      [ 0.0112,  0.0165,  0.0018,  ..., -0.0266,  0.0184, -0.0394]])),\n",
       "             ('out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델만 모은다고 가정\n",
    "# CNN weight는 4차원, bias는 1차원, linear는 2차원\n",
    "\n",
    "cnn_weight = {}\n",
    "cnn_bias = {}\n",
    "lin_weight = {}\n",
    "\n",
    "new_state_dict = {}\n",
    "\n",
    "# 모델 불러오기\n",
    "simple_md = simple_cnn()\n",
    "\n",
    "# 10개만 모아서 \n",
    "model_dict = {\"simple_md\":simple_md}\n",
    "\n",
    "for name in model_dict:\n",
    "    weights_dict = model_dict[name].state_dict()\n",
    "\n",
    "    for k, v in weights_dict.items():\n",
    "        # cnn weight\n",
    "\n",
    "        temp_name = f'{name}_{k}'\n",
    "\n",
    "        if len(v.size()) == 4:\n",
    "            cnn_weight[temp_name] = v\n",
    "        \n",
    "        # bias\n",
    "        elif len(v.size()) == 1:\n",
    "            cnn_bias[temp_name] = v\n",
    "        \n",
    "        # linear weight\n",
    "        elif len(v.size()) == 2:\n",
    "            lin_weight[temp_name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cnn_weight:\n",
    "    print(cnn_weight[name].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cnn_bias:\n",
    "    print(cnn_bias[name].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in lin_weight:\n",
    "    print(lin_weight[name].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_bias, '/home/mkkim/cnn_bias.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
