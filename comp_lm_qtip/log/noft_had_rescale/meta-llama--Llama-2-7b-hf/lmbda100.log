I0321 02:52:24.177511 1596483 config.py:54] PyTorch version 2.6.0 available.
W0321 02:52:24.460412 1596483 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:52:25.477653 1596483 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  7.04it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.35it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  7.81it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.04it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.23it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.38it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.07it/s]
I0321 02:52:26.425632 1596483 quantize_finetune_llama.py:144] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:15,  2.03it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:00<00:14,  2.04it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:14,  2.06it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:01<00:13,  2.06it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:02<00:13,  2.07it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:02<00:12,  2.14it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:03<00:11,  2.20it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:03<00:10,  2.24it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:04<00:10,  2.27it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:04<00:09,  2.30it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:04<00:09,  2.31it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:05<00:08,  2.32it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:05<00:08,  2.32it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:06<00:07,  2.32it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:06<00:07,  2.32it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:07<00:06,  2.35it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:07<00:06,  2.39it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:07<00:05,  2.42it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:08<00:05,  2.43it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:08<00:04,  2.44it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:09<00:04,  2.46it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:09<00:04,  2.47it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:09<00:03,  2.46it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:10<00:03,  2.48it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:10<00:02,  2.48it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:11<00:02,  2.49it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:11<00:02,  2.48it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:11<00:01,  2.49it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:12<00:01,  2.50it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:12<00:00,  2.52it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:13<00:00,  2.52it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:13<00:00,  2.54it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:13<00:00,  2.37it/s]
I0321 02:52:47.609255 1596483 quantize_finetune_llama.py:179] loaded compression model
I0321 02:53:11.737281 1596483 quantize_finetune_llama.py:183] loaded dataset and devset
I0321 02:53:16.952951 1596483 quantize_finetune_llama.py:203] layer 0 gpu 0
I0321 02:53:20.618177 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 0 in 3.520676374435425s
tensor(0.0192) tensor(-3.6338e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0321 02:53:35.288556 1596857 config.py:54] PyTorch version 2.6.0 available.
W0321 02:53:35.571692 1596857 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:53:36.460915 1596857 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:53:36.464915 1596483 quantize_finetune_llama.py:203] layer 1 gpu 1
I0321 02:53:36.478341 1596857 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:53:40.181505 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 1 in 3.5527923107147217s
I0321 02:53:43.601246 1596936 config.py:54] PyTorch version 2.6.0 available.
W0321 02:53:43.918578 1596936 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:53:44.828809 1596936 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:53:44.832826 1596483 quantize_finetune_llama.py:203] layer 2 gpu 2
I0321 02:53:44.845923 1596936 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:53:48.094450 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 2 in 3.1007654666900635s
I0321 02:53:51.803629 1597027 config.py:54] PyTorch version 2.6.0 available.
W0321 02:53:52.142817 1597027 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:53:53.122833 1597027 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:53:53.127044 1596483 quantize_finetune_llama.py:203] layer 3 gpu 3
I0321 02:53:53.141117 1597027 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:53:55.886129 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 3 in 2.5975430011749268s
I0321 02:53:59.803917 1597103 config.py:54] PyTorch version 2.6.0 available.
W0321 02:54:00.164879 1597103 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:54:01.328547 1597103 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:54:01.333007 1596483 quantize_finetune_llama.py:203] layer 4 gpu 0
I0321 02:54:01.350192 1597103 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.13391368091106415 tr(WHW.T) 4.225186347961426
bpp_loss 2.9616440534591675
0_q proxy err 0.0029876548796892166 tr(WHW.T) 2710.363037109375
bpp_loss 2.9757773876190186
0_k proxy err 0.003629914252087474 tr(WHW.T) 1698.7349853515625
bpp_loss 2.9753347635269165
0_o proxy err 0.014364308677613735 tr(WHW.T) 0.9668058156967163
bpp_loss 2.966304898262024
0_up proxy err 0.11980719119310379 tr(WHW.T) 43.27138900756836
bpp_loss 2.976447349370912
0_gate proxy err 0.0848347395658493 tr(WHW.T) 63.47430419921875
bpp_loss 2.9770145859829213
0_down proxy err 0.06341959536075592 tr(WHW.T) 0.656814694404602
bpp_loss 2.979876917462016
1_v proxy err 0.46343880891799927 tr(WHW.T) 16.465883255004883
bpp_loss 2.9600718021392822
1_q proxy err 0.009242926724255085 tr(WHW.T) 4778.43994140625
bpp_loss 2.970989227294922
1_k proxy err 0.009137635119259357 tr(WHW.T) 4995.39208984375
bpp_loss 2.971257209777832
1_o proxy err 0.07914472371339798 tr(WHW.T) 1.1115814447402954
bpp_loss 2.9722952842712402
1_up proxy err 0.07446587085723877 tr(WHW.T) 109.66383361816406
bpp_loss 3.006590732308321
1_gate proxy err 0.040215298533439636 tr(WHW.T) 221.3038787841797
bpp_loss 3.009874388229015
1_down proxy err 0.034586284309625626 tr(WHW.T) 2041.4736328125
bpp_loss 2.9575739572214528
I0321 02:54:42.442036 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 4 in 0.9192442893981934s
I0321 02:54:46.244536 1597288 config.py:54] PyTorch version 2.6.0 available.
W0321 02:54:46.576962 1597288 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:54:47.610438 1597288 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:54:47.614581 1596483 quantize_finetune_llama.py:203] layer 5 gpu 1
I0321 02:54:47.628420 1597288 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.1193787008523941 tr(WHW.T) 136.67332458496094
bpp_loss 2.982567310333252
2_q proxy err 0.005793828517198563 tr(WHW.T) 7752.85205078125
bpp_loss 3.009116530418396
2_k proxy err 0.004887837450951338 tr(WHW.T) 10205.837890625
bpp_loss 3.012570858001709
2_o proxy err 0.030828820541501045 tr(WHW.T) 1.4603197574615479
bpp_loss 3.0685014724731445
2_up proxy err 0.0272879246622324 tr(WHW.T) 193.43603515625
bpp_loss 3.1290540473405706
2_gate proxy err 0.018687786534428596 tr(WHW.T) 306.6622619628906
bpp_loss 3.140756828840389
2_down proxy err 0.05623167008161545 tr(WHW.T) 3.010739803314209
bpp_loss 3.0484116354654
I0321 02:54:50.897991 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 5 in 0.9955363273620605s
I0321 02:54:54.691559 1597362 config.py:54] PyTorch version 2.6.0 available.
W0321 02:54:55.041393 1597362 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:54:56.053460 1597362 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:54:56.057600 1596483 quantize_finetune_llama.py:203] layer 6 gpu 2
I0321 02:54:56.073101 1597362 data_utils.py:336] using 256 training seqs, 128 validation seqs
3_v proxy err 0.10263744741678238 tr(WHW.T) 284.77557373046875
bpp_loss 2.99597430229187
3_q proxy err 0.009117397479712963 tr(WHW.T) 7217.63720703125
bpp_loss 3.031957268714905
3_k proxy err 0.007086704485118389 tr(WHW.T) 10074.73828125
bpp_loss 3.0355730056762695
3_o proxy err 0.056080128997564316 tr(WHW.T) 3.3527450561523438
bpp_loss 3.005953311920166
3_up proxy err 0.040344785898923874 tr(WHW.T) 284.7950744628906
bpp_loss 3.090398211811864
3_gate proxy err 0.026320235803723335 tr(WHW.T) 478.13714599609375
bpp_loss 3.1007417190906614
3_down proxy err 0.05563955754041672 tr(WHW.T) 6.133229732513428
bpp_loss 3.0502378108889556
I0321 02:54:59.390614 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 6 in 1.045565128326416s
I0321 02:55:03.002416 1597454 config.py:54] PyTorch version 2.6.0 available.
W0321 02:55:03.339977 1597454 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:55:04.338901 1597454 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:55:04.342888 1596483 quantize_finetune_llama.py:203] layer 7 gpu 3
I0321 02:55:04.356243 1597454 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:55:05.712306 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 7 in 0.921205997467041s
I0321 02:55:09.690480 1597528 config.py:54] PyTorch version 2.6.0 available.
W0321 02:55:10.036076 1597528 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:55:11.153179 1597528 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:55:11.157758 1596483 quantize_finetune_llama.py:203] layer 8 gpu 0
I0321 02:55:11.188402 1597528 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.11283592879772186 tr(WHW.T) 274.6131286621094
bpp_loss 2.992684841156006
4_q proxy err 0.01000708993524313 tr(WHW.T) 6914.9892578125
bpp_loss 3.0252550840377808
4_k proxy err 0.007197450380772352 tr(WHW.T) 10415.33203125
bpp_loss 3.0279935598373413
4_o proxy err 0.03048061393201351 tr(WHW.T) 5.139806270599365
bpp_loss 3.0799474716186523
4_up proxy err 0.05064651742577553 tr(WHW.T) 397.6960144042969
bpp_loss 3.057869312375091
4_gate proxy err 0.027864564210176468 tr(WHW.T) 821.1856689453125
bpp_loss 3.068934063578761
4_down proxy err 0.06119435653090477 tr(WHW.T) 11.562739372253418
bpp_loss 3.039598686750545
5_v proxy err 0.12247384339570999 tr(WHW.T) 298.47540283203125
bpp_loss 2.9927196502685547
5_q proxy err 0.011550885625183582 tr(WHW.T) 6770.97509765625
bpp_loss 3.0236401557922363
5_k proxy err 0.008014987222850323 tr(WHW.T) 10841.955078125
bpp_loss 3.0274739265441895
5_o proxy err 0.07201149314641953 tr(WHW.T) 7.947142601013184
bpp_loss 3.013675332069397
5_up proxy err 0.04892949014902115 tr(WHW.T) 506.6408386230469
bpp_loss 3.060183502906977
5_gate proxy err 0.025661872699856758 tr(WHW.T) 1104.867919921875
bpp_loss 3.072058921636537
5_down proxy err 0.05670079588890076 tr(WHW.T) 15.6494779586792
bpp_loss 3.053869291793468
I0321 02:55:53.069150 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 8 in 1.1055283546447754s
I0321 02:55:56.717822 1597713 config.py:54] PyTorch version 2.6.0 available.
W0321 02:55:57.041570 1597713 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:55:58.054275 1597713 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:55:58.058443 1596483 quantize_finetune_llama.py:203] layer 9 gpu 1
I0321 02:55:58.072036 1597713 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.10358733683824539 tr(WHW.T) 443.5464782714844
bpp_loss 2.997495174407959
6_q proxy err 0.012781175784766674 tr(WHW.T) 7576.53857421875
bpp_loss 3.0328121185302734
6_k proxy err 0.009811870753765106 tr(WHW.T) 10409.4033203125
bpp_loss 3.0347853899002075
6_o proxy err 0.04609541594982147 tr(WHW.T) 11.564380645751953
bpp_loss 3.0500400066375732
6_up proxy err 0.05520358681678772 tr(WHW.T) 617.2608642578125
bpp_loss 3.047611502713935
6_gate proxy err 0.025691328570246696 tr(WHW.T) 1554.7271728515625
bpp_loss 3.06016345356786
6_down proxy err 0.06056998297572136 tr(WHW.T) 22.988168716430664
bpp_loss 3.0488704858824263
I0321 02:56:01.922688 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 9 in 1.1179838180541992s
I0321 02:56:05.770264 1597800 config.py:54] PyTorch version 2.6.0 available.
W0321 02:56:06.103598 1597800 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

7_v proxy err 0.10423529148101807 tr(WHW.T) 489.9357604980469
bpp_loss 2.9979392290115356
7_q proxy err 0.013734083622694016 tr(WHW.T) 7672.17919921875
bpp_loss 3.0323450565338135
7_k proxy err 0.010694938711822033 tr(WHW.T) 10198.3701171875
bpp_loss 3.033328652381897
7_o proxy err 0.05799275264143944 tr(WHW.T) 15.11335563659668
bpp_loss 3.040237545967102
7_up proxy err 0.06483080238103867 tr(WHW.T) 735.8538818359375
bpp_loss 3.0322026097497274
7_gate proxy err 0.02975822240114212 tr(WHW.T) 1876.0390625
bpp_loss 3.0424861464389537
7_down proxy err 0.06869295984506607 tr(WHW.T) 30.58672523498535
bpp_loss 3.0392685601877614
W0321 02:56:07.048869 1597800 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:56:07.052949 1596483 quantize_finetune_llama.py:203] layer 10 gpu 2
I0321 02:56:07.069643 1597800 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:56:08.449074 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 10 in 0.9684693813323975s
I0321 02:56:12.134208 1597876 config.py:54] PyTorch version 2.6.0 available.
W0321 02:56:12.448847 1597876 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:56:13.457840 1597876 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:56:13.461970 1596483 quantize_finetune_llama.py:203] layer 11 gpu 3
I0321 02:56:13.476205 1597876 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:56:15.170354 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 11 in 1.1919031143188477s
I0321 02:56:18.985005 1597950 config.py:54] PyTorch version 2.6.0 available.
W0321 02:56:19.335964 1597950 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:56:20.320294 1597950 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:56:20.324544 1596483 quantize_finetune_llama.py:203] layer 12 gpu 0
I0321 02:56:20.338386 1597950 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.1002417802810669 tr(WHW.T) 530.9967041015625
bpp_loss 2.9972771406173706
8_q proxy err 0.014817358925938606 tr(WHW.T) 7228.1201171875
bpp_loss 3.0298635959625244
8_k proxy err 0.010560347698628902 tr(WHW.T) 10639.1015625
bpp_loss 3.031245470046997
8_o proxy err 0.05398067459464073 tr(WHW.T) 20.092191696166992
bpp_loss 3.061297655105591
8_up proxy err 0.06477541476488113 tr(WHW.T) 866.312744140625
bpp_loss 3.0271673867868825
8_gate proxy err 0.032347772270441055 tr(WHW.T) 1970.857177734375
bpp_loss 3.034697776617006
8_down proxy err 0.07574320584535599 tr(WHW.T) 37.177734375
bpp_loss 3.032764013423476
9_v proxy err 0.09738406538963318 tr(WHW.T) 565.0663452148438
bpp_loss 2.999700665473938
9_q proxy err 0.015411082655191422 tr(WHW.T) 6970.3359375
bpp_loss 3.032430648803711
9_k proxy err 0.010479692369699478 tr(WHW.T) 10987.3515625
bpp_loss 3.035410165786743
9_o proxy err 0.05581869184970856 tr(WHW.T) 25.610172271728516
bpp_loss 3.0642457008361816
9_up proxy err 0.056015487760305405 tr(WHW.T) 970.8984375
bpp_loss 3.0361132954442223
9_gate proxy err 0.02850639633834362 tr(WHW.T) 2132.69384765625
bpp_loss 3.0432322302529977
9_down proxy err 0.0340241864323616 tr(WHW.T) 42.99482727050781
bpp_loss 3.130035489104515
I0321 02:57:04.180943 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 12 in 1.0244777202606201s
I0321 02:57:08.019287 1598123 config.py:54] PyTorch version 2.6.0 available.
W0321 02:57:08.365030 1598123 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

10_v proxy err 0.09804636985063553 tr(WHW.T) 578.807373046875
bpp_loss 2.99875271320343
10_q proxy err 0.016063755378127098 tr(WHW.T) 6915.87109375
bpp_loss 3.031257152557373
10_k proxy err 0.010958466678857803 tr(WHW.T) 10996.2431640625
bpp_loss 3.034725308418274
10_o proxy err 0.04632396996021271 tr(WHW.T) 35.184165954589844
bpp_loss 3.0952228307724
10_up proxy err 0.05242567136883736 tr(WHW.T) 1080.198486328125
bpp_loss 3.0383740802143895
10_gate proxy err 0.02759725973010063 tr(WHW.T) 2260.88330078125
bpp_loss 3.0445004840229832
10_down proxy err 0.04847373440861702 tr(WHW.T) 52.33584976196289
bpp_loss 3.074119989262071
W0321 02:57:09.376947 1598123 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:57:09.381119 1596483 quantize_finetune_llama.py:203] layer 13 gpu 1
I0321 02:57:09.397236 1598123 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:57:11.301873 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 13 in 1.0470244884490967s
I0321 02:57:15.156732 1598197 config.py:54] PyTorch version 2.6.0 available.
11_v proxy err 0.09283795952796936 tr(WHW.T) 723.1956176757812
bpp_loss 3.004554510116577
11_q proxy err 0.016915369778871536 tr(WHW.T) 7027.10986328125
bpp_loss 3.0343856811523438
11_k proxy err 0.011804649606347084 tr(WHW.T) 10511.23046875
bpp_loss 3.0353060960769653
11_o proxy err 0.05674418807029724 tr(WHW.T) 36.654052734375
bpp_loss 3.076830744743347
11_up proxy err 0.04985365644097328 tr(WHW.T) 1139.6044921875
bpp_loss 3.046195629031159
11_gate proxy err 0.025803424417972565 tr(WHW.T) 2392.716552734375
bpp_loss 3.0517851363780886
11_down proxy err 0.02745804563164711 tr(WHW.T) 56.13530731201172
bpp_loss 3.17200567555982
W0321 02:57:15.473725 1598197 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:57:16.508399 1598197 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:57:16.512442 1596483 quantize_finetune_llama.py:203] layer 14 gpu 2
I0321 02:57:16.525965 1598197 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:57:17.994945 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 14 in 1.0227019786834717s
I0321 02:57:21.676506 1598281 config.py:54] PyTorch version 2.6.0 available.
W0321 02:57:21.981831 1598281 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:57:22.929222 1598281 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:57:22.933210 1596483 quantize_finetune_llama.py:203] layer 15 gpu 3
I0321 02:57:22.947199 1598281 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:57:24.484172 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 15 in 1.0527467727661133s
I0321 02:57:28.278579 1598345 config.py:54] PyTorch version 2.6.0 available.
W0321 02:57:28.627629 1598345 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:57:29.665389 1598345 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:57:29.669559 1596483 quantize_finetune_llama.py:203] layer 16 gpu 0
I0321 02:57:29.683640 1598345 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.09491067379713058 tr(WHW.T) 703.318603515625
bpp_loss 3.003955602645874
12_q proxy err 0.017323801293969154 tr(WHW.T) 7045.6435546875
bpp_loss 3.0354846715927124
12_k proxy err 0.012014276348054409 tr(WHW.T) 10893.65625
bpp_loss 3.0390472412109375
12_o proxy err 0.05929763987660408 tr(WHW.T) 39.29071044921875
bpp_loss 3.0743297338485718
12_up proxy err 0.047151122242212296 tr(WHW.T) 1228.298583984375
bpp_loss 3.0524767498637355
12_gate proxy err 0.02592804655432701 tr(WHW.T) 2381.994873046875
bpp_loss 3.0569403005200764
12_down proxy err 0.03816668689250946 tr(WHW.T) 64.17745208740234
bpp_loss 3.113895438438238
13_v proxy err 0.09294082224369049 tr(WHW.T) 714.5677490234375
bpp_loss 3.010043144226074
13_q proxy err 0.01660989783704281 tr(WHW.T) 6956.03564453125
bpp_loss 3.041552424430847
13_k proxy err 0.011726686730980873 tr(WHW.T) 10426.6318359375
bpp_loss 3.044148087501526
13_o proxy err 0.045008499175310135 tr(WHW.T) 45.8377571105957
bpp_loss 3.1020160913467407
13_up proxy err 0.045045964419841766 tr(WHW.T) 1367.6221923828125
bpp_loss 3.054958787075309
13_gate proxy err 0.02492389641702175 tr(WHW.T) 2601.504638671875
bpp_loss 3.0581720041674236
13_down proxy err 0.04808962345123291 tr(WHW.T) 79.3589096069336
bpp_loss 3.081670029218807
I0321 02:58:13.940201 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 16 in 1.0003385543823242s
I0321 02:58:17.650193 1598458 config.py:54] PyTorch version 2.6.0 available.
W0321 02:58:17.976140 1598458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

14_v proxy err 0.09809067100286484 tr(WHW.T) 706.1612548828125
bpp_loss 3.0082480907440186
14_q proxy err 0.01723194681107998 tr(WHW.T) 7077.06103515625
bpp_loss 3.039795160293579
14_k proxy err 0.011522925458848476 tr(WHW.T) 11295.16796875
bpp_loss 3.0430121421813965
14_o proxy err 0.05227722227573395 tr(WHW.T) 50.921180725097656
bpp_loss 3.0962607860565186
14_up proxy err 0.040420059114694595 tr(WHW.T) 1464.7159423828125
bpp_loss 3.0686416625976562
14_gate proxy err 0.02309149131178856 tr(WHW.T) 2682.584716796875
bpp_loss 3.0718630413676418
14_down proxy err 0.03445388004183769 tr(WHW.T) 90.28684997558594
bpp_loss 3.133736299913983
W0321 02:58:18.979570 1598458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:58:18.983663 1596483 quantize_finetune_llama.py:203] layer 17 gpu 1
I0321 02:58:19.000074 1598458 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:58:20.727921 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 17 in 1.25362229347229s
I0321 02:58:24.587588 1598517 config.py:54] PyTorch version 2.6.0 available.
15_v proxy err 0.09714900702238083 tr(WHW.T) 762.7275390625
bpp_loss 3.006947875022888
15_q proxy err 0.017122935503721237 tr(WHW.T) 7252.0009765625
bpp_loss 3.0339255332946777
15_k proxy err 0.012095222249627113 tr(WHW.T) 11072.3974609375
bpp_loss 3.0377780199050903
15_o proxy err 0.056346189230680466 tr(WHW.T) 59.61664962768555
bpp_loss 3.071658730506897
15_up proxy err 0.04079752042889595 tr(WHW.T) 1641.0228271484375
bpp_loss 3.0656864254973657
15_gate proxy err 0.024078676477074623 tr(WHW.T) 2905.140380859375
bpp_loss 3.0687718945880267
15_down proxy err 0.04645376279950142 tr(WHW.T) 114.09001922607422
bpp_loss 3.087218949961108
W0321 02:58:24.876304 1598517 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:58:25.822667 1598517 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:58:25.826840 1596483 quantize_finetune_llama.py:203] layer 18 gpu 2
I0321 02:58:25.840538 1598517 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:58:27.312859 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 18 in 1.0146164894104004s
I0321 02:58:31.219431 1598573 config.py:54] PyTorch version 2.6.0 available.
W0321 02:58:31.521624 1598573 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:58:32.483946 1598573 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:58:32.488253 1596483 quantize_finetune_llama.py:203] layer 19 gpu 3
I0321 02:58:32.503404 1598573 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:58:34.044570 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 19 in 1.042910099029541s
I0321 02:58:37.914283 1598632 config.py:54] PyTorch version 2.6.0 available.
W0321 02:58:38.251155 1598632 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:58:39.229154 1598632 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:58:39.233394 1596483 quantize_finetune_llama.py:203] layer 20 gpu 0
I0321 02:58:39.247513 1598632 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.10204432159662247 tr(WHW.T) 780.7407836914062
bpp_loss 3.010765790939331
16_q proxy err 0.017618020996451378 tr(WHW.T) 7193.3974609375
bpp_loss 3.035966992378235
16_k proxy err 0.011731634847819805 tr(WHW.T) 11630.361328125
bpp_loss 3.039488196372986
16_o proxy err 0.04446819797158241 tr(WHW.T) 88.22785186767578
bpp_loss 3.084985613822937
16_up proxy err 0.032978691160678864 tr(WHW.T) 1890.9385986328125
bpp_loss 3.0906616920648617
16_gate proxy err 0.019457697868347168 tr(WHW.T) 3369.859130859375
bpp_loss 3.0952292154001637
16_down proxy err 0.04517164081335068 tr(WHW.T) 152.0294952392578
bpp_loss 3.092623244884402
17_v proxy err 0.08524264395236969 tr(WHW.T) 845.7654418945312
bpp_loss 3.021064281463623
17_q proxy err 0.015800487250089645 tr(WHW.T) 7163.2734375
bpp_loss 3.0499733686447144
17_k proxy err 0.011227099224925041 tr(WHW.T) 10697.431640625
bpp_loss 3.053315043449402
17_o proxy err 0.03886401280760765 tr(WHW.T) 58.14826965332031
bpp_loss 3.116290807723999
17_up proxy err 0.030863383784890175 tr(WHW.T) 1921.07861328125
bpp_loss 3.1134283376294514
17_gate proxy err 0.017655685544013977 tr(WHW.T) 3571.31640625
bpp_loss 3.1205126740211666
17_down proxy err 0.0416567325592041 tr(WHW.T) 165.43495178222656
bpp_loss 3.1058444311452464
I0321 02:59:23.483293 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 20 in 0.9924716949462891s
I0321 02:59:27.257757 1598745 config.py:54] PyTorch version 2.6.0 available.
W0321 02:59:27.600302 1598745 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

18_v proxy err 0.07977920770645142 tr(WHW.T) 1003.7705078125
bpp_loss 3.027896761894226
18_q proxy err 0.015564149245619774 tr(WHW.T) 7510.48046875
bpp_loss 3.0531810522079468
18_k proxy err 0.011734435334801674 tr(WHW.T) 10462.6650390625
bpp_loss 3.056102991104126
18_o proxy err 0.06022940203547478 tr(WHW.T) 69.96558380126953
bpp_loss 3.05114483833313
18_up proxy err 0.030887369066476822 tr(WHW.T) 2023.183837890625
bpp_loss 3.122910965320676
18_gate proxy err 0.01775282248854637 tr(WHW.T) 3783.076416015625
bpp_loss 3.1322088906931325
18_down proxy err 0.05613946169614792 tr(WHW.T) 198.52699279785156
bpp_loss 3.065395554830862
W0321 02:59:28.662711 1598745 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:59:28.666837 1596483 quantize_finetune_llama.py:203] layer 21 gpu 1
I0321 02:59:28.680588 1598745 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:59:30.582463 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 21 in 1.0122008323669434s
I0321 02:59:34.506959 1598804 config.py:54] PyTorch version 2.6.0 available.
W0321 02:59:34.847394 1598804 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

19_v proxy err 0.07832040637731552 tr(WHW.T) 1019.1412353515625
bpp_loss 3.0293163061141968
19_q proxy err 0.01636640913784504 tr(WHW.T) 6944.4130859375
bpp_loss 3.053162097930908
19_k proxy err 0.011367080733180046 tr(WHW.T) 10548.4892578125
bpp_loss 3.0562589168548584
19_o proxy err 0.03932186961174011 tr(WHW.T) 62.291683197021484
bpp_loss 3.106181263923645
19_up proxy err 0.029071679338812828 tr(WHW.T) 2149.330322265625
bpp_loss 3.1344451904296875
19_gate proxy err 0.01824614778161049 tr(WHW.T) 3687.5126953125
bpp_loss 3.144873330759448
19_down proxy err 0.04918567091226578 tr(WHW.T) 222.93177795410156
bpp_loss 3.0785590327063272
W0321 02:59:35.786298 1598804 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:59:35.790377 1596483 quantize_finetune_llama.py:203] layer 22 gpu 2
I0321 02:59:35.804059 1598804 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:59:37.235221 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 22 in 0.9674208164215088s
I0321 02:59:41.033709 1598863 config.py:54] PyTorch version 2.6.0 available.
W0321 02:59:41.355883 1598863 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:59:42.314257 1598863 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:59:42.318911 1596483 quantize_finetune_llama.py:203] layer 23 gpu 3
I0321 02:59:42.334530 1598863 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 02:59:44.053098 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 23 in 1.2244985103607178s
I0321 02:59:47.848231 1598922 config.py:54] PyTorch version 2.6.0 available.
W0321 02:59:48.168619 1598922 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 02:59:49.190069 1598922 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 02:59:49.194407 1596483 quantize_finetune_llama.py:203] layer 24 gpu 0
I0321 02:59:49.210170 1598922 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.08485335111618042 tr(WHW.T) 990.5983276367188
bpp_loss 3.028610348701477
20_q proxy err 0.016631241887807846 tr(WHW.T) 7150.947265625
bpp_loss 3.051683783531189
20_k proxy err 0.012051239609718323 tr(WHW.T) 10386.2470703125
bpp_loss 3.0544605255126953
20_o proxy err 0.037951141595840454 tr(WHW.T) 100.31707000732422
bpp_loss 3.074171304702759
20_up proxy err 0.02713860757648945 tr(WHW.T) 2340.89453125
bpp_loss 3.1435341058775434
20_gate proxy err 0.01708792708814144 tr(WHW.T) 4024.62744140625
bpp_loss 3.1554895445357922
20_down proxy err 0.09081050008535385 tr(WHW.T) 274.8815002441406
bpp_loss 3.0211216904396236
21_v proxy err 0.08421459794044495 tr(WHW.T) 1144.5655517578125
bpp_loss 3.0319103002548218
21_q proxy err 0.018183773383498192 tr(WHW.T) 7064.314453125
bpp_loss 3.0508828163146973
21_k proxy err 0.013398587703704834 tr(WHW.T) 9976.4658203125
bpp_loss 3.052909731864929
21_o proxy err 0.03099680133163929 tr(WHW.T) 75.50972747802734
bpp_loss 3.125595211982727
21_up proxy err 0.030716324225068092 tr(WHW.T) 2361.650390625
bpp_loss 3.1304076438726383
21_gate proxy err 0.01977275311946869 tr(WHW.T) 4004.37646484375
bpp_loss 3.1429526750431505
21_down proxy err 0.036038439720869064 tr(WHW.T) 276.5857849121094
bpp_loss 3.1228235377821814
I0321 03:00:36.607384 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 24 in 1.0392835140228271s
I0321 03:00:40.319777 1599038 config.py:54] PyTorch version 2.6.0 available.
W0321 03:00:40.702665 1599038 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

22_v proxy err 0.07826679199934006 tr(WHW.T) 1243.2529296875
bpp_loss 3.0337570905685425
22_q proxy err 0.017032621428370476 tr(WHW.T) 7746.84765625
bpp_loss 3.054906129837036
22_k proxy err 0.012936083599925041 tr(WHW.T) 10603.2041015625
bpp_loss 3.0569812059402466
22_o proxy err 0.029026972129940987 tr(WHW.T) 114.30065155029297
bpp_loss 3.1039594411849976
22_up proxy err 0.029033979400992393 tr(WHW.T) 2474.510498046875
bpp_loss 3.1416114984556684
22_gate proxy err 0.018993092700839043 tr(WHW.T) 4156.64013671875
bpp_loss 3.1559584861577945
22_down proxy err 0.04464723542332649 tr(WHW.T) 311.8800048828125
bpp_loss 3.091539427291515
W0321 03:00:41.750099 1599038 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:00:41.754221 1596483 quantize_finetune_llama.py:203] layer 25 gpu 1
I0321 03:00:41.768979 1599038 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:00:43.430378 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 25 in 0.9772779941558838s
I0321 03:00:47.262997 1599097 config.py:54] PyTorch version 2.6.0 available.
W0321 03:00:47.590442 1599097 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

23_v proxy err 0.07328030467033386 tr(WHW.T) 1486.037353515625
bpp_loss 3.0414196252822876
23_q proxy err 0.018844200298190117 tr(WHW.T) 7346.60986328125
bpp_loss 3.05897319316864
23_k proxy err 0.014290821738541126 tr(WHW.T) 9982.2392578125
bpp_loss 3.0604348182678223
23_o proxy err 0.03503028675913811 tr(WHW.T) 85.13458251953125
bpp_loss 3.1159437894821167
23_up proxy err 0.039830099791288376 tr(WHW.T) 2533.51025390625
bpp_loss 3.0982266803120457
23_gate proxy err 0.026868551969528198 tr(WHW.T) 4097.51953125
bpp_loss 3.1087039681368096
23_down proxy err 0.051744841039180756 tr(WHW.T) 321.33892822265625
bpp_loss 3.074967805729356
W0321 03:00:48.521697 1599097 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:00:48.526000 1596483 quantize_finetune_llama.py:203] layer 26 gpu 2
I0321 03:00:48.540732 1599097 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:00:50.516623 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 26 in 1.014404535293579s
I0321 03:00:54.232387 1599156 config.py:54] PyTorch version 2.6.0 available.
W0321 03:00:54.560739 1599156 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 03:00:55.545332 1599156 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:00:55.549304 1596483 quantize_finetune_llama.py:203] layer 27 gpu 3
I0321 03:00:55.562914 1599156 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:00:56.961915 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 27 in 0.9460611343383789s
I0321 03:01:00.749765 1599215 config.py:54] PyTorch version 2.6.0 available.
W0321 03:01:01.079507 1599215 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 03:01:02.089169 1599215 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:01:02.093205 1596483 quantize_finetune_llama.py:203] layer 28 gpu 0
I0321 03:01:02.107680 1599215 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.0883377343416214 tr(WHW.T) 1394.900634765625
bpp_loss 3.0276224613189697
24_q proxy err 0.021963100880384445 tr(WHW.T) 7020.447265625
bpp_loss 3.041124939918518
24_k proxy err 0.015507876873016357 tr(WHW.T) 10323.43359375
bpp_loss 3.0424654483795166
24_o proxy err 0.04608443006873131 tr(WHW.T) 133.98797607421875
bpp_loss 3.048543095588684
24_up proxy err 0.032645050436258316 tr(WHW.T) 2621.76513671875
bpp_loss 3.1323559783225834
24_gate proxy err 0.021897895261645317 tr(WHW.T) 4262.74853515625
bpp_loss 3.145040467728016
24_down proxy err 0.08816926926374435 tr(WHW.T) 340.22412109375
bpp_loss 3.0261967681175053
25_v proxy err 0.06965363025665283 tr(WHW.T) 1707.664794921875
bpp_loss 3.0487862825393677
25_q proxy err 0.019962415099143982 tr(WHW.T) 7162.16357421875
bpp_loss 3.062761068344116
25_k proxy err 0.015178358182311058 tr(WHW.T) 9611.58984375
bpp_loss 3.0637216567993164
25_o proxy err 0.03562484681606293 tr(WHW.T) 83.535888671875
bpp_loss 3.115608811378479
25_up proxy err 0.03990331292152405 tr(WHW.T) 2805.728515625
bpp_loss 3.10069079731786
25_gate proxy err 0.026149312034249306 tr(WHW.T) 4666.4404296875
bpp_loss 3.110906024311864
25_down proxy err 0.10113665461540222 tr(WHW.T) 373.460693359375
bpp_loss 3.0153447528218114
I0321 03:01:55.409799 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 28 in 0.9921722412109375s
I0321 03:01:59.377345 1599340 config.py:54] PyTorch version 2.6.0 available.
W0321 03:01:59.749279 1599340 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

26_v proxy err 0.07007407397031784 tr(WHW.T) 1668.8843994140625
bpp_loss 3.0488064289093018
26_q proxy err 0.0183718204498291 tr(WHW.T) 7469.98291015625
bpp_loss 3.059994697570801
26_k proxy err 0.013563975691795349 tr(WHW.T) 10487.8740234375
bpp_loss 3.0616469383239746
26_o proxy err 0.03443613275885582 tr(WHW.T) 202.88172912597656
bpp_loss 3.0596702098846436
26_up proxy err 0.036437276750802994 tr(WHW.T) 3154.75146484375
bpp_loss 3.1059584506722384
26_gate proxy err 0.023585980758070946 tr(WHW.T) 5302.16455078125
bpp_loss 3.1164369804914607
26_down proxy err 0.03332976996898651 tr(WHW.T) 401.19390869140625
bpp_loss 3.139351201611896
W0321 03:02:00.781533 1599340 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:02:00.785742 1596483 quantize_finetune_llama.py:203] layer 29 gpu 1
I0321 03:02:00.799209 1599340 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:02:02.594899 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 29 in 1.1898508071899414s
I0321 03:02:06.333359 1599399 config.py:54] PyTorch version 2.6.0 available.
27_v proxy err 0.05423709750175476 tr(WHW.T) 1799.3350830078125
bpp_loss 3.071974754333496
27_q proxy err 0.015256465412676334 tr(WHW.T) 7691.708984375
bpp_loss 3.0891458988189697
27_k proxy err 0.011348264291882515 tr(WHW.T) 10618.70703125
bpp_loss 3.090921401977539
27_o proxy err 0.05365061014890671 tr(WHW.T) 126.13690185546875
bpp_loss 3.0505905151367188
27_up proxy err 0.03486793115735054 tr(WHW.T) 3691.557861328125
bpp_loss 3.1000580898551053
27_gate proxy err 0.023289518430829048 tr(WHW.T) 5990.82568359375
bpp_loss 3.1095907521802326
27_down proxy err 0.03587283566594124 tr(WHW.T) 466.9318542480469
bpp_loss 3.12424114138581
W0321 03:02:06.623041 1599399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 03:02:07.542967 1599399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:02:07.547181 1596483 quantize_finetune_llama.py:203] layer 30 gpu 2
I0321 03:02:07.560642 1599399 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:02:08.989255 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 30 in 0.9723892211914062s
I0321 03:02:12.664861 1599458 config.py:54] PyTorch version 2.6.0 available.
W0321 03:02:12.991927 1599458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 03:02:14.011729 1599458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:02:14.016042 1596483 quantize_finetune_llama.py:203] layer 31 gpu 3
I0321 03:02:14.031004 1599458 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0321 03:02:15.579008 1596483 quantize_finetune_llama.py:234] computed original embedding for layer 31 in 1.0771477222442627s
I0321 03:02:19.500960 1599515 config.py:54] PyTorch version 2.6.0 available.
W0321 03:02:19.840491 1599515 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0321 03:02:20.867231 1599515 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0321 03:02:20.886041 1599515 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.05728280916810036 tr(WHW.T) 2018.944091796875
bpp_loss 3.0642404556274414
28_q proxy err 0.01709013618528843 tr(WHW.T) 7651.126953125
bpp_loss 3.073587417602539
28_k proxy err 0.012783179990947247 tr(WHW.T) 10544.8251953125
bpp_loss 3.075508236885071
28_o proxy err 0.029215317219495773 tr(WHW.T) 194.8240966796875
bpp_loss 3.1044121980667114
28_up proxy err 0.030213167890906334 tr(WHW.T) 4661.2666015625
bpp_loss 3.097331912018532
28_gate proxy err 0.022928817197680473 tr(WHW.T) 6547.48193359375
bpp_loss 3.104799669842387
28_down proxy err 0.058393269777297974 tr(WHW.T) 603.8403930664062
bpp_loss 3.054027712622354
29_v proxy err 0.06502503156661987 tr(WHW.T) 1801.7730712890625
bpp_loss 3.0565587282180786
29_q proxy err 0.017809130251407623 tr(WHW.T) 7227.0009765625
bpp_loss 3.0623857975006104
29_k proxy err 0.012617937289178371 tr(WHW.T) 10558.609375
bpp_loss 3.0641930103302
29_o proxy err 0.022103844210505486 tr(WHW.T) 207.9054412841797
bpp_loss 3.141047716140747
29_up proxy err 0.02395123988389969 tr(WHW.T) 6070.0498046875
bpp_loss 3.100830078125
29_gate proxy err 0.020824803039431572 tr(WHW.T) 7369.6142578125
bpp_loss 3.107506330623183
29_down proxy err 0.04700898006558418 tr(WHW.T) 782.2448120117188
bpp_loss 3.0705093339432117
30_v proxy err 0.036935970187187195 tr(WHW.T) 2261.489501953125
bpp_loss 3.1139014959335327
30_q proxy err 0.011407936923205853 tr(WHW.T) 7815.9453125
bpp_loss 3.119440197944641
30_k proxy err 0.008749761618673801 tr(WHW.T) 10521.625
bpp_loss 3.1223297119140625
30_o proxy err 0.0346587598323822 tr(WHW.T) 251.96908569335938
bpp_loss 3.071036696434021
30_up proxy err 0.01990533620119095 tr(WHW.T) 10016.376953125
bpp_loss 3.0678471409997274
30_gate proxy err 0.019210049882531166 tr(WHW.T) 11001.119140625
bpp_loss 3.0737175165220747
30_down proxy err 0.1214231625199318 tr(WHW.T) 3582.617919921875
bpp_loss 2.9704079295313637
31_v proxy err 0.0394199974834919 tr(WHW.T) 1268.2034912109375
bpp_loss 3.1057769060134888
31_q proxy err 0.008841597475111485 tr(WHW.T) 6858.09130859375
bpp_loss 3.127223491668701
31_k proxy err 0.006284303031861782 tr(WHW.T) 10233.677734375
bpp_loss 3.1335116624832153
31_o proxy err 0.017951110377907753 tr(WHW.T) 457.7950744628906
bpp_loss 3.088991165161133
31_up proxy err 0.017985424026846886 tr(WHW.T) 14563.890625
bpp_loss 3.0329447901526163
31_gate proxy err 0.018722517415881157 tr(WHW.T) 14836.2939453125
bpp_loss 3.0373052552688953
31_down proxy err 0.0283550675958395 tr(WHW.T) 17873.55859375
bpp_loss 2.98343330205873
I0321 03:03:38.437158 1599666 config.py:54] PyTorch version 2.6.0 available.
W0321 03:03:38.744413 1599666 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0321 03:03:38.998925 1599666 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  2.68it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:01,  3.43it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  4.01it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:01<00:00,  4.36it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:01<00:00,  4.82it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  5.08it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  4.44it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  4.35it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  4.47it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  4.98it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  5.28it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:01<00:00,  5.01it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  4.89it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  4.89it/s]
I0321 03:03:42.794290 1599666 hfize_llama.py:153] loaded layer 0
I0321 03:03:43.694292 1599666 hfize_llama.py:153] loaded layer 1
I0321 03:03:44.536160 1599666 hfize_llama.py:153] loaded layer 2
I0321 03:03:45.377620 1599666 hfize_llama.py:153] loaded layer 3
I0321 03:03:46.191191 1599666 hfize_llama.py:153] loaded layer 4
I0321 03:03:47.020897 1599666 hfize_llama.py:153] loaded layer 5
I0321 03:03:47.820482 1599666 hfize_llama.py:153] loaded layer 6
I0321 03:03:48.604496 1599666 hfize_llama.py:153] loaded layer 7
I0321 03:03:49.380995 1599666 hfize_llama.py:153] loaded layer 8
I0321 03:03:50.174865 1599666 hfize_llama.py:153] loaded layer 9
I0321 03:03:50.954820 1599666 hfize_llama.py:153] loaded layer 10
I0321 03:03:51.737410 1599666 hfize_llama.py:153] loaded layer 11
I0321 03:03:52.605239 1599666 hfize_llama.py:153] loaded layer 12
I0321 03:03:53.527508 1599666 hfize_llama.py:153] loaded layer 13
I0321 03:03:54.377208 1599666 hfize_llama.py:153] loaded layer 14
I0321 03:03:55.966954 1599666 hfize_llama.py:153] loaded layer 15
I0321 03:03:58.040987 1599666 hfize_llama.py:153] loaded layer 16
I0321 03:04:00.292766 1599666 hfize_llama.py:153] loaded layer 17
I0321 03:04:02.253726 1599666 hfize_llama.py:153] loaded layer 18
I0321 03:04:04.224390 1599666 hfize_llama.py:153] loaded layer 19
I0321 03:04:06.056700 1599666 hfize_llama.py:153] loaded layer 20
I0321 03:04:08.028495 1599666 hfize_llama.py:153] loaded layer 21
I0321 03:04:10.041760 1599666 hfize_llama.py:153] loaded layer 22
I0321 03:04:11.827644 1599666 hfize_llama.py:153] loaded layer 23
I0321 03:04:13.114260 1599666 hfize_llama.py:153] loaded layer 24
I0321 03:04:14.958536 1599666 hfize_llama.py:153] loaded layer 25
I0321 03:04:16.252011 1599666 hfize_llama.py:153] loaded layer 26
I0321 03:04:17.352843 1599666 hfize_llama.py:153] loaded layer 27
I0321 03:04:19.291730 1599666 hfize_llama.py:153] loaded layer 28
I0321 03:04:21.042124 1599666 hfize_llama.py:153] loaded layer 29
I0321 03:04:22.179758 1599666 hfize_llama.py:153] loaded layer 30
I0321 03:04:24.072667 1599666 hfize_llama.py:153] loaded layer 31
I0321 03:04:24.072781 1599666 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:07,  1.52s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.32s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.26s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.14s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.02it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.11s/it]
I0321 03:05:23.483409 1599666 hfize_llama.py:167] successfully loaded hfized model
I0321 07:20:10.729973 1628624 config.py:54] PyTorch version 2.6.0 available.
W0321 07:20:11.020135 1628624 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0321 07:20:11.252147 1628624 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  9.00it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00, 10.12it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00, 10.01it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.12it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00, 10.29it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00, 10.45it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.60it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.54it/s]
I0321 07:20:14.194807 1628624 hfize_llama.py:153] loaded layer 0
I0321 07:20:15.657123 1628624 hfize_llama.py:153] loaded layer 1
I0321 07:20:17.088874 1628624 hfize_llama.py:153] loaded layer 2
I0321 07:20:18.518324 1628624 hfize_llama.py:153] loaded layer 3
I0321 07:20:19.892949 1628624 hfize_llama.py:153] loaded layer 4
I0321 07:20:21.269723 1628624 hfize_llama.py:153] loaded layer 5
I0321 07:20:22.720980 1628624 hfize_llama.py:153] loaded layer 6
I0321 07:20:24.124269 1628624 hfize_llama.py:153] loaded layer 7
I0321 07:20:25.533810 1628624 hfize_llama.py:153] loaded layer 8
I0321 07:20:26.971352 1628624 hfize_llama.py:153] loaded layer 9
I0321 07:20:28.370451 1628624 hfize_llama.py:153] loaded layer 10
I0321 07:20:29.791142 1628624 hfize_llama.py:153] loaded layer 11
I0321 07:20:31.255410 1628624 hfize_llama.py:153] loaded layer 12
I0321 07:20:32.739802 1628624 hfize_llama.py:153] loaded layer 13
I0321 07:20:34.189552 1628624 hfize_llama.py:153] loaded layer 14
I0321 07:20:35.492168 1628624 hfize_llama.py:153] loaded layer 15
I0321 07:20:36.748717 1628624 hfize_llama.py:153] loaded layer 16
I0321 07:20:38.071170 1628624 hfize_llama.py:153] loaded layer 17
I0321 07:20:39.117175 1628624 hfize_llama.py:153] loaded layer 18
I0321 07:20:40.445180 1628624 hfize_llama.py:153] loaded layer 19
I0321 07:20:41.639030 1628624 hfize_llama.py:153] loaded layer 20
I0321 07:20:43.082726 1628624 hfize_llama.py:153] loaded layer 21
I0321 07:20:44.540422 1628624 hfize_llama.py:153] loaded layer 22
I0321 07:20:45.930432 1628624 hfize_llama.py:153] loaded layer 23
I0321 07:20:46.981520 1628624 hfize_llama.py:153] loaded layer 24
I0321 07:20:48.091892 1628624 hfize_llama.py:153] loaded layer 25
I0321 07:20:49.218810 1628624 hfize_llama.py:153] loaded layer 26
I0321 07:20:50.384472 1628624 hfize_llama.py:153] loaded layer 27
I0321 07:20:51.320910 1628624 hfize_llama.py:153] loaded layer 28
I0321 07:20:52.198445 1628624 hfize_llama.py:153] loaded layer 29
I0321 07:20:53.076379 1628624 hfize_llama.py:153] loaded layer 30
I0321 07:20:54.135062 1628624 hfize_llama.py:153] loaded layer 31
I0321 07:20:54.135242 1628624 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.04it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.20it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.28it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.30it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.32it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.55it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]
I0321 07:21:27.080643 1628624 hfize_llama.py:167] successfully loaded hfized model
W0321 07:21:30.739122 1629814 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0321 07:21:31.262511 1629814 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.28it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.22it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.21it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.20it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.20it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]
I0321 07:21:36.326864 1629814 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 4.053138732910156:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 4.053138732910156:   1%|          | 1/166 [00:01<04:25,  1.61s/it]avg_loss = 4.341749429702759:   1%|          | 1/166 [00:02<04:25,  1.61s/it]avg_loss = 4.341749429702759:   1%|          | 2/166 [00:02<03:45,  1.38s/it]avg_loss = 4.594805876413981:   1%|          | 2/166 [00:04<03:45,  1.38s/it]avg_loss = 4.594805876413981:   2%|▏         | 3/166 [00:04<03:32,  1.31s/it]avg_loss = 4.7417073249816895:   2%|▏         | 3/166 [00:05<03:32,  1.31s/it]avg_loss = 4.7417073249816895:   2%|▏         | 4/166 [00:05<03:26,  1.27s/it]avg_loss = 4.584071683883667:   2%|▏         | 4/166 [00:06<03:26,  1.27s/it] avg_loss = 4.584071683883667:   3%|▎         | 5/166 [00:06<03:22,  1.26s/it]avg_loss = 4.641623218854268:   3%|▎         | 5/166 [00:07<03:22,  1.26s/it]avg_loss = 4.641623218854268:   4%|▎         | 6/166 [00:07<03:20,  1.25s/it]avg_loss = 4.4896601268223355:   4%|▎         | 6/166 [00:08<03:20,  1.25s/it]avg_loss = 4.4896601268223355:   4%|▍         | 7/166 [00:08<03:18,  1.25s/it]avg_loss = 4.358835071325302:   4%|▍         | 7/166 [00:10<03:18,  1.25s/it] avg_loss = 4.358835071325302:   5%|▍         | 8/166 [00:10<03:16,  1.25s/it]avg_loss = 4.3298548857371015:   5%|▍         | 8/166 [00:11<03:16,  1.25s/it]avg_loss = 4.3298548857371015:   5%|▌         | 9/166 [00:11<03:15,  1.25s/it]avg_loss = 4.323378729820251:   5%|▌         | 9/166 [00:12<03:15,  1.25s/it] avg_loss = 4.323378729820251:   6%|▌         | 10/166 [00:12<03:14,  1.25s/it]avg_loss = 4.354160980744795:   6%|▌         | 10/166 [00:13<03:14,  1.25s/it]avg_loss = 4.354160980744795:   7%|▋         | 11/166 [00:13<03:13,  1.25s/it]avg_loss = 4.358726004759471:   7%|▋         | 11/166 [00:15<03:13,  1.25s/it]avg_loss = 4.358726004759471:   7%|▋         | 12/166 [00:15<03:12,  1.25s/it]avg_loss = 4.325965166091919:   7%|▋         | 12/166 [00:16<03:12,  1.25s/it]avg_loss = 4.325965166091919:   8%|▊         | 13/166 [00:16<03:11,  1.25s/it]avg_loss = 4.332795364516122:   8%|▊         | 13/166 [00:17<03:11,  1.25s/it]avg_loss = 4.332795364516122:   8%|▊         | 14/166 [00:17<03:10,  1.25s/it]avg_loss = 4.353028726577759:   8%|▊         | 14/166 [00:18<03:10,  1.25s/it]avg_loss = 4.353028726577759:   9%|▉         | 15/166 [00:18<03:09,  1.25s/it]avg_loss = 4.351469501852989:   9%|▉         | 15/166 [00:20<03:09,  1.25s/it]avg_loss = 4.351469501852989:  10%|▉         | 16/166 [00:20<03:08,  1.26s/it]avg_loss = 4.338913987664616:  10%|▉         | 16/166 [00:21<03:08,  1.26s/it]avg_loss = 4.338913987664616:  10%|█         | 17/166 [00:21<03:07,  1.26s/it]avg_loss = 4.340147693951924:  10%|█         | 17/166 [00:22<03:07,  1.26s/it]avg_loss = 4.340147693951924:  11%|█         | 18/166 [00:22<03:06,  1.26s/it]avg_loss = 4.358810638126574:  11%|█         | 18/166 [00:24<03:06,  1.26s/it]avg_loss = 4.358810638126574:  11%|█▏        | 19/166 [00:24<03:05,  1.26s/it]avg_loss = 4.367111361026764:  11%|█▏        | 19/166 [00:25<03:05,  1.26s/it]avg_loss = 4.367111361026764:  12%|█▏        | 20/166 [00:25<03:04,  1.26s/it]avg_loss = 4.3665524777911955:  12%|█▏        | 20/166 [00:26<03:04,  1.26s/it]avg_loss = 4.3665524777911955:  13%|█▎        | 21/166 [00:26<03:03,  1.26s/it]avg_loss = 4.331353360956365:  13%|█▎        | 21/166 [00:27<03:03,  1.26s/it] avg_loss = 4.331353360956365:  13%|█▎        | 22/166 [00:27<03:02,  1.27s/it]avg_loss = 4.315885616385418:  13%|█▎        | 22/166 [00:29<03:02,  1.27s/it]avg_loss = 4.315885616385418:  14%|█▍        | 23/166 [00:29<03:01,  1.27s/it]avg_loss = 4.3373880088329315:  14%|█▍        | 23/166 [00:30<03:01,  1.27s/it]avg_loss = 4.3373880088329315:  14%|█▍        | 24/166 [00:30<03:00,  1.27s/it]avg_loss = 4.359597387313843:  14%|█▍        | 24/166 [00:31<03:00,  1.27s/it] avg_loss = 4.359597387313843:  15%|█▌        | 25/166 [00:31<02:58,  1.27s/it]avg_loss = 4.366344240995554:  15%|█▌        | 25/166 [00:32<02:58,  1.27s/it]avg_loss = 4.366344240995554:  16%|█▌        | 26/166 [00:32<02:57,  1.27s/it]avg_loss = 4.379105029282747:  16%|█▌        | 26/166 [00:34<02:57,  1.27s/it]avg_loss = 4.379105029282747:  16%|█▋        | 27/166 [00:34<02:56,  1.27s/it]avg_loss = 4.383306324481964:  16%|█▋        | 27/166 [00:35<02:56,  1.27s/it]avg_loss = 4.383306324481964:  17%|█▋        | 28/166 [00:35<02:55,  1.27s/it]avg_loss = 4.400054035515621:  17%|█▋        | 28/166 [00:36<02:55,  1.27s/it]avg_loss = 4.400054035515621:  17%|█▋        | 29/166 [00:36<02:54,  1.28s/it]avg_loss = 4.408572252591451:  17%|█▋        | 29/166 [00:38<02:54,  1.28s/it]avg_loss = 4.408572252591451:  18%|█▊        | 30/166 [00:38<02:53,  1.28s/it]avg_loss = 4.423391088362663:  18%|█▊        | 30/166 [00:39<02:53,  1.28s/it]avg_loss = 4.423391088362663:  19%|█▊        | 31/166 [00:39<02:52,  1.28s/it]avg_loss = 4.435595087707043:  19%|█▊        | 31/166 [00:40<02:52,  1.28s/it]avg_loss = 4.435595087707043:  19%|█▉        | 32/166 [00:40<02:51,  1.28s/it]avg_loss = 4.465984337257616:  19%|█▉        | 32/166 [00:41<02:51,  1.28s/it]avg_loss = 4.465984337257616:  20%|█▉        | 33/166 [00:41<02:50,  1.28s/it]avg_loss = 4.480826553176431:  20%|█▉        | 33/166 [00:43<02:50,  1.28s/it]avg_loss = 4.480826553176431:  20%|██        | 34/166 [00:43<02:48,  1.28s/it]avg_loss = 4.498203066417149:  20%|██        | 34/166 [00:44<02:48,  1.28s/it]avg_loss = 4.498203066417149:  21%|██        | 35/166 [00:44<02:47,  1.28s/it]avg_loss = 4.502745012442271:  21%|██        | 35/166 [00:45<02:47,  1.28s/it]avg_loss = 4.502745012442271:  22%|██▏       | 36/166 [00:45<02:46,  1.28s/it]avg_loss = 4.514713731971947:  22%|██▏       | 36/166 [00:46<02:46,  1.28s/it]avg_loss = 4.514713731971947:  22%|██▏       | 37/166 [00:46<02:45,  1.28s/it]avg_loss = 4.521596438006351:  22%|██▏       | 37/166 [00:48<02:45,  1.28s/it]avg_loss = 4.521596438006351:  23%|██▎       | 38/166 [00:48<02:44,  1.28s/it]avg_loss = 4.527231357036492:  23%|██▎       | 38/166 [00:49<02:44,  1.28s/it]avg_loss = 4.527231357036492:  23%|██▎       | 39/166 [00:49<02:43,  1.28s/it]avg_loss = 4.5308507025241855:  23%|██▎       | 39/166 [00:50<02:43,  1.28s/it]avg_loss = 4.5308507025241855:  24%|██▍       | 40/166 [00:50<02:41,  1.28s/it]avg_loss = 4.52525954711728:  24%|██▍       | 40/166 [00:52<02:41,  1.28s/it]  avg_loss = 4.52525954711728:  25%|██▍       | 41/166 [00:52<02:40,  1.29s/it]avg_loss = 4.509309569994609:  25%|██▍       | 41/166 [00:53<02:40,  1.29s/it]avg_loss = 4.509309569994609:  25%|██▌       | 42/166 [00:53<02:39,  1.29s/it]avg_loss = 4.496862034464991:  25%|██▌       | 42/166 [00:54<02:39,  1.29s/it]avg_loss = 4.496862034464991:  26%|██▌       | 43/166 [00:54<02:38,  1.29s/it]avg_loss = 4.487490924921903:  26%|██▌       | 43/166 [00:56<02:38,  1.29s/it]avg_loss = 4.487490924921903:  27%|██▋       | 44/166 [00:56<02:37,  1.29s/it]avg_loss = 4.469878498713175:  27%|██▋       | 44/166 [00:57<02:37,  1.29s/it]avg_loss = 4.469878498713175:  27%|██▋       | 45/166 [00:57<02:36,  1.29s/it]avg_loss = 4.4560069986011674:  27%|██▋       | 45/166 [00:58<02:36,  1.29s/it]avg_loss = 4.4560069986011674:  28%|██▊       | 46/166 [00:58<02:34,  1.29s/it]avg_loss = 4.452325511485972:  28%|██▊       | 46/166 [00:59<02:34,  1.29s/it] avg_loss = 4.452325511485972:  28%|██▊       | 47/166 [00:59<02:33,  1.29s/it]avg_loss = 4.456572179992993:  28%|██▊       | 47/166 [01:01<02:33,  1.29s/it]avg_loss = 4.456572179992993:  29%|██▉       | 48/166 [01:01<02:32,  1.29s/it]avg_loss = 4.470242913888425:  29%|██▉       | 48/166 [01:02<02:32,  1.29s/it]avg_loss = 4.470242913888425:  30%|██▉       | 49/166 [01:02<02:31,  1.30s/it]avg_loss = 4.480304045677185:  30%|██▉       | 49/166 [01:03<02:31,  1.30s/it]avg_loss = 4.480304045677185:  30%|███       | 50/166 [01:03<02:30,  1.30s/it]avg_loss = 4.491370355381685:  30%|███       | 50/166 [01:05<02:30,  1.30s/it]avg_loss = 4.491370355381685:  31%|███       | 51/166 [01:05<02:29,  1.30s/it]avg_loss = 4.497615314446962:  31%|███       | 51/166 [01:06<02:29,  1.30s/it]avg_loss = 4.497615314446962:  31%|███▏      | 52/166 [01:06<02:28,  1.30s/it]avg_loss = 4.50343589512807:  31%|███▏      | 52/166 [01:07<02:28,  1.30s/it] avg_loss = 4.50343589512807:  32%|███▏      | 53/166 [01:07<02:26,  1.30s/it]avg_loss = 4.49547306255058:  32%|███▏      | 53/166 [01:08<02:26,  1.30s/it]avg_loss = 4.49547306255058:  33%|███▎      | 54/166 [01:08<02:25,  1.30s/it]avg_loss = 4.498706917329268:  33%|███▎      | 54/166 [01:10<02:25,  1.30s/it]avg_loss = 4.498706917329268:  33%|███▎      | 55/166 [01:10<02:24,  1.30s/it]avg_loss = 4.492320431130273:  33%|███▎      | 55/166 [01:11<02:24,  1.30s/it]avg_loss = 4.492320431130273:  34%|███▎      | 56/166 [01:11<02:22,  1.30s/it]avg_loss = 4.475989475584867:  34%|███▎      | 56/166 [01:12<02:22,  1.30s/it]avg_loss = 4.475989475584867:  34%|███▍      | 57/166 [01:12<02:21,  1.30s/it]avg_loss = 4.482770303200031:  34%|███▍      | 57/166 [01:14<02:21,  1.30s/it]avg_loss = 4.482770303200031:  35%|███▍      | 58/166 [01:14<02:20,  1.30s/it]avg_loss = 4.478321212833211:  35%|███▍      | 58/166 [01:15<02:20,  1.30s/it]avg_loss = 4.478321212833211:  36%|███▌      | 59/166 [01:15<02:19,  1.30s/it]avg_loss = 4.472197723388672:  36%|███▌      | 59/166 [01:16<02:19,  1.30s/it]avg_loss = 4.472197723388672:  36%|███▌      | 60/166 [01:16<02:17,  1.30s/it]avg_loss = 4.461544791205984:  36%|███▌      | 60/166 [01:18<02:17,  1.30s/it]avg_loss = 4.461544791205984:  37%|███▋      | 61/166 [01:18<02:16,  1.30s/it]avg_loss = 4.460789461289683:  37%|███▋      | 61/166 [01:19<02:16,  1.30s/it]avg_loss = 4.460789461289683:  37%|███▋      | 62/166 [01:19<02:15,  1.30s/it]avg_loss = 4.455721283715869:  37%|███▋      | 62/166 [01:20<02:15,  1.30s/it]avg_loss = 4.455721283715869:  38%|███▊      | 63/166 [01:20<02:13,  1.30s/it]avg_loss = 4.450379829853773:  38%|███▊      | 63/166 [01:21<02:13,  1.30s/it]avg_loss = 4.450379829853773:  39%|███▊      | 64/166 [01:21<02:12,  1.30s/it]avg_loss = 4.444413496897771:  39%|███▊      | 64/166 [01:23<02:12,  1.30s/it]avg_loss = 4.444413496897771:  39%|███▉      | 65/166 [01:23<02:11,  1.30s/it]avg_loss = 4.430886330026569:  39%|███▉      | 65/166 [01:24<02:11,  1.30s/it]avg_loss = 4.430886330026569:  40%|███▉      | 66/166 [01:24<02:09,  1.30s/it]avg_loss = 4.423657641481998:  40%|███▉      | 66/166 [01:25<02:09,  1.30s/it]avg_loss = 4.423657641481998:  40%|████      | 67/166 [01:25<02:08,  1.30s/it]avg_loss = 4.420823444338406:  40%|████      | 67/166 [01:27<02:08,  1.30s/it]avg_loss = 4.420823444338406:  41%|████      | 68/166 [01:27<02:07,  1.30s/it]avg_loss = 4.423513415930928:  41%|████      | 68/166 [01:28<02:07,  1.30s/it]avg_loss = 4.423513415930928:  42%|████▏     | 69/166 [01:28<02:06,  1.30s/it]avg_loss = 4.433401145253863:  42%|████▏     | 69/166 [01:29<02:06,  1.30s/it]avg_loss = 4.433401145253863:  42%|████▏     | 70/166 [01:29<02:04,  1.30s/it]avg_loss = 4.438558769897676:  42%|████▏     | 70/166 [01:31<02:04,  1.30s/it]avg_loss = 4.438558769897676:  43%|████▎     | 71/166 [01:31<02:03,  1.30s/it]avg_loss = 4.447187254826228:  43%|████▎     | 71/166 [01:32<02:03,  1.30s/it]avg_loss = 4.447187254826228:  43%|████▎     | 72/166 [01:32<02:02,  1.30s/it]avg_loss = 4.458994907875583:  43%|████▎     | 72/166 [01:33<02:02,  1.30s/it]avg_loss = 4.458994907875583:  44%|████▍     | 73/166 [01:33<02:01,  1.30s/it]avg_loss = 4.4534366420797395:  44%|████▍     | 73/166 [01:34<02:01,  1.30s/it]avg_loss = 4.4534366420797395:  45%|████▍     | 74/166 [01:34<01:59,  1.30s/it]avg_loss = 4.456625229517619:  45%|████▍     | 74/166 [01:36<01:59,  1.30s/it] avg_loss = 4.456625229517619:  45%|████▌     | 75/166 [01:36<01:58,  1.30s/it]avg_loss = 4.460438913420627:  45%|████▌     | 75/166 [01:37<01:58,  1.30s/it]avg_loss = 4.460438913420627:  46%|████▌     | 76/166 [01:37<01:57,  1.30s/it]avg_loss = 4.456037233402203:  46%|████▌     | 76/166 [01:38<01:57,  1.30s/it]avg_loss = 4.456037233402203:  46%|████▋     | 77/166 [01:38<01:55,  1.30s/it]avg_loss = 4.454530156575716:  46%|████▋     | 77/166 [01:40<01:55,  1.30s/it]avg_loss = 4.454530156575716:  47%|████▋     | 78/166 [01:40<01:54,  1.30s/it]avg_loss = 4.450014292439328:  47%|████▋     | 78/166 [01:41<01:54,  1.30s/it]avg_loss = 4.450014292439328:  48%|████▊     | 79/166 [01:41<01:53,  1.31s/it]avg_loss = 4.446212550997734:  48%|████▊     | 79/166 [01:42<01:53,  1.31s/it]avg_loss = 4.446212550997734:  48%|████▊     | 80/166 [01:42<01:52,  1.30s/it]avg_loss = 4.42799954061155:  48%|████▊     | 80/166 [01:44<01:52,  1.30s/it] avg_loss = 4.42799954061155:  49%|████▉     | 81/166 [01:44<01:50,  1.31s/it]avg_loss = 4.424589514732361:  49%|████▉     | 81/166 [01:45<01:50,  1.31s/it]avg_loss = 4.424589514732361:  49%|████▉     | 82/166 [01:45<01:49,  1.31s/it]avg_loss = 4.426767288920391:  49%|████▉     | 82/166 [01:46<01:49,  1.31s/it]avg_loss = 4.426767288920391:  50%|█████     | 83/166 [01:46<01:48,  1.30s/it]avg_loss = 4.434668469996679:  50%|█████     | 83/166 [01:48<01:48,  1.30s/it]avg_loss = 4.434668469996679:  51%|█████     | 84/166 [01:48<01:47,  1.31s/it]avg_loss = 4.439764463200289:  51%|█████     | 84/166 [01:49<01:47,  1.31s/it]avg_loss = 4.439764463200289:  51%|█████     | 85/166 [01:49<01:45,  1.31s/it]avg_loss = 4.437564586484155:  51%|█████     | 85/166 [01:50<01:45,  1.31s/it]avg_loss = 4.437564586484155:  52%|█████▏    | 86/166 [01:50<01:44,  1.31s/it]avg_loss = 4.43620027070758:  52%|█████▏    | 86/166 [01:51<01:44,  1.31s/it] avg_loss = 4.43620027070758:  52%|█████▏    | 87/166 [01:51<01:43,  1.31s/it]avg_loss = 4.4363042414188385:  52%|█████▏    | 87/166 [01:53<01:43,  1.31s/it]avg_loss = 4.4363042414188385:  53%|█████▎    | 88/166 [01:53<01:41,  1.31s/it]avg_loss = 4.438369330395473:  53%|█████▎    | 88/166 [01:54<01:41,  1.31s/it] avg_loss = 4.438369330395473:  54%|█████▎    | 89/166 [01:54<01:40,  1.31s/it]avg_loss = 4.442222984631856:  54%|█████▎    | 89/166 [01:55<01:40,  1.31s/it]avg_loss = 4.442222984631856:  54%|█████▍    | 90/166 [01:55<01:39,  1.31s/it]avg_loss = 4.443160096367637:  54%|█████▍    | 90/166 [01:57<01:39,  1.31s/it]avg_loss = 4.443160096367637:  55%|█████▍    | 91/166 [01:57<01:38,  1.31s/it]avg_loss = 4.447401168553726:  55%|█████▍    | 91/166 [01:58<01:38,  1.31s/it]avg_loss = 4.447401168553726:  55%|█████▌    | 92/166 [01:58<01:36,  1.31s/it]avg_loss = 4.449863462037937:  55%|█████▌    | 92/166 [01:59<01:36,  1.31s/it]avg_loss = 4.449863462037937:  56%|█████▌    | 93/166 [01:59<01:35,  1.31s/it]avg_loss = 4.439720876673435:  56%|█████▌    | 93/166 [02:01<01:35,  1.31s/it]avg_loss = 4.439720876673435:  57%|█████▋    | 94/166 [02:01<01:34,  1.31s/it]avg_loss = 4.432388709720812:  57%|█████▋    | 94/166 [02:02<01:34,  1.31s/it]avg_loss = 4.432388709720812:  57%|█████▋    | 95/166 [02:02<01:32,  1.31s/it]avg_loss = 4.430810752014319:  57%|█████▋    | 95/166 [02:03<01:32,  1.31s/it]avg_loss = 4.430810752014319:  58%|█████▊    | 96/166 [02:03<01:31,  1.31s/it]avg_loss = 4.426468478035681:  58%|█████▊    | 96/166 [02:05<01:31,  1.31s/it]avg_loss = 4.426468478035681:  58%|█████▊    | 97/166 [02:05<01:30,  1.31s/it]avg_loss = 4.424051924627655:  58%|█████▊    | 97/166 [02:06<01:30,  1.31s/it]avg_loss = 4.424051924627655:  59%|█████▉    | 98/166 [02:06<01:28,  1.31s/it]avg_loss = 4.423860976190278:  59%|█████▉    | 98/166 [02:07<01:28,  1.31s/it]avg_loss = 4.423860976190278:  60%|█████▉    | 99/166 [02:07<01:27,  1.31s/it]avg_loss = 4.425911929607391:  60%|█████▉    | 99/166 [02:08<01:27,  1.31s/it]avg_loss = 4.425911929607391:  60%|██████    | 100/166 [02:08<01:26,  1.31s/it]avg_loss = 4.427570576714997:  60%|██████    | 100/166 [02:10<01:26,  1.31s/it]avg_loss = 4.427570576714997:  61%|██████    | 101/166 [02:10<01:25,  1.31s/it]avg_loss = 4.42948126559164:  61%|██████    | 101/166 [02:11<01:25,  1.31s/it] avg_loss = 4.42948126559164:  61%|██████▏   | 102/166 [02:11<01:23,  1.31s/it]avg_loss = 4.4307233916903:  61%|██████▏   | 102/166 [02:12<01:23,  1.31s/it] avg_loss = 4.4307233916903:  62%|██████▏   | 103/166 [02:12<01:22,  1.31s/it]avg_loss = 4.437420608905645:  62%|██████▏   | 103/166 [02:14<01:22,  1.31s/it]avg_loss = 4.437420608905645:  63%|██████▎   | 104/166 [02:14<01:21,  1.31s/it]avg_loss = 4.444239332562401:  63%|██████▎   | 104/166 [02:15<01:21,  1.31s/it]avg_loss = 4.444239332562401:  63%|██████▎   | 105/166 [02:15<01:19,  1.31s/it]avg_loss = 4.449232009221923:  63%|██████▎   | 105/166 [02:16<01:19,  1.31s/it]avg_loss = 4.449232009221923:  64%|██████▍   | 106/166 [02:16<01:18,  1.31s/it]avg_loss = 4.456237144559343:  64%|██████▍   | 106/166 [02:18<01:18,  1.31s/it]avg_loss = 4.456237144559343:  64%|██████▍   | 107/166 [02:18<01:17,  1.31s/it]avg_loss = 4.464414846014093:  64%|██████▍   | 107/166 [02:19<01:17,  1.31s/it]avg_loss = 4.464414846014093:  65%|██████▌   | 108/166 [02:19<01:15,  1.31s/it]avg_loss = 4.472986066013301:  65%|██████▌   | 108/166 [02:20<01:15,  1.31s/it]avg_loss = 4.472986066013301:  66%|██████▌   | 109/166 [02:20<01:14,  1.31s/it]avg_loss = 4.477861931107261:  66%|██████▌   | 109/166 [02:22<01:14,  1.31s/it]avg_loss = 4.477861931107261:  66%|██████▋   | 110/166 [02:22<01:13,  1.31s/it]avg_loss = 4.474936530396745:  66%|██████▋   | 110/166 [02:23<01:13,  1.31s/it]avg_loss = 4.474936530396745:  67%|██████▋   | 111/166 [02:23<01:12,  1.31s/it]avg_loss = 4.482633460845266:  67%|██████▋   | 111/166 [02:24<01:12,  1.31s/it]avg_loss = 4.482633460845266:  67%|██████▋   | 112/166 [02:24<01:10,  1.31s/it]avg_loss = 4.4814207300675655:  67%|██████▋   | 112/166 [02:26<01:10,  1.31s/it]avg_loss = 4.4814207300675655:  68%|██████▊   | 113/166 [02:26<01:09,  1.31s/it]avg_loss = 4.483446169317815:  68%|██████▊   | 113/166 [02:27<01:09,  1.31s/it] avg_loss = 4.483446169317815:  69%|██████▊   | 114/166 [02:27<01:08,  1.31s/it]avg_loss = 4.483890390396118:  69%|██████▊   | 114/166 [02:28<01:08,  1.31s/it]avg_loss = 4.483890390396118:  69%|██████▉   | 115/166 [02:28<01:06,  1.31s/it]avg_loss = 4.4849828584440825:  69%|██████▉   | 115/166 [02:29<01:06,  1.31s/it]avg_loss = 4.4849828584440825:  70%|██████▉   | 116/166 [02:29<01:05,  1.31s/it]avg_loss = 4.484272416840252:  70%|██████▉   | 116/166 [02:31<01:05,  1.31s/it] avg_loss = 4.484272416840252:  70%|███████   | 117/166 [02:31<01:04,  1.31s/it]avg_loss = 4.483594326649682:  70%|███████   | 117/166 [02:32<01:04,  1.31s/it]avg_loss = 4.483594326649682:  71%|███████   | 118/166 [02:32<01:02,  1.31s/it]avg_loss = 4.485221504163341:  71%|███████   | 118/166 [02:33<01:02,  1.31s/it]avg_loss = 4.485221504163341:  72%|███████▏  | 119/166 [02:33<01:01,  1.31s/it]avg_loss = 4.485656454165777:  72%|███████▏  | 119/166 [02:35<01:01,  1.31s/it]avg_loss = 4.485656454165777:  72%|███████▏  | 120/166 [02:35<01:00,  1.31s/it]avg_loss = 4.485286245661333:  72%|███████▏  | 120/166 [02:36<01:00,  1.31s/it]avg_loss = 4.485286245661333:  73%|███████▎  | 121/166 [02:36<00:58,  1.31s/it]avg_loss = 4.486295866184547:  73%|███████▎  | 121/166 [02:37<00:58,  1.31s/it]avg_loss = 4.486295866184547:  73%|███████▎  | 122/166 [02:37<00:57,  1.31s/it]avg_loss = 4.487158781144677:  73%|███████▎  | 122/166 [02:39<00:57,  1.31s/it]avg_loss = 4.487158781144677:  74%|███████▍  | 123/166 [02:39<00:56,  1.31s/it]avg_loss = 4.486280946962295:  74%|███████▍  | 123/166 [02:40<00:56,  1.31s/it]avg_loss = 4.486280946962295:  75%|███████▍  | 124/166 [02:40<00:54,  1.31s/it]avg_loss = 4.484518972396851:  75%|███████▍  | 124/166 [02:41<00:54,  1.31s/it]avg_loss = 4.484518972396851:  75%|███████▌  | 125/166 [02:41<00:53,  1.31s/it]avg_loss = 4.482631972857884:  75%|███████▌  | 125/166 [02:43<00:53,  1.31s/it]avg_loss = 4.482631972857884:  76%|███████▌  | 126/166 [02:43<00:52,  1.31s/it]avg_loss = 4.478244544952873:  76%|███████▌  | 126/166 [02:44<00:52,  1.31s/it]avg_loss = 4.478244544952873:  77%|███████▋  | 127/166 [02:44<00:51,  1.31s/it]avg_loss = 4.478054851293564:  77%|███████▋  | 127/166 [02:45<00:51,  1.31s/it]avg_loss = 4.478054851293564:  77%|███████▋  | 128/166 [02:45<00:49,  1.31s/it]avg_loss = 4.477957762489023:  77%|███████▋  | 128/166 [02:46<00:49,  1.31s/it]avg_loss = 4.477957762489023:  78%|███████▊  | 129/166 [02:46<00:48,  1.31s/it]avg_loss = 4.481414288740892:  78%|███████▊  | 129/166 [02:48<00:48,  1.31s/it]avg_loss = 4.481414288740892:  78%|███████▊  | 130/166 [02:48<00:47,  1.31s/it]avg_loss = 4.480637142676433:  78%|███████▊  | 130/166 [02:49<00:47,  1.31s/it]avg_loss = 4.480637142676433:  79%|███████▉  | 131/166 [02:49<00:45,  1.31s/it]avg_loss = 4.483764456980156:  79%|███████▉  | 131/166 [02:50<00:45,  1.31s/it]avg_loss = 4.483764456980156:  80%|███████▉  | 132/166 [02:50<00:44,  1.31s/it]avg_loss = 4.485585772005239:  80%|███████▉  | 132/166 [02:52<00:44,  1.31s/it]avg_loss = 4.485585772005239:  80%|████████  | 133/166 [02:52<00:43,  1.31s/it]avg_loss = 4.486864677116053:  80%|████████  | 133/166 [02:53<00:43,  1.31s/it]avg_loss = 4.486864677116053:  81%|████████  | 134/166 [02:53<00:41,  1.31s/it]avg_loss = 4.482911812817609:  81%|████████  | 134/166 [02:54<00:41,  1.31s/it]avg_loss = 4.482911812817609:  81%|████████▏ | 135/166 [02:54<00:40,  1.31s/it]avg_loss = 4.485632202204536:  81%|████████▏ | 135/166 [02:56<00:40,  1.31s/it]avg_loss = 4.485632202204536:  82%|████████▏ | 136/166 [02:56<00:39,  1.31s/it]avg_loss = 4.484770433746115:  82%|████████▏ | 136/166 [02:57<00:39,  1.31s/it]avg_loss = 4.484770433746115:  83%|████████▎ | 137/166 [02:57<00:37,  1.31s/it]avg_loss = 4.485290098881376:  83%|████████▎ | 137/166 [02:58<00:37,  1.31s/it]avg_loss = 4.485290098881376:  83%|████████▎ | 138/166 [02:58<00:36,  1.31s/it]avg_loss = 4.482682536831863:  83%|████████▎ | 138/166 [03:00<00:36,  1.31s/it]avg_loss = 4.482682536831863:  84%|████████▎ | 139/166 [03:00<00:35,  1.31s/it]avg_loss = 4.477096167632512:  84%|████████▎ | 139/166 [03:01<00:35,  1.31s/it]avg_loss = 4.477096167632512:  84%|████████▍ | 140/166 [03:01<00:34,  1.31s/it]avg_loss = 4.475090552729072:  84%|████████▍ | 140/166 [03:02<00:34,  1.31s/it]avg_loss = 4.475090552729072:  85%|████████▍ | 141/166 [03:02<00:32,  1.31s/it]avg_loss = 4.473479813253376:  85%|████████▍ | 141/166 [03:03<00:32,  1.31s/it]avg_loss = 4.473479813253376:  86%|████████▌ | 142/166 [03:03<00:31,  1.31s/it]avg_loss = 4.472512126802565:  86%|████████▌ | 142/166 [03:05<00:31,  1.31s/it]avg_loss = 4.472512126802565:  86%|████████▌ | 143/166 [03:05<00:30,  1.31s/it]avg_loss = 4.473385630382432:  86%|████████▌ | 143/166 [03:06<00:30,  1.31s/it]avg_loss = 4.473385630382432:  87%|████████▋ | 144/166 [03:06<00:28,  1.31s/it]avg_loss = 4.470890813038267:  87%|████████▋ | 144/166 [03:07<00:28,  1.31s/it]avg_loss = 4.470890813038267:  87%|████████▋ | 145/166 [03:07<00:27,  1.31s/it]avg_loss = 4.468517563114427:  87%|████████▋ | 145/166 [03:09<00:27,  1.31s/it]avg_loss = 4.468517563114427:  88%|████████▊ | 146/166 [03:09<00:26,  1.31s/it]avg_loss = 4.462849955980469:  88%|████████▊ | 146/166 [03:10<00:26,  1.31s/it]avg_loss = 4.462849955980469:  89%|████████▊ | 147/166 [03:10<00:24,  1.31s/it]avg_loss = 4.458697617053986:  89%|████████▊ | 147/166 [03:11<00:24,  1.31s/it]avg_loss = 4.458697617053986:  89%|████████▉ | 148/166 [03:11<00:23,  1.31s/it]avg_loss = 4.454908876611082:  89%|████████▉ | 148/166 [03:13<00:23,  1.31s/it]avg_loss = 4.454908876611082:  90%|████████▉ | 149/166 [03:13<00:22,  1.31s/it]avg_loss = 4.455519971847534:  90%|████████▉ | 149/166 [03:14<00:22,  1.31s/it]avg_loss = 4.455519971847534:  90%|█████████ | 150/166 [03:14<00:20,  1.31s/it]avg_loss = 4.4524177147063195:  90%|█████████ | 150/166 [03:15<00:20,  1.31s/it]avg_loss = 4.4524177147063195:  91%|█████████ | 151/166 [03:15<00:19,  1.31s/it]avg_loss = 4.452148243000633:  91%|█████████ | 151/166 [03:17<00:19,  1.31s/it] avg_loss = 4.452148243000633:  92%|█████████▏| 152/166 [03:17<00:18,  1.31s/it]avg_loss = 4.449816713146135:  92%|█████████▏| 152/166 [03:18<00:18,  1.31s/it]avg_loss = 4.449816713146135:  92%|█████████▏| 153/166 [03:18<00:17,  1.31s/it]avg_loss = 4.451485912521164:  92%|█████████▏| 153/166 [03:19<00:17,  1.31s/it]avg_loss = 4.451485912521164:  93%|█████████▎| 154/166 [03:19<00:15,  1.31s/it]avg_loss = 4.448288600675522:  93%|█████████▎| 154/166 [03:21<00:15,  1.31s/it]avg_loss = 4.448288600675522:  93%|█████████▎| 155/166 [03:21<00:14,  1.31s/it]avg_loss = 4.446781962345808:  93%|█████████▎| 155/166 [03:22<00:14,  1.31s/it]avg_loss = 4.446781962345808:  94%|█████████▍| 156/166 [03:22<00:13,  1.31s/it]avg_loss = 4.443094980944494:  94%|█████████▍| 156/166 [03:23<00:13,  1.31s/it]avg_loss = 4.443094980944494:  95%|█████████▍| 157/166 [03:23<00:11,  1.31s/it]avg_loss = 4.430388058288188:  95%|█████████▍| 157/166 [03:24<00:11,  1.31s/it]avg_loss = 4.430388058288188:  95%|█████████▌| 158/166 [03:24<00:10,  1.31s/it]avg_loss = 4.430942082555039:  95%|█████████▌| 158/166 [03:26<00:10,  1.31s/it]avg_loss = 4.430942082555039:  96%|█████████▌| 159/166 [03:26<00:09,  1.31s/it]avg_loss = 4.431220239400863:  96%|█████████▌| 159/166 [03:27<00:09,  1.31s/it]avg_loss = 4.431220239400863:  96%|█████████▋| 160/166 [03:27<00:07,  1.31s/it]avg_loss = 4.432967902710719:  96%|█████████▋| 160/166 [03:28<00:07,  1.31s/it]avg_loss = 4.432967902710719:  97%|█████████▋| 161/166 [03:28<00:06,  1.31s/it]avg_loss = 4.433230729750645:  97%|█████████▋| 161/166 [03:30<00:06,  1.31s/it]avg_loss = 4.433230729750645:  98%|█████████▊| 162/166 [03:30<00:05,  1.31s/it]avg_loss = 4.433694924313598:  98%|█████████▊| 162/166 [03:31<00:05,  1.31s/it]avg_loss = 4.433694924313598:  98%|█████████▊| 163/166 [03:31<00:03,  1.31s/it]avg_loss = 4.436789980748805:  98%|█████████▊| 163/166 [03:32<00:03,  1.31s/it]avg_loss = 4.436789980748805:  99%|█████████▉| 164/166 [03:32<00:02,  1.31s/it]avg_loss = 4.439030332276316:  99%|█████████▉| 164/166 [03:34<00:02,  1.31s/it]avg_loss = 4.439030332276316:  99%|█████████▉| 165/166 [03:34<00:01,  1.31s/it]avg_loss = 4.442809461111046:  99%|█████████▉| 165/166 [03:35<00:01,  1.31s/it]avg_loss = 4.442809461111046: 100%|██████████| 166/166 [03:35<00:00,  1.31s/it]avg_loss = 4.442809461111046: 100%|██████████| 166/166 [03:35<00:00,  1.30s/it]
I0321 07:25:57.620124 1629814 eval_ppl.py:107] wikitext2 perplexity: 85.01345825195312
wikitext2 perplexity: 85.013
