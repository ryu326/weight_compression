I0401 08:54:38.789502 2921572 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:54:38.789592 2921572 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:54:38.789633 2921572 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:54:39.122276 2921572 config.py:54] PyTorch version 2.6.0 available.
W0401 08:54:39.318946 2921572 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:54:40.035290 2921572 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.57it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.36it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.82it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.85it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.89it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.02it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.80it/s]
I0401 08:54:41.535993 2921572 quantize_finetune_llama.py:152] loaded model
I0401 08:54:41.847810 2921572 quantize_finetune_llama.py:190] loaded compression model
I0401 08:55:00.248034 2921572 quantize_finetune_llama.py:194] loaded dataset and devset
I0401 08:55:05.304627 2921572 quantize_finetune_llama.py:214] layer 0 gpu 0
I0401 08:55:07.775672 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 2.3063485622406006s
tensor([0.]) tensor([0.])
tensor([0.]) tensor([0.])
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0401 08:55:24.008718 2922162 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:55:24.008811 2922162 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:55:24.008854 2922162 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:55:24.343167 2922162 config.py:54] PyTorch version 2.6.0 available.
W0401 08:55:24.544737 2922162 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:55:25.134683 2922162 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:55:25.138582 2921572 quantize_finetune_llama.py:214] layer 1 gpu 1
I0401 08:55:25.153556 2922162 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:55:28.063894 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 2.7565693855285645s
I0401 08:55:31.785029 2922307 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:55:31.785123 2922307 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:55:31.785167 2922307 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:55:32.122879 2922307 config.py:54] PyTorch version 2.6.0 available.
W0401 08:55:32.327205 2922307 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:55:32.941019 2922307 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:55:32.944946 2921572 quantize_finetune_llama.py:214] layer 2 gpu 2
I0401 08:55:32.961060 2922307 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:55:35.410957 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 2.302288293838501s
I0401 08:55:39.469222 2922455 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:55:39.469328 2922455 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:55:39.469374 2922455 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:55:39.861026 2922455 config.py:54] PyTorch version 2.6.0 available.
W0401 08:55:40.079993 2922455 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:55:40.758566 2922455 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:55:40.762801 2921572 quantize_finetune_llama.py:214] layer 3 gpu 3
I0401 08:55:40.780879 2922455 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:55:43.374498 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 2.429222583770752s
I0401 08:55:47.529289 2922605 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:55:47.529411 2922605 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:55:47.529457 2922605 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:55:47.924209 2922605 config.py:54] PyTorch version 2.6.0 available.
W0401 08:55:48.148142 2922605 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:55:48.828685 2922605 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:55:48.833172 2921572 quantize_finetune_llama.py:214] layer 4 gpu 0
I0401 08:55:48.856544 2922605 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_v proxy err 0.28165462613105774 tr(WHW.T) 60.88684844970703
bpp_loss 1.9503207802772522
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_q proxy err 0.002947988687083125 tr(WHW.T) 288094.65625
bpp_loss 2.605745315551758
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_k proxy err 0.0023013672325760126 tr(WHW.T) 100180.734375
bpp_loss 2.6993541717529297
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_o proxy err 0.026643505319952965 tr(WHW.T) 3123.217529296875
bpp_loss 2.1029441356658936
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_up proxy err 0.054462630301713943 tr(WHW.T) 8924.451171875
bpp_loss 2.156210150037493
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_gate proxy err 0.034374937415122986 tr(WHW.T) 15778.666015625
bpp_loss 2.2313499450683594
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_down proxy err 0.04299424588680267 tr(WHW.T) 10818.205078125
bpp_loss 2.1850457191467285
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_v proxy err 0.21812620759010315 tr(WHW.T) 109.07096099853516
bpp_loss 1.9810278415679932
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_q proxy err 0.0035508449655026197 tr(WHW.T) 144826.484375
bpp_loss 2.420103907585144
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_k proxy err 0.001854165457189083 tr(WHW.T) 75539.046875
bpp_loss 2.7677836418151855
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_o proxy err 0.046910736709833145 tr(WHW.T) 1983.8321533203125
bpp_loss 2.117691993713379
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_up proxy err 0.05813082307577133 tr(WHW.T) 8230.8203125
bpp_loss 2.1787026269095287
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_gate proxy err 0.03862578049302101 tr(WHW.T) 13952.365234375
bpp_loss 2.245375292641776
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_down proxy err 0.05996060371398926 tr(WHW.T) 13978.03125
bpp_loss 2.18332770892552
I0401 08:56:35.179029 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.9590215682983398s
I0401 08:56:39.223333 2923175 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:56:39.223438 2923175 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:56:39.223479 2923175 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:56:39.631215 2923175 config.py:54] PyTorch version 2.6.0 available.
W0401 08:56:39.855548 2923175 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:56:40.643770 2923175 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:56:40.647912 2921572 quantize_finetune_llama.py:214] layer 5 gpu 1
I0401 08:56:40.663930 2923175 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_v proxy err 0.12462883442640305 tr(WHW.T) 155.95950317382812
bpp_loss 1.927349030971527
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_q proxy err 0.006908185314387083 tr(WHW.T) 41475.15625
bpp_loss 2.525000214576721
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_k proxy err 0.00421096058562398 tr(WHW.T) 22614.533203125
bpp_loss 3.042058825492859
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_o proxy err 0.04421716555953026 tr(WHW.T) 1967.3226318359375
bpp_loss 2.0682278871536255
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_up proxy err 0.06327264755964279 tr(WHW.T) 7600.474609375
bpp_loss 2.165959971291678
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_gate proxy err 0.0364048033952713 tr(WHW.T) 15113.31640625
bpp_loss 2.273747307913644
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_down proxy err 0.0617256686091423 tr(WHW.T) 7726.72509765625
bpp_loss 2.1731901509421214
I0401 08:56:43.338681 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.9429361820220947s
I0401 08:56:47.349041 2923318 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:56:47.349144 2923318 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:56:47.349185 2923318 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:56:47.729698 2923318 config.py:54] PyTorch version 2.6.0 available.
W0401 08:56:47.945534 2923318 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:56:48.591082 2923318 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:56:48.595037 2921572 quantize_finetune_llama.py:214] layer 6 gpu 2
I0401 08:56:48.611974 2923318 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_v proxy err 0.08677226305007935 tr(WHW.T) 289.3331604003906
bpp_loss 1.9848255515098572
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_q proxy err 0.005444231443107128 tr(WHW.T) 47576.9296875
bpp_loss 2.608715534210205
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_k proxy err 0.0030576963908970356 tr(WHW.T) 26174.515625
bpp_loss 3.32134747505188
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_o proxy err 0.058330703526735306 tr(WHW.T) 1857.15771484375
bpp_loss 2.0911524295806885
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_up proxy err 0.06296341121196747 tr(WHW.T) 7536.46484375
bpp_loss 2.1518569673810686
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_gate proxy err 0.02844286523759365 tr(WHW.T) 20884.34765625
bpp_loss 2.3180768149239674
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_down proxy err 0.06655973941087723 tr(WHW.T) 6998.6103515625
bpp_loss 2.1553124019077847
I0401 08:56:51.062071 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.8748891353607178s
I0401 08:56:55.109976 2923476 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:56:55.110068 2923476 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:56:55.110108 2923476 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:56:55.452810 2923476 config.py:54] PyTorch version 2.6.0 available.
W0401 08:56:55.662382 2923476 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:56:56.313749 2923476 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:56:56.317854 2921572 quantize_finetune_llama.py:214] layer 7 gpu 3
I0401 08:56:56.335049 2923476 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:56:57.709096 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.8794324398040771s
I0401 08:57:01.712482 2923612 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:57:01.712588 2923612 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:57:01.712629 2923612 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:57:02.108452 2923612 config.py:54] PyTorch version 2.6.0 available.
W0401 08:57:02.332189 2923612 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:57:02.989157 2923612 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:57:02.993561 2921572 quantize_finetune_llama.py:214] layer 8 gpu 0
I0401 08:57:03.011728 2923612 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_v proxy err 0.09469150751829147 tr(WHW.T) 285.30712890625
bpp_loss 2.014615535736084
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_q proxy err 0.0057486724108457565 tr(WHW.T) 50114.859375
bpp_loss 2.5315850973129272
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_k proxy err 0.0028976253233850002 tr(WHW.T) 29301.974609375
bpp_loss 3.265301823616028
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_o proxy err 0.08139944821596146 tr(WHW.T) 1297.2481689453125
bpp_loss 2.111872434616089
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_up proxy err 0.06272369623184204 tr(WHW.T) 7383.48779296875
bpp_loss 2.135464668273926
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_gate proxy err 0.021876266226172447 tr(WHW.T) 29130.974609375
bpp_loss 2.3695639201572964
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_down proxy err 0.07036564499139786 tr(WHW.T) 6395.72265625
bpp_loss 2.143139668873378
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_v proxy err 0.10232185572385788 tr(WHW.T) 208.81988525390625
bpp_loss 1.9461970329284668
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_q proxy err 0.007362330332398415 tr(WHW.T) 35991.625
bpp_loss 2.5251907110214233
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_k proxy err 0.0043079545721411705 tr(WHW.T) 22997.75390625
bpp_loss 3.0055601596832275
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_o proxy err 0.09689605981111526 tr(WHW.T) 1055.5865478515625
bpp_loss 2.045401155948639
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_up proxy err 0.061208099126815796 tr(WHW.T) 7656.43310546875
bpp_loss 2.13615151814052
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_gate proxy err 0.02095099166035652 tr(WHW.T) 30386.947265625
bpp_loss 2.3753294263567244
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_down proxy err 0.07016459107398987 tr(WHW.T) 6411.12939453125
bpp_loss 2.1479975496019637
I0401 08:57:50.709789 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 1.163485050201416s
I0401 08:57:54.753024 2924204 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:57:54.753137 2924204 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:57:54.753178 2924204 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:57:55.143791 2924204 config.py:54] PyTorch version 2.6.0 available.
W0401 08:57:55.366271 2924204 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:57:56.000185 2924204 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:57:56.004246 2921572 quantize_finetune_llama.py:214] layer 9 gpu 1
I0401 08:57:56.021718 2924204 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_v proxy err 0.09609456360340118 tr(WHW.T) 253.63377380371094
bpp_loss 1.9692801237106323
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_q proxy err 0.007208020426332951 tr(WHW.T) 35639.5859375
bpp_loss 2.587936043739319
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_k proxy err 0.002880588872358203 tr(WHW.T) 26163.654296875
bpp_loss 3.47415030002594
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_o proxy err 0.0977410227060318 tr(WHW.T) 1009.1483764648438
bpp_loss 2.113015651702881
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_up proxy err 0.05942977964878082 tr(WHW.T) 7923.53564453125
bpp_loss 2.135543550763811
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_gate proxy err 0.018427258357405663 tr(WHW.T) 35748.39453125
bpp_loss 2.370474406651088
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_down proxy err 0.0692644864320755 tr(WHW.T) 6483.5595703125
bpp_loss 2.148639508656093
I0401 08:57:58.694937 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.9275674819946289s
I0401 08:58:02.692890 2924347 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:58:02.692987 2924347 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:58:02.693028 2924347 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:58:03.037266 2924347 config.py:54] PyTorch version 2.6.0 available.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_v proxy err 0.07847195863723755 tr(WHW.T) 309.4270935058594
bpp_loss 1.9663644433021545
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_q proxy err 0.007327024359256029 tr(WHW.T) 35144.953125
bpp_loss 2.5409504175186157
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_k proxy err 0.002661536680534482 tr(WHW.T) 26850.4921875
bpp_loss 3.5793997049331665
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_o proxy err 0.11260941624641418 tr(WHW.T) 959.2155151367188
bpp_loss 2.0746723413467407
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_up proxy err 0.05539771914482117 tr(WHW.T) 8627.4501953125
bpp_loss 2.146836417061942
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_gate proxy err 0.018816066905856133 tr(WHW.T) 34903.53515625
bpp_loss 2.3466929027012418
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_down proxy err 0.06894474476575851 tr(WHW.T) 6534.6279296875
bpp_loss 2.1619836262294223
W0401 08:58:03.238912 2924347 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:58:03.905279 2924347 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:58:03.909413 2921572 quantize_finetune_llama.py:214] layer 10 gpu 2
I0401 08:58:03.926015 2924347 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:58:05.331079 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.9416329860687256s
I0401 08:58:09.180441 2924513 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:58:09.180546 2924513 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:58:09.180595 2924513 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:58:09.564029 2924513 config.py:54] PyTorch version 2.6.0 available.
W0401 08:58:09.784850 2924513 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:58:10.422085 2924513 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:58:10.425996 2921572 quantize_finetune_llama.py:214] layer 11 gpu 3
I0401 08:58:10.441405 2924513 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:58:11.869426 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 0.9586825370788574s
I0401 08:58:15.844384 2924657 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:58:15.844502 2924657 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:58:15.844552 2924657 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:58:16.256283 2924657 config.py:54] PyTorch version 2.6.0 available.
W0401 08:58:16.490256 2924657 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:58:17.134111 2924657 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:58:17.138016 2921572 quantize_finetune_llama.py:214] layer 12 gpu 0
I0401 08:58:17.154345 2924657 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_v proxy err 0.09504242986440659 tr(WHW.T) 257.7052307128906
bpp_loss 1.9975862503051758
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_q proxy err 0.01005300972610712 tr(WHW.T) 26600.9765625
bpp_loss 2.446628451347351
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_k proxy err 0.003856995142996311 tr(WHW.T) 22528.748046875
bpp_loss 3.133893370628357
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_o proxy err 0.13727644085884094 tr(WHW.T) 745.6061401367188
bpp_loss 2.116756796836853
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_up proxy err 0.055927496403455734 tr(WHW.T) 8495.0546875
bpp_loss 2.145148686000279
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_gate proxy err 0.0177488774061203 tr(WHW.T) 37238.1484375
bpp_loss 2.3503684997558594
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_down proxy err 0.06904656440019608 tr(WHW.T) 6488.8173828125
bpp_loss 2.1623784133366177
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_v proxy err 0.0809418261051178 tr(WHW.T) 351.4288024902344
bpp_loss 2.0723114013671875
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_q proxy err 0.009530526585876942 tr(WHW.T) 25653.232421875
bpp_loss 2.517948269844055
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_k proxy err 0.0036393473856151104 tr(WHW.T) 20942.638671875
bpp_loss 3.3297064304351807
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_o proxy err 0.1508309543132782 tr(WHW.T) 776.6017456054688
bpp_loss 2.1167173385620117
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_up proxy err 0.053443796932697296 tr(WHW.T) 8970.6455078125
bpp_loss 2.1511388506208147
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_gate proxy err 0.017171291634440422 tr(WHW.T) 39415.71875
bpp_loss 2.3520541872297014
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_down proxy err 0.07194432616233826 tr(WHW.T) 6272.90380859375
bpp_loss 2.1600654465811595
I0401 08:59:05.559075 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 0.9535281658172607s
I0401 08:59:09.596826 2925218 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:59:09.596940 2925218 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:59:09.596982 2925218 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:59:09.981781 2925218 config.py:54] PyTorch version 2.6.0 available.
W0401 08:59:10.208485 2925218 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_v proxy err 0.09613031893968582 tr(WHW.T) 251.83889770507812
bpp_loss 1.9902244806289673
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_q proxy err 0.011310702189803123 tr(WHW.T) 23338.15625
bpp_loss 2.468273162841797
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_k proxy err 0.004324232693761587 tr(WHW.T) 19743.95703125
bpp_loss 3.174179792404175
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_o proxy err 0.14975012838840485 tr(WHW.T) 680.6640625
bpp_loss 2.1051697731018066
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_up proxy err 0.053043052554130554 tr(WHW.T) 9199.1572265625
bpp_loss 2.1615700040544783
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_gate proxy err 0.01747514307498932 tr(WHW.T) 37399.37109375
bpp_loss 2.342238289969308
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_down proxy err 0.07089243084192276 tr(WHW.T) 6525.2333984375
bpp_loss 2.1642470019204274
W0401 08:59:10.863103 2925218 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:59:10.867142 2921572 quantize_finetune_llama.py:214] layer 13 gpu 1
I0401 08:59:10.883657 2925218 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:59:12.586932 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 0.948523998260498s
I0401 08:59:16.540908 2925365 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:59:16.541004 2925365 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:59:16.541047 2925365 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:59:16.931500 2925365 config.py:54] PyTorch version 2.6.0 available.
W0401 08:59:17.133621 2925365 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_v proxy err 0.0787871927022934 tr(WHW.T) 319.5691223144531
bpp_loss 1.9744359850883484
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_q proxy err 0.010544276796281338 tr(WHW.T) 22190.8984375
bpp_loss 2.4943175315856934
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_k proxy err 0.004071954637765884 tr(WHW.T) 18027.423828125
bpp_loss 3.3750911951065063
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_o proxy err 0.19534525275230408 tr(WHW.T) 565.9476928710938
bpp_loss 2.0844937562942505
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_up proxy err 0.05319725722074509 tr(WHW.T) 9192.595703125
bpp_loss 2.1667531558445523
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_gate proxy err 0.01783059909939766 tr(WHW.T) 36884.09375
bpp_loss 2.318163735525949
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_down proxy err 0.06979192793369293 tr(WHW.T) 6655.890625
bpp_loss 2.1711113112313405
W0401 08:59:17.712976 2925365 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:59:17.716781 2921572 quantize_finetune_llama.py:214] layer 14 gpu 2
I0401 08:59:17.731759 2925365 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:59:19.318406 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 1.0950193405151367s
I0401 08:59:23.118982 2925508 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:59:23.119086 2925508 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:59:23.119126 2925508 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:59:23.494268 2925508 config.py:54] PyTorch version 2.6.0 available.
W0401 08:59:23.708762 2925508 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:59:24.332444 2925508 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:59:24.336457 2921572 quantize_finetune_llama.py:214] layer 15 gpu 3
I0401 08:59:24.354603 2925508 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:59:25.857860 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 1.0321054458618164s
I0401 08:59:29.947987 2925649 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:59:29.948097 2925649 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:59:29.948137 2925649 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:59:30.353058 2925649 config.py:54] PyTorch version 2.6.0 available.
W0401 08:59:30.582005 2925649 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:59:31.252479 2925649 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:59:31.256663 2921572 quantize_finetune_llama.py:214] layer 16 gpu 0
I0401 08:59:31.275548 2925649 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_v proxy err 0.08032067120075226 tr(WHW.T) 363.6233825683594
bpp_loss 2.0558879375457764
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_q proxy err 0.006873228587210178 tr(WHW.T) 34102.625
bpp_loss 2.5759472846984863
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_k proxy err 0.002850881079211831 tr(WHW.T) 23057.041015625
bpp_loss 3.567099690437317
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_o proxy err 0.14604076743125916 tr(WHW.T) 779.7713012695312
bpp_loss 2.1363701820373535
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_up proxy err 0.04992498829960823 tr(WHW.T) 10027.1552734375
bpp_loss 2.1798582758222307
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_gate proxy err 0.01774366945028305 tr(WHW.T) 37334.1015625
bpp_loss 2.2975185939243863
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_down proxy err 0.06894765794277191 tr(WHW.T) 6822.7119140625
bpp_loss 2.181278501238142
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_v proxy err 0.09648797661066055 tr(WHW.T) 280.153564453125
bpp_loss 2.0111924409866333
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_q proxy err 0.011232631281018257 tr(WHW.T) 20897.375
bpp_loss 2.5113296508789062
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_k proxy err 0.00439232774078846 tr(WHW.T) 17798.916015625
bpp_loss 3.300084710121155
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_o proxy err 0.15637975931167603 tr(WHW.T) 675.2068481445312
bpp_loss 2.1504056453704834
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_up proxy err 0.05021025612950325 tr(WHW.T) 10010.2880859375
bpp_loss 2.180692740849086
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_gate proxy err 0.01715896837413311 tr(WHW.T) 38921.26171875
bpp_loss 2.302410806928362
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_down proxy err 0.07258642464876175 tr(WHW.T) 6560.505859375
bpp_loss 2.1725239072527205
I0401 09:00:19.891505 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.8194339275360107s
I0401 09:00:23.856395 2926218 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:00:23.856500 2926218 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:00:23.856547 2926218 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:00:24.244052 2926218 config.py:54] PyTorch version 2.6.0 available.
W0401 09:00:24.457731 2926218 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_v proxy err 0.09428128600120544 tr(WHW.T) 281.3382873535156
bpp_loss 2.013692855834961
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_q proxy err 0.011576824821531773 tr(WHW.T) 20881.8359375
bpp_loss 2.469735622406006
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_k proxy err 0.004735043738037348 tr(WHW.T) 18619.298828125
bpp_loss 3.102852702140808
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_o proxy err 0.16775758564472198 tr(WHW.T) 686.2976684570312
bpp_loss 2.0934141874313354
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_up proxy err 0.0543171651661396 tr(WHW.T) 9164.287109375
bpp_loss 2.176952634538923
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_gate proxy err 0.016408974304795265 tr(WHW.T) 41785.8203125
bpp_loss 2.3177898951939175
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_down proxy err 0.07443661242723465 tr(WHW.T) 6390.916015625
bpp_loss 2.1713083471570696
W0401 09:00:25.107683 2926218 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:00:25.111808 2921572 quantize_finetune_llama.py:214] layer 17 gpu 1
I0401 09:00:25.128399 2926218 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:00:26.770147 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 0.8155407905578613s
I0401 09:00:30.730667 2926369 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:00:30.730777 2926369 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:00:30.730821 2926369 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:00:31.093442 2926369 config.py:54] PyTorch version 2.6.0 available.
W0401 09:00:31.298648 2926369 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_v proxy err 0.09949424117803574 tr(WHW.T) 284.0271301269531
bpp_loss 2.0586555004119873
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_q proxy err 0.009968195110559464 tr(WHW.T) 28079.306640625
bpp_loss 2.4921430349349976
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_k proxy err 0.0038270980585366488 tr(WHW.T) 18871.66796875
bpp_loss 3.3948224782943726
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_o proxy err 0.1373804360628128 tr(WHW.T) 827.9279174804688
bpp_loss 2.1445311307907104
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_up proxy err 0.05489015579223633 tr(WHW.T) 8994.5693359375
bpp_loss 2.1727355548313687
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_gate proxy err 0.015006034635007381 tr(WHW.T) 46217.96875
bpp_loss 2.350937979561942
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_down proxy err 0.07394815981388092 tr(WHW.T) 6399.38671875
bpp_loss 2.1681596551622664
W0401 09:00:31.868393 2926369 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:00:31.872372 2921572 quantize_finetune_llama.py:214] layer 18 gpu 2
I0401 09:00:31.887277 2926369 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:00:33.468877 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.8734278678894043s
I0401 09:00:37.268323 2926505 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:00:37.268423 2926505 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:00:37.268465 2926505 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:00:37.655005 2926505 config.py:54] PyTorch version 2.6.0 available.
W0401 09:00:37.873387 2926505 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:00:38.509909 2926505 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:00:38.513881 2921572 quantize_finetune_llama.py:214] layer 19 gpu 3
I0401 09:00:38.530084 2926505 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:00:40.006727 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 0.982243537902832s
I0401 09:00:44.085360 2926638 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:00:44.085474 2926638 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:00:44.085519 2926638 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:00:44.504061 2926638 config.py:54] PyTorch version 2.6.0 available.
W0401 09:00:44.741961 2926638 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:00:45.402538 2926638 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:00:45.407581 2921572 quantize_finetune_llama.py:214] layer 20 gpu 0
I0401 09:00:45.430474 2926638 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_v proxy err 0.09649062156677246 tr(WHW.T) 274.28167724609375
bpp_loss 2.0307806730270386
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_q proxy err 0.01044194120913744 tr(WHW.T) 24486.64453125
bpp_loss 2.527705669403076
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_k proxy err 0.004018891137093306 tr(WHW.T) 19506.357421875
bpp_loss 3.3011934757232666
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_o proxy err 0.1123015508055687 tr(WHW.T) 969.0885620117188
bpp_loss 2.1480345726013184
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_up proxy err 0.058197423815727234 tr(WHW.T) 8331.1826171875
bpp_loss 2.16326447895595
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_gate proxy err 0.016618061810731888 tr(WHW.T) 41176.12890625
bpp_loss 2.37974670955113
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_down proxy err 0.07362480461597443 tr(WHW.T) 6288.2802734375
bpp_loss 2.1642744541168213
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_v proxy err 0.10441169887781143 tr(WHW.T) 283.9730224609375
bpp_loss 2.0709880590438843
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_q proxy err 0.008900373242795467 tr(WHW.T) 27571.44140625
bpp_loss 2.568884253501892
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_k proxy err 0.004392552189528942 tr(WHW.T) 17429.814453125
bpp_loss 3.321095108985901
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_o proxy err 0.1050233244895935 tr(WHW.T) 1106.6993408203125
bpp_loss 2.1511765718460083
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_up proxy err 0.05732465162873268 tr(WHW.T) 8452.5419921875
bpp_loss 2.1609279768807546
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_gate proxy err 0.016460221260786057 tr(WHW.T) 41717.5625
bpp_loss 2.3916116441999162
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_down proxy err 0.07407808303833008 tr(WHW.T) 6212.31494140625
bpp_loss 2.1658285004752025
I0401 09:01:33.753391 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.0775907039642334s
I0401 09:01:37.876727 2927241 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:01:37.876831 2927241 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:01:37.876872 2927241 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:01:38.248951 2927241 config.py:54] PyTorch version 2.6.0 available.
W0401 09:01:38.457138 2927241 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_v proxy err 0.09214981645345688 tr(WHW.T) 287.61376953125
bpp_loss 2.0252009630203247
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_q proxy err 0.010016909800469875 tr(WHW.T) 22399.498046875
bpp_loss 2.6183807849884033
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_k proxy err 0.0041139991953969 tr(WHW.T) 17394.810546875
bpp_loss 3.5011274814605713
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_o proxy err 0.09186609089374542 tr(WHW.T) 1203.193603515625
bpp_loss 2.157320499420166
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_up proxy err 0.060278911143541336 tr(WHW.T) 7982.8837890625
bpp_loss 2.156790460859026
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_gate proxy err 0.019004637375473976 tr(WHW.T) 35243.5546875
bpp_loss 2.3960508619035994
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_down proxy err 0.07443621754646301 tr(WHW.T) 6226.57861328125
bpp_loss 2.159701551709856
W0401 09:01:39.067731 2927241 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:01:39.071706 2921572 quantize_finetune_llama.py:214] layer 21 gpu 1
I0401 09:01:39.087100 2927241 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:01:40.715311 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.8833053112030029s
I0401 09:01:44.642830 2927377 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:01:44.642951 2927377 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:01:44.642996 2927377 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:01:45.029195 2927377 config.py:54] PyTorch version 2.6.0 available.
W0401 09:01:45.236053 2927377 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_v proxy err 0.08375990390777588 tr(WHW.T) 341.0596618652344
bpp_loss 2.047784686088562
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_q proxy err 0.009587233886122704 tr(WHW.T) 24038.03515625
bpp_loss 2.6049184799194336
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_k proxy err 0.0044914474710822105 tr(WHW.T) 15553.287109375
bpp_loss 3.4057371616363525
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_o proxy err 0.09784964472055435 tr(WHW.T) 1168.891845703125
bpp_loss 2.1497005224227905
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_up proxy err 0.06230848282575607 tr(WHW.T) 7649.2919921875
bpp_loss 2.154607023511614
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_gate proxy err 0.02013377659022808 tr(WHW.T) 32811.99609375
bpp_loss 2.412243161882673
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_down proxy err 0.07385025918483734 tr(WHW.T) 6182.73583984375
bpp_loss 2.1661648750305176
W0401 09:01:45.803706 2927377 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:01:45.807750 2921572 quantize_finetune_llama.py:214] layer 22 gpu 2
I0401 09:01:45.828121 2927377 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:01:47.452306 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 0.9909517765045166s
I0401 09:01:51.250668 2927516 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:01:51.250773 2927516 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:01:51.250816 2927516 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:01:51.625555 2927516 config.py:54] PyTorch version 2.6.0 available.
W0401 09:01:51.841654 2927516 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:01:52.480873 2927516 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:01:52.484849 2921572 quantize_finetune_llama.py:214] layer 23 gpu 3
I0401 09:01:52.500561 2927516 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:01:54.001442 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 1.0304827690124512s
I0401 09:01:58.047197 2927657 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:01:58.047304 2927657 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:01:58.047345 2927657 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:01:58.442009 2927657 config.py:54] PyTorch version 2.6.0 available.
W0401 09:01:58.672129 2927657 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:01:59.308481 2927657 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:01:59.312570 2921572 quantize_finetune_llama.py:214] layer 24 gpu 0
I0401 09:01:59.329406 2927657 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_v proxy err 0.08984125405550003 tr(WHW.T) 330.192138671875
bpp_loss 2.0745609998703003
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_q proxy err 0.010914616286754608 tr(WHW.T) 20737.7421875
bpp_loss 2.577089786529541
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_k proxy err 0.004760763142257929 tr(WHW.T) 15395.810546875
bpp_loss 3.2848352193832397
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_o proxy err 0.09342198073863983 tr(WHW.T) 1205.1229248046875
bpp_loss 2.147626757621765
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_up proxy err 0.06290449947118759 tr(WHW.T) 7599.658203125
bpp_loss 2.156691483088902
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_gate proxy err 0.021112382411956787 tr(WHW.T) 30665.015625
bpp_loss 2.4226269040788924
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_down proxy err 0.07403867691755295 tr(WHW.T) 6300.8623046875
bpp_loss 2.156740631375994
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_v proxy err 0.08400532603263855 tr(WHW.T) 362.87310791015625
bpp_loss 2.0980595350265503
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_q proxy err 0.008647450245916843 tr(WHW.T) 25838.111328125
bpp_loss 2.5959869623184204
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_k proxy err 0.004080386832356453 tr(WHW.T) 16787.453125
bpp_loss 3.420185685157776
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_o proxy err 0.09252311289310455 tr(WHW.T) 1266.6689453125
bpp_loss 2.1485233306884766
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_up proxy err 0.061887308955192566 tr(WHW.T) 7772.57080078125
bpp_loss 2.1574397768293108
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_gate proxy err 0.02102142572402954 tr(WHW.T) 31566.3828125
bpp_loss 2.4152289799281528
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_down proxy err 0.07367765158414841 tr(WHW.T) 6351.46484375
bpp_loss 2.1603584630148753
I0401 09:02:47.710733 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.9418532848358154s
I0401 09:02:51.726503 2928241 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:02:51.726614 2928241 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:02:51.726655 2928241 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:02:52.119146 2928241 config.py:54] PyTorch version 2.6.0 available.
W0401 09:02:52.333004 2928241 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_v proxy err 0.09210586547851562 tr(WHW.T) 346.0789489746094
bpp_loss 2.1307791471481323
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_q proxy err 0.010416674427688122 tr(WHW.T) 20319.60546875
bpp_loss 2.5822595357894897
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_k proxy err 0.004740717820823193 tr(WHW.T) 14724.09765625
bpp_loss 3.2998580932617188
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_o proxy err 0.09969039261341095 tr(WHW.T) 1221.8309326171875
bpp_loss 2.153594136238098
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_up proxy err 0.0634693130850792 tr(WHW.T) 7547.25537109375
bpp_loss 2.162461280822754
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_gate proxy err 0.02171020209789276 tr(WHW.T) 29534.099609375
bpp_loss 2.441151891435896
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_down proxy err 0.07209722697734833 tr(WHW.T) 6529.4912109375
bpp_loss 2.1613138743809293
W0401 09:02:52.942004 2928241 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:02:52.945902 2921572 quantize_finetune_llama.py:214] layer 25 gpu 1
I0401 09:02:52.961697 2928241 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:02:55.240951 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 0.9935293197631836s
I0401 09:02:59.142260 2928384 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:02:59.142487 2928384 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:02:59.142537 2928384 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:02:59.491084 2928384 config.py:54] PyTorch version 2.6.0 available.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_v proxy err 0.08383387327194214 tr(WHW.T) 397.90704345703125
bpp_loss 2.1698285341262817
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_q proxy err 0.00956224836409092 tr(WHW.T) 22608.931640625
bpp_loss 2.578368902206421
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_k proxy err 0.004719781689345837 tr(WHW.T) 14857.474609375
bpp_loss 3.3048475980758667
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_o proxy err 0.07453545182943344 tr(WHW.T) 1744.470947265625
bpp_loss 2.149844765663147
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_up proxy err 0.06471917033195496 tr(WHW.T) 7419.2080078125
bpp_loss 2.1655516624450684
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_gate proxy err 0.023232650011777878 tr(WHW.T) 27291.65234375
bpp_loss 2.445319448198591
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_down proxy err 0.07103203982114792 tr(WHW.T) 6666.9853515625
bpp_loss 2.163062368120466
W0401 09:02:59.691934 2928384 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:03:00.285453 2928384 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:03:00.289371 2921572 quantize_finetune_llama.py:214] layer 26 gpu 2
I0401 09:03:00.305512 2928384 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:03:01.604114 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.8503429889678955s
I0401 09:03:05.446920 2928533 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:03:05.447026 2928533 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:03:05.447067 2928533 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:03:05.814617 2928533 config.py:54] PyTorch version 2.6.0 available.
W0401 09:03:06.032741 2928533 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:03:06.651971 2928533 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:03:06.655929 2921572 quantize_finetune_llama.py:214] layer 27 gpu 3
I0401 09:03:06.671050 2928533 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:03:08.048749 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.9100432395935059s
I0401 09:03:12.115140 2928679 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:03:12.115249 2928679 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:03:12.115291 2928679 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:03:12.503621 2928679 config.py:54] PyTorch version 2.6.0 available.
W0401 09:03:12.734418 2928679 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:03:13.374100 2928679 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:03:13.378250 2921572 quantize_finetune_llama.py:214] layer 28 gpu 0
I0401 09:03:13.397131 2928679 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_v proxy err 0.0773085504770279 tr(WHW.T) 467.2783508300781
bpp_loss 2.2352967262268066
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_q proxy err 0.009651348926126957 tr(WHW.T) 22436.099609375
bpp_loss 2.540900230407715
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_k proxy err 0.005358966067433357 tr(WHW.T) 14183.4345703125
bpp_loss 3.020386815071106
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_o proxy err 0.08458652347326279 tr(WHW.T) 1589.4920654296875
bpp_loss 2.175707221031189
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_up proxy err 0.06582119315862656 tr(WHW.T) 7311.1435546875
bpp_loss 2.1669271332877025
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_gate proxy err 0.02449377253651619 tr(WHW.T) 25877.26171875
bpp_loss 2.4486183438982283
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_down proxy err 0.07084546983242035 tr(WHW.T) 6741.93701171875
bpp_loss 2.16509941646031
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_v proxy err 0.06528688222169876 tr(WHW.T) 557.8086547851562
bpp_loss 2.248857259750366
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_q proxy err 0.0084409574046731 tr(WHW.T) 26112.029296875
bpp_loss 2.527397036552429
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_k proxy err 0.005264863837510347 tr(WHW.T) 14416.6201171875
bpp_loss 3.0061917304992676
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_o proxy err 0.06839122623205185 tr(WHW.T) 1990.481201171875
bpp_loss 2.182587742805481
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_up proxy err 0.06549034267663956 tr(WHW.T) 7382.19091796875
bpp_loss 2.175774710518973
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_gate proxy err 0.024124491959810257 tr(WHW.T) 26307.435546875
bpp_loss 2.460110936846052
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_down proxy err 0.07343513518571854 tr(WHW.T) 6615.951171875
bpp_loss 2.170022112982614
I0401 09:04:02.281039 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 0.9071564674377441s
I0401 09:04:06.325787 2929243 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:04:06.325886 2929243 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:04:06.325928 2929243 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_v proxy err 0.08526258915662766 tr(WHW.T) 434.54583740234375
bpp_loss 2.2922892570495605
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_q proxy err 0.010066934861242771 tr(WHW.T) 21403.28125
bpp_loss 2.532327651977539
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_k proxy err 0.005075692664831877 tr(WHW.T) 15425.5859375
bpp_loss 3.060198187828064
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_o proxy err 0.057315465062856674 tr(WHW.T) 2388.72412109375
bpp_loss 2.200324773788452
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_up proxy err 0.0638701394200325 tr(WHW.T) 7645.65625
bpp_loss 2.1808371543884277
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_gate proxy err 0.022582601755857468 tr(WHW.T) 28901.4453125
bpp_loss 2.4478676659720287
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_down proxy err 0.07310525327920914 tr(WHW.T) 6618.82470703125
bpp_loss 2.1764564514160156
I0401 09:04:06.687601 2929243 config.py:54] PyTorch version 2.6.0 available.
W0401 09:04:06.896529 2929243 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:04:07.491638 2929243 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:04:07.495552 2921572 quantize_finetune_llama.py:214] layer 29 gpu 1
I0401 09:04:07.511173 2929243 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:04:08.898082 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 0.9202704429626465s
I0401 09:04:12.894646 2929384 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:04:12.894763 2929384 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:04:12.894808 2929384 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:04:13.242262 2929384 config.py:54] PyTorch version 2.6.0 available.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_v proxy err 0.05984019488096237 tr(WHW.T) 677.69384765625
bpp_loss 2.335630774497986
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_q proxy err 0.010100830346345901 tr(WHW.T) 21305.96875
bpp_loss 2.5074868202209473
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_k proxy err 0.005946130026131868 tr(WHW.T) 14011.6201171875
bpp_loss 2.946401000022888
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_o proxy err 0.06441761553287506 tr(WHW.T) 2159.9560546875
bpp_loss 2.2275184392929077
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_up proxy err 0.058292191475629807 tr(WHW.T) 8475.5947265625
bpp_loss 2.1940610068184987
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_gate proxy err 0.02025643177330494 tr(WHW.T) 32809.0390625
bpp_loss 2.4522861753191267
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_down proxy err 0.07446816563606262 tr(WHW.T) 6543.35791015625
bpp_loss 2.184445926121303
W0401 09:04:13.450101 2929384 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:04:14.014657 2929384 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:04:14.018392 2921572 quantize_finetune_llama.py:214] layer 30 gpu 2
I0401 09:04:14.033110 2929384 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:04:15.675345 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 1.1798629760742188s
I0401 09:04:19.502712 2929535 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:04:19.502819 2929535 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:04:19.502863 2929535 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:04:19.898128 2929535 config.py:54] PyTorch version 2.6.0 available.
W0401 09:04:20.119669 2929535 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:04:20.805433 2929535 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:04:20.809508 2921572 quantize_finetune_llama.py:214] layer 31 gpu 3
I0401 09:04:20.826314 2929535 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 09:04:22.373150 2921572 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 1.0583550930023193s
I0401 09:04:26.773751 2929686 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:04:26.773856 2929686 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:04:26.773900 2929686 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:04:27.155415 2929686 config.py:54] PyTorch version 2.6.0 available.
W0401 09:04:27.380425 2929686 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 09:04:28.050972 2929686 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 09:04:28.073770 2929686 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_v proxy err 0.06838463246822357 tr(WHW.T) 601.4844360351562
bpp_loss 2.4033695459365845
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_q proxy err 0.009508132934570312 tr(WHW.T) 23163.888671875
bpp_loss 2.5186046361923218
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_k proxy err 0.004597499966621399 tr(WHW.T) 14994.2119140625
bpp_loss 3.1156606674194336
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_o proxy err 0.05714112147688866 tr(WHW.T) 2511.445556640625
bpp_loss 2.2350873947143555
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_up proxy err 0.04975942522287369 tr(WHW.T) 10246.0703125
bpp_loss 2.208313192640032
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_gate proxy err 0.018956752493977547 tr(WHW.T) 35920.9609375
bpp_loss 2.428196498325893
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_down proxy err 0.06897442787885666 tr(WHW.T) 7210.08740234375
bpp_loss 2.19594635282244
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_v proxy err 0.05013498291373253 tr(WHW.T) 850.4290161132812
bpp_loss 2.4425469636917114
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_q proxy err 0.010779645293951035 tr(WHW.T) 20653.2265625
bpp_loss 2.506821036338806
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_k proxy err 0.004515140783041716 tr(WHW.T) 16365.796875
bpp_loss 3.16418719291687
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_o proxy err 0.04872402176260948 tr(WHW.T) 3102.844970703125
bpp_loss 2.2636219263076782
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_up proxy err 0.04127288609743118 tr(WHW.T) 12868.505859375
bpp_loss 2.2313568932669505
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_gate proxy err 0.018180450424551964 tr(WHW.T) 38364.47265625
bpp_loss 2.410698618207659
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_down proxy err 0.06766897439956665 tr(WHW.T) 7470.5244140625
bpp_loss 2.2076896258762906
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_v proxy err 0.056384000927209854 tr(WHW.T) 863.060791015625
bpp_loss 2.6556161642074585
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_q proxy err 0.0096318069845438 tr(WHW.T) 24050.6328125
bpp_loss 2.3965015411376953
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_k proxy err 0.006609194912016392 tr(WHW.T) 14030.5888671875
bpp_loss 2.650990605354309
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_o proxy err 0.032945528626441956 tr(WHW.T) 4869.1748046875
bpp_loss 2.3270184993743896
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_up proxy err 0.026636619120836258 tr(WHW.T) 21711.1953125
bpp_loss 2.2494165556771413
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_gate proxy err 0.01447678916156292 tr(WHW.T) 51954.453125
bpp_loss 2.428481783185686
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_down proxy err 0.058311209082603455 tr(WHW.T) 8810.1787109375
bpp_loss 2.211881637573242
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_v proxy err 0.027087539434432983 tr(WHW.T) 1808.723876953125
bpp_loss 2.476043224334717
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_q proxy err 0.006377061363309622 tr(WHW.T) 46175.66015625
bpp_loss 2.4741145372390747
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_k proxy err 0.004568655975162983 tr(WHW.T) 20467.64453125
bpp_loss 2.8916999101638794
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_o proxy err 0.07140997797250748 tr(WHW.T) 2213.58154296875
bpp_loss 2.2809780836105347
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_up proxy err 0.011072663590312004 tr(WHW.T) 69019.4453125
bpp_loss 2.3653076716831754
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_gate proxy err 0.006873085629194975 tr(WHW.T) 144452.5625
bpp_loss 2.5417573111397878
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_down proxy err 0.053173523396253586 tr(WHW.T) 9960.1884765625
bpp_loss 2.230560541152954
I0401 09:05:38.556633 2930441 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:05:38.556798 2930441 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:05:38.556843 2930441 utils.py:162] NumExpr defaulting to 16 threads.
I0401 09:05:38.974181 2930441 config.py:54] PyTorch version 2.6.0 available.
W0401 09:05:39.201149 2930441 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0401 09:05:39.336995 2930441 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:01,  4.15it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  5.22it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  5.14it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  5.84it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  6.69it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.27it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  7.89it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  6.59it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.44it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.90it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.73it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.49it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.74it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.97it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.24it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.99it/s]
I0401 09:05:42.934526 2930441 hfize_llama.py:153] loaded layer 0
I0401 09:05:43.677985 2930441 hfize_llama.py:153] loaded layer 1
I0401 09:05:44.419925 2930441 hfize_llama.py:153] loaded layer 2
I0401 09:05:45.178893 2930441 hfize_llama.py:153] loaded layer 3
I0401 09:05:46.001806 2930441 hfize_llama.py:153] loaded layer 4
I0401 09:05:46.776659 2930441 hfize_llama.py:153] loaded layer 5
I0401 09:05:47.529408 2930441 hfize_llama.py:153] loaded layer 6
I0401 09:05:48.316823 2930441 hfize_llama.py:153] loaded layer 7
I0401 09:05:49.214369 2930441 hfize_llama.py:153] loaded layer 8
I0401 09:05:50.000283 2930441 hfize_llama.py:153] loaded layer 9
I0401 09:05:50.777806 2930441 hfize_llama.py:153] loaded layer 10
I0401 09:05:51.549825 2930441 hfize_llama.py:153] loaded layer 11
I0401 09:05:52.305945 2930441 hfize_llama.py:153] loaded layer 12
I0401 09:05:53.066661 2930441 hfize_llama.py:153] loaded layer 13
I0401 09:05:53.801044 2930441 hfize_llama.py:153] loaded layer 14
I0401 09:05:54.550614 2930441 hfize_llama.py:153] loaded layer 15
I0401 09:05:55.243674 2930441 hfize_llama.py:153] loaded layer 16
I0401 09:05:55.936932 2930441 hfize_llama.py:153] loaded layer 17
I0401 09:05:56.677636 2930441 hfize_llama.py:153] loaded layer 18
I0401 09:05:57.422397 2930441 hfize_llama.py:153] loaded layer 19
I0401 09:05:58.149163 2930441 hfize_llama.py:153] loaded layer 20
I0401 09:05:58.881618 2930441 hfize_llama.py:153] loaded layer 21
I0401 09:05:59.621115 2930441 hfize_llama.py:153] loaded layer 22
I0401 09:06:00.347995 2930441 hfize_llama.py:153] loaded layer 23
I0401 09:06:01.060238 2930441 hfize_llama.py:153] loaded layer 24
I0401 09:06:01.761879 2930441 hfize_llama.py:153] loaded layer 25
I0401 09:06:02.438106 2930441 hfize_llama.py:153] loaded layer 26
I0401 09:06:03.127459 2930441 hfize_llama.py:153] loaded layer 27
I0401 09:06:03.819314 2930441 hfize_llama.py:153] loaded layer 28
I0401 09:06:04.518464 2930441 hfize_llama.py:153] loaded layer 29
I0401 09:06:05.233701 2930441 hfize_llama.py:153] loaded layer 30
I0401 09:06:05.925732 2930441 hfize_llama.py:153] loaded layer 31
I0401 09:06:05.925868 2930441 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.22s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.03s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:03,  1.03it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:03<00:02,  1.09it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:04<00:01,  1.13it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.19it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.19it/s]
I0401 09:06:40.969371 2930441 hfize_llama.py:167] successfully loaded hfized model
I0401 09:06:45.804112 2931238 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 09:06:45.804282 2931238 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 09:06:45.804329 2931238 utils.py:162] NumExpr defaulting to 16 threads.
W0401 09:06:46.275000 2931238 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0401 09:06:46.798622 2931238 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.24s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.20s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.20s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.17s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.10s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.05s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.03s/it]
I0401 09:06:54.145559 2931238 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 3.496263265609741:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 3.496263265609741:   1%|          | 1/141 [00:01<04:26,  1.91s/it]avg_loss = 3.880132794380188:   1%|          | 1/141 [00:03<04:26,  1.91s/it]avg_loss = 3.880132794380188:   1%|▏         | 2/141 [00:03<03:48,  1.64s/it]avg_loss = 4.127766688664754:   1%|▏         | 2/141 [00:04<03:48,  1.64s/it]avg_loss = 4.127766688664754:   2%|▏         | 3/141 [00:04<03:35,  1.56s/it]avg_loss = 4.2143674492836:   2%|▏         | 3/141 [00:06<03:35,  1.56s/it]  avg_loss = 4.2143674492836:   3%|▎         | 4/141 [00:06<03:29,  1.53s/it]avg_loss = 4.30860276222229:   3%|▎         | 4/141 [00:07<03:29,  1.53s/it]avg_loss = 4.30860276222229:   4%|▎         | 5/141 [00:07<03:25,  1.51s/it]avg_loss = 4.16944960753123:   4%|▎         | 5/141 [00:09<03:25,  1.51s/it]avg_loss = 4.16944960753123:   4%|▍         | 6/141 [00:09<03:22,  1.50s/it]avg_loss = 4.077653714588711:   4%|▍         | 6/141 [00:10<03:22,  1.50s/it]avg_loss = 4.077653714588711:   5%|▍         | 7/141 [00:10<03:19,  1.49s/it]avg_loss = 4.09527525305748:   5%|▍         | 7/141 [00:12<03:19,  1.49s/it] avg_loss = 4.09527525305748:   6%|▌         | 8/141 [00:12<03:18,  1.49s/it]avg_loss = 4.165161106321547:   6%|▌         | 8/141 [00:13<03:18,  1.49s/it]avg_loss = 4.165161106321547:   6%|▋         | 9/141 [00:13<03:16,  1.49s/it]avg_loss = 4.163509583473205:   6%|▋         | 9/141 [00:15<03:16,  1.49s/it]avg_loss = 4.163509583473205:   7%|▋         | 10/141 [00:15<03:15,  1.49s/it]avg_loss = 4.149233146147295:   7%|▋         | 10/141 [00:16<03:15,  1.49s/it]avg_loss = 4.149233146147295:   8%|▊         | 11/141 [00:16<03:13,  1.49s/it]avg_loss = 4.150946239630382:   8%|▊         | 11/141 [00:18<03:13,  1.49s/it]avg_loss = 4.150946239630382:   9%|▊         | 12/141 [00:18<03:12,  1.49s/it]avg_loss = 4.143961411256057:   9%|▊         | 12/141 [00:19<03:12,  1.49s/it]avg_loss = 4.143961411256057:   9%|▉         | 13/141 [00:19<03:11,  1.50s/it]avg_loss = 4.134005631719317:   9%|▉         | 13/141 [00:21<03:11,  1.50s/it]avg_loss = 4.134005631719317:  10%|▉         | 14/141 [00:21<03:10,  1.50s/it]avg_loss = 4.136251274744669:  10%|▉         | 14/141 [00:22<03:10,  1.50s/it]avg_loss = 4.136251274744669:  11%|█         | 15/141 [00:22<03:09,  1.50s/it]avg_loss = 4.162967845797539:  11%|█         | 15/141 [00:24<03:09,  1.50s/it]avg_loss = 4.162967845797539:  11%|█▏        | 16/141 [00:24<03:07,  1.50s/it]avg_loss = 4.148690658457139:  11%|█▏        | 16/141 [00:25<03:07,  1.50s/it]avg_loss = 4.148690658457139:  12%|█▏        | 17/141 [00:25<03:06,  1.51s/it]avg_loss = 4.15301337507036:  12%|█▏        | 17/141 [00:27<03:06,  1.51s/it] avg_loss = 4.15301337507036:  13%|█▎        | 18/141 [00:27<03:05,  1.51s/it]avg_loss = 4.15365195274353:  13%|█▎        | 18/141 [00:28<03:05,  1.51s/it]avg_loss = 4.15365195274353:  13%|█▎        | 19/141 [00:28<03:04,  1.51s/it]avg_loss = 4.151644456386566:  13%|█▎        | 19/141 [00:30<03:04,  1.51s/it]avg_loss = 4.151644456386566:  14%|█▍        | 20/141 [00:30<03:03,  1.51s/it]avg_loss = 4.160802511941819:  14%|█▍        | 20/141 [00:31<03:03,  1.51s/it]avg_loss = 4.160802511941819:  15%|█▍        | 21/141 [00:31<03:01,  1.52s/it]avg_loss = 4.176754572174766:  15%|█▍        | 21/141 [00:33<03:01,  1.52s/it]avg_loss = 4.176754572174766:  16%|█▌        | 22/141 [00:33<03:00,  1.52s/it]avg_loss = 4.177619695663452:  16%|█▌        | 22/141 [00:34<03:00,  1.52s/it]avg_loss = 4.177619695663452:  16%|█▋        | 23/141 [00:34<02:59,  1.52s/it]avg_loss = 4.186037570238113:  16%|█▋        | 23/141 [00:36<02:59,  1.52s/it]avg_loss = 4.186037570238113:  17%|█▋        | 24/141 [00:36<02:58,  1.52s/it]avg_loss = 4.192968511581421:  17%|█▋        | 24/141 [00:37<02:58,  1.52s/it]avg_loss = 4.192968511581421:  18%|█▊        | 25/141 [00:37<02:56,  1.52s/it]avg_loss = 4.201729361827557:  18%|█▊        | 25/141 [00:39<02:56,  1.52s/it]avg_loss = 4.201729361827557:  18%|█▊        | 26/141 [00:39<02:55,  1.53s/it]avg_loss = 4.2242661140583175:  18%|█▊        | 26/141 [00:40<02:55,  1.53s/it]avg_loss = 4.2242661140583175:  19%|█▉        | 27/141 [00:40<02:54,  1.53s/it]avg_loss = 4.2377802559307645:  19%|█▉        | 27/141 [00:42<02:54,  1.53s/it]avg_loss = 4.2377802559307645:  20%|█▉        | 28/141 [00:42<02:52,  1.53s/it]avg_loss = 4.237714956546652:  20%|█▉        | 28/141 [00:44<02:52,  1.53s/it] avg_loss = 4.237714956546652:  21%|██        | 29/141 [00:44<02:51,  1.53s/it]avg_loss = 4.2359234889348345:  21%|██        | 29/141 [00:45<02:51,  1.53s/it]avg_loss = 4.2359234889348345:  21%|██▏       | 30/141 [00:45<02:50,  1.53s/it]avg_loss = 4.227318386877736:  21%|██▏       | 30/141 [00:47<02:50,  1.53s/it] avg_loss = 4.227318386877736:  22%|██▏       | 31/141 [00:47<02:49,  1.54s/it]avg_loss = 4.221763126552105:  22%|██▏       | 31/141 [00:48<02:49,  1.54s/it]avg_loss = 4.221763126552105:  23%|██▎       | 32/141 [00:48<02:47,  1.54s/it]avg_loss = 4.21759903792179:  23%|██▎       | 32/141 [00:50<02:47,  1.54s/it] avg_loss = 4.21759903792179:  23%|██▎       | 33/141 [00:50<02:46,  1.54s/it]avg_loss = 4.216131722225862:  23%|██▎       | 33/141 [00:51<02:46,  1.54s/it]avg_loss = 4.216131722225862:  24%|██▍       | 34/141 [00:51<02:45,  1.54s/it]avg_loss = 4.21192946434021:  24%|██▍       | 34/141 [00:53<02:45,  1.54s/it] avg_loss = 4.21192946434021:  25%|██▍       | 35/141 [00:53<02:43,  1.55s/it]avg_loss = 4.197548508644104:  25%|██▍       | 35/141 [00:54<02:43,  1.55s/it]avg_loss = 4.197548508644104:  26%|██▌       | 36/141 [00:54<02:42,  1.55s/it]avg_loss = 4.182549798810804:  26%|██▌       | 36/141 [00:56<02:42,  1.55s/it]avg_loss = 4.182549798810804:  26%|██▌       | 37/141 [00:56<02:41,  1.55s/it]avg_loss = 4.168340394371434:  26%|██▌       | 37/141 [00:57<02:41,  1.55s/it]avg_loss = 4.168340394371434:  27%|██▋       | 38/141 [00:57<02:39,  1.55s/it]avg_loss = 4.155935898805276:  27%|██▋       | 38/141 [00:59<02:39,  1.55s/it]avg_loss = 4.155935898805276:  28%|██▊       | 39/141 [00:59<02:38,  1.55s/it]avg_loss = 4.147721689939499:  28%|██▊       | 39/141 [01:01<02:38,  1.55s/it]avg_loss = 4.147721689939499:  28%|██▊       | 40/141 [01:01<02:36,  1.55s/it]avg_loss = 4.155939142878463:  28%|██▊       | 40/141 [01:02<02:36,  1.55s/it]avg_loss = 4.155939142878463:  29%|██▉       | 41/141 [01:02<02:35,  1.55s/it]avg_loss = 4.174985391753061:  29%|██▉       | 41/141 [01:04<02:35,  1.55s/it]avg_loss = 4.174985391753061:  30%|██▉       | 42/141 [01:04<02:33,  1.55s/it]avg_loss = 4.195148529008377:  30%|██▉       | 42/141 [01:05<02:33,  1.55s/it]avg_loss = 4.195148529008377:  30%|███       | 43/141 [01:05<02:32,  1.55s/it]avg_loss = 4.2063417705622586:  30%|███       | 43/141 [01:07<02:32,  1.55s/it]avg_loss = 4.2063417705622586:  31%|███       | 44/141 [01:07<02:30,  1.56s/it]avg_loss = 4.218466975953844:  31%|███       | 44/141 [01:08<02:30,  1.56s/it] avg_loss = 4.218466975953844:  32%|███▏      | 45/141 [01:08<02:29,  1.56s/it]avg_loss = 4.222834778868633:  32%|███▏      | 45/141 [01:10<02:29,  1.56s/it]avg_loss = 4.222834778868633:  33%|███▎      | 46/141 [01:10<02:28,  1.56s/it]avg_loss = 4.2248207812613625:  33%|███▎      | 46/141 [01:12<02:28,  1.56s/it]avg_loss = 4.2248207812613625:  33%|███▎      | 47/141 [01:12<02:26,  1.56s/it]avg_loss = 4.2196472734212875:  33%|███▎      | 47/141 [01:13<02:26,  1.56s/it]avg_loss = 4.2196472734212875:  34%|███▍      | 48/141 [01:13<02:25,  1.56s/it]avg_loss = 4.220819147265687:  34%|███▍      | 48/141 [01:15<02:25,  1.56s/it] avg_loss = 4.220819147265687:  35%|███▍      | 49/141 [01:15<02:23,  1.56s/it]avg_loss = 4.217120995521546:  35%|███▍      | 49/141 [01:16<02:23,  1.56s/it]avg_loss = 4.217120995521546:  35%|███▌      | 50/141 [01:16<02:22,  1.57s/it]avg_loss = 4.212582854663625:  35%|███▌      | 50/141 [01:18<02:22,  1.57s/it]avg_loss = 4.212582854663625:  36%|███▌      | 51/141 [01:18<02:20,  1.57s/it]avg_loss = 4.207505771747003:  36%|███▌      | 51/141 [01:19<02:20,  1.57s/it]avg_loss = 4.207505771747003:  37%|███▋      | 52/141 [01:19<02:19,  1.57s/it]avg_loss = 4.199300671523472:  37%|███▋      | 52/141 [01:21<02:19,  1.57s/it]avg_loss = 4.199300671523472:  38%|███▊      | 53/141 [01:21<02:17,  1.57s/it]avg_loss = 4.19430853260888:  38%|███▊      | 53/141 [01:22<02:17,  1.57s/it] avg_loss = 4.19430853260888:  38%|███▊      | 54/141 [01:22<02:16,  1.57s/it]avg_loss = 4.183319703015414:  38%|███▊      | 54/141 [01:24<02:16,  1.57s/it]avg_loss = 4.183319703015414:  39%|███▉      | 55/141 [01:24<02:15,  1.57s/it]avg_loss = 4.17249082667487:  39%|███▉      | 55/141 [01:26<02:15,  1.57s/it] avg_loss = 4.17249082667487:  40%|███▉      | 56/141 [01:26<02:13,  1.57s/it]avg_loss = 4.168186007884511:  40%|███▉      | 56/141 [01:27<02:13,  1.57s/it]avg_loss = 4.168186007884511:  40%|████      | 57/141 [01:27<02:12,  1.57s/it]avg_loss = 4.1637978183812105:  40%|████      | 57/141 [01:29<02:12,  1.57s/it]avg_loss = 4.1637978183812105:  41%|████      | 58/141 [01:29<02:10,  1.58s/it]avg_loss = 4.173847541970722:  41%|████      | 58/141 [01:30<02:10,  1.58s/it] avg_loss = 4.173847541970722:  42%|████▏     | 59/141 [01:30<02:09,  1.58s/it]avg_loss = 4.1806065201759335:  42%|████▏     | 59/141 [01:32<02:09,  1.58s/it]avg_loss = 4.1806065201759335:  43%|████▎     | 60/141 [01:32<02:07,  1.58s/it]avg_loss = 4.184171719629257:  43%|████▎     | 60/141 [01:34<02:07,  1.58s/it] avg_loss = 4.184171719629257:  43%|████▎     | 61/141 [01:34<02:06,  1.58s/it]avg_loss = 4.1912338541400045:  43%|████▎     | 61/141 [01:35<02:06,  1.58s/it]avg_loss = 4.1912338541400045:  44%|████▍     | 62/141 [01:35<02:04,  1.58s/it]avg_loss = 4.181876988638015:  44%|████▍     | 62/141 [01:37<02:04,  1.58s/it] avg_loss = 4.181876988638015:  45%|████▍     | 63/141 [01:37<02:02,  1.58s/it]avg_loss = 4.182959210127592:  45%|████▍     | 63/141 [01:38<02:02,  1.58s/it]avg_loss = 4.182959210127592:  45%|████▌     | 64/141 [01:38<02:01,  1.58s/it]avg_loss = 4.187399757825411:  45%|████▌     | 64/141 [01:40<02:01,  1.58s/it]avg_loss = 4.187399757825411:  46%|████▌     | 65/141 [01:40<01:59,  1.58s/it]avg_loss = 4.185631589456038:  46%|████▌     | 65/141 [01:41<01:59,  1.58s/it]avg_loss = 4.185631589456038:  47%|████▋     | 66/141 [01:41<01:58,  1.58s/it]avg_loss = 4.183793640848416:  47%|████▋     | 66/141 [01:43<01:58,  1.58s/it]avg_loss = 4.183793640848416:  48%|████▊     | 67/141 [01:43<01:56,  1.58s/it]avg_loss = 4.186669079696431:  48%|████▊     | 67/141 [01:45<01:56,  1.58s/it]avg_loss = 4.186669079696431:  48%|████▊     | 68/141 [01:45<01:55,  1.58s/it]avg_loss = 4.187657746715822:  48%|████▊     | 68/141 [01:46<01:55,  1.58s/it]avg_loss = 4.187657746715822:  49%|████▉     | 69/141 [01:46<01:53,  1.58s/it]avg_loss = 4.1923735175813945:  49%|████▉     | 69/141 [01:48<01:53,  1.58s/it]avg_loss = 4.1923735175813945:  50%|████▉     | 70/141 [01:48<01:52,  1.58s/it]avg_loss = 4.197398182371972:  50%|████▉     | 70/141 [01:49<01:52,  1.58s/it] avg_loss = 4.197398182371972:  50%|█████     | 71/141 [01:49<01:50,  1.58s/it]avg_loss = 4.203844259182612:  50%|█████     | 71/141 [01:51<01:50,  1.58s/it]avg_loss = 4.203844259182612:  51%|█████     | 72/141 [01:51<01:48,  1.58s/it]avg_loss = 4.201360640460497:  51%|█████     | 72/141 [01:52<01:48,  1.58s/it]avg_loss = 4.201360640460497:  52%|█████▏    | 73/141 [01:52<01:47,  1.58s/it]avg_loss = 4.2009572370632275:  52%|█████▏    | 73/141 [01:54<01:47,  1.58s/it]avg_loss = 4.2009572370632275:  52%|█████▏    | 74/141 [01:54<01:45,  1.58s/it]avg_loss = 4.198099946975708:  52%|█████▏    | 74/141 [01:56<01:45,  1.58s/it] avg_loss = 4.198099946975708:  53%|█████▎    | 75/141 [01:56<01:44,  1.58s/it]avg_loss = 4.195981260977294:  53%|█████▎    | 75/141 [01:57<01:44,  1.58s/it]avg_loss = 4.195981260977294:  54%|█████▍    | 76/141 [01:57<01:42,  1.58s/it]avg_loss = 4.198303789287419:  54%|█████▍    | 76/141 [01:59<01:42,  1.58s/it]avg_loss = 4.198303789287419:  55%|█████▍    | 77/141 [01:59<01:41,  1.58s/it]avg_loss = 4.199654777844747:  55%|█████▍    | 77/141 [02:00<01:41,  1.58s/it]avg_loss = 4.199654777844747:  55%|█████▌    | 78/141 [02:00<01:39,  1.59s/it]avg_loss = 4.198753619495826:  55%|█████▌    | 78/141 [02:02<01:39,  1.59s/it]avg_loss = 4.198753619495826:  56%|█████▌    | 79/141 [02:02<01:38,  1.58s/it]avg_loss = 4.183705857396125:  56%|█████▌    | 79/141 [02:04<01:38,  1.58s/it]avg_loss = 4.183705857396125:  57%|█████▋    | 80/141 [02:04<01:36,  1.58s/it]avg_loss = 4.178124068695822:  57%|█████▋    | 80/141 [02:05<01:36,  1.58s/it]avg_loss = 4.178124068695822:  57%|█████▋    | 81/141 [02:05<01:34,  1.58s/it]avg_loss = 4.172940012885303:  57%|█████▋    | 81/141 [02:07<01:34,  1.58s/it]avg_loss = 4.172940012885303:  58%|█████▊    | 82/141 [02:07<01:33,  1.58s/it]avg_loss = 4.168831391506885:  58%|█████▊    | 82/141 [02:08<01:33,  1.58s/it]avg_loss = 4.168831391506885:  59%|█████▉    | 83/141 [02:08<01:31,  1.58s/it]avg_loss = 4.167361103353047:  59%|█████▉    | 83/141 [02:10<01:31,  1.58s/it]avg_loss = 4.167361103353047:  60%|█████▉    | 84/141 [02:10<01:30,  1.59s/it]avg_loss = 4.170316906536327:  60%|█████▉    | 84/141 [02:12<01:30,  1.59s/it]avg_loss = 4.170316906536327:  60%|██████    | 85/141 [02:12<01:28,  1.59s/it]avg_loss = 4.172078362731046:  60%|██████    | 85/141 [02:13<01:28,  1.59s/it]avg_loss = 4.172078362731046:  61%|██████    | 86/141 [02:13<01:27,  1.59s/it]avg_loss = 4.173858837149609:  61%|██████    | 86/141 [02:15<01:27,  1.59s/it]avg_loss = 4.173858837149609:  62%|██████▏   | 87/141 [02:15<01:25,  1.59s/it]avg_loss = 4.182213482531634:  62%|██████▏   | 87/141 [02:16<01:25,  1.59s/it]avg_loss = 4.182213482531634:  62%|██████▏   | 88/141 [02:16<01:24,  1.59s/it]avg_loss = 4.192218429586861:  62%|██████▏   | 88/141 [02:18<01:24,  1.59s/it]avg_loss = 4.192218429586861:  63%|██████▎   | 89/141 [02:18<01:22,  1.59s/it]avg_loss = 4.202875277731153:  63%|██████▎   | 89/141 [02:19<01:22,  1.59s/it]avg_loss = 4.202875277731153:  64%|██████▍   | 90/141 [02:19<01:21,  1.59s/it]avg_loss = 4.209277983550187:  64%|██████▍   | 90/141 [02:21<01:21,  1.59s/it]avg_loss = 4.209277983550187:  65%|██████▍   | 91/141 [02:21<01:19,  1.59s/it]avg_loss = 4.217222662075706:  65%|██████▍   | 91/141 [02:23<01:19,  1.59s/it]avg_loss = 4.217222662075706:  65%|██████▌   | 92/141 [02:23<01:18,  1.59s/it]avg_loss = 4.223860963698356:  65%|██████▌   | 92/141 [02:24<01:18,  1.59s/it]avg_loss = 4.223860963698356:  66%|██████▌   | 93/141 [02:24<01:16,  1.59s/it]avg_loss = 4.224212476547728:  66%|██████▌   | 93/141 [02:26<01:16,  1.59s/it]avg_loss = 4.224212476547728:  67%|██████▋   | 94/141 [02:26<01:14,  1.59s/it]avg_loss = 4.232995924196746:  67%|██████▋   | 94/141 [02:27<01:14,  1.59s/it]avg_loss = 4.232995924196746:  67%|██████▋   | 95/141 [02:27<01:13,  1.59s/it]avg_loss = 4.2363767102360725:  67%|██████▋   | 95/141 [02:29<01:13,  1.59s/it]avg_loss = 4.2363767102360725:  68%|██████▊   | 96/141 [02:29<01:11,  1.60s/it]avg_loss = 4.241357692738169:  68%|██████▊   | 96/141 [02:31<01:11,  1.60s/it] avg_loss = 4.241357692738169:  69%|██████▉   | 97/141 [02:31<01:10,  1.60s/it]avg_loss = 4.243952602756266:  69%|██████▉   | 97/141 [02:32<01:10,  1.60s/it]avg_loss = 4.243952602756266:  70%|██████▉   | 98/141 [02:32<01:08,  1.59s/it]avg_loss = 4.250198954283589:  70%|██████▉   | 98/141 [02:34<01:08,  1.59s/it]avg_loss = 4.250198954283589:  70%|███████   | 99/141 [02:34<01:06,  1.59s/it]avg_loss = 4.255321280956268:  70%|███████   | 99/141 [02:35<01:06,  1.59s/it]avg_loss = 4.255321280956268:  71%|███████   | 100/141 [02:35<01:05,  1.59s/it]avg_loss = 4.260815877725582:  71%|███████   | 100/141 [02:37<01:05,  1.59s/it]avg_loss = 4.260815877725582:  72%|███████▏  | 101/141 [02:37<01:03,  1.59s/it]avg_loss = 4.266764250456118:  72%|███████▏  | 101/141 [02:39<01:03,  1.59s/it]avg_loss = 4.266764250456118:  72%|███████▏  | 102/141 [02:39<01:01,  1.59s/it]avg_loss = 4.271331182961325:  72%|███████▏  | 102/141 [02:40<01:01,  1.59s/it]avg_loss = 4.271331182961325:  73%|███████▎  | 103/141 [02:40<01:00,  1.59s/it]avg_loss = 4.276864645572809:  73%|███████▎  | 103/141 [02:42<01:00,  1.59s/it]avg_loss = 4.276864645572809:  74%|███████▍  | 104/141 [02:42<00:58,  1.59s/it]avg_loss = 4.275740757442656:  74%|███████▍  | 104/141 [02:43<00:58,  1.59s/it]avg_loss = 4.275740757442656:  74%|███████▍  | 105/141 [02:43<00:57,  1.59s/it]avg_loss = 4.275539130534765:  74%|███████▍  | 105/141 [02:45<00:57,  1.59s/it]avg_loss = 4.275539130534765:  75%|███████▌  | 106/141 [02:45<00:55,  1.59s/it]avg_loss = 4.273933176682374:  75%|███████▌  | 106/141 [02:47<00:55,  1.59s/it]avg_loss = 4.273933176682374:  76%|███████▌  | 107/141 [02:47<00:54,  1.59s/it]avg_loss = 4.272971764758781:  76%|███████▌  | 107/141 [02:48<00:54,  1.59s/it]avg_loss = 4.272971764758781:  77%|███████▋  | 108/141 [02:48<00:52,  1.59s/it]avg_loss = 4.271932647862566:  77%|███████▋  | 108/141 [02:50<00:52,  1.59s/it]avg_loss = 4.271932647862566:  77%|███████▋  | 109/141 [02:50<00:50,  1.59s/it]avg_loss = 4.272220353646712:  77%|███████▋  | 109/141 [02:51<00:50,  1.59s/it]avg_loss = 4.272220353646712:  78%|███████▊  | 110/141 [02:51<00:49,  1.59s/it]avg_loss = 4.277388213991045:  78%|███████▊  | 110/141 [02:53<00:49,  1.59s/it]avg_loss = 4.277388213991045:  79%|███████▊  | 111/141 [02:53<00:47,  1.59s/it]avg_loss = 4.276500346405165:  79%|███████▊  | 111/141 [02:54<00:47,  1.59s/it]avg_loss = 4.276500346405165:  79%|███████▉  | 112/141 [02:54<00:46,  1.59s/it]avg_loss = 4.277867593596467:  79%|███████▉  | 112/141 [02:56<00:46,  1.59s/it]avg_loss = 4.277867593596467:  80%|████████  | 113/141 [02:56<00:44,  1.59s/it]avg_loss = 4.28390659993155:  80%|████████  | 113/141 [02:58<00:44,  1.59s/it] avg_loss = 4.28390659993155:  81%|████████  | 114/141 [02:58<00:42,  1.59s/it]avg_loss = 4.281005001068115:  81%|████████  | 114/141 [02:59<00:42,  1.59s/it]avg_loss = 4.281005001068115:  82%|████████▏ | 115/141 [02:59<00:41,  1.59s/it]avg_loss = 4.277956099345766:  82%|████████▏ | 115/141 [03:01<00:41,  1.59s/it]avg_loss = 4.277956099345766:  82%|████████▏ | 116/141 [03:01<00:39,  1.59s/it]avg_loss = 4.279401999253493:  82%|████████▏ | 116/141 [03:02<00:39,  1.59s/it]avg_loss = 4.279401999253493:  83%|████████▎ | 117/141 [03:02<00:38,  1.59s/it]avg_loss = 4.274723545979645:  83%|████████▎ | 117/141 [03:04<00:38,  1.59s/it]avg_loss = 4.274723545979645:  84%|████████▎ | 118/141 [03:04<00:36,  1.59s/it]avg_loss = 4.270078889462126:  84%|████████▎ | 118/141 [03:06<00:36,  1.59s/it]avg_loss = 4.270078889462126:  84%|████████▍ | 119/141 [03:06<00:34,  1.59s/it]avg_loss = 4.264818912744522:  84%|████████▍ | 119/141 [03:07<00:34,  1.59s/it]avg_loss = 4.264818912744522:  85%|████████▌ | 120/141 [03:07<00:33,  1.59s/it]avg_loss = 4.267492812527113:  85%|████████▌ | 120/141 [03:09<00:33,  1.59s/it]avg_loss = 4.267492812527113:  86%|████████▌ | 121/141 [03:09<00:31,  1.59s/it]avg_loss = 4.267749882135235:  86%|████████▌ | 121/141 [03:10<00:31,  1.59s/it]avg_loss = 4.267749882135235:  87%|████████▋ | 122/141 [03:10<00:30,  1.59s/it]avg_loss = 4.266620331663426:  87%|████████▋ | 122/141 [03:12<00:30,  1.59s/it]avg_loss = 4.266620331663426:  87%|████████▋ | 123/141 [03:12<00:28,  1.59s/it]avg_loss = 4.2674494693356175:  87%|████████▋ | 123/141 [03:14<00:28,  1.59s/it]avg_loss = 4.2674494693356175:  88%|████████▊ | 124/141 [03:14<00:27,  1.60s/it]avg_loss = 4.262829341888428:  88%|████████▊ | 124/141 [03:15<00:27,  1.60s/it] avg_loss = 4.262829341888428:  89%|████████▊ | 125/141 [03:15<00:25,  1.60s/it]avg_loss = 4.261907028773474:  89%|████████▊ | 125/141 [03:17<00:25,  1.60s/it]avg_loss = 4.261907028773474:  89%|████████▉ | 126/141 [03:17<00:23,  1.60s/it]avg_loss = 4.262512954201285:  89%|████████▉ | 126/141 [03:18<00:23,  1.60s/it]avg_loss = 4.262512954201285:  90%|█████████ | 127/141 [03:18<00:22,  1.60s/it]avg_loss = 4.258450428023934:  90%|█████████ | 127/141 [03:20<00:22,  1.60s/it]avg_loss = 4.258450428023934:  91%|█████████ | 128/141 [03:20<00:20,  1.60s/it]avg_loss = 4.2589805126190186:  91%|█████████ | 128/141 [03:22<00:20,  1.60s/it]avg_loss = 4.2589805126190186:  91%|█████████▏| 129/141 [03:22<00:19,  1.60s/it]avg_loss = 4.258715756122882:  91%|█████████▏| 129/141 [03:23<00:19,  1.60s/it] avg_loss = 4.258715756122882:  92%|█████████▏| 130/141 [03:23<00:17,  1.60s/it]avg_loss = 4.258883852995079:  92%|█████████▏| 130/141 [03:25<00:17,  1.60s/it]avg_loss = 4.258883852995079:  93%|█████████▎| 131/141 [03:25<00:15,  1.60s/it]avg_loss = 4.2587685422463855:  93%|█████████▎| 131/141 [03:26<00:15,  1.60s/it]avg_loss = 4.2587685422463855:  94%|█████████▎| 132/141 [03:26<00:14,  1.60s/it]avg_loss = 4.2529058062044305:  94%|█████████▎| 132/141 [03:28<00:14,  1.60s/it]avg_loss = 4.2529058062044305:  94%|█████████▍| 133/141 [03:28<00:12,  1.60s/it]avg_loss = 4.245077894694769:  94%|█████████▍| 133/141 [03:30<00:12,  1.60s/it] avg_loss = 4.245077894694769:  95%|█████████▌| 134/141 [03:30<00:11,  1.60s/it]avg_loss = 4.245632704982051:  95%|█████████▌| 134/141 [03:31<00:11,  1.60s/it]avg_loss = 4.245632704982051:  96%|█████████▌| 135/141 [03:31<00:09,  1.60s/it]avg_loss = 4.249271052725175:  96%|█████████▌| 135/141 [03:33<00:09,  1.60s/it]avg_loss = 4.249271052725175:  96%|█████████▋| 136/141 [03:33<00:07,  1.59s/it]avg_loss = 4.251045063464311:  96%|█████████▋| 136/141 [03:34<00:07,  1.59s/it]avg_loss = 4.251045063464311:  97%|█████████▋| 137/141 [03:34<00:06,  1.59s/it]avg_loss = 4.257284751836805:  97%|█████████▋| 137/141 [03:36<00:06,  1.59s/it]avg_loss = 4.257284751836805:  98%|█████████▊| 138/141 [03:36<00:04,  1.59s/it]avg_loss = 4.261830583750773:  98%|█████████▊| 138/141 [03:38<00:04,  1.59s/it]avg_loss = 4.261830583750773:  99%|█████████▊| 139/141 [03:38<00:03,  1.59s/it]avg_loss = 4.266367568288531:  99%|█████████▊| 139/141 [03:39<00:03,  1.59s/it]avg_loss = 4.266367568288531:  99%|█████████▉| 140/141 [03:39<00:01,  1.59s/it]avg_loss = 4.270136322535522:  99%|█████████▉| 140/141 [03:41<00:01,  1.59s/it]avg_loss = 4.270136322535522: 100%|██████████| 141/141 [03:41<00:00,  1.59s/it]avg_loss = 4.270136322535522: 100%|██████████| 141/141 [03:41<00:00,  1.57s/it]
I0401 09:11:01.079050 2931238 eval_ppl.py:107] wikitext2 perplexity: 71.53138732910156
wikitext2 perplexity: 71.531
