I0401 08:35:39.518018 2906350 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:35:39.518106 2906350 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:35:39.518144 2906350 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:35:39.834939 2906350 config.py:54] PyTorch version 2.6.0 available.
W0401 08:35:40.019653 2906350 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:35:40.645839 2906350 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.34it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.83it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.07it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.19it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.27it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.38it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.21it/s]
I0401 08:35:42.054273 2906350 quantize_finetune_llama.py:152] loaded model
I0401 08:35:42.304634 2906350 quantize_finetune_llama.py:190] loaded compression model
I0401 08:35:59.926859 2906350 quantize_finetune_llama.py:194] loaded dataset and devset
I0401 08:36:05.098015 2906350 quantize_finetune_llama.py:214] layer 0 gpu 0
I0401 08:36:07.575758 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 2.3203704357147217s
tensor([0.]) tensor([0.])
tensor([0.]) tensor([0.])
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0401 08:36:20.473213 2906923 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:36:20.473300 2906923 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:36:20.473340 2906923 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:36:20.794625 2906923 config.py:54] PyTorch version 2.6.0 available.
W0401 08:36:20.988396 2906923 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:36:21.518356 2906923 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:36:21.522173 2906350 quantize_finetune_llama.py:214] layer 1 gpu 1
I0401 08:36:21.536756 2906923 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:36:24.185131 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 2.4935929775238037s
I0401 08:36:27.871391 2907058 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:36:27.871479 2907058 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:36:27.871519 2907058 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:36:28.194962 2907058 config.py:54] PyTorch version 2.6.0 available.
W0401 08:36:28.401279 2907058 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:36:29.074301 2907058 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:36:29.078289 2906350 quantize_finetune_llama.py:214] layer 2 gpu 2
I0401 08:36:29.094824 2907058 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:36:31.766756 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 2.5192105770111084s
I0401 08:36:35.677692 2907216 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:36:35.677793 2907216 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:36:35.677840 2907216 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:36:36.046580 2907216 config.py:54] PyTorch version 2.6.0 available.
W0401 08:36:36.258848 2907216 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:36:36.929713 2907216 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:36:36.933828 2906350 quantize_finetune_llama.py:214] layer 3 gpu 3
I0401 08:36:36.950767 2907216 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:36:39.669236 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 2.554067850112915s
I0401 08:36:43.847084 2907366 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:36:43.847194 2907366 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:36:43.847239 2907366 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:36:44.244988 2907366 config.py:54] PyTorch version 2.6.0 available.
W0401 08:36:44.483427 2907366 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:36:45.182620 2907366 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:36:45.187182 2906350 quantize_finetune_llama.py:214] layer 4 gpu 0
I0401 08:36:45.229783 2907366 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_v proxy err 1.0285414457321167 tr(WHW.T) 60.88684844970703
bpp_loss 0.5774275958538055
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_q proxy err 0.5607432126998901 tr(WHW.T) 288094.65625
bpp_loss 0.5901182293891907
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_k proxy err 0.5999683141708374 tr(WHW.T) 100180.734375
bpp_loss 0.6013953387737274
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_o proxy err 0.6337699890136719 tr(WHW.T) 3123.217529296875
bpp_loss 0.5543727576732635
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_up proxy err 0.8586907982826233 tr(WHW.T) 8924.451171875
bpp_loss 0.5153344529015678
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_gate proxy err 0.7790419459342957 tr(WHW.T) 15778.666015625
bpp_loss 0.5314582075391497
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_down proxy err 0.7732182741165161 tr(WHW.T) 10818.205078125
bpp_loss 0.5362546954836164
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_v proxy err 1.0396307706832886 tr(WHW.T) 109.07096099853516
bpp_loss 0.530419796705246
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_q proxy err 0.68259596824646 tr(WHW.T) 144826.484375
bpp_loss 0.5505920946598053
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_k proxy err 0.6680675148963928 tr(WHW.T) 75539.046875
bpp_loss 0.5626172721385956
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_o proxy err 0.7286701202392578 tr(WHW.T) 1983.8321533203125
bpp_loss 0.5556212067604065
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_up proxy err 0.8268539309501648 tr(WHW.T) 8230.8203125
bpp_loss 0.5319124119622367
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_gate proxy err 0.7852882146835327 tr(WHW.T) 13952.365234375
bpp_loss 0.5316076789583478
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_down proxy err 0.6966670155525208 tr(WHW.T) 13978.03125
bpp_loss 0.5249223794255938
I0401 08:37:31.406306 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.9908294677734375s
I0401 08:37:35.350849 2907971 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:37:35.350958 2907971 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:37:35.350999 2907971 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:37:35.735872 2907971 config.py:54] PyTorch version 2.6.0 available.
W0401 08:37:35.955785 2907971 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:37:36.634025 2907971 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:37:36.637985 2906350 quantize_finetune_llama.py:214] layer 5 gpu 1
I0401 08:37:36.654065 2907971 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_v proxy err 0.8820054531097412 tr(WHW.T) 155.95950317382812
bpp_loss 0.5336292684078217
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_q proxy err 0.6750842332839966 tr(WHW.T) 41475.15625
bpp_loss 0.5648942589759827
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_k proxy err 0.6899033784866333 tr(WHW.T) 22614.533203125
bpp_loss 0.5624371469020844
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_o proxy err 0.7017964720726013 tr(WHW.T) 1967.3226318359375
bpp_loss 0.5541725158691406
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_up proxy err 0.8823928236961365 tr(WHW.T) 7600.474609375
bpp_loss 0.5136317525591169
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_gate proxy err 0.8004645109176636 tr(WHW.T) 15113.31640625
bpp_loss 0.525698219026838
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_down proxy err 0.8470125198364258 tr(WHW.T) 7726.72509765625
bpp_loss 0.5226946728570121
I0401 08:37:39.162504 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.9704763889312744s
I0401 08:37:43.159749 2908117 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:37:43.159879 2908117 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:37:43.159928 2908117 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:37:43.538423 2908117 config.py:54] PyTorch version 2.6.0 available.
W0401 08:37:43.751411 2908117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:37:44.418253 2908117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:37:44.422581 2906350 quantize_finetune_llama.py:214] layer 6 gpu 2
I0401 08:37:44.440966 2908117 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_v proxy err 0.8430110216140747 tr(WHW.T) 289.3331604003906
bpp_loss 0.5300745964050293
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_q proxy err 0.6858527064323425 tr(WHW.T) 47576.9296875
bpp_loss 0.5559679865837097
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_k proxy err 0.6837263703346252 tr(WHW.T) 26174.515625
bpp_loss 0.5605962872505188
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_o proxy err 0.7496297955513 tr(WHW.T) 1857.15771484375
bpp_loss 0.5509326756000519
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_up proxy err 0.8797460198402405 tr(WHW.T) 7536.46484375
bpp_loss 0.5133117948259626
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_gate proxy err 0.7764455676078796 tr(WHW.T) 20884.34765625
bpp_loss 0.5283153397696358
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_down proxy err 0.8593855500221252 tr(WHW.T) 6998.6103515625
bpp_loss 0.5214934859957013
I0401 08:37:47.326059 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.8713557720184326s
I0401 08:37:51.415133 2908275 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:37:51.415233 2908275 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:37:51.415279 2908275 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:37:51.784887 2908275 config.py:54] PyTorch version 2.6.0 available.
W0401 08:37:52.006141 2908275 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:37:52.693037 2908275 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:37:52.697093 2906350 quantize_finetune_llama.py:214] layer 7 gpu 3
I0401 08:37:52.713903 2908275 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:37:54.128103 2906350 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.9101104736328125s
I0401 08:37:58.190424 2908433 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:37:58.190542 2908433 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:37:58.190583 2908433 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:37:58.577302 2908433 config.py:54] PyTorch version 2.6.0 available.
W0401 08:37:58.798736 2908433 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:37:59.445669 2908433 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:37:59.449731 2906350 quantize_finetune_llama.py:214] layer 8 gpu 0
I0401 08:37:59.466531 2908433 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:38:12.795919 2908710 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:38:12.796033 2908710 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:38:12.796073 2908710 utils.py:162] NumExpr defaulting to 16 threads.
