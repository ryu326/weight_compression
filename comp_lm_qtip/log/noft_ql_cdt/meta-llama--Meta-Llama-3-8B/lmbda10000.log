I0401 08:38:17.372099 2908854 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:38:17.372196 2908854 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:38:17.372236 2908854 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:38:17.696530 2908854 config.py:54] PyTorch version 2.6.0 available.
W0401 08:38:17.883292 2908854 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:38:18.551877 2908854 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.26it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.80it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.14it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.21it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.23it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.34it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.16it/s]
I0401 08:38:19.979836 2908854 quantize_finetune_llama.py:152] loaded model
I0401 08:38:20.241407 2908854 quantize_finetune_llama.py:190] loaded compression model
I0401 08:38:38.456817 2908854 quantize_finetune_llama.py:194] loaded dataset and devset
I0401 08:38:43.412878 2908854 quantize_finetune_llama.py:214] layer 0 gpu 0
I0401 08:38:45.907933 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 2.3324055671691895s
tensor([0.]) tensor([0.])
tensor([0.]) tensor([0.])
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0401 08:38:59.036114 2909399 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:38:59.036208 2909399 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:38:59.036246 2909399 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:38:59.359600 2909399 config.py:54] PyTorch version 2.6.0 available.
W0401 08:38:59.545918 2909399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:39:00.104687 2909399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:39:00.108363 2908854 quantize_finetune_llama.py:214] layer 1 gpu 1
I0401 08:39:00.122460 2909399 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:39:02.792771 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 2.5131568908691406s
I0401 08:39:06.497389 2909567 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:39:06.497477 2909567 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:39:06.497514 2909567 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:39:06.820569 2909567 config.py:54] PyTorch version 2.6.0 available.
W0401 08:39:07.009027 2909567 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:39:07.614618 2909567 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:39:07.618605 2908854 quantize_finetune_llama.py:214] layer 2 gpu 2
I0401 08:39:07.634499 2909567 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:39:10.384175 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 2.6010029315948486s
I0401 08:39:14.293360 2909715 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:39:14.293462 2909715 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:39:14.293504 2909715 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:39:14.655297 2909715 config.py:54] PyTorch version 2.6.0 available.
W0401 08:39:14.868874 2909715 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:39:15.497289 2909715 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:39:15.501378 2908854 quantize_finetune_llama.py:214] layer 3 gpu 3
I0401 08:39:15.521335 2909715 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:39:18.154232 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 2.4644336700439453s
I0401 08:39:22.374541 2909865 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:39:22.374650 2909865 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:39:22.374693 2909865 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:39:22.763655 2909865 config.py:54] PyTorch version 2.6.0 available.
W0401 08:39:22.986402 2909865 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:39:23.660049 2909865 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:39:23.664454 2908854 quantize_finetune_llama.py:214] layer 4 gpu 0
I0401 08:39:23.688551 2909865 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_v proxy err 0.6102864146232605 tr(WHW.T) 60.88684844970703
bpp_loss 1.2250544428825378
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_q proxy err 0.01775999180972576 tr(WHW.T) 288094.65625
bpp_loss 1.6237134337425232
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_k proxy err 0.012490332126617432 tr(WHW.T) 100180.734375
bpp_loss 1.6788846254348755
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_o proxy err 0.07272092252969742 tr(WHW.T) 3123.217529296875
bpp_loss 1.4105173349380493
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_up proxy err 0.16953203082084656 tr(WHW.T) 8924.451171875
bpp_loss 1.366478102547782
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_gate proxy err 0.11342824250459671 tr(WHW.T) 15778.666015625
bpp_loss 1.4299958774021693
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
0_down proxy err 0.1294621229171753 tr(WHW.T) 10818.205078125
bpp_loss 1.4091803857258387
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_v proxy err 0.5298042297363281 tr(WHW.T) 109.07096099853516
bpp_loss 1.2008932828903198
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_q proxy err 0.01770625449717045 tr(WHW.T) 144826.484375
bpp_loss 1.6849083304405212
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_k proxy err 0.00931232888251543 tr(WHW.T) 75539.046875
bpp_loss 2.0070639848709106
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_o proxy err 0.12372316420078278 tr(WHW.T) 1983.8321533203125
bpp_loss 1.401387095451355
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_up proxy err 0.18349327147006989 tr(WHW.T) 8230.8203125
bpp_loss 1.3686580657958984
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_gate proxy err 0.12500357627868652 tr(WHW.T) 13952.365234375
bpp_loss 1.4459127698625838
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
1_down proxy err 0.18813596665859222 tr(WHW.T) 13978.03125
bpp_loss 1.3886029890605383
I0401 08:40:09.788295 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.9597268104553223s
I0401 08:40:13.710490 2910417 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:40:13.710600 2910417 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:40:13.710641 2910417 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:40:14.095551 2910417 config.py:54] PyTorch version 2.6.0 available.
W0401 08:40:14.313647 2910417 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:40:14.937011 2910417 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:40:14.940846 2908854 quantize_finetune_llama.py:214] layer 5 gpu 1
I0401 08:40:14.956220 2910417 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_v proxy err 0.3558158874511719 tr(WHW.T) 155.95950317382812
bpp_loss 1.1390074491500854
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_q proxy err 0.02690829336643219 tr(WHW.T) 41475.15625
bpp_loss 1.7787560820579529
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_k proxy err 0.016705160960555077 tr(WHW.T) 22614.533203125
bpp_loss 2.2894426584243774
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_o proxy err 0.12485213577747345 tr(WHW.T) 1967.3226318359375
bpp_loss 1.331266462802887
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_up proxy err 0.19322600960731506 tr(WHW.T) 7600.474609375
bpp_loss 1.371624537876674
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_gate proxy err 0.11596507579088211 tr(WHW.T) 15113.31640625
bpp_loss 1.4888497761317663
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
2_down proxy err 0.19103844463825226 tr(WHW.T) 7726.72509765625
bpp_loss 1.3663484028407507
I0401 08:40:17.731135 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.9391477108001709s
I0401 08:40:21.677133 2910560 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:40:21.677234 2910560 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:40:21.677275 2910560 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:40:22.048623 2910560 config.py:54] PyTorch version 2.6.0 available.
W0401 08:40:22.262526 2910560 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:40:22.954195 2910560 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:40:22.958388 2908854 quantize_finetune_llama.py:214] layer 6 gpu 2
I0401 08:40:22.974192 2910560 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_v proxy err 0.25952473282814026 tr(WHW.T) 289.3331604003906
bpp_loss 1.2008747458457947
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_q proxy err 0.019720805808901787 tr(WHW.T) 47576.9296875
bpp_loss 1.863904595375061
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_k proxy err 0.012880678288638592 tr(WHW.T) 26174.515625
bpp_loss 2.3668978214263916
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_o proxy err 0.17470405995845795 tr(WHW.T) 1857.15771484375
bpp_loss 1.3096920251846313
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_up proxy err 0.19292572140693665 tr(WHW.T) 7536.46484375
bpp_loss 1.3579243932451521
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_gate proxy err 0.09251811355352402 tr(WHW.T) 20884.34765625
bpp_loss 1.5439506258283342
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
3_down proxy err 0.20502814650535583 tr(WHW.T) 6998.6103515625
bpp_loss 1.3500824655805315
I0401 08:40:25.480152 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.8067913055419922s
I0401 08:40:29.346668 2910721 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:40:29.346766 2910721 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:40:29.346807 2910721 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:40:29.710393 2910721 config.py:54] PyTorch version 2.6.0 available.
W0401 08:40:29.927571 2910721 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:40:30.565466 2910721 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:40:30.569497 2908854 quantize_finetune_llama.py:214] layer 7 gpu 3
I0401 08:40:30.585771 2910721 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:40:32.104835 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 1.0021004676818848s
I0401 08:40:36.235309 2910847 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:40:36.235417 2910847 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:40:36.235456 2910847 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:40:36.639567 2910847 config.py:54] PyTorch version 2.6.0 available.
W0401 08:40:36.871412 2910847 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:40:37.519370 2910847 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:40:37.523404 2908854 quantize_finetune_llama.py:214] layer 8 gpu 0
I0401 08:40:37.540602 2910847 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_v proxy err 0.2737337052822113 tr(WHW.T) 285.30712890625
bpp_loss 1.2333025336265564
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_q proxy err 0.022152457386255264 tr(WHW.T) 50114.859375
bpp_loss 1.7854440212249756
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_k proxy err 0.012283248826861382 tr(WHW.T) 29301.974609375
bpp_loss 2.380757212638855
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_o proxy err 0.22785590589046478 tr(WHW.T) 1297.2481689453125
bpp_loss 1.3399308919906616
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_up proxy err 0.19494536519050598 tr(WHW.T) 7383.48779296875
bpp_loss 1.334846087864467
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_gate proxy err 0.07277421653270721 tr(WHW.T) 29130.974609375
bpp_loss 1.613016128540039
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
4_down proxy err 0.21256229281425476 tr(WHW.T) 6395.72265625
bpp_loss 1.3475833960941859
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_v proxy err 0.3040062487125397 tr(WHW.T) 208.81988525390625
bpp_loss 1.1568519473075867
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_q proxy err 0.02700584940612316 tr(WHW.T) 35991.625
bpp_loss 1.776566743850708
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_k proxy err 0.017530521377921104 tr(WHW.T) 22997.75390625
bpp_loss 2.233287811279297
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_o proxy err 0.27150365710258484 tr(WHW.T) 1055.5865478515625
bpp_loss 1.269438087940216
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_up proxy err 0.18984687328338623 tr(WHW.T) 7656.43310546875
bpp_loss 1.3384605816432409
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_gate proxy err 0.06849496811628342 tr(WHW.T) 30386.947265625
bpp_loss 1.638953617640904
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
5_down proxy err 0.21151430904865265 tr(WHW.T) 6411.12939453125
bpp_loss 1.3519046817507063
I0401 08:41:24.990337 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 1.182990550994873s
I0401 08:41:29.040948 2911446 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:41:29.041064 2911446 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:41:29.041107 2911446 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:41:29.440268 2911446 config.py:54] PyTorch version 2.6.0 available.
W0401 08:41:29.662373 2911446 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:41:30.340466 2911446 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:41:30.344362 2908854 quantize_finetune_llama.py:214] layer 9 gpu 1
I0401 08:41:30.364546 2911446 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_v proxy err 0.28146517276763916 tr(WHW.T) 253.63377380371094
bpp_loss 1.1923747062683105
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_q proxy err 0.025150572881102562 tr(WHW.T) 35639.5859375
bpp_loss 1.8584155440330505
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_k proxy err 0.012486295774579048 tr(WHW.T) 26163.654296875
bpp_loss 2.4059728384017944
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_o proxy err 0.2619794011116028 tr(WHW.T) 1009.1483764648438
bpp_loss 1.3655871748924255
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_up proxy err 0.18419034779071808 tr(WHW.T) 7923.53564453125
bpp_loss 1.3430018424987793
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_gate proxy err 0.062006160616874695 tr(WHW.T) 35748.39453125
bpp_loss 1.6276548249380929
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
6_down proxy err 0.20879758894443512 tr(WHW.T) 6483.5595703125
bpp_loss 1.3530843768801009
I0401 08:41:33.311089 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.9788045883178711s
I0401 08:41:37.303972 2911592 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:41:37.304075 2911592 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:41:37.304116 2911592 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:41:37.631152 2911592 config.py:54] PyTorch version 2.6.0 available.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_v proxy err 0.24504290521144867 tr(WHW.T) 309.4270935058594
bpp_loss 1.1857763528823853
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_q proxy err 0.026126407086849213 tr(WHW.T) 35144.953125
bpp_loss 1.8136053085327148
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_k proxy err 0.012473071925342083 tr(WHW.T) 26850.4921875
bpp_loss 2.4382834434509277
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_o proxy err 0.3135080635547638 tr(WHW.T) 959.2155151367188
bpp_loss 1.2903883457183838
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_up proxy err 0.1746983379125595 tr(WHW.T) 8627.4501953125
bpp_loss 1.3482566561017717
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_gate proxy err 0.06444147974252701 tr(WHW.T) 34903.53515625
bpp_loss 1.5934739794049944
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
7_down proxy err 0.2056599110364914 tr(WHW.T) 6534.6279296875
bpp_loss 1.370672617639814
W0401 08:41:37.828869 2911592 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:41:38.438459 2911592 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:41:38.442389 2908854 quantize_finetune_llama.py:214] layer 10 gpu 2
I0401 08:41:38.457861 2911592 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:41:39.878506 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.9367403984069824s
I0401 08:41:43.658810 2911740 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:41:43.658911 2911740 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:41:43.658952 2911740 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:41:44.022548 2911740 config.py:54] PyTorch version 2.6.0 available.
W0401 08:41:44.239974 2911740 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:41:44.843991 2911740 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:41:44.847909 2908854 quantize_finetune_llama.py:214] layer 11 gpu 3
I0401 08:41:44.863531 2911740 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:41:46.363420 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 1.0234453678131104s
I0401 08:41:50.490039 2911869 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:41:50.490147 2911869 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:41:50.490189 2911869 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:41:50.898530 2911869 config.py:54] PyTorch version 2.6.0 available.
W0401 08:41:51.129199 2911869 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:41:51.788762 2911869 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:41:51.792761 2908854 quantize_finetune_llama.py:214] layer 12 gpu 0
I0401 08:41:51.808940 2911869 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_v proxy err 0.27209365367889404 tr(WHW.T) 257.7052307128906
bpp_loss 1.222537100315094
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_q proxy err 0.035669658333063126 tr(WHW.T) 26600.9765625
bpp_loss 1.686196506023407
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_k proxy err 0.013644268736243248 tr(WHW.T) 22528.748046875
bpp_loss 2.4014883041381836
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_o proxy err 0.36635032296180725 tr(WHW.T) 745.6061401367188
bpp_loss 1.3549368381500244
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_up proxy err 0.17703849077224731 tr(WHW.T) 8495.0546875
bpp_loss 1.3452825546264648
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_gate proxy err 0.06174270436167717 tr(WHW.T) 37238.1484375
bpp_loss 1.5883772713797433
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
8_down proxy err 0.20394617319107056 tr(WHW.T) 6488.8173828125
bpp_loss 1.378382682800293
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_v proxy err 0.23341040313243866 tr(WHW.T) 351.4288024902344
bpp_loss 1.292742669582367
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_q proxy err 0.03253474086523056 tr(WHW.T) 25653.232421875
bpp_loss 1.7677392363548279
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_k proxy err 0.013609637506306171 tr(WHW.T) 20942.638671875
bpp_loss 2.4358972311019897
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_o proxy err 0.4104679822921753 tr(WHW.T) 776.6017456054688
bpp_loss 1.3306215405464172
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_up proxy err 0.16998133063316345 tr(WHW.T) 8970.6455078125
bpp_loss 1.3506905691964286
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_gate proxy err 0.06028226763010025 tr(WHW.T) 39415.71875
bpp_loss 1.5856946536472865
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
9_down proxy err 0.21269434690475464 tr(WHW.T) 6272.90380859375
bpp_loss 1.3727814299719674
I0401 08:42:40.434800 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 1.04990816116333s
I0401 08:42:44.442544 2912463 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:42:44.442656 2912463 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:42:44.442698 2912463 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:42:44.826796 2912463 config.py:54] PyTorch version 2.6.0 available.
W0401 08:42:45.041839 2912463 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_v proxy err 0.2731245160102844 tr(WHW.T) 251.83889770507812
bpp_loss 1.2182984352111816
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_q proxy err 0.039627719670534134 tr(WHW.T) 23338.15625
bpp_loss 1.7175408005714417
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_k proxy err 0.015745358541607857 tr(WHW.T) 19743.95703125
bpp_loss 2.4077452421188354
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_o proxy err 0.39417561888694763 tr(WHW.T) 680.6640625
bpp_loss 1.34387868642807
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_up proxy err 0.16663220524787903 tr(WHW.T) 9199.1572265625
bpp_loss 1.3677709443228585
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_gate proxy err 0.062034912407398224 tr(WHW.T) 37399.37109375
bpp_loss 1.5664750507899694
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
10_down proxy err 0.2122258096933365 tr(WHW.T) 6525.2333984375
bpp_loss 1.3693173612867082
W0401 08:42:45.678363 2912463 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:42:45.682954 2908854 quantize_finetune_llama.py:214] layer 13 gpu 1
I0401 08:42:45.698698 2912463 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:42:47.566205 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 1.0139119625091553s
I0401 08:42:51.604297 2912596 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:42:51.604398 2912596 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:42:51.604440 2912596 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_v proxy err 0.236692875623703 tr(WHW.T) 319.5691223144531
bpp_loss 1.2022014260292053
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_q proxy err 0.036524079740047455 tr(WHW.T) 22190.8984375
bpp_loss 1.7380034923553467
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_k proxy err 0.01589314453303814 tr(WHW.T) 18027.423828125
bpp_loss 2.4384907484054565
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_o proxy err 0.5162271857261658 tr(WHW.T) 565.9476928710938
bpp_loss 1.2986461520195007
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_up proxy err 0.16675937175750732 tr(WHW.T) 9192.595703125
bpp_loss 1.3713804653712682
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_gate proxy err 0.0641414001584053 tr(WHW.T) 36884.09375
bpp_loss 1.5340687888009208
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
11_down proxy err 0.21010391414165497 tr(WHW.T) 6655.890625
bpp_loss 1.3723467418125697
I0401 08:42:51.957405 2912596 config.py:54] PyTorch version 2.6.0 available.
W0401 08:42:52.157247 2912596 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:42:52.709390 2912596 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:42:52.713259 2908854 quantize_finetune_llama.py:214] layer 14 gpu 2
I0401 08:42:52.731416 2912596 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:42:54.342040 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 1.149216651916504s
I0401 08:42:58.111974 2912739 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:42:58.112075 2912739 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:42:58.112117 2912739 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:42:58.502023 2912739 config.py:54] PyTorch version 2.6.0 available.
W0401 08:42:58.730584 2912739 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:42:59.396822 2912739 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:42:59.400785 2908854 quantize_finetune_llama.py:214] layer 15 gpu 3
I0401 08:42:59.416752 2912739 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:43:00.881036 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 0.9887444972991943s
I0401 08:43:05.018217 2912876 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:43:05.018325 2912876 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:43:05.018366 2912876 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:43:05.420194 2912876 config.py:54] PyTorch version 2.6.0 available.
W0401 08:43:05.640542 2912876 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:43:06.274865 2912876 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:43:06.279070 2908854 quantize_finetune_llama.py:214] layer 16 gpu 0
I0401 08:43:06.295485 2912876 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_v proxy err 0.23787856101989746 tr(WHW.T) 363.6233825683594
bpp_loss 1.2693673372268677
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_q proxy err 0.023296944797039032 tr(WHW.T) 34102.625
bpp_loss 1.8533656001091003
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_k proxy err 0.012623953633010387 tr(WHW.T) 23057.041015625
bpp_loss 2.4301795959472656
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_o proxy err 0.39431238174438477 tr(WHW.T) 779.7713012695312
bpp_loss 1.3539625406265259
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_up proxy err 0.1596638262271881 tr(WHW.T) 10027.1552734375
bpp_loss 1.3746797016688757
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_gate proxy err 0.06470964848995209 tr(WHW.T) 37334.1015625
bpp_loss 1.509326798575265
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
12_down proxy err 0.19447050988674164 tr(WHW.T) 6822.7119140625
bpp_loss 1.427610993385315
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_v proxy err 0.27447444200515747 tr(WHW.T) 280.153564453125
bpp_loss 1.2325521111488342
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_q proxy err 0.03740890324115753 tr(WHW.T) 20897.375
bpp_loss 1.7620255947113037
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_k proxy err 0.015389849431812763 tr(WHW.T) 17798.916015625
bpp_loss 2.46262788772583
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_o proxy err 0.3975019156932831 tr(WHW.T) 675.2068481445312
bpp_loss 1.4271594882011414
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_up proxy err 0.15977530181407928 tr(WHW.T) 10010.2880859375
bpp_loss 1.378387451171875
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_gate proxy err 0.06358211487531662 tr(WHW.T) 38921.26171875
bpp_loss 1.5123305320739746
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
13_down proxy err 0.21926648914813995 tr(WHW.T) 6560.505859375
bpp_loss 1.3689543519701277
I0401 08:43:54.539855 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.9006505012512207s
I0401 08:43:58.516005 2913460 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:43:58.516121 2913460 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:43:58.516167 2913460 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:43:58.903589 2913460 config.py:54] PyTorch version 2.6.0 available.
W0401 08:43:59.120682 2913460 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_v proxy err 0.27127522230148315 tr(WHW.T) 281.3382873535156
bpp_loss 1.231954574584961
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_q proxy err 0.04088401049375534 tr(WHW.T) 20881.8359375
bpp_loss 1.7107433080673218
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_k proxy err 0.01807424984872341 tr(WHW.T) 18619.298828125
bpp_loss 2.2944992780685425
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_o proxy err 0.4565405547618866 tr(WHW.T) 686.2976684570312
bpp_loss 1.300077736377716
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_up proxy err 0.17157484591007233 tr(WHW.T) 9164.287109375
bpp_loss 1.3727855682373047
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_gate proxy err 0.06043292582035065 tr(WHW.T) 41785.8203125
bpp_loss 1.5292823655264718
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
14_down proxy err 0.22319395840168 tr(WHW.T) 6390.916015625
bpp_loss 1.371280585016523
W0401 08:43:59.740174 2913460 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:43:59.744270 2908854 quantize_finetune_llama.py:214] layer 17 gpu 1
I0401 08:43:59.760519 2913460 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:44:01.704787 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 0.9117536544799805s
I0401 08:44:05.711098 2913606 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:44:05.711197 2913606 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:44:05.711237 2913606 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:44:06.086021 2913606 config.py:54] PyTorch version 2.6.0 available.
W0401 08:44:06.292250 2913606 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_v proxy err 0.28104928135871887 tr(WHW.T) 284.0271301269531
bpp_loss 1.2738640308380127
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_q proxy err 0.033285681158304214 tr(WHW.T) 28079.306640625
bpp_loss 1.7481375336647034
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_k proxy err 0.013471395708620548 tr(WHW.T) 18871.66796875
bpp_loss 2.5287240743637085
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_o proxy err 0.3745354115962982 tr(WHW.T) 827.9279174804688
bpp_loss 1.3728691935539246
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_up proxy err 0.1723528355360031 tr(WHW.T) 8994.5693359375
bpp_loss 1.375054086957659
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_gate proxy err 0.05650822073221207 tr(WHW.T) 46217.96875
bpp_loss 1.554959501538958
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
15_down proxy err 0.22144772112369537 tr(WHW.T) 6399.38671875
bpp_loss 1.3693654366901942
W0401 08:44:06.824191 2913606 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:44:06.827684 2908854 quantize_finetune_llama.py:214] layer 18 gpu 2
I0401 08:44:06.841910 2913606 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:44:08.289887 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.853543758392334s
I0401 08:44:12.117716 2913772 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:44:12.117821 2913772 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:44:12.117863 2913772 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:44:12.492502 2913772 config.py:54] PyTorch version 2.6.0 available.
W0401 08:44:12.715706 2913772 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:44:13.334655 2913772 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:44:13.338714 2908854 quantize_finetune_llama.py:214] layer 19 gpu 3
I0401 08:44:13.354181 2913772 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:44:14.876213 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 1.0548677444458008s
I0401 08:44:18.835141 2913906 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:44:18.835256 2913906 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:44:18.835296 2913906 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:44:19.225388 2913906 config.py:54] PyTorch version 2.6.0 available.
W0401 08:44:19.449404 2913906 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:44:20.119262 2913906 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:44:20.123369 2908854 quantize_finetune_llama.py:214] layer 20 gpu 0
I0401 08:44:20.139641 2913906 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_v proxy err 0.27333739399909973 tr(WHW.T) 274.28167724609375
bpp_loss 1.247418761253357
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_q proxy err 0.03547931835055351 tr(WHW.T) 24486.64453125
bpp_loss 1.7807044982910156
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_k proxy err 0.014875915832817554 tr(WHW.T) 19506.357421875
bpp_loss 2.4243483543395996
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_o proxy err 0.3059469163417816 tr(WHW.T) 969.0885620117188
bpp_loss 1.3833502531051636
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_up proxy err 0.18004824221134186 tr(WHW.T) 8331.1826171875
bpp_loss 1.3692703928266252
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_gate proxy err 0.05877675861120224 tr(WHW.T) 41176.12890625
bpp_loss 1.599175180707659
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
16_down proxy err 0.21960556507110596 tr(WHW.T) 6288.2802734375
bpp_loss 1.3704272508621216
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_v proxy err 0.2930299937725067 tr(WHW.T) 283.9730224609375
bpp_loss 1.2836652994155884
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_q proxy err 0.028432724997401237 tr(WHW.T) 27571.44140625
bpp_loss 1.8367260098457336
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_k proxy err 0.015787383541464806 tr(WHW.T) 17429.814453125
bpp_loss 2.4565733671188354
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_o proxy err 0.29236355423927307 tr(WHW.T) 1106.6993408203125
bpp_loss 1.3796110153198242
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_up proxy err 0.17960448563098907 tr(WHW.T) 8452.5419921875
bpp_loss 1.3634627205984933
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_gate proxy err 0.058649029582738876 tr(WHW.T) 41717.5625
bpp_loss 1.6075475556509835
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
17_down proxy err 0.22141136229038239 tr(WHW.T) 6212.31494140625
bpp_loss 1.3684562955583846
I0401 08:45:08.724860 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.1841793060302734s
I0401 08:45:12.852919 2914482 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:45:12.853019 2914482 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:45:12.853059 2914482 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:45:13.225936 2914482 config.py:54] PyTorch version 2.6.0 available.
W0401 08:45:13.435084 2914482 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_v proxy err 0.2641522288322449 tr(WHW.T) 287.61376953125
bpp_loss 1.2424137592315674
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_q proxy err 0.032797958701848984 tr(WHW.T) 22399.498046875
bpp_loss 1.8518291115760803
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_k proxy err 0.01632639393210411 tr(WHW.T) 17394.810546875
bpp_loss 2.4428083896636963
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_o proxy err 0.24620309472084045 tr(WHW.T) 1203.193603515625
bpp_loss 1.4202557802200317
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_up proxy err 0.1842501014471054 tr(WHW.T) 7982.8837890625
bpp_loss 1.369321346282959
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_gate proxy err 0.06320104748010635 tr(WHW.T) 35243.5546875
bpp_loss 1.6362974984305245
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
18_down proxy err 0.2236606329679489 tr(WHW.T) 6226.57861328125
bpp_loss 1.359848243849618
W0401 08:45:14.077474 2914482 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:45:14.081344 2908854 quantize_finetune_llama.py:214] layer 21 gpu 1
I0401 08:45:14.098173 2914482 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:45:15.706058 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.9226067066192627s
I0401 08:45:19.722078 2914618 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:45:19.722171 2914618 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:45:19.722213 2914618 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_v proxy err 0.24617859721183777 tr(WHW.T) 341.0596618652344
bpp_loss 1.2622438669204712
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_q proxy err 0.029796553775668144 tr(WHW.T) 24038.03515625
bpp_loss 1.8833708763122559
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_k proxy err 0.016700949519872665 tr(WHW.T) 15553.287109375
bpp_loss 2.4493567943573
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_o proxy err 0.2746141850948334 tr(WHW.T) 1168.891845703125
bpp_loss 1.3702296614646912
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_up proxy err 0.1902286857366562 tr(WHW.T) 7649.2919921875
bpp_loss 1.3659086908612932
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_gate proxy err 0.06645229458808899 tr(WHW.T) 32811.99609375
bpp_loss 1.6477312360491072
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
19_down proxy err 0.21773754060268402 tr(WHW.T) 6182.73583984375
bpp_loss 1.3792860507965088
I0401 08:45:20.080028 2914618 config.py:54] PyTorch version 2.6.0 available.
W0401 08:45:20.281831 2914618 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:45:20.836050 2914618 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:45:20.839718 2908854 quantize_finetune_llama.py:214] layer 22 gpu 2
I0401 08:45:20.857567 2914618 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:45:22.244493 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 0.9381709098815918s
I0401 08:45:26.056668 2914757 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:45:26.056771 2914757 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:45:26.056814 2914757 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:45:26.450448 2914757 config.py:54] PyTorch version 2.6.0 available.
W0401 08:45:26.684171 2914757 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:45:27.312504 2914757 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:45:27.316507 2908854 quantize_finetune_llama.py:214] layer 23 gpu 3
I0401 08:45:27.333979 2914757 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:45:28.840074 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 1.0233330726623535s
I0401 08:45:32.964809 2914895 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:45:32.964912 2914895 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:45:32.964957 2914895 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:45:33.371834 2914895 config.py:54] PyTorch version 2.6.0 available.
W0401 08:45:33.597687 2914895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:45:34.241802 2914895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:45:34.245899 2908854 quantize_finetune_llama.py:214] layer 24 gpu 0
I0401 08:45:34.262228 2914895 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_v proxy err 0.259687602519989 tr(WHW.T) 330.192138671875
bpp_loss 1.2840264439582825
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_q proxy err 0.03351881355047226 tr(WHW.T) 20737.7421875
bpp_loss 1.8566496968269348
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_k proxy err 0.0178365558385849 tr(WHW.T) 15395.810546875
bpp_loss 2.3596723079681396
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_o proxy err 0.2622854709625244 tr(WHW.T) 1205.1229248046875
bpp_loss 1.3749663829803467
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_up proxy err 0.19179372489452362 tr(WHW.T) 7599.658203125
bpp_loss 1.3670124326433455
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_gate proxy err 0.06828493624925613 tr(WHW.T) 30665.015625
bpp_loss 1.6653850419180733
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
20_down proxy err 0.2245517522096634 tr(WHW.T) 6300.8623046875
bpp_loss 1.3526688132967268
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_v proxy err 0.245949849486351 tr(WHW.T) 362.87310791015625
bpp_loss 1.3019289374351501
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_q proxy err 0.02715909481048584 tr(WHW.T) 25838.111328125
bpp_loss 1.8728085160255432
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_k proxy err 0.014969990588724613 tr(WHW.T) 16787.453125
bpp_loss 2.48268723487854
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_o proxy err 0.26478031277656555 tr(WHW.T) 1266.6689453125
bpp_loss 1.3538976907730103
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_up proxy err 0.19120806455612183 tr(WHW.T) 7772.57080078125
bpp_loss 1.3609800338745117
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_gate proxy err 0.06843861937522888 tr(WHW.T) 31566.3828125
bpp_loss 1.6602936472211565
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
21_down proxy err 0.21981318295001984 tr(WHW.T) 6351.46484375
bpp_loss 1.364738839013236
I0401 08:46:22.693469 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 1.0210185050964355s
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_v proxy err 0.26392415165901184 tr(WHW.T) 346.0789489746094
bpp_loss 1.3318982124328613
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_q proxy err 0.032084450125694275 tr(WHW.T) 20319.60546875
bpp_loss 1.8468405604362488
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_k proxy err 0.016770338639616966 tr(WHW.T) 14724.09765625
bpp_loss 2.433996796607971
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_o proxy err 0.2909959852695465 tr(WHW.T) 1221.8309326171875
bpp_loss 1.3469216227531433
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_up proxy err 0.19042466580867767 tr(WHW.T) 7547.25537109375
bpp_loss 1.3809003148760115
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_gate proxy err 0.06831969320774078 tr(WHW.T) 29534.099609375
bpp_loss 1.7005020550319128
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
22_down proxy err 0.21827688813209534 tr(WHW.T) 6529.4912109375
bpp_loss 1.3592377049582345
I0401 08:46:26.756640 2915482 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:46:26.756749 2915482 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:46:26.756792 2915482 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:46:27.145822 2915482 config.py:54] PyTorch version 2.6.0 available.
W0401 08:46:27.362461 2915482 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:46:27.976331 2915482 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:46:27.980455 2908854 quantize_finetune_llama.py:214] layer 25 gpu 1
I0401 08:46:27.999165 2915482 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:46:29.372715 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 0.9038417339324951s
I0401 08:46:33.255918 2915615 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:46:33.256020 2915615 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:46:33.256063 2915615 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_v proxy err 0.24447831511497498 tr(WHW.T) 397.90704345703125
bpp_loss 1.3708451390266418
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_q proxy err 0.02841969206929207 tr(WHW.T) 22608.931640625
bpp_loss 1.8784158825874329
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_k proxy err 0.015547757036983967 tr(WHW.T) 14857.474609375
bpp_loss 2.5278037786483765
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_o proxy err 0.22548986971378326 tr(WHW.T) 1744.470947265625
bpp_loss 1.3458919525146484
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_up proxy err 0.19340576231479645 tr(WHW.T) 7419.2080078125
bpp_loss 1.3833346366882324
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_gate proxy err 0.07163441181182861 tr(WHW.T) 27291.65234375
bpp_loss 1.7125629016331263
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
23_down proxy err 0.2151479721069336 tr(WHW.T) 6666.9853515625
bpp_loss 1.3629881824765886
I0401 08:46:33.600354 2915615 config.py:54] PyTorch version 2.6.0 available.
W0401 08:46:33.812980 2915615 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:46:34.443701 2915615 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:46:34.447480 2908854 quantize_finetune_llama.py:214] layer 26 gpu 2
I0401 08:46:34.462874 2915615 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:46:35.670383 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.792182207107544s
I0401 08:46:39.499485 2915744 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:46:39.499584 2915744 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:46:39.499628 2915744 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:46:39.842307 2915744 config.py:54] PyTorch version 2.6.0 available.
W0401 08:46:40.063831 2915744 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:46:40.689347 2915744 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:46:40.693350 2908854 quantize_finetune_llama.py:214] layer 27 gpu 3
I0401 08:46:40.709258 2915744 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:46:42.132282 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.9586114883422852s
I0401 08:46:46.233854 2915895 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:46:46.233947 2915895 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:46:46.233991 2915895 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:46:46.584384 2915895 config.py:54] PyTorch version 2.6.0 available.
W0401 08:46:46.800583 2915895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:46:47.431695 2915895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:46:47.435662 2908854 quantize_finetune_llama.py:214] layer 28 gpu 0
I0401 08:46:47.452413 2915895 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_v proxy err 0.22547924518585205 tr(WHW.T) 467.2783508300781
bpp_loss 1.4348514080047607
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_q proxy err 0.03000393882393837 tr(WHW.T) 22436.099609375
bpp_loss 1.8196777701377869
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_k proxy err 0.018935536965727806 tr(WHW.T) 14183.4345703125
bpp_loss 2.2438695430755615
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_o proxy err 0.2501382827758789 tr(WHW.T) 1589.4920654296875
bpp_loss 1.3725164532661438
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_up proxy err 0.19896304607391357 tr(WHW.T) 7311.1435546875
bpp_loss 1.3753322873796736
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_gate proxy err 0.07472959160804749 tr(WHW.T) 25877.26171875
bpp_loss 1.7172661508832658
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
24_down proxy err 0.21471230685710907 tr(WHW.T) 6741.93701171875
bpp_loss 1.364959648677281
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_v proxy err 0.19400787353515625 tr(WHW.T) 557.8086547851562
bpp_loss 1.4475684762001038
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_q proxy err 0.027156749740242958 tr(WHW.T) 26112.029296875
bpp_loss 1.7988161444664001
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_k proxy err 0.017379147931933403 tr(WHW.T) 14416.6201171875
bpp_loss 2.313555598258972
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_o proxy err 0.20804725587368011 tr(WHW.T) 1990.481201171875
bpp_loss 1.3721545338630676
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_up proxy err 0.19579339027404785 tr(WHW.T) 7382.19091796875
bpp_loss 1.3909876687186105
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_gate proxy err 0.07338136434555054 tr(WHW.T) 26307.435546875
bpp_loss 1.7272334780011858
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
25_down proxy err 0.22118838131427765 tr(WHW.T) 6615.951171875
bpp_loss 1.3702053342546736
I0401 08:47:36.357666 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 1.005969762802124s
I0401 08:47:40.401649 2916479 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:47:40.401761 2916479 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:47:40.401804 2916479 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_v proxy err 0.23165281116962433 tr(WHW.T) 434.54583740234375
bpp_loss 1.5262813568115234
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_q proxy err 0.03151705116033554 tr(WHW.T) 21403.28125
bpp_loss 1.8023480772972107
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_k proxy err 0.017633117735385895 tr(WHW.T) 15425.5859375
bpp_loss 2.3019882440567017
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_o proxy err 0.17384037375450134 tr(WHW.T) 2388.72412109375
bpp_loss 1.3823695182800293
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_up proxy err 0.1925341635942459 tr(WHW.T) 7645.65625
bpp_loss 1.392822333744594
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_gate proxy err 0.07036592066287994 tr(WHW.T) 28901.4453125
bpp_loss 1.7003782817295618
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
26_down proxy err 0.22014078497886658 tr(WHW.T) 6618.82470703125
bpp_loss 1.3756749629974365
I0401 08:47:40.779847 2916479 config.py:54] PyTorch version 2.6.0 available.
W0401 08:47:40.994240 2916479 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:47:41.604432 2916479 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:47:41.608421 2908854 quantize_finetune_llama.py:214] layer 29 gpu 1
I0401 08:47:41.624552 2916479 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:47:43.037788 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 0.9359109401702881s
I0401 08:47:47.011723 2916615 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:47:47.011832 2916615 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:47:47.011876 2916615 utils.py:162] NumExpr defaulting to 16 threads.
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_v proxy err 0.17300501465797424 tr(WHW.T) 677.69384765625
bpp_loss 1.5490866303443909
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_q proxy err 0.03275570273399353 tr(WHW.T) 21305.96875
bpp_loss 1.7674598097801208
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_k proxy err 0.020955879241228104 tr(WHW.T) 14011.6201171875
bpp_loss 2.201887011528015
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_o proxy err 0.1895848512649536 tr(WHW.T) 2159.9560546875
bpp_loss 1.4278593063354492
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_up proxy err 0.17345255613327026 tr(WHW.T) 8475.5947265625
bpp_loss 1.4206047739301408
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_gate proxy err 0.06401243060827255 tr(WHW.T) 32809.0390625
bpp_loss 1.7012549127851213
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
27_down proxy err 0.22325532138347626 tr(WHW.T) 6543.35791015625
bpp_loss 1.3822981800351823
I0401 08:47:47.343106 2916615 config.py:54] PyTorch version 2.6.0 available.
W0401 08:47:47.553955 2916615 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:47:48.179659 2916615 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:47:48.183327 2908854 quantize_finetune_llama.py:214] layer 30 gpu 2
I0401 08:47:48.206080 2916615 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:47:49.590109 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 0.9597325325012207s
I0401 08:47:53.338646 2916751 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:47:53.338737 2916751 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:47:53.338780 2916751 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:47:53.682123 2916751 config.py:54] PyTorch version 2.6.0 available.
W0401 08:47:53.894542 2916751 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:47:54.566915 2916751 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:47:54.570841 2908854 quantize_finetune_llama.py:214] layer 31 gpu 3
I0401 08:47:54.587511 2916751 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0401 08:47:56.198611 2908854 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 1.145005702972412s
I0401 08:48:00.225402 2916895 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:48:00.225506 2916895 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:48:00.225548 2916895 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:48:00.601507 2916895 config.py:54] PyTorch version 2.6.0 available.
W0401 08:48:00.821579 2916895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0401 08:48:01.491841 2916895 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0401 08:48:01.514098 2916895 data_utils.py:336] using 256 training seqs, 128 validation seqs
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_v proxy err 0.19399234652519226 tr(WHW.T) 601.4844360351562
bpp_loss 1.6146486401557922
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_q proxy err 0.03108927421271801 tr(WHW.T) 23163.888671875
bpp_loss 1.7966501116752625
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_k proxy err 0.01765351928770542 tr(WHW.T) 14994.2119140625
bpp_loss 2.2195886373519897
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_o proxy err 0.15971143543720245 tr(WHW.T) 2511.445556640625
bpp_loss 1.4658377766609192
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_up proxy err 0.15412309765815735 tr(WHW.T) 10246.0703125
bpp_loss 1.4203977584838867
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_gate proxy err 0.06117454171180725 tr(WHW.T) 35920.9609375
bpp_loss 1.671780722481864
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
28_down proxy err 0.20928548276424408 tr(WHW.T) 7210.08740234375
bpp_loss 1.3956524303981237
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_v proxy err 0.14058031141757965 tr(WHW.T) 850.4290161132812
bpp_loss 1.692109227180481
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_q proxy err 0.03804801031947136 tr(WHW.T) 20653.2265625
bpp_loss 1.7647019028663635
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_k proxy err 0.016250276938080788 tr(WHW.T) 16365.796875
bpp_loss 2.4055161476135254
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_o proxy err 0.14752666652202606 tr(WHW.T) 3102.844970703125
bpp_loss 1.4648125171661377
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_up proxy err 0.12921205163002014 tr(WHW.T) 12868.505859375
bpp_loss 1.4573126520429338
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_gate proxy err 0.06012919545173645 tr(WHW.T) 38364.47265625
bpp_loss 1.643756321498326
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
29_down proxy err 0.20189981162548065 tr(WHW.T) 7470.5244140625
bpp_loss 1.4126271179744176
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_v proxy err 0.16776196658611298 tr(WHW.T) 863.060791015625
bpp_loss 1.815965473651886
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_q proxy err 0.035368144512176514 tr(WHW.T) 24050.6328125
bpp_loss 1.6313070058822632
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_k proxy err 0.02479659952223301 tr(WHW.T) 14030.5888671875
bpp_loss 1.8723013401031494
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_o proxy err 0.09967928379774094 tr(WHW.T) 4869.1748046875
bpp_loss 1.538621187210083
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_up proxy err 0.09117444604635239 tr(WHW.T) 21711.1953125
bpp_loss 1.4744977269853865
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_gate proxy err 0.0493306964635849 tr(WHW.T) 51954.453125
bpp_loss 1.6704220090593611
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
30_down proxy err 0.1780519187450409 tr(WHW.T) 8810.1787109375
bpp_loss 1.413187793322972
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_v proxy err 0.08475655317306519 tr(WHW.T) 1808.723876953125
bpp_loss 1.7158427834510803
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_q proxy err 0.027730967849493027 tr(WHW.T) 46175.66015625
bpp_loss 1.7123225927352905
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 64, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_k proxy err 0.020057205110788345 tr(WHW.T) 20467.64453125
bpp_loss 2.119888186454773
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_o proxy err 0.1954129934310913 tr(WHW.T) 2213.58154296875
bpp_loss 1.4982510805130005
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_up proxy err 0.04527565464377403 tr(WHW.T) 69019.4453125
bpp_loss 1.596388612474714
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 896, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_gate proxy err 0.026527920737862587 tr(WHW.T) 144452.5625
bpp_loss 1.8095920426504952
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
weight_block torch.Size([2048, 256, 16])
q_level torch.Size([2048, 1])
l_cdt torch.Size([2048, 7])
31_down proxy err 0.1572192758321762 tr(WHW.T) 9960.1884765625
bpp_loss 1.4352947303227015
I0401 08:49:11.847272 2917684 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:49:11.847427 2917684 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:49:11.847466 2917684 utils.py:162] NumExpr defaulting to 16 threads.
I0401 08:49:12.238627 2917684 config.py:54] PyTorch version 2.6.0 available.
W0401 08:49:12.439950 2917684 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0401 08:49:12.561024 2917684 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:01,  3.72it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:01,  4.44it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  4.78it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  4.79it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:01<00:00,  4.49it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:01<00:00,  5.37it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  6.23it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  5.25it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.48it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.60it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.42it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.64it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.90it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.05it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.28it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.96it/s]
I0401 08:49:16.606741 2917684 hfize_llama.py:153] loaded layer 0
I0401 08:49:17.451022 2917684 hfize_llama.py:153] loaded layer 1
I0401 08:49:18.260045 2917684 hfize_llama.py:153] loaded layer 2
I0401 08:49:19.094976 2917684 hfize_llama.py:153] loaded layer 3
I0401 08:49:19.956608 2917684 hfize_llama.py:153] loaded layer 4
I0401 08:49:20.795345 2917684 hfize_llama.py:153] loaded layer 5
I0401 08:49:21.622953 2917684 hfize_llama.py:153] loaded layer 6
I0401 08:49:22.486733 2917684 hfize_llama.py:153] loaded layer 7
I0401 08:49:23.327086 2917684 hfize_llama.py:153] loaded layer 8
I0401 08:49:24.173241 2917684 hfize_llama.py:153] loaded layer 9
I0401 08:49:24.998546 2917684 hfize_llama.py:153] loaded layer 10
I0401 08:49:25.826540 2917684 hfize_llama.py:153] loaded layer 11
I0401 08:49:26.642828 2917684 hfize_llama.py:153] loaded layer 12
I0401 08:49:27.474319 2917684 hfize_llama.py:153] loaded layer 13
I0401 08:49:28.278215 2917684 hfize_llama.py:153] loaded layer 14
I0401 08:49:29.072696 2917684 hfize_llama.py:153] loaded layer 15
I0401 08:49:29.842069 2917684 hfize_llama.py:153] loaded layer 16
I0401 08:49:30.597425 2917684 hfize_llama.py:153] loaded layer 17
I0401 08:49:31.414196 2917684 hfize_llama.py:153] loaded layer 18
I0401 08:49:32.206374 2917684 hfize_llama.py:153] loaded layer 19
I0401 08:49:33.013223 2917684 hfize_llama.py:153] loaded layer 20
I0401 08:49:33.810072 2917684 hfize_llama.py:153] loaded layer 21
I0401 08:49:34.627150 2917684 hfize_llama.py:153] loaded layer 22
I0401 08:49:35.417388 2917684 hfize_llama.py:153] loaded layer 23
I0401 08:49:36.194632 2917684 hfize_llama.py:153] loaded layer 24
I0401 08:49:36.918076 2917684 hfize_llama.py:153] loaded layer 25
I0401 08:49:37.611290 2917684 hfize_llama.py:153] loaded layer 26
I0401 08:49:38.312970 2917684 hfize_llama.py:153] loaded layer 27
I0401 08:49:39.021492 2917684 hfize_llama.py:153] loaded layer 28
I0401 08:49:39.736628 2917684 hfize_llama.py:153] loaded layer 29
I0401 08:49:40.461051 2917684 hfize_llama.py:153] loaded layer 30
I0401 08:49:41.155411 2917684 hfize_llama.py:153] loaded layer 31
I0401 08:49:41.155544 2917684 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.19s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:04,  1.01it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:02<00:03,  1.07it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:03<00:02,  1.09it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:04<00:01,  1.12it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.13it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.32it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.16it/s]
I0401 08:50:16.666142 2917684 hfize_llama.py:167] successfully loaded hfized model
I0401 08:50:21.541557 2918498 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0401 08:50:21.541703 2918498 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0401 08:50:21.541743 2918498 utils.py:162] NumExpr defaulting to 16 threads.
W0401 08:50:21.967552 2918498 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0401 08:50:22.322850 2918498 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.12s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.12s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.14s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.14s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.07s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.11it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.02s/it]
I0401 08:50:29.579633 2918498 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 12.872599601745605:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 12.872599601745605:   1%|          | 1/141 [00:01<04:18,  1.85s/it]avg_loss = 12.435531616210938:   1%|          | 1/141 [00:03<04:18,  1.85s/it]avg_loss = 12.435531616210938:   1%|▏         | 2/141 [00:03<03:42,  1.60s/it]avg_loss = 12.787950197855631:   1%|▏         | 2/141 [00:04<03:42,  1.60s/it]avg_loss = 12.787950197855631:   2%|▏         | 3/141 [00:04<03:30,  1.52s/it]avg_loss = 12.739522218704224:   2%|▏         | 3/141 [00:06<03:30,  1.52s/it]avg_loss = 12.739522218704224:   3%|▎         | 4/141 [00:06<03:24,  1.49s/it]avg_loss = 12.801981925964355:   3%|▎         | 4/141 [00:07<03:24,  1.49s/it]avg_loss = 12.801981925964355:   4%|▎         | 5/141 [00:07<03:19,  1.47s/it]avg_loss = 12.63852071762085:   4%|▎         | 5/141 [00:09<03:19,  1.47s/it] avg_loss = 12.63852071762085:   4%|▍         | 6/141 [00:09<03:17,  1.46s/it]avg_loss = 12.397008214678083:   4%|▍         | 6/141 [00:10<03:17,  1.46s/it]avg_loss = 12.397008214678083:   5%|▍         | 7/141 [00:10<03:15,  1.46s/it]avg_loss = 12.351932287216187:   5%|▍         | 7/141 [00:11<03:15,  1.46s/it]avg_loss = 12.351932287216187:   6%|▌         | 8/141 [00:11<03:13,  1.45s/it]avg_loss = 12.321130646599663:   6%|▌         | 8/141 [00:13<03:13,  1.45s/it]avg_loss = 12.321130646599663:   6%|▋         | 9/141 [00:13<03:11,  1.45s/it]avg_loss = 12.38808765411377:   6%|▋         | 9/141 [00:14<03:11,  1.45s/it] avg_loss = 12.38808765411377:   7%|▋         | 10/141 [00:14<03:10,  1.45s/it]avg_loss = 12.368117765946822:   7%|▋         | 10/141 [00:16<03:10,  1.45s/it]avg_loss = 12.368117765946822:   8%|▊         | 11/141 [00:16<03:09,  1.45s/it]avg_loss = 12.30874482790629:   8%|▊         | 11/141 [00:17<03:09,  1.45s/it] avg_loss = 12.30874482790629:   9%|▊         | 12/141 [00:17<03:07,  1.46s/it]avg_loss = 12.364824881920448:   9%|▊         | 12/141 [00:19<03:07,  1.46s/it]avg_loss = 12.364824881920448:   9%|▉         | 13/141 [00:19<03:06,  1.46s/it]avg_loss = 12.333815438406807:   9%|▉         | 13/141 [00:20<03:06,  1.46s/it]avg_loss = 12.333815438406807:  10%|▉         | 14/141 [00:20<03:05,  1.46s/it]avg_loss = 12.331638209025066:  10%|▉         | 14/141 [00:22<03:05,  1.46s/it]avg_loss = 12.331638209025066:  11%|█         | 15/141 [00:22<03:04,  1.46s/it]avg_loss = 12.327189147472382:  11%|█         | 15/141 [00:23<03:04,  1.46s/it]avg_loss = 12.327189147472382:  11%|█▏        | 16/141 [00:23<03:03,  1.46s/it]avg_loss = 12.304823370540843:  11%|█▏        | 16/141 [00:25<03:03,  1.46s/it]avg_loss = 12.304823370540843:  12%|█▏        | 17/141 [00:25<03:01,  1.47s/it]avg_loss = 12.289392736223009:  12%|█▏        | 17/141 [00:26<03:01,  1.47s/it]avg_loss = 12.289392736223009:  13%|█▎        | 18/141 [00:26<03:00,  1.47s/it]avg_loss = 12.29537582397461:  13%|█▎        | 18/141 [00:28<03:00,  1.47s/it] avg_loss = 12.29537582397461:  13%|█▎        | 19/141 [00:28<02:59,  1.47s/it]avg_loss = 12.298723602294922:  13%|█▎        | 19/141 [00:29<02:59,  1.47s/it]avg_loss = 12.298723602294922:  14%|█▍        | 20/141 [00:29<02:58,  1.47s/it]avg_loss = 12.28061308179583:  14%|█▍        | 20/141 [00:30<02:58,  1.47s/it] avg_loss = 12.28061308179583:  15%|█▍        | 21/141 [00:30<02:57,  1.48s/it]avg_loss = 12.311346574263139:  15%|█▍        | 21/141 [00:32<02:57,  1.48s/it]avg_loss = 12.311346574263139:  16%|█▌        | 22/141 [00:32<02:55,  1.48s/it]avg_loss = 12.285407563914424:  16%|█▌        | 22/141 [00:33<02:55,  1.48s/it]avg_loss = 12.285407563914424:  16%|█▋        | 23/141 [00:33<02:54,  1.48s/it]avg_loss = 12.26815132300059:  16%|█▋        | 23/141 [00:35<02:54,  1.48s/it] avg_loss = 12.26815132300059:  17%|█▋        | 24/141 [00:35<02:53,  1.49s/it]avg_loss = 12.25345157623291:  17%|█▋        | 24/141 [00:36<02:53,  1.49s/it]avg_loss = 12.25345157623291:  18%|█▊        | 25/141 [00:36<02:52,  1.49s/it]avg_loss = 12.265003864581768:  18%|█▊        | 25/141 [00:38<02:52,  1.49s/it]avg_loss = 12.265003864581768:  18%|█▊        | 26/141 [00:38<02:51,  1.49s/it]avg_loss = 12.256781860634133:  18%|█▊        | 26/141 [00:39<02:51,  1.49s/it]avg_loss = 12.256781860634133:  19%|█▉        | 27/141 [00:39<02:50,  1.49s/it]avg_loss = 12.279878446034022:  19%|█▉        | 27/141 [00:41<02:50,  1.49s/it]avg_loss = 12.279878446034022:  20%|█▉        | 28/141 [00:41<02:49,  1.50s/it]avg_loss = 12.264808621899835:  20%|█▉        | 28/141 [00:42<02:49,  1.50s/it]avg_loss = 12.264808621899835:  21%|██        | 29/141 [00:42<02:47,  1.50s/it]avg_loss = 12.253598022460938:  21%|██        | 29/141 [00:44<02:47,  1.50s/it]avg_loss = 12.253598022460938:  21%|██▏       | 30/141 [00:44<02:46,  1.50s/it]avg_loss = 12.257127577258695:  21%|██▏       | 30/141 [00:45<02:46,  1.50s/it]avg_loss = 12.257127577258695:  22%|██▏       | 31/141 [00:45<02:45,  1.50s/it]avg_loss = 12.256912529468536:  22%|██▏       | 31/141 [00:47<02:45,  1.50s/it]avg_loss = 12.256912529468536:  23%|██▎       | 32/141 [00:47<02:43,  1.50s/it]avg_loss = 12.237110687024666:  23%|██▎       | 32/141 [00:48<02:43,  1.50s/it]avg_loss = 12.237110687024666:  23%|██▎       | 33/141 [00:48<02:42,  1.51s/it]avg_loss = 12.254343818215762:  23%|██▎       | 33/141 [00:50<02:42,  1.51s/it]avg_loss = 12.254343818215762:  24%|██▍       | 34/141 [00:50<02:41,  1.51s/it]avg_loss = 12.297845186505999:  24%|██▍       | 34/141 [00:52<02:41,  1.51s/it]avg_loss = 12.297845186505999:  25%|██▍       | 35/141 [00:52<02:40,  1.51s/it]avg_loss = 12.275981267293295:  25%|██▍       | 35/141 [00:53<02:40,  1.51s/it]avg_loss = 12.275981267293295:  26%|██▌       | 36/141 [00:53<02:38,  1.51s/it]avg_loss = 12.254518818210911:  26%|██▌       | 36/141 [00:55<02:38,  1.51s/it]avg_loss = 12.254518818210911:  26%|██▌       | 37/141 [00:55<02:37,  1.51s/it]avg_loss = 12.227368379894056:  26%|██▌       | 37/141 [00:56<02:37,  1.51s/it]avg_loss = 12.227368379894056:  27%|██▋       | 38/141 [00:56<02:35,  1.51s/it]avg_loss = 12.19231656881479:  27%|██▋       | 38/141 [00:58<02:35,  1.51s/it] avg_loss = 12.19231656881479:  28%|██▊       | 39/141 [00:58<02:34,  1.51s/it]avg_loss = 12.182196950912475:  28%|██▊       | 39/141 [00:59<02:34,  1.51s/it]avg_loss = 12.182196950912475:  28%|██▊       | 40/141 [00:59<02:32,  1.51s/it]avg_loss = 12.184649141823373:  28%|██▊       | 40/141 [01:01<02:32,  1.51s/it]avg_loss = 12.184649141823373:  29%|██▉       | 41/141 [01:01<02:31,  1.52s/it]avg_loss = 12.212591330210367:  29%|██▉       | 41/141 [01:02<02:31,  1.52s/it]avg_loss = 12.212591330210367:  30%|██▉       | 42/141 [01:02<02:30,  1.52s/it]avg_loss = 12.231369062911632:  30%|██▉       | 42/141 [01:04<02:30,  1.52s/it]avg_loss = 12.231369062911632:  30%|███       | 43/141 [01:04<02:28,  1.52s/it]avg_loss = 12.248824748125942:  30%|███       | 43/141 [01:05<02:28,  1.52s/it]avg_loss = 12.248824748125942:  31%|███       | 44/141 [01:05<02:27,  1.52s/it]avg_loss = 12.252095773484971:  31%|███       | 44/141 [01:07<02:27,  1.52s/it]avg_loss = 12.252095773484971:  32%|███▏      | 45/141 [01:07<02:26,  1.52s/it]avg_loss = 12.25831645468007:  32%|███▏      | 45/141 [01:08<02:26,  1.52s/it] avg_loss = 12.25831645468007:  33%|███▎      | 46/141 [01:08<02:24,  1.52s/it]avg_loss = 12.246159492655003:  33%|███▎      | 46/141 [01:10<02:24,  1.52s/it]avg_loss = 12.246159492655003:  33%|███▎      | 47/141 [01:10<02:23,  1.52s/it]avg_loss = 12.23775957028071:  33%|███▎      | 47/141 [01:11<02:23,  1.52s/it] avg_loss = 12.23775957028071:  34%|███▍      | 48/141 [01:11<02:21,  1.52s/it]avg_loss = 12.228047390373385:  34%|███▍      | 48/141 [01:13<02:21,  1.52s/it]avg_loss = 12.228047390373385:  35%|███▍      | 49/141 [01:13<02:20,  1.52s/it]avg_loss = 12.225290279388428:  35%|███▍      | 49/141 [01:14<02:20,  1.52s/it]avg_loss = 12.225290279388428:  35%|███▌      | 50/141 [01:14<02:18,  1.53s/it]avg_loss = 12.229843064850451:  35%|███▌      | 50/141 [01:16<02:18,  1.53s/it]avg_loss = 12.229843064850451:  36%|███▌      | 51/141 [01:16<02:17,  1.53s/it]avg_loss = 12.22960035617535:  36%|███▌      | 51/141 [01:17<02:17,  1.53s/it] avg_loss = 12.22960035617535:  37%|███▋      | 52/141 [01:17<02:16,  1.53s/it]avg_loss = 12.2317472673812:  37%|███▋      | 52/141 [01:19<02:16,  1.53s/it] avg_loss = 12.2317472673812:  38%|███▊      | 53/141 [01:19<02:14,  1.53s/it]avg_loss = 12.236959828270805:  38%|███▊      | 53/141 [01:20<02:14,  1.53s/it]avg_loss = 12.236959828270805:  38%|███▊      | 54/141 [01:20<02:13,  1.53s/it]avg_loss = 12.229938420382412:  38%|███▊      | 54/141 [01:22<02:13,  1.53s/it]avg_loss = 12.229938420382412:  39%|███▉      | 55/141 [01:22<02:11,  1.53s/it]avg_loss = 12.239716683115278:  39%|███▉      | 55/141 [01:24<02:11,  1.53s/it]avg_loss = 12.239716683115278:  40%|███▉      | 56/141 [01:24<02:10,  1.53s/it]avg_loss = 12.23353151689496:  40%|███▉      | 56/141 [01:25<02:10,  1.53s/it] avg_loss = 12.23353151689496:  40%|████      | 57/141 [01:25<02:08,  1.53s/it]avg_loss = 12.249909565366547:  40%|████      | 57/141 [01:27<02:08,  1.53s/it]avg_loss = 12.249909565366547:  41%|████      | 58/141 [01:27<02:07,  1.53s/it]avg_loss = 12.25353110038628:  41%|████      | 58/141 [01:28<02:07,  1.53s/it] avg_loss = 12.25353110038628:  42%|████▏     | 59/141 [01:28<02:05,  1.53s/it]avg_loss = 12.250544627507528:  42%|████▏     | 59/141 [01:30<02:05,  1.53s/it]avg_loss = 12.250544627507528:  43%|████▎     | 60/141 [01:30<02:04,  1.54s/it]avg_loss = 12.251991506482733:  43%|████▎     | 60/141 [01:31<02:04,  1.54s/it]avg_loss = 12.251991506482733:  43%|████▎     | 61/141 [01:31<02:02,  1.53s/it]avg_loss = 12.272506806158251:  43%|████▎     | 61/141 [01:33<02:02,  1.53s/it]avg_loss = 12.272506806158251:  44%|████▍     | 62/141 [01:33<02:01,  1.53s/it]avg_loss = 12.27372634221637:  44%|████▍     | 62/141 [01:34<02:01,  1.53s/it] avg_loss = 12.27372634221637:  45%|████▍     | 63/141 [01:34<01:59,  1.53s/it]avg_loss = 12.277198269963264:  45%|████▍     | 63/141 [01:36<01:59,  1.53s/it]avg_loss = 12.277198269963264:  45%|████▌     | 64/141 [01:36<01:58,  1.54s/it]avg_loss = 12.277460802518405:  45%|████▌     | 64/141 [01:37<01:58,  1.54s/it]avg_loss = 12.277460802518405:  46%|████▌     | 65/141 [01:37<01:56,  1.53s/it]avg_loss = 12.282305789716316:  46%|████▌     | 65/141 [01:39<01:56,  1.53s/it]avg_loss = 12.282305789716316:  47%|████▋     | 66/141 [01:39<01:55,  1.54s/it]avg_loss = 12.27320416293927:  47%|████▋     | 66/141 [01:40<01:55,  1.54s/it] avg_loss = 12.27320416293927:  48%|████▊     | 67/141 [01:40<01:53,  1.54s/it]avg_loss = 12.27794983807732:  48%|████▊     | 67/141 [01:42<01:53,  1.54s/it]avg_loss = 12.27794983807732:  48%|████▊     | 68/141 [01:42<01:52,  1.54s/it]avg_loss = 12.273994653121285:  48%|████▊     | 68/141 [01:44<01:52,  1.54s/it]avg_loss = 12.273994653121285:  49%|████▉     | 69/141 [01:44<01:51,  1.54s/it]avg_loss = 12.277451174599785:  49%|████▉     | 69/141 [01:45<01:51,  1.54s/it]avg_loss = 12.277451174599785:  50%|████▉     | 70/141 [01:45<01:49,  1.54s/it]avg_loss = 12.28948063917563:  50%|████▉     | 70/141 [01:47<01:49,  1.54s/it] avg_loss = 12.28948063917563:  50%|█████     | 71/141 [01:47<01:47,  1.54s/it]avg_loss = 12.29401179154714:  50%|█████     | 71/141 [01:48<01:47,  1.54s/it]avg_loss = 12.29401179154714:  51%|█████     | 72/141 [01:48<01:46,  1.54s/it]avg_loss = 12.286930815814292:  51%|█████     | 72/141 [01:50<01:46,  1.54s/it]avg_loss = 12.286930815814292:  52%|█████▏    | 73/141 [01:50<01:44,  1.54s/it]avg_loss = 12.286021039292619:  52%|█████▏    | 73/141 [01:51<01:44,  1.54s/it]avg_loss = 12.286021039292619:  52%|█████▏    | 74/141 [01:51<01:43,  1.55s/it]avg_loss = 12.290959714253743:  52%|█████▏    | 74/141 [01:53<01:43,  1.55s/it]avg_loss = 12.290959714253743:  53%|█████▎    | 75/141 [01:53<01:42,  1.55s/it]avg_loss = 12.292773861634103:  53%|█████▎    | 75/141 [01:54<01:42,  1.55s/it]avg_loss = 12.292773861634103:  54%|█████▍    | 76/141 [01:54<01:40,  1.55s/it]avg_loss = 12.291148099032315:  54%|█████▍    | 76/141 [01:56<01:40,  1.55s/it]avg_loss = 12.291148099032315:  55%|█████▍    | 77/141 [01:56<01:38,  1.55s/it]avg_loss = 12.293891380994747:  55%|█████▍    | 77/141 [01:57<01:38,  1.55s/it]avg_loss = 12.293891380994747:  55%|█████▌    | 78/141 [01:57<01:37,  1.54s/it]avg_loss = 12.293835072577755:  55%|█████▌    | 78/141 [01:59<01:37,  1.54s/it]avg_loss = 12.293835072577755:  56%|█████▌    | 79/141 [01:59<01:35,  1.54s/it]avg_loss = 12.274923121929168:  56%|█████▌    | 79/141 [02:01<01:35,  1.54s/it]avg_loss = 12.274923121929168:  57%|█████▋    | 80/141 [02:01<01:34,  1.55s/it]avg_loss = 12.27934087352988:  57%|█████▋    | 80/141 [02:02<01:34,  1.55s/it] avg_loss = 12.27934087352988:  57%|█████▋    | 81/141 [02:02<01:32,  1.54s/it]avg_loss = 12.266639093073403:  57%|█████▋    | 81/141 [02:04<01:32,  1.54s/it]avg_loss = 12.266639093073403:  58%|█████▊    | 82/141 [02:04<01:31,  1.54s/it]avg_loss = 12.2671167764319:  58%|█████▊    | 82/141 [02:05<01:31,  1.54s/it]  avg_loss = 12.2671167764319:  59%|█████▉    | 83/141 [02:05<01:29,  1.54s/it]avg_loss = 12.266898291451591:  59%|█████▉    | 83/141 [02:07<01:29,  1.54s/it]avg_loss = 12.266898291451591:  60%|█████▉    | 84/141 [02:07<01:28,  1.55s/it]avg_loss = 12.25798179402071:  60%|█████▉    | 84/141 [02:08<01:28,  1.55s/it] avg_loss = 12.25798179402071:  60%|██████    | 85/141 [02:08<01:26,  1.55s/it]avg_loss = 12.255811269893202:  60%|██████    | 85/141 [02:10<01:26,  1.55s/it]avg_loss = 12.255811269893202:  61%|██████    | 86/141 [02:10<01:25,  1.55s/it]avg_loss = 12.259247670228454:  61%|██████    | 86/141 [02:11<01:25,  1.55s/it]avg_loss = 12.259247670228454:  62%|██████▏   | 87/141 [02:11<01:23,  1.55s/it]avg_loss = 12.257825992324136:  62%|██████▏   | 87/141 [02:13<01:23,  1.55s/it]avg_loss = 12.257825992324136:  62%|██████▏   | 88/141 [02:13<01:22,  1.55s/it]avg_loss = 12.255026335126898:  62%|██████▏   | 88/141 [02:14<01:22,  1.55s/it]avg_loss = 12.255026335126898:  63%|██████▎   | 89/141 [02:14<01:20,  1.55s/it]avg_loss = 12.263267919752334:  63%|██████▎   | 89/141 [02:16<01:20,  1.55s/it]avg_loss = 12.263267919752334:  64%|██████▍   | 90/141 [02:16<01:19,  1.55s/it]avg_loss = 12.2607999424358:  64%|██████▍   | 90/141 [02:18<01:19,  1.55s/it]  avg_loss = 12.2607999424358:  65%|██████▍   | 91/141 [02:18<01:17,  1.55s/it]avg_loss = 12.259491505830184:  65%|██████▍   | 91/141 [02:19<01:17,  1.55s/it]avg_loss = 12.259491505830184:  65%|██████▌   | 92/141 [02:19<01:16,  1.55s/it]avg_loss = 12.25527298835016:  65%|██████▌   | 92/141 [02:21<01:16,  1.55s/it] avg_loss = 12.25527298835016:  66%|██████▌   | 93/141 [02:21<01:14,  1.56s/it]avg_loss = 12.253183283704393:  66%|██████▌   | 93/141 [02:22<01:14,  1.56s/it]avg_loss = 12.253183283704393:  67%|██████▋   | 94/141 [02:22<01:13,  1.56s/it]avg_loss = 12.25726590407522:  67%|██████▋   | 94/141 [02:24<01:13,  1.56s/it] avg_loss = 12.25726590407522:  67%|██████▋   | 95/141 [02:24<01:11,  1.56s/it]avg_loss = 12.251271615425745:  67%|██████▋   | 95/141 [02:25<01:11,  1.56s/it]avg_loss = 12.251271615425745:  68%|██████▊   | 96/141 [02:25<01:09,  1.56s/it]avg_loss = 12.254210501602016:  68%|██████▊   | 96/141 [02:27<01:09,  1.56s/it]avg_loss = 12.254210501602016:  69%|██████▉   | 97/141 [02:27<01:08,  1.55s/it]avg_loss = 12.254323784185916:  69%|██████▉   | 97/141 [02:28<01:08,  1.55s/it]avg_loss = 12.254323784185916:  70%|██████▉   | 98/141 [02:28<01:06,  1.55s/it]avg_loss = 12.254346809001884:  70%|██████▉   | 98/141 [02:30<01:06,  1.55s/it]avg_loss = 12.254346809001884:  70%|███████   | 99/141 [02:30<01:05,  1.55s/it]avg_loss = 12.25361258506775:  70%|███████   | 99/141 [02:32<01:05,  1.55s/it] avg_loss = 12.25361258506775:  71%|███████   | 100/141 [02:32<01:03,  1.55s/it]avg_loss = 12.254178490969213:  71%|███████   | 100/141 [02:33<01:03,  1.55s/it]avg_loss = 12.254178490969213:  72%|███████▏  | 101/141 [02:33<01:02,  1.56s/it]avg_loss = 12.259503289765002:  72%|███████▏  | 101/141 [02:35<01:02,  1.56s/it]avg_loss = 12.259503289765002:  72%|███████▏  | 102/141 [02:35<01:00,  1.55s/it]avg_loss = 12.250696182250977:  72%|███████▏  | 102/141 [02:36<01:00,  1.55s/it]avg_loss = 12.250696182250977:  73%|███████▎  | 103/141 [02:36<00:59,  1.56s/it]avg_loss = 12.251027666605436:  73%|███████▎  | 103/141 [02:38<00:59,  1.56s/it]avg_loss = 12.251027666605436:  74%|███████▍  | 104/141 [02:38<00:57,  1.56s/it]avg_loss = 12.247947420392718:  74%|███████▍  | 104/141 [02:39<00:57,  1.56s/it]avg_loss = 12.247947420392718:  74%|███████▍  | 105/141 [02:39<00:56,  1.56s/it]avg_loss = 12.25215106640222:  74%|███████▍  | 105/141 [02:41<00:56,  1.56s/it] avg_loss = 12.25215106640222:  75%|███████▌  | 106/141 [02:41<00:54,  1.56s/it]avg_loss = 12.261726584389946:  75%|███████▌  | 106/141 [02:42<00:54,  1.56s/it]avg_loss = 12.261726584389946:  76%|███████▌  | 107/141 [02:42<00:52,  1.56s/it]avg_loss = 12.268657587192676:  76%|███████▌  | 107/141 [02:44<00:52,  1.56s/it]avg_loss = 12.268657587192676:  77%|███████▋  | 108/141 [02:44<00:51,  1.56s/it]avg_loss = 12.273533611122621:  77%|███████▋  | 108/141 [02:46<00:51,  1.56s/it]avg_loss = 12.273533611122621:  77%|███████▋  | 109/141 [02:46<00:49,  1.56s/it]avg_loss = 12.268489291451194:  77%|███████▋  | 109/141 [02:47<00:49,  1.56s/it]avg_loss = 12.268489291451194:  78%|███████▊  | 110/141 [02:47<00:48,  1.56s/it]avg_loss = 12.283866624574404:  78%|███████▊  | 110/141 [02:49<00:48,  1.56s/it]avg_loss = 12.283866624574404:  79%|███████▊  | 111/141 [02:49<00:46,  1.56s/it]avg_loss = 12.276706423078265:  79%|███████▊  | 111/141 [02:50<00:46,  1.56s/it]avg_loss = 12.276706423078265:  79%|███████▉  | 112/141 [02:50<00:45,  1.56s/it]avg_loss = 12.282298476295134:  79%|███████▉  | 112/141 [02:52<00:45,  1.56s/it]avg_loss = 12.282298476295134:  80%|████████  | 113/141 [02:52<00:43,  1.56s/it]avg_loss = 12.2881726967661:  80%|████████  | 113/141 [02:53<00:43,  1.56s/it]  avg_loss = 12.2881726967661:  81%|████████  | 114/141 [02:53<00:41,  1.55s/it]avg_loss = 12.29451499607252:  81%|████████  | 114/141 [02:55<00:41,  1.55s/it]avg_loss = 12.29451499607252:  82%|████████▏ | 115/141 [02:55<00:40,  1.55s/it]avg_loss = 12.298016260410177:  82%|████████▏ | 115/141 [02:56<00:40,  1.55s/it]avg_loss = 12.298016260410177:  82%|████████▏ | 116/141 [02:56<00:38,  1.55s/it]avg_loss = 12.297304471333822:  82%|████████▏ | 116/141 [02:58<00:38,  1.55s/it]avg_loss = 12.297304471333822:  83%|████████▎ | 117/141 [02:58<00:37,  1.55s/it]avg_loss = 12.294296426288152:  83%|████████▎ | 117/141 [03:00<00:37,  1.55s/it]avg_loss = 12.294296426288152:  84%|████████▎ | 118/141 [03:00<00:35,  1.55s/it]avg_loss = 12.291759186432142:  84%|████████▎ | 118/141 [03:01<00:35,  1.55s/it]avg_loss = 12.291759186432142:  84%|████████▍ | 119/141 [03:01<00:34,  1.55s/it]avg_loss = 12.295407589276632:  84%|████████▍ | 119/141 [03:03<00:34,  1.55s/it]avg_loss = 12.295407589276632:  85%|████████▌ | 120/141 [03:03<00:32,  1.55s/it]avg_loss = 12.301679185599335:  85%|████████▌ | 120/141 [03:04<00:32,  1.55s/it]avg_loss = 12.301679185599335:  86%|████████▌ | 121/141 [03:04<00:31,  1.55s/it]avg_loss = 12.3065028815973:  86%|████████▌ | 121/141 [03:06<00:31,  1.55s/it]  avg_loss = 12.3065028815973:  87%|████████▋ | 122/141 [03:06<00:29,  1.56s/it]avg_loss = 12.301493768769552:  87%|████████▋ | 122/141 [03:07<00:29,  1.56s/it]avg_loss = 12.301493768769552:  87%|████████▋ | 123/141 [03:07<00:28,  1.56s/it]avg_loss = 12.301342502717048:  87%|████████▋ | 123/141 [03:09<00:28,  1.56s/it]avg_loss = 12.301342502717048:  88%|████████▊ | 124/141 [03:09<00:26,  1.55s/it]avg_loss = 12.300555305480957:  88%|████████▊ | 124/141 [03:10<00:26,  1.55s/it]avg_loss = 12.300555305480957:  89%|████████▊ | 125/141 [03:10<00:24,  1.55s/it]avg_loss = 12.298365714058043:  89%|████████▊ | 125/141 [03:12<00:24,  1.55s/it]avg_loss = 12.298365714058043:  89%|████████▉ | 126/141 [03:12<00:23,  1.55s/it]avg_loss = 12.30100266764483:  89%|████████▉ | 126/141 [03:14<00:23,  1.55s/it] avg_loss = 12.30100266764483:  90%|█████████ | 127/141 [03:14<00:21,  1.56s/it]avg_loss = 12.300997838377953:  90%|█████████ | 127/141 [03:15<00:21,  1.56s/it]avg_loss = 12.300997838377953:  91%|█████████ | 128/141 [03:15<00:20,  1.56s/it]avg_loss = 12.303980346797973:  91%|█████████ | 128/141 [03:17<00:20,  1.56s/it]avg_loss = 12.303980346797973:  91%|█████████▏| 129/141 [03:17<00:18,  1.56s/it]avg_loss = 12.306652164459228:  91%|█████████▏| 129/141 [03:18<00:18,  1.56s/it]avg_loss = 12.306652164459228:  92%|█████████▏| 130/141 [03:18<00:17,  1.56s/it]avg_loss = 12.30675125850066:  92%|█████████▏| 130/141 [03:20<00:17,  1.56s/it] avg_loss = 12.30675125850066:  93%|█████████▎| 131/141 [03:20<00:15,  1.56s/it]avg_loss = 12.309460762775306:  93%|█████████▎| 131/141 [03:21<00:15,  1.56s/it]avg_loss = 12.309460762775306:  94%|█████████▎| 132/141 [03:21<00:14,  1.56s/it]avg_loss = 12.30141650465198:  94%|█████████▎| 132/141 [03:23<00:14,  1.56s/it] avg_loss = 12.30141650465198:  94%|█████████▍| 133/141 [03:23<00:12,  1.56s/it]avg_loss = 12.298846202110177:  94%|█████████▍| 133/141 [03:24<00:12,  1.56s/it]avg_loss = 12.298846202110177:  95%|█████████▌| 134/141 [03:24<00:10,  1.56s/it]avg_loss = 12.300088289048936:  95%|█████████▌| 134/141 [03:26<00:10,  1.56s/it]avg_loss = 12.300088289048936:  96%|█████████▌| 135/141 [03:26<00:09,  1.56s/it]avg_loss = 12.300117036875557:  96%|█████████▌| 135/141 [03:28<00:09,  1.56s/it]avg_loss = 12.300117036875557:  96%|█████████▋| 136/141 [03:28<00:07,  1.56s/it]avg_loss = 12.298269278811713:  96%|█████████▋| 136/141 [03:29<00:07,  1.56s/it]avg_loss = 12.298269278811713:  97%|█████████▋| 137/141 [03:29<00:06,  1.56s/it]avg_loss = 12.30010079646456:  97%|█████████▋| 137/141 [03:31<00:06,  1.56s/it] avg_loss = 12.30010079646456:  98%|█████████▊| 138/141 [03:31<00:04,  1.56s/it]avg_loss = 12.300249964213199:  98%|█████████▊| 138/141 [03:32<00:04,  1.56s/it]avg_loss = 12.300249964213199:  99%|█████████▊| 139/141 [03:32<00:03,  1.56s/it]avg_loss = 12.30602627481733:  99%|█████████▊| 139/141 [03:34<00:03,  1.56s/it] avg_loss = 12.30602627481733:  99%|█████████▉| 140/141 [03:34<00:01,  1.56s/it]avg_loss = 12.311396524415795:  99%|█████████▉| 140/141 [03:35<00:01,  1.56s/it]avg_loss = 12.311396524415795: 100%|██████████| 141/141 [03:35<00:00,  1.56s/it]avg_loss = 12.311396524415795: 100%|██████████| 141/141 [03:35<00:00,  1.53s/it]
I0401 08:54:29.601004 2918498 eval_ppl.py:107] wikitext2 perplexity: 222214.09375
wikitext2 perplexity: 222214.094
