I0320 08:41:15.983391 1389933 config.py:54] PyTorch version 2.6.0 available.
W0320 08:41:16.271125 1389933 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0320 08:41:17.178775 1389933 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  7.54it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.98it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.33it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.97it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.05it/s]
I0320 08:41:18.128736 1389933 quantize_finetune_llama.py:144] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:14,  2.08it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:00<00:14,  2.08it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:13,  2.09it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:01<00:13,  2.09it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:02<00:12,  2.11it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:02<00:12,  2.11it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:03<00:11,  2.10it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:03<00:11,  2.10it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:04<00:10,  2.10it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:04<00:10,  2.09it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:05<00:10,  2.09it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:05<00:09,  2.10it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:06<00:09,  2.11it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:06<00:08,  2.11it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:07<00:08,  2.11it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:07<00:07,  2.10it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:08<00:07,  2.10it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:08<00:06,  2.10it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:09<00:06,  2.09it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:09<00:05,  2.09it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:10<00:05,  2.09it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:10<00:04,  2.10it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:10<00:04,  2.08it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:11<00:03,  2.08it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:11<00:03,  2.11it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:12<00:02,  2.16it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:12<00:02,  2.16it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:13<00:01,  2.15it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:13<00:01,  2.15it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:14<00:00,  2.13it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:14<00:00,  2.18it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:15<00:00,  2.23it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:15<00:00,  2.12it/s]
I0320 08:41:38.109023 1389933 quantize_finetune_llama.py:179] loaded compression model
I0320 08:41:52.490680 1389933 quantize_finetune_llama.py:183] loaded dataset and devset
I0320 08:41:57.551382 1389933 quantize_finetune_llama.py:203] layer 0 gpu 0
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0320 08:42:55.470223 1389933 quantize_finetune_llama.py:234] computed original embedding for layer 0 in 57.77483081817627s
tensor(0.0192) tensor(-3.6338e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0320 08:43:21.388834 1391229 config.py:54] PyTorch version 2.6.0 available.
W0320 08:43:21.667842 1391229 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0320 08:43:22.543479 1391229 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0320 08:43:22.547487 1389933 quantize_finetune_llama.py:203] layer 1 gpu 1
I0320 08:43:22.560685 1391229 data_utils.py:336] using 256 training seqs, 128 validation seqs
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0320 08:43:39.640116 1391229 finetune.py:45] layer 0_v initial loss 2.8663910356385713e-08
W0320 08:43:39.640346 1391229 warnings.py:109] /workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(orig_dtype==torch.float16))

I0320 08:44:11.323062 1391229 finetune.py:68] layer 0_v @ epoch 0 new loss 7.19363635326431e-09 old loss 2.8663910356385713e-08 BETTER
I0320 08:44:24.378641 1389933 quantize_finetune_llama.py:234] computed original embedding for layer 1 in 61.66535210609436s
I0320 08:44:33.074619 1391912 config.py:54] PyTorch version 2.6.0 available.
W0320 08:44:33.362007 1391912 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0320 08:44:34.274007 1391912 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0320 08:44:34.277725 1389933 quantize_finetune_llama.py:203] layer 2 gpu 2
I0320 08:44:34.290982 1391912 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0320 08:44:44.553163 1391229 finetune.py:68] layer 0_v @ epoch 1 new loss 3.6645093626219705e-09 old loss 7.19363635326431e-09 BETTER
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0320 08:44:52.287563 1391912 finetune.py:45] layer 1_v initial loss 3.3019757665897487e-06
W0320 08:44:52.288034 1391912 warnings.py:109] /workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(orig_dtype==torch.float16))

I0320 08:45:18.022206 1391229 finetune.py:68] layer 0_v @ epoch 2 new loss 2.9306743698498394e-09 old loss 3.6645093626219705e-09 BETTER
I0320 08:45:23.043311 1391912 finetune.py:68] layer 1_v @ epoch 0 new loss 9.642303666623775e-07 old loss 3.3019757665897487e-06 BETTER
I0320 08:45:38.564933 1389933 quantize_finetune_llama.py:234] computed original embedding for layer 2 in 64.10043430328369s
I0320 08:45:47.370451 1392747 config.py:54] PyTorch version 2.6.0 available.
W0320 08:45:47.714982 1392747 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0320 08:45:48.722219 1392747 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0320 08:45:48.726536 1389933 quantize_finetune_llama.py:203] layer 3 gpu 0
I0320 08:45:48.740041 1392747 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0320 08:45:51.912108 1391229 finetune.py:68] layer 0_v @ epoch 3 new loss 2.6414965770271692e-09 old loss 2.9306743698498394e-09 BETTER
I0320 08:45:55.032410 1391912 finetune.py:76] layer 1_v @ epoch 1 new loss 1.165078629128402e-06 old loss 9.642303666623775e-07 WORSE
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0320 08:46:07.119976 1392747 finetune.py:45] layer 2_v initial loss 2.4973653012239083e-07
W0320 08:46:07.120388 1392747 warnings.py:109] /workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(orig_dtype==torch.float16))

I0320 08:46:25.942241 1391229 finetune.py:68] layer 0_v @ epoch 4 new loss 2.476760574410264e-09 old loss 2.6414965770271692e-09 BETTER
