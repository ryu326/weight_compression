I0409 18:09:29.437783 1581899 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 18:09:29.437885 1581899 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 18:09:29.437923 1581899 utils.py:162] NumExpr defaulting to 16 threads.
I0409 18:09:29.754295 1581899 config.py:54] PyTorch version 2.6.0 available.
W0409 18:09:29.951636 1581899 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 18:09:30.571429 1581899 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.12it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  6.89it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.44it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.75it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.92it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.47it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.61it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]
I0409 18:09:32.092103 1581899 quantize_finetune_llama.py:163] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:21,  1.44it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:21,  1.43it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:20,  1.42it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:17,  1.57it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:16,  1.67it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:14,  1.74it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:13,  1.79it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:13,  1.83it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:05<00:12,  1.85it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:05<00:11,  1.88it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:11,  1.89it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:06<00:10,  1.90it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:09,  1.93it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:07<00:09,  1.93it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:08,  1.94it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:08<00:08,  1.95it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:07,  1.96it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:09<00:07,  1.97it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.97it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:10<00:06,  1.97it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:05,  1.95it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:11<00:05,  1.96it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:04,  2.00it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:12<00:03,  2.07it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:13<00:03,  1.88it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:14<00:03,  1.84it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:14<00:02,  1.84it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:15<00:02,  1.92it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:15<00:01,  1.99it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:15<00:00,  2.04it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:16<00:00,  2.06it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  2.10it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.89it/s]
I0409 18:10:02.348756 1581899 quantize_finetune_llama.py:201] loaded compression model
I0409 18:10:22.688380 1581899 quantize_finetune_llama.py:205] loaded dataset and devset
I0409 18:10:24.899204 1581899 quantize_finetune_llama.py:225] layer 0 gpu 0
I0409 18:10:27.250986 1581899 quantize_finetune_llama.py:256] computed original embedding for layer 0 in 2.163832187652588s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0409 18:10:42.115112 1583100 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 18:10:42.115218 1583100 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 18:10:42.115259 1583100 utils.py:162] NumExpr defaulting to 16 threads.
I0409 18:10:42.467341 1583100 config.py:54] PyTorch version 2.6.0 available.
W0409 18:10:42.676705 1583100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 18:10:43.244917 1583100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 18:10:43.248755 1581899 quantize_finetune_llama.py:225] layer 1 gpu 0
I0409 18:10:43.261534 1583100 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.012663488276302814 err 0.7710399031639099 tr(WHW.T) 60.88684844970703
bpp_loss 4.403017997741699
0_q proxy err 0.00015234753664117306 err 43.89051055908203 tr(WHW.T) 288094.65625
bpp_loss 3.383499503135681
0_k proxy err 0.00014897323853801936 err 14.924247741699219 tr(WHW.T) 100180.734375
bpp_loss 3.9246712923049927
0_o proxy err 0.0017117856768891215 err 5.346279144287109 tr(WHW.T) 3123.217529296875
bpp_loss 4.320614576339722
0_up proxy err 0.018107548356056213 err 161.5999298095703 tr(WHW.T) 8924.451171875
bpp_loss 2.9570471899850026
0_gate proxy err 0.01046028546988964 err 165.04934692382812 tr(WHW.T) 15778.666015625
bpp_loss 3.066056524004255
0_down proxy err 0.012809163890779018 err 138.57215881347656 tr(WHW.T) 10818.205078125
bpp_loss 2.9505288941519603
I0409 18:11:20.091247 1581899 quantize_finetune_llama.py:256] computed original embedding for layer 1 in 0.8471932411193848s
I0409 18:11:24.123086 1583951 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 18:11:24.123203 1583951 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 18:11:24.123249 1583951 utils.py:162] NumExpr defaulting to 16 threads.
I0409 18:11:24.491365 1583951 config.py:54] PyTorch version 2.6.0 available.
W0409 18:11:24.690509 1583951 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 18:11:25.237366 1583951 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 18:11:25.241205 1581899 quantize_finetune_llama.py:225] layer 2 gpu 0
I0409 18:11:25.264027 1583951 data_utils.py:336] using 256 training seqs, 128 validation seqs
1_v proxy err 0.007458393462002277 err 0.8134941458702087 tr(WHW.T) 109.07096099853516
bpp_loss 5.229259729385376
1_q proxy err 0.00020187514019198716 err 29.236865997314453 tr(WHW.T) 144826.484375
bpp_loss 3.6344006061553955
1_k proxy err 0.00012200995115563273 err 9.21651554107666 tr(WHW.T) 75539.046875
bpp_loss 4.297932863235474
1_o proxy err 0.0027164211496710777 err 5.388923645019531 tr(WHW.T) 1983.8321533203125
bpp_loss 4.700344562530518
1_up proxy err 0.019899675622582436 err 163.7906494140625 tr(WHW.T) 8230.8203125
bpp_loss 2.9713310514177596
1_gate proxy err 0.011976547539234161 err 167.10116577148438 tr(WHW.T) 13952.365234375
bpp_loss 3.077267646789551
1_down proxy err 0.0011802114313468337 err 16.497032165527344 tr(WHW.T) 13978.03125
bpp_loss 2.966089589255197
I0409 18:12:02.568411 1581899 quantize_finetune_llama.py:256] computed original embedding for layer 2 in 0.9700541496276855s
I0409 18:12:06.671403 1584956 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 18:12:06.671622 1584956 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 18:12:06.671747 1584956 utils.py:162] NumExpr defaulting to 16 threads.
I0409 18:12:07.084908 1584956 config.py:54] PyTorch version 2.6.0 available.
W0409 18:12:07.279566 1584956 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 18:12:07.845394 1584956 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 18:12:07.849185 1581899 quantize_finetune_llama.py:225] layer 3 gpu 0
I0409 18:12:07.865288 1584956 data_utils.py:336] using 256 training seqs, 128 validation seqs
