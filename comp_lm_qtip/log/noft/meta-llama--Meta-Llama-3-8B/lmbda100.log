I0408 02:47:43.349110 298052 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:47:43.349208 298052 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:47:43.349246 298052 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:47:43.666631 298052 config.py:54] PyTorch version 2.6.0 available.
W0408 02:47:43.853703 298052 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:47:44.463916 298052 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.26it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.72it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.94it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.70it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.85it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.00it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.89it/s]
I0408 02:47:45.920006 298052 quantize_finetune_llama.py:157] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:00<00:00, 17041.36it/s]
I0408 02:47:49.545327 298052 quantize_finetune_llama.py:195] loaded compression model
I0408 02:48:07.296828 298052 quantize_finetune_llama.py:199] loaded dataset and devset
I0408 02:48:12.803249 298052 quantize_finetune_llama.py:219] layer 0 gpu 0
I0408 02:48:14.721498 298052 quantize_finetune_llama.py:250] computed original embedding for layer 0 in 1.7705721855163574s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0408 02:48:34.270750 298690 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:48:34.270853 298690 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:48:34.270891 298690 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:48:34.591886 298690 config.py:54] PyTorch version 2.6.0 available.
W0408 02:48:34.780430 298690 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:48:35.347969 298690 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:48:35.351795 298052 quantize_finetune_llama.py:219] layer 1 gpu 1
I0408 02:48:35.365110 298690 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:48:39.592146 298052 quantize_finetune_llama.py:250] computed original embedding for layer 1 in 4.069340467453003s
I0408 02:48:43.221615 298858 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:48:43.221730 298858 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:48:43.221772 298858 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:48:43.579864 298858 config.py:54] PyTorch version 2.6.0 available.
W0408 02:48:43.788975 298858 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:48:44.431974 298858 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:48:44.436052 298052 quantize_finetune_llama.py:219] layer 2 gpu 2
I0408 02:48:44.450932 298858 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:48:48.295125 298052 quantize_finetune_llama.py:250] computed original embedding for layer 2 in 3.6875476837158203s
I0408 02:48:52.216075 299025 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:48:52.216183 299025 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:48:52.216224 299025 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:48:52.613993 299025 config.py:54] PyTorch version 2.6.0 available.
W0408 02:48:52.840494 299025 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:48:53.490015 299025 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:48:53.494347 298052 quantize_finetune_llama.py:219] layer 3 gpu 3
I0408 02:48:53.509971 299025 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:48:57.883171 298052 quantize_finetune_llama.py:250] computed original embedding for layer 3 in 4.204302549362183s
I0408 02:49:01.799715 299195 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:49:01.799933 299195 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:49:01.800016 299195 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:49:02.219315 299195 config.py:54] PyTorch version 2.6.0 available.
W0408 02:49:02.454855 299195 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:49:03.116242 299195 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:49:03.120470 298052 quantize_finetune_llama.py:219] layer 4 gpu 0
I0408 02:49:03.148509 299195 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.06292521953582764 err 3.8313183784484863 tr(WHW.T) 60.88684844970703
bpp_loss 3.2370285987854004
0_q proxy err 0.00010959242354147136 err 31.5729923248291 tr(WHW.T) 288094.65625
bpp_loss 4.030368447303772
0_k proxy err 9.983196650864556e-05 err 10.001239776611328 tr(WHW.T) 100180.734375
bpp_loss 4.642569065093994
0_o proxy err 0.005433015991002321 err 16.968490600585938 tr(WHW.T) 3123.217529296875
bpp_loss 3.308503270149231
0_up proxy err 0.007260303944349289 err 64.79422760009766 tr(WHW.T) 8924.451171875
bpp_loss 3.6066859449659074
0_gate proxy err 0.0042414856143295765 err 66.92498779296875 tr(WHW.T) 15778.666015625
bpp_loss 3.7081523963383267
0_down proxy err 0.00590786337852478 err 63.912479400634766 tr(WHW.T) 10818.205078125
bpp_loss 3.5998972484043668
1_v proxy err 0.0386628732085228 err 4.216996669769287 tr(WHW.T) 109.07096099853516
bpp_loss 3.3468215465545654
1_q proxy err 0.00018466476467438042 err 26.744348526000977 tr(WHW.T) 144826.484375
bpp_loss 4.268676280975342
1_k proxy err 0.00010360204760218039 err 7.825999736785889 tr(WHW.T) 75539.046875
bpp_loss 4.983175754547119
1_o proxy err 0.008674535900354385 err 17.208824157714844 tr(WHW.T) 1983.8321533203125
bpp_loss 3.390756130218506
1_up proxy err 0.007898249663412571 err 65.00907135009766 tr(WHW.T) 8230.8203125
bpp_loss 3.6220274652753557
1_gate proxy err 0.004808362573385239 err 67.08802795410156 tr(WHW.T) 13952.365234375
bpp_loss 3.7258975165230885
1_down proxy err 0.003645973978564143 err 50.963539123535156 tr(WHW.T) 13978.03125
bpp_loss 3.617948532104492
I0408 02:49:19.629621 298052 quantize_finetune_llama.py:250] computed original embedding for layer 4 in 0.8638758659362793s
I0408 02:49:23.740136 299514 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:49:23.740247 299514 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:49:23.740288 299514 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:49:24.139117 299514 config.py:54] PyTorch version 2.6.0 available.
W0408 02:49:24.363885 299514 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:49:25.005966 299514 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:49:25.010267 298052 quantize_finetune_llama.py:219] layer 5 gpu 1
I0408 02:49:25.025657 299514 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.026301991194486618 err 4.10204553604126 tr(WHW.T) 155.95950317382812
bpp_loss 3.244817018508911
2_q proxy err 0.000551645818632096 err 22.879596710205078 tr(WHW.T) 41475.15625
bpp_loss 4.24832010269165
2_k proxy err 0.0002991344372276217 err 6.7647857666015625 tr(WHW.T) 22614.533203125
bpp_loss 5.134323596954346
2_o proxy err 0.008697478100657463 err 17.110746383666992 tr(WHW.T) 1967.3226318359375
bpp_loss 3.3403600454330444
2_up proxy err 0.008531047962605953 err 64.84001159667969 tr(WHW.T) 7600.474609375
bpp_loss 3.6178698199135915
2_gate proxy err 0.004477299749851227 err 67.6668472290039 tr(WHW.T) 15113.31640625
bpp_loss 3.7600429398672923
2_down proxy err 0.008391709066927433 err 64.8404312133789 tr(WHW.T) 7726.72509765625
bpp_loss 3.6206304005214145
I0408 02:49:28.634370 298052 quantize_finetune_llama.py:250] computed original embedding for layer 5 in 0.8833179473876953s
I0408 02:49:32.500441 299681 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:49:32.500549 299681 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:49:32.500589 299681 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:49:32.866559 299681 config.py:54] PyTorch version 2.6.0 available.
W0408 02:49:33.090514 299681 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:49:33.777789 299681 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:49:33.781937 298052 quantize_finetune_llama.py:219] layer 6 gpu 2
I0408 02:49:33.796749 299681 data_utils.py:336] using 256 training seqs, 128 validation seqs
3_v proxy err 0.014714079909026623 err 4.2572712898254395 tr(WHW.T) 289.3331604003906
bpp_loss 3.345806837081909
3_q proxy err 0.0004838559834752232 err 23.020381927490234 tr(WHW.T) 47576.9296875
bpp_loss 4.282341003417969
3_k proxy err 0.0002550834615249187 err 6.676685810089111 tr(WHW.T) 26174.515625
bpp_loss 5.20915412902832
3_o proxy err 0.009487515315413475 err 17.61981201171875 tr(WHW.T) 1857.15771484375
bpp_loss 3.446340560913086
3_up proxy err 0.008567577227950096 err 64.56924438476562 tr(WHW.T) 7536.46484375
bpp_loss 3.598167794091361
3_gate proxy err 0.0033106436021625996 err 69.14063262939453 tr(WHW.T) 20884.34765625
bpp_loss 3.831740583692278
3_down proxy err 0.00920895766466856 err 64.44990539550781 tr(WHW.T) 6998.6103515625
bpp_loss 3.595522335597447
I0408 02:49:38.609986 298052 quantize_finetune_llama.py:250] computed original embedding for layer 6 in 0.9276351928710938s
I0408 02:49:42.400074 299853 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:49:42.400192 299853 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:49:42.400236 299853 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:49:42.793812 299853 config.py:54] PyTorch version 2.6.0 available.
W0408 02:49:43.012755 299853 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:49:43.651623 299853 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:49:43.655699 298052 quantize_finetune_llama.py:219] layer 7 gpu 3
I0408 02:49:43.672779 299853 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:49:45.095051 298052 quantize_finetune_llama.py:250] computed original embedding for layer 7 in 0.9162857532501221s
I0408 02:49:49.099047 300008 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:49:49.099173 300008 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:49:49.099217 300008 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:49:49.499686 300008 config.py:54] PyTorch version 2.6.0 available.
W0408 02:49:49.716252 300008 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:49:50.293270 300008 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:49:50.297368 298052 quantize_finetune_llama.py:219] layer 8 gpu 0
I0408 02:49:50.314599 300008 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.01503830123692751 err 4.290534496307373 tr(WHW.T) 285.30712890625
bpp_loss 3.396791696548462
4_q proxy err 0.000455692206742242 err 22.836950302124023 tr(WHW.T) 50114.859375
bpp_loss 4.246515989303589
4_k proxy err 0.00023073672491591424 err 6.761041641235352 tr(WHW.T) 29301.974609375
bpp_loss 5.1801557540893555
4_o proxy err 0.01356431096792221 err 17.596277236938477 tr(WHW.T) 1297.2481689453125
bpp_loss 3.4591656923294067
4_up proxy err 0.008679541759192944 err 64.08528900146484 tr(WHW.T) 7383.48779296875
bpp_loss 3.571086508887155
4_gate proxy err 0.002426103688776493 err 70.67476654052734 tr(WHW.T) 29130.974609375
bpp_loss 3.9015627588544572
4_down proxy err 0.010018824599683285 err 64.07762145996094 tr(WHW.T) 6395.72265625
bpp_loss 3.5689394814627513
5_v proxy err 0.020179351791739464 err 4.213850021362305 tr(WHW.T) 208.81988525390625
bpp_loss 3.2781193256378174
5_q proxy err 0.0006219731876626611 err 22.385826110839844 tr(WHW.T) 35991.625
bpp_loss 4.229933261871338
5_k proxy err 0.00028542184736579657 err 6.564061641693115 tr(WHW.T) 22997.75390625
bpp_loss 5.1647467613220215
5_o proxy err 0.01644420623779297 err 17.3582820892334 tr(WHW.T) 1055.5865478515625
bpp_loss 3.4006903171539307
5_up proxy err 0.008384881541132927 err 64.19828796386719 tr(WHW.T) 7656.43310546875
bpp_loss 3.5776535783495222
5_gate proxy err 0.002333512296900153 err 70.90831756591797 tr(WHW.T) 30386.947265625
bpp_loss 3.904359442847116
5_down proxy err 0.009993154555559158 err 64.0674057006836 tr(WHW.T) 6411.12939453125
bpp_loss 3.5734197071620395
I0408 02:50:09.297532 298052 quantize_finetune_llama.py:250] computed original embedding for layer 8 in 1.165097951889038s
I0408 02:50:13.309368 300325 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:50:13.309479 300325 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:50:13.309520 300325 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:50:13.689063 300325 config.py:54] PyTorch version 2.6.0 available.
W0408 02:50:13.905320 300325 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:50:14.517158 300325 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:50:14.521218 298052 quantize_finetune_llama.py:219] layer 9 gpu 1
I0408 02:50:14.538065 300325 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.016973000019788742 err 4.304925918579102 tr(WHW.T) 253.63377380371094
bpp_loss 3.329211950302124
6_q proxy err 0.0006306796567514539 err 22.477161407470703 tr(WHW.T) 35639.5859375
bpp_loss 4.279874086380005
6_k proxy err 0.0002598010760266334 err 6.797345161437988 tr(WHW.T) 26163.654296875
bpp_loss 5.227919101715088
6_o proxy err 0.017458653077483177 err 17.618371963500977 tr(WHW.T) 1009.1483764648438
bpp_loss 3.435972213745117
6_up proxy err 0.00811244547367096 err 64.27925109863281 tr(WHW.T) 7923.53564453125
bpp_loss 3.5775199958256314
6_gate proxy err 0.00198932527564466 err 71.11518096923828 tr(WHW.T) 35748.39453125
bpp_loss 3.9081943375723704
6_down proxy err 0.009887350723147392 err 64.105224609375 tr(WHW.T) 6483.5595703125
bpp_loss 3.572333335876465
I0408 02:50:19.026540 298052 quantize_finetune_llama.py:250] computed original embedding for layer 9 in 1.033383846282959s
I0408 02:50:22.904388 300490 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:50:22.904500 300490 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:50:22.904541 300490 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:50:23.292833 300490 config.py:54] PyTorch version 2.6.0 available.
W0408 02:50:23.514255 300490 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

7_v proxy err 0.01353367418050766 err 4.187685489654541 tr(WHW.T) 309.4270935058594
bpp_loss 3.3239023685455322
7_q proxy err 0.0006259562214836478 err 21.999202728271484 tr(WHW.T) 35144.953125
bpp_loss 4.204926490783691
7_k proxy err 0.0002490907208994031 err 6.68820858001709 tr(WHW.T) 26850.4921875
bpp_loss 5.259917259216309
7_o proxy err 0.01831340417265892 err 17.56650161743164 tr(WHW.T) 959.2155151367188
bpp_loss 3.4476613998413086
7_up proxy err 0.007480317261070013 err 64.53606414794922 tr(WHW.T) 8627.4501953125
bpp_loss 3.590876885822841
7_gate proxy err 0.0020240333396941423 err 70.64591979980469 tr(WHW.T) 34903.53515625
bpp_loss 3.8793918745858327
7_down proxy err 0.009830950759351254 err 64.24160766601562 tr(WHW.T) 6534.6279296875
bpp_loss 3.5851635251726424
W0408 02:50:24.144103 300490 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:50:24.148237 298052 quantize_finetune_llama.py:219] layer 10 gpu 2
I0408 02:50:24.162577 300490 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:50:25.931711 298052 quantize_finetune_llama.py:250] computed original embedding for layer 10 in 1.0408344268798828s
I0408 02:50:29.833911 300628 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:50:29.834020 300628 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:50:29.834061 300628 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:50:30.189001 300628 config.py:54] PyTorch version 2.6.0 available.
W0408 02:50:30.392119 300628 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:50:30.953105 300628 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:50:30.957404 298052 quantize_finetune_llama.py:219] layer 11 gpu 3
I0408 02:50:30.972943 300628 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:50:32.469501 298052 quantize_finetune_llama.py:250] computed original embedding for layer 11 in 1.0185604095458984s
I0408 02:50:36.654167 300761 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:50:36.654291 300761 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:50:36.654333 300761 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:50:37.053497 300761 config.py:54] PyTorch version 2.6.0 available.
W0408 02:50:37.268632 300761 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:50:37.895020 300761 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:50:37.899245 298052 quantize_finetune_llama.py:219] layer 12 gpu 0
I0408 02:50:37.914727 300761 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.016629738733172417 err 4.2855706214904785 tr(WHW.T) 257.7052307128906
bpp_loss 3.3504273891448975
8_q proxy err 0.0008174876566044986 err 21.745969772338867 tr(WHW.T) 26600.9765625
bpp_loss 4.193664312362671
8_k proxy err 0.0002874924975913018 err 6.476845741271973 tr(WHW.T) 22528.748046875
bpp_loss 5.1715288162231445
8_o proxy err 0.023544181138277054 err 17.554685592651367 tr(WHW.T) 745.6061401367188
bpp_loss 3.4601935148239136
8_up proxy err 0.0075810132548213005 err 64.401123046875 tr(WHW.T) 8495.0546875
bpp_loss 3.586514336722238
8_gate proxy err 0.001897207461297512 err 70.64849090576172 tr(WHW.T) 37238.1484375
bpp_loss 3.8833649839673723
8_down proxy err 0.009889689274132252 err 64.1723861694336 tr(WHW.T) 6488.8173828125
bpp_loss 3.58147280556815
9_v proxy err 0.012425903230905533 err 4.366820335388184 tr(WHW.T) 351.4288024902344
bpp_loss 3.453902006149292
9_q proxy err 0.000850945245474577 err 21.829496383666992 tr(WHW.T) 25653.232421875
bpp_loss 4.201360464096069
9_k proxy err 0.00031036132713779807 err 6.499785423278809 tr(WHW.T) 20942.638671875
bpp_loss 5.189379692077637
9_o proxy err 0.022901229560375214 err 17.78513526916504 tr(WHW.T) 776.6017456054688
bpp_loss 3.5167276859283447
9_up proxy err 0.007190039847046137 err 64.49929809570312 tr(WHW.T) 8970.6455078125
bpp_loss 3.595087630408151
9_gate proxy err 0.0018006039317697287 err 70.97209930419922 tr(WHW.T) 39415.71875
bpp_loss 3.896738052368164
9_down proxy err 0.010235566645860672 err 64.20672607421875 tr(WHW.T) 6272.90380859375
bpp_loss 3.5844293321881975
I0408 02:50:59.535112 298052 quantize_finetune_llama.py:250] computed original embedding for layer 12 in 1.0594499111175537s
I0408 02:51:03.591514 301127 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:03.591615 301127 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:03.591655 301127 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:51:03.935378 301127 config.py:54] PyTorch version 2.6.0 available.
10_v proxy err 0.016993142664432526 err 4.279534339904785 tr(WHW.T) 251.83889770507812
bpp_loss 3.3410587310791016
10_q proxy err 0.0009356678347103298 err 21.836761474609375 tr(WHW.T) 23338.15625
bpp_loss 4.212794780731201
10_k proxy err 0.00032940658275038004 err 6.50378942489624 tr(WHW.T) 19743.95703125
bpp_loss 5.199295997619629
10_o proxy err 0.0258854441344738 err 17.619291305541992 tr(WHW.T) 680.6640625
bpp_loss 3.45111882686615
10_up proxy err 0.007056971546262503 err 64.9181900024414 tr(WHW.T) 9199.1572265625
bpp_loss 3.6122402804238454
10_gate proxy err 0.001883380115032196 err 70.4372329711914 tr(WHW.T) 37399.37109375
bpp_loss 3.8660552161080495
10_down proxy err 0.00988424476236105 err 64.49700164794922 tr(WHW.T) 6525.2333984375
bpp_loss 3.5992355346679688
W0408 02:51:04.125956 301127 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:51:04.733505 301127 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:04.737622 298052 quantize_finetune_llama.py:219] layer 13 gpu 1
I0408 02:51:04.752598 301127 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:51:06.266064 298052 quantize_finetune_llama.py:250] computed original embedding for layer 13 in 1.0047903060913086s
I0408 02:51:10.207435 301253 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:10.207552 301253 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:10.207597 301253 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:51:10.591268 301253 config.py:54] PyTorch version 2.6.0 available.
W0408 02:51:10.801081 301253 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

11_v proxy err 0.013267206028103828 err 4.2397894859313965 tr(WHW.T) 319.5691223144531
bpp_loss 3.340866804122925
11_q proxy err 0.0009664437966421247 err 21.446256637573242 tr(WHW.T) 22190.8984375
bpp_loss 4.146041631698608
11_k proxy err 0.00036573238321579993 err 6.593212604522705 tr(WHW.T) 18027.423828125
bpp_loss 5.195851802825928
11_o proxy err 0.031178515404462814 err 17.645408630371094 tr(WHW.T) 565.9476928710938
bpp_loss 3.4699864387512207
11_up proxy err 0.007063227705657482 err 64.92939758300781 tr(WHW.T) 9192.595703125
bpp_loss 3.6186180795942033
11_gate proxy err 0.0019016986479982734 err 70.1424331665039 tr(WHW.T) 36884.09375
bpp_loss 3.8462506362370084
11_down proxy err 0.009721248410642147 err 64.70356750488281 tr(WHW.T) 6655.890625
bpp_loss 3.6065514428274974
W0408 02:51:11.354612 301253 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:11.358169 298052 quantize_finetune_llama.py:219] layer 14 gpu 2
I0408 02:51:11.372396 301253 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:51:13.216885 298052 quantize_finetune_llama.py:250] computed original embedding for layer 14 in 1.2135944366455078s
I0408 02:51:17.290611 301399 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:17.290723 301399 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:17.290765 301399 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:51:17.666769 301399 config.py:54] PyTorch version 2.6.0 available.
W0408 02:51:17.867714 301399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:51:18.462776 301399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:18.466720 298052 quantize_finetune_llama.py:219] layer 15 gpu 3
I0408 02:51:18.483354 301399 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:51:20.034571 298052 quantize_finetune_llama.py:250] computed original embedding for layer 15 in 1.081376552581787s
I0408 02:51:24.148594 301540 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:24.148715 301540 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:24.148762 301540 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:51:24.553098 301540 config.py:54] PyTorch version 2.6.0 available.
W0408 02:51:24.776502 301540 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:51:25.422026 301540 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:25.426653 298052 quantize_finetune_llama.py:219] layer 16 gpu 0
I0408 02:51:25.442345 301540 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.012131722643971443 err 4.411377906799316 tr(WHW.T) 363.6233825683594
bpp_loss 3.4636893272399902
12_q proxy err 0.0006475064437836409 err 22.081668853759766 tr(WHW.T) 34102.625
bpp_loss 4.197685718536377
12_k proxy err 0.00028295646188780665 err 6.524138927459717 tr(WHW.T) 23057.041015625
bpp_loss 5.181294918060303
12_o proxy err 0.022908363491296768 err 17.863285064697266 tr(WHW.T) 779.7713012695312
bpp_loss 3.5215286016464233
12_up proxy err 0.006503316108137369 err 65.20976257324219 tr(WHW.T) 10027.1552734375
bpp_loss 3.638040781021118
12_gate proxy err 0.0018707729177549481 err 69.8436279296875 tr(WHW.T) 37334.1015625
bpp_loss 3.8258458205631802
12_down proxy err 0.009490089491009712 err 64.7481460571289 tr(WHW.T) 6822.7119140625
bpp_loss 3.6227006912231445
13_v proxy err 0.015565676614642143 err 4.360779762268066 tr(WHW.T) 280.153564453125
bpp_loss 3.40189790725708
13_q proxy err 0.0010272531071677804 err 21.466894149780273 tr(WHW.T) 20897.375
bpp_loss 4.180989980697632
13_k proxy err 0.00036255206214264035 err 6.453033447265625 tr(WHW.T) 17798.916015625
bpp_loss 5.20693826675415
13_o proxy err 0.02645527943968773 err 17.86278533935547 tr(WHW.T) 675.2068481445312
bpp_loss 3.4986677169799805
13_up proxy err 0.006525702774524689 err 65.32416534423828 tr(WHW.T) 10010.2880859375
bpp_loss 3.6415088857923235
13_gate proxy err 0.0018009464256465435 err 70.09510803222656 tr(WHW.T) 38921.26171875
bpp_loss 3.830236094338553
13_down proxy err 0.0099127646535635 err 65.03275299072266 tr(WHW.T) 6560.505859375
bpp_loss 3.6233628136771068
I0408 02:51:46.050166 298052 quantize_finetune_llama.py:250] computed original embedding for layer 16 in 1.0161528587341309s
I0408 02:51:50.019918 301883 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:50.020147 301883 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:50.020252 301883 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:51:50.388696 301883 config.py:54] PyTorch version 2.6.0 available.
W0408 02:51:50.594691 301883 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:51:51.183563 301883 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:51.187489 298052 quantize_finetune_llama.py:219] layer 17 gpu 1
I0408 02:51:51.200982 301883 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.015372831374406815 err 4.324965953826904 tr(WHW.T) 281.3382873535156
bpp_loss 3.3911972045898438
14_q proxy err 0.0010343026369810104 err 21.59813690185547 tr(WHW.T) 20881.8359375
bpp_loss 4.153017520904541
14_k proxy err 0.0003490325470920652 err 6.498741149902344 tr(WHW.T) 18619.298828125
bpp_loss 5.1590681076049805
14_o proxy err 0.025780117139220238 err 17.692834854125977 tr(WHW.T) 686.2976684570312
bpp_loss 3.4932082891464233
14_up proxy err 0.007114281412214041 err 65.19731903076172 tr(WHW.T) 9164.287109375
bpp_loss 3.637215648378645
14_gate proxy err 0.0016857108566910028 err 70.43881225585938 tr(WHW.T) 41785.8203125
bpp_loss 3.8602141993386403
14_down proxy err 0.010157419368624687 err 64.91521453857422 tr(WHW.T) 6390.916015625
bpp_loss 3.621612548828125
I0408 02:51:54.001247 298052 quantize_finetune_llama.py:250] computed original embedding for layer 17 in 1.0338451862335205s
I0408 02:51:58.009393 302026 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:51:58.009486 302026 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:51:58.009525 302026 utils.py:162] NumExpr defaulting to 16 threads.
15_v proxy err 0.01539474818855524 err 4.372526168823242 tr(WHW.T) 284.0271301269531
bpp_loss 3.453658103942871
15_q proxy err 0.0007833624258637428 err 21.996273040771484 tr(WHW.T) 28079.306640625
bpp_loss 4.286397933959961
15_k proxy err 0.0003503337502479553 err 6.611382007598877 tr(WHW.T) 18871.66796875
bpp_loss 5.18640661239624
15_o proxy err 0.021601704880595207 err 17.884654998779297 tr(WHW.T) 827.9279174804688
bpp_loss 3.5226383209228516
15_up proxy err 0.007236468140035868 err 65.08891296386719 tr(WHW.T) 8994.5693359375
bpp_loss 3.629257849284581
15_gate proxy err 0.0015446410980075598 err 71.39017486572266 tr(WHW.T) 46217.96875
bpp_loss 3.8968233040400913
15_down proxy err 0.010122193023562431 err 64.77582550048828 tr(WHW.T) 6399.38671875
bpp_loss 3.616391454424177
I0408 02:51:58.332205 302026 config.py:54] PyTorch version 2.6.0 available.
W0408 02:51:58.520020 302026 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:51:59.051830 302026 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:51:59.055473 298052 quantize_finetune_llama.py:219] layer 18 gpu 2
I0408 02:51:59.068391 302026 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:52:00.571702 298052 quantize_finetune_llama.py:250] computed original embedding for layer 18 in 1.022221565246582s
I0408 02:52:04.674926 302167 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:04.675045 302167 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:04.675087 302167 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:52:05.071374 302167 config.py:54] PyTorch version 2.6.0 available.
W0408 02:52:05.296628 302167 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:05.909799 302167 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:05.913955 298052 quantize_finetune_llama.py:219] layer 19 gpu 3
I0408 02:52:05.928713 302167 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:52:07.459162 298052 quantize_finetune_llama.py:250] computed original embedding for layer 19 in 1.1114501953125s
I0408 02:52:11.620892 302303 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:11.621020 302303 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:11.621070 302303 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:52:12.038096 302303 config.py:54] PyTorch version 2.6.0 available.
W0408 02:52:12.264085 302303 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:12.911090 302303 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:12.915356 298052 quantize_finetune_llama.py:219] layer 20 gpu 0
I0408 02:52:12.930320 302303 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.015803085640072823 err 4.334496974945068 tr(WHW.T) 274.28167724609375
bpp_loss 3.40584659576416
16_q proxy err 0.0008955862140282989 err 21.929901123046875 tr(WHW.T) 24486.64453125
bpp_loss 4.261316299438477
16_k proxy err 0.0003364720905665308 err 6.563344955444336 tr(WHW.T) 19506.357421875
bpp_loss 5.185060977935791
16_o proxy err 0.018470101058483124 err 17.8991641998291 tr(WHW.T) 969.0885620117188
bpp_loss 3.5050089359283447
16_up proxy err 0.0077932048588991165 err 64.9266128540039 tr(WHW.T) 8331.1826171875
bpp_loss 3.6152916976383755
16_gate proxy err 0.0017358771292492747 err 71.47669982910156 tr(WHW.T) 41176.12890625
bpp_loss 3.931856155395508
16_down proxy err 0.010269483551383018 err 64.577392578125 tr(WHW.T) 6288.2802734375
bpp_loss 3.603182111467634
17_v proxy err 0.015516521409153938 err 4.406273365020752 tr(WHW.T) 283.9730224609375
bpp_loss 3.4850943088531494
17_q proxy err 0.0008008552249521017 err 22.080732345581055 tr(WHW.T) 27571.44140625
bpp_loss 4.270614147186279
17_k proxy err 0.0003744197019841522 err 6.526065826416016 tr(WHW.T) 17429.814453125
bpp_loss 5.203762054443359
17_o proxy err 0.016244594007730484 err 17.977880477905273 tr(WHW.T) 1106.6993408203125
bpp_loss 3.534117102622986
17_up proxy err 0.007671342696994543 err 64.84234619140625 tr(WHW.T) 8452.5419921875
bpp_loss 3.611156633922032
17_gate proxy err 0.0017206266056746244 err 71.78034973144531 tr(WHW.T) 41717.5625
bpp_loss 3.945538418633597
17_down proxy err 0.010374649427831173 err 64.45059204101562 tr(WHW.T) 6212.31494140625
bpp_loss 3.6013313020978654
I0408 02:52:34.703521 298052 quantize_finetune_llama.py:250] computed original embedding for layer 20 in 1.3474302291870117s
I0408 02:52:38.662889 302653 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:38.662982 302653 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:38.663021 302653 utils.py:162] NumExpr defaulting to 16 threads.
18_v proxy err 0.015012978576123714 err 4.317939281463623 tr(WHW.T) 287.61376953125
bpp_loss 3.39957594871521
18_q proxy err 0.0009845246095210314 err 22.0528564453125 tr(WHW.T) 22399.498046875
bpp_loss 4.268903732299805
18_k proxy err 0.0003792875213548541 err 6.597634792327881 tr(WHW.T) 17394.810546875
bpp_loss 5.284782409667969
18_o proxy err 0.014900258742272854 err 17.92789649963379 tr(WHW.T) 1203.193603515625
bpp_loss 3.5136539936065674
18_up proxy err 0.008108017034828663 err 64.72535705566406 tr(WHW.T) 7982.8837890625
bpp_loss 3.60653509412493
18_gate proxy err 0.0020315165165811777 err 71.59786224365234 tr(WHW.T) 35243.5546875
bpp_loss 3.9546501636505127
18_down proxy err 0.01034843735396862 err 64.43535614013672 tr(WHW.T) 6226.57861328125
bpp_loss 3.5990693228585378
I0408 02:52:38.982984 302653 config.py:54] PyTorch version 2.6.0 available.
W0408 02:52:39.187641 302653 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:39.806167 302653 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:39.810032 298052 quantize_finetune_llama.py:219] layer 21 gpu 1
I0408 02:52:39.823535 302653 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:52:41.321107 298052 quantize_finetune_llama.py:250] computed original embedding for layer 21 in 1.0318083763122559s
I0408 02:52:45.205916 302804 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:45.206039 302804 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:45.206084 302804 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:52:45.580784 302804 config.py:54] PyTorch version 2.6.0 available.
19_v proxy err 0.012904185801744461 err 4.401097297668457 tr(WHW.T) 341.0596618652344
bpp_loss 3.4435830116271973
19_q proxy err 0.0009143435745500028 err 21.979022979736328 tr(WHW.T) 24038.03515625
bpp_loss 4.268052577972412
19_k proxy err 0.00042292129364795983 err 6.577816486358643 tr(WHW.T) 15553.287109375
bpp_loss 5.181816101074219
19_o proxy err 0.015306403860449791 err 17.891530990600586 tr(WHW.T) 1168.891845703125
bpp_loss 3.5280230045318604
19_up proxy err 0.0084524592384696 err 64.65532684326172 tr(WHW.T) 7649.2919921875
bpp_loss 3.6027462823050365
19_gate proxy err 0.002186940051615238 err 71.75786590576172 tr(WHW.T) 32811.99609375
bpp_loss 3.9663046087537492
19_down proxy err 0.010413345880806446 err 64.38296508789062 tr(WHW.T) 6182.73583984375
bpp_loss 3.597132819039481
W0408 02:52:45.784185 302804 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:46.331955 302804 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:46.335649 298052 quantize_finetune_llama.py:219] layer 22 gpu 2
I0408 02:52:46.348471 302804 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:52:47.721346 298052 quantize_finetune_llama.py:250] computed original embedding for layer 22 in 0.9461915493011475s
I0408 02:52:51.606020 302930 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:51.606132 302930 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:51.606173 302930 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:52:51.986283 302930 config.py:54] PyTorch version 2.6.0 available.
W0408 02:52:52.205360 302930 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:52.832295 302930 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:52.836611 298052 quantize_finetune_llama.py:219] layer 23 gpu 3
I0408 02:52:52.851576 302930 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:52:54.251078 298052 quantize_finetune_llama.py:250] computed original embedding for layer 23 in 0.9381814002990723s
I0408 02:52:58.381465 303081 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:52:58.381586 303081 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:52:58.381632 303081 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:52:58.790674 303081 config.py:54] PyTorch version 2.6.0 available.
W0408 02:52:59.014779 303081 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:52:59.707698 303081 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:52:59.712182 298052 quantize_finetune_llama.py:219] layer 24 gpu 0
I0408 02:52:59.728519 303081 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.01346743106842041 err 4.446839809417725 tr(WHW.T) 330.192138671875
bpp_loss 3.4855763912200928
20_q proxy err 0.001048916019499302 err 21.75214958190918 tr(WHW.T) 20737.7421875
bpp_loss 4.24091362953186
20_k proxy err 0.0004233501385897398 err 6.517818450927734 tr(WHW.T) 15395.810546875
bpp_loss 5.130876541137695
20_o proxy err 0.014853875152766705 err 17.900745391845703 tr(WHW.T) 1205.1229248046875
bpp_loss 3.5162147283554077
20_up proxy err 0.008510074578225613 err 64.67366027832031 tr(WHW.T) 7599.658203125
bpp_loss 3.6063328811100552
20_gate proxy err 0.0023358722683042288 err 71.62956237792969 tr(WHW.T) 30665.015625
bpp_loss 3.9688989434923445
20_down proxy err 0.010229473002254963 err 64.45449829101562 tr(WHW.T) 6300.8623046875
bpp_loss 3.6012272153581892
21_v proxy err 0.012343519367277622 err 4.47913122177124 tr(WHW.T) 362.87310791015625
bpp_loss 3.51418399810791
21_q proxy err 0.0008498181705363095 err 21.95769691467285 tr(WHW.T) 25838.111328125
bpp_loss 4.236547946929932
21_k proxy err 0.0003884317120537162 err 6.520779132843018 tr(WHW.T) 16787.453125
bpp_loss 5.175832748413086
21_o proxy err 0.013981427997350693 err 17.709840774536133 tr(WHW.T) 1266.6689453125
bpp_loss 3.536283493041992
21_up proxy err 0.008325259201228619 err 64.70866394042969 tr(WHW.T) 7772.57080078125
bpp_loss 3.6093101501464844
21_gate proxy err 0.0022757654078304768 err 71.83768463134766 tr(WHW.T) 31566.3828125
bpp_loss 3.9811168057577953
21_down proxy err 0.010161545127630234 err 64.54069519042969 tr(WHW.T) 6351.46484375
bpp_loss 3.60399900163923
I0408 02:53:22.285265 298052 quantize_finetune_llama.py:250] computed original embedding for layer 24 in 1.0883824825286865s
22_v proxy err 0.012956487014889717 err 4.483967304229736 tr(WHW.T) 346.0789489746094
bpp_loss 3.56557559967041
22_q proxy err 0.0010644346475601196 err 21.62889289855957 tr(WHW.T) 20319.60546875
bpp_loss 4.196983098983765
22_k proxy err 0.00043987983372062445 err 6.476833820343018 tr(WHW.T) 14724.09765625
bpp_loss 5.106654644012451
22_o proxy err 0.01489288080483675 err 18.196582794189453 tr(WHW.T) 1221.8309326171875
bpp_loss 3.560111165046692
22_up proxy err 0.008584150113165379 err 64.78677368164062 tr(WHW.T) 7547.25537109375
bpp_loss 3.6130397660391673
22_gate proxy err 0.0024332080502063036 err 71.86260986328125 tr(WHW.T) 29534.099609375
bpp_loss 3.9855318750653947
22_down proxy err 0.009887748397886753 err 64.56196594238281 tr(WHW.T) 6529.4912109375
bpp_loss 3.6077985763549805
I0408 02:53:26.229675 303419 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:53:26.229778 303419 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:53:26.229819 303419 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:53:26.585119 303419 config.py:54] PyTorch version 2.6.0 available.
W0408 02:53:26.794783 303419 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:53:27.374530 303419 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:53:27.378974 298052 quantize_finetune_llama.py:219] layer 25 gpu 1
I0408 02:53:27.393244 303419 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:53:29.130934 298052 quantize_finetune_llama.py:250] computed original embedding for layer 25 in 1.2452075481414795s
23_v proxy err 0.011551753617823124 err 4.596524238586426 tr(WHW.T) 397.90704345703125
bpp_loss 3.620274543762207
23_q proxy err 0.0009648879640735686 err 21.815086364746094 tr(WHW.T) 22608.931640625
bpp_loss 4.20421576499939
23_k proxy err 0.0004347716167103499 err 6.45960807800293 tr(WHW.T) 14857.474609375
bpp_loss 5.10703706741333
23_o proxy err 0.010481431148946285 err 18.2845516204834 tr(WHW.T) 1744.470947265625
bpp_loss 3.5810956954956055
23_up proxy err 0.008747600950300694 err 64.9002685546875 tr(WHW.T) 7419.2080078125
bpp_loss 3.617288725716727
23_gate proxy err 0.002631426090374589 err 71.81596374511719 tr(WHW.T) 27291.65234375
bpp_loss 3.9889912605285645
23_down proxy err 0.009700164198875427 err 64.67085266113281 tr(WHW.T) 6666.9853515625
bpp_loss 3.612213815961565
I0408 02:53:33.109865 303562 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:53:33.109980 303562 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:53:33.110023 303562 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:53:33.446043 303562 config.py:54] PyTorch version 2.6.0 available.
W0408 02:53:33.657763 303562 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:53:34.209989 303562 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:53:34.213665 298052 quantize_finetune_llama.py:219] layer 26 gpu 2
I0408 02:53:34.226790 303562 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:53:35.554764 298052 quantize_finetune_llama.py:250] computed original embedding for layer 26 in 0.9248025417327881s
I0408 02:53:39.495902 303703 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:53:39.496024 303703 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:53:39.496063 303703 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:53:39.876076 303703 config.py:54] PyTorch version 2.6.0 available.
W0408 02:53:40.095618 303703 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:53:40.710509 303703 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:53:40.714541 298052 quantize_finetune_llama.py:219] layer 27 gpu 3
I0408 02:53:40.728530 303703 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:53:42.139351 298052 quantize_finetune_llama.py:250] computed original embedding for layer 27 in 0.9456973075866699s
I0408 02:53:46.120721 303844 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:53:46.120834 303844 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:53:46.120875 303844 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:53:46.516479 303844 config.py:54] PyTorch version 2.6.0 available.
W0408 02:53:46.742432 303844 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:53:47.421160 303844 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:53:47.425393 298052 quantize_finetune_llama.py:219] layer 28 gpu 0
I0408 02:53:47.440061 303844 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.010093062184751034 err 4.716269493103027 tr(WHW.T) 467.2783508300781
bpp_loss 3.7165794372558594
24_q proxy err 0.000966545834671706 err 21.685518264770508 tr(WHW.T) 22436.099609375
bpp_loss 4.169379472732544
24_k proxy err 0.00044933019671589136 err 6.373045444488525 tr(WHW.T) 14183.4345703125
bpp_loss 4.934964179992676
24_o proxy err 0.011562041938304901 err 18.37777328491211 tr(WHW.T) 1589.4920654296875
bpp_loss 3.6261987686157227
24_up proxy err 0.008879412896931171 err 64.91866302490234 tr(WHW.T) 7311.1435546875
bpp_loss 3.621901750564575
24_gate proxy err 0.0027765301056206226 err 71.8489990234375 tr(WHW.T) 25877.26171875
bpp_loss 3.995889970234462
24_down proxy err 0.009619932621717453 err 64.85697937011719 tr(WHW.T) 6741.93701171875
bpp_loss 3.617424556187221
25_v proxy err 0.008527458645403385 err 4.75669002532959 tr(WHW.T) 557.8086547851562
bpp_loss 3.728070020675659
25_q proxy err 0.0008287375094369054 err 21.640018463134766 tr(WHW.T) 26112.029296875
bpp_loss 4.148374080657959
25_k proxy err 0.0004395585274323821 err 6.336948394775391 tr(WHW.T) 14416.6201171875
bpp_loss 4.92311954498291
25_o proxy err 0.009229755029082298 err 18.371654510498047 tr(WHW.T) 1990.481201171875
bpp_loss 3.6295140981674194
25_up proxy err 0.0088009312748909 err 64.97015380859375 tr(WHW.T) 7382.19091796875
bpp_loss 3.6310696601867676
25_gate proxy err 0.0027371023315936327 err 72.00614166259766 tr(WHW.T) 26307.435546875
bpp_loss 4.005198376519339
25_down proxy err 0.009815041907131672 err 64.93583679199219 tr(WHW.T) 6615.951171875
bpp_loss 3.626546178545271
I0408 02:54:11.231843 298052 quantize_finetune_llama.py:250] computed original embedding for layer 28 in 1.001253366470337s
I0408 02:54:15.158982 304194 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:54:15.159081 304194 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:54:15.159123 304194 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:54:15.533414 304194 config.py:54] PyTorch version 2.6.0 available.
W0408 02:54:15.723140 304194 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

26_v proxy err 0.011002750135958195 err 4.7811994552612305 tr(WHW.T) 434.54583740234375
bpp_loss 3.792006254196167
26_q proxy err 0.0010043727234005928 err 21.496871948242188 tr(WHW.T) 21403.28125
bpp_loss 4.155888557434082
26_k proxy err 0.0004124769475311041 err 6.362698554992676 tr(WHW.T) 15425.5859375
bpp_loss 4.996563911437988
26_o proxy err 0.007708367891609669 err 18.413164138793945 tr(WHW.T) 2388.72412109375
bpp_loss 3.6509026288986206
26_up proxy err 0.00852623675018549 err 65.18867492675781 tr(WHW.T) 7645.65625
bpp_loss 3.6397834164755687
26_gate proxy err 0.0024900499265640974 err 71.9660415649414 tr(WHW.T) 28901.4453125
bpp_loss 4.00994838987078
26_down proxy err 0.00981805007904768 err 64.98395538330078 tr(WHW.T) 6618.82470703125
bpp_loss 3.6353074482509067
W0408 02:54:16.346699 304194 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:54:16.350948 298052 quantize_finetune_llama.py:219] layer 29 gpu 1
I0408 02:54:16.366724 304194 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:54:17.800552 298052 quantize_finetune_llama.py:250] computed original embedding for layer 29 in 0.9686594009399414s
I0408 02:54:21.617636 304323 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:54:21.617744 304323 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:54:21.617785 304323 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:54:21.993803 304323 config.py:54] PyTorch version 2.6.0 available.
W0408 02:54:22.213216 304323 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:54:22.853952 304323 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:54:22.857552 298052 quantize_finetune_llama.py:219] layer 30 gpu 2
I0408 02:54:22.870629 304323 data_utils.py:336] using 256 training seqs, 128 validation seqs
27_v proxy err 0.0072991857305169106 err 4.946613311767578 tr(WHW.T) 677.69384765625
bpp_loss 3.872598648071289
27_q proxy err 0.0010107361013069749 err 21.534711837768555 tr(WHW.T) 21305.96875
bpp_loss 4.126901626586914
27_k proxy err 0.00045448984019458294 err 6.368138790130615 tr(WHW.T) 14011.6201171875
bpp_loss 4.950887203216553
27_o proxy err 0.008739354088902473 err 18.87662124633789 tr(WHW.T) 2159.9560546875
bpp_loss 3.6792945861816406
27_up proxy err 0.007730261422693729 err 65.51856231689453 tr(WHW.T) 8475.5947265625
bpp_loss 3.653531381062099
27_gate proxy err 0.0022017736919224262 err 72.23807525634766 tr(WHW.T) 32809.0390625
bpp_loss 4.017937523978097
27_down proxy err 0.009950419887900352 err 65.10916137695312 tr(WHW.T) 6543.35791015625
bpp_loss 3.6475155694144115
I0408 02:54:24.953755 298052 quantize_finetune_llama.py:250] computed original embedding for layer 30 in 0.8769350051879883s
I0408 02:54:28.918194 304478 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:54:28.918309 304478 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:54:28.918349 304478 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:54:29.322768 304478 config.py:54] PyTorch version 2.6.0 available.
W0408 02:54:29.541671 304478 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:54:30.274312 304478 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:54:30.278559 298052 quantize_finetune_llama.py:219] layer 31 gpu 3
I0408 02:54:30.294817 304478 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0408 02:54:31.844429 298052 quantize_finetune_llama.py:250] computed original embedding for layer 31 in 1.0957930088043213s
I0408 02:54:36.044168 304609 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:54:36.044296 304609 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:54:36.044337 304609 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:54:36.537653 304609 config.py:54] PyTorch version 2.6.0 available.
W0408 02:54:36.760272 304609 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0408 02:54:37.442119 304609 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0408 02:54:37.462792 304609 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.008229603059589863 err 4.949978351593018 tr(WHW.T) 601.4844360351562
bpp_loss 3.9372620582580566
28_q proxy err 0.0009410289349034429 err 21.797889709472656 tr(WHW.T) 23163.888671875
bpp_loss 4.133872747421265
28_k proxy err 0.00043051113607361913 err 6.455175399780273 tr(WHW.T) 14994.2119140625
bpp_loss 4.896484375
28_o proxy err 0.007549498695880175 err 18.960155487060547 tr(WHW.T) 2511.445556640625
bpp_loss 3.706821084022522
28_up proxy err 0.006445455830544233 err 66.04059600830078 tr(WHW.T) 10246.0703125
bpp_loss 3.6761207239968434
28_gate proxy err 0.002004590118303895 err 72.00680541992188 tr(WHW.T) 35920.9609375
bpp_loss 4.004050833838327
28_down proxy err 0.009046724066138268 err 65.22766876220703 tr(WHW.T) 7210.08740234375
bpp_loss 3.665893009730748
29_v proxy err 0.005943835247308016 err 5.054810047149658 tr(WHW.T) 850.4290161132812
bpp_loss 3.9983620643615723
29_q proxy err 0.0010535947512835264 err 21.760129928588867 tr(WHW.T) 20653.2265625
bpp_loss 4.125101327896118
29_k proxy err 0.0003908459038939327 err 6.396504878997803 tr(WHW.T) 16365.796875
bpp_loss 5.001546382904053
29_o proxy err 0.006119393743574619 err 18.987529754638672 tr(WHW.T) 3102.844970703125
bpp_loss 3.751071572303772
29_up proxy err 0.005179456900805235 err 66.65187072753906 tr(WHW.T) 12868.505859375
bpp_loss 3.7069879940577914
29_gate proxy err 0.0018774957861751318 err 72.02913665771484 tr(WHW.T) 38364.47265625
bpp_loss 3.9928007466452464
29_down proxy err 0.008846884593367577 err 66.09086608886719 tr(WHW.T) 7470.5244140625
bpp_loss 3.6856788907732283
30_v proxy err 0.006230296567082405 err 5.377124786376953 tr(WHW.T) 863.060791015625
bpp_loss 4.288699150085449
30_q proxy err 0.0008821420487947762 err 21.216073989868164 tr(WHW.T) 24050.6328125
bpp_loss 4.021165132522583
30_k proxy err 0.0004395358555484563 err 6.166946887969971 tr(WHW.T) 14030.5888671875
bpp_loss 4.635194301605225
30_o proxy err 0.004118265118449926 err 20.052553176879883 tr(WHW.T) 4869.1748046875
bpp_loss 3.834357261657715
30_up proxy err 0.003121675457805395 err 67.77530670166016 tr(WHW.T) 21711.1953125
bpp_loss 3.73421471459525
30_gate proxy err 0.0014070224715396762 err 73.10108184814453 tr(WHW.T) 51954.453125
bpp_loss 4.03825889314924
30_down proxy err 0.007372323889285326 err 64.95149230957031 tr(WHW.T) 8810.1787109375
bpp_loss 3.6925704138619557
31_v proxy err 0.0029040714725852013 err 5.252663612365723 tr(WHW.T) 1808.723876953125
bpp_loss 4.082311630249023
31_q proxy err 0.0004832299309782684 err 22.313461303710938 tr(WHW.T) 46175.66015625
bpp_loss 4.177239894866943
31_k proxy err 0.00031856304849497974 err 6.520235061645508 tr(WHW.T) 20467.64453125
bpp_loss 4.876802444458008
31_o proxy err 0.008302588947117329 err 18.37845802307129 tr(WHW.T) 2213.58154296875
bpp_loss 3.8035404682159424
31_up proxy err 0.0010579921072348952 err 73.02202606201172 tr(WHW.T) 69019.4453125
bpp_loss 3.9195443221500943
31_gate proxy err 0.0005407559219747782 err 78.11357879638672 tr(WHW.T) 144452.5625
bpp_loss 4.2540420804704935
31_down proxy err 0.006597776897251606 err 65.71510314941406 tr(WHW.T) 9960.1884765625
bpp_loss 3.7242373057774136
I0408 02:55:23.927572 305175 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:55:23.927762 305175 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:55:23.927804 305175 utils.py:162] NumExpr defaulting to 16 threads.
I0408 02:55:24.243843 305175 config.py:54] PyTorch version 2.6.0 available.
W0408 02:55:24.446961 305175 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0408 02:55:24.557690 305175 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.66it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.61it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  9.00it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.21it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.38it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.33it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.24it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.63it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  9.00it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.89it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.07it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.21it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.26it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.48it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.24it/s]
I0408 02:55:27.397258 305175 hfize_llama.py:161] loaded layer 0
I0408 02:55:27.729506 305175 hfize_llama.py:161] loaded layer 1
I0408 02:55:28.016894 305175 hfize_llama.py:161] loaded layer 2
I0408 02:55:28.335413 305175 hfize_llama.py:161] loaded layer 3
I0408 02:55:28.630996 305175 hfize_llama.py:161] loaded layer 4
I0408 02:55:28.906817 305175 hfize_llama.py:161] loaded layer 5
I0408 02:55:29.183445 305175 hfize_llama.py:161] loaded layer 6
I0408 02:55:29.527455 305175 hfize_llama.py:161] loaded layer 7
I0408 02:55:29.834146 305175 hfize_llama.py:161] loaded layer 8
I0408 02:55:30.118396 305175 hfize_llama.py:161] loaded layer 9
I0408 02:55:30.415779 305175 hfize_llama.py:161] loaded layer 10
I0408 02:55:30.713626 305175 hfize_llama.py:161] loaded layer 11
I0408 02:55:30.984691 305175 hfize_llama.py:161] loaded layer 12
I0408 02:55:31.408624 305175 hfize_llama.py:161] loaded layer 13
I0408 02:55:31.750363 305175 hfize_llama.py:161] loaded layer 14
I0408 02:55:32.045024 305175 hfize_llama.py:161] loaded layer 15
I0408 02:55:32.416141 305175 hfize_llama.py:161] loaded layer 16
I0408 02:55:32.731359 305175 hfize_llama.py:161] loaded layer 17
I0408 02:55:33.002475 305175 hfize_llama.py:161] loaded layer 18
I0408 02:55:33.288064 305175 hfize_llama.py:161] loaded layer 19
I0408 02:55:33.579918 305175 hfize_llama.py:161] loaded layer 20
I0408 02:55:33.837958 305175 hfize_llama.py:161] loaded layer 21
I0408 02:55:34.165587 305175 hfize_llama.py:161] loaded layer 22
I0408 02:55:34.438642 305175 hfize_llama.py:161] loaded layer 23
I0408 02:55:34.716000 305175 hfize_llama.py:161] loaded layer 24
I0408 02:55:35.023517 305175 hfize_llama.py:161] loaded layer 25
I0408 02:55:35.277901 305175 hfize_llama.py:161] loaded layer 26
I0408 02:55:35.572967 305175 hfize_llama.py:161] loaded layer 27
I0408 02:55:35.901666 305175 hfize_llama.py:161] loaded layer 28
I0408 02:55:36.178557 305175 hfize_llama.py:161] loaded layer 29
I0408 02:55:36.442186 305175 hfize_llama.py:161] loaded layer 30
I0408 02:55:36.759544 305175 hfize_llama.py:161] loaded layer 31
I0408 02:55:36.759659 305175 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.48s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.14s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.04s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:02,  1.01it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:01,  1.05it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.09it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.25it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]
I0408 02:56:18.152863 305175 hfize_llama.py:175] successfully loaded hfized model
I0408 02:56:23.087379 305972 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0408 02:56:23.087564 305972 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0408 02:56:23.087605 305972 utils.py:162] NumExpr defaulting to 16 threads.
W0408 02:56:23.434329 305972 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0408 02:56:23.819213 305972 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.12s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.05s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.04s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.04s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.03s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.01s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.03it/s]
I0408 02:56:30.708147 305972 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 1.704284906387329:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 1.704284906387329:   1%|          | 1/141 [00:01<04:18,  1.84s/it]avg_loss = 1.9775691032409668:   1%|          | 1/141 [00:03<04:18,  1.84s/it]avg_loss = 1.9775691032409668:   1%|▏         | 2/141 [00:03<03:43,  1.61s/it]avg_loss = 2.1052756309509277:   1%|▏         | 2/141 [00:04<03:43,  1.61s/it]avg_loss = 2.1052756309509277:   2%|▏         | 3/141 [00:04<03:32,  1.54s/it]avg_loss = 2.0518056750297546:   2%|▏         | 3/141 [00:06<03:32,  1.54s/it]avg_loss = 2.0518056750297546:   3%|▎         | 4/141 [00:06<03:26,  1.51s/it]avg_loss = 2.0001893758773805:   3%|▎         | 4/141 [00:07<03:26,  1.51s/it]avg_loss = 2.0001893758773805:   4%|▎         | 5/141 [00:07<03:22,  1.49s/it]avg_loss = 1.9029210805892944:   4%|▎         | 5/141 [00:09<03:22,  1.49s/it]avg_loss = 1.9029210805892944:   4%|▍         | 6/141 [00:09<03:20,  1.48s/it]avg_loss = 1.8410608768463135:   4%|▍         | 6/141 [00:10<03:20,  1.48s/it]avg_loss = 1.8410608768463135:   5%|▍         | 7/141 [00:10<03:18,  1.48s/it]avg_loss = 1.834603264927864:   5%|▍         | 7/141 [00:12<03:18,  1.48s/it] avg_loss = 1.834603264927864:   6%|▌         | 8/141 [00:12<03:16,  1.48s/it]avg_loss = 1.8657236496607463:   6%|▌         | 8/141 [00:13<03:16,  1.48s/it]avg_loss = 1.8657236496607463:   6%|▋         | 9/141 [00:13<03:14,  1.48s/it]avg_loss = 1.8680788040161134:   6%|▋         | 9/141 [00:15<03:14,  1.48s/it]avg_loss = 1.8680788040161134:   7%|▋         | 10/141 [00:15<03:13,  1.48s/it]avg_loss = 1.861140337857333:   7%|▋         | 10/141 [00:16<03:13,  1.48s/it] avg_loss = 1.861140337857333:   8%|▊         | 11/141 [00:16<03:12,  1.48s/it]avg_loss = 1.8839719692866008:   8%|▊         | 11/141 [00:17<03:12,  1.48s/it]avg_loss = 1.8839719692866008:   9%|▊         | 12/141 [00:17<03:11,  1.48s/it]avg_loss = 1.8970357271341176:   9%|▊         | 12/141 [00:19<03:11,  1.48s/it]avg_loss = 1.8970357271341176:   9%|▉         | 13/141 [00:19<03:09,  1.48s/it]avg_loss = 1.9151789460863387:   9%|▉         | 13/141 [00:20<03:09,  1.48s/it]avg_loss = 1.9151789460863387:  10%|▉         | 14/141 [00:20<03:09,  1.49s/it]avg_loss = 1.9250170230865478:  10%|▉         | 14/141 [00:22<03:09,  1.49s/it]avg_loss = 1.9250170230865478:  11%|█         | 15/141 [00:22<03:07,  1.49s/it]avg_loss = 1.9493601769208908:  11%|█         | 15/141 [00:23<03:07,  1.49s/it]avg_loss = 1.9493601769208908:  11%|█▏        | 16/141 [00:23<03:06,  1.49s/it]avg_loss = 1.952151389682994:  11%|█▏        | 16/141 [00:25<03:06,  1.49s/it] avg_loss = 1.952151389682994:  12%|█▏        | 17/141 [00:25<03:05,  1.49s/it]avg_loss = 1.9557395444975958:  12%|█▏        | 17/141 [00:26<03:05,  1.49s/it]avg_loss = 1.9557395444975958:  13%|█▎        | 18/141 [00:26<03:04,  1.50s/it]avg_loss = 1.9429225294213546:  13%|█▎        | 18/141 [00:28<03:04,  1.50s/it]avg_loss = 1.9429225294213546:  13%|█▎        | 19/141 [00:28<03:02,  1.50s/it]avg_loss = 1.9422823309898376:  13%|█▎        | 19/141 [00:29<03:02,  1.50s/it]avg_loss = 1.9422823309898376:  14%|█▍        | 20/141 [00:29<03:01,  1.50s/it]avg_loss = 1.9470566340855189:  14%|█▍        | 20/141 [00:31<03:01,  1.50s/it]avg_loss = 1.9470566340855189:  15%|█▍        | 21/141 [00:31<03:00,  1.50s/it]avg_loss = 1.9491274085911838:  15%|█▍        | 21/141 [00:33<03:00,  1.50s/it]avg_loss = 1.9491274085911838:  16%|█▌        | 22/141 [00:33<02:59,  1.51s/it]avg_loss = 1.9512653609980708:  16%|█▌        | 22/141 [00:34<02:59,  1.51s/it]avg_loss = 1.9512653609980708:  16%|█▋        | 23/141 [00:34<02:58,  1.51s/it]avg_loss = 1.9558433145284653:  16%|█▋        | 23/141 [00:36<02:58,  1.51s/it]avg_loss = 1.9558433145284653:  17%|█▋        | 24/141 [00:36<02:56,  1.51s/it]avg_loss = 1.9613103914260863:  17%|█▋        | 24/141 [00:37<02:56,  1.51s/it]avg_loss = 1.9613103914260863:  18%|█▊        | 25/141 [00:37<02:55,  1.51s/it]avg_loss = 1.9724234663523161:  18%|█▊        | 25/141 [00:39<02:55,  1.51s/it]avg_loss = 1.9724234663523161:  18%|█▊        | 26/141 [00:39<02:54,  1.51s/it]avg_loss = 1.9847649247558028:  18%|█▊        | 26/141 [00:40<02:54,  1.51s/it]avg_loss = 1.9847649247558028:  19%|█▉        | 27/141 [00:40<02:52,  1.51s/it]avg_loss = 1.990674832037517:  19%|█▉        | 27/141 [00:42<02:52,  1.51s/it] avg_loss = 1.990674832037517:  20%|█▉        | 28/141 [00:42<02:51,  1.52s/it]avg_loss = 1.9867205249852147:  20%|█▉        | 28/141 [00:43<02:51,  1.52s/it]avg_loss = 1.9867205249852147:  21%|██        | 29/141 [00:43<02:50,  1.52s/it]avg_loss = 1.9767218708992005:  21%|██        | 29/141 [00:45<02:50,  1.52s/it]avg_loss = 1.9767218708992005:  21%|██▏       | 30/141 [00:45<02:48,  1.52s/it]avg_loss = 1.9637220482672415:  21%|██▏       | 30/141 [00:46<02:48,  1.52s/it]avg_loss = 1.9637220482672415:  22%|██▏       | 31/141 [00:46<02:47,  1.52s/it]avg_loss = 1.9523253254592419:  22%|██▏       | 31/141 [00:48<02:47,  1.52s/it]avg_loss = 1.9523253254592419:  23%|██▎       | 32/141 [00:48<02:46,  1.53s/it]avg_loss = 1.9503657348228223:  23%|██▎       | 32/141 [00:49<02:46,  1.53s/it]avg_loss = 1.9503657348228223:  23%|██▎       | 33/141 [00:49<02:45,  1.53s/it]avg_loss = 1.948970444062177:  23%|██▎       | 33/141 [00:51<02:45,  1.53s/it] avg_loss = 1.948970444062177:  24%|██▍       | 34/141 [00:51<02:43,  1.53s/it]avg_loss = 1.9519142355237689:  24%|██▍       | 34/141 [00:52<02:43,  1.53s/it]avg_loss = 1.9519142355237689:  25%|██▍       | 35/141 [00:52<02:42,  1.53s/it]avg_loss = 1.9348892205291324:  25%|██▍       | 35/141 [00:54<02:42,  1.53s/it]avg_loss = 1.9348892205291324:  26%|██▌       | 36/141 [00:54<02:40,  1.53s/it]avg_loss = 1.918926728738321:  26%|██▌       | 36/141 [00:55<02:40,  1.53s/it] avg_loss = 1.918926728738321:  26%|██▌       | 37/141 [00:55<02:39,  1.53s/it]avg_loss = 1.903532690123508:  26%|██▌       | 37/141 [00:57<02:39,  1.53s/it]avg_loss = 1.903532690123508:  27%|██▋       | 38/141 [00:57<02:37,  1.53s/it]avg_loss = 1.8891599575678508:  27%|██▋       | 38/141 [00:58<02:37,  1.53s/it]avg_loss = 1.8891599575678508:  28%|██▊       | 39/141 [00:58<02:36,  1.53s/it]avg_loss = 1.8801736384630203:  28%|██▊       | 39/141 [01:00<02:36,  1.53s/it]avg_loss = 1.8801736384630203:  28%|██▊       | 40/141 [01:00<02:35,  1.54s/it]avg_loss = 1.885081055687695:  28%|██▊       | 40/141 [01:02<02:35,  1.54s/it] avg_loss = 1.885081055687695:  29%|██▉       | 41/141 [01:02<02:33,  1.54s/it]avg_loss = 1.9014815063703627:  29%|██▉       | 41/141 [01:03<02:33,  1.54s/it]avg_loss = 1.9014815063703627:  30%|██▉       | 42/141 [01:03<02:32,  1.54s/it]avg_loss = 1.9177756836247999:  30%|██▉       | 42/141 [01:05<02:32,  1.54s/it]avg_loss = 1.9177756836247999:  30%|███       | 43/141 [01:05<02:30,  1.54s/it]avg_loss = 1.921972857280211:  30%|███       | 43/141 [01:06<02:30,  1.54s/it] avg_loss = 1.921972857280211:  31%|███       | 44/141 [01:06<02:29,  1.54s/it]avg_loss = 1.926495263311598:  31%|███       | 44/141 [01:08<02:29,  1.54s/it]avg_loss = 1.926495263311598:  32%|███▏      | 45/141 [01:08<02:27,  1.54s/it]avg_loss = 1.9313479273215584:  32%|███▏      | 45/141 [01:09<02:27,  1.54s/it]avg_loss = 1.9313479273215584:  33%|███▎      | 46/141 [01:09<02:26,  1.54s/it]avg_loss = 1.9375932089825894:  33%|███▎      | 46/141 [01:11<02:26,  1.54s/it]avg_loss = 1.9375932089825894:  33%|███▎      | 47/141 [01:11<02:24,  1.54s/it]avg_loss = 1.9409717842936516:  33%|███▎      | 47/141 [01:12<02:24,  1.54s/it]avg_loss = 1.9409717842936516:  34%|███▍      | 48/141 [01:12<02:23,  1.54s/it]avg_loss = 1.9400534508179645:  34%|███▍      | 48/141 [01:14<02:23,  1.54s/it]avg_loss = 1.9400534508179645:  35%|███▍      | 49/141 [01:14<02:22,  1.54s/it]avg_loss = 1.9401264476776123:  35%|███▍      | 49/141 [01:15<02:22,  1.54s/it]avg_loss = 1.9401264476776123:  35%|███▌      | 50/141 [01:15<02:20,  1.55s/it]avg_loss = 1.9339217064427394:  35%|███▌      | 50/141 [01:17<02:20,  1.55s/it]avg_loss = 1.9339217064427394:  36%|███▌      | 51/141 [01:17<02:19,  1.55s/it]avg_loss = 1.9296925411774561:  36%|███▌      | 51/141 [01:19<02:19,  1.55s/it]avg_loss = 1.9296925411774561:  37%|███▋      | 52/141 [01:19<02:17,  1.55s/it]avg_loss = 1.9231239579758554:  37%|███▋      | 52/141 [01:20<02:17,  1.55s/it]avg_loss = 1.9231239579758554:  38%|███▊      | 53/141 [01:20<02:16,  1.55s/it]avg_loss = 1.9197272658348083:  38%|███▊      | 53/141 [01:22<02:16,  1.55s/it]avg_loss = 1.9197272658348083:  38%|███▊      | 54/141 [01:22<02:14,  1.55s/it]avg_loss = 1.9120262080972845:  38%|███▊      | 54/141 [01:23<02:14,  1.55s/it]avg_loss = 1.9120262080972845:  39%|███▉      | 55/141 [01:23<02:13,  1.55s/it]avg_loss = 1.9041019018207277:  39%|███▉      | 55/141 [01:25<02:13,  1.55s/it]avg_loss = 1.9041019018207277:  40%|███▉      | 56/141 [01:25<02:11,  1.55s/it]avg_loss = 1.8993074392017566:  40%|███▉      | 56/141 [01:26<02:11,  1.55s/it]avg_loss = 1.8993074392017566:  40%|████      | 57/141 [01:26<02:10,  1.55s/it]avg_loss = 1.8962945444830532:  40%|████      | 57/141 [01:28<02:10,  1.55s/it]avg_loss = 1.8962945444830532:  41%|████      | 58/141 [01:28<02:08,  1.55s/it]avg_loss = 1.898366802829807:  41%|████      | 58/141 [01:29<02:08,  1.55s/it] avg_loss = 1.898366802829807:  42%|████▏     | 59/141 [01:29<02:07,  1.55s/it]avg_loss = 1.9037421464920044:  42%|████▏     | 59/141 [01:31<02:07,  1.55s/it]avg_loss = 1.9037421464920044:  43%|████▎     | 60/141 [01:31<02:06,  1.56s/it]avg_loss = 1.9092028649126898:  43%|████▎     | 60/141 [01:33<02:06,  1.56s/it]avg_loss = 1.9092028649126898:  43%|████▎     | 61/141 [01:33<02:04,  1.56s/it]avg_loss = 1.9162057368986067:  43%|████▎     | 61/141 [01:34<02:04,  1.56s/it]avg_loss = 1.9162057368986067:  44%|████▍     | 62/141 [01:34<02:03,  1.56s/it]avg_loss = 1.9074034936844357:  44%|████▍     | 62/141 [01:36<02:03,  1.56s/it]avg_loss = 1.9074034936844357:  45%|████▍     | 63/141 [01:36<02:01,  1.56s/it]avg_loss = 1.905221313238144:  45%|████▍     | 63/141 [01:37<02:01,  1.56s/it] avg_loss = 1.905221313238144:  45%|████▌     | 64/141 [01:37<02:00,  1.56s/it]avg_loss = 1.9027150355852567:  45%|████▌     | 64/141 [01:39<02:00,  1.56s/it]avg_loss = 1.9027150355852567:  46%|████▌     | 65/141 [01:39<01:58,  1.56s/it]avg_loss = 1.8968153577862363:  46%|████▌     | 65/141 [01:40<01:58,  1.56s/it]avg_loss = 1.8968153577862363:  47%|████▋     | 66/141 [01:40<01:57,  1.56s/it]avg_loss = 1.8943713298484461:  47%|████▋     | 66/141 [01:42<01:57,  1.56s/it]avg_loss = 1.8943713298484461:  48%|████▊     | 67/141 [01:42<01:55,  1.56s/it]avg_loss = 1.8914614565232222:  48%|████▊     | 67/141 [01:43<01:55,  1.56s/it]avg_loss = 1.8914614565232222:  48%|████▊     | 68/141 [01:43<01:53,  1.56s/it]avg_loss = 1.888637976369996:  48%|████▊     | 68/141 [01:45<01:53,  1.56s/it] avg_loss = 1.888637976369996:  49%|████▉     | 69/141 [01:45<01:52,  1.56s/it]avg_loss = 1.8894945689610072:  49%|████▉     | 69/141 [01:47<01:52,  1.56s/it]avg_loss = 1.8894945689610072:  50%|████▉     | 70/141 [01:47<01:50,  1.56s/it]avg_loss = 1.8930994289022096:  50%|████▉     | 70/141 [01:48<01:50,  1.56s/it]avg_loss = 1.8930994289022096:  50%|█████     | 71/141 [01:48<01:49,  1.56s/it]avg_loss = 1.895724160803689:  50%|█████     | 71/141 [01:50<01:49,  1.56s/it] avg_loss = 1.895724160803689:  51%|█████     | 72/141 [01:50<01:47,  1.56s/it]avg_loss = 1.8941738393208751:  51%|█████     | 72/141 [01:51<01:47,  1.56s/it]avg_loss = 1.8941738393208751:  52%|█████▏    | 73/141 [01:51<01:46,  1.56s/it]avg_loss = 1.8957320886689264:  52%|█████▏    | 73/141 [01:53<01:46,  1.56s/it]avg_loss = 1.8957320886689264:  52%|█████▏    | 74/141 [01:53<01:44,  1.56s/it]avg_loss = 1.8958612219492594:  52%|█████▏    | 74/141 [01:54<01:44,  1.56s/it]avg_loss = 1.8958612219492594:  53%|█████▎    | 75/141 [01:54<01:43,  1.56s/it]avg_loss = 1.8946112488445483:  53%|█████▎    | 75/141 [01:56<01:43,  1.56s/it]avg_loss = 1.8946112488445483:  54%|█████▍    | 76/141 [01:56<01:41,  1.57s/it]avg_loss = 1.8956981773500319:  54%|█████▍    | 76/141 [01:58<01:41,  1.57s/it]avg_loss = 1.8956981773500319:  55%|█████▍    | 77/141 [01:58<01:40,  1.57s/it]avg_loss = 1.8981985938854706:  55%|█████▍    | 77/141 [01:59<01:40,  1.57s/it]avg_loss = 1.8981985938854706:  55%|█████▌    | 78/141 [01:59<01:38,  1.57s/it]avg_loss = 1.9020823542075822:  55%|█████▌    | 78/141 [02:01<01:38,  1.57s/it]avg_loss = 1.9020823542075822:  56%|█████▌    | 79/141 [02:01<01:37,  1.57s/it]avg_loss = 1.8988485604524612:  56%|█████▌    | 79/141 [02:02<01:37,  1.57s/it]avg_loss = 1.8988485604524612:  57%|█████▋    | 80/141 [02:02<01:35,  1.57s/it]avg_loss = 1.897510337240902:  57%|█████▋    | 80/141 [02:04<01:35,  1.57s/it] avg_loss = 1.897510337240902:  57%|█████▋    | 81/141 [02:04<01:34,  1.57s/it]avg_loss = 1.8966549823923808:  57%|█████▋    | 81/141 [02:05<01:34,  1.57s/it]avg_loss = 1.8966549823923808:  58%|█████▊    | 82/141 [02:05<01:32,  1.57s/it]avg_loss = 1.8949116899306515:  58%|█████▊    | 82/141 [02:07<01:32,  1.57s/it]avg_loss = 1.8949116899306515:  59%|█████▉    | 83/141 [02:07<01:31,  1.58s/it]avg_loss = 1.8924526671568553:  59%|█████▉    | 83/141 [02:09<01:31,  1.58s/it]avg_loss = 1.8924526671568553:  60%|█████▉    | 84/141 [02:09<01:29,  1.58s/it]avg_loss = 1.889915436856887:  60%|█████▉    | 84/141 [02:10<01:29,  1.58s/it] avg_loss = 1.889915436856887:  60%|██████    | 85/141 [02:10<01:28,  1.58s/it]avg_loss = 1.8914112143738324:  60%|██████    | 85/141 [02:12<01:28,  1.58s/it]avg_loss = 1.8914112143738324:  61%|██████    | 86/141 [02:12<01:26,  1.58s/it]avg_loss = 1.8931608323393196:  61%|██████    | 86/141 [02:13<01:26,  1.58s/it]avg_loss = 1.8931608323393196:  62%|██████▏   | 87/141 [02:13<01:25,  1.58s/it]avg_loss = 1.8941384621641852:  62%|██████▏   | 87/141 [02:15<01:25,  1.58s/it]avg_loss = 1.8941384621641852:  62%|██████▏   | 88/141 [02:15<01:23,  1.57s/it]avg_loss = 1.9028201384490795:  62%|██████▏   | 88/141 [02:16<01:23,  1.57s/it]avg_loss = 1.9028201384490795:  63%|██████▎   | 89/141 [02:16<01:21,  1.57s/it]avg_loss = 1.9103875093989902:  63%|██████▎   | 89/141 [02:18<01:21,  1.57s/it]avg_loss = 1.9103875093989902:  64%|██████▍   | 90/141 [02:18<01:20,  1.57s/it]avg_loss = 1.9133696411992167:  64%|██████▍   | 90/141 [02:20<01:20,  1.57s/it]avg_loss = 1.9133696411992167:  65%|██████▍   | 91/141 [02:20<01:18,  1.57s/it]avg_loss = 1.9184762330158898:  65%|██████▍   | 91/141 [02:21<01:18,  1.57s/it]avg_loss = 1.9184762330158898:  65%|██████▌   | 92/141 [02:21<01:17,  1.58s/it]avg_loss = 1.9236353353787494:  65%|██████▌   | 92/141 [02:23<01:17,  1.58s/it]avg_loss = 1.9236353353787494:  66%|██████▌   | 93/141 [02:23<01:15,  1.58s/it]avg_loss = 1.924543135977806:  66%|██████▌   | 93/141 [02:24<01:15,  1.58s/it] avg_loss = 1.924543135977806:  67%|██████▋   | 94/141 [02:24<01:14,  1.58s/it]avg_loss = 1.9281132560027272:  67%|██████▋   | 94/141 [02:26<01:14,  1.58s/it]avg_loss = 1.9281132560027272:  67%|██████▋   | 95/141 [02:26<01:12,  1.58s/it]avg_loss = 1.9289212288955848:  67%|██████▋   | 95/141 [02:27<01:12,  1.58s/it]avg_loss = 1.9289212288955848:  68%|██████▊   | 96/141 [02:27<01:10,  1.58s/it]avg_loss = 1.9306857008294962:  68%|██████▊   | 96/141 [02:29<01:10,  1.58s/it]avg_loss = 1.9306857008294962:  69%|██████▉   | 97/141 [02:29<01:09,  1.58s/it]avg_loss = 1.927438422125213:  69%|██████▉   | 97/141 [02:31<01:09,  1.58s/it] avg_loss = 1.927438422125213:  70%|██████▉   | 98/141 [02:31<01:07,  1.58s/it]avg_loss = 1.9285794364081488:  70%|██████▉   | 98/141 [02:32<01:07,  1.58s/it]avg_loss = 1.9285794364081488:  70%|███████   | 99/141 [02:32<01:06,  1.58s/it]avg_loss = 1.930798761844635:  70%|███████   | 99/141 [02:34<01:06,  1.58s/it] avg_loss = 1.930798761844635:  71%|███████   | 100/141 [02:34<01:04,  1.58s/it]avg_loss = 1.9298724254759232:  71%|███████   | 100/141 [02:35<01:04,  1.58s/it]avg_loss = 1.9298724254759232:  72%|███████▏  | 101/141 [02:35<01:03,  1.58s/it]avg_loss = 1.9302407538189608:  72%|███████▏  | 101/141 [02:37<01:03,  1.58s/it]avg_loss = 1.9302407538189608:  72%|███████▏  | 102/141 [02:37<01:01,  1.58s/it]avg_loss = 1.928994177614601:  72%|███████▏  | 102/141 [02:39<01:01,  1.58s/it] avg_loss = 1.928994177614601:  73%|███████▎  | 103/141 [02:39<01:00,  1.58s/it]avg_loss = 1.9319684012578084:  73%|███████▎  | 103/141 [02:40<01:00,  1.58s/it]avg_loss = 1.9319684012578084:  74%|███████▍  | 104/141 [02:40<00:58,  1.58s/it]avg_loss = 1.9310030153819493:  74%|███████▍  | 104/141 [02:42<00:58,  1.58s/it]avg_loss = 1.9310030153819493:  74%|███████▍  | 105/141 [02:42<00:56,  1.58s/it]avg_loss = 1.9302122660402983:  74%|███████▍  | 105/141 [02:43<00:56,  1.58s/it]avg_loss = 1.9302122660402983:  75%|███████▌  | 106/141 [02:43<00:55,  1.58s/it]avg_loss = 1.9279264868976913:  75%|███████▌  | 106/141 [02:45<00:55,  1.58s/it]avg_loss = 1.9279264868976913:  76%|███████▌  | 107/141 [02:45<00:53,  1.58s/it]avg_loss = 1.9256641025896426:  76%|███████▌  | 107/141 [02:46<00:53,  1.58s/it]avg_loss = 1.9256641025896426:  77%|███████▋  | 108/141 [02:46<00:52,  1.58s/it]avg_loss = 1.9234578467290335:  77%|███████▋  | 108/141 [02:48<00:52,  1.58s/it]avg_loss = 1.9234578467290335:  77%|███████▋  | 109/141 [02:48<00:50,  1.58s/it]avg_loss = 1.9210066686977039:  77%|███████▋  | 109/141 [02:50<00:50,  1.58s/it]avg_loss = 1.9210066686977039:  78%|███████▊  | 110/141 [02:50<00:48,  1.58s/it]avg_loss = 1.9233464786598273:  78%|███████▊  | 110/141 [02:51<00:48,  1.58s/it]avg_loss = 1.9233464786598273:  79%|███████▊  | 111/141 [02:51<00:47,  1.58s/it]avg_loss = 1.9231023735233717:  79%|███████▊  | 111/141 [02:53<00:47,  1.58s/it]avg_loss = 1.9231023735233717:  79%|███████▉  | 112/141 [02:53<00:45,  1.58s/it]avg_loss = 1.9242119905167976:  79%|███████▉  | 112/141 [02:54<00:45,  1.58s/it]avg_loss = 1.9242119905167976:  80%|████████  | 113/141 [02:54<00:44,  1.58s/it]avg_loss = 1.925141806142372:  80%|████████  | 113/141 [02:56<00:44,  1.58s/it] avg_loss = 1.925141806142372:  81%|████████  | 114/141 [02:56<00:42,  1.58s/it]avg_loss = 1.9241958483405734:  81%|████████  | 114/141 [02:57<00:42,  1.58s/it]avg_loss = 1.9241958483405734:  82%|████████▏ | 115/141 [02:57<00:41,  1.58s/it]avg_loss = 1.9229682694221366:  82%|████████▏ | 115/141 [02:59<00:41,  1.58s/it]avg_loss = 1.9229682694221366:  82%|████████▏ | 116/141 [02:59<00:39,  1.58s/it]avg_loss = 1.925188493524861:  82%|████████▏ | 116/141 [03:01<00:39,  1.58s/it] avg_loss = 1.925188493524861:  83%|████████▎ | 117/141 [03:01<00:37,  1.58s/it]avg_loss = 1.9247281399823852:  83%|████████▎ | 117/141 [03:02<00:37,  1.58s/it]avg_loss = 1.9247281399823852:  84%|████████▎ | 118/141 [03:02<00:36,  1.58s/it]avg_loss = 1.9232944470493734:  84%|████████▎ | 118/141 [03:04<00:36,  1.58s/it]avg_loss = 1.9232944470493734:  84%|████████▍ | 119/141 [03:04<00:34,  1.58s/it]avg_loss = 1.921468452612559:  84%|████████▍ | 119/141 [03:05<00:34,  1.58s/it] avg_loss = 1.921468452612559:  85%|████████▌ | 120/141 [03:05<00:33,  1.58s/it]avg_loss = 1.9212478330312681:  85%|████████▌ | 120/141 [03:07<00:33,  1.58s/it]avg_loss = 1.9212478330312681:  86%|████████▌ | 121/141 [03:07<00:31,  1.58s/it]avg_loss = 1.9217024562788791:  86%|████████▌ | 121/141 [03:09<00:31,  1.58s/it]avg_loss = 1.9217024562788791:  87%|████████▋ | 122/141 [03:09<00:30,  1.58s/it]avg_loss = 1.9214616267661737:  87%|████████▋ | 122/141 [03:10<00:30,  1.58s/it]avg_loss = 1.9214616267661737:  87%|████████▋ | 123/141 [03:10<00:28,  1.58s/it]avg_loss = 1.9215309687199131:  87%|████████▋ | 123/141 [03:12<00:28,  1.58s/it]avg_loss = 1.9215309687199131:  88%|████████▊ | 124/141 [03:12<00:26,  1.58s/it]avg_loss = 1.9202464628219604:  88%|████████▊ | 124/141 [03:13<00:26,  1.58s/it]avg_loss = 1.9202464628219604:  89%|████████▊ | 125/141 [03:13<00:25,  1.58s/it]avg_loss = 1.9205889115257868:  89%|████████▊ | 125/141 [03:15<00:25,  1.58s/it]avg_loss = 1.9205889115257868:  89%|████████▉ | 126/141 [03:15<00:23,  1.58s/it]avg_loss = 1.9202108401951827:  89%|████████▉ | 126/141 [03:16<00:23,  1.58s/it]avg_loss = 1.9202108401951827:  90%|█████████ | 127/141 [03:16<00:22,  1.58s/it]avg_loss = 1.9189310986548662:  90%|█████████ | 127/141 [03:18<00:22,  1.58s/it]avg_loss = 1.9189310986548662:  91%|█████████ | 128/141 [03:18<00:20,  1.58s/it]avg_loss = 1.9190143587053283:  91%|█████████ | 128/141 [03:20<00:20,  1.58s/it]avg_loss = 1.9190143587053283:  91%|█████████▏| 129/141 [03:20<00:18,  1.58s/it]avg_loss = 1.919692522745866:  91%|█████████▏| 129/141 [03:21<00:18,  1.58s/it] avg_loss = 1.919692522745866:  92%|█████████▏| 130/141 [03:21<00:17,  1.58s/it]avg_loss = 1.9207065660534923:  92%|█████████▏| 130/141 [03:23<00:17,  1.58s/it]avg_loss = 1.9207065660534923:  93%|█████████▎| 131/141 [03:23<00:15,  1.58s/it]avg_loss = 1.921185525077762:  93%|█████████▎| 131/141 [03:24<00:15,  1.58s/it] avg_loss = 1.921185525077762:  94%|█████████▎| 132/141 [03:24<00:14,  1.58s/it]avg_loss = 1.9181075965551506:  94%|█████████▎| 132/141 [03:26<00:14,  1.58s/it]avg_loss = 1.9181075965551506:  94%|█████████▍| 133/141 [03:26<00:12,  1.58s/it]avg_loss = 1.9135699894890856:  94%|█████████▍| 133/141 [03:28<00:12,  1.58s/it]avg_loss = 1.9135699894890856:  95%|█████████▌| 134/141 [03:28<00:11,  1.58s/it]avg_loss = 1.9159870836469861:  95%|█████████▌| 134/141 [03:29<00:11,  1.58s/it]avg_loss = 1.9159870836469861:  96%|█████████▌| 135/141 [03:29<00:09,  1.58s/it]avg_loss = 1.9194876306197222:  96%|█████████▌| 135/141 [03:31<00:09,  1.58s/it]avg_loss = 1.9194876306197222:  96%|█████████▋| 136/141 [03:31<00:07,  1.58s/it]avg_loss = 1.9207832412998171:  96%|█████████▋| 136/141 [03:32<00:07,  1.58s/it]avg_loss = 1.9207832412998171:  97%|█████████▋| 137/141 [03:32<00:06,  1.58s/it]avg_loss = 1.9195329270501067:  97%|█████████▋| 137/141 [03:34<00:06,  1.58s/it]avg_loss = 1.9195329270501067:  98%|█████████▊| 138/141 [03:34<00:04,  1.58s/it]avg_loss = 1.9197668806254435:  98%|█████████▊| 138/141 [03:35<00:04,  1.58s/it]avg_loss = 1.9197668806254435:  99%|█████████▊| 139/141 [03:35<00:03,  1.58s/it]avg_loss = 1.9205466440745762:  99%|█████████▊| 139/141 [03:37<00:03,  1.58s/it]avg_loss = 1.9205466440745762:  99%|█████████▉| 140/141 [03:37<00:01,  1.58s/it]avg_loss = 1.9217121634922973:  99%|█████████▉| 140/141 [03:39<00:01,  1.58s/it]avg_loss = 1.9217121634922973: 100%|██████████| 141/141 [03:39<00:00,  1.58s/it]avg_loss = 1.9217121634922973: 100%|██████████| 141/141 [03:39<00:00,  1.55s/it]
I0408 03:00:34.754483 305972 eval_ppl.py:107] wikitext2 perplexity: 6.83264684677124
wikitext2 perplexity: 6.833
