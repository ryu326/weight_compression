I0325 15:20:29.658497 855355 config.py:54] PyTorch version 2.6.0 available.
W0325 15:20:29.960777 855355 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:20:30.926820 855355 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.32it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.11it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.47it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.71it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.81it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.92it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.99it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.72it/s]
I0325 15:20:32.443748 855355 quantize_finetune_llama.py:150] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:00<00:00, 15448.63it/s]
I0325 15:20:36.946860 855355 quantize_finetune_llama.py:185] loaded compression model
I0325 15:20:55.668422 855355 quantize_finetune_llama.py:189] loaded dataset and devset
I0325 15:20:57.825705 855355 quantize_finetune_llama.py:209] layer 0 gpu 0
I0325 15:21:01.166218 855355 quantize_finetune_llama.py:240] computed original embedding for layer 0 in 3.2072412967681885s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0325 15:21:14.015947 856068 config.py:54] PyTorch version 2.6.0 available.
W0325 15:21:14.322633 856068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:21:15.250425 856068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:21:15.254552 855355 quantize_finetune_llama.py:209] layer 1 gpu 0
I0325 15:21:15.267565 856068 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.2263733595609665 tr(WHW.T) 60.88684844970703
bpp_loss 2.3689017295837402
0_q proxy err 0.00035189976915717125 tr(WHW.T) 288094.65625
bpp_loss 3.142915964126587
0_k proxy err 0.0002728318504523486 tr(WHW.T) 100180.734375
bpp_loss 3.7105348110198975
0_o proxy err 0.018243243917822838 tr(WHW.T) 3123.217529296875
bpp_loss 2.4375383853912354
0_up proxy err 0.024389658123254776 tr(WHW.T) 8924.451171875
bpp_loss 2.736821617398943
0_gate proxy err 0.014349127188324928 tr(WHW.T) 15778.666015625
bpp_loss 2.8393376214163646
0_down proxy err 0.02000090666115284 tr(WHW.T) 10818.205078125
bpp_loss 2.7298033578055247
I0325 15:22:09.141787 855355 quantize_finetune_llama.py:240] computed original embedding for layer 1 in 0.8338749408721924s
I0325 15:22:12.551545 856809 config.py:54] PyTorch version 2.6.0 available.
W0325 15:22:12.848539 856809 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:22:13.763104 856809 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:22:13.767143 855355 quantize_finetune_llama.py:209] layer 2 gpu 0
I0325 15:22:13.780200 856809 data_utils.py:336] using 256 training seqs, 128 validation seqs
1_v proxy err 0.12754474580287933 tr(WHW.T) 109.07096099853516
bpp_loss 2.475299596786499
1_q proxy err 0.0008211824460886419 tr(WHW.T) 144826.484375
bpp_loss 3.385319232940674
1_k proxy err 0.00043802449363283813 tr(WHW.T) 75539.046875
bpp_loss 4.051069736480713
1_o proxy err 0.02922194078564644 tr(WHW.T) 1983.8321533203125
bpp_loss 2.518936038017273
1_up proxy err 0.026403512805700302 tr(WHW.T) 8230.8203125
bpp_loss 2.752472298485892
1_gate proxy err 0.016166329383850098 tr(WHW.T) 13952.365234375
bpp_loss 2.857765163694109
1_down proxy err 0.01517237164080143 tr(WHW.T) 13978.03125
bpp_loss 2.748213495526995
I0325 15:23:07.470928 855355 quantize_finetune_llama.py:240] computed original embedding for layer 2 in 0.8295648097991943s
I0325 15:23:10.888156 857554 config.py:54] PyTorch version 2.6.0 available.
W0325 15:23:11.183023 857554 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:23:12.083625 857554 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:23:12.087714 855355 quantize_finetune_llama.py:209] layer 3 gpu 0
I0325 15:23:12.101098 857554 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.0892791897058487 tr(WHW.T) 155.95950317382812
bpp_loss 2.3741753101348877
2_q proxy err 0.0020717927254736423 tr(WHW.T) 41475.15625
bpp_loss 3.373378276824951
2_k proxy err 0.0011642975732684135 tr(WHW.T) 22614.533203125
bpp_loss 4.200467586517334
2_o proxy err 0.029204202815890312 tr(WHW.T) 1967.3226318359375
bpp_loss 2.4690890312194824
2_up proxy err 0.02854795940220356 tr(WHW.T) 7600.474609375
bpp_loss 2.7482948984418596
2_gate proxy err 0.015074764378368855 tr(WHW.T) 15113.31640625
bpp_loss 2.892446688243321
2_down proxy err 0.028057541698217392 tr(WHW.T) 7726.72509765625
bpp_loss 2.7510074887956892
I0325 15:24:06.089235 855355 quantize_finetune_llama.py:240] computed original embedding for layer 3 in 0.8107807636260986s
I0325 15:24:09.494443 858299 config.py:54] PyTorch version 2.6.0 available.
W0325 15:24:09.791931 858299 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:24:10.735622 858299 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:24:10.739480 855355 quantize_finetune_llama.py:209] layer 4 gpu 0
I0325 15:24:10.760653 858299 data_utils.py:336] using 256 training seqs, 128 validation seqs
3_v proxy err 0.04976136237382889 tr(WHW.T) 289.3331604003906
bpp_loss 2.474210739135742
3_q proxy err 0.001810961402952671 tr(WHW.T) 47576.9296875
bpp_loss 3.4086947441101074
3_k proxy err 0.0009748981683515012 tr(WHW.T) 26174.515625
bpp_loss 4.281251907348633
3_o proxy err 0.03170834854245186 tr(WHW.T) 1857.15771484375
bpp_loss 2.5746753215789795
3_up proxy err 0.028646942228078842 tr(WHW.T) 7536.46484375
bpp_loss 2.7282541479383196
3_gate proxy err 0.011237279511988163 tr(WHW.T) 20884.34765625
bpp_loss 2.9645771299089705
3_down proxy err 0.030746180564165115 tr(WHW.T) 6998.6103515625
bpp_loss 2.7255678176879883
I0325 15:25:04.751644 855355 quantize_finetune_llama.py:240] computed original embedding for layer 4 in 0.8061964511871338s
I0325 15:25:08.284703 859028 config.py:54] PyTorch version 2.6.0 available.
W0325 15:25:08.577075 859028 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:25:09.508165 859028 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:25:09.512370 855355 quantize_finetune_llama.py:209] layer 5 gpu 0
I0325 15:25:09.526778 859028 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.05062813311815262 tr(WHW.T) 285.30712890625
bpp_loss 2.525714874267578
4_q proxy err 0.0017119921976700425 tr(WHW.T) 50114.859375
bpp_loss 3.372502565383911
4_k proxy err 0.0008934821817092597 tr(WHW.T) 29301.974609375
bpp_loss 4.256523609161377
4_o proxy err 0.045016635209321976 tr(WHW.T) 1297.2481689453125
bpp_loss 2.5877933502197266
4_up proxy err 0.029072534292936325 tr(WHW.T) 7383.48779296875
bpp_loss 2.700825963701521
4_gate proxy err 0.00833516288548708 tr(WHW.T) 29130.974609375
bpp_loss 3.035025324140276
4_down proxy err 0.03341306746006012 tr(WHW.T) 6395.72265625
bpp_loss 2.6986799240112305
I0325 15:26:03.378802 855355 quantize_finetune_llama.py:240] computed original embedding for layer 5 in 0.8211076259613037s
I0325 15:26:06.925509 859755 config.py:54] PyTorch version 2.6.0 available.
W0325 15:26:07.223187 859755 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:26:08.158644 859755 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:26:08.162671 855355 quantize_finetune_llama.py:209] layer 6 gpu 0
I0325 15:26:08.176711 859755 data_utils.py:336] using 256 training seqs, 128 validation seqs
5_v proxy err 0.06795042753219604 tr(WHW.T) 208.81988525390625
bpp_loss 2.4066851139068604
5_q proxy err 0.002259570173919201 tr(WHW.T) 35991.625
bpp_loss 3.3557960987091064
5_k proxy err 0.0010725418105721474 tr(WHW.T) 22997.75390625
bpp_loss 4.238964080810547
5_o proxy err 0.054972413927316666 tr(WHW.T) 1055.5865478515625
bpp_loss 2.5294896364212036
5_up proxy err 0.02807128243148327 tr(WHW.T) 7656.43310546875
bpp_loss 2.7073898315429688
5_gate proxy err 0.00802215188741684 tr(WHW.T) 30386.947265625
bpp_loss 3.0382140363965715
5_down proxy err 0.03336314857006073 tr(WHW.T) 6411.12939453125
bpp_loss 2.7031706401279996
I0325 15:27:02.099503 855355 quantize_finetune_llama.py:240] computed original embedding for layer 6 in 0.8202013969421387s
I0325 15:27:05.595485 860499 config.py:54] PyTorch version 2.6.0 available.
W0325 15:27:05.889746 860499 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:27:06.786869 860499 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:27:06.791019 855355 quantize_finetune_llama.py:209] layer 7 gpu 0
I0325 15:27:06.811477 860499 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.05674523115158081 tr(WHW.T) 253.63377380371094
bpp_loss 2.457477331161499
6_q proxy err 0.002315283054485917 tr(WHW.T) 35639.5859375
bpp_loss 3.405282497406006
6_k proxy err 0.0009577882010489702 tr(WHW.T) 26163.654296875
bpp_loss 4.307061195373535
6_o proxy err 0.05796562135219574 tr(WHW.T) 1009.1483764648438
bpp_loss 2.5645984411239624
6_up proxy err 0.02715705893933773 tr(WHW.T) 7923.53564453125
bpp_loss 2.7072926930018832
6_gate proxy err 0.006898219231516123 tr(WHW.T) 35748.39453125
bpp_loss 3.0417584351130893
6_down proxy err 0.0329621285200119 tr(WHW.T) 6483.5595703125
bpp_loss 2.7021630150931224
I0325 15:28:00.786666 855355 quantize_finetune_llama.py:240] computed original embedding for layer 7 in 0.8220500946044922s
I0325 15:28:04.312374 861247 config.py:54] PyTorch version 2.6.0 available.
W0325 15:28:04.598234 861247 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:28:05.516067 861247 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:28:05.520153 855355 quantize_finetune_llama.py:209] layer 8 gpu 0
I0325 15:28:05.533241 861247 data_utils.py:336] using 256 training seqs, 128 validation seqs
7_v proxy err 0.04660879075527191 tr(WHW.T) 309.4270935058594
bpp_loss 2.4520163536071777
7_q proxy err 0.0023082694970071316 tr(WHW.T) 35144.953125
bpp_loss 3.332499861717224
7_k proxy err 0.0009591359994374216 tr(WHW.T) 26850.4921875
bpp_loss 4.336081504821777
7_o proxy err 0.06105678528547287 tr(WHW.T) 959.2155151367188
bpp_loss 2.5763484239578247
7_up proxy err 0.02509263902902603 tr(WHW.T) 8627.4501953125
bpp_loss 2.7208375930786133
7_gate proxy err 0.007023178972303867 tr(WHW.T) 34903.53515625
bpp_loss 3.012641293661935
7_down proxy err 0.03278280049562454 tr(WHW.T) 6534.6279296875
bpp_loss 2.7151031494140625
I0325 15:28:59.350770 855355 quantize_finetune_llama.py:240] computed original embedding for layer 8 in 1.0516867637634277s
I0325 15:29:02.833070 861989 config.py:54] PyTorch version 2.6.0 available.
W0325 15:29:03.126014 861989 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:29:04.075737 861989 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:29:04.079810 855355 quantize_finetune_llama.py:209] layer 9 gpu 0
I0325 15:29:04.093003 861989 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.055487699806690216 tr(WHW.T) 257.7052307128906
bpp_loss 2.4792003631591797
8_q proxy err 0.00292194657959044 tr(WHW.T) 26600.9765625
bpp_loss 3.31958544254303
8_k proxy err 0.0010599959641695023 tr(WHW.T) 22528.748046875
bpp_loss 4.247509956359863
8_o proxy err 0.07861250638961792 tr(WHW.T) 745.6061401367188
bpp_loss 2.589345693588257
8_up proxy err 0.025434277951717377 tr(WHW.T) 8495.0546875
bpp_loss 2.7164454460144043
8_gate proxy err 0.006594861391931772 tr(WHW.T) 37238.1484375
bpp_loss 3.016397135598319
8_down proxy err 0.032993417233228683 tr(WHW.T) 6488.8173828125
bpp_loss 2.711489677429199
I0325 15:29:57.925471 855355 quantize_finetune_llama.py:240] computed original embedding for layer 9 in 0.7964625358581543s
I0325 15:30:01.306914 862721 config.py:54] PyTorch version 2.6.0 available.
W0325 15:30:01.604171 862721 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:30:02.603150 862721 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:30:02.607142 855355 quantize_finetune_llama.py:209] layer 10 gpu 0
I0325 15:30:02.620182 862721 data_utils.py:336] using 256 training seqs, 128 validation seqs
9_v proxy err 0.04245695844292641 tr(WHW.T) 351.4288024902344
bpp_loss 2.583117723464966
9_q proxy err 0.003006336744874716 tr(WHW.T) 25653.232421875
bpp_loss 3.327823519706726
9_k proxy err 0.0011317043099552393 tr(WHW.T) 20942.638671875
bpp_loss 4.2660417556762695
9_o proxy err 0.07612712681293488 tr(WHW.T) 776.6017456054688
bpp_loss 2.646595001220703
9_up proxy err 0.024180175736546516 tr(WHW.T) 8970.6455078125
bpp_loss 2.725099495479039
9_gate proxy err 0.006255241110920906 tr(WHW.T) 39415.71875
bpp_loss 3.0295540264674594
9_down proxy err 0.03416125103831291 tr(WHW.T) 6272.90380859375
bpp_loss 2.7145118713378906
I0325 15:30:56.523082 855355 quantize_finetune_llama.py:240] computed original embedding for layer 10 in 0.8730816841125488s
I0325 15:30:59.976453 863468 config.py:54] PyTorch version 2.6.0 available.
W0325 15:31:00.272604 863468 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:31:01.208372 863468 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:31:01.212396 855355 quantize_finetune_llama.py:209] layer 11 gpu 0
I0325 15:31:01.225879 863468 data_utils.py:336] using 256 training seqs, 128 validation seqs
10_v proxy err 0.056755922734737396 tr(WHW.T) 251.83889770507812
bpp_loss 2.470085382461548
10_q proxy err 0.003284586826339364 tr(WHW.T) 23338.15625
bpp_loss 3.336669087409973
10_k proxy err 0.0012077681021764874 tr(WHW.T) 19743.95703125
bpp_loss 4.272884368896484
10_o proxy err 0.08580398559570312 tr(WHW.T) 680.6640625
bpp_loss 2.5802568197250366
10_up proxy err 0.023701103404164314 tr(WHW.T) 9199.1572265625
bpp_loss 2.7424569811139787
10_gate proxy err 0.006528008263558149 tr(WHW.T) 37399.37109375
bpp_loss 2.9988112109048024
10_down proxy err 0.032893143594264984 tr(WHW.T) 6525.2333984375
bpp_loss 2.7295171192714145
I0325 15:31:55.068293 855355 quantize_finetune_llama.py:240] computed original embedding for layer 11 in 0.906003475189209s
I0325 15:31:58.609033 864209 config.py:54] PyTorch version 2.6.0 available.
W0325 15:31:58.909626 864209 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:31:59.847751 864209 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:31:59.852433 855355 quantize_finetune_llama.py:209] layer 12 gpu 0
I0325 15:31:59.868169 864209 data_utils.py:336] using 256 training seqs, 128 validation seqs
11_v proxy err 0.04514013230800629 tr(WHW.T) 319.5691223144531
bpp_loss 2.4690701961517334
11_q proxy err 0.0034374617971479893 tr(WHW.T) 22190.8984375
bpp_loss 3.2737492322921753
11_k proxy err 0.0013133017346262932 tr(WHW.T) 18027.423828125
bpp_loss 4.273093223571777
11_o proxy err 0.10310608893632889 tr(WHW.T) 565.9476928710938
bpp_loss 2.5993236303329468
11_up proxy err 0.023715194314718246 tr(WHW.T) 9192.595703125
bpp_loss 2.748963321958269
11_gate proxy err 0.006598440930247307 tr(WHW.T) 36884.09375
bpp_loss 2.9786629676818848
11_down proxy err 0.032357700169086456 tr(WHW.T) 6655.890625
bpp_loss 2.736910138811384
I0325 15:32:55.368315 855355 quantize_finetune_llama.py:240] computed original embedding for layer 12 in 1.1008810997009277s
I0325 15:32:58.893060 864982 config.py:54] PyTorch version 2.6.0 available.
W0325 15:32:59.204035 864982 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:33:00.155605 864982 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:33:00.159712 855355 quantize_finetune_llama.py:209] layer 13 gpu 0
I0325 15:33:00.180245 864982 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.04050388187170029 tr(WHW.T) 363.6233825683594
bpp_loss 2.5923526287078857
12_q proxy err 0.002344670705497265 tr(WHW.T) 34102.625
bpp_loss 3.32818067073822
12_k proxy err 0.0010580834932625294 tr(WHW.T) 23057.041015625
bpp_loss 4.267986297607422
12_o proxy err 0.0756911039352417 tr(WHW.T) 779.7713012695312
bpp_loss 2.651024580001831
12_up proxy err 0.021853318437933922 tr(WHW.T) 10027.1552734375
bpp_loss 2.768654993602208
12_gate proxy err 0.006506673526018858 tr(WHW.T) 37334.1015625
bpp_loss 2.957997594560896
12_down proxy err 0.031697340309619904 tr(WHW.T) 6822.7119140625
bpp_loss 2.753166879926409
I0325 15:33:55.420318 855355 quantize_finetune_llama.py:240] computed original embedding for layer 13 in 0.9605190753936768s
I0325 15:33:59.013649 865748 config.py:54] PyTorch version 2.6.0 available.
W0325 15:33:59.322185 865748 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:34:00.283911 865748 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:34:00.287908 855355 quantize_finetune_llama.py:209] layer 14 gpu 0
I0325 15:34:00.300706 865748 data_utils.py:336] using 256 training seqs, 128 validation seqs
13_v proxy err 0.051725681871175766 tr(WHW.T) 280.153564453125
bpp_loss 2.5302066802978516
13_q proxy err 0.0036040623672306538 tr(WHW.T) 20897.375
bpp_loss 3.3074148893356323
13_k proxy err 0.0013219522079452872 tr(WHW.T) 17798.916015625
bpp_loss 4.27998161315918
13_o proxy err 0.08740735054016113 tr(WHW.T) 675.2068481445312
bpp_loss 2.6281228065490723
13_up proxy err 0.021933086216449738 tr(WHW.T) 10010.2880859375
bpp_loss 2.772188799721854
13_gate proxy err 0.0062757208943367004 tr(WHW.T) 38921.26171875
bpp_loss 2.9623747212546214
13_down proxy err 0.03291301429271698 tr(WHW.T) 6560.505859375
bpp_loss 2.7538930347987582
I0325 15:34:55.878077 855355 quantize_finetune_llama.py:240] computed original embedding for layer 14 in 1.0745162963867188s
I0325 15:34:59.309139 866526 config.py:54] PyTorch version 2.6.0 available.
W0325 15:34:59.601212 866526 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:35:00.779264 866526 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:35:00.783034 855355 quantize_finetune_llama.py:209] layer 15 gpu 0
I0325 15:35:00.796119 866526 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.05152268335223198 tr(WHW.T) 281.3382873535156
bpp_loss 2.5197324752807617
14_q proxy err 0.0036455518566071987 tr(WHW.T) 20881.8359375
bpp_loss 3.2818020582199097
14_k proxy err 0.0012777033261954784 tr(WHW.T) 18619.298828125
bpp_loss 4.235860824584961
14_o proxy err 0.08595141023397446 tr(WHW.T) 686.2976684570312
bpp_loss 2.622357487678528
14_up proxy err 0.02391006238758564 tr(WHW.T) 9164.287109375
bpp_loss 2.767832006726946
14_gate proxy err 0.005884656682610512 tr(WHW.T) 41785.8203125
bpp_loss 2.992298432758876
14_down proxy err 0.03380139544606209 tr(WHW.T) 6390.916015625
bpp_loss 2.7520272391183034
I0325 15:35:54.756738 855355 quantize_finetune_llama.py:240] computed original embedding for layer 15 in 0.960747241973877s
I0325 15:35:58.043810 867279 config.py:54] PyTorch version 2.6.0 available.
W0325 15:35:58.344609 867279 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:35:59.264741 867279 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:35:59.268732 855355 quantize_finetune_llama.py:209] layer 16 gpu 0
I0325 15:35:59.282404 867279 data_utils.py:336] using 256 training seqs, 128 validation seqs
15_v proxy err 0.05157481133937836 tr(WHW.T) 284.0271301269531
bpp_loss 2.5826900005340576
15_q proxy err 0.0027305129915475845 tr(WHW.T) 28079.306640625
bpp_loss 3.406893253326416
15_k proxy err 0.0012527331709861755 tr(WHW.T) 18871.66796875
bpp_loss 4.268583297729492
15_o proxy err 0.07150096446275711 tr(WHW.T) 827.9279174804688
bpp_loss 2.6522104740142822
15_up proxy err 0.024265719577670097 tr(WHW.T) 8994.5693359375
bpp_loss 2.759796619415283
15_gate proxy err 0.00541187496855855 tr(WHW.T) 46217.96875
bpp_loss 3.0291997364589145
15_down proxy err 0.033722713589668274 tr(WHW.T) 6399.38671875
bpp_loss 2.746732030596052
I0325 15:36:53.700098 855355 quantize_finetune_llama.py:240] computed original embedding for layer 16 in 0.8725218772888184s
I0325 15:36:57.014749 868036 config.py:54] PyTorch version 2.6.0 available.
W0325 15:36:57.303195 868036 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:36:58.211155 868036 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:36:58.215393 855355 quantize_finetune_llama.py:209] layer 17 gpu 0
I0325 15:36:58.228734 868036 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.05279592424631119 tr(WHW.T) 274.28167724609375
bpp_loss 2.5344254970550537
16_q proxy err 0.0031322662252932787 tr(WHW.T) 24486.64453125
bpp_loss 3.3874428272247314
16_k proxy err 0.0012161724735051394 tr(WHW.T) 19506.357421875
bpp_loss 4.265420436859131
16_o proxy err 0.06103436276316643 tr(WHW.T) 969.0885620117188
bpp_loss 2.634091019630432
16_up proxy err 0.026072215288877487 tr(WHW.T) 8331.1826171875
bpp_loss 2.745642900466919
16_gate proxy err 0.006024936679750681 tr(WHW.T) 41176.12890625
bpp_loss 3.0644962787628174
16_down proxy err 0.034136004745960236 tr(WHW.T) 6288.2802734375
bpp_loss 2.733386857169015
I0325 15:37:52.399768 855355 quantize_finetune_llama.py:240] computed original embedding for layer 17 in 1.093132734298706s
I0325 15:37:55.688607 868792 config.py:54] PyTorch version 2.6.0 available.
W0325 15:37:55.971461 868792 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:37:56.893121 868792 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:37:56.897111 855355 quantize_finetune_llama.py:209] layer 18 gpu 0
I0325 15:37:56.909961 868792 data_utils.py:336] using 256 training seqs, 128 validation seqs
17_v proxy err 0.05188900977373123 tr(WHW.T) 283.9730224609375
bpp_loss 2.6139750480651855
17_q proxy err 0.002800346352159977 tr(WHW.T) 27571.44140625
bpp_loss 3.395188570022583
17_k proxy err 0.001352999941445887 tr(WHW.T) 17429.814453125
bpp_loss 4.282591342926025
17_o proxy err 0.053792066872119904 tr(WHW.T) 1106.6993408203125
bpp_loss 2.663537621498108
17_up proxy err 0.025686629116535187 tr(WHW.T) 8452.5419921875
bpp_loss 2.7414819513048445
17_gate proxy err 0.005971844308078289 tr(WHW.T) 41717.5625
bpp_loss 3.078064067023141
17_down proxy err 0.034533776342868805 tr(WHW.T) 6212.31494140625
bpp_loss 2.7314325060163225
I0325 15:38:50.485584 855355 quantize_finetune_llama.py:240] computed original embedding for layer 18 in 0.9699957370758057s
I0325 15:38:53.746199 869551 config.py:54] PyTorch version 2.6.0 available.
W0325 15:38:54.036638 869551 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:38:54.961681 869551 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:38:54.965443 855355 quantize_finetune_llama.py:209] layer 19 gpu 0
I0325 15:38:54.978291 869551 data_utils.py:336] using 256 training seqs, 128 validation seqs
18_v proxy err 0.050614144653081894 tr(WHW.T) 287.61376953125
bpp_loss 2.528013229370117
18_q proxy err 0.003410706529393792 tr(WHW.T) 22399.498046875
bpp_loss 3.396634578704834
18_k proxy err 0.001393325044773519 tr(WHW.T) 17394.810546875
bpp_loss 4.357868194580078
18_o proxy err 0.049430955201387405 tr(WHW.T) 1203.193603515625
bpp_loss 2.642692804336548
18_up proxy err 0.027128012850880623 tr(WHW.T) 7982.8837890625
bpp_loss 2.736695868628366
18_gate proxy err 0.006980954669415951 tr(WHW.T) 35243.5546875
bpp_loss 3.0876899446759904
18_down proxy err 0.03450014442205429 tr(WHW.T) 6226.57861328125
bpp_loss 2.7292960030691966
I0325 15:39:48.422650 855355 quantize_finetune_llama.py:240] computed original embedding for layer 19 in 0.8979349136352539s
I0325 15:39:51.710700 870291 config.py:54] PyTorch version 2.6.0 available.
W0325 15:39:51.998579 870291 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:39:52.919195 870291 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:39:52.922984 855355 quantize_finetune_llama.py:209] layer 20 gpu 0
I0325 15:39:52.935835 870291 data_utils.py:336] using 256 training seqs, 128 validation seqs
19_v proxy err 0.04345789924263954 tr(WHW.T) 341.0596618652344
bpp_loss 2.5725274085998535
19_q proxy err 0.003187039168551564 tr(WHW.T) 24038.03515625
bpp_loss 3.395562529563904
19_k proxy err 0.0015141041949391365 tr(WHW.T) 15553.287109375
bpp_loss 4.2652435302734375
19_o proxy err 0.05088001489639282 tr(WHW.T) 1168.891845703125
bpp_loss 2.657332181930542
19_up proxy err 0.028246724978089333 tr(WHW.T) 7649.2919921875
bpp_loss 2.7329606669289723
19_gate proxy err 0.007479580584913492 tr(WHW.T) 32811.99609375
bpp_loss 3.0995619978223528
19_down proxy err 0.0346275195479393 tr(WHW.T) 6182.73583984375
bpp_loss 2.727262496948242
I0325 15:40:46.941771 855355 quantize_finetune_llama.py:240] computed original embedding for layer 20 in 1.0055406093597412s
I0325 15:40:50.248947 871051 config.py:54] PyTorch version 2.6.0 available.
W0325 15:40:50.532988 871051 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:40:51.437950 871051 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:40:51.441822 855355 quantize_finetune_llama.py:209] layer 21 gpu 0
I0325 15:40:51.455470 871051 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.04524316266179085 tr(WHW.T) 330.192138671875
bpp_loss 2.6145455837249756
20_q proxy err 0.003637879155576229 tr(WHW.T) 20737.7421875
bpp_loss 3.368153929710388
20_k proxy err 0.001517627271823585 tr(WHW.T) 15395.810546875
bpp_loss 4.216653347015381
20_o proxy err 0.049263015389442444 tr(WHW.T) 1205.1229248046875
bpp_loss 2.6453505754470825
20_up proxy err 0.028473855927586555 tr(WHW.T) 7599.658203125
bpp_loss 2.736576897757394
20_gate proxy err 0.007984153926372528 tr(WHW.T) 30665.015625
bpp_loss 3.1022842270987376
20_down proxy err 0.03408581018447876 tr(WHW.T) 6300.8623046875
bpp_loss 2.7314246041434154
I0325 15:41:45.312508 855355 quantize_finetune_llama.py:240] computed original embedding for layer 21 in 0.8603074550628662s
I0325 15:41:48.608220 871823 config.py:54] PyTorch version 2.6.0 available.
W0325 15:41:48.894715 871823 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:41:49.830443 871823 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:41:49.834858 855355 quantize_finetune_llama.py:209] layer 22 gpu 0
I0325 15:41:49.855854 871823 data_utils.py:336] using 256 training seqs, 128 validation seqs
21_v proxy err 0.04118417948484421 tr(WHW.T) 362.87310791015625
bpp_loss 2.6434197425842285
21_q proxy err 0.0029559009708464146 tr(WHW.T) 25838.111328125
bpp_loss 3.3658134937286377
21_k proxy err 0.0014014622429385781 tr(WHW.T) 16787.453125
bpp_loss 4.261486053466797
21_o proxy err 0.04654025286436081 tr(WHW.T) 1266.6689453125
bpp_loss 2.665682554244995
21_up proxy err 0.027880745008587837 tr(WHW.T) 7772.57080078125
bpp_loss 2.739530290876116
21_gate proxy err 0.00778835779055953 tr(WHW.T) 31566.3828125
bpp_loss 3.11464296068464
21_down proxy err 0.033880218863487244 tr(WHW.T) 6351.46484375
bpp_loss 2.7342514310564314
I0325 15:42:43.291903 855355 quantize_finetune_llama.py:240] computed original embedding for layer 22 in 0.8723647594451904s
I0325 15:42:46.716387 872561 config.py:54] PyTorch version 2.6.0 available.
W0325 15:42:47.021007 872561 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:42:47.948497 872561 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:42:47.952598 855355 quantize_finetune_llama.py:209] layer 23 gpu 0
I0325 15:42:47.965447 872561 data_utils.py:336] using 256 training seqs, 128 validation seqs
22_v proxy err 0.04391881823539734 tr(WHW.T) 346.0789489746094
bpp_loss 2.695276975631714
22_q proxy err 0.003663458861410618 tr(WHW.T) 20319.60546875
bpp_loss 3.328057050704956
22_k proxy err 0.001565605984069407 tr(WHW.T) 14724.09765625
bpp_loss 4.195911407470703
22_o proxy err 0.04947267472743988 tr(WHW.T) 1221.8309326171875
bpp_loss 2.689692497253418
22_up proxy err 0.028727712109684944 tr(WHW.T) 7547.25537109375
bpp_loss 2.7433692046574185
22_gate proxy err 0.008307598531246185 tr(WHW.T) 29534.099609375
bpp_loss 3.1194550650460378
22_down proxy err 0.032977379858493805 tr(WHW.T) 6529.4912109375
bpp_loss 2.738132885524205
I0325 15:43:41.672661 855355 quantize_finetune_llama.py:240] computed original embedding for layer 23 in 0.8306968212127686s
I0325 15:43:45.020085 873317 config.py:54] PyTorch version 2.6.0 available.
W0325 15:43:45.316354 873317 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:43:46.216102 873317 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:43:46.219801 855355 quantize_finetune_llama.py:209] layer 24 gpu 0
I0325 15:43:46.233471 873317 data_utils.py:336] using 256 training seqs, 128 validation seqs
23_v proxy err 0.03838028013706207 tr(WHW.T) 397.90704345703125
bpp_loss 2.7506520748138428
23_q proxy err 0.0033373802434653044 tr(WHW.T) 22608.931640625
bpp_loss 3.3353891372680664
23_k proxy err 0.0015508087817579508 tr(WHW.T) 14857.474609375
bpp_loss 4.197999477386475
23_o proxy err 0.034998729825019836 tr(WHW.T) 1744.470947265625
bpp_loss 2.7109087705612183
23_up proxy err 0.029205523431301117 tr(WHW.T) 7419.2080078125
bpp_loss 2.747601168496268
23_gate proxy err 0.008942355401813984 tr(WHW.T) 27291.65234375
bpp_loss 3.12295777457101
23_down proxy err 0.0323050282895565 tr(WHW.T) 6666.9853515625
bpp_loss 2.742653029305594
I0325 15:44:39.389681 855355 quantize_finetune_llama.py:240] computed original embedding for layer 24 in 0.8506443500518799s
I0325 15:44:42.825312 874068 config.py:54] PyTorch version 2.6.0 available.
W0325 15:44:43.120248 874068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:44:44.225569 874068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:44:44.229649 855355 quantize_finetune_llama.py:209] layer 25 gpu 0
I0325 15:44:44.242799 874068 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.03372785076498985 tr(WHW.T) 467.2783508300781
bpp_loss 2.8481407165527344
24_q proxy err 0.0033247401006519794 tr(WHW.T) 22436.099609375
bpp_loss 3.3001980781555176
24_k proxy err 0.0015859808772802353 tr(WHW.T) 14183.4345703125
bpp_loss 4.031640529632568
24_o proxy err 0.03848811239004135 tr(WHW.T) 1589.4920654296875
bpp_loss 2.756912589073181
24_up proxy err 0.029656199738383293 tr(WHW.T) 7311.1435546875
bpp_loss 2.7523602076939175
24_gate proxy err 0.009428407065570354 tr(WHW.T) 25877.26171875
bpp_loss 3.129958459309169
24_down proxy err 0.032042138278484344 tr(WHW.T) 6741.93701171875
bpp_loss 2.7479611805507114
I0325 15:45:38.125926 855355 quantize_finetune_llama.py:240] computed original embedding for layer 25 in 0.8917109966278076s
I0325 15:45:41.444707 874821 config.py:54] PyTorch version 2.6.0 available.
W0325 15:45:41.736044 874821 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:45:42.910270 874821 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:45:42.914055 855355 quantize_finetune_llama.py:209] layer 26 gpu 0
I0325 15:45:42.926917 874821 data_utils.py:336] using 256 training seqs, 128 validation seqs
25_v proxy err 0.02822030521929264 tr(WHW.T) 557.8086547851562
bpp_loss 2.8596391677856445
25_q proxy err 0.002870161086320877 tr(WHW.T) 26112.029296875
bpp_loss 3.2798478603363037
25_k proxy err 0.0015781623078510165 tr(WHW.T) 14416.6201171875
bpp_loss 4.020153522491455
25_o proxy err 0.03074420802295208 tr(WHW.T) 1990.481201171875
bpp_loss 2.760053038597107
25_up proxy err 0.02942497283220291 tr(WHW.T) 7382.19091796875
bpp_loss 2.7615669795445035
25_gate proxy err 0.009259830228984356 tr(WHW.T) 26307.435546875
bpp_loss 3.139137472425188
25_down proxy err 0.032617099583148956 tr(WHW.T) 6615.951171875
bpp_loss 2.7572263990129744
I0325 15:46:36.464037 855355 quantize_finetune_llama.py:240] computed original embedding for layer 26 in 0.6941092014312744s
I0325 15:46:39.892905 875578 config.py:54] PyTorch version 2.6.0 available.
W0325 15:46:40.186431 875578 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:46:41.086840 875578 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:46:41.090946 855355 quantize_finetune_llama.py:209] layer 27 gpu 0
I0325 15:46:41.104345 875578 data_utils.py:336] using 256 training seqs, 128 validation seqs
26_v proxy err 0.036595944315195084 tr(WHW.T) 434.54583740234375
bpp_loss 2.9245996475219727
26_q proxy err 0.0034693079069256783 tr(WHW.T) 21403.28125
bpp_loss 3.2869932651519775
26_k proxy err 0.001493048737756908 tr(WHW.T) 15425.5859375
bpp_loss 4.088101863861084
26_o proxy err 0.025661444291472435 tr(WHW.T) 2388.72412109375
bpp_loss 2.7818210124969482
26_up proxy err 0.028507789596915245 tr(WHW.T) 7645.65625
bpp_loss 2.7705444267817905
26_gate proxy err 0.008461780846118927 tr(WHW.T) 28901.4453125
bpp_loss 3.1432809829711914
26_down proxy err 0.03269340097904205 tr(WHW.T) 6618.82470703125
bpp_loss 2.7661022458757674
I0325 15:47:34.490970 855355 quantize_finetune_llama.py:240] computed original embedding for layer 27 in 0.8665845394134521s
I0325 15:47:37.877518 876327 config.py:54] PyTorch version 2.6.0 available.
W0325 15:47:38.178475 876327 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:47:39.108873 876327 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:47:39.113033 855355 quantize_finetune_llama.py:209] layer 28 gpu 0
I0325 15:47:39.126239 876327 data_utils.py:336] using 256 training seqs, 128 validation seqs
27_v proxy err 0.0239342600107193 tr(WHW.T) 677.69384765625
bpp_loss 3.0054800510406494
27_q proxy err 0.003488901536911726 tr(WHW.T) 21305.96875
bpp_loss 3.258523941040039
27_k proxy err 0.0016393676633015275 tr(WHW.T) 14011.6201171875
bpp_loss 4.043614864349365
27_o proxy err 0.028815826401114464 tr(WHW.T) 2159.9560546875
bpp_loss 2.810703158378601
27_up proxy err 0.025796974077820778 tr(WHW.T) 8475.5947265625
bpp_loss 2.784452404294695
27_gate proxy err 0.007497040089219809 tr(WHW.T) 32809.0390625
bpp_loss 3.150669574737549
27_down proxy err 0.032910216599702835 tr(WHW.T) 6543.35791015625
bpp_loss 2.7784486498151506
I0325 15:48:32.599400 855355 quantize_finetune_llama.py:240] computed original embedding for layer 28 in 0.7731740474700928s
I0325 15:48:36.048524 877074 config.py:54] PyTorch version 2.6.0 available.
W0325 15:48:36.349146 877074 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:48:37.273395 877074 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:48:37.277445 855355 quantize_finetune_llama.py:209] layer 29 gpu 0
I0325 15:48:37.291645 877074 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.027434390038251877 tr(WHW.T) 601.4844360351562
bpp_loss 3.071439743041992
28_q proxy err 0.0032672504894435406 tr(WHW.T) 23163.888671875
bpp_loss 3.265994071960449
28_k proxy err 0.001521266414783895 tr(WHW.T) 14994.2119140625
bpp_loss 4.001594066619873
28_o proxy err 0.02475789748132229 tr(WHW.T) 2511.445556640625
bpp_loss 2.8386199474334717
28_up proxy err 0.021611200645565987 tr(WHW.T) 10246.0703125
bpp_loss 2.8074338095528737
28_gate proxy err 0.00685655465349555 tr(WHW.T) 35920.9609375
bpp_loss 3.1363184452056885
28_down proxy err 0.030201038345694542 tr(WHW.T) 7210.08740234375
bpp_loss 2.7970679146902904
I0325 15:49:30.669233 855355 quantize_finetune_llama.py:240] computed original embedding for layer 29 in 0.7447454929351807s
I0325 15:49:33.984872 877830 config.py:54] PyTorch version 2.6.0 available.
W0325 15:49:34.281156 877830 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:49:35.201673 877830 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:49:35.205741 855355 quantize_finetune_llama.py:209] layer 30 gpu 0
I0325 15:49:35.219059 877830 data_utils.py:336] using 256 training seqs, 128 validation seqs
29_v proxy err 0.019738929346203804 tr(WHW.T) 850.4290161132812
bpp_loss 3.1329965591430664
29_q proxy err 0.0037265773862600327 tr(WHW.T) 20653.2265625
bpp_loss 3.257270932197571
29_k proxy err 0.0014108956092968583 tr(WHW.T) 16365.796875
bpp_loss 4.0981574058532715
29_o proxy err 0.020383166149258614 tr(WHW.T) 3102.844970703125
bpp_loss 2.883440613746643
29_up proxy err 0.017444763332605362 tr(WHW.T) 12868.505859375
bpp_loss 2.838677338191441
29_gate proxy err 0.0064133149571716785 tr(WHW.T) 38364.47265625
bpp_loss 3.1243347440447127
29_down proxy err 0.02933061681687832 tr(WHW.T) 7470.5244140625
bpp_loss 2.8171048845563615
I0325 15:50:28.489198 855355 quantize_finetune_llama.py:240] computed original embedding for layer 30 in 0.8880903720855713s
I0325 15:50:31.921971 878570 config.py:54] PyTorch version 2.6.0 available.
W0325 15:50:32.218108 878570 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:50:33.258605 878570 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:50:33.262400 855355 quantize_finetune_llama.py:209] layer 31 gpu 0
I0325 15:50:33.275677 878570 data_utils.py:336] using 256 training seqs, 128 validation seqs
30_v proxy err 0.02066693641245365 tr(WHW.T) 863.060791015625
bpp_loss 3.419981002807617
30_q proxy err 0.00310377380810678 tr(WHW.T) 24050.6328125
bpp_loss 3.1522475481033325
30_k proxy err 0.001589080784469843 tr(WHW.T) 14030.5888671875
bpp_loss 3.748322010040283
30_o proxy err 0.013369956985116005 tr(WHW.T) 4869.1748046875
bpp_loss 2.9677549600601196
30_up proxy err 0.010751254856586456 tr(WHW.T) 21711.1953125
bpp_loss 2.8662797723497664
30_gate proxy err 0.004894154611974955 tr(WHW.T) 51954.453125
bpp_loss 3.1687443937574113
30_down proxy err 0.024650029838085175 tr(WHW.T) 8810.1787109375
bpp_loss 2.8238319669451033
I0325 15:51:26.832598 855355 quantize_finetune_llama.py:240] computed original embedding for layer 31 in 0.9079990386962891s
I0325 15:51:30.306241 879319 config.py:54] PyTorch version 2.6.0 available.
W0325 15:51:30.598489 879319 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 15:51:31.558228 879319 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 15:51:31.575308 879319 data_utils.py:336] using 256 training seqs, 128 validation seqs
31_v proxy err 0.0097823366522789 tr(WHW.T) 1808.723876953125
bpp_loss 3.2147467136383057
31_q proxy err 0.0018422537250444293 tr(WHW.T) 46175.66015625
bpp_loss 3.3062937259674072
31_k proxy err 0.001253194292075932 tr(WHW.T) 20467.64453125
bpp_loss 3.981879472732544
31_o proxy err 0.027485227212309837 tr(WHW.T) 2213.58154296875
bpp_loss 2.9354560375213623
31_up proxy err 0.003848865395411849 tr(WHW.T) 69019.4453125
bpp_loss 3.053219727107457
31_gate proxy err 0.002006468130275607 tr(WHW.T) 144452.5625
bpp_loss 3.3821661472320557
31_down proxy err 0.022293614223599434 tr(WHW.T) 9960.1884765625
bpp_loss 2.855638231549944
I0325 15:52:34.302826 880145 config.py:54] PyTorch version 2.6.0 available.
W0325 15:52:34.600018 880145 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0325 15:52:34.839272 880145 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.78it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  9.94it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.03it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.03it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.25it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  9.59it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  9.06it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  9.28it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.28it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.44it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.88it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.62it/s]
I0325 15:52:37.430917 880145 hfize_llama.py:153] loaded layer 0
I0325 15:52:37.751167 880145 hfize_llama.py:153] loaded layer 1
I0325 15:52:38.080033 880145 hfize_llama.py:153] loaded layer 2
I0325 15:52:38.378471 880145 hfize_llama.py:153] loaded layer 3
I0325 15:52:38.667988 880145 hfize_llama.py:153] loaded layer 4
I0325 15:52:38.966768 880145 hfize_llama.py:153] loaded layer 5
I0325 15:52:39.264131 880145 hfize_llama.py:153] loaded layer 6
I0325 15:52:39.575288 880145 hfize_llama.py:153] loaded layer 7
I0325 15:52:39.916218 880145 hfize_llama.py:153] loaded layer 8
I0325 15:52:40.253494 880145 hfize_llama.py:153] loaded layer 9
I0325 15:52:40.587160 880145 hfize_llama.py:153] loaded layer 10
I0325 15:52:40.888695 880145 hfize_llama.py:153] loaded layer 11
I0325 15:52:41.207932 880145 hfize_llama.py:153] loaded layer 12
I0325 15:52:41.538239 880145 hfize_llama.py:153] loaded layer 13
I0325 15:52:41.878004 880145 hfize_llama.py:153] loaded layer 14
I0325 15:52:42.173247 880145 hfize_llama.py:153] loaded layer 15
I0325 15:52:42.459721 880145 hfize_llama.py:153] loaded layer 16
I0325 15:52:42.764957 880145 hfize_llama.py:153] loaded layer 17
I0325 15:52:43.068956 880145 hfize_llama.py:153] loaded layer 18
I0325 15:52:43.388880 880145 hfize_llama.py:153] loaded layer 19
I0325 15:52:43.679897 880145 hfize_llama.py:153] loaded layer 20
I0325 15:52:43.971888 880145 hfize_llama.py:153] loaded layer 21
I0325 15:52:44.268102 880145 hfize_llama.py:153] loaded layer 22
I0325 15:52:44.563887 880145 hfize_llama.py:153] loaded layer 23
I0325 15:52:44.859880 880145 hfize_llama.py:153] loaded layer 24
I0325 15:52:45.192508 880145 hfize_llama.py:153] loaded layer 25
I0325 15:52:45.468738 880145 hfize_llama.py:153] loaded layer 26
I0325 15:52:45.740433 880145 hfize_llama.py:153] loaded layer 27
I0325 15:52:46.021474 880145 hfize_llama.py:153] loaded layer 28
I0325 15:52:46.289507 880145 hfize_llama.py:153] loaded layer 29
I0325 15:52:46.576795 880145 hfize_llama.py:153] loaded layer 30
I0325 15:52:46.871585 880145 hfize_llama.py:153] loaded layer 31
I0325 15:52:46.871687 880145 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.50s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:07,  1.47s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.30s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:03,  1.26s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.21s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:07<00:01,  1.18s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.01it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]
I0325 15:53:36.111098 880145 hfize_llama.py:167] successfully loaded hfized model
W0325 15:53:40.459206 881168 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0325 15:53:40.954356 881168 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.17s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.22s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.19s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.19s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:07<00:01,  1.19s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.12s/it]
I0325 15:53:49.284382 881168 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 2.0465145111083984:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 2.0465145111083984:   1%|          | 1/141 [00:01<04:25,  1.89s/it]avg_loss = 2.361081838607788:   1%|          | 1/141 [00:03<04:25,  1.89s/it] avg_loss = 2.361081838607788:   1%|▏         | 2/141 [00:03<03:52,  1.67s/it]avg_loss = 2.5264200369517007:   1%|▏         | 2/141 [00:04<03:52,  1.67s/it]avg_loss = 2.5264200369517007:   2%|▏         | 3/141 [00:04<03:41,  1.60s/it]avg_loss = 2.498048961162567:   2%|▏         | 3/141 [00:06<03:41,  1.60s/it] avg_loss = 2.498048961162567:   3%|▎         | 4/141 [00:06<03:35,  1.57s/it]avg_loss = 2.477606916427612:   3%|▎         | 4/141 [00:07<03:35,  1.57s/it]avg_loss = 2.477606916427612:   4%|▎         | 5/141 [00:07<03:31,  1.56s/it]avg_loss = 2.4134428898493447:   4%|▎         | 5/141 [00:09<03:31,  1.56s/it]avg_loss = 2.4134428898493447:   4%|▍         | 6/141 [00:09<03:29,  1.55s/it]avg_loss = 2.384589059012277:   4%|▍         | 6/141 [00:11<03:29,  1.55s/it] avg_loss = 2.384589059012277:   5%|▍         | 7/141 [00:11<03:27,  1.55s/it]avg_loss = 2.409727394580841:   5%|▍         | 7/141 [00:12<03:27,  1.55s/it]avg_loss = 2.409727394580841:   6%|▌         | 8/141 [00:12<03:25,  1.55s/it]avg_loss = 2.449100070529514:   6%|▌         | 8/141 [00:14<03:25,  1.55s/it]avg_loss = 2.449100070529514:   6%|▋         | 9/141 [00:14<03:24,  1.55s/it]avg_loss = 2.437099266052246:   6%|▋         | 9/141 [00:15<03:24,  1.55s/it]avg_loss = 2.437099266052246:   7%|▋         | 10/141 [00:15<03:22,  1.55s/it]avg_loss = 2.427756808020852:   7%|▋         | 10/141 [00:17<03:22,  1.55s/it]avg_loss = 2.427756808020852:   8%|▊         | 11/141 [00:17<03:21,  1.55s/it]avg_loss = 2.4471979339917502:   8%|▊         | 11/141 [00:18<03:21,  1.55s/it]avg_loss = 2.4471979339917502:   9%|▊         | 12/141 [00:18<03:20,  1.56s/it]avg_loss = 2.468691954245934:   9%|▊         | 12/141 [00:20<03:20,  1.56s/it] avg_loss = 2.468691954245934:   9%|▉         | 13/141 [00:20<03:19,  1.56s/it]avg_loss = 2.4982096467699324:   9%|▉         | 13/141 [00:21<03:19,  1.56s/it]avg_loss = 2.4982096467699324:  10%|▉         | 14/141 [00:21<03:18,  1.56s/it]avg_loss = 2.515383243560791:  10%|▉         | 14/141 [00:23<03:18,  1.56s/it] avg_loss = 2.515383243560791:  11%|█         | 15/141 [00:23<03:17,  1.57s/it]avg_loss = 2.5415273010730743:  11%|█         | 15/141 [00:25<03:17,  1.57s/it]avg_loss = 2.5415273010730743:  11%|█▏        | 16/141 [00:25<03:16,  1.57s/it]avg_loss = 2.551092736861285:  11%|█▏        | 16/141 [00:26<03:16,  1.57s/it] avg_loss = 2.551092736861285:  12%|█▏        | 17/141 [00:26<03:15,  1.57s/it]avg_loss = 2.552999085850186:  12%|█▏        | 17/141 [00:28<03:15,  1.57s/it]avg_loss = 2.552999085850186:  13%|█▎        | 18/141 [00:28<03:14,  1.58s/it]avg_loss = 2.5375885712473014:  13%|█▎        | 18/141 [00:29<03:14,  1.58s/it]avg_loss = 2.5375885712473014:  13%|█▎        | 19/141 [00:29<03:13,  1.58s/it]avg_loss = 2.5335671663284303:  13%|█▎        | 19/141 [00:31<03:13,  1.58s/it]avg_loss = 2.5335671663284303:  14%|█▍        | 20/141 [00:31<03:12,  1.59s/it]avg_loss = 2.5340434937250045:  14%|█▍        | 20/141 [00:33<03:12,  1.59s/it]avg_loss = 2.5340434937250045:  15%|█▍        | 21/141 [00:33<03:10,  1.59s/it]avg_loss = 2.531696471300992:  15%|█▍        | 21/141 [00:34<03:10,  1.59s/it] avg_loss = 2.531696471300992:  16%|█▌        | 22/141 [00:34<03:09,  1.59s/it]avg_loss = 2.5300039104793384:  16%|█▌        | 22/141 [00:36<03:09,  1.59s/it]avg_loss = 2.5300039104793384:  16%|█▋        | 23/141 [00:36<03:08,  1.60s/it]avg_loss = 2.53098792831103:  16%|█▋        | 23/141 [00:37<03:08,  1.60s/it]  avg_loss = 2.53098792831103:  17%|█▋        | 24/141 [00:37<03:07,  1.60s/it]avg_loss = 2.5363691234588623:  17%|█▋        | 24/141 [00:39<03:07,  1.60s/it]avg_loss = 2.5363691234588623:  18%|█▊        | 25/141 [00:39<03:06,  1.61s/it]avg_loss = 2.54487983080057:  18%|█▊        | 25/141 [00:41<03:06,  1.61s/it]  avg_loss = 2.54487983080057:  18%|█▊        | 26/141 [00:41<03:05,  1.61s/it]avg_loss = 2.5561976962619357:  18%|█▊        | 26/141 [00:42<03:05,  1.61s/it]avg_loss = 2.5561976962619357:  19%|█▉        | 27/141 [00:42<03:03,  1.61s/it]avg_loss = 2.555951178073883:  19%|█▉        | 27/141 [00:44<03:03,  1.61s/it] avg_loss = 2.555951178073883:  20%|█▉        | 28/141 [00:44<03:02,  1.62s/it]avg_loss = 2.5470184128859947:  20%|█▉        | 28/141 [00:46<03:02,  1.62s/it]avg_loss = 2.5470184128859947:  21%|██        | 29/141 [00:46<03:01,  1.62s/it]avg_loss = 2.5336856921513875:  21%|██        | 29/141 [00:47<03:01,  1.62s/it]avg_loss = 2.5336856921513875:  21%|██▏       | 30/141 [00:47<03:00,  1.63s/it]avg_loss = 2.518271630810153:  21%|██▏       | 30/141 [00:49<03:00,  1.63s/it] avg_loss = 2.518271630810153:  22%|██▏       | 31/141 [00:49<02:59,  1.63s/it]avg_loss = 2.5037726312875748:  22%|██▏       | 31/141 [00:50<02:59,  1.63s/it]avg_loss = 2.5037726312875748:  23%|██▎       | 32/141 [00:50<02:57,  1.63s/it]avg_loss = 2.496727820598718:  23%|██▎       | 32/141 [00:52<02:57,  1.63s/it] avg_loss = 2.496727820598718:  23%|██▎       | 33/141 [00:52<02:56,  1.63s/it]avg_loss = 2.4920332431793213:  23%|██▎       | 33/141 [00:54<02:56,  1.63s/it]avg_loss = 2.4920332431793213:  24%|██▍       | 34/141 [00:54<02:55,  1.64s/it]avg_loss = 2.493299055099487:  24%|██▍       | 34/141 [00:55<02:55,  1.64s/it] avg_loss = 2.493299055099487:  25%|██▍       | 35/141 [00:55<02:53,  1.64s/it]avg_loss = 2.47453013393614:  25%|██▍       | 35/141 [00:57<02:53,  1.64s/it] avg_loss = 2.47453013393614:  26%|██▌       | 36/141 [00:57<02:52,  1.64s/it]avg_loss = 2.4586605542414897:  26%|██▌       | 36/141 [00:59<02:52,  1.64s/it]avg_loss = 2.4586605542414897:  26%|██▌       | 37/141 [00:59<02:51,  1.65s/it]avg_loss = 2.4425182938575745:  26%|██▌       | 37/141 [01:00<02:51,  1.65s/it]avg_loss = 2.4425182938575745:  27%|██▋       | 38/141 [01:00<02:49,  1.65s/it]avg_loss = 2.4284301140369515:  27%|██▋       | 38/141 [01:02<02:49,  1.65s/it]avg_loss = 2.4284301140369515:  28%|██▊       | 39/141 [01:02<02:48,  1.65s/it]avg_loss = 2.41802878677845:  28%|██▊       | 39/141 [01:04<02:48,  1.65s/it]  avg_loss = 2.41802878677845:  28%|██▊       | 40/141 [01:04<02:47,  1.65s/it]avg_loss = 2.423531779428808:  28%|██▊       | 40/141 [01:05<02:47,  1.65s/it]avg_loss = 2.423531779428808:  29%|██▉       | 41/141 [01:05<02:45,  1.66s/it]avg_loss = 2.437282457238152:  29%|██▉       | 41/141 [01:07<02:45,  1.66s/it]avg_loss = 2.437282457238152:  30%|██▉       | 42/141 [01:07<02:44,  1.66s/it]avg_loss = 2.451026952543924:  30%|██▉       | 42/141 [01:09<02:44,  1.66s/it]avg_loss = 2.451026952543924:  30%|███       | 43/141 [01:09<02:42,  1.66s/it]avg_loss = 2.4565520801327447:  30%|███       | 43/141 [01:10<02:42,  1.66s/it]avg_loss = 2.4565520801327447:  31%|███       | 44/141 [01:10<02:41,  1.66s/it]avg_loss = 2.4631574233373006:  31%|███       | 44/141 [01:12<02:41,  1.66s/it]avg_loss = 2.4631574233373006:  32%|███▏      | 45/141 [01:12<02:39,  1.67s/it]avg_loss = 2.4683743171069934:  32%|███▏      | 45/141 [01:14<02:39,  1.67s/it]avg_loss = 2.4683743171069934:  33%|███▎      | 46/141 [01:14<02:38,  1.67s/it]avg_loss = 2.4749848056346813:  33%|███▎      | 46/141 [01:15<02:38,  1.67s/it]avg_loss = 2.4749848056346813:  33%|███▎      | 47/141 [01:15<02:36,  1.67s/it]avg_loss = 2.476743904252847:  33%|███▎      | 47/141 [01:17<02:36,  1.67s/it] avg_loss = 2.476743904252847:  34%|███▍      | 48/141 [01:17<02:35,  1.67s/it]avg_loss = 2.476411967861409:  34%|███▍      | 48/141 [01:19<02:35,  1.67s/it]avg_loss = 2.476411967861409:  35%|███▍      | 49/141 [01:19<02:33,  1.67s/it]avg_loss = 2.473557827472687:  35%|███▍      | 49/141 [01:20<02:33,  1.67s/it]avg_loss = 2.473557827472687:  35%|███▌      | 50/141 [01:20<02:32,  1.67s/it]avg_loss = 2.4685753350164377:  35%|███▌      | 50/141 [01:22<02:32,  1.67s/it]avg_loss = 2.4685753350164377:  36%|███▌      | 51/141 [01:22<02:30,  1.68s/it]avg_loss = 2.4632465816461124:  36%|███▌      | 51/141 [01:24<02:30,  1.68s/it]avg_loss = 2.4632465816461124:  37%|███▋      | 52/141 [01:24<02:29,  1.68s/it]avg_loss = 2.456567366168184:  37%|███▋      | 52/141 [01:25<02:29,  1.68s/it] avg_loss = 2.456567366168184:  38%|███▊      | 53/141 [01:25<02:27,  1.68s/it]avg_loss = 2.4526414937443204:  38%|███▊      | 53/141 [01:27<02:27,  1.68s/it]avg_loss = 2.4526414937443204:  38%|███▊      | 54/141 [01:27<02:26,  1.68s/it]avg_loss = 2.444449513608759:  38%|███▊      | 54/141 [01:29<02:26,  1.68s/it] avg_loss = 2.444449513608759:  39%|███▉      | 55/141 [01:29<02:24,  1.68s/it]avg_loss = 2.4365372338465283:  39%|███▉      | 55/141 [01:30<02:24,  1.68s/it]avg_loss = 2.4365372338465283:  40%|███▉      | 56/141 [01:30<02:23,  1.69s/it]avg_loss = 2.43471738539244:  40%|███▉      | 56/141 [01:32<02:23,  1.69s/it]  avg_loss = 2.43471738539244:  40%|████      | 57/141 [01:32<02:21,  1.69s/it]avg_loss = 2.430373185667498:  40%|████      | 57/141 [01:34<02:21,  1.69s/it]avg_loss = 2.430373185667498:  41%|████      | 58/141 [01:34<02:20,  1.69s/it]avg_loss = 2.432425646458642:  41%|████      | 58/141 [01:36<02:20,  1.69s/it]avg_loss = 2.432425646458642:  42%|████▏     | 59/141 [01:36<02:18,  1.69s/it]avg_loss = 2.437538284063339:  42%|████▏     | 59/141 [01:37<02:18,  1.69s/it]avg_loss = 2.437538284063339:  43%|████▎     | 60/141 [01:37<02:17,  1.69s/it]avg_loss = 2.4408104478335773:  43%|████▎     | 60/141 [01:39<02:17,  1.69s/it]avg_loss = 2.4408104478335773:  43%|████▎     | 61/141 [01:39<02:15,  1.69s/it]avg_loss = 2.4484285904515173:  43%|████▎     | 61/141 [01:41<02:15,  1.69s/it]avg_loss = 2.4484285904515173:  44%|████▍     | 62/141 [01:41<02:13,  1.70s/it]avg_loss = 2.4404842020973327:  44%|████▍     | 62/141 [01:42<02:13,  1.70s/it]avg_loss = 2.4404842020973327:  45%|████▍     | 63/141 [01:42<02:12,  1.70s/it]avg_loss = 2.4372649677097797:  45%|████▍     | 63/141 [01:44<02:12,  1.70s/it]avg_loss = 2.4372649677097797:  45%|████▌     | 64/141 [01:44<02:10,  1.70s/it]avg_loss = 2.4339274699871356:  45%|████▌     | 64/141 [01:46<02:10,  1.70s/it]avg_loss = 2.4339274699871356:  46%|████▌     | 65/141 [01:46<02:08,  1.70s/it]avg_loss = 2.4271105600125864:  46%|████▌     | 65/141 [01:47<02:08,  1.70s/it]avg_loss = 2.4271105600125864:  47%|████▋     | 66/141 [01:47<02:07,  1.70s/it]avg_loss = 2.422029886672746:  47%|████▋     | 66/141 [01:49<02:07,  1.70s/it] avg_loss = 2.422029886672746:  48%|████▊     | 67/141 [01:49<02:05,  1.70s/it]avg_loss = 2.4198389474083397:  48%|████▊     | 67/141 [01:51<02:05,  1.70s/it]avg_loss = 2.4198389474083397:  48%|████▊     | 68/141 [01:51<02:03,  1.70s/it]avg_loss = 2.4195351600646973:  48%|████▊     | 68/141 [01:53<02:03,  1.70s/it]avg_loss = 2.4195351600646973:  49%|████▉     | 69/141 [01:53<02:02,  1.70s/it]avg_loss = 2.4197469915662495:  49%|████▉     | 69/141 [01:54<02:02,  1.70s/it]avg_loss = 2.4197469915662495:  50%|████▉     | 70/141 [01:54<02:00,  1.70s/it]avg_loss = 2.422043608947539:  50%|████▉     | 70/141 [01:56<02:00,  1.70s/it] avg_loss = 2.422043608947539:  50%|█████     | 71/141 [01:56<01:58,  1.70s/it]avg_loss = 2.42522065838178:  50%|█████     | 71/141 [01:58<01:58,  1.70s/it] avg_loss = 2.42522065838178:  51%|█████     | 72/141 [01:58<01:57,  1.70s/it]avg_loss = 2.423214804636289:  51%|█████     | 72/141 [01:59<01:57,  1.70s/it]avg_loss = 2.423214804636289:  52%|█████▏    | 73/141 [01:59<01:55,  1.70s/it]avg_loss = 2.4251319202216894:  52%|█████▏    | 73/141 [02:01<01:55,  1.70s/it]avg_loss = 2.4251319202216894:  52%|█████▏    | 74/141 [02:01<01:53,  1.70s/it]avg_loss = 2.424533618291219:  52%|█████▏    | 74/141 [02:03<01:53,  1.70s/it] avg_loss = 2.424533618291219:  53%|█████▎    | 75/141 [02:03<01:52,  1.70s/it]avg_loss = 2.423456985699503:  53%|█████▎    | 75/141 [02:04<01:52,  1.70s/it]avg_loss = 2.423456985699503:  54%|█████▍    | 76/141 [02:04<01:50,  1.70s/it]avg_loss = 2.4249316531342346:  54%|█████▍    | 76/141 [02:06<01:50,  1.70s/it]avg_loss = 2.4249316531342346:  55%|█████▍    | 77/141 [02:06<01:49,  1.70s/it]avg_loss = 2.4267256351617665:  55%|█████▍    | 77/141 [02:08<01:49,  1.70s/it]avg_loss = 2.4267256351617665:  55%|█████▌    | 78/141 [02:08<01:47,  1.70s/it]avg_loss = 2.4294254659097407:  55%|█████▌    | 78/141 [02:10<01:47,  1.70s/it]avg_loss = 2.4294254659097407:  56%|█████▌    | 79/141 [02:10<01:45,  1.70s/it]avg_loss = 2.4237644523382187:  56%|█████▌    | 79/141 [02:11<01:45,  1.70s/it]avg_loss = 2.4237644523382187:  57%|█████▋    | 80/141 [02:11<01:44,  1.71s/it]avg_loss = 2.4212863356978804:  57%|█████▋    | 80/141 [02:13<01:44,  1.71s/it]avg_loss = 2.4212863356978804:  57%|█████▋    | 81/141 [02:13<01:42,  1.71s/it]avg_loss = 2.419902810236303:  57%|█████▋    | 81/141 [02:15<01:42,  1.71s/it] avg_loss = 2.419902810236303:  58%|█████▊    | 82/141 [02:15<01:40,  1.71s/it]avg_loss = 2.417237011783094:  58%|█████▊    | 82/141 [02:16<01:40,  1.71s/it]avg_loss = 2.417237011783094:  59%|█████▉    | 83/141 [02:16<01:38,  1.71s/it]avg_loss = 2.414117517925444:  59%|█████▉    | 83/141 [02:18<01:38,  1.71s/it]avg_loss = 2.414117517925444:  60%|█████▉    | 84/141 [02:18<01:37,  1.71s/it]avg_loss = 2.4125551279853372:  60%|█████▉    | 84/141 [02:20<01:37,  1.71s/it]avg_loss = 2.4125551279853372:  60%|██████    | 85/141 [02:20<01:35,  1.71s/it]avg_loss = 2.4132700548615564:  60%|██████    | 85/141 [02:22<01:35,  1.71s/it]avg_loss = 2.4132700548615564:  61%|██████    | 86/141 [02:22<01:33,  1.71s/it]avg_loss = 2.414250042246676:  61%|██████    | 86/141 [02:23<01:33,  1.71s/it] avg_loss = 2.414250042246676:  62%|██████▏   | 87/141 [02:23<01:32,  1.71s/it]avg_loss = 2.415738517587835:  62%|██████▏   | 87/141 [02:25<01:32,  1.71s/it]avg_loss = 2.415738517587835:  62%|██████▏   | 88/141 [02:25<01:30,  1.71s/it]avg_loss = 2.4237372928790832:  62%|██████▏   | 88/141 [02:27<01:30,  1.71s/it]avg_loss = 2.4237372928790832:  63%|██████▎   | 89/141 [02:27<01:28,  1.71s/it]avg_loss = 2.430470996432834:  63%|██████▎   | 89/141 [02:28<01:28,  1.71s/it] avg_loss = 2.430470996432834:  64%|██████▍   | 90/141 [02:28<01:27,  1.71s/it]avg_loss = 2.433918224586235:  64%|██████▍   | 90/141 [02:30<01:27,  1.71s/it]avg_loss = 2.433918224586235:  65%|██████▍   | 91/141 [02:30<01:25,  1.71s/it]avg_loss = 2.4395002100778664:  65%|██████▍   | 91/141 [02:32<01:25,  1.71s/it]avg_loss = 2.4395002100778664:  65%|██████▌   | 92/141 [02:32<01:23,  1.71s/it]avg_loss = 2.4461737012350433:  65%|██████▌   | 92/141 [02:33<01:23,  1.71s/it]avg_loss = 2.4461737012350433:  66%|██████▌   | 93/141 [02:33<01:22,  1.71s/it]avg_loss = 2.446571542861614:  66%|██████▌   | 93/141 [02:35<01:22,  1.71s/it] avg_loss = 2.446571542861614:  67%|██████▋   | 94/141 [02:35<01:20,  1.71s/it]avg_loss = 2.4501234983143054:  67%|██████▋   | 94/141 [02:37<01:20,  1.71s/it]avg_loss = 2.4501234983143054:  67%|██████▋   | 95/141 [02:37<01:18,  1.71s/it]avg_loss = 2.4502155209581056:  67%|██████▋   | 95/141 [02:39<01:18,  1.71s/it]avg_loss = 2.4502155209581056:  68%|██████▊   | 96/141 [02:39<01:16,  1.71s/it]avg_loss = 2.4507809914264485:  68%|██████▊   | 96/141 [02:40<01:16,  1.71s/it]avg_loss = 2.4507809914264485:  69%|██████▉   | 97/141 [02:40<01:15,  1.71s/it]avg_loss = 2.449233057547589:  69%|██████▉   | 97/141 [02:42<01:15,  1.71s/it] avg_loss = 2.449233057547589:  70%|██████▉   | 98/141 [02:42<01:13,  1.71s/it]avg_loss = 2.449538233304265:  70%|██████▉   | 98/141 [02:44<01:13,  1.71s/it]avg_loss = 2.449538233304265:  70%|███████   | 99/141 [02:44<01:11,  1.71s/it]avg_loss = 2.4511257672309874:  70%|███████   | 99/141 [02:45<01:11,  1.71s/it]avg_loss = 2.4511257672309874:  71%|███████   | 100/141 [02:45<01:10,  1.71s/it]avg_loss = 2.4506098114617982:  71%|███████   | 100/141 [02:47<01:10,  1.71s/it]avg_loss = 2.4506098114617982:  72%|███████▏  | 101/141 [02:47<01:08,  1.71s/it]avg_loss = 2.4509150514415667:  72%|███████▏  | 101/141 [02:49<01:08,  1.71s/it]avg_loss = 2.4509150514415667:  72%|███████▏  | 102/141 [02:49<01:06,  1.71s/it]avg_loss = 2.4512481110767252:  72%|███████▏  | 102/141 [02:51<01:06,  1.71s/it]avg_loss = 2.4512481110767252:  73%|███████▎  | 103/141 [02:51<01:05,  1.71s/it]avg_loss = 2.455950461901151:  73%|███████▎  | 103/141 [02:52<01:05,  1.71s/it] avg_loss = 2.455950461901151:  74%|███████▍  | 104/141 [02:52<01:03,  1.71s/it]avg_loss = 2.456002805346534:  74%|███████▍  | 104/141 [02:54<01:03,  1.71s/it]avg_loss = 2.456002805346534:  74%|███████▍  | 105/141 [02:54<01:01,  1.71s/it]avg_loss = 2.455139738208843:  74%|███████▍  | 105/141 [02:56<01:01,  1.71s/it]avg_loss = 2.455139738208843:  75%|███████▌  | 106/141 [02:56<01:00,  1.71s/it]avg_loss = 2.4533481998978375:  75%|███████▌  | 106/141 [02:57<01:00,  1.71s/it]avg_loss = 2.4533481998978375:  76%|███████▌  | 107/141 [02:57<00:58,  1.71s/it]avg_loss = 2.451300353915603:  76%|███████▌  | 107/141 [02:59<00:58,  1.71s/it] avg_loss = 2.451300353915603:  77%|███████▋  | 108/141 [02:59<00:56,  1.71s/it]avg_loss = 2.450197040487867:  77%|███████▋  | 108/141 [03:01<00:56,  1.71s/it]avg_loss = 2.450197040487867:  77%|███████▋  | 109/141 [03:01<00:54,  1.71s/it]avg_loss = 2.4472799929705533:  77%|███████▋  | 109/141 [03:03<00:54,  1.71s/it]avg_loss = 2.4472799929705533:  78%|███████▊  | 110/141 [03:03<00:53,  1.71s/it]avg_loss = 2.449790439090213:  78%|███████▊  | 110/141 [03:04<00:53,  1.71s/it] avg_loss = 2.449790439090213:  79%|███████▊  | 111/141 [03:04<00:51,  1.71s/it]avg_loss = 2.449137872883252:  79%|███████▊  | 111/141 [03:06<00:51,  1.71s/it]avg_loss = 2.449137872883252:  79%|███████▉  | 112/141 [03:06<00:49,  1.72s/it]avg_loss = 2.449698695039327:  79%|███████▉  | 112/141 [03:08<00:49,  1.72s/it]avg_loss = 2.449698695039327:  80%|████████  | 113/141 [03:08<00:48,  1.72s/it]avg_loss = 2.45066643806926:  80%|████████  | 113/141 [03:09<00:48,  1.72s/it] avg_loss = 2.45066643806926:  81%|████████  | 114/141 [03:09<00:46,  1.72s/it]avg_loss = 2.4487979391346806:  81%|████████  | 114/141 [03:11<00:46,  1.72s/it]avg_loss = 2.4487979391346806:  82%|████████▏ | 115/141 [03:11<00:44,  1.72s/it]avg_loss = 2.447859681885818:  82%|████████▏ | 115/141 [03:13<00:44,  1.72s/it] avg_loss = 2.447859681885818:  82%|████████▏ | 116/141 [03:13<00:42,  1.72s/it]avg_loss = 2.4503113163842096:  82%|████████▏ | 116/141 [03:15<00:42,  1.72s/it]avg_loss = 2.4503113163842096:  83%|████████▎ | 117/141 [03:15<00:41,  1.72s/it]avg_loss = 2.449206629041898:  83%|████████▎ | 117/141 [03:16<00:41,  1.72s/it] avg_loss = 2.449206629041898:  84%|████████▎ | 118/141 [03:16<00:39,  1.72s/it]avg_loss = 2.447468921917827:  84%|████████▎ | 118/141 [03:18<00:39,  1.72s/it]avg_loss = 2.447468921917827:  84%|████████▍ | 119/141 [03:18<00:37,  1.72s/it]avg_loss = 2.4450832466284433:  84%|████████▍ | 119/141 [03:20<00:37,  1.72s/it]avg_loss = 2.4450832466284433:  85%|████████▌ | 120/141 [03:20<00:36,  1.72s/it]avg_loss = 2.4452307697170035:  85%|████████▌ | 120/141 [03:21<00:36,  1.72s/it]avg_loss = 2.4452307697170035:  86%|████████▌ | 121/141 [03:21<00:34,  1.72s/it]avg_loss = 2.4453750477462517:  86%|████████▌ | 121/141 [03:23<00:34,  1.72s/it]avg_loss = 2.4453750477462517:  87%|████████▋ | 122/141 [03:23<00:32,  1.72s/it]avg_loss = 2.4444048327159105:  87%|████████▋ | 122/141 [03:25<00:32,  1.72s/it]avg_loss = 2.4444048327159105:  87%|████████▋ | 123/141 [03:25<00:30,  1.72s/it]avg_loss = 2.444772576132128:  87%|████████▋ | 123/141 [03:27<00:30,  1.72s/it] avg_loss = 2.444772576132128:  88%|████████▊ | 124/141 [03:27<00:29,  1.72s/it]avg_loss = 2.4435303916931153:  88%|████████▊ | 124/141 [03:28<00:29,  1.72s/it]avg_loss = 2.4435303916931153:  89%|████████▊ | 125/141 [03:28<00:27,  1.72s/it]avg_loss = 2.4438988386638583:  89%|████████▊ | 125/141 [03:30<00:27,  1.72s/it]avg_loss = 2.4438988386638583:  89%|████████▉ | 126/141 [03:30<00:25,  1.72s/it]avg_loss = 2.4441924282884973:  89%|████████▉ | 126/141 [03:32<00:25,  1.72s/it]avg_loss = 2.4441924282884973:  90%|█████████ | 127/141 [03:32<00:24,  1.72s/it]avg_loss = 2.442326480522752:  90%|█████████ | 127/141 [03:34<00:24,  1.72s/it] avg_loss = 2.442326480522752:  91%|█████████ | 128/141 [03:34<00:22,  1.72s/it]avg_loss = 2.441760680472204:  91%|█████████ | 128/141 [03:35<00:22,  1.72s/it]avg_loss = 2.441760680472204:  91%|█████████▏| 129/141 [03:35<00:20,  1.72s/it]avg_loss = 2.4428340966884905:  91%|█████████▏| 129/141 [03:37<00:20,  1.72s/it]avg_loss = 2.4428340966884905:  92%|█████████▏| 130/141 [03:37<00:18,  1.72s/it]avg_loss = 2.443567443439979:  92%|█████████▏| 130/141 [03:39<00:18,  1.72s/it] avg_loss = 2.443567443439979:  93%|█████████▎| 131/141 [03:39<00:17,  1.72s/it]avg_loss = 2.4442900852723555:  93%|█████████▎| 131/141 [03:40<00:17,  1.72s/it]avg_loss = 2.4442900852723555:  94%|█████████▎| 132/141 [03:40<00:15,  1.72s/it]avg_loss = 2.440952295647528:  94%|█████████▎| 132/141 [03:42<00:15,  1.72s/it] avg_loss = 2.440952295647528:  94%|█████████▍| 133/141 [03:42<00:13,  1.72s/it]avg_loss = 2.4360928740074383:  94%|█████████▍| 133/141 [03:44<00:13,  1.72s/it]avg_loss = 2.4360928740074383:  95%|█████████▌| 134/141 [03:44<00:12,  1.72s/it]avg_loss = 2.4383759171874435:  95%|█████████▌| 134/141 [03:46<00:12,  1.72s/it]avg_loss = 2.4383759171874435:  96%|█████████▌| 135/141 [03:46<00:10,  1.72s/it]avg_loss = 2.442684440928347:  96%|█████████▌| 135/141 [03:47<00:10,  1.72s/it] avg_loss = 2.442684440928347:  96%|█████████▋| 136/141 [03:47<00:08,  1.72s/it]avg_loss = 2.444175623629215:  96%|█████████▋| 136/141 [03:49<00:08,  1.72s/it]avg_loss = 2.444175623629215:  97%|█████████▋| 137/141 [03:49<00:06,  1.72s/it]avg_loss = 2.4429561132970066:  97%|█████████▋| 137/141 [03:51<00:06,  1.72s/it]avg_loss = 2.4429561132970066:  98%|█████████▊| 138/141 [03:51<00:05,  1.72s/it]avg_loss = 2.4430293342192395:  98%|█████████▊| 138/141 [03:52<00:05,  1.72s/it]avg_loss = 2.4430293342192395:  99%|█████████▊| 139/141 [03:52<00:03,  1.72s/it]avg_loss = 2.444780158145087:  99%|█████████▊| 139/141 [03:54<00:03,  1.72s/it] avg_loss = 2.444780158145087:  99%|█████████▉| 140/141 [03:54<00:01,  1.72s/it]avg_loss = 2.4459801388125046:  99%|█████████▉| 140/141 [03:56<00:01,  1.72s/it]avg_loss = 2.4459801388125046: 100%|██████████| 141/141 [03:56<00:00,  1.72s/it]avg_loss = 2.4459801388125046: 100%|██████████| 141/141 [03:56<00:00,  1.68s/it]
I0325 15:58:10.014201 881168 eval_ppl.py:107] wikitext2 perplexity: 11.541855812072754
wikitext2 perplexity: 11.542
