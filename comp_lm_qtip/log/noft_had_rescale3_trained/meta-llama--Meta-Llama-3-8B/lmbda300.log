I0403 02:07:37.836385 3274942 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:07:37.836483 3274942 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:07:37.836525 3274942 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:07:38.164299 3274942 config.py:54] PyTorch version 2.6.0 available.
W0403 02:07:38.362542 3274942 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:07:38.982146 3274942 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.81it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.32it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.97it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.59it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.13it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.39it/s]
I0403 02:07:40.563555 3274942 quantize_finetune_llama.py:152] loaded model
I0403 02:07:40.887966 3274942 quantize_finetune_llama.py:190] loaded compression model
I0403 02:08:03.968415 3274942 quantize_finetune_llama.py:194] loaded dataset and devset
I0403 02:08:08.473233 3274942 quantize_finetune_llama.py:214] layer 0 gpu 0
I0403 02:08:11.335420 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 2.6938998699188232s
Use train scale and shift
tensor(-1.5053e-07, device='cuda:0') tensor(0.0156, device='cuda:0')
tensor(0.0156, device='cuda:0') tensor(-1.5053e-07, device='cuda:0')
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0403 02:08:26.348316 3275751 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:08:26.348429 3275751 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:08:26.348473 3275751 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:08:26.736119 3275751 config.py:54] PyTorch version 2.6.0 available.
W0403 02:08:26.964570 3275751 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:08:27.609892 3275751 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:08:27.614151 3274942 quantize_finetune_llama.py:214] layer 1 gpu 1
I0403 02:08:28.654030 3275751 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:08:32.282366 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 4.4656994342803955s
I0403 02:08:36.527965 3275988 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:08:36.528078 3275988 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:08:36.528126 3275988 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:08:36.903205 3275988 config.py:54] PyTorch version 2.6.0 available.
W0403 02:08:37.123038 3275988 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:08:37.754757 3275988 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:08:37.758688 3274942 quantize_finetune_llama.py:214] layer 2 gpu 0
I0403 02:08:38.384449 3275988 data_utils.py:336] using 256 training seqs, 128 validation seqs00_v proxy err 0.001048567472025752 err 0.06199849396944046 tr(WHW.T) 59.12685012817383
bpp_loss 6.366294622421265
0_q proxy err 3.0357772629940882e-05 err 8.744322776794434 tr(WHW.T) 288042.3125
bpp_loss 5.117767333984375
0_k proxy err 2.1660140191670507e-05 err 2.1693310737609863 tr(WHW.T) 100153.140625
bpp_loss 6.737518310546875
0_o proxy err 0.0005048059392720461 err 1.57199227809906 tr(WHW.T) 3114.052734375
bpp_loss 4.66696834564209
0_up proxy err 0.003510966431349516 err 31.108455657958984 tr(WHW.T) 8860.3681640625
bpp_loss 4.188613619123187
0_gate proxy err 0.002077469602227211 err 32.617889404296875 tr(WHW.T) 15700.7783203125
bpp_loss 4.2633530752999445
0_down proxy err 0.0013939770869910717 err 14.991433143615723 tr(WHW.T) 10754.4326171875
bpp_loss 4.630942412785122
1_v proxy err 0.0012891521910205483 err 0.137387216091156 tr(WHW.T) 106.5717544555664
bpp_loss 6.34446382522583
1_q proxy err 3.239587022108026e-05 err 4.6899590492248535 tr(WHW.T) 144770.28125
bpp_loss 5.340329170227051
1_k proxy err 1.911946128529962e-05 err 1.4437170028686523 tr(WHW.T) 75510.3359375
bpp_loss 7.059277057647705
1_o proxy err 0.0012543488992378116 err 2.4735662937164307 tr(WHW.T) 1971.9923095703125
bpp_loss 4.649106740951538
1_up proxy err 0.0038293180987238884 err 31.265625 tr(WHW.T) 8164.80224609375
bpp_loss 4.199428558349609
1_gate proxy err 0.0023356631863862276 err 32.40167236328125 tr(WHW.T) 13872.5791015625
bpp_loss 4.276232719421387
1_down proxy err 4.150522727286443e-05 err 0.577440083026886 tr(WHW.T) 13912.466796875
bpp_loss 4.749457699911935
I0403 02:09:32.198331 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 1.0175635814666748s
I0403 02:09:36.051664 3277009 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:09:36.051760 3277009 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:09:36.051801 3277009 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:09:36.398513 3277009 config.py:54] PyTorch version 2.6.0 available.
W0403 02:09:36.618790 3277009 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:09:37.224612 3277009 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:09:37.229054 3274942 quantize_finetune_llama.py:214] layer 3 gpu 1
I0403 02:09:37.429375 3277009 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:09:38.719866 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 0.9600715637207031s
I0403 02:09:43.030575 3277178 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:09:43.030680 3277178 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:09:43.030720 3277178 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:09:43.466030 3277178 config.py:54] PyTorch version 2.6.0 available.
W0403 02:09:43.696931 3277178 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:09:44.454870 3277178 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:09:44.459106 3274942 quantize_finetune_llama.py:214] layer 4 gpu 0
I0403 02:09:44.783418 3277178 data_utils.py:336] using 256 training seqs, 128 validation se2_v2_v proxy err 0.0007243735017254949 err 0.11169460415840149 tr(WHW.T) 154.19476318359375
bpp_loss 6.334555387496948
2_q proxy err 0.00011889261077158153 err 4.925045013427734 tr(WHW.T) 41424.31640625
bpp_loss 5.1791346073150635
2_k proxy err 5.5986212828429416e-05 err 1.2644248008728027 tr(WHW.T) 22584.57421875
bpp_loss 6.876790761947632
2_o proxy err 0.0012281297240406275 err 2.403813362121582 tr(WHW.T) 1957.2958984375
bpp_loss 4.619564771652222
2_up proxy err 0.00428381422534585 err 32.278907775878906 tr(WHW.T) 7535.0859375
bpp_loss 4.188031469072614
2_gate proxy err 0.0022263203281909227 err 33.45921325683594 tr(WHW.T) 15028.9306640625
bpp_loss 4.296541213989258
2_down proxy err 0.0020406749099493027 err 15.633435249328613 tr(WHW.T) 7660.9140625
bpp_loss 4.6268086433410645
3_v proxy err 0.0005528046749532223 err 0.1585688292980194 tr(WHW.T) 286.84423828125
bpp_loss 6.335252523422241
3_q proxy err 0.00015221728244796395 err 7.234222412109375 tr(WHW.T) 47525.6328125
bpp_loss 5.040539741516113
3_k proxy err 6.920309533597901e-05 err 1.8092870712280273 tr(WHW.T) 26144.59765625
bpp_loss 6.552289962768555
3_o proxy err 0.001696986029855907 err 3.129337787628174 tr(WHW.T) 1844.0562744140625
bpp_loss 4.622243165969849
3_up proxy err 0.00426184618845582 err 31.85087776184082 tr(WHW.T) 7473.4931640625
bpp_loss 4.176173482622419
3_gate proxy err 0.0016125630354508758 err 33.52396774291992 tr(WHW.T) 20789.244140625
bpp_loss 4.360469681876046
3_down proxy err 0.002186832018196583 err 15.167593955993652 tr(WHW.T) 6935.875
bpp_loss 4.620271137782505
I0403 02:10:37.328397 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 1.0258169174194336s
I0403 02:10:41.225687 3278029 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:10:41.225802 3278029 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:10:41.225875 3278029 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:10:41.622411 3278029 config.py:54] PyTorch version 2.6.0 available.
W0403 02:10:41.867737 3278029 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:10:42.571164 3278029 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:10:42.575001 3274942 quantize_finetune_llama.py:214] layer 5 gpu 1
I0403 02:10:42.844313 3278029 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:10:44.161861 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 1.0365288257598877s
I0403 02:10:48.422523 3278166 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:10:48.422746 3278166 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:10:48.422871 3278166 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:10:48.878084 3278166 config.py:54] PyTorch version 2.6.0 available.
W0403 02:10:49.114862 3278166 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:10:49.810029 3278166 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:10:49.814430 3274942 quantize_finetune_llama.py:214] layer 6 gpu 0
I0403 02:10:50.122509 3278166 data_utils.py:336] using 256 training seqs, 128 validation se4_v4_v proxy err 0.0006497823633253574 err 0.18350519239902496 tr(WHW.T) 282.4102478027344
bpp_loss 6.334542989730835
4_q proxy err 0.0001268349151359871 err 6.349973678588867 tr(WHW.T) 50064.87109375
bpp_loss 5.079478740692139
4_k proxy err 5.574586248258129e-05 err 1.631851077079773 tr(WHW.T) 29273.04296875
bpp_loss 6.648936748504639
4_o proxy err 0.002307398244738579 err 2.9616353511810303 tr(WHW.T) 1283.5389404296875
bpp_loss 4.645924091339111
4_up proxy err 0.004220070783048868 err 30.906431198120117 tr(WHW.T) 7323.67578125
bpp_loss 4.163287026541574
4_gate proxy err 0.0011464785784482956 err 33.276493072509766 tr(WHW.T) 29024.958984375
bpp_loss 4.426526750837054
4_down proxy err 0.002287391573190689 err 14.493162155151367 tr(WHW.T) 6336.10888671875
bpp_loss 4.618065220969064
5_v proxy err 0.000610192131716758 err 0.12620730698108673 tr(WHW.T) 206.8320770263672
bpp_loss 6.333962678909302
5_q proxy err 0.0001681260037003085 err 6.042818546295166 tr(WHW.T) 35942.19921875
bpp_loss 5.0806756019592285
5_k proxy err 6.801502604503185e-05 err 1.5622079372406006 tr(WHW.T) 22968.5703125
bpp_loss 6.667245626449585
5_o proxy err 0.00247916835360229 err 2.5878849029541016 tr(WHW.T) 1043.85205078125
bpp_loss 4.637428045272827
5_up proxy err 0.0040487684309482574 err 30.75412368774414 tr(WHW.T) 7595.9208984375
bpp_loss 4.1687710625784735
5_gate proxy err 0.0010861577466130257 err 32.88997268676758 tr(WHW.T) 30281.02734375
bpp_loss 4.4285445894513815
5_down proxy err 0.0023153899237513542 err 14.705012321472168 tr(WHW.T) 6350.9873046875
bpp_loss 4.616425786699567
I0403 02:11:43.025975 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 1.090926170349121s
I0403 02:11:46.923498 3278994 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:11:46.923601 3278994 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:11:46.923642 3278994 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:11:47.328077 3278994 config.py:54] PyTorch version 2.6.0 available.
W0403 02:11:47.544032 3278994 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:11:48.197525 3278994 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:11:48.201787 3274942 quantize_finetune_llama.py:214] layer 7 gpu 1
I0403 02:11:48.466246 3278994 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:11:49.698130 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.986553430557251s
I0403 02:11:53.864761 3279206 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:11:53.864875 3279206 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:11:53.864921 3279206 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:11:54.294650 3279206 config.py:54] PyTorch version 2.6.0 available.
W0403 02:11:54.527512 3279206 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:11:55.203132 3279206 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:11:55.207076 3274942 quantize_finetune_llama.py:214] layer 8 gpu 0
I0403 02:11:56.525638 3279206 data_utils.py:336] using 256 training seqs, 128 validation seq6_6_v proxy err 0.0005965519230812788 err 0.14989887177944183 tr(WHW.T) 251.27548217773438
bpp_loss 6.3348259925842285
6_q proxy err 0.00018398315296508372 err 6.547616958618164 tr(WHW.T) 35588.1328125
bpp_loss 5.079309701919556
6_k proxy err 6.487455539172515e-05 err 1.6954678297042847 tr(WHW.T) 26134.55859375
bpp_loss 6.588804483413696
6_o proxy err 0.002991386456415057 err 2.980513334274292 tr(WHW.T) 996.3651733398438
bpp_loss 4.6267125606536865
6_up proxy err 0.003826922969892621 err 30.091297149658203 tr(WHW.T) 7863.052734375
bpp_loss 4.173640523638044
6_gate proxy err 0.0009061387972906232 err 32.295989990234375 tr(WHW.T) 35641.328125
bpp_loss 4.439857482910156
6_down proxy err 0.0022789309732615948 err 14.638664245605469 tr(WHW.T) 6423.478515625
bpp_loss 4.617160797119141
7_v proxy err 0.00048034332576207817 err 0.14751742780208588 tr(WHW.T) 307.1083068847656
bpp_loss 6.333420991897583
7_q proxy err 0.00019299313134979457 err 6.773613452911377 tr(WHW.T) 35097.69140625
bpp_loss 4.9958655834198
7_k proxy err 6.754692003596574e-05 err 1.8116676807403564 tr(WHW.T) 26820.87890625
bpp_loss 6.556524276733398
7_o proxy err 0.00325262313708663 err 3.076970100402832 tr(WHW.T) 945.9965209960938
bpp_loss 4.627752304077148
7_up proxy err 0.0034689472522586584 err 29.712465286254883 tr(WHW.T) 8565.2685546875
bpp_loss 4.187060492379325
7_gate proxy err 0.000909002439584583 err 31.633636474609375 tr(WHW.T) 34800.38671875
bpp_loss 4.421756063188825
7_down proxy err 0.0023214288521558046 err 15.026151657104492 tr(WHW.T) 6472.80322265625
bpp_loss 4.618288380759103
I0403 02:12:47.679854 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 1.307481050491333s
I0403 02:12:51.558498 3280135 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:12:51.558599 3280135 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:12:51.558641 3280135 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:12:51.930501 3280135 config.py:54] PyTorch version 2.6.0 available.
W0403 02:12:52.146214 3280135 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:12:52.824493 3280135 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:12:52.828593 3274942 quantize_finetune_llama.py:214] layer 9 gpu 1
I0403 02:12:53.124062 3280135 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:12:54.378747 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.9778280258178711s
I0403 02:12:58.596914 3280285 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:12:58.597026 3280285 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:12:58.597069 3280285 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:12:59.079766 3280285 config.py:54] PyTorch version 2.6.0 available.
W0403 02:12:59.298848 3280285 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:12:59.959285 3280285 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:12:59.963341 3274942 quantize_finetune_llama.py:214] layer 10 gpu 0
I0403 02:13:00.380407 3280285 data_utils.py:336] using 256 training seqs, 128 validation seq8_8_v proxy err 0.0006366404122672975 err 0.16243621706962585 tr(WHW.T) 255.14593505859375
bpp_loss 6.335503101348877
8_q proxy err 0.0002425592247163877 err 6.440768241882324 tr(WHW.T) 26553.384765625
bpp_loss 5.015859365463257
8_k proxy err 7.644791185157374e-05 err 1.720047950744629 tr(WHW.T) 22499.607421875
bpp_loss 6.555444002151489
8_o proxy err 0.0043732658959925175 err 3.2006704807281494 tr(WHW.T) 731.8719482421875
bpp_loss 4.627152919769287
8_up proxy err 0.0035009898710995913 err 29.52532386779785 tr(WHW.T) 8433.421875
bpp_loss 4.184894970485142
8_gate proxy err 0.0008458211668767035 err 31.408733367919922 tr(WHW.T) 37134.01171875
bpp_loss 4.428919519696917
8_down proxy err 0.0023260354064404964 err 14.950348854064941 tr(WHW.T) 6427.3955078125
bpp_loss 4.61749267578125
9_v proxy err 0.0006304469425231218 err 0.21937872469425201 tr(WHW.T) 347.97332763671875
bpp_loss 6.335256338119507
9_q proxy err 0.0002541320864111185 err 6.5072102546691895 tr(WHW.T) 25605.623046875
bpp_loss 5.0070695877075195
9_k proxy err 8.342270302819088e-05 err 1.744667410850525 tr(WHW.T) 20913.580078125
bpp_loss 6.530519485473633
9_o proxy err 0.0043601393699646 err 3.317451238632202 tr(WHW.T) 760.8590087890625
bpp_loss 4.655597925186157
9_up proxy err 0.0033350896555930376 err 29.708633422851562 tr(WHW.T) 8907.896484375
bpp_loss 4.190653256007603
9_gate proxy err 0.0008047095616348088 err 31.632305145263672 tr(WHW.T) 39308.97265625
bpp_loss 4.44289003099714
9_down proxy err 0.0024299791548401117 err 15.09282398223877 tr(WHW.T) 6211.091796875
bpp_loss 4.616792270115444
I0403 02:13:55.507690 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.9889345169067383s
I0403 02:13:59.622097 3281126 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:13:59.622194 3281126 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:13:59.622235 3281126 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:14:00.009624 3281126 config.py:54] PyTorch version 2.6.0 available.
W0403 02:14:00.240608 3281126 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:14:00.941146 3281126 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:14:00.945339 3274942 quantize_finetune_llama.py:214] layer 11 gpu 1
I0403 02:14:01.132343 3281126 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:14:02.422224 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 0.9264039993286133s
I0403 02:14:06.620947 3281272 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:14:06.621056 3281272 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:14:06.621096 3281272 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:14:07.066431 3281272 config.py:54] PyTorch version 2.6.0 available.
W0403 02:14:07.294807 3281272 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:14:07.957556 3281272 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:14:07.961943 3274942 quantize_finetune_llama.py:214] layer 12 gpu 0
I0403 02:14:08.211141 3281272 data_utils.py:336] using 256 training seqs, 128 validation seq1010_v proxy err 0.0006354694487527013 err 0.15845218300819397 tr(WHW.T) 249.34664916992188
bpp_loss 6.333212852478027
10_q proxy err 0.00025870418176054955 err 6.024891376495361 tr(WHW.T) 23288.728515625
bpp_loss 5.068832874298096
10_k proxy err 8.170994988176972e-05 err 1.6108533143997192 tr(WHW.T) 19714.28515625
bpp_loss 6.628121376037598
10_o proxy err 0.004409155808389187 err 2.9419827461242676 tr(WHW.T) 667.2440185546875
bpp_loss 4.641239881515503
10_up proxy err 0.0032806056551635265 err 29.966400146484375 tr(WHW.T) 9134.4111328125
bpp_loss 4.201238904680524
10_gate proxy err 0.0008485974976792932 err 31.65077781677246 tr(WHW.T) 37297.75
bpp_loss 4.413000379289899
10_down proxy err 0.002402703743427992 err 15.525369644165039 tr(WHW.T) 6461.62451171875
bpp_loss 4.6165531022208075
11_v proxy err 0.0004891307326033711 err 0.1551189422607422 tr(WHW.T) 317.1318664550781
bpp_loss 6.335348844528198
11_q proxy err 0.00028467082302086055 err 6.304469108581543 tr(WHW.T) 22146.5234375
bpp_loss 4.963911056518555
11_k proxy err 9.326925646746531e-05 err 1.6787090301513672 tr(WHW.T) 17998.525390625
bpp_loss 6.5415565967559814
11_o proxy err 0.005282274913042784 err 2.9154794216156006 tr(WHW.T) 551.9363403320312
bpp_loss 4.654700994491577
11_up proxy err 0.0032147173769772053 err 29.340652465820312 tr(WHW.T) 9126.9775390625
bpp_loss 4.211265019008091
11_gate proxy err 0.0008451778558082879 err 31.08985137939453 tr(WHW.T) 36784.98046875
bpp_loss 4.402311733790806
11_down proxy err 0.002388578373938799 err 15.74379825592041 tr(WHW.T) 6591.28369140625
bpp_loss 4.617482049124582
I0403 02:15:00.411532 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 0.9037423133850098s
I0403 02:15:04.366455 3282292 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:15:04.366557 3282292 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:15:04.366603 3282292 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:15:04.758382 3282292 config.py:54] PyTorch version 2.6.0 available.
W0403 02:15:04.990637 3282292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:15:05.645438 3282292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:15:05.649541 3274942 quantize_finetune_llama.py:214] layer 13 gpu 1
I0403 02:15:06.167771 3282292 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:15:07.058512 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 0.9276418685913086s
I0403 02:15:11.199708 3282446 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:15:11.199842 3282446 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:15:11.199895 3282446 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:15:11.608711 3282446 config.py:54] PyTorch version 2.6.0 available.
W0403 02:15:11.832202 3282446 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:15:12.450047 3282446 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:15:12.454077 3274942 quantize_finetune_llama.py:214] layer 14 gpu 0
I0403 02:15:12.870588 3282446 data_utils.py:336] using 256 training seqs, 128 validation seq1212_v proxy err 0.0005991726648062468 err 0.21583496034145355 tr(WHW.T) 360.2216491699219
bpp_loss 6.334227800369263
12_q proxy err 0.00020352264982648194 err 6.931385040283203 tr(WHW.T) 34057.0703125
bpp_loss 4.955256700515747
12_k proxy err 7.771491073071957e-05 err 1.7897380590438843 tr(WHW.T) 23029.533203125
bpp_loss 6.451955080032349
12_o proxy err 0.00470283068716526 err 3.5935747623443604 tr(WHW.T) 764.130126953125
bpp_loss 4.632813215255737
12_up proxy err 0.0028608187567442656 err 28.490707397460938 tr(WHW.T) 9958.9345703125
bpp_loss 4.233334541320801
12_gate proxy err 0.0008190054213628173 err 30.497535705566406 tr(WHW.T) 37237.28125
bpp_loss 4.393114226205008
12_down proxy err 0.0023751608096063137 err 16.04688262939453 tr(WHW.T) 6756.125
bpp_loss 4.621234825679234
13_v proxy err 0.0006635311874561012 err 0.1839635968208313 tr(WHW.T) 277.2493591308594
bpp_loss 6.332663536071777
13_q proxy err 0.00030011372291482985 err 6.2576117515563965 tr(WHW.T) 20850.80078125
bpp_loss 5.004783868789673
13_k proxy err 9.734438935993239e-05 err 1.7297430038452148 tr(WHW.T) 17769.314453125
bpp_loss 6.548462867736816
13_o proxy err 0.004877195693552494 err 3.220372438430786 tr(WHW.T) 660.2918090820312
bpp_loss 4.647849082946777
13_up proxy err 0.0028614141047000885 err 28.447254180908203 tr(WHW.T) 9941.6767578125
bpp_loss 4.236107962472098
13_gate proxy err 0.0007929193670861423 err 30.7843074798584 tr(WHW.T) 38824.0078125
bpp_loss 4.393854413713727
13_down proxy err 0.0024768610019236803 err 16.084646224975586 tr(WHW.T) 6493.9638671875
bpp_loss 4.620299816131592
I0403 02:16:07.614675 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 0.9961786270141602s
I0403 02:16:11.474424 3283280 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:16:11.474529 3283280 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:16:11.474573 3283280 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:16:11.876668 3283280 config.py:54] PyTorch version 2.6.0 available.
W0403 02:16:12.099804 3283280 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:16:12.718615 3283280 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:16:12.722409 3274942 quantize_finetune_llama.py:214] layer 15 gpu 1
I0403 02:16:12.927241 3283280 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:16:14.045751 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 0.8201239109039307s
I0403 02:16:18.171405 3283420 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:16:18.171512 3283420 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:16:18.171557 3283420 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:16:18.561739 3283420 config.py:54] PyTorch version 2.6.0 available.
W0403 02:16:18.775365 3283420 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:16:19.428148 3283420 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:16:19.432363 3274942 quantize_finetune_llama.py:214] layer 16 gpu 0
I0403 02:16:19.634901 3283420 data_utils.py:336] using 256 training seqs, 128 validation s14_v14_v proxy err 0.0006496934220194817 err 0.18093428015708923 tr(WHW.T) 278.4917907714844
bpp_loss 6.333888530731201
14_q proxy err 0.000281206943327561 err 5.859575271606445 tr(WHW.T) 20837.234375
bpp_loss 4.998623609542847
14_k proxy err 8.664600318297744e-05 err 1.610771894454956 tr(WHW.T) 18590.26171875
bpp_loss 6.590193033218384
14_o proxy err 0.004997252952307463 err 3.3557558059692383 tr(WHW.T) 671.5200805664062
bpp_loss 4.635134935379028
14_up proxy err 0.003056187415495515 err 27.799701690673828 tr(WHW.T) 9096.203125
bpp_loss 4.237426212855747
14_gate proxy err 0.0007451869896613061 err 31.062118530273438 tr(WHW.T) 41683.65625
bpp_loss 4.420592035566058
14_down proxy err 0.0025020597968250513 err 15.82470417022705 tr(WHW.T) 6324.6708984375
bpp_loss 4.62430647441319
15_v proxy err 0.0007619402604177594 err 0.2138391137123108 tr(WHW.T) 280.6507568359375
bpp_loss 6.3351218700408936
15_q proxy err 0.00023862888338044286 err 6.687521457672119 tr(WHW.T) 28024.77734375
bpp_loss 5.110318422317505
15_k proxy err 9.137456800090149e-05 err 1.7218126058578491 tr(WHW.T) 18843.455078125
bpp_loss 6.493148565292358
15_o proxy err 0.004058130085468292 err 3.295416831970215 tr(WHW.T) 812.0530395507812
bpp_loss 4.660597562789917
15_up proxy err 0.0031593062449246645 err 28.204946517944336 tr(WHW.T) 8927.576171875
bpp_loss 4.227818897792271
15_gate proxy err 0.0006850667996332049 err 31.588821411132812 tr(WHW.T) 46110.5703125
bpp_loss 4.44746698651995
15_down proxy err 0.002489617792889476 err 15.76880931854248 tr(WHW.T) 6333.8271484375
bpp_loss 4.621744155883789
I0403 02:17:12.318073 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.8592512607574463s
I0403 02:17:16.354403 3284417 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:17:16.354511 3284417 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:17:16.354552 3284417 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:17:16.756126 3284417 config.py:54] PyTorch version 2.6.0 available.
W0403 02:17:16.984633 3284417 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:17:17.629264 3284417 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:17:17.633568 3274942 quantize_finetune_llama.py:214] layer 17 gpu 1
I0403 02:17:18.206793 3284417 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:17:18.866883 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 0.7564942836761475s
I0403 02:17:23.007460 3284558 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:17:23.007564 3284558 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:17:23.007605 3284558 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:17:23.449988 3284558 config.py:54] PyTorch version 2.6.0 available.
W0403 02:17:23.688031 3284558 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:17:24.420766 3284558 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:17:24.425594 3274942 quantize_finetune_llama.py:214] layer 18 gpu 0
I0403 02:17:24.713782 3284558 data_utils.py:336] using 256 training seqs, 128 validation s16_v16_v proxy err 0.0006928970688022673 err 0.18799421191215515 tr(WHW.T) 271.31622314453125
bpp_loss 6.335253953933716
16_q proxy err 0.0002396372437942773 err 5.85574197769165 tr(WHW.T) 24435.859375
bpp_loss 5.101728439331055
16_k proxy err 8.014796185307205e-05 err 1.5611002445220947 tr(WHW.T) 19477.728515625
bpp_loss 6.61101508140564
16_o proxy err 0.003528853412717581 err 3.366364002227783 tr(WHW.T) 953.9540405273438
bpp_loss 4.641239643096924
16_up proxy err 0.0035495914053171873 err 29.341005325317383 tr(WHW.T) 8266.0234375
bpp_loss 4.208301271711077
16_gate proxy err 0.0007873408030718565 err 32.33108901977539 tr(WHW.T) 41063.65234375
bpp_loss 4.470837865556989
16_down proxy err 0.0024831206537783146 err 15.456064224243164 tr(WHW.T) 6224.45166015625
bpp_loss 4.6195453235081265
17_v proxy err 0.0008089899201877415 err 0.2268296331167221 tr(WHW.T) 280.38623046875
bpp_loss 6.335480213165283
17_q proxy err 0.00023629730276297778 err 6.502830505371094 tr(WHW.T) 27519.69921875
bpp_loss 5.07825231552124
17_k proxy err 9.850045898929238e-05 err 1.7139925956726074 tr(WHW.T) 17400.859375
bpp_loss 6.520519495010376
17_o proxy err 0.003096149768680334 err 3.376192331314087 tr(WHW.T) 1090.4486083984375
bpp_loss 4.661957025527954
17_up proxy err 0.0035560461692512035 err 29.82779884338379 tr(WHW.T) 8387.9111328125
bpp_loss 4.201454162597656
17_gate proxy err 0.0007878486649133265 err 32.776702880859375 tr(WHW.T) 41602.7890625
bpp_loss 4.481161253792899
17_down proxy err 0.0025236434303224087 err 15.517114639282227 tr(WHW.T) 6148.6953125
bpp_loss 4.617268426077707
I0403 02:18:18.174040 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.857546329498291s
I0403 02:18:22.408318 3285377 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:18:22.408440 3285377 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:18:22.408493 3285377 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:18:22.824569 3285377 config.py:54] PyTorch version 2.6.0 available.
W0403 02:18:23.042689 3285377 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:18:23.763316 3285377 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:18:23.767396 3274942 quantize_finetune_llama.py:214] layer 19 gpu 1
I0403 02:18:24.136473 3285377 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:18:25.597727 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 1.3328545093536377s
I0403 02:18:29.766463 3285526 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:18:29.766593 3285526 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:18:29.766642 3285526 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:18:30.251335 3285526 config.py:54] PyTorch version 2.6.0 available.
W0403 02:18:30.494541 3285526 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:18:31.264135 3285526 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:18:31.268134 3274942 quantize_finetune_llama.py:214] layer 20 gpu 0
I0403 02:18:31.583270 3285526 data_utils.py:336] using 256 training seqs, 128 validation s18_v18_v proxy err 0.0006514832493849099 err 0.18547721207141876 tr(WHW.T) 284.69989013671875
bpp_loss 6.335077524185181
18_q proxy err 0.0002918103418778628 err 6.521814346313477 tr(WHW.T) 22349.49609375
bpp_loss 5.046449661254883
18_k proxy err 0.00010281553841196 err 1.7853293418884277 tr(WHW.T) 17364.392578125
bpp_loss 6.535481691360474
18_o proxy err 0.0027836239896714687 err 3.3063673973083496 tr(WHW.T) 1187.7923583984375
bpp_loss 4.650844573974609
18_up proxy err 0.003890339285135269 err 30.80736541748047 tr(WHW.T) 7918.9404296875
bpp_loss 4.1898491723196845
18_gate proxy err 0.0009467566851526499 err 33.2579345703125 tr(WHW.T) 35128.28125
bpp_loss 4.4800213405064175
18_down proxy err 0.002507570432499051 err 15.455086708068848 tr(WHW.T) 6163.37109375
bpp_loss 4.616377830505371
19_v proxy err 0.00061303551774472 err 0.2070774883031845 tr(WHW.T) 337.79034423828125
bpp_loss 6.335545539855957
19_q proxy err 0.0002801689552143216 err 6.720652103424072 tr(WHW.T) 23987.85546875
bpp_loss 5.036447286605835
19_k proxy err 0.00011128973710583523 err 1.7277956008911133 tr(WHW.T) 15525.201171875
bpp_loss 6.459887981414795
19_o proxy err 0.0030088787898421288 err 3.4695348739624023 tr(WHW.T) 1153.098876953125
bpp_loss 4.645824909210205
19_up proxy err 0.00409332662820816 err 31.05138397216797 tr(WHW.T) 7585.85546875
bpp_loss 4.18485232761928
19_gate proxy err 0.0010214860085397959 err 33.39780807495117 tr(WHW.T) 32695.314453125
bpp_loss 4.486969130379813
19_down proxy err 0.002510957419872284 err 15.3665771484375 tr(WHW.T) 6119.80810546875
bpp_loss 4.616225242614746
I0403 02:19:30.350192 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.046402931213379s
I0403 02:19:34.210872 3286542 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:19:34.210978 3286542 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:19:34.211020 3286542 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:19:34.644265 3286542 config.py:54] PyTorch version 2.6.0 available.
W0403 02:19:34.862303 3286542 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:19:35.564579 3286542 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:19:35.568511 3274942 quantize_finetune_llama.py:214] layer 21 gpu 1
I0403 02:19:36.423614 3286542 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:19:37.010130 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.9743428230285645s
I0403 02:19:41.317000 3286737 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:19:41.317102 3286737 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:19:41.317143 3286737 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:19:41.724317 3286737 config.py:54] PyTorch version 2.6.0 available.
W0403 02:19:41.955991 3286737 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:19:42.629461 3286737 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:19:42.633382 3274942 quantize_finetune_llama.py:214] layer 22 gpu 0
I0403 02:19:42.937559 3286737 data_utils.py:336] using 256 training seqs, 128 validation se20_20_v proxy err 0.0006996889715082943 err 0.22851181030273438 tr(WHW.T) 326.5905456542969
bpp_loss 6.3349385261535645
20_q proxy err 0.00030329672154039145 err 6.274815559387207 tr(WHW.T) 20688.703125
bpp_loss 5.043704271316528
20_k proxy err 0.00010692739306250587 err 1.643312692642212 tr(WHW.T) 15368.4912109375
bpp_loss 6.468683481216431
20_o proxy err 0.002896950813010335 err 3.4463844299316406 tr(WHW.T) 1189.6593017578125
bpp_loss 4.641669273376465
20_up proxy err 0.004141268320381641 err 31.207746505737305 tr(WHW.T) 7535.79443359375
bpp_loss 4.186223575047085
20_gate proxy err 0.001095661660656333 err 33.470672607421875 tr(WHW.T) 30548.365234375
bpp_loss 4.485905238560268
20_down proxy err 0.002484231488779187 err 15.495328903198242 tr(WHW.T) 6237.4736328125
bpp_loss 4.616048608507429
21_v proxy err 0.0006782980053685606 err 0.24353080987930298 tr(WHW.T) 359.03216552734375
bpp_loss 6.336847305297852
21_q proxy err 0.00025201146490871906 err 6.499432563781738 tr(WHW.T) 25790.224609375
bpp_loss 5.015124559402466
21_k proxy err 0.00010076758917421103 err 1.6888407468795776 tr(WHW.T) 16759.76171875
bpp_loss 6.473398447036743
21_o proxy err 0.002461165189743042 err 3.077543020248413 tr(WHW.T) 1250.4415283203125
bpp_loss 4.684253692626953
21_up proxy err 0.004033790901303291 err 31.09377670288086 tr(WHW.T) 7708.326171875
bpp_loss 4.189546040126255
21_gate proxy err 0.0010629388270899653 err 33.427101135253906 tr(WHW.T) 31447.8125
bpp_loss 4.497346878051758
21_down proxy err 0.0024744332768023014 err 15.558521270751953 tr(WHW.T) 6287.7109375
bpp_loss 4.616717542920794
I0403 02:20:41.505602 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 0.9810705184936523s
I0403 02:20:45.540077 3287623 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:20:45.540175 3287623 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:20:45.540217 3287623 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:20:45.896401 3287623 config.py:54] PyTorch version 2.6.0 available.
W0403 02:20:46.149324 3287623 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:20:46.865880 3287623 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:20:46.869910 3274942 quantize_finetune_llama.py:214] layer 23 gpu 1
I0403 02:20:47.211486 3287623 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:20:48.286693 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 0.8001866340637207s
I0403 02:20:52.934102 3287759 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:20:52.934269 3287759 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:20:52.934312 3287759 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:20:53.436353 3287759 config.py:54] PyTorch version 2.6.0 available.
W0403 02:20:53.674318 3287759 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:20:54.501385 3287759 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:20:54.506071 3274942 quantize_finetune_llama.py:214] layer 24 gpu 0
I0403 02:20:54.776465 3287759 data_utils.py:336] using 256 training seqs, 128 validation se22_22_v proxy err 0.0007872675778344274 err 0.26910480856895447 tr(WHW.T) 341.8212890625
bpp_loss 6.335792541503906
22_q proxy err 0.0002970969071611762 err 6.023395538330078 tr(WHW.T) 20274.177734375
bpp_loss 5.0010645389556885
22_k proxy err 0.00010833693522727117 err 1.5922856330871582 tr(WHW.T) 14697.5322265625
bpp_loss 6.478826284408569
22_o proxy err 0.003261432284489274 err 3.9300951957702637 tr(WHW.T) 1205.021240234375
bpp_loss 4.629385948181152
22_up proxy err 0.004202202893793583 err 31.443424224853516 tr(WHW.T) 7482.60498046875
bpp_loss 4.189586775643485
22_gate proxy err 0.0011351939756423235 err 33.39234924316406 tr(WHW.T) 29415.544921875
bpp_loss 4.497030258178711
22_down proxy err 0.0024274829775094986 err 15.694418907165527 tr(WHW.T) 6465.3056640625
bpp_loss 4.61604608808245
23_v proxy err 0.0007613262860104442 err 0.29934147000312805 tr(WHW.T) 393.1842041015625
bpp_loss 6.332549095153809
23_q proxy err 0.00029309274395927787 err 6.6130828857421875 tr(WHW.T) 22563.107421875
bpp_loss 4.969304323196411
23_k proxy err 0.0001138784209615551 err 1.6889417171478271 tr(WHW.T) 14831.095703125
bpp_loss 6.403408527374268
23_o proxy err 0.002374888863414526 err 4.101467609405518 tr(WHW.T) 1727.0145263671875
bpp_loss 4.62878680229187
23_up proxy err 0.004281379748135805 err 31.485462188720703 tr(WHW.T) 7354.04541015625
bpp_loss 4.192306246076312
23_gate proxy err 0.0012231966247782111 err 33.23757553100586 tr(WHW.T) 27172.716796875
bpp_loss 4.499958038330078
23_down proxy err 0.0023982850834727287 err 15.834104537963867 tr(WHW.T) 6602.26123046875
bpp_loss 4.61584506716047
I0403 02:21:57.259336 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.9235813617706299s
I0403 02:22:01.092503 3288731 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:22:01.092597 3288731 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:22:01.092637 3288731 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:22:01.456352 3288731 config.py:54] PyTorch version 2.6.0 available.
W0403 02:22:01.685967 3288731 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:22:02.284028 3288731 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:22:02.287894 3274942 quantize_finetune_llama.py:214] layer 25 gpu 1
I0403 02:22:02.555452 3288731 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:22:04.091039 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 1.2285361289978027s
I0403 02:22:08.354639 3288945 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:22:08.354745 3288945 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:22:08.354790 3288945 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:22:08.783137 3288945 config.py:54] PyTorch version 2.6.0 available.
W0403 02:22:09.006530 3288945 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:22:09.715625 3288945 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:22:09.719582 3274942 quantize_finetune_llama.py:214] layer 26 gpu 0
I0403 02:22:09.918439 3288945 data_utils.py:336] using 256 training seqs, 128 validation se24_24_v proxy err 0.0007786851492710412 err 0.35943350195884705 tr(WHW.T) 461.59027099609375
bpp_loss 6.335040807723999
24_q proxy err 0.0002902710984926671 err 6.499684810638428 tr(WHW.T) 22391.7734375
bpp_loss 4.95289421081543
24_k proxy err 0.00011326531239319593 err 1.6037859916687012 tr(WHW.T) 14159.55078125
bpp_loss 6.361437797546387
24_o proxy err 0.0026721321046352386 err 4.196285247802734 tr(WHW.T) 1570.388427734375
bpp_loss 4.652324438095093
24_up proxy err 0.0043664369732141495 err 31.636606216430664 tr(WHW.T) 7245.40576171875
bpp_loss 4.194856779915946
24_gate proxy err 0.0012909133220091462 err 33.250484466552734 tr(WHW.T) 25757.33203125
bpp_loss 4.505392347063337
24_down proxy err 0.002396572381258011 err 16.000905990600586 tr(WHW.T) 6676.57958984375
bpp_loss 4.615774154663086
25_v proxy err 0.0006619513151235878 err 0.3654273450374603 tr(WHW.T) 552.045654296875
bpp_loss 6.334609031677246
25_q proxy err 0.00025802504387684166 err 6.7264814376831055 tr(WHW.T) 26069.1015625
bpp_loss 4.914942026138306
25_k proxy err 0.00011060468386858702 err 1.5919325351715088 tr(WHW.T) 14392.994140625
bpp_loss 6.353970766067505
25_o proxy err 0.0021265936084091663 err 4.191924571990967 tr(WHW.T) 1971.1920166015625
bpp_loss 4.6566808223724365
25_up proxy err 0.0043098595924675465 err 31.52797508239746 tr(WHW.T) 7315.31396484375
bpp_loss 4.202642713274274
25_gate proxy err 0.001265955506823957 err 33.150047302246094 tr(WHW.T) 26185.79296875
bpp_loss 4.515898704528809
25_down proxy err 0.002484631724655628 err 16.273012161254883 tr(WHW.T) 6549.46630859375
bpp_loss 4.6158858026777
I0403 02:23:09.938047 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 1.244659662246704s
I0403 02:23:14.224704 3289940 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:23:14.224873 3289940 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:23:14.224914 3289940 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:23:14.857977 3289940 config.py:54] PyTorch version 2.6.0 available.
W0403 02:23:15.146892 3289940 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:23:16.038127 3289940 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:23:16.042312 3274942 quantize_finetune_llama.py:214] layer 27 gpu 1
I0403 02:23:16.244431 3289940 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:23:17.843130 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 1.2536077499389648s
I0403 02:23:22.860778 3290100 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:23:22.860939 3290100 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:23:22.860982 3290100 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:23:23.470538 3290100 config.py:54] PyTorch version 2.6.0 available.
W0403 02:23:23.731045 3290100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:23:24.566772 3290100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:23:24.571525 3274942 quantize_finetune_llama.py:214] layer 28 gpu 0
I0403 02:23:24.888205 3290100 data_utils.py:336] using 256 training seqs, 128 validation se26_26_v proxy err 0.0009393412619829178 err 0.4022091329097748 tr(WHW.T) 428.18212890625
bpp_loss 6.335138320922852
26_q proxy err 0.00029521153192035854 err 6.305640697479248 tr(WHW.T) 21359.736328125
bpp_loss 4.951411724090576
26_k proxy err 0.00010544374526944011 err 1.6238715648651123 tr(WHW.T) 15400.359375
bpp_loss 6.410944700241089
26_o proxy err 0.001667543314397335 err 3.9498093128204346 tr(WHW.T) 2368.6396484375
bpp_loss 4.690463304519653
26_up proxy err 0.004156166221946478 err 31.494112014770508 tr(WHW.T) 7577.68359375
bpp_loss 4.20980031149728
26_gate proxy err 0.0011519459076225758 err 33.150814056396484 tr(WHW.T) 28778.099609375
bpp_loss 4.525535311017718
26_down proxy err 0.0025254711508750916 err 16.544904708862305 tr(WHW.T) 6551.21533203125
bpp_loss 4.61603661945888
27_v proxy err 0.0006961466278880835 err 0.46665701270103455 tr(WHW.T) 670.343017578125
bpp_loss 6.33370566368103
27_q proxy err 0.00031273794593289495 err 6.650012493133545 tr(WHW.T) 21263.849609375
bpp_loss 4.9030656814575195
27_k proxy err 0.00011798053310485557 err 1.650189757347107 tr(WHW.T) 13986.966796875
bpp_loss 6.353573560714722
27_o proxy err 0.002002973575145006 err 4.283926010131836 tr(WHW.T) 2138.783203125
bpp_loss 4.684274911880493
27_up proxy err 0.003787245135754347 err 31.835079193115234 tr(WHW.T) 8405.8671875
bpp_loss 4.21827643258231
27_gate proxy err 0.0010240006959065795 err 33.468082427978516 tr(WHW.T) 32683.65234375
bpp_loss 4.5351201466151645
27_down proxy err 0.0023832463193684816 err 15.429668426513672 tr(WHW.T) 6474.22314453125
bpp_loss 4.649059976850237
I0403 02:24:29.577440 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 1.0130062103271484s
I0403 02:24:33.730072 3291047 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:24:33.730174 3291047 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:24:33.730215 3291047 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:24:34.129975 3291047 config.py:54] PyTorch version 2.6.0 available.
W0403 02:24:34.369768 3291047 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:24:35.130745 3291047 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:24:35.134583 3274942 quantize_finetune_llama.py:214] layer 29 gpu 1
I0403 02:24:35.640766 3291047 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:24:36.643597 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 1.0472164154052734s
I0403 02:24:40.949701 3291210 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:24:40.949803 3291210 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:24:40.949846 3291210 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:24:41.354349 3291210 config.py:54] PyTorch version 2.6.0 available.
W0403 02:24:41.576269 3291210 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:24:42.304936 3291210 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:24:42.308774 3274942 quantize_finetune_llama.py:214] layer 30 gpu 0
I0403 02:24:42.516795 3291210 data_utils.py:336] using 256 training seqs, 128 validation s28_v28_v proxy err 0.0008422808023169637 err 0.49994707107543945 tr(WHW.T) 593.5634155273438
bpp_loss 6.334815979003906
28_q proxy err 0.000289919349597767 err 6.703441143035889 tr(WHW.T) 23121.744140625
bpp_loss 4.901614665985107
28_k proxy err 0.00010264212323818356 err 1.5367426872253418 tr(WHW.T) 14971.8525390625
bpp_loss 6.332428693771362
28_o proxy err 0.0016733426600694656 err 4.165166854858398 tr(WHW.T) 2489.129638671875
bpp_loss 4.71494722366333
28_up proxy err 0.0030888153705745935 err 31.423734664916992 tr(WHW.T) 10173.3935546875
bpp_loss 4.239581789289202
28_gate proxy err 0.0009249460999853909 err 33.11033630371094 tr(WHW.T) 35797.04296875
bpp_loss 4.529577527727399
28_down proxy err 0.002166296821087599 err 15.464238166809082 tr(WHW.T) 7138.55908203125
bpp_loss 4.6610934393746515
29_v proxy err 0.0006487080827355385 err 0.5460882186889648 tr(WHW.T) 841.8088989257812
bpp_loss 6.334355592727661
29_q proxy err 0.0003678342036437243 err 7.581636905670166 tr(WHW.T) 20611.560546875
bpp_loss 4.833038091659546
29_k proxy err 0.00010370016389060766 err 1.6945929527282715 tr(WHW.T) 16341.275390625
bpp_loss 6.3458287715911865
29_o proxy err 0.0011782252695411444 err 3.627730131149292 tr(WHW.T) 3078.978271484375
bpp_loss 4.7831947803497314
29_up proxy err 0.002473248168826103 err 31.637142181396484 tr(WHW.T) 12791.73828125
bpp_loss 4.262954575674875
29_gate proxy err 0.0008673456613905728 err 33.168365478515625 tr(WHW.T) 38241.23046875
bpp_loss 4.525506155831473
29_down proxy err 0.0018426518654450774 err 13.628942489624023 tr(WHW.T) 7396.3740234375
bpp_loss 4.714448383876255
I0403 02:25:41.743279 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 1.0933136940002441s
I0403 02:25:46.240395 3292273 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:25:46.240538 3292273 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:25:46.240582 3292273 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:25:46.683397 3292273 config.py:54] PyTorch version 2.6.0 available.
W0403 02:25:46.915371 3292273 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:25:47.663543 3292273 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:25:47.669386 3274942 quantize_finetune_llama.py:214] layer 31 gpu 1
I0403 02:25:47.897194 3292273 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:25:49.778076 3274942 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 1.4368419647216797s
I0403 02:25:54.271134 3292431 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:25:54.271275 3292431 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:25:54.271317 3292431 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:25:54.802047 3292431 config.py:54] PyTorch version 2.6.0 available.
W0403 02:25:55.072462 3292431 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:25:56.238004 3292431 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:25:56.516196 3292431 data_utils.py:336] using 256 training seqs, 128 validation 30_v 30_v proxy err 0.0009243481326848269 err 0.7862973213195801 tr(WHW.T) 850.650634765625
bpp_loss 6.334716796875
30_q proxy err 0.00028136520995758474 err 6.756356239318848 tr(WHW.T) 24012.763671875
bpp_loss 4.823483943939209
30_k proxy err 9.423009760212153e-05 err 1.3203271627426147 tr(WHW.T) 14011.7353515625
bpp_loss 6.332206726074219
30_o proxy err 0.0010842420160770416 err 5.249735355377197 tr(WHW.T) 4841.84814453125
bpp_loss 4.726968050003052
30_up proxy err 0.0015117090661078691 err 32.69900894165039 tr(WHW.T) 21630.490234375
bpp_loss 4.280718803405762
30_gate proxy err 0.0006580852204933763 err 34.1035041809082 tr(WHW.T) 51822.3203125
bpp_loss 4.570073400224958
30_down proxy err 0.0010827264050021768 err 9.45756721496582 tr(WHW.T) 8734.9560546875
bpp_loss 4.808636392865862
31_v proxy err 0.0003504740016069263 err 0.6304634809494019 tr(WHW.T) 1798.8880615234375
bpp_loss 6.336410999298096
31_q proxy err 0.00017970098997466266 err 8.289599418640137 tr(WHW.T) 46129.9609375
bpp_loss 4.872085332870483
31_k proxy err 7.747965719318017e-05 err 1.5840940475463867 tr(WHW.T) 20445.2890625
bpp_loss 6.35440993309021
31_o proxy err 0.0011377950431779027 err 2.488299608230591 tr(WHW.T) 2186.948974609375
bpp_loss 4.913111209869385
31_up proxy err 0.0005098687834106386 err 35.13545227050781 tr(WHW.T) 68910.7734375
bpp_loss 4.433588300432477
31_gate proxy err 0.0002512749924790114 err 36.25418472290039 tr(WHW.T) 144280.90625
bpp_loss 4.773967742919922
31_down proxy err 0.0004758472787216306 err 4.701403617858887 tr(WHW.T) 9880.068359375
bpp_loss 4.929454667227609
 02:26:46.932877 3293026 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:26:46.933019 3293026 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:26:46.933063 3293026 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:26:47.263854 3293026 config.py:54] PyTorch version 2.6.0 available.
W0403 02:26:47.478319 3293026 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:26:47.592387 3293026 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.39it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.55it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.56it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.47it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.61it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.52it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.00it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.13it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.30it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.24it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.02it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]
I0403 02:26:51.107151 3293026 hfize_llama.py:161] loaded layer 0
I0403 02:26:51.927901 3293026 hfize_llama.py:161] loaded layer 1
I0403 02:26:52.806516 3293026 hfize_llama.py:161] loaded layer 2
I0403 02:26:53.602488 3293026 hfize_llama.py:161] loaded layer 3
I0403 02:26:54.419361 3293026 hfize_llama.py:161] loaded layer 4
I0403 02:26:55.184110 3293026 hfize_llama.py:161] loaded layer 5
I0403 02:26:56.077420 3293026 hfize_llama.py:161] loaded layer 6
I0403 02:26:56.912961 3293026 hfize_llama.py:161] loaded layer 7
I0403 02:26:57.712309 3293026 hfize_llama.py:161] loaded layer 8
I0403 02:26:58.522483 3293026 hfize_llama.py:161] loaded layer 9
I0403 02:26:59.401473 3293026 hfize_llama.py:161] loaded layer 10
I0403 02:27:00.229027 3293026 hfize_llama.py:161] loaded layer 11
I0403 02:27:01.005867 3293026 hfize_llama.py:161] loaded layer 12
I0403 02:27:01.832962 3293026 hfize_llama.py:161] loaded layer 13
I0403 02:27:02.652352 3293026 hfize_llama.py:161] loaded layer 14
I0403 02:27:03.575497 3293026 hfize_llama.py:161] loaded layer 15
I0403 02:27:04.355778 3293026 hfize_llama.py:161] loaded layer 16
I0403 02:27:05.216810 3293026 hfize_llama.py:161] loaded layer 17
I0403 02:27:06.085261 3293026 hfize_llama.py:161] loaded layer 18
I0403 02:27:06.974628 3293026 hfize_llama.py:161] loaded layer 19
I0403 02:27:07.825143 3293026 hfize_llama.py:161] loaded layer 20
I0403 02:27:08.597865 3293026 hfize_llama.py:161] loaded layer 21
I0403 02:27:09.370064 3293510 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:27:09.370242 3293510 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:27:09.370285 3293510 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:27:09.608994 3293026 hfize_llama.py:161] loaded layer 22
I0403 02:27:09.701037 3293510 config.py:54] PyTorch version 2.6.0 available.
W0403 02:27:09.916383 3293510 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:27:10.032021 3293510 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

I0403 02:27:10.438832 3293026 hfize_llama.py:161] loaded layer 23
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.70it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.76it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.16it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.38it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.59it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.54it/s]I0403 02:27:11.346120 3293026 hfize_llama.py:161] loaded layer 24
Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.51it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.37it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.59it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.52it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.35it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.55it/s]I0403 02:27:12.237104 3293026 hfize_llama.py:161] loaded layer 25
Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.40it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.46it/s]
I0403 02:27:12.928094 3293026 hfize_llama.py:161] loaded layer 26
I0403 02:27:13.501971 3293510 hfize_llama.py:161] loaded layer 0
I0403 02:27:13.646420 3293026 hfize_llama.py:161] loaded layer 27
I0403 02:27:14.322654 3293026 hfize_llama.py:161] loaded layer 28
I0403 02:27:14.384005 3293510 hfize_llama.py:161] loaded layer 1
I0403 02:27:15.019687 3293026 hfize_llama.py:161] loaded layer 29
I0403 02:27:15.168286 3293510 hfize_llama.py:161] loaded layer 2
I0403 02:27:15.716380 3293026 hfize_llama.py:161] loaded layer 30
I0403 02:27:15.976090 3293510 hfize_llama.py:161] loaded layer 3
I0403 02:27:16.402357 3293026 hfize_llama.py:161] loaded layer 31
I0403 02:27:16.402511 3293026 hfize_llama.py:165] saving model...
I0403 02:27:16.775911 3293510 hfize_llama.py:161] loaded layer 4
I0403 02:27:17.577925 3293510 hfize_llama.py:161] loaded layer 5
I0403 02:27:18.412647 3293510 hfize_llama.py:161] loaded layer 6
I0403 02:27:19.253402 3293510 hfize_llama.py:161] loaded layer 7
I0403 02:27:20.030384 3293510 hfize_llama.py:161] loaded layer 8
I0403 02:27:20.851051 3293510 hfize_llama.py:161] loaded layer 9
I0403 02:27:21.608113 3293510 hfize_llama.py:161] loaded layer 10
I0403 02:27:22.403803 3293510 hfize_llama.py:161] loaded layer 11
I0403 02:27:23.149322 3293510 hfize_llama.py:161] loaded layer 12
I0403 02:27:24.081286 3293510 hfize_llama.py:161] loaded layer 13
I0403 02:27:24.901886 3293510 hfize_llama.py:161] loaded layer 14
I0403 02:27:25.697522 3293510 hfize_llama.py:161] loaded layer 15
I0403 02:27:26.474299 3293510 hfize_llama.py:161] loaded layer 16
I0403 02:27:27.210588 3293510 hfize_llama.py:161] loaded layer 17
I0403 02:27:28.050475 3293510 hfize_llama.py:161] loaded layer 18
I0403 02:27:28.821587 3293510 hfize_llama.py:161] loaded layer 19
I0403 02:27:29.597806 3293510 hfize_llama.py:161] loaded layer 20
I0403 02:27:30.373833 3293510 hfize_llama.py:161] loaded layer 21
I0403 02:27:31.217418 3293510 hfize_llama.py:161] loaded layer 22
I0403 02:27:32.005373 3293510 hfize_llama.py:161] loaded layer 23
I0403 02:27:32.773848 3293510 hfize_llama.py:161] loaded layer 24
I0403 02:27:33.546053 3293510 hfize_llama.py:161] loaded layer 25
I0403 02:27:34.236749 3293510 hfize_llama.py:161] loaded layer 26
I0403 02:27:35.312848 3293510 hfize_llama.py:161] loaded layer 27
I0403 02:27:36.031658 3293510 hfize_llama.py:161] loaded layer 28
I0403 02:27:36.766097 3293510 hfize_llama.py:161] loaded layer 29
I0403 02:27:37.573024 3293510 hfize_llama.py:161] loaded layer 30
I0403 02:27:38.320977 3293510 hfize_llama.py:161] loaded layer 31
I0403 02:27:38.321094 3293510 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:08,  1.36s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.16s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.15s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.10s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.12s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.09s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.08it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.05s/it]
I0403 02:28:02.644458 3293026 hfize_llama.py:175] successfully loaded hfized model
I0403 02:28:07.809620 3294545 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:28:07.809747 3294545 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:28:07.809805 3294545 utils.py:162] NumExpr defaulting to 16 threads.
W0403 02:28:08.167226 3294545 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:28:08.584285 3294545 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.17s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.19s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.24s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:05<00:07,  1.87s/it]
Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 49, in model_from_hf_path
    model = maybe_wrap(use_cuda_graph)(model_cls).from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4755, in _load_pretrained_model
    state_dict = load_state_dict(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 504, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
safetensors_rust.SafetensorError: Error while deserializing header: MetadataIncompleteBuffer
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 194, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 166, in main
    model.save_pretrained(args.hf_output_path, safe_serialization=True)
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3034, in save_pretrained
    safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={"format": "pt"})
  File "/opt/conda/lib/python3.10/site-packages/safetensors/torch.py", line 286, in save_file
    serialize_file(_flatten(tensors), filename, metadata=metadata)
safetensors_rust.SafetensorError: Error while serializing: IoError(Os { code: 2, kind: NotFound, message: "No such file or directory" })
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../hf_model_comp/comp_qtip/hf/noft_had_rescale3_trained/meta-llama--Meta-Llama-3-8B/lmbda300'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 34, in model_from_hf_path
    bad_config = transformers.AutoConfig.from_pretrained(path)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '../hf_model_comp/comp_qtip/hf/noft_had_rescale3_trained/meta-llama--Meta-Llama-3-8B/lmbda300'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
I0403 02:45:13.911970 3307752 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:45:13.912100 3307752 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:45:13.912146 3307752 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:45:14.277814 3307752 config.py:54] PyTorch version 2.6.0 available.
W0403 02:45:14.549906 3307752 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:45:14.671659 3307752 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:01,  4.93it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  6.02it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  6.99it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.73it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.06it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.22it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.37it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.52it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  6.95it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.15it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.09it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.00it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  6.86it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  6.85it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  6.95it/s]
I0403 02:45:18.783942 3307752 hfize_llama.py:161] loaded layer 0
I0403 02:45:20.162316 3307752 hfize_llama.py:161] loaded layer 1
I0403 02:45:21.520402 3307752 hfize_llama.py:161] loaded layer 2
I0403 02:45:22.904664 3307752 hfize_llama.py:161] loaded layer 3
I0403 02:45:24.152777 3307752 hfize_llama.py:161] loaded layer 4
I0403 02:45:25.458408 3307752 hfize_llama.py:161] loaded layer 5
I0403 02:45:26.748688 3307752 hfize_llama.py:161] loaded layer 6
I0403 02:45:28.069360 3307752 hfize_llama.py:161] loaded layer 7
I0403 02:45:29.290734 3307752 hfize_llama.py:161] loaded layer 8
I0403 02:45:30.544399 3307752 hfize_llama.py:161] loaded layer 9
I0403 02:45:31.943337 3307752 hfize_llama.py:161] loaded layer 10
I0403 02:45:33.102378 3307752 hfize_llama.py:161] loaded layer 11
I0403 02:45:34.286333 3307752 hfize_llama.py:161] loaded layer 12
I0403 02:45:35.604199 3307752 hfize_llama.py:161] loaded layer 13
I0403 02:45:36.749384 3307752 hfize_llama.py:161] loaded layer 14
I0403 02:45:38.001819 3307752 hfize_llama.py:161] loaded layer 15
I0403 02:45:39.028268 3307752 hfize_llama.py:161] loaded layer 16
I0403 02:45:40.227138 3307752 hfize_llama.py:161] loaded layer 17
I0403 02:45:41.462297 3307752 hfize_llama.py:161] loaded layer 18
I0403 02:45:42.503731 3307752 hfize_llama.py:161] loaded layer 19
I0403 02:45:43.608057 3307752 hfize_llama.py:161] loaded layer 20
I0403 02:45:44.779929 3307752 hfize_llama.py:161] loaded layer 21
I0403 02:45:45.907306 3307752 hfize_llama.py:161] loaded layer 22
I0403 02:45:47.218289 3307752 hfize_llama.py:161] loaded layer 23
I0403 02:45:48.345441 3307752 hfize_llama.py:161] loaded layer 24
I0403 02:45:49.423944 3307752 hfize_llama.py:161] loaded layer 25
I0403 02:45:50.444730 3307752 hfize_llama.py:161] loaded layer 26
I0403 02:45:51.436037 3307752 hfize_llama.py:161] loaded layer 27
I0403 02:45:52.380588 3307752 hfize_llama.py:161] loaded layer 28
I0403 02:45:53.537166 3307752 hfize_llama.py:161] loaded layer 29
I0403 02:45:54.535935 3307752 hfize_llama.py:161] loaded layer 30
I0403 02:45:55.473559 3307752 hfize_llama.py:161] loaded layer 31
I0403 02:45:55.473688 3307752 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.25s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.26s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.25s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.24s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.28s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:07<00:01,  1.24s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.03s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]
I0403 02:46:44.408011 3307752 hfize_llama.py:175] successfully loaded hfized model
I0403 02:46:49.384568 3309162 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:46:49.384693 3309162 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:46:49.384737 3309162 utils.py:162] NumExpr defaulting to 16 threads.
W0403 02:46:49.753632 3309162 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:46:50.225409 3309162 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:05,  1.02it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.26s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.35s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:05<00:04,  1.36s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:06<00:02,  1.40s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.41s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.26s/it]
I0403 02:46:59.162604 3309162 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 1.5419118404388428:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 1.5419118404388428:   1%|          | 1/141 [00:01<04:19,  1.86s/it]avg_loss = 1.8606772422790527:   1%|          | 1/141 [00:03<04:19,  1.86s/it]avg_loss = 1.8606772422790527:   1%|▏         | 2/141 [00:03<03:44,  1.62s/it]avg_loss = 1.9973115921020508:   1%|▏         | 2/141 [00:04<03:44,  1.62s/it]avg_loss = 1.9973115921020508:   2%|▏         | 3/141 [00:04<03:32,  1.54s/it]avg_loss = 1.953675091266632:   2%|▏         | 3/141 [00:06<03:32,  1.54s/it] avg_loss = 1.953675091266632:   3%|▎         | 4/141 [00:06<03:26,  1.51s/it]avg_loss = 1.9055605411529541:   3%|▎         | 4/141 [00:07<03:26,  1.51s/it]avg_loss = 1.9055605411529541:   4%|▎         | 5/141 [00:07<03:22,  1.49s/it]avg_loss = 1.809520920117696:   4%|▎         | 5/141 [00:09<03:22,  1.49s/it] avg_loss = 1.809520920117696:   4%|▍         | 6/141 [00:09<03:19,  1.48s/it]avg_loss = 1.7442797763007027:   4%|▍         | 6/141 [00:10<03:19,  1.48s/it]avg_loss = 1.7442797763007027:   5%|▍         | 7/141 [00:10<03:17,  1.47s/it]avg_loss = 1.7412375211715698:   5%|▍         | 7/141 [00:12<03:17,  1.47s/it]avg_loss = 1.7412375211715698:   6%|▌         | 8/141 [00:12<03:16,  1.47s/it]avg_loss = 1.7760376930236816:   6%|▌         | 8/141 [00:13<03:16,  1.47s/it]avg_loss = 1.7760376930236816:   6%|▋         | 9/141 [00:13<03:14,  1.47s/it]avg_loss = 1.7810767769813538:   6%|▋         | 9/141 [00:15<03:14,  1.47s/it]avg_loss = 1.7810767769813538:   7%|▋         | 10/141 [00:15<03:13,  1.47s/it]avg_loss = 1.777695189822804:   7%|▋         | 10/141 [00:16<03:13,  1.47s/it] avg_loss = 1.777695189822804:   8%|▊         | 11/141 [00:16<03:11,  1.48s/it]avg_loss = 1.800993651151657:   8%|▊         | 11/141 [00:17<03:11,  1.48s/it]avg_loss = 1.800993651151657:   9%|▊         | 12/141 [00:17<03:10,  1.48s/it]avg_loss = 1.813877903498136:   9%|▊         | 12/141 [00:19<03:10,  1.48s/it]avg_loss = 1.813877903498136:   9%|▉         | 13/141 [00:19<03:09,  1.48s/it]avg_loss = 1.8323758585112435:   9%|▉         | 13/141 [00:20<03:09,  1.48s/it]avg_loss = 1.8323758585112435:  10%|▉         | 14/141 [00:20<03:08,  1.48s/it]avg_loss = 1.8425442854563394:  10%|▉         | 14/141 [00:22<03:08,  1.48s/it]avg_loss = 1.8425442854563394:  11%|█         | 15/141 [00:22<03:07,  1.48s/it]avg_loss = 1.8672780841588974:  11%|█         | 15/141 [00:23<03:07,  1.48s/it]avg_loss = 1.8672780841588974:  11%|█▏        | 16/141 [00:23<03:05,  1.49s/it]avg_loss = 1.870416851604686:  11%|█▏        | 16/141 [00:25<03:05,  1.49s/it] avg_loss = 1.870416851604686:  12%|█▏        | 17/141 [00:25<03:04,  1.49s/it]avg_loss = 1.8729765481419034:  12%|█▏        | 17/141 [00:26<03:04,  1.49s/it]avg_loss = 1.8729765481419034:  13%|█▎        | 18/141 [00:26<03:03,  1.49s/it]avg_loss = 1.8531046666597064:  13%|█▎        | 18/141 [00:28<03:03,  1.49s/it]avg_loss = 1.8531046666597064:  13%|█▎        | 19/141 [00:28<03:02,  1.50s/it]avg_loss = 1.8521830558776855:  13%|█▎        | 19/141 [00:29<03:02,  1.50s/it]avg_loss = 1.8521830558776855:  14%|█▍        | 20/141 [00:29<03:01,  1.50s/it]avg_loss = 1.857009666306632:  14%|█▍        | 20/141 [00:31<03:01,  1.50s/it] avg_loss = 1.857009666306632:  15%|█▍        | 21/141 [00:31<03:00,  1.50s/it]avg_loss = 1.8595316139134495:  15%|█▍        | 21/141 [00:32<03:00,  1.50s/it]avg_loss = 1.8595316139134495:  16%|█▌        | 22/141 [00:32<02:58,  1.50s/it]avg_loss = 1.8610333929891172:  16%|█▌        | 22/141 [00:34<02:58,  1.50s/it]avg_loss = 1.8610333929891172:  16%|█▋        | 23/141 [00:34<02:57,  1.51s/it]avg_loss = 1.8660824447870255:  16%|█▋        | 23/141 [00:35<02:57,  1.51s/it]avg_loss = 1.8660824447870255:  17%|█▋        | 24/141 [00:35<02:56,  1.51s/it]avg_loss = 1.8720111894607543:  17%|█▋        | 24/141 [00:37<02:56,  1.51s/it]avg_loss = 1.8720111894607543:  18%|█▊        | 25/141 [00:37<02:55,  1.51s/it]avg_loss = 1.8835921058287988:  18%|█▊        | 25/141 [00:39<02:55,  1.51s/it]avg_loss = 1.8835921058287988:  18%|█▊        | 26/141 [00:39<02:54,  1.52s/it]avg_loss = 1.8965286369676944:  18%|█▊        | 26/141 [00:40<02:54,  1.52s/it]avg_loss = 1.8965286369676944:  19%|█▉        | 27/141 [00:40<02:53,  1.52s/it]avg_loss = 1.9032534658908844:  19%|█▉        | 27/141 [00:42<02:53,  1.52s/it]avg_loss = 1.9032534658908844:  20%|█▉        | 28/141 [00:42<02:51,  1.52s/it]avg_loss = 1.9000612168476498:  20%|█▉        | 28/141 [00:43<02:51,  1.52s/it]avg_loss = 1.9000612168476498:  21%|██        | 29/141 [00:43<02:50,  1.52s/it]avg_loss = 1.8903687874476114:  21%|██        | 29/141 [00:45<02:50,  1.52s/it]avg_loss = 1.8903687874476114:  21%|██▏       | 30/141 [00:45<02:49,  1.53s/it]avg_loss = 1.8758568994460567:  21%|██▏       | 30/141 [00:46<02:49,  1.53s/it]avg_loss = 1.8758568994460567:  22%|██▏       | 31/141 [00:46<02:47,  1.53s/it]avg_loss = 1.8637882433831692:  22%|██▏       | 31/141 [00:48<02:47,  1.53s/it]avg_loss = 1.8637882433831692:  23%|██▎       | 32/141 [00:48<02:46,  1.53s/it]avg_loss = 1.8625676595803462:  23%|██▎       | 32/141 [00:49<02:46,  1.53s/it]avg_loss = 1.8625676595803462:  23%|██▎       | 33/141 [00:49<02:45,  1.53s/it]avg_loss = 1.8610710501670837:  23%|██▎       | 33/141 [00:51<02:45,  1.53s/it]avg_loss = 1.8610710501670837:  24%|██▍       | 34/141 [00:51<02:44,  1.53s/it]avg_loss = 1.8640604904719762:  24%|██▍       | 34/141 [00:52<02:44,  1.53s/it]avg_loss = 1.8640604904719762:  25%|██▍       | 35/141 [00:52<02:42,  1.54s/it]avg_loss = 1.8477723664707608:  25%|██▍       | 35/141 [00:54<02:42,  1.54s/it]avg_loss = 1.8477723664707608:  26%|██▌       | 36/141 [00:54<02:41,  1.54s/it]avg_loss = 1.8324920164572227:  26%|██▌       | 36/141 [00:55<02:41,  1.54s/it]avg_loss = 1.8324920164572227:  26%|██▌       | 37/141 [00:55<02:39,  1.54s/it]avg_loss = 1.8177040501644737:  26%|██▌       | 37/141 [00:57<02:39,  1.54s/it]avg_loss = 1.8177040501644737:  27%|██▋       | 38/141 [00:57<02:38,  1.54s/it]avg_loss = 1.8037398686775794:  27%|██▋       | 38/141 [00:58<02:38,  1.54s/it]avg_loss = 1.8037398686775794:  28%|██▊       | 39/141 [00:58<02:37,  1.54s/it]avg_loss = 1.7954751580953598:  28%|██▊       | 39/141 [01:00<02:37,  1.54s/it]avg_loss = 1.7954751580953598:  28%|██▊       | 40/141 [01:00<02:35,  1.54s/it]avg_loss = 1.8004713436452353:  28%|██▊       | 40/141 [01:02<02:35,  1.54s/it]avg_loss = 1.8004713436452353:  29%|██▉       | 41/141 [01:02<02:34,  1.54s/it]avg_loss = 1.8177939454714458:  29%|██▉       | 41/141 [01:03<02:34,  1.54s/it]avg_loss = 1.8177939454714458:  30%|██▉       | 42/141 [01:03<02:33,  1.55s/it]avg_loss = 1.8342655952586684:  30%|██▉       | 42/141 [01:05<02:33,  1.55s/it]avg_loss = 1.8342655952586684:  30%|███       | 43/141 [01:05<02:31,  1.55s/it]avg_loss = 1.8369716243310408:  30%|███       | 43/141 [01:06<02:31,  1.55s/it]avg_loss = 1.8369716243310408:  31%|███       | 44/141 [01:06<02:30,  1.55s/it]avg_loss = 1.8412854353586832:  31%|███       | 44/141 [01:08<02:30,  1.55s/it]avg_loss = 1.8412854353586832:  32%|███▏      | 45/141 [01:08<02:28,  1.55s/it]avg_loss = 1.8469272644623467:  32%|███▏      | 45/141 [01:09<02:28,  1.55s/it]avg_loss = 1.8469272644623467:  33%|███▎      | 46/141 [01:09<02:27,  1.55s/it]avg_loss = 1.8535816010008468:  33%|███▎      | 46/141 [01:11<02:27,  1.55s/it]avg_loss = 1.8535816010008468:  33%|███▎      | 47/141 [01:11<02:25,  1.55s/it]avg_loss = 1.856891706585884:  33%|███▎      | 47/141 [01:12<02:25,  1.55s/it] avg_loss = 1.856891706585884:  34%|███▍      | 48/141 [01:12<02:24,  1.55s/it]avg_loss = 1.8554773549644314:  34%|███▍      | 48/141 [01:14<02:24,  1.55s/it]avg_loss = 1.8554773549644314:  35%|███▍      | 49/141 [01:14<02:22,  1.55s/it]avg_loss = 1.8551937770843505:  35%|███▍      | 49/141 [01:16<02:22,  1.55s/it]avg_loss = 1.8551937770843505:  35%|███▌      | 50/141 [01:16<02:21,  1.55s/it]avg_loss = 1.8486602376489079:  35%|███▌      | 50/141 [01:17<02:21,  1.55s/it]avg_loss = 1.8486602376489079:  36%|███▌      | 51/141 [01:17<02:19,  1.55s/it]avg_loss = 1.8449362447628608:  36%|███▌      | 51/141 [01:19<02:19,  1.55s/it]avg_loss = 1.8449362447628608:  37%|███▋      | 52/141 [01:19<02:18,  1.56s/it]avg_loss = 1.8384335243477012:  37%|███▋      | 52/141 [01:20<02:18,  1.56s/it]avg_loss = 1.8384335243477012:  38%|███▊      | 53/141 [01:20<02:17,  1.56s/it]avg_loss = 1.8355969941174541:  38%|███▊      | 53/141 [01:22<02:17,  1.56s/it]avg_loss = 1.8355969941174541:  38%|███▊      | 54/141 [01:22<02:15,  1.56s/it]avg_loss = 1.827998568794944:  38%|███▊      | 54/141 [01:23<02:15,  1.56s/it] avg_loss = 1.827998568794944:  39%|███▉      | 55/141 [01:23<02:14,  1.56s/it]avg_loss = 1.8203326314687729:  39%|███▉      | 55/141 [01:25<02:14,  1.56s/it]avg_loss = 1.8203326314687729:  40%|███▉      | 56/141 [01:25<02:12,  1.56s/it]avg_loss = 1.8136916474292153:  40%|███▉      | 56/141 [01:27<02:12,  1.56s/it]avg_loss = 1.8136916474292153:  40%|████      | 57/141 [01:27<02:11,  1.57s/it]avg_loss = 1.81100228326074:  40%|████      | 57/141 [01:28<02:11,  1.57s/it]  avg_loss = 1.81100228326074:  41%|████      | 58/141 [01:28<02:10,  1.57s/it]avg_loss = 1.813333268892967:  41%|████      | 58/141 [01:30<02:10,  1.57s/it]avg_loss = 1.813333268892967:  42%|████▏     | 59/141 [01:30<02:08,  1.57s/it]avg_loss = 1.8191367983818054:  42%|████▏     | 59/141 [01:31<02:08,  1.57s/it]avg_loss = 1.8191367983818054:  43%|████▎     | 60/141 [01:31<02:07,  1.57s/it]avg_loss = 1.8252177785654538:  43%|████▎     | 60/141 [01:33<02:07,  1.57s/it]avg_loss = 1.8252177785654538:  43%|████▎     | 61/141 [01:33<02:05,  1.57s/it]avg_loss = 1.832602939298076:  43%|████▎     | 61/141 [01:34<02:05,  1.57s/it] avg_loss = 1.832602939298076:  44%|████▍     | 62/141 [01:34<02:04,  1.57s/it]avg_loss = 1.8233947924205236:  44%|████▍     | 62/141 [01:36<02:04,  1.57s/it]avg_loss = 1.8233947924205236:  45%|████▍     | 63/141 [01:36<02:02,  1.57s/it]avg_loss = 1.8213212583214045:  45%|████▍     | 63/141 [01:38<02:02,  1.57s/it]avg_loss = 1.8213212583214045:  45%|████▌     | 64/141 [01:38<02:01,  1.57s/it]avg_loss = 1.8187627975757306:  45%|████▌     | 64/141 [01:39<02:01,  1.57s/it]avg_loss = 1.8187627975757306:  46%|████▌     | 65/141 [01:39<01:59,  1.58s/it]avg_loss = 1.8127513473684138:  46%|████▌     | 65/141 [01:41<01:59,  1.58s/it]avg_loss = 1.8127513473684138:  47%|████▋     | 66/141 [01:41<01:58,  1.57s/it]avg_loss = 1.8101231482491564:  47%|████▋     | 66/141 [01:42<01:58,  1.57s/it]avg_loss = 1.8101231482491564:  48%|████▊     | 67/141 [01:42<01:56,  1.58s/it]avg_loss = 1.8066220143262077:  48%|████▊     | 67/141 [01:44<01:56,  1.58s/it]avg_loss = 1.8066220143262077:  48%|████▊     | 68/141 [01:44<01:55,  1.58s/it]avg_loss = 1.8037403977435569:  48%|████▊     | 68/141 [01:45<01:55,  1.58s/it]avg_loss = 1.8037403977435569:  49%|████▉     | 69/141 [01:45<01:53,  1.58s/it]avg_loss = 1.804684591293335:  49%|████▉     | 69/141 [01:47<01:53,  1.58s/it] avg_loss = 1.804684591293335:  50%|████▉     | 70/141 [01:47<01:52,  1.58s/it]avg_loss = 1.8085610497165734:  50%|████▉     | 70/141 [01:49<01:52,  1.58s/it]avg_loss = 1.8085610497165734:  50%|█████     | 71/141 [01:49<01:50,  1.58s/it]avg_loss = 1.8109004580312305:  50%|█████     | 71/141 [01:50<01:50,  1.58s/it]avg_loss = 1.8109004580312305:  51%|█████     | 72/141 [01:50<01:48,  1.58s/it]avg_loss = 1.809553430504995:  51%|█████     | 72/141 [01:52<01:48,  1.58s/it] avg_loss = 1.809553430504995:  52%|█████▏    | 73/141 [01:52<01:47,  1.58s/it]avg_loss = 1.8113521901336875:  52%|█████▏    | 73/141 [01:53<01:47,  1.58s/it]avg_loss = 1.8113521901336875:  52%|█████▏    | 74/141 [01:53<01:45,  1.58s/it]avg_loss = 1.8115983788172405:  52%|█████▏    | 74/141 [01:55<01:45,  1.58s/it]avg_loss = 1.8115983788172405:  53%|█████▎    | 75/141 [01:55<01:44,  1.58s/it]avg_loss = 1.8104930347517918:  53%|█████▎    | 75/141 [01:56<01:44,  1.58s/it]avg_loss = 1.8104930347517918:  54%|█████▍    | 76/141 [01:56<01:42,  1.58s/it]avg_loss = 1.8117482708646107:  54%|█████▍    | 76/141 [01:58<01:42,  1.58s/it]avg_loss = 1.8117482708646107:  55%|█████▍    | 77/141 [01:58<01:40,  1.58s/it]avg_loss = 1.8142421627656007:  55%|█████▍    | 77/141 [02:00<01:40,  1.58s/it]avg_loss = 1.8142421627656007:  55%|█████▌    | 78/141 [02:00<01:39,  1.58s/it]avg_loss = 1.8185033209716217:  55%|█████▌    | 78/141 [02:01<01:39,  1.58s/it]avg_loss = 1.8185033209716217:  56%|█████▌    | 79/141 [02:01<01:37,  1.58s/it]avg_loss = 1.8156877860426903:  56%|█████▌    | 79/141 [02:03<01:37,  1.58s/it]avg_loss = 1.8156877860426903:  57%|█████▋    | 80/141 [02:03<01:36,  1.58s/it]avg_loss = 1.81466038580294:  57%|█████▋    | 80/141 [02:04<01:36,  1.58s/it]  avg_loss = 1.81466038580294:  57%|█████▋    | 81/141 [02:04<01:34,  1.58s/it]avg_loss = 1.8140078666733532:  57%|█████▋    | 81/141 [02:06<01:34,  1.58s/it]avg_loss = 1.8140078666733532:  58%|█████▊    | 82/141 [02:06<01:33,  1.58s/it]avg_loss = 1.8122966418783348:  58%|█████▊    | 82/141 [02:08<01:33,  1.58s/it]avg_loss = 1.8122966418783348:  59%|█████▉    | 83/141 [02:08<01:31,  1.58s/it]avg_loss = 1.8102388495490664:  59%|█████▉    | 83/141 [02:09<01:31,  1.58s/it]avg_loss = 1.8102388495490664:  60%|█████▉    | 84/141 [02:09<01:30,  1.58s/it]avg_loss = 1.8079227615805233:  60%|█████▉    | 84/141 [02:11<01:30,  1.58s/it]avg_loss = 1.8079227615805233:  60%|██████    | 85/141 [02:11<01:28,  1.58s/it]avg_loss = 1.8097773790359497:  60%|██████    | 85/141 [02:12<01:28,  1.58s/it]avg_loss = 1.8097773790359497:  61%|██████    | 86/141 [02:12<01:27,  1.58s/it]avg_loss = 1.811799437150188:  61%|██████    | 86/141 [02:14<01:27,  1.58s/it] avg_loss = 1.811799437150188:  62%|██████▏   | 87/141 [02:14<01:25,  1.58s/it]avg_loss = 1.8119799223813144:  62%|██████▏   | 87/141 [02:15<01:25,  1.58s/it]avg_loss = 1.8119799223813144:  62%|██████▏   | 88/141 [02:15<01:24,  1.59s/it]avg_loss = 1.8207791628462544:  62%|██████▏   | 88/141 [02:17<01:24,  1.59s/it]avg_loss = 1.8207791628462544:  63%|██████▎   | 89/141 [02:17<01:22,  1.59s/it]avg_loss = 1.8283218251334297:  63%|██████▎   | 89/141 [02:19<01:22,  1.59s/it]avg_loss = 1.8283218251334297:  64%|██████▍   | 90/141 [02:19<01:21,  1.59s/it]avg_loss = 1.831478367795001:  64%|██████▍   | 90/141 [02:20<01:21,  1.59s/it] avg_loss = 1.831478367795001:  65%|██████▍   | 91/141 [02:20<01:19,  1.59s/it]avg_loss = 1.8364964023880337:  65%|██████▍   | 91/141 [02:22<01:19,  1.59s/it]avg_loss = 1.8364964023880337:  65%|██████▌   | 92/141 [02:22<01:17,  1.59s/it]avg_loss = 1.8415535188490344:  65%|██████▌   | 92/141 [02:23<01:17,  1.59s/it]avg_loss = 1.8415535188490344:  66%|██████▌   | 93/141 [02:23<01:16,  1.59s/it]avg_loss = 1.842636006943723:  66%|██████▌   | 93/141 [02:25<01:16,  1.59s/it] avg_loss = 1.842636006943723:  67%|██████▋   | 94/141 [02:25<01:14,  1.59s/it]avg_loss = 1.8464935980345074:  67%|██████▋   | 94/141 [02:27<01:14,  1.59s/it]avg_loss = 1.8464935980345074:  67%|██████▋   | 95/141 [02:27<01:13,  1.59s/it]avg_loss = 1.8474955670535564:  67%|██████▋   | 95/141 [02:28<01:13,  1.59s/it]avg_loss = 1.8474955670535564:  68%|██████▊   | 96/141 [02:28<01:11,  1.59s/it]avg_loss = 1.849460229431231:  68%|██████▊   | 96/141 [02:30<01:11,  1.59s/it] avg_loss = 1.849460229431231:  69%|██████▉   | 97/141 [02:30<01:10,  1.59s/it]avg_loss = 1.844334571945424:  69%|██████▉   | 97/141 [02:31<01:10,  1.59s/it]avg_loss = 1.844334571945424:  70%|██████▉   | 98/141 [02:31<01:08,  1.59s/it]avg_loss = 1.8449731439051003:  70%|██████▉   | 98/141 [02:33<01:08,  1.59s/it]avg_loss = 1.8449731439051003:  70%|███████   | 99/141 [02:33<01:06,  1.59s/it]avg_loss = 1.8467766010761262:  70%|███████   | 99/141 [02:35<01:06,  1.59s/it]avg_loss = 1.8467766010761262:  71%|███████   | 100/141 [02:35<01:05,  1.59s/it]avg_loss = 1.8452402034608444:  71%|███████   | 100/141 [02:36<01:05,  1.59s/it]avg_loss = 1.8452402034608444:  72%|███████▏  | 101/141 [02:36<01:03,  1.59s/it]avg_loss = 1.8452613587472952:  72%|███████▏  | 101/141 [02:38<01:03,  1.59s/it]avg_loss = 1.8452613587472952:  72%|███████▏  | 102/141 [02:38<01:01,  1.59s/it]avg_loss = 1.8430696864729945:  72%|███████▏  | 102/141 [02:39<01:01,  1.59s/it]avg_loss = 1.8430696864729945:  73%|███████▎  | 103/141 [02:39<01:00,  1.59s/it]avg_loss = 1.8453851674611752:  73%|███████▎  | 103/141 [02:41<01:00,  1.59s/it]avg_loss = 1.8453851674611752:  74%|███████▍  | 104/141 [02:41<00:58,  1.59s/it]avg_loss = 1.843343320347014:  74%|███████▍  | 104/141 [02:42<00:58,  1.59s/it] avg_loss = 1.843343320347014:  74%|███████▍  | 105/141 [02:42<00:57,  1.59s/it]avg_loss = 1.841940627907807:  74%|███████▍  | 105/141 [02:44<00:57,  1.59s/it]avg_loss = 1.841940627907807:  75%|███████▌  | 106/141 [02:44<00:55,  1.59s/it]avg_loss = 1.8394856408377673:  75%|███████▌  | 106/141 [02:46<00:55,  1.59s/it]avg_loss = 1.8394856408377673:  76%|███████▌  | 107/141 [02:46<00:54,  1.59s/it]avg_loss = 1.837089744982896:  76%|███████▌  | 107/141 [02:47<00:54,  1.59s/it] avg_loss = 1.837089744982896:  77%|███████▋  | 108/141 [02:47<00:52,  1.59s/it]avg_loss = 1.834382489186908:  77%|███████▋  | 108/141 [02:49<00:52,  1.59s/it]avg_loss = 1.834382489186908:  77%|███████▋  | 109/141 [02:49<00:50,  1.59s/it]avg_loss = 1.831900372288444:  77%|███████▋  | 109/141 [02:50<00:50,  1.59s/it]avg_loss = 1.831900372288444:  78%|███████▊  | 110/141 [02:50<00:49,  1.59s/it]avg_loss = 1.8342745508159604:  78%|███████▊  | 110/141 [02:52<00:49,  1.59s/it]avg_loss = 1.8342745508159604:  79%|███████▊  | 111/141 [02:52<00:47,  1.59s/it]avg_loss = 1.8340822117669242:  79%|███████▊  | 111/141 [02:54<00:47,  1.59s/it]avg_loss = 1.8340822117669242:  79%|███████▉  | 112/141 [02:54<00:46,  1.59s/it]avg_loss = 1.8352886396171773:  79%|███████▉  | 112/141 [02:55<00:46,  1.59s/it]avg_loss = 1.8352886396171773:  80%|████████  | 113/141 [02:55<00:44,  1.59s/it]avg_loss = 1.836285690466563:  80%|████████  | 113/141 [02:57<00:44,  1.59s/it] avg_loss = 1.836285690466563:  81%|████████  | 114/141 [02:57<00:42,  1.59s/it]avg_loss = 1.835728353002797:  81%|████████  | 114/141 [02:58<00:42,  1.59s/it]avg_loss = 1.835728353002797:  82%|████████▏ | 115/141 [02:58<00:41,  1.59s/it]avg_loss = 1.8342297601288762:  82%|████████▏ | 115/141 [03:00<00:41,  1.59s/it]avg_loss = 1.8342297601288762:  82%|████████▏ | 116/141 [03:00<00:39,  1.59s/it]avg_loss = 1.8363754576088016:  82%|████████▏ | 116/141 [03:02<00:39,  1.59s/it]avg_loss = 1.8363754576088016:  83%|████████▎ | 117/141 [03:02<00:38,  1.59s/it]avg_loss = 1.8361493066205816:  83%|████████▎ | 117/141 [03:03<00:38,  1.59s/it]avg_loss = 1.8361493066205816:  84%|████████▎ | 118/141 [03:03<00:36,  1.59s/it]avg_loss = 1.8348108860624939:  84%|████████▎ | 118/141 [03:05<00:36,  1.59s/it]avg_loss = 1.8348108860624939:  84%|████████▍ | 119/141 [03:05<00:34,  1.59s/it]avg_loss = 1.8331221411625545:  84%|████████▍ | 119/141 [03:06<00:34,  1.59s/it]avg_loss = 1.8331221411625545:  85%|████████▌ | 120/141 [03:06<00:33,  1.59s/it]avg_loss = 1.8329733137256843:  85%|████████▌ | 120/141 [03:08<00:33,  1.59s/it]avg_loss = 1.8329733137256843:  86%|████████▌ | 121/141 [03:08<00:31,  1.59s/it]avg_loss = 1.8333255081880289:  86%|████████▌ | 121/141 [03:09<00:31,  1.59s/it]avg_loss = 1.8333255081880289:  87%|████████▋ | 122/141 [03:09<00:30,  1.59s/it]avg_loss = 1.8332261961650074:  87%|████████▋ | 122/141 [03:11<00:30,  1.59s/it]avg_loss = 1.8332261961650074:  87%|████████▋ | 123/141 [03:11<00:28,  1.59s/it]avg_loss = 1.8335084059546072:  87%|████████▋ | 123/141 [03:13<00:28,  1.59s/it]avg_loss = 1.8335084059546072:  88%|████████▊ | 124/141 [03:13<00:26,  1.59s/it]avg_loss = 1.8323322143554688:  88%|████████▊ | 124/141 [03:14<00:26,  1.59s/it]avg_loss = 1.8323322143554688:  89%|████████▊ | 125/141 [03:14<00:25,  1.59s/it]avg_loss = 1.8328224496235923:  89%|████████▊ | 125/141 [03:16<00:25,  1.59s/it]avg_loss = 1.8328224496235923:  89%|████████▉ | 126/141 [03:16<00:23,  1.59s/it]avg_loss = 1.8326010394284105:  89%|████████▉ | 126/141 [03:17<00:23,  1.59s/it]avg_loss = 1.8326010394284105:  90%|█████████ | 127/141 [03:17<00:22,  1.59s/it]avg_loss = 1.831264960579574:  90%|█████████ | 127/141 [03:19<00:22,  1.59s/it] avg_loss = 1.831264960579574:  91%|█████████ | 128/141 [03:19<00:20,  1.59s/it]avg_loss = 1.8315448030944943:  91%|█████████ | 128/141 [03:21<00:20,  1.59s/it]avg_loss = 1.8315448030944943:  91%|█████████▏| 129/141 [03:21<00:19,  1.59s/it]avg_loss = 1.8322546913073614:  91%|█████████▏| 129/141 [03:22<00:19,  1.59s/it]avg_loss = 1.8322546913073614:  92%|█████████▏| 130/141 [03:22<00:17,  1.59s/it]avg_loss = 1.833215299453444:  92%|█████████▏| 130/141 [03:24<00:17,  1.59s/it] avg_loss = 1.833215299453444:  93%|█████████▎| 131/141 [03:24<00:15,  1.59s/it]avg_loss = 1.8339014206871842:  93%|█████████▎| 131/141 [03:25<00:15,  1.59s/it]avg_loss = 1.8339014206871842:  94%|█████████▎| 132/141 [03:25<00:14,  1.60s/it]avg_loss = 1.8311582364534076:  94%|█████████▎| 132/141 [03:27<00:14,  1.60s/it]avg_loss = 1.8311582364534076:  94%|█████████▍| 133/141 [03:27<00:12,  1.60s/it]avg_loss = 1.8268553570135315:  94%|█████████▍| 133/141 [03:29<00:12,  1.60s/it]avg_loss = 1.8268553570135315:  95%|█████████▌| 134/141 [03:29<00:11,  1.60s/it]avg_loss = 1.8294418900101272:  95%|█████████▌| 134/141 [03:30<00:11,  1.60s/it]avg_loss = 1.8294418900101272:  96%|█████████▌| 135/141 [03:30<00:09,  1.60s/it]avg_loss = 1.8329332751386307:  96%|█████████▌| 135/141 [03:32<00:09,  1.60s/it]avg_loss = 1.8329332751386307:  96%|█████████▋| 136/141 [03:32<00:07,  1.60s/it]avg_loss = 1.8338250748432465:  96%|█████████▋| 136/141 [03:33<00:07,  1.60s/it]avg_loss = 1.8338250748432465:  97%|█████████▋| 137/141 [03:33<00:06,  1.60s/it]avg_loss = 1.8325087350347768:  97%|█████████▋| 137/141 [03:35<00:06,  1.60s/it]avg_loss = 1.8325087350347768:  98%|█████████▊| 138/141 [03:35<00:04,  1.60s/it]avg_loss = 1.832656789169037:  98%|█████████▊| 138/141 [03:37<00:04,  1.60s/it] avg_loss = 1.832656789169037:  99%|█████████▊| 139/141 [03:37<00:03,  1.60s/it]avg_loss = 1.8332370272704532:  99%|█████████▊| 139/141 [03:38<00:03,  1.60s/it]avg_loss = 1.8332370272704532:  99%|█████████▉| 140/141 [03:38<00:01,  1.60s/it]avg_loss = 1.8344911066352898:  99%|█████████▉| 140/141 [03:40<00:01,  1.60s/it]avg_loss = 1.8344911066352898: 100%|██████████| 141/141 [03:40<00:00,  1.60s/it]avg_loss = 1.8344911066352898: 100%|██████████| 141/141 [03:40<00:00,  1.56s/it]
I0403 02:51:04.478351 3309162 eval_ppl.py:107] wikitext2 perplexity: 6.261946678161621
wikitext2 perplexity: 6.262
