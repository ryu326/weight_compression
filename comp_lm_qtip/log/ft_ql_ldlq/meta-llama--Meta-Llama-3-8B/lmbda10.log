I0328 01:57:42.702911 2072148 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0328 01:57:42.703013 2072148 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0328 01:57:42.703052 2072148 utils.py:162] NumExpr defaulting to 16 threads.
I0328 01:57:43.023895 2072148 config.py:54] PyTorch version 2.6.0 available.
W0328 01:57:43.214219 2072148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0328 01:57:43.769139 2072148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.10it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.61it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.82it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.94it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.63it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.81it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.97it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.82it/s]
I0328 01:57:45.231608 2072148 quantize_finetune_llama.py:150] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:22,  1.40it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:17,  1.67it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:16,  1.77it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:15,  1.84it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:02<00:14,  1.87it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:13,  1.88it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:03<00:13,  1.90it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:12,  1.91it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:04<00:12,  1.91it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:05<00:11,  1.91it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:05<00:11,  1.91it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:06<00:10,  1.92it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:06<00:09,  1.91it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:07<00:09,  1.91it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:07<00:08,  1.92it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:07,  1.95it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:09<00:07,  1.96it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.95it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:10<00:06,  1.95it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:05,  1.94it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:11<00:05,  1.94it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:04,  1.95it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:12<00:04,  1.98it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:13<00:03,  2.04it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:13<00:02,  2.09it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:13<00:02,  2.13it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:14<00:01,  2.15it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:14<00:01,  2.17it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:15<00:00,  2.18it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:15<00:00,  2.18it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  2.20it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.98it/s]
I0328 01:58:06.989923 2072148 quantize_finetune_llama.py:185] loaded compression model
I0328 01:58:25.383302 2072148 quantize_finetune_llama.py:189] loaded dataset and devset
I0328 01:58:30.787034 2072148 quantize_finetune_llama.py:209] layer 0 gpu 0
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0328 01:58:52.597904 2073016 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0328 01:58:52.598097 2073016 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0328 01:58:52.598137 2073016 utils.py:162] NumExpr defaulting to 16 threads.
I0328 01:58:52.912083 2073016 config.py:54] PyTorch version 2.6.0 available.
W0328 01:58:53.115975 2073016 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 186, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 24, in main
    assert os.path.exists(args.quantized_path)
AssertionError
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../hf_model_comp/comp_qtip/hf/ft_ql_ldlq/meta-llama--Meta-Llama-3-8B/lmbda10'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 34, in model_from_hf_path
    bad_config = transformers.AutoConfig.from_pretrained(path)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '../hf_model_comp/comp_qtip/hf/ft_ql_ldlq/meta-llama--Meta-Llama-3-8B/lmbda10'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
I0328 01:59:17.004163 2073386 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0328 01:59:17.004362 2073386 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0328 01:59:17.004401 2073386 utils.py:162] NumExpr defaulting to 16 threads.
I0328 01:59:17.317120 2073386 config.py:54] PyTorch version 2.6.0 available.
W0328 01:59:17.524989 2073386 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0328 01:59:17.636672 2073386 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.52it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.38it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.78it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.06it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.07it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.26it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.97it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.92it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  9.11it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  9.17it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.15it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.16it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.08it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.20it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s]
I0328 01:59:20.614120 2073386 hfize_llama.py:153] loaded layer 0
I0328 01:59:21.022339 2073386 hfize_llama.py:153] loaded layer 1
I0328 01:59:21.317023 2073386 hfize_llama.py:153] loaded layer 2
I0328 01:59:21.676863 2073386 hfize_llama.py:153] loaded layer 3
I0328 01:59:22.035969 2073386 hfize_llama.py:153] loaded layer 4
I0328 01:59:22.342322 2073386 hfize_llama.py:153] loaded layer 5
I0328 01:59:22.656098 2073386 hfize_llama.py:153] loaded layer 6
I0328 01:59:23.035790 2073386 hfize_llama.py:153] loaded layer 7
I0328 01:59:23.320436 2073386 hfize_llama.py:153] loaded layer 8
I0328 01:59:23.636651 2073386 hfize_llama.py:153] loaded layer 9
I0328 01:59:23.978401 2073386 hfize_llama.py:153] loaded layer 10
I0328 01:59:24.272650 2073386 hfize_llama.py:153] loaded layer 11
I0328 01:59:24.559502 2073386 hfize_llama.py:153] loaded layer 12
I0328 01:59:24.888742 2073386 hfize_llama.py:153] loaded layer 13
I0328 01:59:25.204824 2073386 hfize_llama.py:153] loaded layer 14
I0328 01:59:25.549999 2073386 hfize_llama.py:153] loaded layer 15
I0328 01:59:25.850165 2073386 hfize_llama.py:153] loaded layer 16
I0328 01:59:26.227166 2073386 hfize_llama.py:153] loaded layer 17
I0328 01:59:26.553287 2073386 hfize_llama.py:153] loaded layer 18
I0328 01:59:26.956511 2073386 hfize_llama.py:153] loaded layer 19
I0328 01:59:27.401122 2073386 hfize_llama.py:153] loaded layer 20
I0328 01:59:27.685025 2073386 hfize_llama.py:153] loaded layer 21
I0328 01:59:28.013677 2073386 hfize_llama.py:153] loaded layer 22
I0328 01:59:28.308883 2073386 hfize_llama.py:153] loaded layer 23
I0328 01:59:28.576880 2073386 hfize_llama.py:153] loaded layer 24
I0328 01:59:28.849600 2073386 hfize_llama.py:153] loaded layer 25
I0328 01:59:29.121432 2073386 hfize_llama.py:153] loaded layer 26
I0328 01:59:29.392342 2073386 hfize_llama.py:153] loaded layer 27
I0328 01:59:29.727069 2073386 hfize_llama.py:153] loaded layer 28
I0328 01:59:30.081720 2073386 hfize_llama.py:153] loaded layer 29
I0328 01:59:30.342641 2073386 hfize_llama.py:153] loaded layer 30
I0328 01:59:30.642253 2073386 hfize_llama.py:153] loaded layer 31
I0328 01:59:30.642381 2073386 hfize_llama.py:157] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.24s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.11s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.03s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:02,  1.01it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:04<00:01,  1.08it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.17it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]
I0328 02:00:15.160668 2073386 hfize_llama.py:167] successfully loaded hfized model
I0328 02:00:20.019087 2074237 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0328 02:00:20.019289 2074237 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0328 02:00:20.019332 2074237 utils.py:162] NumExpr defaulting to 16 threads.
W0328 02:00:20.367413 2074237 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0328 02:00:20.718939 2074237 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.11s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.04s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.05s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.04s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.02s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:00,  1.02it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.05it/s]
I0328 02:00:27.457134 2074237 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 4.067083835601807:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 4.067083835601807:   1%|          | 1/141 [00:01<04:27,  1.91s/it]avg_loss = 4.591012239456177:   1%|          | 1/141 [00:03<04:27,  1.91s/it]avg_loss = 4.591012239456177:   1%|▏         | 2/141 [00:03<03:54,  1.68s/it]avg_loss = 4.8135749499003095:   1%|▏         | 2/141 [00:04<03:54,  1.68s/it]avg_loss = 4.8135749499003095:   2%|▏         | 3/141 [00:04<03:42,  1.61s/it]avg_loss = 4.8855191469192505:   2%|▏         | 3/141 [00:06<03:42,  1.61s/it]avg_loss = 4.8855191469192505:   3%|▎         | 4/141 [00:06<03:36,  1.58s/it]avg_loss = 5.073800373077392:   3%|▎         | 4/141 [00:08<03:36,  1.58s/it] avg_loss = 5.073800373077392:   4%|▎         | 5/141 [00:08<03:32,  1.56s/it]avg_loss = 5.005177815755208:   4%|▎         | 5/141 [00:09<03:32,  1.56s/it]avg_loss = 5.005177815755208:   4%|▍         | 6/141 [00:09<03:30,  1.56s/it]avg_loss = 4.943940843854632:   4%|▍         | 6/141 [00:11<03:30,  1.56s/it]avg_loss = 4.943940843854632:   5%|▍         | 7/141 [00:11<03:28,  1.56s/it]avg_loss = 4.984259128570557:   5%|▍         | 7/141 [00:12<03:28,  1.56s/it]avg_loss = 4.984259128570557:   6%|▌         | 8/141 [00:12<03:26,  1.56s/it]avg_loss = 5.0242874887254505:   6%|▌         | 8/141 [00:14<03:26,  1.56s/it]avg_loss = 5.0242874887254505:   6%|▋         | 9/141 [00:14<03:25,  1.56s/it]avg_loss = 4.9935526847839355:   6%|▋         | 9/141 [00:15<03:25,  1.56s/it]avg_loss = 4.9935526847839355:   7%|▋         | 10/141 [00:15<03:24,  1.56s/it]avg_loss = 5.007361628792503:   7%|▋         | 10/141 [00:17<03:24,  1.56s/it] avg_loss = 5.007361628792503:   8%|▊         | 11/141 [00:17<03:22,  1.56s/it]avg_loss = 5.014422098795573:   8%|▊         | 11/141 [00:18<03:22,  1.56s/it]avg_loss = 5.014422098795573:   9%|▊         | 12/141 [00:18<03:21,  1.56s/it]avg_loss = 4.99610790839562:   9%|▊         | 12/141 [00:20<03:21,  1.56s/it] avg_loss = 4.99610790839562:   9%|▉         | 13/141 [00:20<03:20,  1.57s/it]avg_loss = 4.97640974181039:   9%|▉         | 13/141 [00:22<03:20,  1.57s/it]avg_loss = 4.97640974181039:  10%|▉         | 14/141 [00:22<03:19,  1.57s/it]avg_loss = 4.985759576161702:  10%|▉         | 14/141 [00:23<03:19,  1.57s/it]avg_loss = 4.985759576161702:  11%|█         | 15/141 [00:23<03:18,  1.57s/it]avg_loss = 5.002201080322266:  11%|█         | 15/141 [00:25<03:18,  1.57s/it]avg_loss = 5.002201080322266:  11%|█▏        | 16/141 [00:25<03:17,  1.58s/it]avg_loss = 4.9792792095857505:  11%|█▏        | 16/141 [00:26<03:17,  1.58s/it]avg_loss = 4.9792792095857505:  12%|█▏        | 17/141 [00:26<03:16,  1.58s/it]avg_loss = 4.9784895579020185:  12%|█▏        | 17/141 [00:28<03:16,  1.58s/it]avg_loss = 4.9784895579020185:  13%|█▎        | 18/141 [00:28<03:15,  1.59s/it]avg_loss = 4.98826413405569:  13%|█▎        | 18/141 [00:30<03:15,  1.59s/it]  avg_loss = 4.98826413405569:  13%|█▎        | 19/141 [00:30<03:13,  1.59s/it]avg_loss = 4.983281040191651:  13%|█▎        | 19/141 [00:31<03:13,  1.59s/it]avg_loss = 4.983281040191651:  14%|█▍        | 20/141 [00:31<03:12,  1.59s/it]avg_loss = 4.988654091244652:  14%|█▍        | 20/141 [00:33<03:12,  1.59s/it]avg_loss = 4.988654091244652:  15%|█▍        | 21/141 [00:33<03:11,  1.60s/it]avg_loss = 5.017464052547108:  15%|█▍        | 21/141 [00:34<03:11,  1.60s/it]avg_loss = 5.017464052547108:  16%|█▌        | 22/141 [00:34<03:10,  1.60s/it]avg_loss = 5.030733004860256:  16%|█▌        | 22/141 [00:36<03:10,  1.60s/it]avg_loss = 5.030733004860256:  16%|█▋        | 23/141 [00:36<03:08,  1.60s/it]avg_loss = 5.034532288710277:  16%|█▋        | 23/141 [00:38<03:08,  1.60s/it]avg_loss = 5.034532288710277:  17%|█▋        | 24/141 [00:38<03:07,  1.60s/it]avg_loss = 5.042991695404052:  17%|█▋        | 24/141 [00:39<03:07,  1.60s/it]avg_loss = 5.042991695404052:  18%|█▊        | 25/141 [00:39<03:06,  1.61s/it]avg_loss = 5.045204859513503:  18%|█▊        | 25/141 [00:41<03:06,  1.61s/it]avg_loss = 5.045204859513503:  18%|█▊        | 26/141 [00:41<03:05,  1.61s/it]avg_loss = 5.053733878665501:  18%|█▊        | 26/141 [00:42<03:05,  1.61s/it]avg_loss = 5.053733878665501:  19%|█▉        | 27/141 [00:42<03:04,  1.61s/it]avg_loss = 5.05757783140455:  19%|█▉        | 27/141 [00:44<03:04,  1.61s/it] avg_loss = 5.05757783140455:  20%|█▉        | 28/141 [00:44<03:02,  1.62s/it]avg_loss = 5.066342386706122:  20%|█▉        | 28/141 [00:46<03:02,  1.62s/it]avg_loss = 5.066342386706122:  21%|██        | 29/141 [00:46<03:01,  1.62s/it]avg_loss = 5.060270595550537:  21%|██        | 29/141 [00:47<03:01,  1.62s/it]avg_loss = 5.060270595550537:  21%|██▏       | 30/141 [00:47<03:00,  1.62s/it]avg_loss = 5.060117475448116:  21%|██▏       | 30/141 [00:49<03:00,  1.62s/it]avg_loss = 5.060117475448116:  22%|██▏       | 31/141 [00:49<02:58,  1.63s/it]avg_loss = 5.093205615878105:  22%|██▏       | 31/141 [00:51<02:58,  1.63s/it]avg_loss = 5.093205615878105:  23%|██▎       | 32/141 [00:51<02:57,  1.63s/it]avg_loss = 5.095740289399118:  23%|██▎       | 32/141 [00:52<02:57,  1.63s/it]avg_loss = 5.095740289399118:  23%|██▎       | 33/141 [00:52<02:56,  1.63s/it]avg_loss = 5.087832170374253:  23%|██▎       | 33/141 [00:54<02:56,  1.63s/it]avg_loss = 5.087832170374253:  24%|██▍       | 34/141 [00:54<02:54,  1.63s/it]avg_loss = 5.087241200038365:  24%|██▍       | 34/141 [00:55<02:54,  1.63s/it]avg_loss = 5.087241200038365:  25%|██▍       | 35/141 [00:55<02:53,  1.63s/it]avg_loss = 5.064285808139378:  25%|██▍       | 35/141 [00:57<02:53,  1.63s/it]avg_loss = 5.064285808139378:  26%|██▌       | 36/141 [00:57<02:51,  1.64s/it]avg_loss = 5.0518658741100415:  26%|██▌       | 36/141 [00:59<02:51,  1.64s/it]avg_loss = 5.0518658741100415:  26%|██▌       | 37/141 [00:59<02:50,  1.64s/it]avg_loss = 5.028653621673584:  26%|██▌       | 37/141 [01:00<02:50,  1.64s/it] avg_loss = 5.028653621673584:  27%|██▋       | 38/141 [01:00<02:49,  1.64s/it]avg_loss = 5.0093698257055035:  27%|██▋       | 38/141 [01:02<02:49,  1.64s/it]avg_loss = 5.0093698257055035:  28%|██▊       | 39/141 [01:02<02:47,  1.65s/it]avg_loss = 4.996277785301208:  28%|██▊       | 39/141 [01:04<02:47,  1.65s/it] avg_loss = 4.996277785301208:  28%|██▊       | 40/141 [01:04<02:46,  1.65s/it]avg_loss = 5.000078084992199:  28%|██▊       | 40/141 [01:05<02:46,  1.65s/it]avg_loss = 5.000078084992199:  29%|██▉       | 41/141 [01:05<02:44,  1.65s/it]avg_loss = 5.012306599389939:  29%|██▉       | 41/141 [01:07<02:44,  1.65s/it]avg_loss = 5.012306599389939:  30%|██▉       | 42/141 [01:07<02:43,  1.65s/it]avg_loss = 5.024905748145525:  30%|██▉       | 42/141 [01:09<02:43,  1.65s/it]avg_loss = 5.024905748145525:  30%|███       | 43/141 [01:09<02:41,  1.65s/it]avg_loss = 5.02605536851016:  30%|███       | 43/141 [01:10<02:41,  1.65s/it] avg_loss = 5.02605536851016:  31%|███       | 44/141 [01:10<02:40,  1.65s/it]avg_loss = 5.025676430596246:  31%|███       | 44/141 [01:12<02:40,  1.65s/it]avg_loss = 5.025676430596246:  32%|███▏      | 45/141 [01:12<02:39,  1.66s/it]avg_loss = 5.0284381016441015:  32%|███▏      | 45/141 [01:14<02:39,  1.66s/it]avg_loss = 5.0284381016441015:  33%|███▎      | 46/141 [01:14<02:37,  1.66s/it]avg_loss = 5.029902316154318:  33%|███▎      | 46/141 [01:15<02:37,  1.66s/it] avg_loss = 5.029902316154318:  33%|███▎      | 47/141 [01:15<02:35,  1.66s/it]avg_loss = 5.028194139401118:  33%|███▎      | 47/141 [01:17<02:35,  1.66s/it]avg_loss = 5.028194139401118:  34%|███▍      | 48/141 [01:17<02:34,  1.66s/it]avg_loss = 5.02676467506253:  34%|███▍      | 48/141 [01:19<02:34,  1.66s/it] avg_loss = 5.02676467506253:  35%|███▍      | 49/141 [01:19<02:32,  1.66s/it]avg_loss = 5.019182415008545:  35%|███▍      | 49/141 [01:20<02:32,  1.66s/it]avg_loss = 5.019182415008545:  35%|███▌      | 50/141 [01:20<02:31,  1.66s/it]avg_loss = 5.0133444842170265:  35%|███▌      | 50/141 [01:22<02:31,  1.66s/it]avg_loss = 5.0133444842170265:  36%|███▌      | 51/141 [01:22<02:29,  1.66s/it]avg_loss = 5.007148742675781:  36%|███▌      | 51/141 [01:24<02:29,  1.66s/it] avg_loss = 5.007148742675781:  37%|███▋      | 52/141 [01:24<02:28,  1.67s/it]avg_loss = 4.999685404435644:  37%|███▋      | 52/141 [01:25<02:28,  1.67s/it]avg_loss = 4.999685404435644:  38%|███▊      | 53/141 [01:25<02:26,  1.67s/it]avg_loss = 4.995606192836055:  38%|███▊      | 53/141 [01:27<02:26,  1.67s/it]avg_loss = 4.995606192836055:  38%|███▊      | 54/141 [01:27<02:25,  1.67s/it]avg_loss = 4.9875509782270955:  38%|███▊      | 54/141 [01:29<02:25,  1.67s/it]avg_loss = 4.9875509782270955:  39%|███▉      | 55/141 [01:29<02:23,  1.67s/it]avg_loss = 4.9848149844578336:  39%|███▉      | 55/141 [01:30<02:23,  1.67s/it]avg_loss = 4.9848149844578336:  40%|███▉      | 56/141 [01:30<02:22,  1.67s/it]avg_loss = 4.981938688378585:  40%|███▉      | 56/141 [01:32<02:22,  1.67s/it] avg_loss = 4.981938688378585:  40%|████      | 57/141 [01:32<02:20,  1.67s/it]avg_loss = 4.985198382673593:  40%|████      | 57/141 [01:34<02:20,  1.67s/it]avg_loss = 4.985198382673593:  41%|████      | 58/141 [01:34<02:19,  1.67s/it]avg_loss = 4.994415541826668:  41%|████      | 58/141 [01:35<02:19,  1.67s/it]avg_loss = 4.994415541826668:  42%|████▏     | 59/141 [01:35<02:17,  1.68s/it]avg_loss = 5.001635917027792:  42%|████▏     | 59/141 [01:37<02:17,  1.68s/it]avg_loss = 5.001635917027792:  43%|████▎     | 60/141 [01:37<02:15,  1.68s/it]avg_loss = 5.004372229341601:  43%|████▎     | 60/141 [01:39<02:15,  1.68s/it]avg_loss = 5.004372229341601:  43%|████▎     | 61/141 [01:39<02:14,  1.68s/it]avg_loss = 5.010023509302447:  43%|████▎     | 61/141 [01:40<02:14,  1.68s/it]avg_loss = 5.010023509302447:  44%|████▍     | 62/141 [01:40<02:12,  1.68s/it]avg_loss = 5.003037271045503:  44%|████▍     | 62/141 [01:42<02:12,  1.68s/it]avg_loss = 5.003037271045503:  45%|████▍     | 63/141 [01:42<02:11,  1.68s/it]avg_loss = 5.0049508810043335:  45%|████▍     | 63/141 [01:44<02:11,  1.68s/it]avg_loss = 5.0049508810043335:  45%|████▌     | 64/141 [01:44<02:09,  1.68s/it]avg_loss = 5.006222519507775:  45%|████▌     | 64/141 [01:45<02:09,  1.68s/it] avg_loss = 5.006222519507775:  46%|████▌     | 65/141 [01:45<02:07,  1.68s/it]avg_loss = 4.99983650265318:  46%|████▌     | 65/141 [01:47<02:07,  1.68s/it] avg_loss = 4.99983650265318:  47%|████▋     | 66/141 [01:47<02:06,  1.68s/it]avg_loss = 4.996152215929174:  47%|████▋     | 66/141 [01:49<02:06,  1.68s/it]avg_loss = 4.996152215929174:  48%|████▊     | 67/141 [01:49<02:04,  1.68s/it]avg_loss = 5.0013214560116035:  48%|████▊     | 67/141 [01:51<02:04,  1.68s/it]avg_loss = 5.0013214560116035:  48%|████▊     | 68/141 [01:51<02:02,  1.68s/it]avg_loss = 5.009344142416249:  48%|████▊     | 68/141 [01:52<02:02,  1.68s/it] avg_loss = 5.009344142416249:  49%|████▉     | 69/141 [01:52<02:01,  1.69s/it]avg_loss = 5.0128879002162385:  49%|████▉     | 69/141 [01:54<02:01,  1.69s/it]avg_loss = 5.0128879002162385:  50%|████▉     | 70/141 [01:54<01:59,  1.69s/it]avg_loss = 5.011014817466198:  50%|████▉     | 70/141 [01:56<01:59,  1.69s/it] avg_loss = 5.011014817466198:  50%|█████     | 71/141 [01:56<01:58,  1.69s/it]avg_loss = 5.014968428346846:  50%|█████     | 71/141 [01:57<01:58,  1.69s/it]avg_loss = 5.014968428346846:  51%|█████     | 72/141 [01:57<01:56,  1.69s/it]avg_loss = 5.009596008144013:  51%|█████     | 72/141 [01:59<01:56,  1.69s/it]avg_loss = 5.009596008144013:  52%|█████▏    | 73/141 [01:59<01:54,  1.69s/it]avg_loss = 5.0080594114355135:  52%|█████▏    | 73/141 [02:01<01:54,  1.69s/it]avg_loss = 5.0080594114355135:  52%|█████▏    | 74/141 [02:01<01:53,  1.69s/it]avg_loss = 5.004873402913412:  52%|█████▏    | 74/141 [02:02<01:53,  1.69s/it] avg_loss = 5.004873402913412:  53%|█████▎    | 75/141 [02:02<01:51,  1.69s/it]avg_loss = 5.000346942951805:  53%|█████▎    | 75/141 [02:04<01:51,  1.69s/it]avg_loss = 5.000346942951805:  54%|█████▍    | 76/141 [02:04<01:49,  1.69s/it]avg_loss = 5.002689497811454:  54%|█████▍    | 76/141 [02:06<01:49,  1.69s/it]avg_loss = 5.002689497811454:  55%|█████▍    | 77/141 [02:06<01:48,  1.69s/it]avg_loss = 5.003106966996804:  55%|█████▍    | 77/141 [02:07<01:48,  1.69s/it]avg_loss = 5.003106966996804:  55%|█████▌    | 78/141 [02:07<01:46,  1.69s/it]avg_loss = 5.004672503169579:  55%|█████▌    | 78/141 [02:09<01:46,  1.69s/it]avg_loss = 5.004672503169579:  56%|█████▌    | 79/141 [02:09<01:44,  1.69s/it]avg_loss = 4.992340826988221:  56%|█████▌    | 79/141 [02:11<01:44,  1.69s/it]avg_loss = 4.992340826988221:  57%|█████▋    | 80/141 [02:11<01:43,  1.69s/it]avg_loss = 4.990851643644733:  57%|█████▋    | 80/141 [02:13<01:43,  1.69s/it]avg_loss = 4.990851643644733:  57%|█████▋    | 81/141 [02:13<01:41,  1.69s/it]avg_loss = 4.9874088938643295:  57%|█████▋    | 81/141 [02:14<01:41,  1.69s/it]avg_loss = 4.9874088938643295:  58%|█████▊    | 82/141 [02:14<01:39,  1.69s/it]avg_loss = 4.985023762806352:  58%|█████▊    | 82/141 [02:16<01:39,  1.69s/it] avg_loss = 4.985023762806352:  59%|█████▉    | 83/141 [02:16<01:38,  1.69s/it]avg_loss = 4.982885661579314:  59%|█████▉    | 83/141 [02:18<01:38,  1.69s/it]avg_loss = 4.982885661579314:  60%|█████▉    | 84/141 [02:18<01:36,  1.70s/it]avg_loss = 4.984482467875761:  60%|█████▉    | 84/141 [02:19<01:36,  1.70s/it]avg_loss = 4.984482467875761:  60%|██████    | 85/141 [02:19<01:34,  1.70s/it]avg_loss = 4.986175293146178:  60%|██████    | 85/141 [02:21<01:34,  1.70s/it]avg_loss = 4.986175293146178:  61%|██████    | 86/141 [02:21<01:33,  1.70s/it]avg_loss = 4.98859707514445:  61%|██████    | 86/141 [02:23<01:33,  1.70s/it] avg_loss = 4.98859707514445:  62%|██████▏   | 87/141 [02:23<01:31,  1.70s/it]avg_loss = 4.9974630149928005:  62%|██████▏   | 87/141 [02:24<01:31,  1.70s/it]avg_loss = 4.9974630149928005:  62%|██████▏   | 88/141 [02:24<01:30,  1.70s/it]avg_loss = 5.003565723976393:  62%|██████▏   | 88/141 [02:26<01:30,  1.70s/it] avg_loss = 5.003565723976393:  63%|██████▎   | 89/141 [02:26<01:28,  1.70s/it]avg_loss = 5.0121061695946585:  63%|██████▎   | 89/141 [02:28<01:28,  1.70s/it]avg_loss = 5.0121061695946585:  64%|██████▍   | 90/141 [02:28<01:26,  1.70s/it]avg_loss = 5.01607664338835:  64%|██████▍   | 90/141 [02:30<01:26,  1.70s/it]  avg_loss = 5.01607664338835:  65%|██████▍   | 91/141 [02:30<01:24,  1.70s/it]avg_loss = 5.020881507707679:  65%|██████▍   | 91/141 [02:31<01:24,  1.70s/it]avg_loss = 5.020881507707679:  65%|██████▌   | 92/141 [02:31<01:23,  1.70s/it]avg_loss = 5.025167860010619:  65%|██████▌   | 92/141 [02:33<01:23,  1.70s/it]avg_loss = 5.025167860010619:  66%|██████▌   | 93/141 [02:33<01:21,  1.70s/it]avg_loss = 5.023075129123444:  66%|██████▌   | 93/141 [02:35<01:21,  1.70s/it]avg_loss = 5.023075129123444:  67%|██████▋   | 94/141 [02:35<01:19,  1.70s/it]avg_loss = 5.025738234268991:  67%|██████▋   | 94/141 [02:36<01:19,  1.70s/it]avg_loss = 5.025738234268991:  67%|██████▋   | 95/141 [02:36<01:18,  1.70s/it]avg_loss = 5.0264118413130445:  67%|██████▋   | 95/141 [02:38<01:18,  1.70s/it]avg_loss = 5.0264118413130445:  68%|██████▊   | 96/141 [02:38<01:16,  1.70s/it]avg_loss = 5.028730648080098:  68%|██████▊   | 96/141 [02:40<01:16,  1.70s/it] avg_loss = 5.028730648080098:  69%|██████▉   | 97/141 [02:40<01:14,  1.70s/it]avg_loss = 5.027514963733907:  69%|██████▉   | 97/141 [02:41<01:14,  1.70s/it]avg_loss = 5.027514963733907:  70%|██████▉   | 98/141 [02:41<01:13,  1.70s/it]avg_loss = 5.03075693111227:  70%|██████▉   | 98/141 [02:43<01:13,  1.70s/it] avg_loss = 5.03075693111227:  70%|███████   | 99/141 [02:43<01:11,  1.70s/it]avg_loss = 5.032169728279114:  70%|███████   | 99/141 [02:45<01:11,  1.70s/it]avg_loss = 5.032169728279114:  71%|███████   | 100/141 [02:45<01:09,  1.70s/it]avg_loss = 5.032584568061451:  71%|███████   | 100/141 [02:47<01:09,  1.70s/it]avg_loss = 5.032584568061451:  72%|███████▏  | 101/141 [02:47<01:07,  1.70s/it]avg_loss = 5.035341047773175:  72%|███████▏  | 101/141 [02:48<01:07,  1.70s/it]avg_loss = 5.035341047773175:  72%|███████▏  | 102/141 [02:48<01:06,  1.70s/it]avg_loss = 5.036949986393012:  72%|███████▏  | 102/141 [02:50<01:06,  1.70s/it]avg_loss = 5.036949986393012:  73%|███████▎  | 103/141 [02:50<01:04,  1.70s/it]avg_loss = 5.040702530970941:  73%|███████▎  | 103/141 [02:52<01:04,  1.70s/it]avg_loss = 5.040702530970941:  74%|███████▍  | 104/141 [02:52<01:02,  1.70s/it]avg_loss = 5.039006074269612:  74%|███████▍  | 104/141 [02:53<01:02,  1.70s/it]avg_loss = 5.039006074269612:  74%|███████▍  | 105/141 [02:53<01:01,  1.70s/it]avg_loss = 5.038507915892691:  74%|███████▍  | 105/141 [02:55<01:01,  1.70s/it]avg_loss = 5.038507915892691:  75%|███████▌  | 106/141 [02:55<00:59,  1.70s/it]avg_loss = 5.038057532265921:  75%|███████▌  | 106/141 [02:57<00:59,  1.70s/it]avg_loss = 5.038057532265921:  76%|███████▌  | 107/141 [02:57<00:57,  1.70s/it]avg_loss = 5.033728846797237:  76%|███████▌  | 107/141 [02:58<00:57,  1.70s/it]avg_loss = 5.033728846797237:  77%|███████▋  | 108/141 [02:58<00:56,  1.70s/it]avg_loss = 5.0326854504576515:  77%|███████▋  | 108/141 [03:00<00:56,  1.70s/it]avg_loss = 5.0326854504576515:  77%|███████▋  | 109/141 [03:00<00:54,  1.70s/it]avg_loss = 5.03095193342729:  77%|███████▋  | 109/141 [03:02<00:54,  1.70s/it]  avg_loss = 5.03095193342729:  78%|███████▊  | 110/141 [03:02<00:52,  1.70s/it]avg_loss = 5.036495354798463:  78%|███████▊  | 110/141 [03:04<00:52,  1.70s/it]avg_loss = 5.036495354798463:  79%|███████▊  | 111/141 [03:04<00:50,  1.70s/it]avg_loss = 5.034254738262722:  79%|███████▊  | 111/141 [03:05<00:50,  1.70s/it]avg_loss = 5.034254738262722:  79%|███████▉  | 112/141 [03:05<00:49,  1.70s/it]avg_loss = 5.035459484674234:  79%|███████▉  | 112/141 [03:07<00:49,  1.70s/it]avg_loss = 5.035459484674234:  80%|████████  | 113/141 [03:07<00:47,  1.70s/it]avg_loss = 5.040630064512554:  80%|████████  | 113/141 [03:09<00:47,  1.70s/it]avg_loss = 5.040630064512554:  81%|████████  | 114/141 [03:09<00:45,  1.70s/it]avg_loss = 5.036691122469695:  81%|████████  | 114/141 [03:10<00:45,  1.70s/it]avg_loss = 5.036691122469695:  82%|████████▏ | 115/141 [03:10<00:44,  1.70s/it]avg_loss = 5.033630847930908:  82%|████████▏ | 115/141 [03:12<00:44,  1.70s/it]avg_loss = 5.033630847930908:  82%|████████▏ | 116/141 [03:12<00:42,  1.70s/it]avg_loss = 5.034376058823023:  82%|████████▏ | 116/141 [03:14<00:42,  1.70s/it]avg_loss = 5.034376058823023:  83%|████████▎ | 117/141 [03:14<00:40,  1.70s/it]avg_loss = 5.030852289523109:  83%|████████▎ | 117/141 [03:15<00:40,  1.70s/it]avg_loss = 5.030852289523109:  84%|████████▎ | 118/141 [03:15<00:39,  1.70s/it]avg_loss = 5.026209498653893:  84%|████████▎ | 118/141 [03:17<00:39,  1.70s/it]avg_loss = 5.026209498653893:  84%|████████▍ | 119/141 [03:17<00:37,  1.70s/it]avg_loss = 5.022211277484894:  84%|████████▍ | 119/141 [03:19<00:37,  1.70s/it]avg_loss = 5.022211277484894:  85%|████████▌ | 120/141 [03:19<00:35,  1.70s/it]avg_loss = 5.025889983847121:  85%|████████▌ | 120/141 [03:20<00:35,  1.70s/it]avg_loss = 5.025889983847121:  86%|████████▌ | 121/141 [03:20<00:34,  1.70s/it]avg_loss = 5.025272271672233:  86%|████████▌ | 121/141 [03:22<00:34,  1.70s/it]avg_loss = 5.025272271672233:  87%|████████▋ | 122/141 [03:22<00:32,  1.70s/it]avg_loss = 5.024199284189116:  87%|████████▋ | 122/141 [03:24<00:32,  1.70s/it]avg_loss = 5.024199284189116:  87%|████████▋ | 123/141 [03:24<00:30,  1.70s/it]avg_loss = 5.024462772953894:  87%|████████▋ | 123/141 [03:26<00:30,  1.70s/it]avg_loss = 5.024462772953894:  88%|████████▊ | 124/141 [03:26<00:28,  1.70s/it]avg_loss = 5.016928310394287:  88%|████████▊ | 124/141 [03:27<00:28,  1.70s/it]avg_loss = 5.016928310394287:  89%|████████▊ | 125/141 [03:27<00:27,  1.70s/it]avg_loss = 5.017180927216061:  89%|████████▊ | 125/141 [03:29<00:27,  1.70s/it]avg_loss = 5.017180927216061:  89%|████████▉ | 126/141 [03:29<00:25,  1.70s/it]avg_loss = 5.022503980501431:  89%|████████▉ | 126/141 [03:31<00:25,  1.70s/it]avg_loss = 5.022503980501431:  90%|█████████ | 127/141 [03:31<00:23,  1.70s/it]avg_loss = 5.019427955150604:  90%|█████████ | 127/141 [03:32<00:23,  1.70s/it]avg_loss = 5.019427955150604:  91%|█████████ | 128/141 [03:32<00:22,  1.70s/it]avg_loss = 5.017925214397815:  91%|█████████ | 128/141 [03:34<00:22,  1.70s/it]avg_loss = 5.017925214397815:  91%|█████████▏| 129/141 [03:34<00:20,  1.70s/it]avg_loss = 5.0191375108865595:  91%|█████████▏| 129/141 [03:36<00:20,  1.70s/it]avg_loss = 5.0191375108865595:  92%|█████████▏| 130/141 [03:36<00:18,  1.70s/it]avg_loss = 5.019465759510302:  92%|█████████▏| 130/141 [03:37<00:18,  1.70s/it] avg_loss = 5.019465759510302:  93%|█████████▎| 131/141 [03:37<00:16,  1.70s/it]avg_loss = 5.019457325790867:  93%|█████████▎| 131/141 [03:39<00:16,  1.70s/it]avg_loss = 5.019457325790867:  94%|█████████▎| 132/141 [03:39<00:15,  1.70s/it]avg_loss = 5.015337997809389:  94%|█████████▎| 132/141 [03:41<00:15,  1.70s/it]avg_loss = 5.015337997809389:  94%|█████████▍| 133/141 [03:41<00:13,  1.70s/it]avg_loss = 5.012511406371843:  94%|█████████▍| 133/141 [03:43<00:13,  1.70s/it]avg_loss = 5.012511406371843:  95%|█████████▌| 134/141 [03:43<00:11,  1.70s/it]avg_loss = 5.013493495517307:  95%|█████████▌| 134/141 [03:44<00:11,  1.70s/it]avg_loss = 5.013493495517307:  96%|█████████▌| 135/141 [03:44<00:10,  1.70s/it]avg_loss = 5.017467127126806:  96%|█████████▌| 135/141 [03:46<00:10,  1.70s/it]avg_loss = 5.017467127126806:  96%|█████████▋| 136/141 [03:46<00:08,  1.70s/it]avg_loss = 5.0200831629063964:  96%|█████████▋| 136/141 [03:48<00:08,  1.70s/it]avg_loss = 5.0200831629063964:  97%|█████████▋| 137/141 [03:48<00:06,  1.70s/it]avg_loss = 5.019514149513798:  97%|█████████▋| 137/141 [03:49<00:06,  1.70s/it] avg_loss = 5.019514149513798:  98%|█████████▊| 138/141 [03:49<00:05,  1.70s/it]avg_loss = 5.021034830765759:  98%|█████████▊| 138/141 [03:51<00:05,  1.70s/it]avg_loss = 5.021034830765759:  99%|█████████▊| 139/141 [03:51<00:03,  1.70s/it]avg_loss = 5.024394127300807:  99%|█████████▊| 139/141 [03:53<00:03,  1.70s/it]avg_loss = 5.024394127300807:  99%|█████████▉| 140/141 [03:53<00:01,  1.70s/it]avg_loss = 5.026087470088445:  99%|█████████▉| 140/141 [03:54<00:01,  1.70s/it]avg_loss = 5.026087470088445: 100%|██████████| 141/141 [03:54<00:00,  1.70s/it]avg_loss = 5.026087470088445: 100%|██████████| 141/141 [03:54<00:00,  1.67s/it]
I0328 02:04:46.001930 2074237 eval_ppl.py:107] wikitext2 perplexity: 152.33580017089844
wikitext2 perplexity: 152.336
