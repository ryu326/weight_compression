I0325 03:46:00.841053 328292 config.py:54] PyTorch version 2.6.0 available.
W0325 03:46:01.138806 328292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:46:02.058027 328292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.31it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.13it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.85it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.75it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.94it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.89it/s]
I0325 03:46:03.527791 328292 quantize_finetune_llama.py:150] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:19,  1.57it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:19,  1.56it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:17,  1.70it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:14,  1.88it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:02<00:13,  2.00it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:14,  1.81it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:14,  1.69it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:14,  1.64it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:05<00:15,  1.45it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:06<00:14,  1.48it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:13,  1.54it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:07<00:12,  1.62it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:11,  1.67it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:08<00:10,  1.70it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:09<00:09,  1.71it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:09<00:09,  1.72it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:10<00:08,  1.80it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:10<00:07,  1.79it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:11<00:07,  1.71it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:11<00:07,  1.69it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:12<00:06,  1.70it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:12<00:05,  1.78it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:13<00:04,  1.84it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:13<00:04,  1.89it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:14<00:03,  1.80it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:15<00:03,  1.84it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:15<00:02,  1.82it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:16<00:02,  1.86it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:16<00:01,  1.89it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:17<00:01,  1.93it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:17<00:00,  1.94it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:18<00:00,  1.97it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:18<00:00,  1.76it/s]
I0325 03:46:32.120568 328292 quantize_finetune_llama.py:185] loaded compression model
I0325 03:46:51.578912 328292 quantize_finetune_llama.py:189] loaded dataset and devset
I0325 03:46:54.012565 328292 quantize_finetune_llama.py:209] layer 0 gpu 0
The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
I0325 03:47:45.469257 328292 quantize_finetune_llama.py:240] computed original embedding for layer 0 in 51.31037473678589s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0325 03:48:03.903094 330058 config.py:54] PyTorch version 2.6.0 available.
W0325 03:48:04.240727 330058 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:48:05.215105 330058 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:48:05.219422 328292 quantize_finetune_llama.py:209] layer 1 gpu 0
I0325 03:48:05.233143 330058 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:49:06.433533 328292 quantize_finetune_llama.py:240] computed original embedding for layer 1 in 57.995625257492065s
I0325 03:49:10.152325 330913 config.py:54] PyTorch version 2.6.0 available.
W0325 03:49:10.483813 330913 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:49:11.543070 330913 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:49:11.547433 328292 quantize_finetune_llama.py:209] layer 2 gpu 0
I0325 03:49:11.562251 330913 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-2:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:50:23.466030 328292 quantize_finetune_llama.py:240] computed original embedding for layer 2 in 68.7055389881134s
I0325 03:50:27.282775 331847 config.py:54] PyTorch version 2.6.0 available.
W0325 03:50:27.652246 331847 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:50:28.685789 331847 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:50:28.689797 328292 quantize_finetune_llama.py:209] layer 3 gpu 0
I0325 03:50:28.703026 331847 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-3:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:51:39.743696 328292 quantize_finetune_llama.py:240] computed original embedding for layer 3 in 67.37443351745605s
I0325 03:51:43.546331 332773 config.py:54] PyTorch version 2.6.0 available.
W0325 03:51:43.902080 332773 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:51:44.889965 332773 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:51:44.894335 328292 quantize_finetune_llama.py:209] layer 4 gpu 0
I0325 03:51:44.907729 332773 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-4:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:52:55.682366 328292 quantize_finetune_llama.py:240] computed original embedding for layer 4 in 67.42277121543884s
I0325 03:52:59.446650 333731 config.py:54] PyTorch version 2.6.0 available.
W0325 03:52:59.792398 333731 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:53:00.834046 333731 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:53:00.838324 328292 quantize_finetune_llama.py:209] layer 5 gpu 0
I0325 03:53:00.852649 333731 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-5:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:54:11.903990 328292 quantize_finetune_llama.py:240] computed original embedding for layer 5 in 67.79072523117065s
I0325 03:54:15.670757 334659 config.py:54] PyTorch version 2.6.0 available.
W0325 03:54:16.004050 334659 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:54:16.991561 334659 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:54:16.995560 328292 quantize_finetune_llama.py:209] layer 6 gpu 0
I0325 03:54:17.012737 334659 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-6:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:55:27.452698 328292 quantize_finetune_llama.py:240] computed original embedding for layer 6 in 67.20936799049377s
I0325 03:55:31.197415 335563 config.py:54] PyTorch version 2.6.0 available.
W0325 03:55:31.547373 335563 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:55:32.533703 335563 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:55:32.538129 328292 quantize_finetune_llama.py:209] layer 7 gpu 0
I0325 03:55:32.553013 335563 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-7:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:56:41.819180 328292 quantize_finetune_llama.py:240] computed original embedding for layer 7 in 65.8888943195343s
I0325 03:56:45.485170 336479 config.py:54] PyTorch version 2.6.0 available.
W0325 03:56:45.812719 336479 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:56:46.888747 336479 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:56:46.893222 328292 quantize_finetune_llama.py:209] layer 8 gpu 0
I0325 03:56:46.908509 336479 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-8:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:57:44.060352 328292 quantize_finetune_llama.py:240] computed original embedding for layer 8 in 53.887102127075195s
I0325 03:57:47.842910 337236 config.py:54] PyTorch version 2.6.0 available.
W0325 03:57:48.219542 337236 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:57:49.353702 337236 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:57:49.357913 328292 quantize_finetune_llama.py:209] layer 9 gpu 0
I0325 03:57:49.371769 337236 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-9:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 03:58:58.723549 328292 quantize_finetune_llama.py:240] computed original embedding for layer 9 in 65.8758008480072s
I0325 03:59:02.314038 338149 config.py:54] PyTorch version 2.6.0 available.
W0325 03:59:02.697779 338149 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 03:59:03.717948 338149 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 03:59:03.722026 328292 quantize_finetune_llama.py:209] layer 10 gpu 0
I0325 03:59:03.735622 338149 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-10:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 04:00:13.770051 328292 quantize_finetune_llama.py:240] computed original embedding for layer 10 in 66.68811011314392s
I0325 04:00:17.510555 339099 config.py:54] PyTorch version 2.6.0 available.
W0325 04:00:17.894731 339099 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 04:00:19.054044 339099 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 04:00:19.058274 328292 quantize_finetune_llama.py:209] layer 11 gpu 0
I0325 04:00:19.072807 339099 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-11:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
I0325 04:01:28.634809 328292 quantize_finetune_llama.py:240] computed original embedding for layer 11 in 66.30853962898254s
I0325 04:01:32.333424 340029 config.py:54] PyTorch version 2.6.0 available.
W0325 04:01:32.667670 340029 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0325 04:01:33.646218 340029 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0325 04:01:33.650921 328292 quantize_finetune_llama.py:209] layer 12 gpu 0
I0325 04:01:33.673821 340029 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-12:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 118, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 130, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 58, in compress_linear
    out = pseudo_compress_tensor_ldlq(W, comp_model, args.direction, args.comp_batch_size, ql, H, device, args)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 247, in pseudo_compress_tensor_ldlq
    x_hat, n_pixels, bpp_loss_ = compress_weight_block_with_model(WXWX.reshape(1, -1, model.input_size), model, ql)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 82, in compress_weight_block_with_model
    out = model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/Weight_compression/NWC/models/nwc_ql.py", line 135, in forward
    q_level = data['q_level']
KeyError: 'q_level'
