I0318 12:40:23.920022 628033 config.py:54] PyTorch version 2.6.0 available.
W0318 12:40:24.228375 628033 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 12:40:24.464711 628033 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  9.09it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  9.15it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.59it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.60it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  9.59it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00, 10.02it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00, 10.09it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.12it/s]
I0318 12:40:27.628589 628033 hfize_llama.py:153] loaded layer 0
I0318 12:40:29.117146 628033 hfize_llama.py:153] loaded layer 1
I0318 12:40:30.517686 628033 hfize_llama.py:153] loaded layer 2
I0318 12:40:31.725485 628033 hfize_llama.py:153] loaded layer 3
I0318 12:40:32.938625 628033 hfize_llama.py:153] loaded layer 4
I0318 12:40:34.068820 628033 hfize_llama.py:153] loaded layer 5
I0318 12:40:35.438012 628033 hfize_llama.py:153] loaded layer 6
I0318 12:40:37.138635 628033 hfize_llama.py:153] loaded layer 7
I0318 12:40:38.795093 628033 hfize_llama.py:153] loaded layer 8
I0318 12:40:39.925744 628033 hfize_llama.py:153] loaded layer 9
I0318 12:40:40.988075 628033 hfize_llama.py:153] loaded layer 10
I0318 12:40:42.050715 628033 hfize_llama.py:153] loaded layer 11
I0318 12:40:43.156977 628033 hfize_llama.py:153] loaded layer 12
I0318 12:40:44.197739 628033 hfize_llama.py:153] loaded layer 13
I0318 12:40:45.247225 628033 hfize_llama.py:153] loaded layer 14
I0318 12:40:46.277116 628033 hfize_llama.py:153] loaded layer 15
I0318 12:40:47.259975 628033 hfize_llama.py:153] loaded layer 16
I0318 12:40:48.242337 628033 hfize_llama.py:153] loaded layer 17
I0318 12:40:49.214592 628033 hfize_llama.py:153] loaded layer 18
I0318 12:40:50.181454 628033 hfize_llama.py:153] loaded layer 19
I0318 12:40:51.152999 628033 hfize_llama.py:153] loaded layer 20
I0318 12:40:52.119700 628033 hfize_llama.py:153] loaded layer 21
I0318 12:40:53.089854 628033 hfize_llama.py:153] loaded layer 22
I0318 12:40:54.056919 628033 hfize_llama.py:153] loaded layer 23
I0318 12:40:54.963713 628033 hfize_llama.py:153] loaded layer 24
I0318 12:40:55.813850 628033 hfize_llama.py:153] loaded layer 25
I0318 12:40:56.818971 628033 hfize_llama.py:153] loaded layer 26
I0318 12:40:57.718446 628033 hfize_llama.py:153] loaded layer 27
I0318 12:40:58.596226 628033 hfize_llama.py:153] loaded layer 28
I0318 12:40:59.469647 628033 hfize_llama.py:153] loaded layer 29
I0318 12:41:00.335772 628033 hfize_llama.py:153] loaded layer 30
I0318 12:41:01.199568 628033 hfize_llama.py:153] loaded layer 31
I0318 12:41:01.199724 628033 hfize_llama.py:157] saving model...
### skip ####
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 186, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 165, in main
    model, _ = model_from_hf_path(args.hf_output_path, device_map='cuda')
  File "/workspace/Weight_compression/comp_lm_qtip/lib/utils/unsafe_import.py", line 44, in model_from_hf_path
    model = model_cls.from_pretrained(path,
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 942, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 339, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 500.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 139.25 MiB is free. Process 3347854 has 26.65 GiB memory in use. Process 3350306 has 18.73 GiB memory in use. Process 3352425 has 1.54 GiB memory in use. Process 3352427 has 424.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
