I0318 12:41:41.932364 629674 config.py:54] PyTorch version 2.6.0 available.
W0318 12:41:42.223457 629674 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 12:41:42.466966 629674 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.47it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  9.19it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  9.50it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.84it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.72it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  9.59it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  9.75it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  9.82it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.77it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.83it/s]
I0318 12:41:44.990404 629674 hfize_llama.py:153] loaded layer 0
I0318 12:41:45.788114 629674 hfize_llama.py:153] loaded layer 1
I0318 12:41:46.804770 629674 hfize_llama.py:153] loaded layer 2
I0318 12:41:47.815540 629674 hfize_llama.py:153] loaded layer 3
I0318 12:41:48.921812 629674 hfize_llama.py:153] loaded layer 4
I0318 12:41:49.996191 629674 hfize_llama.py:153] loaded layer 5
I0318 12:41:51.144186 629674 hfize_llama.py:153] loaded layer 6
I0318 12:41:52.144021 629674 hfize_llama.py:153] loaded layer 7
I0318 12:41:53.300040 629674 hfize_llama.py:153] loaded layer 8
I0318 12:41:54.333451 629674 hfize_llama.py:153] loaded layer 9
I0318 12:41:55.429888 629674 hfize_llama.py:153] loaded layer 10
I0318 12:41:56.440681 629674 hfize_llama.py:153] loaded layer 11
I0318 12:41:57.673475 629674 hfize_llama.py:153] loaded layer 12
I0318 12:41:58.722392 629674 hfize_llama.py:153] loaded layer 13
I0318 12:41:59.797717 629674 hfize_llama.py:153] loaded layer 14
I0318 12:42:00.967806 629674 hfize_llama.py:153] loaded layer 15
I0318 12:42:01.900817 629674 hfize_llama.py:153] loaded layer 16
I0318 12:42:02.874128 629674 hfize_llama.py:153] loaded layer 17
I0318 12:42:03.813332 629674 hfize_llama.py:153] loaded layer 18
I0318 12:42:04.737024 629674 hfize_llama.py:153] loaded layer 19
I0318 12:42:05.652768 629674 hfize_llama.py:153] loaded layer 20
I0318 12:42:06.577482 629674 hfize_llama.py:153] loaded layer 21
I0318 12:42:07.504492 629674 hfize_llama.py:153] loaded layer 22
I0318 12:42:08.520048 629674 hfize_llama.py:153] loaded layer 23
I0318 12:42:09.448211 629674 hfize_llama.py:153] loaded layer 24
I0318 12:42:10.338495 629674 hfize_llama.py:153] loaded layer 25
I0318 12:42:11.339935 629674 hfize_llama.py:153] loaded layer 26
I0318 12:42:12.217274 629674 hfize_llama.py:153] loaded layer 27
I0318 12:42:13.092081 629674 hfize_llama.py:153] loaded layer 28
I0318 12:42:14.213201 629674 hfize_llama.py:153] loaded layer 29
I0318 12:42:15.825646 629674 hfize_llama.py:153] loaded layer 30
I0318 12:42:16.957637 629674 hfize_llama.py:153] loaded layer 31
I0318 12:42:16.957763 629674 hfize_llama.py:157] saving model...
### skip ####
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 186, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 165, in main
    model, _ = model_from_hf_path(args.hf_output_path, device_map='cuda')
  File "/workspace/Weight_compression/comp_lm_qtip/lib/utils/unsafe_import.py", line 44, in model_from_hf_path
    model = model_cls.from_pretrained(path,
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 942, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 339, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 49.00 MiB is free. Process 3347854 has 26.65 GiB memory in use. Process 3350306 has 18.37 GiB memory in use. Process 3354595 has 2.41 GiB memory in use. Of the allocated memory 2.00 GiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
