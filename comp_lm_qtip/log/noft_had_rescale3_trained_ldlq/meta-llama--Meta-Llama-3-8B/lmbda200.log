I0403 02:42:24.255593 3305349 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:42:24.255688 3305349 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:42:24.255730 3305349 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:42:24.592550 3305349 config.py:54] PyTorch version 2.6.0 available.
W0403 02:42:24.782530 3305349 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:42:25.380342 3305349 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.15it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.49it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.45it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.62it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.79it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.93it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.72it/s]
I0403 02:42:26.868458 3305349 quantize_finetune_llama.py:152] loaded model
I0403 02:42:27.266233 3305349 quantize_finetune_llama.py:190] loaded compression model
I0403 02:42:45.651741 3305349 quantize_finetune_llama.py:194] loaded dataset and devset
I0403 02:42:49.356756 3305349 quantize_finetune_llama.py:214] layer 0 gpu 0
I0403 02:42:53.136992 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 3.6208813190460205s
Use train scale and shift
tensor(-1.5053e-07, device='cuda:0') tensor(0.0156, device='cuda:0')
tensor(0.0156, device='cuda:0') tensor(-1.5053e-07, device='cuda:0')
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0403 02:43:03.481947 3305999 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:43:03.482034 3305999 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:43:03.482071 3305999 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:43:03.807064 3305999 config.py:54] PyTorch version 2.6.0 available.
W0403 02:43:04.005362 3305999 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:43:04.571985 3305999 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:43:04.575579 3305349 quantize_finetune_llama.py:214] layer 1 gpu 1
I0403 02:43:04.922317 3305999 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:43:08.623178 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 3.884763717651367s
I0403 02:43:12.233839 3306195 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:43:12.233928 3306195 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:43:12.233966 3306195 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:43:12.562855 3306195 config.py:54] PyTorch version 2.6.0 available.
W0403 02:43:12.754405 3306195 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:43:13.336368 3306195 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:43:13.340044 3305349 quantize_finetune_llama.py:214] layer 2 gpu 0
I0403 02:43:13.557072 3306195 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.0006083117914386094 err 0.03596755862236023 tr(WHW.T) 59.12685012817383
bpp_loss 5.756080924416892
0_q proxy err 3.6736769288836513e-06 err 1.0581743717193604 tr(WHW.T) 288042.3125
bpp_loss 4.743109562434256
0_k proxy err 2.7862506613018923e-06 err 0.2790517508983612 tr(WHW.T) 100153.140625
bpp_loss 6.082124305423349
0_o proxy err 0.0002504348522052169 err 0.7798673510551453 tr(WHW.T) 3114.052734375
bpp_loss 4.365963762742467
0_up proxy err 0.003165560308843851 err 28.04802894592285 tr(WHW.T) 8860.3681640625
bpp_loss 3.9388786287579154
0_gate proxy err 0.0018633798463270068 err 29.256513595581055 tr(WHW.T) 15700.7783203125
bpp_loss 4.007402615022978
0_down proxy err 0.0016130437143146992 err 17.347370147705078 tr(WHW.T) 10754.4326171875
bpp_loss 4.328274548486141
1_v proxy err 0.0014214032562449574 err 0.15148143470287323 tr(WHW.T) 106.5717544555664
bpp_loss 5.7349569555372
1_q proxy err 9.054909241967835e-06 err 1.3108817338943481 tr(WHW.T) 144770.28125
bpp_loss 4.9222021617461
1_k proxy err 4.839353550778469e-06 err 0.36542120575904846 tr(WHW.T) 75510.3359375
bpp_loss 6.335691020824015
1_o proxy err 0.0009555684519000351 err 1.884373664855957 tr(WHW.T) 1971.9923095703125
bpp_loss 4.345439888187684
1_up proxy err 0.003624486504122615 err 29.593215942382812 tr(WHW.T) 8164.80224609375
bpp_loss 3.948898125373359
1_gate proxy err 0.0022173707839101553 err 30.760650634765625 tr(WHW.T) 13872.5791015625
bpp_loss 4.019054359024657
1_down proxy err 3.6675370211014524e-05 err 0.5102448463439941 tr(WHW.T) 13912.466796875
bpp_loss 4.42503687143991
I0403 02:45:28.498593 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 1.0277042388916016s
I0403 02:45:32.904273 3308185 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:45:32.904370 3308185 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:45:32.904413 3308185 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:45:33.323805 3308185 config.py:54] PyTorch version 2.6.0 available.
W0403 02:45:33.541404 3308185 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:45:34.176351 3308185 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:45:34.180220 3305349 quantize_finetune_llama.py:214] layer 3 gpu 1
I0403 02:45:34.600388 3308185 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:45:35.971540 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 1.1260225772857666s
I0403 02:45:40.034468 3308350 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:45:40.034560 3308350 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:45:40.034600 3308350 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:45:40.501370 3308350 config.py:54] PyTorch version 2.6.0 available.
W0403 02:45:40.776317 3308350 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:45:41.359860 3308350 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:45:41.363541 3305349 quantize_finetune_llama.py:214] layer 4 gpu 0
I0403 02:45:41.569012 3308350 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.0009272423340007663 err 0.14297591149806976 tr(WHW.T) 154.19476318359375
bpp_loss 5.7290519655216485
2_q proxy err 0.0001005205194815062 err 4.163993835449219 tr(WHW.T) 41424.31640625
bpp_loss 4.787300826516002
2_k proxy err 5.352716107154265e-05 err 1.2088881731033325 tr(WHW.T) 22584.57421875
bpp_loss 6.180366078973748
2_o proxy err 0.001063827658072114 err 2.0822255611419678 tr(WHW.T) 1957.2958984375
bpp_loss 4.318677236326039
2_up proxy err 0.004323731176555157 err 32.57968521118164 tr(WHW.T) 7535.0859375
bpp_loss 3.9380363123491406
2_gate proxy err 0.0022742252331227064 err 34.17917251586914 tr(WHW.T) 15028.9306640625
bpp_loss 4.036966344474682
2_down proxy err 0.0025409867521375418 err 19.46628189086914 tr(WHW.T) 7660.9140625
bpp_loss 4.3245069741471
3_v proxy err 0.0007282980368472636 err 0.2089080959558487 tr(WHW.T) 286.84423828125
bpp_loss 5.731577772414312
3_q proxy err 0.00015424702723976225 err 7.330687522888184 tr(WHW.T) 47525.6328125
bpp_loss 4.6723349132807925
3_k proxy err 7.906535756774247e-05 err 2.067131996154785 tr(WHW.T) 26144.59765625
bpp_loss 5.912019045441411
3_o proxy err 0.001481286366470158 err 2.7315754890441895 tr(WHW.T) 1844.0562744140625
bpp_loss 4.321032962761819
3_up proxy err 0.004299516323953867 err 32.13240432739258 tr(WHW.T) 7473.4931640625
bpp_loss 3.9268563293319727
3_gate proxy err 0.0016614095075055957 err 34.53944778442383 tr(WHW.T) 20789.244140625
bpp_loss 4.094018649908581
3_down proxy err 0.002711318200454116 err 18.80536460876465 tr(WHW.T) 6935.875
bpp_loss 4.31902840271193
I0403 02:47:48.219830 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.8727822303771973s
I0403 02:47:51.668471 3310091 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:47:51.668571 3310091 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:47:51.668613 3310091 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:47:52.000356 3310091 config.py:54] PyTorch version 2.6.0 available.
W0403 02:47:52.189358 3310091 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:47:52.793915 3310091 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:47:52.797424 3305349 quantize_finetune_llama.py:214] layer 5 gpu 1
I0403 02:47:52.971455 3310091 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:47:54.069487 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.8361618518829346s
I0403 02:47:57.641587 3310229 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:47:57.641687 3310229 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:47:57.641725 3310229 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:47:57.973427 3310229 config.py:54] PyTorch version 2.6.0 available.
W0403 02:47:58.163010 3310229 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:47:58.753604 3310229 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:47:58.757121 3305349 quantize_finetune_llama.py:214] layer 6 gpu 0
I0403 02:47:58.958751 3310229 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.0008741698111407459 err 0.24687451124191284 tr(WHW.T) 282.4102478027344
bpp_loss 5.729695495218039
4_q proxy err 0.00012475850235205144 err 6.246018409729004 tr(WHW.T) 50064.87109375
bpp_loss 4.704676957335323
4_k proxy err 6.078254955355078e-05 err 1.7792901992797852 tr(WHW.T) 29273.04296875
bpp_loss 5.992184848990291
4_o proxy err 0.001762877218425274 err 2.262721538543701 tr(WHW.T) 1283.5389404296875
bpp_loss 4.340668652788736
4_up proxy err 0.004363948944956064 err 31.960145950317383 tr(WHW.T) 7323.67578125
bpp_loss 3.9145935306192507
4_gate proxy err 0.0012162209022790194 err 35.30076217651367 tr(WHW.T) 29024.958984375
bpp_loss 4.1521437631121705
4_down proxy err 0.0026804630178958178 err 16.983705520629883 tr(WHW.T) 6336.10888671875
bpp_loss 4.317313563943442
5_v proxy err 0.0008247953956015408 err 0.17059414088726044 tr(WHW.T) 206.8320770263672
bpp_loss 5.728955758153461
5_q proxy err 0.00017125064914580435 err 6.155125141143799 tr(WHW.T) 35942.19921875
bpp_loss 4.7059003812028095
5_k proxy err 7.710234785918146e-05 err 1.7709306478500366 tr(WHW.T) 22968.5703125
bpp_loss 6.006528749363497
5_o proxy err 0.0017834838945418596 err 1.861693263053894 tr(WHW.T) 1043.85205078125
bpp_loss 4.334037537802942
5_up proxy err 0.004228444769978523 err 32.11893081665039 tr(WHW.T) 7595.9208984375
bpp_loss 3.919531538749912
5_gate proxy err 0.0011669977102428675 err 35.337890625 tr(WHW.T) 30281.02734375
bpp_loss 4.153795012339417
5_down proxy err 0.0026602926664054394 err 16.895484924316406 tr(WHW.T) 6350.9873046875
bpp_loss 4.315665108417826
I0403 02:50:03.159299 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.8500604629516602s
I0403 02:50:06.689617 3311827 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:50:06.689701 3311827 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:50:06.689738 3311827 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:50:07.020963 3311827 config.py:54] PyTorch version 2.6.0 available.
W0403 02:50:07.209993 3311827 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:50:07.767238 3311827 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:50:07.770763 3305349 quantize_finetune_llama.py:214] layer 7 gpu 1
I0403 02:50:08.111809 3311827 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:50:09.097074 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.8961904048919678s
I0403 02:50:12.664697 3311968 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:50:12.664788 3311968 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:50:12.664829 3311968 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:50:12.994231 3311968 config.py:54] PyTorch version 2.6.0 available.
W0403 02:50:13.185927 3311968 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:50:13.944995 3311968 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:50:13.948729 3305349 quantize_finetune_llama.py:214] layer 8 gpu 0
I0403 02:50:14.128396 3311968 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.0007959680515341461 err 0.20000725984573364 tr(WHW.T) 251.27548217773438
bpp_loss 5.729602506151423
6_q proxy err 0.000191994258784689 err 6.832716941833496 tr(WHW.T) 35588.1328125
bpp_loss 4.703848616918549
6_k proxy err 7.419255416607484e-05 err 1.9389896392822266 tr(WHW.T) 26134.55859375
bpp_loss 5.939854416646995
6_o proxy err 0.002236997475847602 err 2.2288663387298584 tr(WHW.T) 996.3651733398438
bpp_loss 4.324514258769341
6_up proxy err 0.003991707693785429 err 31.387006759643555 tr(WHW.T) 7863.052734375
bpp_loss 3.9240158185628906
6_gate proxy err 0.0009700078517198563 err 34.57236862182617 tr(WHW.T) 35641.328125
bpp_loss 4.163728043370481
6_down proxy err 0.002537904540076852 err 16.302175521850586 tr(WHW.T) 6423.478515625
bpp_loss 4.316320439334959
7_v proxy err 0.0006272797472774982 err 0.19264282286167145 tr(WHW.T) 307.1083068847656
bpp_loss 5.728445566492155
7_q proxy err 0.0001995100174099207 err 7.002341270446777 tr(WHW.T) 35097.69140625
bpp_loss 4.63545949338004
7_k proxy err 7.537558121839538e-05 err 2.021639347076416 tr(WHW.T) 26820.87890625
bpp_loss 5.913945417152718
7_o proxy err 0.002162603195756674 err 2.0458149909973145 tr(WHW.T) 945.9965209960938
bpp_loss 4.325354870641604
7_up proxy err 0.0036380502860993147 err 31.160877227783203 tr(WHW.T) 8565.2685546875
bpp_loss 3.936366377864033
7_gate proxy err 0.0009734714403748512 err 33.87718200683594 tr(WHW.T) 34800.38671875
bpp_loss 4.147793826114919
7_down proxy err 0.0025597247295081615 err 16.568593978881836 tr(WHW.T) 6472.80322265625
bpp_loss 4.31734745450584
I0403 02:52:19.254282 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 1.04197359085083s
I0403 02:52:22.835552 3313424 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:52:22.835641 3313424 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:52:22.835679 3313424 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:52:23.172496 3313424 config.py:54] PyTorch version 2.6.0 available.
W0403 02:52:23.377803 3313424 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:52:23.951544 3313424 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:52:23.955243 3305349 quantize_finetune_llama.py:214] layer 9 gpu 1
I0403 02:52:24.173243 3313424 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:52:25.143854 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.796332836151123s
I0403 02:52:28.730787 3313649 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:52:28.730885 3313649 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:52:28.730928 3313649 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:52:29.063183 3313649 config.py:54] PyTorch version 2.6.0 available.
W0403 02:52:29.263561 3313649 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:52:29.840668 3313649 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:52:29.844501 3305349 quantize_finetune_llama.py:214] layer 10 gpu 0
I0403 02:52:30.100215 3313649 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.00084497599164024 err 0.2155921906232834 tr(WHW.T) 255.14593505859375
bpp_loss 5.728580860653892
8_q proxy err 0.0002618564758449793 err 6.953176021575928 tr(WHW.T) 26553.384765625
bpp_loss 4.651574018294923
8_k proxy err 9.001923172036186e-05 err 2.025397300720215 tr(WHW.T) 22499.607421875
bpp_loss 5.913820865447633
8_o proxy err 0.0027791147585958242 err 2.0339560508728027 tr(WHW.T) 731.8719482421875
bpp_loss 4.324706283514388
8_up proxy err 0.0037365101743489504 err 31.511566162109375 tr(WHW.T) 8433.421875
bpp_loss 3.9343461774821793
8_gate proxy err 0.0009239814826287329 err 34.31113815307617 tr(WHW.T) 37134.01171875
bpp_loss 4.154180396547807
8_down proxy err 0.002546476200222969 err 16.367210388183594 tr(WHW.T) 6427.3955078125
bpp_loss 4.316968295590153
9_v proxy err 0.0008502890123054385 err 0.2958779036998749 tr(WHW.T) 347.97332763671875
bpp_loss 5.728595161112025
9_q proxy err 0.00028310701600275934 err 7.249131202697754 tr(WHW.T) 25605.623046875
bpp_loss 4.643597938353196
9_k proxy err 0.00010098936036229134 err 2.112049102783203 tr(WHW.T) 20913.580078125
bpp_loss 5.891282067168504
9_o proxy err 0.0026804418303072453 err 2.039438247680664 tr(WHW.T) 760.8590087890625
bpp_loss 4.34893694834318
9_up proxy err 0.003543997183442116 err 31.56955909729004 tr(WHW.T) 8907.896484375
bpp_loss 3.939675151703081
9_gate proxy err 0.0008749461267143488 err 34.39323425292969 tr(WHW.T) 39308.97265625
bpp_loss 4.166394745931029
9_down proxy err 0.0026063043624162674 err 16.18799591064453 tr(WHW.T) 6211.091796875
bpp_loss 4.315968321104135
I0403 02:54:37.244416 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.9063856601715088s
I0403 02:54:41.198378 3315450 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:54:41.198485 3315450 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:54:41.198529 3315450 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:54:41.589591 3315450 config.py:54] PyTorch version 2.6.0 available.
W0403 02:54:41.816288 3315450 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:54:42.427593 3315450 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:54:42.431742 3305349 quantize_finetune_llama.py:214] layer 11 gpu 1
I0403 02:54:42.638137 3315450 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:54:43.930732 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 1.0035834312438965s
I0403 02:54:47.913893 3315582 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:54:47.914005 3315582 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:54:47.914050 3315582 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:54:48.300200 3315582 config.py:54] PyTorch version 2.6.0 available.
W0403 02:54:48.507438 3315582 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:54:49.145736 3315582 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:54:49.149743 3305349 quantize_finetune_llama.py:214] layer 12 gpu 0
I0403 02:54:49.416220 3315582 data_utils.py:336] using 256 training seqs, 128 validation seqs
10_v proxy err 0.0008434586343355477 err 0.2103135883808136 tr(WHW.T) 249.34664916992188
bpp_loss 5.726965121924877
10_q proxy err 0.00028538776678033173 err 6.646317958831787 tr(WHW.T) 23288.728515625
bpp_loss 4.695447937003337
10_k proxy err 9.844877786235884e-05 err 1.9408472776412964 tr(WHW.T) 19714.28515625
bpp_loss 5.973724132520147
10_o proxy err 0.002852305769920349 err 1.903183937072754 tr(WHW.T) 667.2440185546875
bpp_loss 4.336386792361736
10_up proxy err 0.0035017544869333506 err 31.986465454101562 tr(WHW.T) 9134.4111328125
bpp_loss 3.949386547120022
10_gate proxy err 0.0009227496339008212 err 34.41648483276367 tr(WHW.T) 37297.75
bpp_loss 4.140066614707133
10_down proxy err 0.0025949515402317047 err 16.767602920532227 tr(WHW.T) 6461.62451171875
bpp_loss 4.315952433007104
11_v proxy err 0.000663291139062494 err 0.21035075187683105 tr(WHW.T) 317.1318664550781
bpp_loss 5.729920078418218
11_q proxy err 0.0003195330500602722 err 7.0765461921691895 tr(WHW.T) 22146.5234375
bpp_loss 4.608274640981108
11_k proxy err 0.00011590465874178335 err 2.0861129760742188 tr(WHW.T) 17998.525390625
bpp_loss 5.899697381653823
11_o proxy err 0.002994246780872345 err 1.652633547782898 tr(WHW.T) 551.9363403320312
bpp_loss 4.3480356824584305
11_up proxy err 0.0034278538078069687 err 31.28594398498535 tr(WHW.T) 9126.9775390625
bpp_loss 3.9585820361971855
11_gate proxy err 0.0009126351214945316 err 33.571266174316406 tr(WHW.T) 36784.98046875
bpp_loss 4.130636065267026
11_down proxy err 0.0025684612337499857 err 16.92945671081543 tr(WHW.T) 6591.28369140625
bpp_loss 4.3165624693834355
I0403 02:56:59.832860 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 0.8501255512237549s
I0403 02:57:03.459321 3317385 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:57:03.459415 3317385 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:57:03.459457 3317385 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:57:03.822216 3317385 config.py:54] PyTorch version 2.6.0 available.
W0403 02:57:04.039642 3317385 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:57:04.665851 3317385 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:57:04.669654 3305349 quantize_finetune_llama.py:214] layer 13 gpu 1
I0403 02:57:04.869010 3317385 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:57:05.979220 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 0.8469207286834717s
I0403 02:57:09.707169 3317581 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:57:09.707294 3317581 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:57:09.707339 3317581 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:57:10.086941 3317581 config.py:54] PyTorch version 2.6.0 available.
W0403 02:57:10.295481 3317581 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:57:10.993116 3317581 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:57:10.997084 3305349 quantize_finetune_llama.py:214] layer 14 gpu 0
I0403 02:57:11.249941 3317581 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.0008078979444690049 err 0.29102233052253723 tr(WHW.T) 360.2216491699219
bpp_loss 5.7286518851760775
12_q proxy err 0.00022098174667917192 err 7.525990962982178 tr(WHW.T) 34057.0703125
bpp_loss 4.601246779435314
12_k proxy err 9.287053399020806e-05 err 2.1387650966644287 tr(WHW.T) 23029.533203125
bpp_loss 5.826400212827139
12_o proxy err 0.00274765701033175 err 2.099567413330078 tr(WHW.T) 764.130126953125
bpp_loss 4.329791512223892
12_up proxy err 0.0030727526172995567 err 30.601343154907227 tr(WHW.T) 9958.9345703125
bpp_loss 3.978849386596786
12_gate proxy err 0.000877821643371135 err 32.68769073486328 tr(WHW.T) 37237.28125
bpp_loss 4.122503875355635
12_down proxy err 0.0025173521135002375 err 17.007545471191406 tr(WHW.T) 6756.125
bpp_loss 4.319831285825265
13_v proxy err 0.0009018860291689634 err 0.25004732608795166 tr(WHW.T) 277.2493591308594
bpp_loss 5.728316731401719
13_q proxy err 0.00033858313690871 err 7.05972957611084 tr(WHW.T) 20850.80078125
bpp_loss 4.642005402594805
13_k proxy err 0.00011863465624628589 err 2.1080565452575684 tr(WHW.T) 17769.314453125
bpp_loss 5.907806837232783
13_o proxy err 0.002855733735486865 err 1.8856176137924194 tr(WHW.T) 660.2918090820312
bpp_loss 4.341997422277927
13_up proxy err 0.003002480836585164 err 29.849693298339844 tr(WHW.T) 9941.6767578125
bpp_loss 3.981382071639278
13_gate proxy err 0.0008248533704318106 err 32.024112701416016 tr(WHW.T) 38824.0078125
bpp_loss 4.123223313662622
13_down proxy err 0.002581139327958226 err 16.761825561523438 tr(WHW.T) 6493.9638671875
bpp_loss 4.318898443398731
I0403 02:59:21.751098 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 1.3086862564086914s
I0403 02:59:25.795305 3319325 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:59:25.795409 3319325 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:59:25.795453 3319325 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:59:26.169005 3319325 config.py:54] PyTorch version 2.6.0 available.
W0403 02:59:26.379591 3319325 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:59:26.988758 3319325 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:59:26.993151 3305349 quantize_finetune_llama.py:214] layer 15 gpu 1
I0403 02:59:27.301830 3319325 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:59:28.619262 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 1.0764191150665283s
I0403 02:59:32.575208 3319473 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:59:32.575305 3319473 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:59:32.575345 3319473 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:59:32.945637 3319473 config.py:54] PyTorch version 2.6.0 available.
W0403 02:59:33.157606 3319473 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:59:33.818759 3319473 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:59:33.822738 3305349 quantize_finetune_llama.py:214] layer 16 gpu 0
I0403 02:59:34.075136 3319473 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.0008703268831595778 err 0.24237889051437378 tr(WHW.T) 278.4917907714844
bpp_loss 5.72855016682297
14_q proxy err 0.00031130886054597795 err 6.486815452575684 tr(WHW.T) 20837.234375
bpp_loss 4.636956920963712
14_k proxy err 0.00010492779983906075 err 1.950635313987732 tr(WHW.T) 18590.26171875
bpp_loss 5.9424253582255915
14_o proxy err 0.0027891977224498987 err 1.873002290725708 tr(WHW.T) 671.5200805664062
bpp_loss 4.331734662991948
14_up proxy err 0.0032175628002732992 err 29.26760482788086 tr(WHW.T) 9096.203125
bpp_loss 3.9825782255003497
14_gate proxy err 0.0007678154506720603 err 32.00535583496094 tr(WHW.T) 41683.65625
bpp_loss 4.146767043042928
14_down proxy err 0.0027019805274903774 err 17.08913803100586 tr(WHW.T) 6324.6708984375
bpp_loss 4.322547379215913
15_v proxy err 0.0010402252664789557 err 0.29194000363349915 tr(WHW.T) 280.6507568359375
bpp_loss 5.7292915808502585
15_q proxy err 0.0002693775459192693 err 7.549245357513428 tr(WHW.T) 28024.77734375
bpp_loss 4.729643669910729
15_k proxy err 0.00011294808064121753 err 2.1283321380615234 tr(WHW.T) 18843.455078125
bpp_loss 5.861995137995109
15_o proxy err 0.002703177509829402 err 2.1951234340667725 tr(WHW.T) 812.0530395507812
bpp_loss 4.353519697673619
15_up proxy err 0.0032882068771868944 err 29.355716705322266 tr(WHW.T) 8927.576171875
bpp_loss 3.9737651457211802
15_gate proxy err 0.0007031711284071207 err 32.423622131347656 tr(WHW.T) 46110.5703125
bpp_loss 4.170335015282035
15_down proxy err 0.0026541585102677345 err 16.81098175048828 tr(WHW.T) 6333.8271484375
bpp_loss 4.320497627735937
I0403 03:01:45.851344 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 1.198866844177246s
I0403 03:01:49.627223 3321204 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:01:49.627329 3321204 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:01:49.627370 3321204 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:01:50.009915 3321204 config.py:54] PyTorch version 2.6.0 available.
W0403 03:01:50.234802 3321204 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:01:50.896213 3321204 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:01:50.900137 3305349 quantize_finetune_llama.py:214] layer 17 gpu 1
I0403 03:01:51.235014 3321204 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:01:52.142666 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 0.8171494007110596s
I0403 03:01:55.635345 3321338 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:01:55.635434 3321338 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:01:55.635473 3321338 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:01:55.959496 3321338 config.py:54] PyTorch version 2.6.0 available.
W0403 03:01:56.147468 3321338 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:01:56.718160 3321338 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:01:56.721919 3305349 quantize_finetune_llama.py:214] layer 18 gpu 0
I0403 03:01:56.875873 3321338 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.0009415327222086489 err 0.25545310974121094 tr(WHW.T) 271.31622314453125
bpp_loss 5.730068363714963
16_q proxy err 0.0002686596126295626 err 6.5649285316467285 tr(WHW.T) 24435.859375
bpp_loss 4.722915941034444
16_k proxy err 9.783310815691948e-05 err 1.905566692352295 tr(WHW.T) 19477.728515625
bpp_loss 5.95880608947482
16_o proxy err 0.0023639227729290724 err 2.2550737857818604 tr(WHW.T) 953.9540405273438
bpp_loss 4.337126291706227
16_up proxy err 0.003740091575309634 err 30.91568374633789 tr(WHW.T) 8266.0234375
bpp_loss 3.955844877886453
16_gate proxy err 0.0008366564870811999 err 34.356170654296875 tr(WHW.T) 41063.65234375
bpp_loss 4.190702293467309
16_down proxy err 0.002773451153188944 err 17.263212203979492 tr(WHW.T) 6224.45166015625
bpp_loss 4.3183774948785345
17_v proxy err 0.0011315335286781192 err 0.31726640462875366 tr(WHW.T) 280.38623046875
bpp_loss 5.729444964788854
17_q proxy err 0.0002705668448470533 err 7.445918083190918 tr(WHW.T) 27519.69921875
bpp_loss 4.7029810982057825
17_k proxy err 0.00012434195377863944 err 2.1636569499969482 tr(WHW.T) 17400.859375
bpp_loss 5.884342082776129
17_o proxy err 0.0022400568705052137 err 2.442667007446289 tr(WHW.T) 1090.4486083984375
bpp_loss 4.355001100106165
17_up proxy err 0.00370048894546926 err 31.039371490478516 tr(WHW.T) 8387.9111328125
bpp_loss 3.9496108889579773
17_gate proxy err 0.0008310991106554866 err 34.57604217529297 tr(WHW.T) 41602.7890625
bpp_loss 4.199683442246169
17_down proxy err 0.002795666689053178 err 17.1897029876709 tr(WHW.T) 6148.6953125
bpp_loss 4.316543725285945
I0403 03:04:12.994733 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 1.0629920959472656s
I0403 03:04:16.573535 3323215 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:04:16.573625 3323215 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:04:16.573667 3323215 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:04:16.932354 3323215 config.py:54] PyTorch version 2.6.0 available.
W0403 03:04:17.137298 3323215 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:04:17.776647 3323215 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:04:17.780540 3305349 quantize_finetune_llama.py:214] layer 19 gpu 1
I0403 03:04:18.207796 3323215 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:04:19.123677 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 0.9129443168640137s
I0403 03:04:23.206383 3323408 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:04:23.206660 3323408 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:04:23.206766 3323408 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:04:23.622198 3323408 config.py:54] PyTorch version 2.6.0 available.
W0403 03:04:23.851225 3323408 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:04:24.634676 3323408 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:04:24.638893 3305349 quantize_finetune_llama.py:214] layer 20 gpu 0
I0403 03:04:24.839433 3323408 data_utils.py:336] using 256 training seqs, 128 validation seqs
18_v proxy err 0.0008966955938376486 err 0.25528913736343384 tr(WHW.T) 284.69989013671875
bpp_loss 5.73016483488027
18_q proxy err 0.0003377496905159205 err 7.548535346984863 tr(WHW.T) 22349.49609375
bpp_loss 4.6764635972213
18_k proxy err 0.00012978969607502222 err 2.2537193298339844 tr(WHW.T) 17364.392578125
bpp_loss 5.8958468093769625
18_o proxy err 0.002316794591024518 err 2.75187087059021 tr(WHW.T) 1187.7923583984375
bpp_loss 4.345314038801007
18_up proxy err 0.004101361148059368 err 32.47843551635742 tr(WHW.T) 7918.9404296875
bpp_loss 3.93890811842201
18_gate proxy err 0.0010263322619721293 err 36.053287506103516 tr(WHW.T) 35128.28125
bpp_loss 4.198613608056413
18_down proxy err 0.002897975267842412 err 17.861297607421875 tr(WHW.T) 6163.37109375
bpp_loss 4.3156956727283875
19_v proxy err 0.0008616206469014287 err 0.2910471260547638 tr(WHW.T) 337.79034423828125
bpp_loss 5.730741285951808
19_q proxy err 0.00032512308098375797 err 7.799005508422852 tr(WHW.T) 23987.85546875
bpp_loss 4.6685561765916646
19_k proxy err 0.00014428618305828422 err 2.240072011947632 tr(WHW.T) 15525.201171875
bpp_loss 5.833667575963773
19_o proxy err 0.002593130571767688 err 2.990135908126831 tr(WHW.T) 1153.098876953125
bpp_loss 4.3407053970731795
19_up proxy err 0.004353392869234085 err 33.024208068847656 tr(WHW.T) 7585.85546875
bpp_loss 3.9342281012795866
19_gate proxy err 0.0011226332280784845 err 36.7048454284668 tr(WHW.T) 32695.314453125
bpp_loss 4.204679212665984
19_down proxy err 0.0029640020802617073 err 18.139123916625977 tr(WHW.T) 6119.80810546875
bpp_loss 4.315514256445957
I0403 03:06:44.066164 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.0568275451660156s
I0403 03:06:47.891926 3325167 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:06:47.892041 3325167 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:06:47.892082 3325167 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:06:48.398330 3325167 config.py:54] PyTorch version 2.6.0 available.
W0403 03:06:48.633155 3325167 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:06:49.401241 3325167 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:06:49.405303 3305349 quantize_finetune_llama.py:214] layer 21 gpu 1
I0403 03:06:49.616393 3325167 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:06:51.036770 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 1.1044106483459473s
I0403 03:06:55.224297 3325300 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:06:55.224430 3325300 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:06:55.224475 3325300 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:06:55.640542 3325300 config.py:54] PyTorch version 2.6.0 available.
W0403 03:06:55.855751 3325300 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:06:56.506631 3325300 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:06:56.511023 3305349 quantize_finetune_llama.py:214] layer 22 gpu 0
I0403 03:06:56.699498 3325300 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.0009942057076841593 err 0.32469817996025085 tr(WHW.T) 326.5905456542969
bpp_loss 5.7298763893777505
20_q proxy err 0.00035698164720088243 err 7.3854875564575195 tr(WHW.T) 20688.703125
bpp_loss 4.674628540989943
20_k proxy err 0.00014010290033183992 err 2.153170108795166 tr(WHW.T) 15368.4912109375
bpp_loss 5.84209544910118
20_o proxy err 0.0025786675978451967 err 3.0677359104156494 tr(WHW.T) 1189.6593017578125
bpp_loss 4.3373565170913935
20_up proxy err 0.004430620465427637 err 33.38824462890625 tr(WHW.T) 7535.79443359375
bpp_loss 3.9354939038333083
20_gate proxy err 0.0012130809482187033 err 37.057640075683594 tr(WHW.T) 30548.365234375
bpp_loss 4.203742995725146
20_down proxy err 0.002960685407742858 err 18.46719741821289 tr(WHW.T) 6237.4736328125
bpp_loss 4.315285694319755
21_v proxy err 0.0009624260710552335 err 0.34554192423820496 tr(WHW.T) 359.03216552734375
bpp_loss 5.731730314088054
21_q proxy err 0.00029171977075748146 err 7.5235185623168945 tr(WHW.T) 25790.224609375
bpp_loss 4.650350269046612
21_k proxy err 0.00013043115905020386 err 2.185995101928711 tr(WHW.T) 16759.76171875
bpp_loss 5.845191988628358
21_o proxy err 0.0019487037789076567 err 2.4367401599884033 tr(WHW.T) 1250.4415283203125
bpp_loss 4.373569188988768
21_up proxy err 0.004252743441611528 err 32.781532287597656 tr(WHW.T) 7708.326171875
bpp_loss 3.938549842485892
21_gate proxy err 0.0011592073133215308 err 36.454532623291016 tr(WHW.T) 31447.8125
bpp_loss 4.213694447119321
21_down proxy err 0.002885219408199191 err 18.14142608642578 tr(WHW.T) 6287.7109375
bpp_loss 4.315824813409043
I0403 03:09:14.682234 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 1.0090184211730957s
I0403 03:09:18.900014 3327091 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:09:18.900201 3327091 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:09:18.900262 3327091 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:09:19.362735 3327091 config.py:54] PyTorch version 2.6.0 available.
W0403 03:09:19.578106 3327091 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:09:20.239813 3327091 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:09:20.243909 3305349 quantize_finetune_llama.py:214] layer 23 gpu 1
I0403 03:09:20.475507 3327091 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:09:21.759722 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 1.046858549118042s
I0403 03:09:26.130721 3327237 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:09:26.130854 3327237 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:09:26.130895 3327237 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:09:26.576293 3327237 config.py:54] PyTorch version 2.6.0 available.
W0403 03:09:26.791198 3327237 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:09:27.452892 3327237 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:09:27.457012 3305349 quantize_finetune_llama.py:214] layer 24 gpu 0
I0403 03:09:27.652442 3327237 data_utils.py:336] using 256 training seqs, 128 validation seqs
22_v proxy err 0.0010984432883560658 err 0.375471293926239 tr(WHW.T) 341.8212890625
bpp_loss 5.729752826155163
22_q proxy err 0.0003425427421461791 err 6.944772243499756 tr(WHW.T) 20274.177734375
bpp_loss 4.639115344150923
22_k proxy err 0.0001388938253512606 err 2.041396379470825 tr(WHW.T) 14697.5322265625
bpp_loss 5.849666503374465
22_o proxy err 0.0029102249536663294 err 3.506882905960083 tr(WHW.T) 1205.021240234375
bpp_loss 4.32670882192906
22_up proxy err 0.004449053201824427 err 33.29050827026367 tr(WHW.T) 7482.60498046875
bpp_loss 3.9385631840143884
22_gate proxy err 0.0012516406131908298 err 36.817691802978516 tr(WHW.T) 29415.544921875
bpp_loss 4.213413576196347
22_down proxy err 0.002866169670596719 err 18.530662536621094 tr(WHW.T) 6465.3056640625
bpp_loss 4.315332928472864
23_v proxy err 0.0010646191658452153 err 0.4185914397239685 tr(WHW.T) 393.1842041015625
bpp_loss 5.727733822306618
23_q proxy err 0.0003379109548404813 err 7.624321460723877 tr(WHW.T) 22563.107421875
bpp_loss 4.61276543373242
23_k proxy err 0.00014784940867684782 err 2.1927688121795654 tr(WHW.T) 14831.095703125
bpp_loss 5.789135637343861
23_o proxy err 0.0023747875820845366 err 4.101292610168457 tr(WHW.T) 1727.0145263671875
bpp_loss 4.32649756630417
23_up proxy err 0.004531404934823513 err 33.32415771484375 tr(WHW.T) 7354.04541015625
bpp_loss 3.9410561472177505
23_gate proxy err 0.0013521747896447778 err 36.74226379394531 tr(WHW.T) 27172.716796875
bpp_loss 4.215937007950353
23_down proxy err 0.0029175695963203907 err 19.262556076049805 tr(WHW.T) 6602.26123046875
bpp_loss 4.315094337332994
I0403 03:11:37.441909 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.8604183197021484s
I0403 03:11:41.027916 3329048 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:11:41.028014 3329048 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:11:41.028053 3329048 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:11:41.353317 3329048 config.py:54] PyTorch version 2.6.0 available.
W0403 03:11:41.546452 3329048 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:11:42.145255 3329048 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:11:42.148766 3305349 quantize_finetune_llama.py:214] layer 25 gpu 1
I0403 03:11:42.395431 3329048 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:11:43.609964 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 1.0286016464233398s
I0403 03:11:47.223123 3329181 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:11:47.223210 3329181 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:11:47.223249 3329181 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:11:47.542038 3329181 config.py:54] PyTorch version 2.6.0 available.
W0403 03:11:47.729805 3329181 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:11:48.300631 3329181 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:11:48.304155 3305349 quantize_finetune_llama.py:214] layer 26 gpu 0
I0403 03:11:48.519923 3329181 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.0010889361146837473 err 0.5026423335075378 tr(WHW.T) 461.59027099609375
bpp_loss 5.729727020370774
24_q proxy err 0.00032973798806779087 err 7.383418083190918 tr(WHW.T) 22391.7734375
bpp_loss 4.599464534665458
24_k proxy err 0.00014423919492401183 err 2.0423622131347656 tr(WHW.T) 14159.55078125
bpp_loss 5.750943035935052
24_o proxy err 0.0025335121899843216 err 3.978598117828369 tr(WHW.T) 1570.388427734375
bpp_loss 4.346432637306862
24_up proxy err 0.004655731841921806 err 33.732666015625 tr(WHW.T) 7245.40576171875
bpp_loss 3.943412971150662
24_gate proxy err 0.0014418602222576737 err 37.13847351074219 tr(WHW.T) 25757.33203125
bpp_loss 4.220557217752295
24_down proxy err 0.0029795581940561533 err 19.89325714111328 tr(WHW.T) 6676.57958984375
bpp_loss 4.31476472284911
25_v proxy err 0.0009266475099138916 err 0.5115517377853394 tr(WHW.T) 552.045654296875
bpp_loss 5.729711652500555
25_q proxy err 0.00029206176986917853 err 7.613787651062012 tr(WHW.T) 26069.1015625
bpp_loss 4.567397242295556
25_k proxy err 0.00014331030251923949 err 2.062664270401001 tr(WHW.T) 14392.994140625
bpp_loss 5.745843428070657
25_o proxy err 0.00206859246827662 err 4.077592849731445 tr(WHW.T) 1971.1920166015625
bpp_loss 4.35030982166063
25_up proxy err 0.004613595549017191 err 33.749900817871094 tr(WHW.T) 7315.31396484375
bpp_loss 3.9505394155691778
25_gate proxy err 0.0014176275581121445 err 37.121700286865234 tr(WHW.T) 26185.79296875
bpp_loss 4.229696521402469
25_down proxy err 0.003128394950181246 err 20.489316940307617 tr(WHW.T) 6549.46630859375
bpp_loss 4.314747702662966
I0403 03:13:51.908844 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.8510499000549316s
I0403 03:13:55.525623 3330844 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:13:55.525712 3330844 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:13:55.525754 3330844 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:13:55.858633 3330844 config.py:54] PyTorch version 2.6.0 available.
W0403 03:13:56.054190 3330844 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:13:56.620801 3330844 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:13:56.624577 3305349 quantize_finetune_llama.py:214] layer 27 gpu 1
I0403 03:13:56.804422 3330844 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:13:57.838341 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.8207767009735107s
I0403 03:14:01.373288 3330985 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:14:01.373383 3330985 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:14:01.373422 3330985 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:14:01.711762 3330985 config.py:54] PyTorch version 2.6.0 available.
W0403 03:14:01.902601 3330985 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:14:02.472682 3330985 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:14:02.476629 3305349 quantize_finetune_llama.py:214] layer 28 gpu 0
I0403 03:14:02.685906 3330985 data_utils.py:336] using 256 training seqs, 128 validation seqs
26_v proxy err 0.0013264938024803996 err 0.567980945110321 tr(WHW.T) 428.18212890625
bpp_loss 5.729198298184201
26_q proxy err 0.0003353877691552043 err 7.16379451751709 tr(WHW.T) 21359.736328125
bpp_loss 4.598337308387272
26_k proxy err 0.0001337354478891939 err 2.0595738887786865 tr(WHW.T) 15400.359375
bpp_loss 5.793804743909277
26_o proxy err 0.001497716293670237 err 3.5475502014160156 tr(WHW.T) 2368.6396484375
bpp_loss 4.378848252701573
26_up proxy err 0.004462279379367828 err 33.81373977661133 tr(WHW.T) 7577.68359375
bpp_loss 3.957099081017077
26_gate proxy err 0.0012925069313496351 err 37.195892333984375 tr(WHW.T) 28778.099609375
bpp_loss 4.238024810927787
26_down proxy err 0.0031679561361670494 err 20.753963470458984 tr(WHW.T) 6551.21533203125
bpp_loss 4.31511763420089
27_v proxy err 0.0009709309670142829 err 0.6508567929267883 tr(WHW.T) 670.343017578125
bpp_loss 5.72894025570713
27_q proxy err 0.00035655772080644965 err 7.581789493560791 tr(WHW.T) 21263.849609375
bpp_loss 4.557855188380927
27_k proxy err 0.00015127028746064752 err 2.1158125400543213 tr(WHW.T) 13986.966796875
bpp_loss 5.746054776478559
27_o proxy err 0.001733735902234912 err 3.708085298538208 tr(WHW.T) 2138.783203125
bpp_loss 4.373858559993096
27_up proxy err 0.0040792361833155155 err 34.28951644897461 tr(WHW.T) 8405.8671875
bpp_loss 3.9648904532327185
27_gate proxy err 0.0011508484603837132 err 37.613929748535156 tr(WHW.T) 32683.65234375
bpp_loss 4.246276359805571
27_down proxy err 0.002946527674794197 err 19.07647705078125 tr(WHW.T) 6474.22314453125
bpp_loss 4.341410281203155
I0403 03:16:06.199068 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 0.8723659515380859s
I0403 03:16:09.780569 3332491 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:16:09.780659 3332491 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:16:09.780698 3332491 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:16:10.121856 3332491 config.py:54] PyTorch version 2.6.0 available.
W0403 03:16:10.315248 3332491 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:16:10.888854 3332491 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:16:10.892682 3305349 quantize_finetune_llama.py:214] layer 29 gpu 1
I0403 03:16:11.084726 3332491 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:16:12.153242 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 0.8524298667907715s
I0403 03:16:15.715813 3332617 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:16:15.715924 3332617 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:16:15.715969 3332617 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:16:16.048082 3332617 config.py:54] PyTorch version 2.6.0 available.
W0403 03:16:16.243929 3332617 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:16:16.832020 3332617 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:16:16.836033 3305349 quantize_finetune_llama.py:214] layer 30 gpu 0
I0403 03:16:17.039304 3332617 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.001178939826786518 err 0.6997755765914917 tr(WHW.T) 593.5634155273438
bpp_loss 5.72927130095195
28_q proxy err 0.00032732257386669517 err 7.568268775939941 tr(WHW.T) 23121.744140625
bpp_loss 4.556721691042185
28_k proxy err 0.00013017907622270286 err 1.9490219354629517 tr(WHW.T) 14971.8525390625
bpp_loss 5.729319784673862
28_o proxy err 0.0015424428274855018 err 3.8393402099609375 tr(WHW.T) 2489.129638671875
bpp_loss 4.399502069456503
28_up proxy err 0.003293749876320362 err 33.50861358642578 tr(WHW.T) 10173.3935546875
bpp_loss 3.984360095446131
28_gate proxy err 0.001020199153572321 err 36.520111083984375 tr(WHW.T) 35797.04296875
bpp_loss 4.241498786290841
28_down proxy err 0.0026062987744808197 err 18.60521697998047 tr(WHW.T) 7138.55908203125
bpp_loss 4.353422876713531
29_v proxy err 0.000883289787452668 err 0.7435612082481384 tr(WHW.T) 841.8088989257812
bpp_loss 5.7298440602608025
29_q proxy err 0.0004005154187325388 err 8.255248069763184 tr(WHW.T) 20611.560546875
bpp_loss 4.499218216864392
29_k proxy err 0.0001267326297238469 err 2.0709729194641113 tr(WHW.T) 16341.275390625
bpp_loss 5.740036861854605
29_o proxy err 0.0009904515463858843 err 3.049578905105591 tr(WHW.T) 3078.978271484375
bpp_loss 4.4575620527612045
29_up proxy err 0.0025702975690364838 err 32.87857437133789 tr(WHW.T) 12791.73828125
bpp_loss 4.00562880740368
29_gate proxy err 0.0009273962932638824 err 35.46477508544922 tr(WHW.T) 38241.23046875
bpp_loss 4.2380666428777785
29_down proxy err 0.0021415362134575844 err 15.839603424072266 tr(WHW.T) 7396.3740234375
bpp_loss 4.398295740264335
I0403 03:18:18.209110 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 0.595104455947876s
I0403 03:18:21.596738 3333824 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:18:21.596833 3333824 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:18:21.596873 3333824 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:18:21.933020 3333824 config.py:54] PyTorch version 2.6.0 available.
W0403 03:18:22.120948 3333824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:18:22.689661 3333824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:18:22.693198 3305349 quantize_finetune_llama.py:214] layer 31 gpu 1
I0403 03:18:22.899639 3333824 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 03:18:24.050531 3305349 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 0.90329909324646s
I0403 03:18:27.663350 3333957 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:18:27.663437 3333957 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:18:27.663476 3333957 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:18:27.992334 3333957 config.py:54] PyTorch version 2.6.0 available.
W0403 03:18:28.183277 3333957 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 03:18:28.750597 3333957 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 03:18:29.009769 3333957 data_utils.py:336] using 256 training seqs, 128 validation seqs
30_v proxy err 0.0012151096016168594 err 1.0336337089538574 tr(WHW.T) 850.650634765625
bpp_loss 5.729284864035435
30_q proxy err 0.000292825949145481 err 7.03156042098999 tr(WHW.T) 24012.763671875
bpp_loss 4.491374739562161
30_k proxy err 0.00010666441812645644 err 1.494553565979004 tr(WHW.T) 14011.7353515625
bpp_loss 5.728740953956731
30_o proxy err 0.0008626374765299261 err 4.176759719848633 tr(WHW.T) 4841.84814453125
bpp_loss 4.410472569521517
30_up proxy err 0.0015172867570072412 err 32.81965637207031 tr(WHW.T) 21630.490234375
bpp_loss 4.021810369033899
30_gate proxy err 0.0006844691233709455 err 35.47077941894531 tr(WHW.T) 51822.3203125
bpp_loss 4.276548254436681
30_down proxy err 0.001088143908418715 err 9.504889488220215 tr(WHW.T) 8734.9560546875
bpp_loss 4.477121984053936
31_v proxy err 0.0004173214838374406 err 0.7507146596908569 tr(WHW.T) 1798.8880615234375
bpp_loss 5.732908402336761
31_q proxy err 0.00016835964925121516 err 7.766424179077148 tr(WHW.T) 46129.9609375
bpp_loss 4.5324845055583864
31_k proxy err 7.967618148541078e-05 err 1.629002571105957 tr(WHW.T) 20445.2890625
bpp_loss 5.747936442145146
31_o proxy err 0.0005765425157733262 err 1.260869026184082 tr(WHW.T) 2186.948974609375
bpp_loss 4.565223908401094
31_up proxy err 0.000465830642497167 err 32.10074996948242 tr(WHW.T) 68910.7734375
bpp_loss 4.158328590116331
31_gate proxy err 0.00023853052698541433 err 34.415401458740234 tr(WHW.T) 144280.90625
bpp_loss 4.450347499190165
31_down proxy err 0.00026329056709073484 err 2.6013288497924805 tr(WHW.T) 9880.068359375
bpp_loss 4.5791598627277255
I0403 03:20:40.739995 3335210 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:20:40.740102 3335210 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:20:40.740144 3335210 utils.py:162] NumExpr defaulting to 16 threads.
I0403 03:20:41.067445 3335210 config.py:54] PyTorch version 2.6.0 available.
W0403 03:20:41.284961 3335210 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 03:20:41.398980 3335210 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.81it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.68it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.28it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.22it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.23it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.45it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.37it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.23it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.24it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.32it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.52it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.54it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.46it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.43it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.42it/s]
I0403 03:20:44.599490 3335210 hfize_llama.py:161] loaded layer 0
I0403 03:20:45.357768 3335210 hfize_llama.py:161] loaded layer 1
I0403 03:20:46.039388 3335210 hfize_llama.py:161] loaded layer 2
I0403 03:20:46.791368 3335210 hfize_llama.py:161] loaded layer 3
I0403 03:20:47.452309 3335210 hfize_llama.py:161] loaded layer 4
I0403 03:20:48.372317 3335210 hfize_llama.py:161] loaded layer 5
I0403 03:20:49.124959 3335210 hfize_llama.py:161] loaded layer 6
I0403 03:20:49.866133 3335210 hfize_llama.py:161] loaded layer 7
I0403 03:20:50.809298 3335210 hfize_llama.py:161] loaded layer 8
I0403 03:20:51.545073 3335210 hfize_llama.py:161] loaded layer 9
I0403 03:20:52.221454 3335210 hfize_llama.py:161] loaded layer 10
I0403 03:20:52.901577 3335210 hfize_llama.py:161] loaded layer 11
I0403 03:20:53.580938 3335210 hfize_llama.py:161] loaded layer 12
I0403 03:20:54.253211 3335210 hfize_llama.py:161] loaded layer 13
I0403 03:20:54.899373 3335210 hfize_llama.py:161] loaded layer 14
I0403 03:20:55.526962 3335210 hfize_llama.py:161] loaded layer 15
I0403 03:20:56.143491 3335210 hfize_llama.py:161] loaded layer 16
I0403 03:20:56.784202 3335210 hfize_llama.py:161] loaded layer 17
I0403 03:20:57.512691 3335210 hfize_llama.py:161] loaded layer 18
I0403 03:20:58.215210 3335210 hfize_llama.py:161] loaded layer 19
I0403 03:20:58.986325 3335210 hfize_llama.py:161] loaded layer 20
I0403 03:20:59.648222 3335210 hfize_llama.py:161] loaded layer 21
I0403 03:21:00.318780 3335210 hfize_llama.py:161] loaded layer 22
I0403 03:21:00.949809 3335210 hfize_llama.py:161] loaded layer 23
I0403 03:21:01.567248 3335210 hfize_llama.py:161] loaded layer 24
I0403 03:21:02.199435 3335210 hfize_llama.py:161] loaded layer 25
I0403 03:21:02.794393 3335210 hfize_llama.py:161] loaded layer 26
I0403 03:21:03.386586 3335210 hfize_llama.py:161] loaded layer 27
I0403 03:21:03.995219 3335210 hfize_llama.py:161] loaded layer 28
I0403 03:21:04.655650 3335210 hfize_llama.py:161] loaded layer 29
I0403 03:21:05.269641 3335210 hfize_llama.py:161] loaded layer 30
I0403 03:21:05.898514 3335210 hfize_llama.py:161] loaded layer 31
I0403 03:21:05.898692 3335210 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:07,  1.21s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.06s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.01s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.01s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:01,  1.01it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]
I0403 03:21:44.249401 3335210 hfize_llama.py:175] successfully loaded hfized model
I0403 03:21:49.285999 3336116 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 03:21:49.286110 3336116 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 03:21:49.286153 3336116 utils.py:162] NumExpr defaulting to 16 threads.
W0403 03:21:49.650491 3336116 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 03:21:50.005316 3336116 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.04s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.04s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.05s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.07s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.06s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.05s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]
I0403 03:21:56.987980 3336116 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 1.5438504219055176:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 1.5438504219055176:   1%|          | 1/141 [00:01<04:30,  1.93s/it]avg_loss = 1.864777684211731:   1%|          | 1/141 [00:03<04:30,  1.93s/it] avg_loss = 1.864777684211731:   1%|▏         | 2/141 [00:03<03:49,  1.65s/it]avg_loss = 2.0039635499318442:   1%|▏         | 2/141 [00:04<03:49,  1.65s/it]avg_loss = 2.0039635499318442:   2%|▏         | 3/141 [00:04<03:36,  1.57s/it]avg_loss = 1.9584904611110687:   2%|▏         | 3/141 [00:06<03:36,  1.57s/it]avg_loss = 1.9584904611110687:   3%|▎         | 4/141 [00:06<03:29,  1.53s/it]avg_loss = 1.9126733064651489:   3%|▎         | 4/141 [00:07<03:29,  1.53s/it]avg_loss = 1.9126733064651489:   4%|▎         | 5/141 [00:07<03:25,  1.51s/it]avg_loss = 1.8156708876291912:   4%|▎         | 5/141 [00:09<03:25,  1.51s/it]avg_loss = 1.8156708876291912:   4%|▍         | 6/141 [00:09<03:22,  1.50s/it]avg_loss = 1.7517217227390833:   4%|▍         | 6/141 [00:10<03:22,  1.50s/it]avg_loss = 1.7517217227390833:   5%|▍         | 7/141 [00:10<03:20,  1.49s/it]avg_loss = 1.7479075342416763:   5%|▍         | 7/141 [00:12<03:20,  1.49s/it]avg_loss = 1.7479075342416763:   6%|▌         | 8/141 [00:12<03:18,  1.49s/it]avg_loss = 1.7824924389521282:   6%|▌         | 8/141 [00:13<03:18,  1.49s/it]avg_loss = 1.7824924389521282:   6%|▋         | 9/141 [00:13<03:16,  1.49s/it]avg_loss = 1.7869719505310058:   6%|▋         | 9/141 [00:15<03:16,  1.49s/it]avg_loss = 1.7869719505310058:   7%|▋         | 10/141 [00:15<03:15,  1.49s/it]avg_loss = 1.783477078784596:   7%|▋         | 10/141 [00:16<03:15,  1.49s/it] avg_loss = 1.783477078784596:   8%|▊         | 11/141 [00:16<03:14,  1.49s/it]avg_loss = 1.8061184585094452:   8%|▊         | 11/141 [00:18<03:14,  1.49s/it]avg_loss = 1.8061184585094452:   9%|▊         | 12/141 [00:18<03:12,  1.49s/it]avg_loss = 1.8184186495267427:   9%|▊         | 12/141 [00:19<03:12,  1.49s/it]avg_loss = 1.8184186495267427:   9%|▉         | 13/141 [00:19<03:11,  1.50s/it]avg_loss = 1.8362620217459542:   9%|▉         | 13/141 [00:21<03:11,  1.50s/it]avg_loss = 1.8362620217459542:  10%|▉         | 14/141 [00:21<03:10,  1.50s/it]avg_loss = 1.8462780714035034:  10%|▉         | 14/141 [00:22<03:10,  1.50s/it]avg_loss = 1.8462780714035034:  11%|█         | 15/141 [00:22<03:09,  1.50s/it]avg_loss = 1.871287889778614:  11%|█         | 15/141 [00:24<03:09,  1.50s/it] avg_loss = 1.871287889778614:  11%|█▏        | 16/141 [00:24<03:07,  1.50s/it]avg_loss = 1.875074919532327:  11%|█▏        | 16/141 [00:25<03:07,  1.50s/it]avg_loss = 1.875074919532327:  12%|█▏        | 17/141 [00:25<03:06,  1.50s/it]avg_loss = 1.8770825068155925:  12%|█▏        | 17/141 [00:27<03:06,  1.50s/it]avg_loss = 1.8770825068155925:  13%|█▎        | 18/141 [00:27<03:05,  1.51s/it]avg_loss = 1.8580127452549182:  13%|█▎        | 18/141 [00:28<03:05,  1.51s/it]avg_loss = 1.8580127452549182:  13%|█▎        | 19/141 [00:28<03:04,  1.51s/it]avg_loss = 1.8565284371376038:  13%|█▎        | 19/141 [00:30<03:04,  1.51s/it]avg_loss = 1.8565284371376038:  14%|█▍        | 20/141 [00:30<03:02,  1.51s/it]avg_loss = 1.8612643537067233:  14%|█▍        | 20/141 [00:31<03:02,  1.51s/it]avg_loss = 1.8612643537067233:  15%|█▍        | 21/141 [00:31<03:01,  1.51s/it]avg_loss = 1.8638902631672947:  15%|█▍        | 21/141 [00:33<03:01,  1.51s/it]avg_loss = 1.8638902631672947:  16%|█▌        | 22/141 [00:33<03:00,  1.52s/it]avg_loss = 1.8654925926871921:  16%|█▌        | 22/141 [00:34<03:00,  1.52s/it]avg_loss = 1.8654925926871921:  16%|█▋        | 23/141 [00:34<02:59,  1.52s/it]avg_loss = 1.870427871743838:  16%|█▋        | 23/141 [00:36<02:59,  1.52s/it] avg_loss = 1.870427871743838:  17%|█▋        | 24/141 [00:36<02:58,  1.52s/it]avg_loss = 1.8763815355300903:  17%|█▋        | 24/141 [00:37<02:58,  1.52s/it]avg_loss = 1.8763815355300903:  18%|█▊        | 25/141 [00:37<02:56,  1.52s/it]avg_loss = 1.8881302567628713:  18%|█▊        | 25/141 [00:39<02:56,  1.52s/it]avg_loss = 1.8881302567628713:  18%|█▊        | 26/141 [00:39<02:55,  1.53s/it]avg_loss = 1.9012166614885684:  18%|█▊        | 26/141 [00:40<02:55,  1.53s/it]avg_loss = 1.9012166614885684:  19%|█▉        | 27/141 [00:40<02:54,  1.53s/it]avg_loss = 1.9080008906977517:  19%|█▉        | 27/141 [00:42<02:54,  1.53s/it]avg_loss = 1.9080008906977517:  20%|█▉        | 28/141 [00:42<02:52,  1.53s/it]avg_loss = 1.9046198499613796:  20%|█▉        | 28/141 [00:44<02:52,  1.53s/it]avg_loss = 1.9046198499613796:  21%|██        | 29/141 [00:44<02:51,  1.53s/it]avg_loss = 1.8951753417650858:  21%|██        | 29/141 [00:45<02:51,  1.53s/it]avg_loss = 1.8951753417650858:  21%|██▏       | 30/141 [00:45<02:50,  1.53s/it]avg_loss = 1.8808290073948521:  21%|██▏       | 30/141 [00:47<02:50,  1.53s/it]avg_loss = 1.8808290073948521:  22%|██▏       | 31/141 [00:47<02:49,  1.54s/it]avg_loss = 1.8688403777778149:  22%|██▏       | 31/141 [00:48<02:49,  1.54s/it]avg_loss = 1.8688403777778149:  23%|██▎       | 32/141 [00:48<02:47,  1.54s/it]avg_loss = 1.8675786798650569:  23%|██▎       | 32/141 [00:50<02:47,  1.54s/it]avg_loss = 1.8675786798650569:  23%|██▎       | 33/141 [00:50<02:46,  1.54s/it]avg_loss = 1.865959437454448:  23%|██▎       | 33/141 [00:51<02:46,  1.54s/it] avg_loss = 1.865959437454448:  24%|██▍       | 34/141 [00:51<02:44,  1.54s/it]avg_loss = 1.8686335461480277:  24%|██▍       | 34/141 [00:53<02:44,  1.54s/it]avg_loss = 1.8686335461480277:  25%|██▍       | 35/141 [00:53<02:43,  1.55s/it]avg_loss = 1.8519705567095015:  25%|██▍       | 35/141 [00:54<02:43,  1.55s/it]avg_loss = 1.8519705567095015:  26%|██▌       | 36/141 [00:54<02:42,  1.55s/it]avg_loss = 1.8367012868056427:  26%|██▌       | 36/141 [00:56<02:42,  1.55s/it]avg_loss = 1.8367012868056427:  26%|██▌       | 37/141 [00:56<02:40,  1.55s/it]avg_loss = 1.8221099470791065:  26%|██▌       | 37/141 [00:57<02:40,  1.55s/it]avg_loss = 1.8221099470791065:  27%|██▋       | 38/141 [00:57<02:39,  1.55s/it]avg_loss = 1.80795030716138:  27%|██▋       | 38/141 [00:59<02:39,  1.55s/it]  avg_loss = 1.80795030716138:  28%|██▊       | 39/141 [00:59<02:38,  1.55s/it]avg_loss = 1.7997612684965134:  28%|██▊       | 39/141 [01:01<02:38,  1.55s/it]avg_loss = 1.7997612684965134:  28%|██▊       | 40/141 [01:01<02:36,  1.55s/it]avg_loss = 1.8046955916939713:  28%|██▊       | 40/141 [01:02<02:36,  1.55s/it]avg_loss = 1.8046955916939713:  29%|██▉       | 41/141 [01:02<02:35,  1.55s/it]avg_loss = 1.821765368893033:  29%|██▉       | 41/141 [01:04<02:35,  1.55s/it] avg_loss = 1.821765368893033:  30%|██▉       | 42/141 [01:04<02:33,  1.55s/it]avg_loss = 1.838264601175175:  30%|██▉       | 42/141 [01:05<02:33,  1.55s/it]avg_loss = 1.838264601175175:  30%|███       | 43/141 [01:05<02:32,  1.56s/it]avg_loss = 1.8412905606356533:  30%|███       | 43/141 [01:07<02:32,  1.56s/it]avg_loss = 1.8412905606356533:  31%|███       | 44/141 [01:07<02:30,  1.56s/it]avg_loss = 1.845549800660875:  31%|███       | 44/141 [01:08<02:30,  1.56s/it] avg_loss = 1.845549800660875:  32%|███▏      | 45/141 [01:08<02:29,  1.56s/it]avg_loss = 1.8509680343710857:  32%|███▏      | 45/141 [01:10<02:29,  1.56s/it]avg_loss = 1.8509680343710857:  33%|███▎      | 46/141 [01:10<02:28,  1.56s/it]avg_loss = 1.8577365469425282:  33%|███▎      | 46/141 [01:11<02:28,  1.56s/it]avg_loss = 1.8577365469425282:  33%|███▎      | 47/141 [01:11<02:26,  1.56s/it]avg_loss = 1.8611066391070683:  33%|███▎      | 47/141 [01:13<02:26,  1.56s/it]avg_loss = 1.8611066391070683:  34%|███▍      | 48/141 [01:13<02:25,  1.56s/it]avg_loss = 1.8598117998668127:  34%|███▍      | 48/141 [01:15<02:25,  1.56s/it]avg_loss = 1.8598117998668127:  35%|███▍      | 49/141 [01:15<02:24,  1.57s/it]avg_loss = 1.859396140575409:  35%|███▍      | 49/141 [01:16<02:24,  1.57s/it] avg_loss = 1.859396140575409:  35%|███▌      | 50/141 [01:16<02:22,  1.57s/it]avg_loss = 1.8529969968047797:  35%|███▌      | 50/141 [01:18<02:22,  1.57s/it]avg_loss = 1.8529969968047797:  36%|███▌      | 51/141 [01:18<02:20,  1.57s/it]avg_loss = 1.8493651403830602:  36%|███▌      | 51/141 [01:19<02:20,  1.57s/it]avg_loss = 1.8493651403830602:  37%|███▋      | 52/141 [01:19<02:19,  1.57s/it]avg_loss = 1.842917316364792:  37%|███▋      | 52/141 [01:21<02:19,  1.57s/it] avg_loss = 1.842917316364792:  38%|███▊      | 53/141 [01:21<02:18,  1.57s/it]avg_loss = 1.8399312098821003:  38%|███▊      | 53/141 [01:22<02:18,  1.57s/it]avg_loss = 1.8399312098821003:  38%|███▊      | 54/141 [01:22<02:16,  1.57s/it]avg_loss = 1.8323585813695735:  38%|███▊      | 54/141 [01:24<02:16,  1.57s/it]avg_loss = 1.8323585813695735:  39%|███▉      | 55/141 [01:24<02:15,  1.57s/it]avg_loss = 1.824615859559604:  39%|███▉      | 55/141 [01:26<02:15,  1.57s/it] avg_loss = 1.824615859559604:  40%|███▉      | 56/141 [01:26<02:13,  1.57s/it]avg_loss = 1.8181816611373633:  40%|███▉      | 56/141 [01:27<02:13,  1.57s/it]avg_loss = 1.8181816611373633:  40%|████      | 57/141 [01:27<02:12,  1.57s/it]avg_loss = 1.815392354439045:  40%|████      | 57/141 [01:29<02:12,  1.57s/it] avg_loss = 1.815392354439045:  41%|████      | 58/141 [01:29<02:10,  1.57s/it]avg_loss = 1.8176208269798149:  41%|████      | 58/141 [01:30<02:10,  1.57s/it]avg_loss = 1.8176208269798149:  42%|████▏     | 59/141 [01:30<02:09,  1.58s/it]avg_loss = 1.8232522408167522:  42%|████▏     | 59/141 [01:32<02:09,  1.58s/it]avg_loss = 1.8232522408167522:  43%|████▎     | 60/141 [01:32<02:07,  1.58s/it]avg_loss = 1.8293084902841537:  43%|████▎     | 60/141 [01:34<02:07,  1.58s/it]avg_loss = 1.8293084902841537:  43%|████▎     | 61/141 [01:34<02:06,  1.58s/it]avg_loss = 1.8367407014293056:  43%|████▎     | 61/141 [01:35<02:06,  1.58s/it]avg_loss = 1.8367407014293056:  44%|████▍     | 62/141 [01:35<02:04,  1.58s/it]avg_loss = 1.8275137439606681:  44%|████▍     | 62/141 [01:37<02:04,  1.58s/it]avg_loss = 1.8275137439606681:  45%|████▍     | 63/141 [01:37<02:03,  1.58s/it]avg_loss = 1.8254019897431135:  45%|████▍     | 63/141 [01:38<02:03,  1.58s/it]avg_loss = 1.8254019897431135:  45%|████▌     | 64/141 [01:38<02:01,  1.58s/it]avg_loss = 1.8227472580396211:  45%|████▌     | 64/141 [01:40<02:01,  1.58s/it]avg_loss = 1.8227472580396211:  46%|████▌     | 65/141 [01:40<01:59,  1.58s/it]avg_loss = 1.8166988293329875:  46%|████▌     | 65/141 [01:41<01:59,  1.58s/it]avg_loss = 1.8166988293329875:  47%|████▋     | 66/141 [01:41<01:58,  1.58s/it]avg_loss = 1.8141504793024774:  47%|████▋     | 66/141 [01:43<01:58,  1.58s/it]avg_loss = 1.8141504793024774:  48%|████▊     | 67/141 [01:43<01:56,  1.58s/it]avg_loss = 1.8107459071804495:  48%|████▊     | 67/141 [01:45<01:56,  1.58s/it]avg_loss = 1.8107459071804495:  48%|████▊     | 68/141 [01:45<01:55,  1.58s/it]avg_loss = 1.8077865683514138:  48%|████▊     | 68/141 [01:46<01:55,  1.58s/it]avg_loss = 1.8077865683514138:  49%|████▉     | 69/141 [01:46<01:53,  1.58s/it]avg_loss = 1.8086054342133657:  49%|████▉     | 69/141 [01:48<01:53,  1.58s/it]avg_loss = 1.8086054342133657:  50%|████▉     | 70/141 [01:48<01:52,  1.58s/it]avg_loss = 1.8123483439566384:  50%|████▉     | 70/141 [01:49<01:52,  1.58s/it]avg_loss = 1.8123483439566384:  50%|█████     | 71/141 [01:49<01:50,  1.58s/it]avg_loss = 1.8148207896285586:  50%|█████     | 71/141 [01:51<01:50,  1.58s/it]avg_loss = 1.8148207896285586:  51%|█████     | 72/141 [01:51<01:49,  1.58s/it]avg_loss = 1.8134448120038804:  51%|█████     | 72/141 [01:53<01:49,  1.58s/it]avg_loss = 1.8134448120038804:  52%|█████▏    | 73/141 [01:53<01:47,  1.59s/it]avg_loss = 1.8151137587186452:  52%|█████▏    | 73/141 [01:54<01:47,  1.59s/it]avg_loss = 1.8151137587186452:  52%|█████▏    | 74/141 [01:54<01:46,  1.59s/it]avg_loss = 1.8154324181874593:  52%|█████▏    | 74/141 [01:56<01:46,  1.59s/it]avg_loss = 1.8154324181874593:  53%|█████▎    | 75/141 [01:56<01:44,  1.59s/it]avg_loss = 1.8145038422785307:  53%|█████▎    | 75/141 [01:57<01:44,  1.59s/it]avg_loss = 1.8145038422785307:  54%|█████▍    | 76/141 [01:57<01:43,  1.59s/it]avg_loss = 1.8157559137839776:  54%|█████▍    | 76/141 [01:59<01:43,  1.59s/it]avg_loss = 1.8157559137839776:  55%|█████▍    | 77/141 [01:59<01:41,  1.59s/it]avg_loss = 1.8182101845741272:  55%|█████▍    | 77/141 [02:00<01:41,  1.59s/it]avg_loss = 1.8182101845741272:  55%|█████▌    | 78/141 [02:00<01:40,  1.59s/it]avg_loss = 1.822445481638365:  55%|█████▌    | 78/141 [02:02<01:40,  1.59s/it] avg_loss = 1.822445481638365:  56%|█████▌    | 79/141 [02:02<01:38,  1.59s/it]avg_loss = 1.8197411343455314:  56%|█████▌    | 79/141 [02:04<01:38,  1.59s/it]avg_loss = 1.8197411343455314:  57%|█████▋    | 80/141 [02:04<01:36,  1.59s/it]avg_loss = 1.8186914935524081:  57%|█████▋    | 80/141 [02:05<01:36,  1.59s/it]avg_loss = 1.8186914935524081:  57%|█████▋    | 81/141 [02:05<01:35,  1.59s/it]avg_loss = 1.8179904367865585:  57%|█████▋    | 81/141 [02:07<01:35,  1.59s/it]avg_loss = 1.8179904367865585:  58%|█████▊    | 82/141 [02:07<01:33,  1.59s/it]avg_loss = 1.816230374646474:  58%|█████▊    | 82/141 [02:08<01:33,  1.59s/it] avg_loss = 1.816230374646474:  59%|█████▉    | 83/141 [02:08<01:32,  1.59s/it]avg_loss = 1.8140857673826671:  59%|█████▉    | 83/141 [02:10<01:32,  1.59s/it]avg_loss = 1.8140857673826671:  60%|█████▉    | 84/141 [02:10<01:30,  1.59s/it]avg_loss = 1.8117819786071778:  60%|█████▉    | 84/141 [02:12<01:30,  1.59s/it]avg_loss = 1.8117819786071778:  60%|██████    | 85/141 [02:12<01:29,  1.59s/it]avg_loss = 1.8135372372560723:  60%|██████    | 85/141 [02:13<01:29,  1.59s/it]avg_loss = 1.8135372372560723:  61%|██████    | 86/141 [02:13<01:27,  1.59s/it]avg_loss = 1.815579637713816:  61%|██████    | 86/141 [02:15<01:27,  1.59s/it] avg_loss = 1.815579637713816:  62%|██████▏   | 87/141 [02:15<01:25,  1.59s/it]avg_loss = 1.815891596403989:  62%|██████▏   | 87/141 [02:16<01:25,  1.59s/it]avg_loss = 1.815891596403989:  62%|██████▏   | 88/141 [02:16<01:24,  1.59s/it]avg_loss = 1.8246927100620913:  62%|██████▏   | 88/141 [02:18<01:24,  1.59s/it]avg_loss = 1.8246927100620913:  63%|██████▎   | 89/141 [02:18<01:22,  1.59s/it]avg_loss = 1.8322301149368285:  63%|██████▎   | 89/141 [02:20<01:22,  1.59s/it]avg_loss = 1.8322301149368285:  64%|██████▍   | 90/141 [02:20<01:20,  1.59s/it]avg_loss = 1.8353955038301237:  64%|██████▍   | 90/141 [02:21<01:20,  1.59s/it]avg_loss = 1.8353955038301237:  65%|██████▍   | 91/141 [02:21<01:19,  1.59s/it]avg_loss = 1.840427709662396:  65%|██████▍   | 91/141 [02:23<01:19,  1.59s/it] avg_loss = 1.840427709662396:  65%|██████▌   | 92/141 [02:23<01:17,  1.59s/it]avg_loss = 1.8454747558921896:  65%|██████▌   | 92/141 [02:24<01:17,  1.59s/it]avg_loss = 1.8454747558921896:  66%|██████▌   | 93/141 [02:24<01:16,  1.59s/it]avg_loss = 1.8465692616523581:  66%|██████▌   | 93/141 [02:26<01:16,  1.59s/it]avg_loss = 1.8465692616523581:  67%|██████▋   | 94/141 [02:26<01:14,  1.59s/it]avg_loss = 1.850423200506913:  67%|██████▋   | 94/141 [02:27<01:14,  1.59s/it] avg_loss = 1.850423200506913:  67%|██████▋   | 95/141 [02:27<01:13,  1.59s/it]avg_loss = 1.8512442049880822:  67%|██████▋   | 95/141 [02:29<01:13,  1.59s/it]avg_loss = 1.8512442049880822:  68%|██████▊   | 96/141 [02:29<01:11,  1.59s/it]avg_loss = 1.853148687746107:  68%|██████▊   | 96/141 [02:31<01:11,  1.59s/it] avg_loss = 1.853148687746107:  69%|██████▉   | 97/141 [02:31<01:09,  1.59s/it]avg_loss = 1.8482909993249543:  69%|██████▉   | 97/141 [02:32<01:09,  1.59s/it]avg_loss = 1.8482909993249543:  70%|██████▉   | 98/141 [02:32<01:08,  1.59s/it]avg_loss = 1.8490744937549939:  70%|██████▉   | 98/141 [02:34<01:08,  1.59s/it]avg_loss = 1.8490744937549939:  70%|███████   | 99/141 [02:34<01:06,  1.59s/it]avg_loss = 1.8508636617660523:  70%|███████   | 99/141 [02:35<01:06,  1.59s/it]avg_loss = 1.8508636617660523:  71%|███████   | 100/141 [02:35<01:05,  1.59s/it]avg_loss = 1.849392251212998:  71%|███████   | 100/141 [02:37<01:05,  1.59s/it] avg_loss = 1.849392251212998:  72%|███████▏  | 101/141 [02:37<01:03,  1.59s/it]avg_loss = 1.8494526615329818:  72%|███████▏  | 101/141 [02:39<01:03,  1.59s/it]avg_loss = 1.8494526615329818:  72%|███████▏  | 102/141 [02:39<01:01,  1.59s/it]avg_loss = 1.8474202017182286:  72%|███████▏  | 102/141 [02:40<01:01,  1.59s/it]avg_loss = 1.8474202017182286:  73%|███████▎  | 103/141 [02:40<01:00,  1.59s/it]avg_loss = 1.8498050960210652:  73%|███████▎  | 103/141 [02:42<01:00,  1.59s/it]avg_loss = 1.8498050960210652:  74%|███████▍  | 104/141 [02:42<00:58,  1.59s/it]avg_loss = 1.8478771822793143:  74%|███████▍  | 104/141 [02:43<00:58,  1.59s/it]avg_loss = 1.8478771822793143:  74%|███████▍  | 105/141 [02:43<00:57,  1.59s/it]avg_loss = 1.8465515881214503:  74%|███████▍  | 105/141 [02:45<00:57,  1.59s/it]avg_loss = 1.8465515881214503:  75%|███████▌  | 106/141 [02:45<00:55,  1.59s/it]avg_loss = 1.844238010522361:  75%|███████▌  | 106/141 [02:47<00:55,  1.59s/it] avg_loss = 1.844238010522361:  76%|███████▌  | 107/141 [02:47<00:54,  1.59s/it]avg_loss = 1.8418898438965832:  76%|███████▌  | 107/141 [02:48<00:54,  1.59s/it]avg_loss = 1.8418898438965832:  77%|███████▋  | 108/141 [02:48<00:52,  1.59s/it]avg_loss = 1.839269122946153:  77%|███████▋  | 108/141 [02:50<00:52,  1.59s/it] avg_loss = 1.839269122946153:  77%|███████▋  | 109/141 [02:50<00:50,  1.59s/it]avg_loss = 1.8369378024881535:  77%|███████▋  | 109/141 [02:51<00:50,  1.59s/it]avg_loss = 1.8369378024881535:  78%|███████▊  | 110/141 [02:51<00:49,  1.59s/it]avg_loss = 1.839514717325434:  78%|███████▊  | 110/141 [02:53<00:49,  1.59s/it] avg_loss = 1.839514717325434:  79%|███████▊  | 111/141 [02:53<00:47,  1.59s/it]avg_loss = 1.8392192465918404:  79%|███████▊  | 111/141 [02:54<00:47,  1.59s/it]avg_loss = 1.8392192465918404:  79%|███████▉  | 112/141 [02:54<00:46,  1.59s/it]avg_loss = 1.8403775597040632:  79%|███████▉  | 112/141 [02:56<00:46,  1.59s/it]avg_loss = 1.8403775597040632:  80%|████████  | 113/141 [02:56<00:44,  1.59s/it]avg_loss = 1.8413909109015214:  80%|████████  | 113/141 [02:58<00:44,  1.59s/it]avg_loss = 1.8413909109015214:  81%|████████  | 114/141 [02:58<00:42,  1.59s/it]avg_loss = 1.8407629562460859:  81%|████████  | 114/141 [02:59<00:42,  1.59s/it]avg_loss = 1.8407629562460859:  82%|████████▏ | 115/141 [02:59<00:41,  1.59s/it]avg_loss = 1.8392791244490394:  82%|████████▏ | 115/141 [03:01<00:41,  1.59s/it]avg_loss = 1.8392791244490394:  82%|████████▏ | 116/141 [03:01<00:39,  1.59s/it]avg_loss = 1.841365489185366:  82%|████████▏ | 116/141 [03:02<00:39,  1.59s/it] avg_loss = 1.841365489185366:  83%|████████▎ | 117/141 [03:02<00:38,  1.59s/it]avg_loss = 1.8410419205487785:  83%|████████▎ | 117/141 [03:04<00:38,  1.59s/it]avg_loss = 1.8410419205487785:  84%|████████▎ | 118/141 [03:04<00:36,  1.59s/it]avg_loss = 1.8396953143993346:  84%|████████▎ | 118/141 [03:06<00:36,  1.59s/it]avg_loss = 1.8396953143993346:  84%|████████▍ | 119/141 [03:06<00:34,  1.59s/it]avg_loss = 1.8380272726217906:  84%|████████▍ | 119/141 [03:07<00:34,  1.59s/it]avg_loss = 1.8380272726217906:  85%|████████▌ | 120/141 [03:07<00:33,  1.59s/it]avg_loss = 1.83786097932453:  85%|████████▌ | 120/141 [03:09<00:33,  1.59s/it]  avg_loss = 1.83786097932453:  86%|████████▌ | 121/141 [03:09<00:31,  1.60s/it]avg_loss = 1.8382737275029792:  86%|████████▌ | 121/141 [03:10<00:31,  1.60s/it]avg_loss = 1.8382737275029792:  87%|████████▋ | 122/141 [03:10<00:30,  1.60s/it]avg_loss = 1.8381576760997618:  87%|████████▋ | 122/141 [03:12<00:30,  1.60s/it]avg_loss = 1.8381576760997618:  87%|████████▋ | 123/141 [03:12<00:28,  1.60s/it]avg_loss = 1.8383475705500572:  87%|████████▋ | 123/141 [03:14<00:28,  1.60s/it]avg_loss = 1.8383475705500572:  88%|████████▊ | 124/141 [03:14<00:27,  1.60s/it]avg_loss = 1.8371592950820923:  88%|████████▊ | 124/141 [03:15<00:27,  1.60s/it]avg_loss = 1.8371592950820923:  89%|████████▊ | 125/141 [03:15<00:25,  1.60s/it]avg_loss = 1.8375903623444694:  89%|████████▊ | 125/141 [03:17<00:25,  1.60s/it]avg_loss = 1.8375903623444694:  89%|████████▉ | 126/141 [03:17<00:23,  1.60s/it]avg_loss = 1.8373283166585006:  89%|████████▉ | 126/141 [03:18<00:23,  1.60s/it]avg_loss = 1.8373283166585006:  90%|█████████ | 127/141 [03:18<00:22,  1.60s/it]avg_loss = 1.8360177334398031:  90%|█████████ | 127/141 [03:20<00:22,  1.60s/it]avg_loss = 1.8360177334398031:  91%|█████████ | 128/141 [03:20<00:20,  1.60s/it]avg_loss = 1.8361753428629202:  91%|█████████ | 128/141 [03:22<00:20,  1.60s/it]avg_loss = 1.8361753428629202:  91%|█████████▏| 129/141 [03:22<00:19,  1.60s/it]avg_loss = 1.8368950522862948:  91%|█████████▏| 129/141 [03:23<00:19,  1.60s/it]avg_loss = 1.8368950522862948:  92%|█████████▏| 130/141 [03:23<00:17,  1.59s/it]avg_loss = 1.8377857089952658:  92%|█████████▏| 130/141 [03:25<00:17,  1.59s/it]avg_loss = 1.8377857089952658:  93%|█████████▎| 131/141 [03:25<00:15,  1.59s/it]avg_loss = 1.838432151259798:  93%|█████████▎| 131/141 [03:26<00:15,  1.59s/it] avg_loss = 1.838432151259798:  94%|█████████▎| 132/141 [03:26<00:14,  1.59s/it]avg_loss = 1.8356832848455673:  94%|█████████▎| 132/141 [03:28<00:14,  1.59s/it]avg_loss = 1.8356832848455673:  94%|█████████▍| 133/141 [03:28<00:12,  1.59s/it]avg_loss = 1.8313343880781487:  94%|█████████▍| 133/141 [03:30<00:12,  1.59s/it]avg_loss = 1.8313343880781487:  95%|█████████▌| 134/141 [03:30<00:11,  1.59s/it]avg_loss = 1.8339127152054397:  95%|█████████▌| 134/141 [03:31<00:11,  1.59s/it]avg_loss = 1.8339127152054397:  96%|█████████▌| 135/141 [03:31<00:09,  1.59s/it]avg_loss = 1.8374541384332321:  96%|█████████▌| 135/141 [03:33<00:09,  1.59s/it]avg_loss = 1.8374541384332321:  96%|█████████▋| 136/141 [03:33<00:07,  1.59s/it]avg_loss = 1.8383837738176332:  96%|█████████▋| 136/141 [03:34<00:07,  1.59s/it]avg_loss = 1.8383837738176332:  97%|█████████▋| 137/141 [03:34<00:06,  1.59s/it]avg_loss = 1.837060208769812:  97%|█████████▋| 137/141 [03:36<00:06,  1.59s/it] avg_loss = 1.837060208769812:  98%|█████████▊| 138/141 [03:36<00:04,  1.59s/it]avg_loss = 1.8372809552460265:  98%|█████████▊| 138/141 [03:38<00:04,  1.59s/it]avg_loss = 1.8372809552460265:  99%|█████████▊| 139/141 [03:38<00:03,  1.59s/it]avg_loss = 1.8377292513847352:  99%|█████████▊| 139/141 [03:39<00:03,  1.59s/it]avg_loss = 1.8377292513847352:  99%|█████████▉| 140/141 [03:39<00:01,  1.59s/it]avg_loss = 1.8389913410159713:  99%|█████████▉| 140/141 [03:41<00:01,  1.59s/it]avg_loss = 1.8389913410159713: 100%|██████████| 141/141 [03:41<00:00,  1.59s/it]avg_loss = 1.8389913410159713: 100%|██████████| 141/141 [03:41<00:00,  1.57s/it]
I0403 03:26:04.824428 3336116 eval_ppl.py:107] wikitext2 perplexity: 6.29019021987915
wikitext2 perplexity: 6.290
