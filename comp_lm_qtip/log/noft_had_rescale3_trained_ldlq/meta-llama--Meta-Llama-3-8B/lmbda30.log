I0403 01:56:08.749823 3261899 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 01:56:08.749920 3261899 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 01:56:08.749963 3261899 utils.py:162] NumExpr defaulting to 16 threads.
I0403 01:56:09.089732 3261899 config.py:54] PyTorch version 2.6.0 available.
W0403 01:56:09.293675 3261899 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 01:56:09.944061 3261899 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.42it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  6.40it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  6.83it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.17it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.48it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.54it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.74it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.35it/s]
I0403 01:56:11.469084 3261899 quantize_finetune_llama.py:152] loaded model
I0403 01:56:11.875126 3261899 quantize_finetune_llama.py:190] loaded compression model
I0403 01:56:30.373379 3261899 quantize_finetune_llama.py:194] loaded dataset and devset
I0403 01:56:34.812459 3261899 quantize_finetune_llama.py:214] layer 0 gpu 0
I0403 01:56:38.449298 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 3.471141815185547s
Use train scale and shift
tensor(-1.5053e-07, device='cuda:0') tensor(0.0156, device='cuda:0')
tensor(0.0156, device='cuda:0') tensor(-1.5053e-07, device='cuda:0')
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0403 01:56:50.421548 3263148 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 01:56:50.421641 3263148 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 01:56:50.421681 3263148 utils.py:162] NumExpr defaulting to 16 threads.
I0403 01:56:50.753855 3263148 config.py:54] PyTorch version 2.6.0 available.
W0403 01:56:50.944229 3263148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 01:56:51.539086 3263148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 01:56:51.543019 3261899 quantize_finetune_llama.py:214] layer 1 gpu 1
I0403 01:56:51.921520 3263148 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 01:56:55.040164 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 3.301506519317627s
I0403 01:56:58.861437 3263472 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 01:56:58.861540 3263472 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 01:56:58.861581 3263472 utils.py:162] NumExpr defaulting to 16 threads.
I0403 01:56:59.233167 3263472 config.py:54] PyTorch version 2.6.0 available.
W0403 01:56:59.439840 3263472 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 01:57:00.022565 3263472 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 01:57:00.026377 3261899 quantize_finetune_llama.py:214] layer 2 gpu 0
I0403 01:57:00.253834 3263472 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.004497961141169071 err 0.2659502625465393 tr(WHW.T) 59.12685012817383
bpp_loss 4.233173165819608
0_q proxy err 2.5833549443632364e-05 err 7.441155433654785 tr(WHW.T) 288042.3125
bpp_loss 3.410929855541326
0_k proxy err 2.136336115654558e-05 err 2.1396076679229736 tr(WHW.T) 100153.140625
bpp_loss 4.548641307104845
0_o proxy err 0.0016709680203348398 err 5.203482627868652 tr(WHW.T) 3114.052734375
bpp_loss 3.0455579783883877
0_up proxy err 0.020911909639835358 err 185.28721618652344 tr(WHW.T) 8860.3681640625
bpp_loss 2.5805267125501166
0_gate proxy err 0.012291799299418926 err 192.99081420898438 tr(WHW.T) 15700.7783203125
bpp_loss 2.6521517211970473
0_down proxy err 0.010595032013952732 err 113.94355773925781 tr(WHW.T) 10754.4326171875
bpp_loss 2.97007108780755
1_v proxy err 0.010437645949423313 err 1.1123582124710083 tr(WHW.T) 106.5717544555664
bpp_loss 4.1945296240155585
1_q proxy err 6.326323637040332e-05 err 9.158636093139648 tr(WHW.T) 144770.28125
bpp_loss 3.549719317990821
1_k proxy err 3.700883826240897e-05 err 2.7945499420166016 tr(WHW.T) 75510.3359375
bpp_loss 4.740512890275568
1_o proxy err 0.0062982854433357716 err 12.420170783996582 tr(WHW.T) 1971.9923095703125
bpp_loss 2.9966336826910265
1_up proxy err 0.023938177153468132 err 195.4504852294922 tr(WHW.T) 8164.80224609375
bpp_loss 2.591128067046936
1_gate proxy err 0.014620468020439148 err 202.82359313964844 tr(WHW.T) 13872.5791015625
bpp_loss 2.6639662026427686
1_down proxy err 0.00023955055803526193 err 3.3327391147613525 tr(WHW.T) 13912.466796875
bpp_loss 3.053382905798831
I0403 01:59:15.128102 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 1.0742416381835938s
I0403 01:59:19.216239 3266283 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 01:59:19.216345 3266283 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 01:59:19.216387 3266283 utils.py:162] NumExpr defaulting to 16 threads.
I0403 01:59:19.615449 3266283 config.py:54] PyTorch version 2.6.0 available.
W0403 01:59:19.837049 3266283 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 01:59:20.489903 3266283 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 01:59:20.493813 3261899 quantize_finetune_llama.py:214] layer 3 gpu 1
I0403 01:59:20.808607 3266283 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 01:59:22.023061 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 1.0307350158691406s
I0403 01:59:25.949277 3266441 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 01:59:25.949384 3266441 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 01:59:25.949427 3266441 utils.py:162] NumExpr defaulting to 16 threads.
I0403 01:59:26.336235 3266441 config.py:54] PyTorch version 2.6.0 available.
W0403 01:59:26.555410 3266441 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 01:59:27.197072 3266441 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 01:59:27.201137 3261899 quantize_finetune_llama.py:214] layer 4 gpu 0
I0403 01:59:27.349340 3266441 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.006834226194769144 err 1.0538018941879272 tr(WHW.T) 154.19476318359375
bpp_loss 4.1990192357916385
2_q proxy err 0.0006863335147500038 err 28.430896759033203 tr(WHW.T) 41424.31640625
bpp_loss 3.421848773083184
2_k proxy err 0.0004052586737088859 err 9.152594566345215 tr(WHW.T) 22584.57421875
bpp_loss 4.596385827055201
2_o proxy err 0.006989716086536646 err 13.68094253540039 tr(WHW.T) 1957.2958984375
bpp_loss 2.962151922052726
2_up proxy err 0.028545698150992393 err 215.0942840576172 tr(WHW.T) 7535.0859375
bpp_loss 2.5778616602931703
2_gate proxy err 0.014976960606873035 err 225.08770751953125 tr(WHW.T) 15028.9306640625
bpp_loss 2.679925902879664
2_down proxy err 0.016679085791110992 err 127.77703857421875 tr(WHW.T) 7660.9140625
bpp_loss 2.9654917391349693
3_v proxy err 0.0053737410344183445 err 1.541426658630371 tr(WHW.T) 286.84423828125
bpp_loss 4.206864471605513
3_q proxy err 0.00103892816696316 err 49.37571716308594 tr(WHW.T) 47525.6328125
bpp_loss 3.310858299024403
3_k proxy err 0.0005906838923692703 err 15.443192481994629 tr(WHW.T) 26144.59765625
bpp_loss 4.368201283388771
3_o proxy err 0.009729365818202496 err 17.941497802734375 tr(WHW.T) 1844.0562744140625
bpp_loss 2.9646301318425685
3_up proxy err 0.02838728204369545 err 212.15216064453125 tr(WHW.T) 7473.4931640625
bpp_loss 2.5653022594217743
3_gate proxy err 0.01092853769659996 err 227.19602966308594 tr(WHW.T) 20789.244140625
bpp_loss 2.7380974564169134
3_down proxy err 0.017795074731111526 err 123.4244155883789 tr(WHW.T) 6935.875
bpp_loss 2.9602588322179924
I0403 02:01:47.124907 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 1.0151216983795166s
I0403 02:01:51.378501 3268808 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:01:51.378610 3268808 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:01:51.378652 3268808 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:01:51.781733 3268808 config.py:54] PyTorch version 2.6.0 available.
W0403 02:01:52.014561 3268808 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:01:52.672243 3268808 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:01:52.676583 3261899 quantize_finetune_llama.py:214] layer 5 gpu 1
I0403 02:01:52.876437 3268808 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:01:54.195030 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 1.0031940937042236s
I0403 02:01:58.461807 3268972 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:01:58.461920 3268972 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:01:58.461961 3268972 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:01:58.878612 3268972 config.py:54] PyTorch version 2.6.0 available.
W0403 02:01:59.137731 3268972 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:01:59.773217 3268972 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:01:59.777436 3261899 quantize_finetune_llama.py:214] layer 6 gpu 0
I0403 02:01:59.949323 3268972 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.006440537981688976 err 1.8188738822937012 tr(WHW.T) 282.4102478027344
bpp_loss 4.200859370583203
4_q proxy err 0.0008430270827375352 err 42.2060432434082 tr(WHW.T) 50064.87109375
bpp_loss 3.341328633192461
4_k proxy err 0.0004558123473543674 err 13.34301471710205 tr(WHW.T) 29273.04296875
bpp_loss 4.43495424115099
4_o proxy err 0.011570601724088192 err 14.851318359375 tr(WHW.T) 1283.5389404296875
bpp_loss 2.981852697324939
4_up proxy err 0.0288091991096735 err 210.98922729492188 tr(WHW.T) 7323.67578125
bpp_loss 2.551025007851422
4_gate proxy err 0.007990355603396893 err 231.9197540283203 tr(WHW.T) 29024.958984375
bpp_loss 2.7963000667680586
4_down proxy err 0.017598768696188927 err 111.5077133178711 tr(WHW.T) 6336.10888671875
bpp_loss 2.959621069021523
5_v proxy err 0.006080725230276585 err 1.2576889991760254 tr(WHW.T) 206.8320770263672
bpp_loss 4.200956834480166
5_q proxy err 0.0011573951924219728 err 41.599327087402344 tr(WHW.T) 35942.19921875
bpp_loss 3.343275251216255
5_k proxy err 0.0005788240814581513 err 13.294761657714844 tr(WHW.T) 22968.5703125
bpp_loss 4.446987230097875
5_o proxy err 0.011708845384418964 err 12.222302436828613 tr(WHW.T) 1043.85205078125
bpp_loss 2.976912089739926
5_up proxy err 0.027903515845537186 err 211.95289611816406 tr(WHW.T) 7595.9208984375
bpp_loss 2.555323234892317
5_gate proxy err 0.007666029501706362 err 232.13525390625 tr(WHW.T) 30281.02734375
bpp_loss 2.7973701341210733
5_down proxy err 0.017459701746702194 err 110.88634490966797 tr(WHW.T) 6350.9873046875
bpp_loss 2.9569220676120103
I0403 02:04:18.442327 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 1.037597894668579s
I0403 02:04:22.551995 3271164 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:04:22.552112 3271164 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:04:22.552161 3271164 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:04:22.966458 3271164 config.py:54] PyTorch version 2.6.0 available.
W0403 02:04:23.192343 3271164 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:04:23.911119 3271164 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:04:23.914909 3261899 quantize_finetune_llama.py:214] layer 7 gpu 1
I0403 02:04:24.207265 3271164 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:04:25.396516 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.9571363925933838s
I0403 02:04:29.414947 3271318 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:04:29.415049 3271318 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:04:29.415090 3271318 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:04:29.809169 3271318 config.py:54] PyTorch version 2.6.0 available.
W0403 02:04:30.038207 3271318 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:04:30.726503 3271318 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:04:30.730520 3261899 quantize_finetune_llama.py:214] layer 8 gpu 0
I0403 02:04:30.924866 3271318 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.005866175517439842 err 1.474026083946228 tr(WHW.T) 251.27548217773438
bpp_loss 4.199963972379919
6_q proxy err 0.0012960296589881182 err 46.12327575683594 tr(WHW.T) 35588.1328125
bpp_loss 3.3393322643241845
6_k proxy err 0.0005549935740418732 err 14.504512786865234 tr(WHW.T) 26134.55859375
bpp_loss 4.389952673343942
6_o proxy err 0.014675194397568703 err 14.62185287475586 tr(WHW.T) 996.3651733398438
bpp_loss 2.965813014889136
6_up proxy err 0.026335900649428368 err 207.08058166503906 tr(WHW.T) 7863.052734375
bpp_loss 2.559669703112117
6_gate proxy err 0.006372134201228619 err 227.111328125 tr(WHW.T) 35641.328125
bpp_loss 2.8077054721569374
6_down proxy err 0.016657041385769844 err 106.99614715576172 tr(WHW.T) 6423.478515625
bpp_loss 2.9573907575270693
7_v proxy err 0.004623051267117262 err 1.419777512550354 tr(WHW.T) 307.1083068847656
bpp_loss 4.201129363500513
7_q proxy err 0.001338120666332543 err 46.96494674682617 tr(WHW.T) 35097.69140625
bpp_loss 3.2749207540182397
7_k proxy err 0.0005630013765767217 err 15.100192070007324 tr(WHW.T) 26820.87890625
bpp_loss 4.367947233316954
7_o proxy err 0.01418399903923273 err 13.418013572692871 tr(WHW.T) 945.9965209960938
bpp_loss 2.9662561741424724
7_up proxy err 0.02399391122162342 err 205.51429748535156 tr(WHW.T) 8565.2685546875
bpp_loss 2.5721393367275596
7_gate proxy err 0.00639553414657712 err 222.5670623779297 tr(WHW.T) 34800.38671875
bpp_loss 2.7912260134305273
7_down proxy err 0.016802573576569557 err 108.75975799560547 tr(WHW.T) 6472.80322265625
bpp_loss 2.9589663769750456
I0403 02:06:47.164342 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 1.1181321144104004s
I0403 02:06:50.656903 3273956 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:06:50.656988 3273956 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:06:50.657027 3273956 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:06:51.000395 3273956 config.py:54] PyTorch version 2.6.0 available.
W0403 02:06:51.200048 3273956 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:06:51.775478 3273956 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:06:51.779231 3261899 quantize_finetune_llama.py:214] layer 9 gpu 1
I0403 02:06:51.942963 3273956 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:06:53.206245 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.9642159938812256s
I0403 02:06:56.727102 3274117 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:06:56.727185 3274117 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:06:56.727224 3274117 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:06:57.067693 3274117 config.py:54] PyTorch version 2.6.0 available.
W0403 02:06:57.262154 3274117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:06:57.822120 3274117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:06:57.825588 3261899 quantize_finetune_llama.py:214] layer 10 gpu 0
I0403 02:06:58.036468 3274117 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.006223838776350021 err 1.5879871845245361 tr(WHW.T) 255.14593505859375
bpp_loss 4.196709926996846
8_q proxy err 0.0017591264331713319 err 46.71076202392578 tr(WHW.T) 26553.384765625
bpp_loss 3.290242687857244
8_k proxy err 0.0006724765407852829 err 15.130457878112793 tr(WHW.T) 22499.607421875
bpp_loss 4.368388842500281
8_o proxy err 0.01822119578719139 err 13.335582733154297 tr(WHW.T) 731.8719482421875
bpp_loss 2.9646867302362807
8_up proxy err 0.024643950164318085 err 207.83282470703125 tr(WHW.T) 8433.421875
bpp_loss 2.5700161018009697
8_gate proxy err 0.006071032956242561 err 225.44180297851562 tr(WHW.T) 37134.01171875
bpp_loss 2.7979454867142652
8_down proxy err 0.01672150380909443 err 107.47571563720703 tr(WHW.T) 6427.3955078125
bpp_loss 2.9600376951275393
9_v proxy err 0.006259845104068518 err 2.1782591342926025 tr(WHW.T) 347.97332763671875
bpp_loss 4.193704431469087
9_q proxy err 0.0018998367013409734 err 48.64650344848633 tr(WHW.T) 25605.623046875
bpp_loss 3.2820494491024874
9_k proxy err 0.0007538024219684303 err 15.764707565307617 tr(WHW.T) 20913.580078125
bpp_loss 4.349573193117976
9_o proxy err 0.017577137798070908 err 13.373723030090332 tr(WHW.T) 760.8590087890625
bpp_loss 2.988789822033141
9_up proxy err 0.0233700443059206 err 208.1779327392578 tr(WHW.T) 8907.896484375
bpp_loss 2.575433969830296
9_gate proxy err 0.005748019088059664 err 225.94873046875 tr(WHW.T) 39308.97265625
bpp_loss 2.810309777967632
9_down proxy err 0.01710660196840763 err 106.25067138671875 tr(WHW.T) 6211.091796875
bpp_loss 2.9571169753825024
I0403 02:09:17.187630 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.9963202476501465s
I0403 02:09:21.111246 3276531 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:09:21.111339 3276531 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:09:21.111380 3276531 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:09:21.458796 3276531 config.py:54] PyTorch version 2.6.0 available.
W0403 02:09:21.666134 3276531 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:09:22.288428 3276531 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:09:22.292669 3261899 quantize_finetune_llama.py:214] layer 11 gpu 1
I0403 02:09:22.531150 3276531 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:09:23.785821 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 0.9986512660980225s
I0403 02:09:27.674652 3276738 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:09:27.674761 3276738 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:09:27.674806 3276738 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:09:28.058888 3276738 config.py:54] PyTorch version 2.6.0 available.
W0403 02:09:28.287530 3276738 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:09:28.932987 3276738 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:09:28.936960 3261899 quantize_finetune_llama.py:214] layer 12 gpu 0
I0403 02:09:29.139207 3276738 data_utils.py:336] using 256 training seqs, 128 validation seqs
10_v proxy err 0.006210289429873228 err 1.5485148429870605 tr(WHW.T) 249.34664916992188
bpp_loss 4.1936792964697815
10_q proxy err 0.0019246867159381509 err 44.82350540161133 tr(WHW.T) 23288.728515625
bpp_loss 3.3311270313570276
10_k proxy err 0.0007379119633696973 err 14.547407150268555 tr(WHW.T) 19714.28515625
bpp_loss 4.418222006526776
10_o proxy err 0.018694136291742325 err 12.473550796508789 tr(WHW.T) 667.2440185546875
bpp_loss 2.974497391784098
10_up proxy err 0.023086361587047577 err 210.8803253173828 tr(WHW.T) 9134.4111328125
bpp_loss 2.5853986595092073
10_gate proxy err 0.0060629285871982574 err 226.1335906982422 tr(WHW.T) 37297.75
bpp_loss 2.783219710591116
10_down proxy err 0.017034148797392845 err 110.06826782226562 tr(WHW.T) 6461.62451171875
bpp_loss 2.9575998754340356
11_v proxy err 0.004888456780463457 err 1.5502854585647583 tr(WHW.T) 317.1318664550781
bpp_loss 4.19827810744755
11_q proxy err 0.002136364346370101 err 47.313045501708984 tr(WHW.T) 22146.5234375
bpp_loss 3.2475722420495003
11_k proxy err 0.0008649120572954416 err 15.56714153289795 tr(WHW.T) 17998.525390625
bpp_loss 4.355184433690738
11_o proxy err 0.019628116860985756 err 10.833471298217773 tr(WHW.T) 551.9363403320312
bpp_loss 2.98653998906957
11_up proxy err 0.02259044535458088 err 206.1824951171875 tr(WHW.T) 9126.9775390625
bpp_loss 2.594597977918706
11_gate proxy err 0.005997294560074806 err 220.61036682128906 tr(WHW.T) 36784.98046875
bpp_loss 2.7734087677007273
11_down proxy err 0.01685551553964615 err 111.09947967529297 tr(WHW.T) 6591.28369140625
bpp_loss 2.957364968107348
I0403 02:11:45.324520 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 0.9067635536193848s
I0403 02:11:49.228864 3279042 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:11:49.228976 3279042 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:11:49.229018 3279042 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:11:49.632720 3279042 config.py:54] PyTorch version 2.6.0 available.
W0403 02:11:49.891946 3279042 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:11:50.683566 3279042 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:11:50.688181 3261899 quantize_finetune_llama.py:214] layer 13 gpu 1
I0403 02:11:50.842536 3279042 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:11:52.320485 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 1.1017274856567383s
I0403 02:11:56.453263 3279264 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:11:56.453356 3279264 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:11:56.453397 3279264 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:11:56.837116 3279264 config.py:54] PyTorch version 2.6.0 available.
W0403 02:11:57.051301 3279264 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:11:57.668227 3279264 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:11:57.672303 3261899 quantize_finetune_llama.py:214] layer 14 gpu 0
I0403 02:11:58.002973 3279264 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.005953316111117601 err 2.1445133686065674 tr(WHW.T) 360.2216491699219
bpp_loss 4.197327448986471
12_q proxy err 0.0014772305730730295 err 50.31014633178711 tr(WHW.T) 34057.0703125
bpp_loss 3.241223189397715
12_k proxy err 0.0006899794680066407 err 15.889904975891113 tr(WHW.T) 23029.533203125
bpp_loss 4.294022386660799
12_o proxy err 0.018023565411567688 err 13.77234935760498 tr(WHW.T) 764.130126953125
bpp_loss 2.9712215726613067
12_up proxy err 0.02023972198367119 err 201.56607055664062 tr(WHW.T) 9958.9345703125
bpp_loss 2.615680414118937
12_gate proxy err 0.005768873728811741 err 214.81716918945312 tr(WHW.T) 37237.28125
bpp_loss 2.765229091779994
12_down proxy err 0.01652190275490284 err 111.6240463256836 tr(WHW.T) 6756.125
bpp_loss 2.9610197723876417
13_v proxy err 0.006640406791120768 err 1.8410484790802002 tr(WHW.T) 277.2493591308594
bpp_loss 4.197588169015944
13_q proxy err 0.0022722934372723103 err 47.3791389465332 tr(WHW.T) 20850.80078125
bpp_loss 3.2799545967718586
13_k proxy err 0.0008865642012096941 err 15.75363826751709 tr(WHW.T) 17769.314453125
bpp_loss 4.3637056282605045
13_o proxy err 0.01870669238269329 err 12.351876258850098 tr(WHW.T) 660.2918090820312
bpp_loss 2.978914766339585
13_up proxy err 0.01977641135454178 err 196.61068725585938 tr(WHW.T) 9941.6767578125
bpp_loss 2.618406326310443
13_gate proxy err 0.0054214755073189735 err 210.4833984375 tr(WHW.T) 38824.0078125
bpp_loss 2.7662289636209607
13_down proxy err 0.016937296837568283 err 109.99019622802734 tr(WHW.T) 6493.9638671875
bpp_loss 2.959402038765672
I0403 02:14:17.563748 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 1.3913075923919678s
I0403 02:14:21.883712 3281548 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:14:21.883846 3281548 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:14:21.883898 3281548 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:14:22.275171 3281548 config.py:54] PyTorch version 2.6.0 available.
W0403 02:14:22.491667 3281548 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:14:23.140537 3281548 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:14:23.144903 3261899 quantize_finetune_llama.py:214] layer 15 gpu 1
I0403 02:14:23.614896 3281548 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:14:24.878190 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 1.1057298183441162s
I0403 02:14:29.163885 3281686 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:14:29.164000 3281686 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:14:29.164047 3281686 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:14:29.613719 3281686 config.py:54] PyTorch version 2.6.0 available.
W0403 02:14:29.853935 3281686 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:14:30.801963 3281686 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:14:30.806108 3261899 quantize_finetune_llama.py:214] layer 16 gpu 0
I0403 02:14:31.135837 3281686 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.006409640423953533 err 1.7850322723388672 tr(WHW.T) 278.4917907714844
bpp_loss 4.197354331437964
14_q proxy err 0.0020869257859885693 err 43.48575973510742 tr(WHW.T) 20837.234375
bpp_loss 3.275201121054124
14_k proxy err 0.0007850844413042068 err 14.594924926757812 tr(WHW.T) 18590.26171875
bpp_loss 4.39271807752084
14_o proxy err 0.018294112756848335 err 12.284863471984863 tr(WHW.T) 671.5200805664062
bpp_loss 2.9729631380178034
14_up proxy err 0.021189652383327484 err 192.74537658691406 tr(WHW.T) 9096.203125
bpp_loss 2.6194802524654994
14_gate proxy err 0.005044816993176937 err 210.2864227294922 tr(WHW.T) 41683.65625
bpp_loss 2.790174737439624
14_down proxy err 0.01773885451257229 err 112.19242095947266 tr(WHW.T) 6324.6708984375
bpp_loss 2.964419217746971
15_v proxy err 0.007661773823201656 err 2.150282621383667 tr(WHW.T) 280.6507568359375
bpp_loss 4.198389993747696
15_q proxy err 0.0018228890839964151 err 51.0860595703125 tr(WHW.T) 28024.77734375
bpp_loss 3.363662709656637
15_k proxy err 0.000841691333334893 err 15.860372543334961 tr(WHW.T) 18843.455078125
bpp_loss 4.326841115485877
15_o proxy err 0.01773807778954506 err 14.404260635375977 tr(WHW.T) 812.0530395507812
bpp_loss 2.9945940462639555
15_up proxy err 0.02166043035686016 err 193.37513732910156 tr(WHW.T) 8927.576171875
bpp_loss 2.610378566264574
15_gate proxy err 0.0046199895441532135 err 213.0303497314453 tr(WHW.T) 46110.5703125
bpp_loss 2.8143943291423574
15_down proxy err 0.01742606796324253 err 110.37370300292969 tr(WHW.T) 6333.8271484375
bpp_loss 2.962803644676959
I0403 02:16:47.600639 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.8528931140899658s
I0403 02:16:51.757287 3283824 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:16:51.757575 3283824 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:16:51.757616 3283824 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:16:52.143582 3283824 config.py:54] PyTorch version 2.6.0 available.
W0403 02:16:52.359052 3283824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:16:53.001862 3283824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:16:53.005800 3261899 quantize_finetune_llama.py:214] layer 17 gpu 1
I0403 02:16:53.253092 3283824 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:16:54.559718 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 1.0775511264801025s
I0403 02:16:58.603075 3283981 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:16:58.603176 3283981 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:16:58.603219 3283981 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:16:58.991425 3283981 config.py:54] PyTorch version 2.6.0 available.
W0403 02:16:59.211828 3283981 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:16:59.881476 3283981 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:16:59.889304 3261899 quantize_finetune_llama.py:214] layer 18 gpu 0
I0403 02:17:00.180941 3283981 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.006939284969121218 err 1.8827406167984009 tr(WHW.T) 271.31622314453125
bpp_loss 4.200586087128613
16_q proxy err 0.001816018600948155 err 44.3759765625 tr(WHW.T) 24435.859375
bpp_loss 3.3568181166774593
16_k proxy err 0.0007328348001465201 err 14.273957252502441 tr(WHW.T) 19477.728515625
bpp_loss 4.406434949836694
16_o proxy err 0.01551985926926136 err 14.805232048034668 tr(WHW.T) 953.9540405273438
bpp_loss 2.979675169393886
16_up proxy err 0.02464953251183033 err 203.7536163330078 tr(WHW.T) 8266.0234375
bpp_loss 2.5917397861235907
16_gate proxy err 0.005494452081620693 err 225.6222686767578 tr(WHW.T) 41063.65234375
bpp_loss 2.8347691491113176
16_down proxy err 0.018202273175120354 err 113.2991714477539 tr(WHW.T) 6224.45166015625
bpp_loss 2.9596930567973425
17_v proxy err 0.008340146392583847 err 2.3384621143341064 tr(WHW.T) 280.38623046875
bpp_loss 4.198715978709515
17_q proxy err 0.0018253667512908578 err 50.233543395996094 tr(WHW.T) 27519.69921875
bpp_loss 3.3381581691792235
17_k proxy err 0.0009279340738430619 err 16.1468505859375 tr(WHW.T) 17400.859375
bpp_loss 4.344431988836732
17_o proxy err 0.014721190556883812 err 16.052701950073242 tr(WHW.T) 1090.4486083984375
bpp_loss 2.998840880347416
17_up proxy err 0.024394668638706207 err 204.6203155517578 tr(WHW.T) 8387.9111328125
bpp_loss 2.58557182084769
17_gate proxy err 0.005458000116050243 err 227.06802368164062 tr(WHW.T) 41602.7890625
bpp_loss 2.8438538503167883
17_down proxy err 0.018352126702666283 err 112.84163665771484 tr(WHW.T) 6148.6953125
bpp_loss 2.9584120048841993
I0403 02:19:19.870182 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.9626891613006592s
I0403 02:19:23.924332 3286286 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:19:23.924441 3286286 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:19:23.924482 3286286 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:19:24.355778 3286286 config.py:54] PyTorch version 2.6.0 available.
W0403 02:19:24.600673 3286286 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:19:25.265548 3286286 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:19:25.269571 3261899 quantize_finetune_llama.py:214] layer 19 gpu 1
I0403 02:19:26.155239 3286286 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:19:26.838237 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 1.0709691047668457s
I0403 02:19:30.817347 3286469 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:19:30.817451 3286469 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:19:30.817493 3286469 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:19:31.210921 3286469 config.py:54] PyTorch version 2.6.0 available.
W0403 02:19:31.434981 3286469 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:19:32.071306 3286469 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:19:32.075556 3261899 quantize_finetune_llama.py:214] layer 20 gpu 0
I0403 02:19:32.249223 3286469 data_utils.py:336] using 256 training seqs, 128 validation seqs
18_v proxy err 0.0066126370802521706 err 1.8826171159744263 tr(WHW.T) 284.69989013671875
bpp_loss 4.2030283493804745
18_q proxy err 0.002271920209750533 err 50.77627182006836 tr(WHW.T) 22349.49609375
bpp_loss 3.3123356418218464
18_k proxy err 0.0009692749008536339 err 16.830869674682617 tr(WHW.T) 17364.392578125
bpp_loss 4.353840071707964
18_o proxy err 0.015216544270515442 err 18.074094772338867 tr(WHW.T) 1187.7923583984375
bpp_loss 2.9880477630649693
18_up proxy err 0.027041740715503693 err 214.14193725585938 tr(WHW.T) 7918.9404296875
bpp_loss 2.5745004922417656
18_gate proxy err 0.0067390743643045425 err 236.7321014404297 tr(WHW.T) 35128.28125
bpp_loss 2.8422763992234
18_down proxy err 0.01901780068874359 err 117.21376037597656 tr(WHW.T) 6163.37109375
bpp_loss 2.956577983801253
19_v proxy err 0.006358040031045675 err 2.1476845741271973 tr(WHW.T) 337.79034423828125
bpp_loss 4.20547560864361
19_q proxy err 0.0021853221114724874 err 52.42118835449219 tr(WHW.T) 23987.85546875
bpp_loss 3.305316225218121
19_k proxy err 0.0010732471710070968 err 16.662378311157227 tr(WHW.T) 15525.201171875
bpp_loss 4.30082277971087
19_o proxy err 0.01701468788087368 err 19.619617462158203 tr(WHW.T) 1153.098876953125
bpp_loss 2.9810307407169603
19_up proxy err 0.028709545731544495 err 217.78646850585938 tr(WHW.T) 7585.85546875
bpp_loss 2.5694456244818866
19_gate proxy err 0.007369895000010729 err 240.96102905273438 tr(WHW.T) 32695.314453125
bpp_loss 2.8482305124801184
19_down proxy err 0.019452562555670738 err 119.04595184326172 tr(WHW.T) 6119.80810546875
bpp_loss 2.956741746681343
I0403 02:21:56.341104 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.1116557121276855s
I0403 02:22:00.303172 3288716 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:22:00.303288 3288716 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:22:00.303333 3288716 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:22:00.654172 3288716 config.py:54] PyTorch version 2.6.0 available.
W0403 02:22:00.861661 3288716 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:22:01.477823 3288716 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:22:01.482034 3261899 quantize_finetune_llama.py:214] layer 21 gpu 1
I0403 02:22:01.688833 3288716 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:22:02.994559 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.9833743572235107s
I0403 02:22:07.255770 3288937 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:22:07.255901 3288937 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:22:07.255947 3288937 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:22:07.693501 3288937 config.py:54] PyTorch version 2.6.0 available.
W0403 02:22:07.930043 3288937 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:22:08.661473 3288937 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:22:08.665790 3261899 quantize_finetune_llama.py:214] layer 22 gpu 0
I0403 02:22:08.879181 3288937 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.007330345921218395 err 2.39402174949646 tr(WHW.T) 326.5905456542969
bpp_loss 4.201890828553587
20_q proxy err 0.0024002136196941137 err 49.65730667114258 tr(WHW.T) 20688.703125
bpp_loss 3.31139970314689
20_k proxy err 0.0010432222625240684 err 16.032752990722656 tr(WHW.T) 15368.4912109375
bpp_loss 4.30826849618461
20_o proxy err 0.016927791759371758 err 20.1383056640625 tr(WHW.T) 1189.6593017578125
bpp_loss 2.979596466408111
20_up proxy err 0.0292157381772995 err 220.16380310058594 tr(WHW.T) 7535.79443359375
bpp_loss 2.5706676302610765
20_gate proxy err 0.007963314652442932 err 243.2662353515625 tr(WHW.T) 30548.365234375
bpp_loss 2.8470297126498605
20_down proxy err 0.01942742057144642 err 121.17802429199219 tr(WHW.T) 6237.4736328125
bpp_loss 2.9558601340478554
21_v proxy err 0.0070990901440382 err 2.5488016605377197 tr(WHW.T) 359.03216552734375
bpp_loss 4.2042346661910415
21_q proxy err 0.0019581043161451817 err 50.49995040893555 tr(WHW.T) 25790.224609375
bpp_loss 3.287991578807123
21_k proxy err 0.0009710058220662177 err 16.273826599121094 tr(WHW.T) 16759.76171875
bpp_loss 4.310745871858671
21_o proxy err 0.012802917510271072 err 16.009300231933594 tr(WHW.T) 1250.4415283203125
bpp_loss 3.0152083938010037
21_up proxy err 0.028040042147040367 err 216.14178466796875 tr(WHW.T) 7708.326171875
bpp_loss 2.5737795783872053
21_gate proxy err 0.007609395310282707 err 239.29884338378906 tr(WHW.T) 31447.8125
bpp_loss 2.8571910629980266
21_down proxy err 0.018932433798909187 err 119.04167175292969 tr(WHW.T) 6287.7109375
bpp_loss 2.956427024444565
I0403 02:24:38.427548 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 1.1692633628845215s
I0403 02:24:42.654456 3291224 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:24:42.654560 3291224 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:24:42.654607 3291224 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:24:43.077975 3291224 config.py:54] PyTorch version 2.6.0 available.
W0403 02:24:43.294504 3291224 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:24:44.006789 3291224 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:24:44.010818 3261899 quantize_finetune_llama.py:214] layer 23 gpu 1
I0403 02:24:44.297864 3291224 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:24:45.343789 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 0.8663358688354492s
I0403 02:24:49.868799 3291449 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:24:49.868940 3291449 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:24:49.868987 3291449 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:24:50.289438 3291449 config.py:54] PyTorch version 2.6.0 available.
W0403 02:24:50.510647 3291449 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:24:51.224002 3291449 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:24:51.228173 3261899 quantize_finetune_llama.py:214] layer 24 gpu 0
I0403 02:24:51.489670 3291449 data_utils.py:336] using 256 training seqs, 128 validation seqs
22_v proxy err 0.008094297721982002 err 2.76680326461792 tr(WHW.T) 341.8212890625
bpp_loss 4.198200521117542
22_q proxy err 0.0022965427488088608 err 46.560516357421875 tr(WHW.T) 20274.177734375
bpp_loss 3.2772375185159035
22_k proxy err 0.0010342225432395935 err 15.200518608093262 tr(WHW.T) 14697.5322265625
bpp_loss 4.315159635676537
22_o proxy err 0.019090685993433 err 23.004682540893555 tr(WHW.T) 1205.021240234375
bpp_loss 2.967431244906038
22_up proxy err 0.02933315560221672 err 219.48841857910156 tr(WHW.T) 7482.60498046875
bpp_loss 2.5737385365978946
22_gate proxy err 0.008215907961130142 err 241.67539978027344 tr(WHW.T) 29415.544921875
bpp_loss 2.856815604759114
22_down proxy err 0.018808672204613686 err 121.60382080078125 tr(WHW.T) 6465.3056640625
bpp_loss 2.956181215005927
23_v proxy err 0.007845472544431686 err 3.0847158432006836 tr(WHW.T) 393.1842041015625
bpp_loss 4.1981058365199715
23_q proxy err 0.0022590341977775097 err 50.970829010009766 tr(WHW.T) 22563.107421875
bpp_loss 3.252261397021357
23_k proxy err 0.0010970301227644086 err 16.270158767700195 tr(WHW.T) 14831.095703125
bpp_loss 4.263681931653991
23_o proxy err 0.015589449554681778 err 26.923206329345703 tr(WHW.T) 1727.0145263671875
bpp_loss 2.9687623173813336
23_up proxy err 0.029873434454202652 err 219.6905975341797 tr(WHW.T) 7354.04541015625
bpp_loss 2.5761607424356043
23_gate proxy err 0.008875296451151371 err 241.16590881347656 tr(WHW.T) 27172.716796875
bpp_loss 2.859209625915225
23_down proxy err 0.01914161443710327 err 126.37793731689453 tr(WHW.T) 6602.26123046875
bpp_loss 2.955525264692759
I0403 02:27:19.834634 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.8186283111572266s
I0403 02:27:23.263978 3293904 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:27:23.264062 3293904 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:27:23.264101 3293904 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:27:23.584545 3293904 config.py:54] PyTorch version 2.6.0 available.
W0403 02:27:23.771193 3293904 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:27:24.335374 3293904 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:27:24.339011 3261899 quantize_finetune_llama.py:214] layer 25 gpu 1
I0403 02:27:24.568639 3293904 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:27:25.863195 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 1.0330121517181396s
I0403 02:27:29.356435 3294050 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:27:29.356523 3294050 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:27:29.356564 3294050 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:27:29.688221 3294050 config.py:54] PyTorch version 2.6.0 available.
W0403 02:27:29.883558 3294050 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:27:30.472421 3294050 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:27:30.476179 3261899 quantize_finetune_llama.py:214] layer 26 gpu 0
I0403 02:27:30.678107 3294050 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.008025145158171654 err 3.704329013824463 tr(WHW.T) 461.59027099609375
bpp_loss 4.199781849398278
24_q proxy err 0.0022029003594070673 err 49.326847076416016 tr(WHW.T) 22391.7734375
bpp_loss 3.239942203857936
24_k proxy err 0.0010677473619580269 err 15.118823051452637 tr(WHW.T) 14159.55078125
bpp_loss 4.232380881498102
24_o proxy err 0.01662871241569519 err 26.11353874206543 tr(WHW.T) 1570.388427734375
bpp_loss 2.9874759406084195
24_up proxy err 0.030688786879181862 err 222.3527069091797 tr(WHW.T) 7245.40576171875
bpp_loss 2.5784121939380253
24_gate proxy err 0.009462961927056313 err 243.7406463623047 tr(WHW.T) 25757.33203125
bpp_loss 2.8637006246218726
24_down proxy err 0.01954391412436962 err 130.4864959716797 tr(WHW.T) 6676.57958984375
bpp_loss 2.953920789827992
25_v proxy err 0.006830442231148481 err 3.7707159519195557 tr(WHW.T) 552.045654296875
bpp_loss 4.200860071112402
25_q proxy err 0.0019455141155049205 err 50.717803955078125 tr(WHW.T) 26069.1015625
bpp_loss 3.2087842318578623
25_k proxy err 0.0010609317105263472 err 15.269983291625977 tr(WHW.T) 14392.994140625
bpp_loss 4.226402900647372
25_o proxy err 0.013593621551990509 err 26.795639038085938 tr(WHW.T) 1971.1920166015625
bpp_loss 2.9937060595839284
25_up proxy err 0.030401574447751045 err 222.39706420898438 tr(WHW.T) 7315.31396484375
bpp_loss 2.5855495745449195
25_gate proxy err 0.009303594008088112 err 243.62197875976562 tr(WHW.T) 26185.79296875
bpp_loss 2.8728541125809506
25_down proxy err 0.020512819290161133 err 134.3480224609375 tr(WHW.T) 6549.46630859375
bpp_loss 2.9537299052878683
I0403 02:29:37.251012 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.8960878849029541s
I0403 02:29:40.714213 3295547 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:29:40.714308 3295547 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:29:40.714349 3295547 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:29:41.046515 3295547 config.py:54] PyTorch version 2.6.0 available.
W0403 02:29:41.234949 3295547 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:29:41.776661 3295547 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:29:41.780184 3261899 quantize_finetune_llama.py:214] layer 27 gpu 1
I0403 02:29:41.998106 3295547 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:29:43.042523 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.8415729999542236s
I0403 02:29:46.584840 3295673 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:29:46.584937 3295673 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:29:46.584975 3295673 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:29:46.914858 3295673 config.py:54] PyTorch version 2.6.0 available.
W0403 02:29:47.105647 3295673 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:29:47.667760 3295673 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:29:47.671323 3261899 quantize_finetune_llama.py:214] layer 28 gpu 0
I0403 02:29:47.904160 3295673 data_utils.py:336] using 256 training seqs, 128 validation seqs
26_v proxy err 0.00976650696247816 err 4.1818437576293945 tr(WHW.T) 428.18212890625
bpp_loss 4.195065997540951
26_q proxy err 0.002239099470898509 err 47.82657241821289 tr(WHW.T) 21359.736328125
bpp_loss 3.239000394649338
26_k proxy err 0.0009927158243954182 err 15.288180351257324 tr(WHW.T) 15400.359375
bpp_loss 4.266991644399241
26_o proxy err 0.00983926746994257 err 23.305679321289062 tr(WHW.T) 2368.6396484375
bpp_loss 3.0206669987528585
26_up proxy err 0.029397910460829735 err 222.76806640625 tr(WHW.T) 7577.68359375
bpp_loss 2.5922614973969758
26_gate proxy err 0.008482622914016247 err 244.11376953125 tr(WHW.T) 28778.099609375
bpp_loss 2.8812951428283538
26_down proxy err 0.020779279991984367 err 136.12953186035156 tr(WHW.T) 6551.21533203125
bpp_loss 2.9546784854693606
27_v proxy err 0.0071578677743673325 err 4.798226833343506 tr(WHW.T) 670.343017578125
bpp_loss 4.200787389709149
27_q proxy err 0.0023724001366645098 err 50.44635772705078 tr(WHW.T) 21263.849609375
bpp_loss 3.199375974771101
27_k proxy err 0.001119190244935453 err 15.65407657623291 tr(WHW.T) 13986.966796875
bpp_loss 4.227445267431904
27_o proxy err 0.011392448097467422 err 24.365976333618164 tr(WHW.T) 2138.783203125
bpp_loss 3.0165948215289973
27_up proxy err 0.02686850167810917 err 225.85305786132812 tr(WHW.T) 8405.8671875
bpp_loss 2.6002389676203683
27_gate proxy err 0.007553889416158199 err 246.88870239257812 tr(WHW.T) 32683.65234375
bpp_loss 2.889581339101174
27_down proxy err 0.019285980612039566 err 124.86174774169922 tr(WHW.T) 6474.22314453125
bpp_loss 2.9713121614685014
I0403 02:31:49.707481 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 0.8010213375091553s
I0403 02:31:53.139851 3297020 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:31:53.139948 3297020 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:31:53.139986 3297020 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:31:53.466588 3297020 config.py:54] PyTorch version 2.6.0 available.
W0403 02:31:53.653614 3297020 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:31:54.190209 3297020 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:31:54.193809 3261899 quantize_finetune_llama.py:214] layer 29 gpu 1
I0403 02:31:54.363540 3297020 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:31:55.431107 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 0.8466894626617432s
I0403 02:31:58.905668 3297142 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:31:58.905755 3297142 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:31:58.905793 3297142 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:31:59.232426 3297142 config.py:54] PyTorch version 2.6.0 available.
W0403 02:31:59.422228 3297142 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:31:59.998719 3297142 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:32:00.002314 3261899 quantize_finetune_llama.py:214] layer 30 gpu 0
I0403 02:32:00.199744 3297142 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.008684198372066021 err 5.154622554779053 tr(WHW.T) 593.5634155273438
bpp_loss 4.197315642610192
28_q proxy err 0.0021774652414023876 err 50.34679412841797 tr(WHW.T) 23121.744140625
bpp_loss 3.1979588747490197
28_k proxy err 0.0009627959807403386 err 14.414839744567871 tr(WHW.T) 14971.8525390625
bpp_loss 4.213358176872134
28_o proxy err 0.01013774424791336 err 25.234159469604492 tr(WHW.T) 2489.129638671875
bpp_loss 3.0401436205138452
28_up proxy err 0.021684052422642708 err 220.60040283203125 tr(WHW.T) 10173.3935546875
bpp_loss 2.6202624276546493
28_gate proxy err 0.006696907337754965 err 239.72947692871094 tr(WHW.T) 35797.04296875
bpp_loss 2.88484517105722
28_down proxy err 0.017102761194109917 err 122.08907318115234 tr(WHW.T) 7138.55908203125
bpp_loss 2.991557593357616
29_v proxy err 0.00651263352483511 err 5.48239278793335 tr(WHW.T) 841.8088989257812
bpp_loss 4.202576195762958
29_q proxy err 0.002652796683833003 err 54.678279876708984 tr(WHW.T) 20611.560546875
bpp_loss 3.141697892860975
29_k proxy err 0.0009371881606057286 err 15.314849853515625 tr(WHW.T) 16341.275390625
bpp_loss 4.220722687605303
29_o proxy err 0.006539153400808573 err 20.1339111328125 tr(WHW.T) 3078.978271484375
bpp_loss 3.101027946395334
29_up proxy err 0.016914278268814087 err 216.36302185058594 tr(WHW.T) 12791.73828125
bpp_loss 2.6424343642512604
29_gate proxy err 0.006087854504585266 err 232.8070526123047 tr(WHW.T) 38241.23046875
bpp_loss 2.8816012624385103
29_down proxy err 0.014068386517465115 err 104.05504608154297 tr(WHW.T) 7396.3740234375
bpp_loss 3.034913302066603
I0403 02:34:06.271638 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 0.561492919921875s
I0403 02:34:09.914175 3298522 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:34:09.914274 3298522 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:34:09.914315 3298522 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:34:10.280210 3298522 config.py:54] PyTorch version 2.6.0 available.
W0403 02:34:10.495060 3298522 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:34:11.133922 3298522 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:34:11.137733 3261899 quantize_finetune_llama.py:214] layer 31 gpu 1
I0403 02:34:11.292600 3298522 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 02:34:12.537499 3261899 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 0.8961563110351562s
I0403 02:34:16.518001 3298653 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:34:16.518098 3298653 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:34:16.518139 3298653 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:34:16.912985 3298653 config.py:54] PyTorch version 2.6.0 available.
W0403 02:34:17.172337 3298653 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 02:34:17.820571 3298653 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 02:34:18.149693 3298653 data_utils.py:336] using 256 training seqs, 128 validation seqs
30_v proxy err 0.008950571529567242 err 7.613809108734131 tr(WHW.T) 850.650634765625
bpp_loss 4.198313381348271
30_q proxy err 0.001940618036314845 err 46.59960174560547 tr(WHW.T) 24012.763671875
bpp_loss 3.1362314746365882
30_k proxy err 0.0007891408749856055 err 11.057232856750488 tr(WHW.T) 14011.7353515625
bpp_loss 4.214983343146741
30_o proxy err 0.005683699157088995 err 27.519607543945312 tr(WHW.T) 4841.84814453125
bpp_loss 3.0555895809666254
30_up proxy err 0.009983896277844906 err 215.95657348632812 tr(WHW.T) 21630.490234375
bpp_loss 2.6597713351116647
30_gate proxy err 0.0044954982586205006 err 232.96714782714844 tr(WHW.T) 51822.3203125
bpp_loss 2.9211447038687766
30_down proxy err 0.007169958204030991 err 62.629268646240234 tr(WHW.T) 8734.9560546875
bpp_loss 3.1092988556151147
31_v proxy err 0.00308337458409369 err 5.546645641326904 tr(WHW.T) 1798.8880615234375
bpp_loss 4.213130045682192
31_q proxy err 0.0011194089893251657 err 51.6382942199707 tr(WHW.T) 46129.9609375
bpp_loss 3.1770935682579875
31_k proxy err 0.0005901354015804827 err 12.065488815307617 tr(WHW.T) 20445.2890625
bpp_loss 4.231451510335319
31_o proxy err 0.0038208886981010437 err 8.356088638305664 tr(WHW.T) 2186.948974609375
bpp_loss 3.1978820539079607
31_up proxy err 0.003060781629756093 err 210.92083740234375 tr(WHW.T) 68910.7734375
bpp_loss 2.8023404169029424
31_gate proxy err 0.0015763238770887256 err 227.43344116210938 tr(WHW.T) 144280.90625
bpp_loss 3.0964121903026744
31_down proxy err 0.001751335454173386 err 17.303314208984375 tr(WHW.T) 9880.068359375
bpp_loss 3.2148557523697883
I0403 02:36:45.798113 3300313 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:36:45.798212 3300313 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:36:45.798254 3300313 utils.py:162] NumExpr defaulting to 16 threads.
I0403 02:36:46.125419 3300313 config.py:54] PyTorch version 2.6.0 available.
W0403 02:36:46.340664 3300313 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:36:46.455122 3300313 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.12it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.67it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.89it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  9.00it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  9.05it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  9.11it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.25it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.05it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.73it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.87it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.86it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.77it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.92it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.84it/s]
I0403 02:36:49.878636 3300313 hfize_llama.py:161] loaded layer 0
I0403 02:36:50.633434 3300313 hfize_llama.py:161] loaded layer 1
I0403 02:36:51.310301 3300313 hfize_llama.py:161] loaded layer 2
I0403 02:36:52.034626 3300313 hfize_llama.py:161] loaded layer 3
I0403 02:36:52.878022 3300313 hfize_llama.py:161] loaded layer 4
I0403 02:36:53.557468 3300313 hfize_llama.py:161] loaded layer 5
I0403 02:36:54.271215 3300313 hfize_llama.py:161] loaded layer 6
I0403 02:36:54.947251 3300313 hfize_llama.py:161] loaded layer 7
I0403 02:36:55.640461 3300313 hfize_llama.py:161] loaded layer 8
I0403 02:36:56.341750 3300313 hfize_llama.py:161] loaded layer 9
I0403 02:36:57.100319 3300313 hfize_llama.py:161] loaded layer 10
I0403 02:36:57.789393 3300313 hfize_llama.py:161] loaded layer 11
I0403 02:36:58.488863 3300313 hfize_llama.py:161] loaded layer 12
I0403 02:36:59.236437 3300313 hfize_llama.py:161] loaded layer 13
I0403 02:36:59.900364 3300313 hfize_llama.py:161] loaded layer 14
I0403 02:37:00.653674 3300313 hfize_llama.py:161] loaded layer 15
I0403 02:37:01.385030 3300313 hfize_llama.py:161] loaded layer 16
I0403 02:37:02.058474 3300313 hfize_llama.py:161] loaded layer 17
I0403 02:37:02.687897 3300313 hfize_llama.py:161] loaded layer 18
I0403 02:37:03.359108 3300313 hfize_llama.py:161] loaded layer 19
I0403 02:37:04.017228 3300313 hfize_llama.py:161] loaded layer 20
I0403 02:37:04.739253 3300313 hfize_llama.py:161] loaded layer 21
I0403 02:37:05.488131 3300313 hfize_llama.py:161] loaded layer 22
I0403 02:37:06.201437 3300313 hfize_llama.py:161] loaded layer 23
I0403 02:37:06.873847 3300313 hfize_llama.py:161] loaded layer 24
I0403 02:37:07.526268 3300313 hfize_llama.py:161] loaded layer 25
I0403 02:37:08.129036 3300313 hfize_llama.py:161] loaded layer 26
I0403 02:37:08.778273 3300313 hfize_llama.py:161] loaded layer 27
I0403 02:37:09.428512 3300313 hfize_llama.py:161] loaded layer 28
I0403 02:37:10.066179 3300313 hfize_llama.py:161] loaded layer 29
I0403 02:37:10.792735 3300313 hfize_llama.py:161] loaded layer 30
I0403 02:37:11.433030 3300313 hfize_llama.py:161] loaded layer 31
I0403 02:37:11.433147 3300313 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:09,  1.50s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:06,  1.21s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.06s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:02,  1.01it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:01,  1.05it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:05<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]
I0403 02:37:54.199153 3300313 hfize_llama.py:175] successfully loaded hfized model
I0403 02:37:59.310841 3301383 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 02:37:59.310954 3301383 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 02:37:59.310997 3301383 utils.py:162] NumExpr defaulting to 16 threads.
W0403 02:37:59.669740 3301383 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 02:38:00.026340 3301383 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:10,  1.70s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:03<00:08,  1.66s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:04<00:05,  1.49s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:06<00:04,  1.46s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:07<00:02,  1.37s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:08<00:01,  1.26s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]
I0403 02:38:09.148822 3301383 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/141 [00:00<?, ?it/s]avg_loss = 1.7333136796951294:   0%|          | 0/141 [00:01<?, ?it/s]avg_loss = 1.7333136796951294:   1%|          | 1/141 [00:01<04:29,  1.92s/it]avg_loss = 2.0241424441337585:   1%|          | 1/141 [00:03<04:29,  1.92s/it]avg_loss = 2.0241424441337585:   1%|▏         | 2/141 [00:03<03:49,  1.65s/it]avg_loss = 2.158004323641459:   1%|▏         | 2/141 [00:04<03:49,  1.65s/it] avg_loss = 2.158004323641459:   2%|▏         | 3/141 [00:04<03:36,  1.57s/it]avg_loss = 2.109520733356476:   2%|▏         | 3/141 [00:06<03:36,  1.57s/it]avg_loss = 2.109520733356476:   3%|▎         | 4/141 [00:06<03:29,  1.53s/it]avg_loss = 2.0657561779022218:   3%|▎         | 4/141 [00:07<03:29,  1.53s/it]avg_loss = 2.0657561779022218:   4%|▎         | 5/141 [00:07<03:25,  1.51s/it]avg_loss = 1.9686732689539592:   4%|▎         | 5/141 [00:09<03:25,  1.51s/it]avg_loss = 1.9686732689539592:   4%|▍         | 6/141 [00:09<03:22,  1.50s/it]avg_loss = 1.9086341517312186:   4%|▍         | 6/141 [00:10<03:22,  1.50s/it]avg_loss = 1.9086341517312186:   5%|▍         | 7/141 [00:10<03:20,  1.49s/it]avg_loss = 1.8998151421546936:   5%|▍         | 7/141 [00:12<03:20,  1.49s/it]avg_loss = 1.8998151421546936:   6%|▌         | 8/141 [00:12<03:18,  1.49s/it]avg_loss = 1.9318848450978596:   6%|▌         | 8/141 [00:13<03:18,  1.49s/it]avg_loss = 1.9318848450978596:   6%|▋         | 9/141 [00:13<03:16,  1.49s/it]avg_loss = 1.9295552730560304:   6%|▋         | 9/141 [00:15<03:16,  1.49s/it]avg_loss = 1.9295552730560304:   7%|▋         | 10/141 [00:15<03:15,  1.49s/it]avg_loss = 1.9227075901898472:   7%|▋         | 10/141 [00:16<03:15,  1.49s/it]avg_loss = 1.9227075901898472:   8%|▊         | 11/141 [00:16<03:13,  1.49s/it]avg_loss = 1.943004459142685:   8%|▊         | 11/141 [00:18<03:13,  1.49s/it] avg_loss = 1.943004459142685:   9%|▊         | 12/141 [00:18<03:12,  1.49s/it]avg_loss = 1.953415458018963:   9%|▊         | 12/141 [00:19<03:12,  1.49s/it]avg_loss = 1.953415458018963:   9%|▉         | 13/141 [00:19<03:11,  1.50s/it]avg_loss = 1.9692605308123998:   9%|▉         | 13/141 [00:21<03:11,  1.50s/it]avg_loss = 1.9692605308123998:  10%|▉         | 14/141 [00:21<03:10,  1.50s/it]avg_loss = 1.9778336763381958:  10%|▉         | 14/141 [00:22<03:10,  1.50s/it]avg_loss = 1.9778336763381958:  11%|█         | 15/141 [00:22<03:08,  1.50s/it]avg_loss = 2.0006318762898445:  11%|█         | 15/141 [00:24<03:08,  1.50s/it]avg_loss = 2.0006318762898445:  11%|█▏        | 16/141 [00:24<03:07,  1.50s/it]avg_loss = 2.0037535429000854:  11%|█▏        | 16/141 [00:25<03:07,  1.50s/it]avg_loss = 2.0037535429000854:  12%|█▏        | 17/141 [00:25<03:06,  1.51s/it]avg_loss = 2.007576300038232:  12%|█▏        | 17/141 [00:27<03:06,  1.51s/it] avg_loss = 2.007576300038232:  13%|█▎        | 18/141 [00:27<03:05,  1.51s/it]avg_loss = 1.99712588285145:  13%|█▎        | 18/141 [00:28<03:05,  1.51s/it] avg_loss = 1.99712588285145:  13%|█▎        | 19/141 [00:28<03:04,  1.51s/it]avg_loss = 1.9948529362678529:  13%|█▎        | 19/141 [00:30<03:04,  1.51s/it]avg_loss = 1.9948529362678529:  14%|█▍        | 20/141 [00:30<03:03,  1.51s/it]avg_loss = 1.9986208961123513:  14%|█▍        | 20/141 [00:31<03:03,  1.51s/it]avg_loss = 1.9986208961123513:  15%|█▍        | 21/141 [00:31<03:01,  1.52s/it]avg_loss = 2.0003984407945112:  15%|█▍        | 21/141 [00:33<03:01,  1.52s/it]avg_loss = 2.0003984407945112:  16%|█▌        | 22/141 [00:33<03:00,  1.52s/it]avg_loss = 2.001632203226504:  16%|█▌        | 22/141 [00:34<03:00,  1.52s/it] avg_loss = 2.001632203226504:  16%|█▋        | 23/141 [00:34<02:59,  1.52s/it]avg_loss = 2.0060947835445404:  16%|█▋        | 23/141 [00:36<02:59,  1.52s/it]avg_loss = 2.0060947835445404:  17%|█▋        | 24/141 [00:36<02:58,  1.52s/it]avg_loss = 2.011871910095215:  17%|█▋        | 24/141 [00:37<02:58,  1.52s/it] avg_loss = 2.011871910095215:  18%|█▊        | 25/141 [00:37<02:56,  1.52s/it]avg_loss = 2.0231454097307644:  18%|█▊        | 25/141 [00:39<02:56,  1.52s/it]avg_loss = 2.0231454097307644:  18%|█▊        | 26/141 [00:39<02:55,  1.53s/it]avg_loss = 2.0348690439153603:  18%|█▊        | 26/141 [00:40<02:55,  1.53s/it]avg_loss = 2.0348690439153603:  19%|█▉        | 27/141 [00:40<02:54,  1.53s/it]avg_loss = 2.040430520262037:  19%|█▉        | 27/141 [00:42<02:54,  1.53s/it] avg_loss = 2.040430520262037:  20%|█▉        | 28/141 [00:42<02:52,  1.53s/it]avg_loss = 2.037205983852518:  20%|█▉        | 28/141 [00:44<02:52,  1.53s/it]avg_loss = 2.037205983852518:  21%|██        | 29/141 [00:44<02:51,  1.53s/it]avg_loss = 2.0289056738217672:  21%|██        | 29/141 [00:45<02:51,  1.53s/it]avg_loss = 2.0289056738217672:  21%|██▏       | 30/141 [00:45<02:50,  1.53s/it]avg_loss = 2.0167162726002354:  21%|██▏       | 30/141 [00:47<02:50,  1.53s/it]avg_loss = 2.0167162726002354:  22%|██▏       | 31/141 [00:47<02:48,  1.54s/it]avg_loss = 2.00624942407012:  22%|██▏       | 31/141 [00:48<02:48,  1.54s/it]  avg_loss = 2.00624942407012:  23%|██▎       | 32/141 [00:48<02:47,  1.54s/it]avg_loss = 2.0042379769411953:  23%|██▎       | 32/141 [00:50<02:47,  1.54s/it]avg_loss = 2.0042379769411953:  23%|██▎       | 33/141 [00:50<02:46,  1.54s/it]avg_loss = 2.001705888439627:  23%|██▎       | 33/141 [00:51<02:46,  1.54s/it] avg_loss = 2.001705888439627:  24%|██▍       | 34/141 [00:51<02:44,  1.54s/it]avg_loss = 2.0037916558129445:  24%|██▍       | 34/141 [00:53<02:44,  1.54s/it]avg_loss = 2.0037916558129445:  25%|██▍       | 35/141 [00:53<02:43,  1.54s/it]avg_loss = 1.9863636195659637:  25%|██▍       | 35/141 [00:54<02:43,  1.54s/it]avg_loss = 1.9863636195659637:  26%|██▌       | 36/141 [00:54<02:42,  1.55s/it]avg_loss = 1.9711898307542544:  26%|██▌       | 36/141 [00:56<02:42,  1.55s/it]avg_loss = 1.9711898307542544:  26%|██▌       | 37/141 [00:56<02:41,  1.55s/it]avg_loss = 1.956366190784856:  26%|██▌       | 37/141 [00:57<02:41,  1.55s/it] avg_loss = 1.956366190784856:  27%|██▋       | 38/141 [00:57<02:39,  1.55s/it]avg_loss = 1.941793985855885:  27%|██▋       | 38/141 [00:59<02:39,  1.55s/it]avg_loss = 1.941793985855885:  28%|██▊       | 39/141 [00:59<02:38,  1.55s/it]avg_loss = 1.9332434803247451:  28%|██▊       | 39/141 [01:01<02:38,  1.55s/it]avg_loss = 1.9332434803247451:  28%|██▊       | 40/141 [01:01<02:36,  1.55s/it]avg_loss = 1.938952739645795:  28%|██▊       | 40/141 [01:02<02:36,  1.55s/it] avg_loss = 1.938952739645795:  29%|██▉       | 41/141 [01:02<02:35,  1.55s/it]avg_loss = 1.954604549067361:  29%|██▉       | 41/141 [01:04<02:35,  1.55s/it]avg_loss = 1.954604549067361:  30%|██▉       | 42/141 [01:04<02:33,  1.55s/it]avg_loss = 1.9704501767491185:  30%|██▉       | 42/141 [01:05<02:33,  1.55s/it]avg_loss = 1.9704501767491185:  30%|███       | 43/141 [01:05<02:32,  1.56s/it]avg_loss = 1.9750285609201952:  30%|███       | 43/141 [01:07<02:32,  1.56s/it]avg_loss = 1.9750285609201952:  31%|███       | 44/141 [01:07<02:30,  1.56s/it]avg_loss = 1.9799094120661418:  31%|███       | 44/141 [01:08<02:30,  1.56s/it]avg_loss = 1.9799094120661418:  32%|███▏      | 45/141 [01:08<02:29,  1.56s/it]avg_loss = 1.9840893201206042:  32%|███▏      | 45/141 [01:10<02:29,  1.56s/it]avg_loss = 1.9840893201206042:  33%|███▎      | 46/141 [01:10<02:27,  1.56s/it]avg_loss = 1.9896535391503192:  33%|███▎      | 46/141 [01:11<02:27,  1.56s/it]avg_loss = 1.9896535391503192:  33%|███▎      | 47/141 [01:11<02:26,  1.56s/it]avg_loss = 1.992193194727103:  33%|███▎      | 47/141 [01:13<02:26,  1.56s/it] avg_loss = 1.992193194727103:  34%|███▍      | 48/141 [01:13<02:25,  1.56s/it]avg_loss = 1.991952998297555:  34%|███▍      | 48/141 [01:15<02:25,  1.56s/it]avg_loss = 1.991952998297555:  35%|███▍      | 49/141 [01:15<02:23,  1.56s/it]avg_loss = 1.9913525342941285:  35%|███▍      | 49/141 [01:16<02:23,  1.56s/it]avg_loss = 1.9913525342941285:  35%|███▌      | 50/141 [01:16<02:22,  1.56s/it]avg_loss = 1.986096929101383:  35%|███▌      | 50/141 [01:18<02:22,  1.56s/it] avg_loss = 1.986096929101383:  36%|███▌      | 51/141 [01:18<02:20,  1.56s/it]avg_loss = 1.9819619724383721:  36%|███▌      | 51/141 [01:19<02:20,  1.56s/it]avg_loss = 1.9819619724383721:  37%|███▋      | 52/141 [01:19<02:19,  1.56s/it]avg_loss = 1.975489562412478:  37%|███▋      | 52/141 [01:21<02:19,  1.56s/it] avg_loss = 1.975489562412478:  38%|███▊      | 53/141 [01:21<02:17,  1.56s/it]avg_loss = 1.9722199572457209:  38%|███▊      | 53/141 [01:22<02:17,  1.56s/it]avg_loss = 1.9722199572457209:  38%|███▊      | 54/141 [01:22<02:15,  1.56s/it]avg_loss = 1.9647123965350064:  38%|███▊      | 54/141 [01:24<02:15,  1.56s/it]avg_loss = 1.9647123965350064:  39%|███▉      | 55/141 [01:24<02:14,  1.56s/it]avg_loss = 1.9566906775747026:  39%|███▉      | 55/141 [01:26<02:14,  1.56s/it]avg_loss = 1.9566906775747026:  40%|███▉      | 56/141 [01:26<02:13,  1.57s/it]avg_loss = 1.9532831133457653:  40%|███▉      | 56/141 [01:27<02:13,  1.57s/it]avg_loss = 1.9532831133457653:  40%|████      | 57/141 [01:27<02:11,  1.57s/it]avg_loss = 1.9504056408487518:  40%|████      | 57/141 [01:29<02:11,  1.57s/it]avg_loss = 1.9504056408487518:  41%|████      | 58/141 [01:29<02:10,  1.57s/it]avg_loss = 1.9524941262552293:  41%|████      | 58/141 [01:30<02:10,  1.57s/it]avg_loss = 1.9524941262552293:  42%|████▏     | 59/141 [01:30<02:08,  1.57s/it]avg_loss = 1.957654470205307:  42%|████▏     | 59/141 [01:32<02:08,  1.57s/it] avg_loss = 1.957654470205307:  43%|████▎     | 60/141 [01:32<02:07,  1.57s/it]avg_loss = 1.963000573095728:  43%|████▎     | 60/141 [01:33<02:07,  1.57s/it]avg_loss = 1.963000573095728:  43%|████▎     | 61/141 [01:33<02:05,  1.57s/it]avg_loss = 1.9701085878956703:  43%|████▎     | 61/141 [01:35<02:05,  1.57s/it]avg_loss = 1.9701085878956703:  44%|████▍     | 62/141 [01:35<02:04,  1.57s/it]avg_loss = 1.9618215201393006:  44%|████▍     | 62/141 [01:37<02:04,  1.57s/it]avg_loss = 1.9618215201393006:  45%|████▍     | 63/141 [01:37<02:02,  1.58s/it]avg_loss = 1.9593346808105707:  45%|████▍     | 63/141 [01:38<02:02,  1.58s/it]avg_loss = 1.9593346808105707:  45%|████▌     | 64/141 [01:38<02:01,  1.58s/it]avg_loss = 1.956946613238408:  45%|████▌     | 64/141 [01:40<02:01,  1.58s/it] avg_loss = 1.956946613238408:  46%|████▌     | 65/141 [01:40<01:59,  1.57s/it]avg_loss = 1.9508041414347561:  46%|████▌     | 65/141 [01:41<01:59,  1.57s/it]avg_loss = 1.9508041414347561:  47%|████▋     | 66/141 [01:41<01:58,  1.58s/it]avg_loss = 1.9478514443582564:  47%|████▋     | 66/141 [01:43<01:58,  1.58s/it]avg_loss = 1.9478514443582564:  48%|████▊     | 67/141 [01:43<01:56,  1.58s/it]avg_loss = 1.945095535586862:  48%|████▊     | 67/141 [01:44<01:56,  1.58s/it] avg_loss = 1.945095535586862:  48%|████▊     | 68/141 [01:44<01:55,  1.58s/it]avg_loss = 1.9426105316134468:  48%|████▊     | 68/141 [01:46<01:55,  1.58s/it]avg_loss = 1.9426105316134468:  49%|████▉     | 69/141 [01:46<01:53,  1.58s/it]avg_loss = 1.943581337588174:  49%|████▉     | 69/141 [01:48<01:53,  1.58s/it] avg_loss = 1.943581337588174:  50%|████▉     | 70/141 [01:48<01:52,  1.58s/it]avg_loss = 1.947245374531813:  50%|████▉     | 70/141 [01:49<01:52,  1.58s/it]avg_loss = 1.947245374531813:  50%|█████     | 71/141 [01:49<01:50,  1.58s/it]avg_loss = 1.9498583094941244:  50%|█████     | 71/141 [01:51<01:50,  1.58s/it]avg_loss = 1.9498583094941244:  51%|█████     | 72/141 [01:51<01:48,  1.58s/it]avg_loss = 1.9480995168424633:  51%|█████     | 72/141 [01:52<01:48,  1.58s/it]avg_loss = 1.9480995168424633:  52%|█████▏    | 73/141 [01:52<01:47,  1.58s/it]avg_loss = 1.9493993536846057:  52%|█████▏    | 73/141 [01:54<01:47,  1.58s/it]avg_loss = 1.9493993536846057:  52%|█████▏    | 74/141 [01:54<01:46,  1.58s/it]avg_loss = 1.9492737992604574:  52%|█████▏    | 74/141 [01:56<01:46,  1.58s/it]avg_loss = 1.9492737992604574:  53%|█████▎    | 75/141 [01:56<01:44,  1.58s/it]avg_loss = 1.9478732363173836:  53%|█████▎    | 75/141 [01:57<01:44,  1.58s/it]avg_loss = 1.9478732363173836:  54%|█████▍    | 76/141 [01:57<01:42,  1.58s/it]avg_loss = 1.9488448492892376:  54%|█████▍    | 76/141 [01:59<01:42,  1.58s/it]avg_loss = 1.9488448492892376:  55%|█████▍    | 77/141 [01:59<01:41,  1.58s/it]avg_loss = 1.9508729149133732:  55%|█████▍    | 77/141 [02:00<01:41,  1.58s/it]avg_loss = 1.9508729149133732:  55%|█████▌    | 78/141 [02:00<01:39,  1.58s/it]avg_loss = 1.9544727907905095:  55%|█████▌    | 78/141 [02:02<01:39,  1.58s/it]avg_loss = 1.9544727907905095:  56%|█████▌    | 79/141 [02:02<01:38,  1.58s/it]avg_loss = 1.9510033115744592:  56%|█████▌    | 79/141 [02:03<01:38,  1.58s/it]avg_loss = 1.9510033115744592:  57%|█████▋    | 80/141 [02:03<01:36,  1.59s/it]avg_loss = 1.9495020265932437:  57%|█████▋    | 80/141 [02:05<01:36,  1.59s/it]avg_loss = 1.9495020265932437:  57%|█████▋    | 81/141 [02:05<01:35,  1.58s/it]avg_loss = 1.9484889085699872:  57%|█████▋    | 81/141 [02:07<01:35,  1.58s/it]avg_loss = 1.9484889085699872:  58%|█████▊    | 82/141 [02:07<01:33,  1.58s/it]avg_loss = 1.9466252872742802:  58%|█████▊    | 82/141 [02:08<01:33,  1.58s/it]avg_loss = 1.9466252872742802:  59%|█████▉    | 83/141 [02:08<01:31,  1.58s/it]avg_loss = 1.944227357705434:  59%|█████▉    | 83/141 [02:10<01:31,  1.58s/it] avg_loss = 1.944227357705434:  60%|█████▉    | 84/141 [02:10<01:30,  1.58s/it]avg_loss = 1.941956535507651:  60%|█████▉    | 84/141 [02:11<01:30,  1.58s/it]avg_loss = 1.941956535507651:  60%|██████    | 85/141 [02:11<01:28,  1.58s/it]avg_loss = 1.9435241707535678:  60%|██████    | 85/141 [02:13<01:28,  1.58s/it]avg_loss = 1.9435241707535678:  61%|██████    | 86/141 [02:13<01:27,  1.58s/it]avg_loss = 1.9454684846702663:  61%|██████    | 86/141 [02:15<01:27,  1.58s/it]avg_loss = 1.9454684846702663:  62%|██████▏   | 87/141 [02:15<01:25,  1.58s/it]avg_loss = 1.9467339475046506:  62%|██████▏   | 87/141 [02:16<01:25,  1.58s/it]avg_loss = 1.9467339475046506:  62%|██████▏   | 88/141 [02:16<01:23,  1.58s/it]avg_loss = 1.9555063796847054:  62%|██████▏   | 88/141 [02:18<01:23,  1.58s/it]avg_loss = 1.9555063796847054:  63%|██████▎   | 89/141 [02:18<01:22,  1.58s/it]avg_loss = 1.9627973119417825:  63%|██████▎   | 89/141 [02:19<01:22,  1.58s/it]avg_loss = 1.9627973119417825:  64%|██████▍   | 90/141 [02:19<01:20,  1.59s/it]avg_loss = 1.9658008106462248:  64%|██████▍   | 90/141 [02:21<01:20,  1.59s/it]avg_loss = 1.9658008106462248:  65%|██████▍   | 91/141 [02:21<01:19,  1.59s/it]avg_loss = 1.9709086768005206:  65%|██████▍   | 91/141 [02:22<01:19,  1.59s/it]avg_loss = 1.9709086768005206:  65%|██████▌   | 92/141 [02:22<01:17,  1.59s/it]avg_loss = 1.9758590049641107:  65%|██████▌   | 92/141 [02:24<01:17,  1.59s/it]avg_loss = 1.9758590049641107:  66%|██████▌   | 93/141 [02:24<01:16,  1.59s/it]avg_loss = 1.9764831890451147:  66%|██████▌   | 93/141 [02:26<01:16,  1.59s/it]avg_loss = 1.9764831890451147:  67%|██████▋   | 94/141 [02:26<01:14,  1.59s/it]avg_loss = 1.9802247762680054:  67%|██████▋   | 94/141 [02:27<01:14,  1.59s/it]avg_loss = 1.9802247762680054:  67%|██████▋   | 95/141 [02:27<01:12,  1.59s/it]avg_loss = 1.980685744434595:  67%|██████▋   | 95/141 [02:29<01:12,  1.59s/it] avg_loss = 1.980685744434595:  68%|██████▊   | 96/141 [02:29<01:11,  1.59s/it]avg_loss = 1.9821103835843272:  68%|██████▊   | 96/141 [02:30<01:11,  1.59s/it]avg_loss = 1.9821103835843272:  69%|██████▉   | 97/141 [02:30<01:09,  1.59s/it]avg_loss = 1.9796205698227396:  69%|██████▉   | 97/141 [02:32<01:09,  1.59s/it]avg_loss = 1.9796205698227396:  70%|██████▉   | 98/141 [02:32<01:08,  1.59s/it]avg_loss = 1.980692399872674:  70%|██████▉   | 98/141 [02:34<01:08,  1.59s/it] avg_loss = 1.980692399872674:  70%|███████   | 99/141 [02:34<01:06,  1.59s/it]avg_loss = 1.983049453496933:  70%|███████   | 99/141 [02:35<01:06,  1.59s/it]avg_loss = 1.983049453496933:  71%|███████   | 100/141 [02:35<01:05,  1.59s/it]avg_loss = 1.982458715391631:  71%|███████   | 100/141 [02:37<01:05,  1.59s/it]avg_loss = 1.982458715391631:  72%|███████▏  | 101/141 [02:37<01:03,  1.59s/it]avg_loss = 1.9830671467033087:  72%|███████▏  | 101/141 [02:38<01:03,  1.59s/it]avg_loss = 1.9830671467033087:  72%|███████▏  | 102/141 [02:38<01:01,  1.59s/it]avg_loss = 1.982566692296741:  72%|███████▏  | 102/141 [02:40<01:01,  1.59s/it] avg_loss = 1.982566692296741:  73%|███████▎  | 103/141 [02:40<01:00,  1.59s/it]avg_loss = 1.9859918974913084:  73%|███████▎  | 103/141 [02:42<01:00,  1.59s/it]avg_loss = 1.9859918974913084:  74%|███████▍  | 104/141 [02:42<00:58,  1.59s/it]avg_loss = 1.985593591417585:  74%|███████▍  | 104/141 [02:43<00:58,  1.59s/it] avg_loss = 1.985593591417585:  74%|███████▍  | 105/141 [02:43<00:57,  1.59s/it]avg_loss = 1.985288606499726:  74%|███████▍  | 105/141 [02:45<00:57,  1.59s/it]avg_loss = 1.985288606499726:  75%|███████▌  | 106/141 [02:45<00:55,  1.59s/it]avg_loss = 1.9834956554608925:  75%|███████▌  | 106/141 [02:46<00:55,  1.59s/it]avg_loss = 1.9834956554608925:  76%|███████▌  | 107/141 [02:46<00:54,  1.59s/it]avg_loss = 1.981596123289179:  76%|███████▌  | 107/141 [02:48<00:54,  1.59s/it] avg_loss = 1.981596123289179:  77%|███████▋  | 108/141 [02:48<00:52,  1.59s/it]avg_loss = 1.9796748358175296:  77%|███████▋  | 108/141 [02:49<00:52,  1.59s/it]avg_loss = 1.9796748358175296:  77%|███████▋  | 109/141 [02:49<00:50,  1.59s/it]avg_loss = 1.9776321378621189:  77%|███████▋  | 109/141 [02:51<00:50,  1.59s/it]avg_loss = 1.9776321378621189:  78%|███████▊  | 110/141 [02:51<00:49,  1.59s/it]avg_loss = 1.980363425907788:  78%|███████▊  | 110/141 [02:53<00:49,  1.59s/it] avg_loss = 1.980363425907788:  79%|███████▊  | 111/141 [02:53<00:47,  1.59s/it]avg_loss = 1.9799214473792486:  79%|███████▊  | 111/141 [02:54<00:47,  1.59s/it]avg_loss = 1.9799214473792486:  79%|███████▉  | 112/141 [02:54<00:46,  1.59s/it]avg_loss = 1.9809344152433683:  79%|███████▉  | 112/141 [02:56<00:46,  1.59s/it]avg_loss = 1.9809344152433683:  80%|████████  | 113/141 [02:56<00:44,  1.59s/it]avg_loss = 1.9820181110449004:  80%|████████  | 113/141 [02:57<00:44,  1.59s/it]avg_loss = 1.9820181110449004:  81%|████████  | 114/141 [02:57<00:42,  1.59s/it]avg_loss = 1.9812380241311114:  81%|████████  | 114/141 [02:59<00:42,  1.59s/it]avg_loss = 1.9812380241311114:  82%|████████▏ | 115/141 [02:59<00:41,  1.59s/it]avg_loss = 1.980205724979269:  82%|████████▏ | 115/141 [03:01<00:41,  1.59s/it] avg_loss = 1.980205724979269:  82%|████████▏ | 116/141 [03:01<00:39,  1.59s/it]avg_loss = 1.9822022222046158:  82%|████████▏ | 116/141 [03:02<00:39,  1.59s/it]avg_loss = 1.9822022222046158:  83%|████████▎ | 117/141 [03:02<00:38,  1.59s/it]avg_loss = 1.9815995329517428:  83%|████████▎ | 117/141 [03:04<00:38,  1.59s/it]avg_loss = 1.9815995329517428:  84%|████████▎ | 118/141 [03:04<00:36,  1.59s/it]avg_loss = 1.9799756442799288:  84%|████████▎ | 118/141 [03:05<00:36,  1.59s/it]avg_loss = 1.9799756442799288:  84%|████████▍ | 119/141 [03:05<00:34,  1.59s/it]avg_loss = 1.9781572957833609:  84%|████████▍ | 119/141 [03:07<00:34,  1.59s/it]avg_loss = 1.9781572957833609:  85%|████████▌ | 120/141 [03:07<00:33,  1.59s/it]avg_loss = 1.9781371542244903:  85%|████████▌ | 120/141 [03:09<00:33,  1.59s/it]avg_loss = 1.9781371542244903:  86%|████████▌ | 121/141 [03:09<00:31,  1.59s/it]avg_loss = 1.9789427792439696:  86%|████████▌ | 121/141 [03:10<00:31,  1.59s/it]avg_loss = 1.9789427792439696:  87%|████████▋ | 122/141 [03:10<00:30,  1.59s/it]avg_loss = 1.978487774608581:  87%|████████▋ | 122/141 [03:12<00:30,  1.59s/it] avg_loss = 1.978487774608581:  87%|████████▋ | 123/141 [03:12<00:28,  1.59s/it]avg_loss = 1.978353488829828:  87%|████████▋ | 123/141 [03:13<00:28,  1.59s/it]avg_loss = 1.978353488829828:  88%|████████▊ | 124/141 [03:13<00:27,  1.59s/it]avg_loss = 1.976901268005371:  88%|████████▊ | 124/141 [03:15<00:27,  1.59s/it]avg_loss = 1.976901268005371:  89%|████████▊ | 125/141 [03:15<00:25,  1.59s/it]avg_loss = 1.9769787807313224:  89%|████████▊ | 125/141 [03:16<00:25,  1.59s/it]avg_loss = 1.9769787807313224:  89%|████████▉ | 126/141 [03:16<00:23,  1.59s/it]avg_loss = 1.976757325525359:  89%|████████▉ | 126/141 [03:18<00:23,  1.59s/it] avg_loss = 1.976757325525359:  90%|█████████ | 127/141 [03:18<00:22,  1.59s/it]avg_loss = 1.9755723113194108:  90%|█████████ | 127/141 [03:20<00:22,  1.59s/it]avg_loss = 1.9755723113194108:  91%|█████████ | 128/141 [03:20<00:20,  1.59s/it]avg_loss = 1.9753899398700212:  91%|█████████ | 128/141 [03:21<00:20,  1.59s/it]avg_loss = 1.9753899398700212:  91%|█████████▏| 129/141 [03:21<00:19,  1.59s/it]avg_loss = 1.9765018674043509:  91%|█████████▏| 129/141 [03:23<00:19,  1.59s/it]avg_loss = 1.9765018674043509:  92%|█████████▏| 130/141 [03:23<00:17,  1.59s/it]avg_loss = 1.977193008852369:  92%|█████████▏| 130/141 [03:24<00:17,  1.59s/it] avg_loss = 1.977193008852369:  93%|█████████▎| 131/141 [03:24<00:15,  1.59s/it]avg_loss = 1.977688002766985:  93%|█████████▎| 131/141 [03:26<00:15,  1.59s/it]avg_loss = 1.977688002766985:  94%|█████████▎| 132/141 [03:26<00:14,  1.59s/it]avg_loss = 1.9747845517065292:  94%|█████████▎| 132/141 [03:28<00:14,  1.59s/it]avg_loss = 1.9747845517065292:  94%|█████████▍| 133/141 [03:28<00:12,  1.59s/it]avg_loss = 1.9699403723674034:  94%|█████████▍| 133/141 [03:29<00:12,  1.59s/it]avg_loss = 1.9699403723674034:  95%|█████████▌| 134/141 [03:29<00:11,  1.59s/it]avg_loss = 1.9722347895304362:  95%|█████████▌| 134/141 [03:31<00:11,  1.59s/it]avg_loss = 1.9722347895304362:  96%|█████████▌| 135/141 [03:31<00:09,  1.59s/it]avg_loss = 1.9756935642046087:  96%|█████████▌| 135/141 [03:32<00:09,  1.59s/it]avg_loss = 1.9756935642046087:  96%|█████████▋| 136/141 [03:32<00:07,  1.59s/it]avg_loss = 1.9770616614905587:  96%|█████████▋| 136/141 [03:34<00:07,  1.59s/it]avg_loss = 1.9770616614905587:  97%|█████████▋| 137/141 [03:34<00:06,  1.59s/it]avg_loss = 1.976071916628575:  97%|█████████▋| 137/141 [03:36<00:06,  1.59s/it] avg_loss = 1.976071916628575:  98%|█████████▊| 138/141 [03:36<00:04,  1.59s/it]avg_loss = 1.9765318306229955:  98%|█████████▊| 138/141 [03:37<00:04,  1.59s/it]avg_loss = 1.9765318306229955:  99%|█████████▊| 139/141 [03:37<00:03,  1.59s/it]avg_loss = 1.9772377380302975:  99%|█████████▊| 139/141 [03:39<00:03,  1.59s/it]avg_loss = 1.9772377380302975:  99%|█████████▉| 140/141 [03:39<00:01,  1.59s/it]avg_loss = 1.9783654677952436:  99%|█████████▉| 140/141 [03:40<00:01,  1.59s/it]avg_loss = 1.9783654677952436: 100%|██████████| 141/141 [03:40<00:00,  1.59s/it]avg_loss = 1.9783654677952436: 100%|██████████| 141/141 [03:40<00:00,  1.57s/it]
I0403 02:42:16.469717 3301383 eval_ppl.py:107] wikitext2 perplexity: 7.2309136390686035
wikitext2 perplexity: 7.231
