I0403 05:42:22.663440 3437978 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:42:22.663541 3437978 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:42:22.663579 3437978 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:42:22.986061 3437978 config.py:54] PyTorch version 2.6.0 available.
W0403 05:42:23.171414 3437978 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:42:23.712194 3437978 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  6.77it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.31it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  7.79it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  7.88it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.92it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.74it/s]
I0403 05:42:24.688671 3437978 quantize_finetune_llama.py:152] loaded model
I0403 05:42:25.075956 3437978 quantize_finetune_llama.py:190] loaded compression model
I0403 05:42:39.125788 3437978 quantize_finetune_llama.py:194] loaded dataset and devset
I0403 05:42:42.506063 3437978 quantize_finetune_llama.py:214] layer 0 gpu 0
I0403 05:42:45.854405 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 3.1878082752227783s
Use train scale and shift
tensor(2.2655e-07, device='cuda:0') tensor(0.0204, device='cuda:0')
tensor(0.0204, device='cuda:0') tensor(2.2655e-07, device='cuda:0')
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0403 05:42:58.259786 3438523 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:42:58.259908 3438523 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:42:58.259946 3438523 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:42:58.578681 3438523 config.py:54] PyTorch version 2.6.0 available.
W0403 05:42:58.765637 3438523 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:42:59.310757 3438523 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:42:59.314664 3437978 quantize_finetune_llama.py:214] layer 1 gpu 1
I0403 05:42:59.463038 3438523 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:43:03.406038 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 3.918210506439209s
I0403 05:43:06.889099 3438671 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:43:06.889197 3438671 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:43:06.889235 3438671 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:43:07.214036 3438671 config.py:54] PyTorch version 2.6.0 available.
W0403 05:43:07.406996 3438671 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:43:07.994552 3438671 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:43:07.998117 3437978 quantize_finetune_llama.py:214] layer 2 gpu 0
I0403 05:43:08.207093 3438671 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.0010114273754879832 err 0.9829831719398499 tr(WHW.T) 971.8771362304688
bpp_loss 3.212884796957951
0_q proxy err 3.333521817694418e-06 err 2.121537923812866 tr(WHW.T) 636425.375
bpp_loss 3.2280168581637554
0_k proxy err 4.931395778839942e-06 err 1.9669569730758667 tr(WHW.T) 398864.15625
bpp_loss 3.3249509821180254
0_o proxy err 7.062762597342953e-05 err 1.1248115301132202 tr(WHW.T) 15925.943359375
bpp_loss 3.0668662266689353
0_up proxy err 0.004136912524700165 err 99.77067565917969 tr(WHW.T) 24117.18359375
bpp_loss 3.098447120900071
0_gate proxy err 0.002832929603755474 err 100.36333465576172 tr(WHW.T) 35427.40234375
bpp_loss 3.113689631050409
0_down proxy err 0.0019061921630054712 err 68.23470306396484 tr(WHW.T) 35796.33984375
bpp_loss 3.29891354337248
1_v proxy err 0.004456516355276108 err 2.9280388355255127 tr(WHW.T) 657.0241088867188
bpp_loss 3.1431592540466227
1_q proxy err 2.5530353013891727e-05 err 4.989076614379883 tr(WHW.T) 195417.453125
bpp_loss 4.04602463421179
1_k proxy err 2.4584054699516855e-05 err 5.02241325378418 tr(WHW.T) 204295.5625
bpp_loss 4.041047855804209
1_o proxy err 0.0013985707191750407 err 5.649709224700928 tr(WHW.T) 4039.630859375
bpp_loss 3.0503118547494523
1_up proxy err 0.005810099188238382 err 134.8491973876953 tr(WHW.T) 23209.44921875
bpp_loss 3.124525004521359
1_gate proxy err 0.002895879093557596 err 135.9732666015625 tr(WHW.T) 46954.0546875
bpp_loss 3.1889163002718326
1_down proxy err 7.94101561041316e-06 err 0.3238300085067749 tr(WHW.T) 40779.421875
bpp_loss 3.4673122496798983
I0403 05:44:58.433598 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 0.8449509143829346s
I0403 05:45:01.974950 3440071 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:45:01.975049 3440071 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:45:01.975087 3440071 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:45:02.301099 3440071 config.py:54] PyTorch version 2.6.0 available.
W0403 05:45:02.502180 3440071 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:45:03.056954 3440071 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:45:03.060488 3437978 quantize_finetune_llama.py:214] layer 3 gpu 1
I0403 05:45:03.229369 3440071 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:45:04.311076 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 0.8324809074401855s
I0403 05:45:07.823859 3440279 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:45:07.823959 3440279 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:45:07.823997 3440279 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:45:08.143969 3440279 config.py:54] PyTorch version 2.6.0 available.
W0403 05:45:08.330982 3440279 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:45:08.874387 3440279 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:45:08.877959 3437978 quantize_finetune_llama.py:214] layer 4 gpu 0
I0403 05:45:09.068928 3440279 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.006745867896825075 err 18.752593994140625 tr(WHW.T) 2779.86376953125
bpp_loss 3.218764906108845
2_q proxy err 0.00012780191900674254 err 20.385454177856445 tr(WHW.T) 159508.203125
bpp_loss 4.015170013997704
2_k proxy err 9.820199193200096e-05 err 20.622514724731445 tr(WHW.T) 210000.984375
bpp_loss 4.120731588220224
2_o proxy err 0.005960369948297739 err 31.593477249145508 tr(WHW.T) 5300.58984375
bpp_loss 3.1152259986265562
2_up proxy err 0.008421776816248894 err 167.87608337402344 tr(WHW.T) 19933.5703125
bpp_loss 3.1309055114208264
2_gate proxy err 0.005345593206584454 err 169.2453155517578 tr(WHW.T) 31660.716796875
bpp_loss 3.209458737525829
2_down proxy err 0.010643511079251766 err 183.95826721191406 tr(WHW.T) 17283.607421875
bpp_loss 3.1973877238153023
3_v proxy err 0.01164004672318697 err 34.67465591430664 tr(WHW.T) 2978.910400390625
bpp_loss 3.111596718430519
3_q proxy err 0.0004962983075529337 err 37.8050537109375 tr(WHW.T) 76174.0546875
bpp_loss 3.834129015041981
3_k proxy err 0.0003580730699468404 err 38.084861755371094 tr(WHW.T) 106360.5859375
bpp_loss 3.9110381340724416
3_o proxy err 0.006523509975522757 err 34.28483963012695 tr(WHW.T) 5255.58154296875
bpp_loss 3.1049655848764814
3_up proxy err 0.01058601401746273 err 184.91455078125 tr(WHW.T) 17467.81640625
bpp_loss 3.1382244312485983
3_gate proxy err 0.006352810654789209 err 186.75350952148438 tr(WHW.T) 29396.990234375
bpp_loss 3.225720420046601
3_down proxy err 0.0107982587069273 err 182.57257080078125 tr(WHW.T) 16907.59375
bpp_loss 3.2071937085670785
I0403 05:47:09.872468 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.9903461933135986s
I0403 05:47:13.690964 3442099 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:47:13.691081 3442099 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:47:13.691124 3442099 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:47:14.087157 3442099 config.py:54] PyTorch version 2.6.0 available.
W0403 05:47:14.315092 3442099 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:47:14.982874 3442099 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:47:14.987128 3437978 quantize_finetune_llama.py:214] layer 5 gpu 1
I0403 05:47:15.164140 3442099 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:47:16.462657 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.9603135585784912s
I0403 05:47:20.165455 3442231 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:47:20.165764 3442231 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:47:20.165811 3442231 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:47:20.525073 3442231 config.py:54] PyTorch version 2.6.0 available.
W0403 05:47:20.735484 3442231 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:47:21.356534 3442231 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:47:21.360558 3437978 quantize_finetune_llama.py:214] layer 6 gpu 0
I0403 05:47:21.532280 3442231 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.011239172890782356 err 34.813961029052734 tr(WHW.T) 3097.555419921875
bpp_loss 3.156135765428189
4_q proxy err 0.0004767248756252229 err 37.540401458740234 tr(WHW.T) 78746.46875
bpp_loss 3.9299424913479015
4_k proxy err 0.0003186553076375276 err 37.8118782043457 tr(WHW.T) 118660.75
bpp_loss 3.9682543544331565
4_o proxy err 0.008165713399648666 err 43.580223083496094 tr(WHW.T) 5336.9765625
bpp_loss 3.0834608545410447
4_up proxy err 0.01041698083281517 err 184.0126953125 tr(WHW.T) 17664.685546875
bpp_loss 3.1354049901629604
4_gate proxy err 0.005098527763038874 err 186.545654296875 tr(WHW.T) 36588.140625
bpp_loss 3.2557379573063794
4_down proxy err 0.010610238648951054 err 178.58018493652344 tr(WHW.T) 16830.9296875
bpp_loss 3.196684130489133
5_v proxy err 0.012102917768061161 err 38.32476043701172 tr(WHW.T) 3166.572021484375
bpp_loss 3.1616175503004342
5_q proxy err 0.0005698940367437899 err 41.3377799987793 tr(WHW.T) 72535.90625
bpp_loss 3.9286169577389956
5_k proxy err 0.00035915730404667556 err 41.736698150634766 tr(WHW.T) 116207.296875
bpp_loss 4.0099390432587825
5_o proxy err 0.008440396748483181 err 31.81648063659668 tr(WHW.T) 3769.5478515625
bpp_loss 3.1550172579009086
5_up proxy err 0.010273866355419159 err 185.10060119628906 tr(WHW.T) 18016.64453125
bpp_loss 3.133801277293715
5_gate proxy err 0.0047607715241611 err 187.65570068359375 tr(WHW.T) 39417.078125
bpp_loss 3.261951268932154
5_down proxy err 0.011749605648219585 err 187.44522094726562 tr(WHW.T) 15953.3203125
bpp_loss 3.183928140460752
I0403 05:49:15.703849 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.9902584552764893s
I0403 05:49:19.410813 3443952 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:49:19.410939 3443952 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:49:19.410985 3443952 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:49:19.795207 3443952 config.py:54] PyTorch version 2.6.0 available.
W0403 05:49:20.004284 3443952 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:49:20.611157 3443952 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:49:20.615002 3437978 quantize_finetune_llama.py:214] layer 7 gpu 1
I0403 05:49:20.796366 3443952 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:49:22.042329 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.9473450183868408s
I0403 05:49:25.667562 3444096 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:49:25.667748 3444096 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:49:25.667846 3444096 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:49:26.039705 3444096 config.py:54] PyTorch version 2.6.0 available.
W0403 05:49:26.229175 3444096 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:49:26.774788 3444096 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:49:26.778545 3437978 quantize_finetune_llama.py:214] layer 8 gpu 0
I0403 05:49:26.953373 3444096 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.01316456776112318 err 41.87430191040039 tr(WHW.T) 3180.833740234375
bpp_loss 3.0921852854662575
6_q proxy err 0.0008382598171010613 err 45.903690338134766 tr(WHW.T) 54760.6953125
bpp_loss 3.792267976910807
6_k proxy err 0.0006115499418228865 err 46.031436920166016 tr(WHW.T) 75270.1171875
bpp_loss 3.829963425931055
6_o proxy err 0.009436837397515774 err 38.13789367675781 tr(WHW.T) 4041.38525390625
bpp_loss 3.0843803065945394
6_up proxy err 0.010463409125804901 err 188.04519653320312 tr(WHW.T) 17971.6953125
bpp_loss 3.1306065022079057
6_gate proxy err 0.004205557983368635 err 191.06231689453125 tr(WHW.T) 45430.91015625
bpp_loss 3.284075658941685
6_down proxy err 0.01184842362999916 err 182.87750244140625 tr(WHW.T) 15434.75390625
bpp_loss 3.181838340884031
7_v proxy err 0.013134447857737541 err 42.6967658996582 tr(WHW.T) 3250.746826171875
bpp_loss 3.0965472737443633
7_q proxy err 0.0009123461204580963 err 46.80390548706055 tr(WHW.T) 51300.6015625
bpp_loss 3.785673242120538
7_k proxy err 0.0006874286336824298 err 46.89982986450195 tr(WHW.T) 68225.015625
bpp_loss 3.7935076829744503
7_o proxy err 0.010338936932384968 err 36.47982406616211 tr(WHW.T) 3528.39208984375
bpp_loss 3.0951152876368724
7_up proxy err 0.010161036625504494 err 185.23643493652344 tr(WHW.T) 18230.072265625
bpp_loss 3.13721518045248
7_gate proxy err 0.004034992773085833 err 188.2263946533203 tr(WHW.T) 46648.5078125
bpp_loss 3.2860062313807563
7_down proxy err 0.011904288083314896 err 181.4258270263672 tr(WHW.T) 15240.3759765625
bpp_loss 3.181621009657203
I0403 05:51:23.297199 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 0.8896498680114746s
I0403 05:51:27.018179 3445820 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:51:27.018321 3445820 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:51:27.018378 3445820 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:51:27.395592 3445820 config.py:54] PyTorch version 2.6.0 available.
W0403 05:51:27.615402 3445820 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:51:28.257301 3445820 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:51:28.261090 3437978 quantize_finetune_llama.py:214] layer 9 gpu 1
I0403 05:51:28.409422 3445820 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:51:29.551256 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.8221368789672852s
I0403 05:51:33.000596 3445960 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:51:33.000688 3445960 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:51:33.000726 3445960 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:51:33.319616 3445960 config.py:54] PyTorch version 2.6.0 available.
W0403 05:51:33.505461 3445960 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:51:34.066159 3445960 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:51:34.069957 3437978 quantize_finetune_llama.py:214] layer 10 gpu 0
I0403 05:51:34.277920 3445960 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.011985337361693382 err 41.59393310546875 tr(WHW.T) 3470.401611328125
bpp_loss 3.1221931850886904
8_q proxy err 0.0009426834294572473 err 44.864715576171875 tr(WHW.T) 47592.55859375
bpp_loss 3.815710441675037
8_k proxy err 0.0006426951731555164 err 45.052886962890625 tr(WHW.T) 70099.9296875
bpp_loss 3.824830331199337
8_o proxy err 0.01084266509860754 err 33.814971923828125 tr(WHW.T) 3118.695556640625
bpp_loss 3.1224173454684205
8_up proxy err 0.009269868955016136 err 184.0305938720703 tr(WHW.T) 19852.556640625
bpp_loss 3.1522172614065713
8_gate proxy err 0.0041170245967805386 err 186.5499267578125 tr(WHW.T) 45311.83203125
bpp_loss 3.2668219142875006
8_down proxy err 0.011829587630927563 err 181.25741577148438 tr(WHW.T) 15322.3779296875
bpp_loss 3.1902073160420326
9_v proxy err 0.012088802643120289 err 44.444061279296875 tr(WHW.T) 3676.465087890625
bpp_loss 3.123019182297867
9_q proxy err 0.001044226111844182 err 47.696510314941406 tr(WHW.T) 45676.421875
bpp_loss 3.8079689933219925
9_k proxy err 0.0006667120615020394 err 48.03995895385742 tr(WHW.T) 72055.03125
bpp_loss 3.8528958723763935
9_o proxy err 0.011328840628266335 err 35.6700439453125 tr(WHW.T) 3148.60498046875
bpp_loss 3.121597474324517
9_up proxy err 0.008956821635365486 err 184.56106567382812 tr(WHW.T) 20605.642578125
bpp_loss 3.1601965864903705
9_gate proxy err 0.004115980118513107 err 186.89271545410156 tr(WHW.T) 45406.61328125
bpp_loss 3.25510563883324
9_down proxy err 0.012000741437077522 err 183.900146484375 tr(WHW.T) 15324.0654296875
bpp_loss 3.1918154496179763
I0403 05:53:33.729825 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 0.88893723487854s
I0403 05:53:37.295244 3447829 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:53:37.295347 3447829 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:53:37.295388 3447829 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:53:37.650790 3447829 config.py:54] PyTorch version 2.6.0 available.
W0403 05:53:37.851765 3447829 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:53:38.442131 3447829 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:53:38.446618 3437978 quantize_finetune_llama.py:214] layer 11 gpu 1
I0403 05:53:38.592638 3447829 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:53:40.022018 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 1.0941901206970215s
I0403 05:53:43.480832 3447966 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:53:43.480934 3447966 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:53:43.480974 3447966 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:53:43.815357 3447966 config.py:54] PyTorch version 2.6.0 available.
W0403 05:53:44.016734 3447966 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:53:44.661647 3447966 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:53:44.665111 3437978 quantize_finetune_llama.py:214] layer 12 gpu 0
I0403 05:53:44.858865 3447966 data_utils.py:336] using 256 training seqs, 128 validation seqs
10_v proxy err 0.012271319516003132 err 44.81021499633789 tr(WHW.T) 3651.62158203125
bpp_loss 3.1163597731501795
10_q proxy err 0.0010946410475298762 err 48.0936393737793 tr(WHW.T) 43935.53515625
bpp_loss 3.8069232231355272
10_k proxy err 0.0006939104059711099 err 48.51325988769531 tr(WHW.T) 69912.859375
bpp_loss 3.8623878742801026
10_o proxy err 0.012207847088575363 err 37.33506393432617 tr(WHW.T) 3058.283935546875
bpp_loss 3.1043764852220193
10_up proxy err 0.00842352956533432 err 184.51263427734375 tr(WHW.T) 21904.43359375
bpp_loss 3.1718337688335154
10_gate proxy err 0.00405613798648119 err 186.51364135742188 tr(WHW.T) 45983.0625
bpp_loss 3.2513922734489276
10_down proxy err 0.011243217624723911 err 181.14100646972656 tr(WHW.T) 16111.1357421875
bpp_loss 3.2043437329229225
11_v proxy err 0.012225782498717308 err 47.56831741333008 tr(WHW.T) 3890.81982421875
bpp_loss 3.133479838317726
11_q proxy err 0.0013355923583731055 err 50.85017395019531 tr(WHW.T) 38073.125
bpp_loss 3.697053150390275
11_k proxy err 0.0008955489611253142 err 51.04420471191406 tr(WHW.T) 56997.671875
bpp_loss 3.689337882969994
11_o proxy err 0.012512274086475372 err 38.2152099609375 tr(WHW.T) 3054.2177734375
bpp_loss 3.1284302268759347
11_up proxy err 0.00880151055753231 err 189.6576385498047 tr(WHW.T) 21548.3046875
bpp_loss 3.1795121452143027
11_gate proxy err 0.0042233774438500404 err 191.68528747558594 tr(WHW.T) 45386.7265625
bpp_loss 3.244806409142045
11_down proxy err 0.01186856348067522 err 186.70179748535156 tr(WHW.T) 15730.783203125
bpp_loss 3.2038134038881507
I0403 05:55:48.796432 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 1.0460200309753418s
I0403 05:55:52.482722 3449796 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:55:52.482824 3449796 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:55:52.482864 3449796 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:55:52.858256 3449796 config.py:54] PyTorch version 2.6.0 available.
W0403 05:55:53.072607 3449796 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:55:53.661875 3449796 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:55:53.665765 3437978 quantize_finetune_llama.py:214] layer 13 gpu 1
I0403 05:55:53.836599 3449796 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:55:55.108749 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 0.96425461769104s
I0403 05:55:58.867583 3449944 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:55:58.867677 3449944 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:55:58.867714 3449944 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:55:59.186641 3449944 config.py:54] PyTorch version 2.6.0 available.
W0403 05:55:59.372354 3449944 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:56:00.013063 3449944 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:56:00.016947 3437978 quantize_finetune_llama.py:214] layer 14 gpu 0
I0403 05:56:00.237187 3449944 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.012877474538981915 err 49.02909851074219 tr(WHW.T) 3807.353515625
bpp_loss 3.120493497001007
12_q proxy err 0.0013644755817949772 err 52.404048919677734 tr(WHW.T) 38406.0
bpp_loss 3.7316005208995193
12_k proxy err 0.0008890583994798362 err 52.83607482910156 tr(WHW.T) 59429.25
bpp_loss 3.7858159361057915
12_o proxy err 0.013195406645536423 err 39.54820251464844 tr(WHW.T) 2997.118896484375
bpp_loss 3.1132448751013726
12_up proxy err 0.008793543092906475 err 191.75421142578125 tr(WHW.T) 21806.251953125
bpp_loss 3.1887916841999044
12_gate proxy err 0.004561993759125471 err 193.49998474121094 tr(WHW.T) 42415.66015625
bpp_loss 3.2359661263262116
12_down proxy err 0.011805826798081398 err 186.34017944335938 tr(WHW.T) 15783.7470703125
bpp_loss 3.21602938908997
13_v proxy err 0.013419486582279205 err 52.1208610534668 tr(WHW.T) 3883.96826171875
bpp_loss 3.1350877009681426
13_q proxy err 0.0014554192312061787 err 55.439544677734375 tr(WHW.T) 38091.8046875
bpp_loss 3.701122669270262
13_k proxy err 0.0009765622089616954 err 55.802490234375 tr(WHW.T) 57141.765625
bpp_loss 3.7305987500585616
13_o proxy err 0.01202448457479477 err 40.790260314941406 tr(WHW.T) 3392.266845703125
bpp_loss 3.134115061897319
13_up proxy err 0.008349274285137653 err 189.42897033691406 tr(WHW.T) 22688.076171875
bpp_loss 3.2007165288682593
13_gate proxy err 0.00441019469872117 err 190.90200805664062 tr(WHW.T) 43286.52734375
bpp_loss 3.2318873896675053
13_down proxy err 0.011441926471889019 err 180.21682739257812 tr(WHW.T) 15750.5673828125
bpp_loss 3.234508198772579
I0403 05:58:01.133527 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 0.8234481811523438s
I0403 05:58:04.654997 3451683 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:58:04.655091 3451683 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:58:04.655129 3451683 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:58:04.974854 3451683 config.py:54] PyTorch version 2.6.0 available.
W0403 05:58:05.160875 3451683 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:58:05.708235 3451683 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:58:05.711731 3437978 quantize_finetune_llama.py:214] layer 15 gpu 1
I0403 05:58:05.894557 3451683 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:58:06.956553 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 0.801354169845581s
I0403 05:58:10.409278 3451824 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:58:10.409371 3451824 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:58:10.409412 3451824 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:58:10.731224 3451824 config.py:54] PyTorch version 2.6.0 available.
W0403 05:58:10.917317 3451824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:58:11.484894 3451824 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:58:11.488386 3437978 quantize_finetune_llama.py:214] layer 16 gpu 0
I0403 05:58:11.637230 3451824 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.013955596834421158 err 50.90401077270508 tr(WHW.T) 3647.569580078125
bpp_loss 3.1211746240151115
14_q proxy err 0.0014716958394274116 err 54.21119689941406 tr(WHW.T) 36835.87109375
bpp_loss 3.698460566753056
14_k proxy err 0.0009291679016314447 err 54.67647171020508 tr(WHW.T) 58844.5546875
bpp_loss 3.7281709750532173
14_o proxy err 0.013554173521697521 err 41.52843475341797 tr(WHW.T) 3063.885498046875
bpp_loss 3.109157406433951
14_up proxy err 0.008647117763757706 err 194.15089416503906 tr(WHW.T) 22452.671875
bpp_loss 3.199899028553519
14_gate proxy err 0.00474092410877347 err 195.5201416015625 tr(WHW.T) 41240.93359375
bpp_loss 3.2273600532911546
14_down proxy err 0.011749593541026115 err 181.0552215576172 tr(WHW.T) 15409.48828125
bpp_loss 3.2371037924272374
15_v proxy err 0.012626873329281807 err 50.5460205078125 tr(WHW.T) 4003.05126953125
bpp_loss 3.1589256284059957
15_q proxy err 0.0013957105111330748 err 53.53017044067383 tr(WHW.T) 38353.34765625
bpp_loss 3.681487293099053
15_k proxy err 0.0009218418272212148 err 54.02080535888672 tr(WHW.T) 58600.94921875
bpp_loss 3.739516287285369
15_o proxy err 0.011921072378754616 err 43.25413131713867 tr(WHW.T) 3628.3759765625
bpp_loss 3.134057404997293
15_up proxy err 0.008282913826406002 err 191.05662536621094 tr(WHW.T) 23066.35546875
bpp_loss 3.2067449380492055
15_gate proxy err 0.004695106763392687 err 192.2471923828125 tr(WHW.T) 40946.2890625
bpp_loss 3.2346070606348127
15_down proxy err 0.01131494902074337 err 174.57879638671875 tr(WHW.T) 15429.0400390625
bpp_loss 3.250386894312362
I0403 06:00:05.076010 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.8458020687103271s
I0403 06:00:08.501096 3453165 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:00:08.501194 3453165 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:00:08.501232 3453165 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:00:08.827180 3453165 config.py:54] PyTorch version 2.6.0 available.
W0403 06:00:09.014805 3453165 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:00:09.606924 3453165 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:00:09.610504 3437978 quantize_finetune_llama.py:214] layer 17 gpu 1
I0403 06:00:09.803763 3453165 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:00:11.079934 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 1.0413899421691895s
I0403 06:00:14.494691 3453316 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:00:14.494794 3453316 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:00:14.494832 3453316 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:00:14.818030 3453316 config.py:54] PyTorch version 2.6.0 available.
W0403 06:00:15.007233 3453316 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:00:15.559126 3453316 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:00:15.562676 3437978 quantize_finetune_llama.py:214] layer 18 gpu 0
I0403 06:00:15.814270 3453316 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.01310430932790041 err 52.26983642578125 tr(WHW.T) 3988.751708984375
bpp_loss 3.182661771774292
16_q proxy err 0.0014878635993227363 err 55.147117614746094 tr(WHW.T) 37064.6328125
bpp_loss 3.656905865238514
16_k proxy err 0.0009272455354221165 err 55.61479568481445 tr(WHW.T) 59978.5
bpp_loss 3.6993540434050374
16_o proxy err 0.010571430437266827 err 49.63524627685547 tr(WHW.T) 4695.22509765625
bpp_loss 3.142901391896885
16_up proxy err 0.0081187067553401 err 191.63075256347656 tr(WHW.T) 23603.60546875
bpp_loss 3.202407720736986
16_gate proxy err 0.004574546590447426 err 192.9302978515625 tr(WHW.T) 42174.73828125
bpp_loss 3.2398957410004248
16_down proxy err 0.011574037373065948 err 176.25518798828125 tr(WHW.T) 15228.4970703125
bpp_loss 3.2484085350838856
17_v proxy err 0.012989049777388573 err 55.3828010559082 tr(WHW.T) 4263.80712890625
bpp_loss 3.1622151865740307
17_q proxy err 0.0016042602946981788 err 58.38343811035156 tr(WHW.T) 36392.74609375
bpp_loss 3.6252983379526995
17_k proxy err 0.0010813638800755143 err 58.81397247314453 tr(WHW.T) 54388.6953125
bpp_loss 3.6598779916530475
17_o proxy err 0.01209558080881834 err 51.98588562011719 tr(WHW.T) 4297.923828125
bpp_loss 3.1477174140745774
17_up proxy err 0.009254880249500275 err 200.0471954345703 tr(WHW.T) 21615.3203125
bpp_loss 3.1946246768672797
17_gate proxy err 0.005001060198992491 err 201.54473876953125 tr(WHW.T) 40300.40234375
bpp_loss 3.248551467996697
17_down proxy err 0.012182717211544514 err 187.04647827148438 tr(WHW.T) 15353.4287109375
bpp_loss 3.2356566198949896
I0403 06:02:12.526591 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.8270695209503174s
I0403 06:02:15.963939 3454752 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:02:15.964031 3454752 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:02:15.964070 3454752 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:02:16.289788 3454752 config.py:54] PyTorch version 2.6.0 available.
W0403 06:02:16.478032 3454752 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:02:17.041880 3454752 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:02:17.045660 3437978 quantize_finetune_llama.py:214] layer 19 gpu 1
I0403 06:02:17.217221 3454752 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:02:18.227142 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 0.7757101058959961s
I0403 06:02:21.800357 3454886 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:02:21.800449 3454886 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:02:21.800487 3454886 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:02:22.177114 3454886 config.py:54] PyTorch version 2.6.0 available.
W0403 06:02:22.371700 3454886 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:02:23.009785 3454886 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:02:23.013914 3437978 quantize_finetune_llama.py:214] layer 20 gpu 0
I0403 06:02:23.225557 3454886 data_utils.py:336] using 256 training seqs, 128 validation seqs
18_v proxy err 0.012647203169763088 err 59.101497650146484 tr(WHW.T) 4673.08837890625
bpp_loss 3.193228247924708
18_q proxy err 0.0017539717955514789 err 61.80610275268555 tr(WHW.T) 35237.796875
bpp_loss 3.5750756355701014
18_k proxy err 0.0012653663288801908 err 62.15379333496094 tr(WHW.T) 49119.20703125
bpp_loss 3.609188685542904
18_o proxy err 0.0106242336332798 err 52.30580139160156 tr(WHW.T) 4923.25390625
bpp_loss 3.190064413822256
18_up proxy err 0.009920254349708557 err 201.38064575195312 tr(WHW.T) 20299.947265625
bpp_loss 3.190230932086706
18_gate proxy err 0.0053324103355407715 err 203.0169219970703 tr(WHW.T) 38072.26171875
bpp_loss 3.2591901561895082
18_down proxy err 0.012020961381494999 err 183.5128631591797 tr(WHW.T) 15266.072265625
bpp_loss 3.244298675032549
19_v proxy err 0.01240752637386322 err 59.41847610473633 tr(WHW.T) 4788.90576171875
bpp_loss 3.1996710054809228
19_q proxy err 0.001885853474959731 err 62.00642776489258 tr(WHW.T) 32879.76953125
bpp_loss 3.5521442171302624
19_k proxy err 0.0012484091566875577 err 62.401432037353516 tr(WHW.T) 49984.76171875
bpp_loss 3.579519630467985
19_o proxy err 0.01139175333082676 err 57.01788330078125 tr(WHW.T) 5005.189453125
bpp_loss 3.184272864542436
19_up proxy err 0.010078967548906803 err 203.31919860839844 tr(WHW.T) 20172.62109375
bpp_loss 3.18956958519858
19_gate proxy err 0.005910167936235666 err 205.0751190185547 tr(WHW.T) 34698.6953125
bpp_loss 3.2632573946097563
19_down proxy err 0.011841384693980217 err 185.87779235839844 tr(WHW.T) 15697.3017578125
bpp_loss 3.245721393459758
I0403 06:04:43.815895 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 1.8981592655181885s
I0403 06:04:48.133728 3456674 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:04:48.133832 3456674 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:04:48.133870 3456674 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:04:48.458755 3456674 config.py:54] PyTorch version 2.6.0 available.
W0403 06:04:48.643695 3456674 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:04:49.199973 3456674 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:04:49.203607 3437978 quantize_finetune_llama.py:214] layer 21 gpu 1
I0403 06:04:49.532659 3456674 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:04:50.425502 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.833214282989502s
I0403 06:04:54.682196 3456823 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:04:54.682371 3456823 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:04:54.682460 3456823 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:04:55.097911 3456823 config.py:54] PyTorch version 2.6.0 available.
W0403 06:04:55.327220 3456823 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:04:55.979487 3456823 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:04:55.983076 3437978 quantize_finetune_llama.py:214] layer 22 gpu 0
I0403 06:04:56.193686 3456823 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.01306451577693224 err 60.69550704956055 tr(WHW.T) 4645.8291015625
bpp_loss 3.2091715245041996
20_q proxy err 0.0018730857409536839 err 63.3388786315918 tr(WHW.T) 33815.2578125
bpp_loss 3.5566134881810285
20_k proxy err 0.0012967216316610575 err 63.733856201171875 tr(WHW.T) 49149.9921875
bpp_loss 3.582787492952775
20_o proxy err 0.008112281560897827 err 55.329166412353516 tr(WHW.T) 6820.419921875
bpp_loss 3.209660646272823
20_up proxy err 0.0098354397341609 err 202.64039611816406 tr(WHW.T) 20603.083984375
bpp_loss 3.1880850599602213
20_gate proxy err 0.005750303156673908 err 204.19314575195312 tr(WHW.T) 35509.98046875
bpp_loss 3.270072426906852
20_down proxy err 0.011555162258446217 err 182.60733032226562 tr(WHW.T) 15803.095703125
bpp_loss 3.2510029176943176
21_v proxy err 0.012796860188245773 err 62.22801208496094 tr(WHW.T) 4862.75634765625
bpp_loss 3.233680197794456
21_q proxy err 0.0021316108759492636 err 64.5058364868164 tr(WHW.T) 30261.54296875
bpp_loss 3.5128211848204955
21_k proxy err 0.0015153584536165 err 64.80950927734375 tr(WHW.T) 42768.43359375
bpp_loss 3.5267187536810525
21_o proxy err 0.010354056023061275 err 66.25823974609375 tr(WHW.T) 6399.25439453125
bpp_loss 3.1955993616138585
21_up proxy err 0.01055043376982212 err 206.3969268798828 tr(WHW.T) 19562.884765625
bpp_loss 3.185702121448378
21_gate proxy err 0.0062588416039943695 err 208.1155548095703 tr(WHW.T) 33251.44921875
bpp_loss 3.2786395289870196
21_down proxy err 0.012103278189897537 err 191.1377716064453 tr(WHW.T) 15792.2314453125
bpp_loss 3.243541262025923
I0403 06:06:53.848603 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 0.9136755466461182s
I0403 06:06:57.617853 3458570 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:06:57.617966 3458570 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:06:57.618008 3458570 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:06:57.989108 3458570 config.py:54] PyTorch version 2.6.0 available.
W0403 06:06:58.210628 3458570 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:06:58.835408 3458570 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:06:58.839720 3437978 quantize_finetune_llama.py:214] layer 23 gpu 1
I0403 06:06:59.217885 3458570 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:07:00.292160 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 1.0575456619262695s
I0403 06:07:03.819430 3458727 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:07:03.819523 3458727 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:07:03.819561 3458727 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:07:04.141591 3458727 config.py:54] PyTorch version 2.6.0 available.
W0403 06:07:04.342304 3458727 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:07:04.890321 3458727 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:07:04.893941 3437978 quantize_finetune_llama.py:214] layer 24 gpu 0
I0403 06:07:05.132992 3458727 data_utils.py:336] using 256 training seqs, 128 validation seqs
22_v proxy err 0.012253058142960072 err 62.636802673339844 tr(WHW.T) 5111.93212890625
bpp_loss 3.2399166377726942
22_q proxy err 0.0020246596541255713 err 64.99848175048828 tr(WHW.T) 32103.412109375
bpp_loss 3.549110467371065
22_k proxy err 0.0014852058375254273 err 65.30410766601562 tr(WHW.T) 43969.734375
bpp_loss 3.5667986482731067
22_o proxy err 0.007946106605231762 err 60.60883331298828 tr(WHW.T) 7627.48828125
bpp_loss 3.2252605713438243
22_up proxy err 0.010712471790611744 err 208.25038146972656 tr(WHW.T) 19439.994140625
bpp_loss 3.184606504648231
22_gate proxy err 0.006415332201868296 err 209.9815216064453 tr(WHW.T) 32731.19921875
bpp_loss 3.286011966855027
22_down proxy err 0.012232407927513123 err 194.18463134765625 tr(WHW.T) 15874.603515625
bpp_loss 3.240147405282356
23_v proxy err 0.011693211272358894 err 66.25992584228516 tr(WHW.T) 5666.529296875
bpp_loss 3.278513766883407
23_q proxy err 0.002421817509457469 err 68.34785461425781 tr(WHW.T) 28221.720703125
bpp_loss 3.5237583167036064
23_k proxy err 0.001786999055184424 err 68.57677459716797 tr(WHW.T) 38375.3828125
bpp_loss 3.5341727202176116
23_o proxy err 0.01033299695700407 err 65.56687927246094 tr(WHW.T) 6345.388671875
bpp_loss 3.267961046018172
23_up proxy err 0.011270590126514435 err 211.3678741455078 tr(WHW.T) 18753.931640625
bpp_loss 3.190294923130856
23_gate proxy err 0.007005674298852682 err 212.97645568847656 tr(WHW.T) 30400.564453125
bpp_loss 3.2856253218338933
23_down proxy err 0.01256859302520752 err 198.79457092285156 tr(WHW.T) 15816.7724609375
bpp_loss 3.246421312740029
I0403 06:09:02.331128 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.8859548568725586s
I0403 06:09:05.842215 3460452 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:09:05.842309 3460452 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:09:05.842348 3460452 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:09:06.161271 3460452 config.py:54] PyTorch version 2.6.0 available.
W0403 06:09:06.358971 3460452 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:09:06.933032 3460452 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:09:06.936540 3437978 quantize_finetune_llama.py:214] layer 25 gpu 1
I0403 06:09:07.151254 3460452 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:09:08.275906 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 0.8865528106689453s
I0403 06:09:11.949419 3460656 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:09:11.949533 3460656 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:09:11.949574 3460656 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:09:12.299381 3460656 config.py:54] PyTorch version 2.6.0 available.
W0403 06:09:12.503899 3460656 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:09:13.182394 3460656 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:09:13.186424 3437978 quantize_finetune_llama.py:214] layer 26 gpu 0
I0403 06:09:13.400437 3460656 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.012153374962508678 err 64.71343994140625 tr(WHW.T) 5324.72998046875
bpp_loss 3.2787734007579274
24_q proxy err 0.002468324964866042 err 66.67284393310547 tr(WHW.T) 27011.373046875
bpp_loss 3.4898230878752656
24_k proxy err 0.0016840059543028474 err 66.95006561279297 tr(WHW.T) 39756.4296875
bpp_loss 3.494204948830884
24_o proxy err 0.00765614677220583 err 61.54481887817383 tr(WHW.T) 8038.615234375
bpp_loss 3.2536777384229936
24_up proxy err 0.011546876281499863 err 213.76727294921875 tr(WHW.T) 18512.99609375
bpp_loss 3.1933566486073093
24_gate proxy err 0.0071395463310182095 err 215.41200256347656 tr(WHW.T) 30171.666015625
bpp_loss 3.288466408675493
24_down proxy err 0.0126855643466115 err 199.87689208984375 tr(WHW.T) 15756.2470703125
bpp_loss 3.252361856790823
25_v proxy err 0.011712364852428436 err 69.42513275146484 tr(WHW.T) 5927.5078125
bpp_loss 3.304366078809835
25_q proxy err 0.0028429969679564238 err 71.19324493408203 tr(WHW.T) 25041.619140625
bpp_loss 3.483809036843013
25_k proxy err 0.0021225211676210165 err 71.38668823242188 tr(WHW.T) 33632.96875
bpp_loss 3.486932386411354
25_o proxy err 0.00992543064057827 err 67.28515625 tr(WHW.T) 6779.06689453125
bpp_loss 3.2709573166212067
25_up proxy err 0.011536063626408577 err 214.84799194335938 tr(WHW.T) 18624.029296875
bpp_loss 3.198989282167235
25_gate proxy err 0.006971282418817282 err 216.48402404785156 tr(WHW.T) 31053.6875
bpp_loss 3.291529288038958
25_down proxy err 0.01208451297134161 err 191.87081909179688 tr(WHW.T) 15877.4140625
bpp_loss 3.2742255090540926
I0403 06:11:10.526419 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.812246561050415s
I0403 06:11:14.012693 3462304 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:11:14.012802 3462304 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:11:14.012845 3462304 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:11:14.370694 3462304 config.py:54] PyTorch version 2.6.0 available.
W0403 06:11:14.581545 3462304 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:11:15.176734 3462304 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:11:15.180472 3437978 quantize_finetune_llama.py:214] layer 27 gpu 1
I0403 06:11:15.404793 3462304 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:11:16.567025 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.9307887554168701s
I0403 06:11:20.196603 3462527 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:11:20.196718 3462527 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:11:20.196760 3462527 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:11:20.591338 3462527 config.py:54] PyTorch version 2.6.0 available.
W0403 06:11:20.801702 3462527 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:11:21.396374 3462527 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:11:21.400509 3437978 quantize_finetune_llama.py:214] layer 28 gpu 0
I0403 06:11:21.654331 3462527 data_utils.py:336] using 256 training seqs, 128 validation seqs
26_v proxy err 0.011466301046311855 err 67.88896942138672 tr(WHW.T) 5920.73828125
bpp_loss 3.333457099972293
26_q proxy err 0.0026035369373857975 err 69.54447937011719 tr(WHW.T) 26711.5390625
bpp_loss 3.4674097766401246
26_k proxy err 0.0018586883088573813 err 69.76326751708984 tr(WHW.T) 37533.6015625
bpp_loss 3.4764321704860777
26_o proxy err 0.005327711347490549 err 52.56351089477539 tr(WHW.T) 9866.05859375
bpp_loss 3.358618194120936
26_up proxy err 0.010814155451953411 err 214.729248046875 tr(WHW.T) 19856.3125
bpp_loss 3.203039577360763
26_gate proxy err 0.006465648300945759 err 216.30393981933594 tr(WHW.T) 33454.33203125
bpp_loss 3.2955627837326635
26_down proxy err 0.012012015096843243 err 185.29177856445312 tr(WHW.T) 15425.537109375
bpp_loss 3.286490981748631
27_v proxy err 0.011067917570471764 err 72.35977935791016 tr(WHW.T) 6537.79541015625
bpp_loss 3.3133576225372963
27_q proxy err 0.0026379458140581846 err 74.23065185546875 tr(WHW.T) 28139.56640625
bpp_loss 3.5028324967133813
27_k proxy err 0.001913377083837986 err 74.388916015625 tr(WHW.T) 38878.3359375
bpp_loss 3.5176395847229287
27_o proxy err 0.007638372015208006 err 55.502685546875 tr(WHW.T) 7266.2978515625
bpp_loss 3.374269689375069
27_up proxy err 0.009760454297065735 err 213.0055694580078 tr(WHW.T) 21823.326171875
bpp_loss 3.2095085954250293
27_gate proxy err 0.006042282562702894 err 214.4466552734375 tr(WHW.T) 35491.0
bpp_loss 3.2973930856516196
27_down proxy err 0.011204448528587818 err 169.4001922607422 tr(WHW.T) 15119.01171875
bpp_loss 3.3132096257190717
I0403 06:13:20.576009 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 0.8088996410369873s
I0403 06:13:24.130463 3464212 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:13:24.130635 3464212 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:13:24.130715 3464212 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:13:24.480599 3464212 config.py:54] PyTorch version 2.6.0 available.
W0403 06:13:24.690141 3464212 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:13:25.308103 3464212 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:13:25.312035 3437978 quantize_finetune_llama.py:214] layer 29 gpu 1
I0403 06:13:25.561571 3464212 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:13:26.843011 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 1.109907627105713s
I0403 06:13:30.653005 3464425 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:13:30.653118 3464425 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:13:30.653161 3464425 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:13:31.076978 3464425 config.py:54] PyTorch version 2.6.0 available.
W0403 06:13:31.299873 3464425 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:13:31.932137 3464425 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:13:31.936359 3437978 quantize_finetune_llama.py:214] layer 30 gpu 0
I0403 06:13:32.169531 3464425 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.010161657817661762 err 71.9192123413086 tr(WHW.T) 7077.5078125
bpp_loss 3.354939020355232
28_q proxy err 0.002718552015721798 err 73.40812683105469 tr(WHW.T) 27002.65625
bpp_loss 3.4562327184830792
28_k proxy err 0.0019750932697206736 err 73.5594482421875 tr(WHW.T) 37243.53125
bpp_loss 3.4735863031237386
28_o proxy err 0.005812249146401882 err 51.63608932495117 tr(WHW.T) 8884.01171875
bpp_loss 3.402757878531702
28_up proxy err 0.008048012852668762 err 210.54542541503906 tr(WHW.T) 26161.169921875
bpp_loss 3.2220374166445676
28_gate proxy err 0.005757586564868689 err 211.84500122070312 tr(WHW.T) 36794.0625
bpp_loss 3.292116694152355
28_down proxy err 0.009863137267529964 err 147.79385375976562 tr(WHW.T) 14984.466796875
bpp_loss 3.3485295091820664
29_v proxy err 0.010507111437618732 err 70.21233367919922 tr(WHW.T) 6682.36328125
bpp_loss 3.3647479529026896
29_q proxy err 0.0026524558197706938 err 71.63236999511719 tr(WHW.T) 27006.056640625
bpp_loss 3.4197420153650455
29_k proxy err 0.001819418277591467 err 71.84762573242188 tr(WHW.T) 39489.33984375
bpp_loss 3.4300280836760066
29_o proxy err 0.005917977541685104 err 62.72493362426758 tr(WHW.T) 10599.048828125
bpp_loss 3.3769043465144932
29_up proxy err 0.006321526598185301 err 207.87779235839844 tr(WHW.T) 32884.11328125
bpp_loss 3.2336293992608094
29_gate proxy err 0.005231088493019342 err 208.94528198242188 tr(WHW.T) 39942.984375
bpp_loss 3.296071195151917
29_down proxy err 0.008491712622344494 err 125.10453796386719 tr(WHW.T) 14732.544921875
bpp_loss 3.3814016951594588
I0403 06:15:34.467464 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 0.8187642097473145s
I0403 06:15:38.152652 3466194 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:15:38.152747 3466194 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:15:38.152787 3466194 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:15:38.516378 3466194 config.py:54] PyTorch version 2.6.0 available.
W0403 06:15:38.720500 3466194 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:15:39.355737 3466194 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:15:39.359596 3437978 quantize_finetune_llama.py:214] layer 31 gpu 1
I0403 06:15:39.560357 3466194 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 06:15:40.700057 3437978 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 0.9425103664398193s
I0403 06:15:44.637195 3466399 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:15:44.637292 3466399 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:15:44.637334 3466399 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:15:45.014362 3466399 config.py:54] PyTorch version 2.6.0 available.
W0403 06:15:45.208968 3466399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 06:15:45.926149 3466399 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 06:15:46.166903 3466399 data_utils.py:336] using 256 training seqs, 128 validation seqs
30_v proxy err 0.00886065699160099 err 72.72406768798828 tr(WHW.T) 8207.525390625
bpp_loss 3.37949750572443
30_q proxy err 0.002586430637165904 err 73.81849670410156 tr(WHW.T) 28540.68359375
bpp_loss 3.4107455301564187
30_k proxy err 0.0019252175698056817 err 74.01545715332031 tr(WHW.T) 38445.2421875
bpp_loss 3.4301268240087666
30_o proxy err 0.0049082497134804726 err 49.88309097290039 tr(WHW.T) 10163.1123046875
bpp_loss 3.4583847416215576
30_up proxy err 0.003735567210242152 err 201.24978637695312 tr(WHW.T) 53873.95703125
bpp_loss 3.2545806948355462
30_gate proxy err 0.0034205385018140078 err 202.38571166992188 tr(WHW.T) 59167.79296875
bpp_loss 3.3271775204081866
30_down proxy err 0.0023013469763100147 err 59.472557067871094 tr(WHW.T) 25842.498046875
bpp_loss 3.460962945313821
31_v proxy err 0.010103074833750725 err 68.09814453125 tr(WHW.T) 6740.33837890625
bpp_loss 3.2574916019802913
31_q proxy err 0.0019136244663968682 err 70.22618865966797 tr(WHW.T) 36698.0
bpp_loss 3.4272433062433265
31_k proxy err 0.0012873333180323243 err 70.53789520263672 tr(WHW.T) 54793.80859375
bpp_loss 3.4819028357742354
31_o proxy err 0.0028331878129392862 err 37.175941467285156 tr(WHW.T) 13121.5947265625
bpp_loss 3.408752617193386
31_up proxy err 0.001955621410161257 err 187.3061065673828 tr(WHW.T) 95778.3046875
bpp_loss 3.306461076230504
31_gate proxy err 0.0019307120237499475 err 188.34181213378906 tr(WHW.T) 97550.4453125
bpp_loss 3.391324198523233
31_down proxy err 0.0006362333078868687 err 23.5576114654541 tr(WHW.T) 37026.6875
bpp_loss 3.5208110265260517
I0403 06:17:53.914408 3468021 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:17:53.914513 3468021 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:17:53.914551 3468021 utils.py:162] NumExpr defaulting to 16 threads.
I0403 06:17:54.286446 3468021 config.py:54] PyTorch version 2.6.0 available.
W0403 06:17:54.488255 3468021 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 06:17:54.593501 3468021 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  4.90it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  5.99it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  6.53it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  6.77it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  6.79it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  6.60it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  6.47it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  6.00it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  6.30it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  5.90it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  5.69it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  5.62it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  5.72it/s]
I0403 06:17:57.670867 3468021 hfize_llama.py:161] loaded layer 0
I0403 06:17:58.592153 3468021 hfize_llama.py:161] loaded layer 1
I0403 06:17:59.402006 3468021 hfize_llama.py:161] loaded layer 2
I0403 06:18:00.164897 3468021 hfize_llama.py:161] loaded layer 3
I0403 06:18:00.912024 3468021 hfize_llama.py:161] loaded layer 4
I0403 06:18:01.623887 3468021 hfize_llama.py:161] loaded layer 5
I0403 06:18:02.341518 3468021 hfize_llama.py:161] loaded layer 6
I0403 06:18:03.056993 3468021 hfize_llama.py:161] loaded layer 7
I0403 06:18:03.976866 3468021 hfize_llama.py:161] loaded layer 8
I0403 06:18:04.740141 3468021 hfize_llama.py:161] loaded layer 9
I0403 06:18:05.619758 3468021 hfize_llama.py:161] loaded layer 10
I0403 06:18:06.470599 3468021 hfize_llama.py:161] loaded layer 11
I0403 06:18:07.364844 3468021 hfize_llama.py:161] loaded layer 12
I0403 06:18:08.229172 3468021 hfize_llama.py:161] loaded layer 13
I0403 06:18:08.999918 3468021 hfize_llama.py:161] loaded layer 14
I0403 06:18:09.797541 3468021 hfize_llama.py:161] loaded layer 15
I0403 06:18:10.734132 3468021 hfize_llama.py:161] loaded layer 16
I0403 06:18:11.593079 3468021 hfize_llama.py:161] loaded layer 17
I0403 06:18:12.436696 3468021 hfize_llama.py:161] loaded layer 18
I0403 06:18:13.268381 3468021 hfize_llama.py:161] loaded layer 19
I0403 06:18:13.967267 3468021 hfize_llama.py:161] loaded layer 20
I0403 06:18:14.677981 3468021 hfize_llama.py:161] loaded layer 21
I0403 06:18:15.364840 3468021 hfize_llama.py:161] loaded layer 22
I0403 06:18:16.129787 3468021 hfize_llama.py:161] loaded layer 23
I0403 06:18:16.923174 3468021 hfize_llama.py:161] loaded layer 24
I0403 06:18:17.836723 3468021 hfize_llama.py:161] loaded layer 25
I0403 06:18:18.868510 3468021 hfize_llama.py:161] loaded layer 26
I0403 06:18:19.918236 3468021 hfize_llama.py:161] loaded layer 27
I0403 06:18:20.984895 3468021 hfize_llama.py:161] loaded layer 28
I0403 06:18:22.012363 3468021 hfize_llama.py:161] loaded layer 29
I0403 06:18:23.027456 3468021 hfize_llama.py:161] loaded layer 30
I0403 06:18:23.962273 3468021 hfize_llama.py:161] loaded layer 31
I0403 06:18:23.962430 3468021 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:07,  1.50s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.22s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.06s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.02s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]
I0403 06:19:16.106248 3468021 hfize_llama.py:175] successfully loaded hfized model
I0403 06:19:20.596047 3469241 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 06:19:20.596166 3469241 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 06:19:20.596210 3469241 utils.py:162] NumExpr defaulting to 16 threads.
W0403 06:19:20.958772 3469241 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 06:19:21.344985 3469241 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.04it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.02it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.04it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.21it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]
I0403 06:19:26.817690 3469241 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.4101845026016235:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.4101845026016235:   1%|          | 1/166 [00:01<04:25,  1.61s/it]avg_loss = 1.673140287399292:   1%|          | 1/166 [00:02<04:25,  1.61s/it] avg_loss = 1.673140287399292:   1%|          | 2/166 [00:02<03:43,  1.36s/it]avg_loss = 1.8418428897857666:   1%|          | 2/166 [00:03<03:43,  1.36s/it]avg_loss = 1.8418428897857666:   2%|▏         | 3/166 [00:03<03:29,  1.28s/it]avg_loss = 1.875976711511612:   2%|▏         | 3/166 [00:05<03:29,  1.28s/it] avg_loss = 1.875976711511612:   2%|▏         | 4/166 [00:05<03:22,  1.25s/it]avg_loss = 1.80555899143219:   2%|▏         | 4/166 [00:06<03:22,  1.25s/it] avg_loss = 1.80555899143219:   3%|▎         | 5/166 [00:06<03:18,  1.23s/it]avg_loss = 1.7819517850875854:   3%|▎         | 5/166 [00:07<03:18,  1.23s/it]avg_loss = 1.7819517850875854:   4%|▎         | 6/166 [00:07<03:15,  1.22s/it]avg_loss = 1.7211282082966395:   4%|▎         | 6/166 [00:08<03:15,  1.22s/it]avg_loss = 1.7211282082966395:   4%|▍         | 7/166 [00:08<03:13,  1.22s/it]avg_loss = 1.663828656077385:   4%|▍         | 7/166 [00:09<03:13,  1.22s/it] avg_loss = 1.663828656077385:   5%|▍         | 8/166 [00:09<03:11,  1.21s/it]avg_loss = 1.6583441495895386:   5%|▍         | 8/166 [00:11<03:11,  1.21s/it]avg_loss = 1.6583441495895386:   5%|▌         | 9/166 [00:11<03:10,  1.21s/it]avg_loss = 1.6630606293678283:   5%|▌         | 9/166 [00:12<03:10,  1.21s/it]avg_loss = 1.6630606293678283:   6%|▌         | 10/166 [00:12<03:08,  1.21s/it]avg_loss = 1.67868219722401:   6%|▌         | 10/166 [00:13<03:08,  1.21s/it]  avg_loss = 1.67868219722401:   7%|▋         | 11/166 [00:13<03:07,  1.21s/it]avg_loss = 1.687502791484197:   7%|▋         | 11/166 [00:14<03:07,  1.21s/it]avg_loss = 1.687502791484197:   7%|▋         | 12/166 [00:14<03:06,  1.21s/it]avg_loss = 1.68257802266341:   7%|▋         | 12/166 [00:16<03:06,  1.21s/it] avg_loss = 1.68257802266341:   8%|▊         | 13/166 [00:16<03:06,  1.22s/it]avg_loss = 1.6939905796732222:   8%|▊         | 13/166 [00:17<03:06,  1.22s/it]avg_loss = 1.6939905796732222:   8%|▊         | 14/166 [00:17<03:05,  1.22s/it]avg_loss = 1.7117128531138102:   8%|▊         | 14/166 [00:18<03:05,  1.22s/it]avg_loss = 1.7117128531138102:   9%|▉         | 15/166 [00:18<03:04,  1.22s/it]avg_loss = 1.7312396466732025:   9%|▉         | 15/166 [00:19<03:04,  1.22s/it]avg_loss = 1.7312396466732025:  10%|▉         | 16/166 [00:19<03:03,  1.22s/it]avg_loss = 1.744972502484041:  10%|▉         | 16/166 [00:20<03:03,  1.22s/it] avg_loss = 1.744972502484041:  10%|█         | 17/166 [00:20<03:02,  1.22s/it]avg_loss = 1.7598730656835768:  10%|█         | 17/166 [00:22<03:02,  1.22s/it]avg_loss = 1.7598730656835768:  11%|█         | 18/166 [00:22<03:01,  1.23s/it]avg_loss = 1.7798087032217729:  11%|█         | 18/166 [00:23<03:01,  1.23s/it]avg_loss = 1.7798087032217729:  11%|█▏        | 19/166 [00:23<03:00,  1.23s/it]avg_loss = 1.7866568505764007:  11%|█▏        | 19/166 [00:24<03:00,  1.23s/it]avg_loss = 1.7866568505764007:  12%|█▏        | 20/166 [00:24<02:59,  1.23s/it]avg_loss = 1.787723387990679:  12%|█▏        | 20/166 [00:25<02:59,  1.23s/it] avg_loss = 1.787723387990679:  13%|█▎        | 21/166 [00:25<02:58,  1.23s/it]avg_loss = 1.7783598899841309:  13%|█▎        | 21/166 [00:27<02:58,  1.23s/it]avg_loss = 1.7783598899841309:  13%|█▎        | 22/166 [00:27<02:57,  1.23s/it]avg_loss = 1.7684858363607656:  13%|█▎        | 22/166 [00:28<02:57,  1.23s/it]avg_loss = 1.7684858363607656:  14%|█▍        | 23/166 [00:28<02:56,  1.23s/it]avg_loss = 1.7757158031066258:  14%|█▍        | 23/166 [00:29<02:56,  1.23s/it]avg_loss = 1.7757158031066258:  14%|█▍        | 24/166 [00:29<02:55,  1.24s/it]avg_loss = 1.7832277774810792:  14%|█▍        | 24/166 [00:30<02:55,  1.24s/it]avg_loss = 1.7832277774810792:  15%|█▌        | 25/166 [00:30<02:54,  1.24s/it]avg_loss = 1.787151405444512:  15%|█▌        | 25/166 [00:32<02:54,  1.24s/it] avg_loss = 1.787151405444512:  16%|█▌        | 26/166 [00:32<02:53,  1.24s/it]avg_loss = 1.7935303405479148:  16%|█▌        | 26/166 [00:33<02:53,  1.24s/it]avg_loss = 1.7935303405479148:  16%|█▋        | 27/166 [00:33<02:52,  1.24s/it]avg_loss = 1.7966382886682237:  16%|█▋        | 27/166 [00:34<02:52,  1.24s/it]avg_loss = 1.7966382886682237:  17%|█▋        | 28/166 [00:34<02:51,  1.24s/it]avg_loss = 1.8065457302948524:  17%|█▋        | 28/166 [00:35<02:51,  1.24s/it]avg_loss = 1.8065457302948524:  17%|█▋        | 29/166 [00:35<02:50,  1.24s/it]avg_loss = 1.806820313135783:  17%|█▋        | 29/166 [00:37<02:50,  1.24s/it] avg_loss = 1.806820313135783:  18%|█▊        | 30/166 [00:37<02:49,  1.25s/it]avg_loss = 1.8205626703077746:  18%|█▊        | 30/166 [00:38<02:49,  1.25s/it]avg_loss = 1.8205626703077746:  19%|█▊        | 31/166 [00:38<02:48,  1.25s/it]avg_loss = 1.8269875049591064:  19%|█▊        | 31/166 [00:39<02:48,  1.25s/it]avg_loss = 1.8269875049591064:  19%|█▉        | 32/166 [00:39<02:47,  1.25s/it]avg_loss = 1.8319220001047307:  19%|█▉        | 32/166 [00:40<02:47,  1.25s/it]avg_loss = 1.8319220001047307:  20%|█▉        | 33/166 [00:40<02:46,  1.25s/it]avg_loss = 1.8307106179349564:  20%|█▉        | 33/166 [00:42<02:46,  1.25s/it]avg_loss = 1.8307106179349564:  20%|██        | 34/166 [00:42<02:45,  1.25s/it]avg_loss = 1.8246105807168143:  20%|██        | 34/166 [00:43<02:45,  1.25s/it]avg_loss = 1.8246105807168143:  21%|██        | 35/166 [00:43<02:44,  1.25s/it]avg_loss = 1.8168312940332625:  21%|██        | 35/166 [00:44<02:44,  1.25s/it]avg_loss = 1.8168312940332625:  22%|██▏       | 36/166 [00:44<02:43,  1.26s/it]avg_loss = 1.8076413289920703:  22%|██▏       | 36/166 [00:45<02:43,  1.26s/it]avg_loss = 1.8076413289920703:  22%|██▏       | 37/166 [00:45<02:42,  1.26s/it]avg_loss = 1.804833318057813:  22%|██▏       | 37/166 [00:47<02:42,  1.26s/it] avg_loss = 1.804833318057813:  23%|██▎       | 38/166 [00:47<02:41,  1.26s/it]avg_loss = 1.8027453330846934:  23%|██▎       | 38/166 [00:48<02:41,  1.26s/it]avg_loss = 1.8027453330846934:  23%|██▎       | 39/166 [00:48<02:40,  1.26s/it]avg_loss = 1.805724811553955:  23%|██▎       | 39/166 [00:49<02:40,  1.26s/it] avg_loss = 1.805724811553955:  24%|██▍       | 40/166 [00:49<02:38,  1.26s/it]avg_loss = 1.805792261914509:  24%|██▍       | 40/166 [00:50<02:38,  1.26s/it]avg_loss = 1.805792261914509:  25%|██▍       | 41/166 [00:50<02:37,  1.26s/it]avg_loss = 1.793214187735603:  25%|██▍       | 41/166 [00:52<02:37,  1.26s/it]avg_loss = 1.793214187735603:  25%|██▌       | 42/166 [00:52<02:36,  1.26s/it]avg_loss = 1.7774363922518353:  25%|██▌       | 42/166 [00:53<02:36,  1.26s/it]avg_loss = 1.7774363922518353:  26%|██▌       | 43/166 [00:53<02:35,  1.26s/it]avg_loss = 1.7668119723146611:  26%|██▌       | 43/166 [00:54<02:35,  1.26s/it]avg_loss = 1.7668119723146611:  27%|██▋       | 44/166 [00:54<02:34,  1.27s/it]avg_loss = 1.7529341220855712:  27%|██▋       | 44/166 [00:56<02:34,  1.27s/it]avg_loss = 1.7529341220855712:  27%|██▋       | 45/166 [00:56<02:33,  1.27s/it]avg_loss = 1.7424763700236445:  27%|██▋       | 45/166 [00:57<02:33,  1.27s/it]avg_loss = 1.7424763700236445:  28%|██▊       | 46/166 [00:57<02:32,  1.27s/it]avg_loss = 1.7354154155609456:  28%|██▊       | 46/166 [00:58<02:32,  1.27s/it]avg_loss = 1.7354154155609456:  28%|██▊       | 47/166 [00:58<02:31,  1.27s/it]avg_loss = 1.7364217390616734:  28%|██▊       | 47/166 [00:59<02:31,  1.27s/it]avg_loss = 1.7364217390616734:  29%|██▉       | 48/166 [00:59<02:30,  1.27s/it]avg_loss = 1.7469004708893445:  29%|██▉       | 48/166 [01:01<02:30,  1.27s/it]avg_loss = 1.7469004708893445:  30%|██▉       | 49/166 [01:01<02:29,  1.27s/it]avg_loss = 1.7572290658950807:  30%|██▉       | 49/166 [01:02<02:29,  1.27s/it]avg_loss = 1.7572290658950807:  30%|███       | 50/166 [01:02<02:27,  1.28s/it]avg_loss = 1.7641085035660689:  30%|███       | 50/166 [01:03<02:27,  1.28s/it]avg_loss = 1.7641085035660689:  31%|███       | 51/166 [01:03<02:26,  1.28s/it]avg_loss = 1.7690992813843947:  31%|███       | 51/166 [01:04<02:26,  1.28s/it]avg_loss = 1.7690992813843947:  31%|███▏      | 52/166 [01:04<02:25,  1.28s/it]avg_loss = 1.7725619100174814:  31%|███▏      | 52/166 [01:06<02:25,  1.28s/it]avg_loss = 1.7725619100174814:  32%|███▏      | 53/166 [01:06<02:24,  1.28s/it]avg_loss = 1.7733878382930048:  32%|███▏      | 53/166 [01:07<02:24,  1.28s/it]avg_loss = 1.7733878382930048:  33%|███▎      | 54/166 [01:07<02:23,  1.28s/it]avg_loss = 1.7757003285668114:  33%|███▎      | 54/166 [01:08<02:23,  1.28s/it]avg_loss = 1.7757003285668114:  33%|███▎      | 55/166 [01:08<02:22,  1.28s/it]avg_loss = 1.7789656200579234:  33%|███▎      | 55/166 [01:10<02:22,  1.28s/it]avg_loss = 1.7789656200579234:  34%|███▎      | 56/166 [01:10<02:20,  1.28s/it]avg_loss = 1.773924472039206:  34%|███▎      | 56/166 [01:11<02:20,  1.28s/it] avg_loss = 1.773924472039206:  34%|███▍      | 57/166 [01:11<02:19,  1.28s/it]avg_loss = 1.7776468663380063:  34%|███▍      | 57/166 [01:12<02:19,  1.28s/it]avg_loss = 1.7776468663380063:  35%|███▍      | 58/166 [01:12<02:18,  1.28s/it]avg_loss = 1.775790824728497:  35%|███▍      | 58/166 [01:13<02:18,  1.28s/it] avg_loss = 1.775790824728497:  36%|███▌      | 59/166 [01:13<02:17,  1.28s/it]avg_loss = 1.7710389991601307:  36%|███▌      | 59/166 [01:15<02:17,  1.28s/it]avg_loss = 1.7710389991601307:  36%|███▌      | 60/166 [01:15<02:16,  1.28s/it]avg_loss = 1.7665554245964425:  36%|███▌      | 60/166 [01:16<02:16,  1.28s/it]avg_loss = 1.7665554245964425:  37%|███▋      | 61/166 [01:16<02:14,  1.28s/it]avg_loss = 1.7625487850558372:  37%|███▋      | 61/166 [01:17<02:14,  1.28s/it]avg_loss = 1.7625487850558372:  37%|███▋      | 62/166 [01:17<02:13,  1.29s/it]avg_loss = 1.756791279429481:  37%|███▋      | 62/166 [01:19<02:13,  1.29s/it] avg_loss = 1.756791279429481:  38%|███▊      | 63/166 [01:19<02:12,  1.29s/it]avg_loss = 1.7525051701813936:  38%|███▊      | 63/166 [01:20<02:12,  1.29s/it]avg_loss = 1.7525051701813936:  39%|███▊      | 64/166 [01:20<02:11,  1.29s/it]avg_loss = 1.7457894820433397:  39%|███▊      | 64/166 [01:21<02:11,  1.29s/it]avg_loss = 1.7457894820433397:  39%|███▉      | 65/166 [01:21<02:10,  1.29s/it]avg_loss = 1.7385160543701865:  39%|███▉      | 65/166 [01:22<02:10,  1.29s/it]avg_loss = 1.7385160543701865:  40%|███▉      | 66/166 [01:22<02:08,  1.29s/it]avg_loss = 1.7334803342819214:  40%|███▉      | 66/166 [01:24<02:08,  1.29s/it]avg_loss = 1.7334803342819214:  40%|████      | 67/166 [01:24<02:07,  1.29s/it]avg_loss = 1.732473778374055:  40%|████      | 67/166 [01:25<02:07,  1.29s/it] avg_loss = 1.732473778374055:  41%|████      | 68/166 [01:25<02:06,  1.29s/it]avg_loss = 1.7346800634826438:  41%|████      | 68/166 [01:26<02:06,  1.29s/it]avg_loss = 1.7346800634826438:  42%|████▏     | 69/166 [01:26<02:05,  1.29s/it]avg_loss = 1.7378893715994699:  42%|████▏     | 69/166 [01:28<02:05,  1.29s/it]avg_loss = 1.7378893715994699:  42%|████▏     | 70/166 [01:28<02:03,  1.29s/it]avg_loss = 1.741620318990358:  42%|████▏     | 70/166 [01:29<02:03,  1.29s/it] avg_loss = 1.741620318990358:  43%|████▎     | 71/166 [01:29<02:02,  1.29s/it]avg_loss = 1.746616691350937:  43%|████▎     | 71/166 [01:30<02:02,  1.29s/it]avg_loss = 1.746616691350937:  43%|████▎     | 72/166 [01:30<02:01,  1.29s/it]avg_loss = 1.7528117486875352:  43%|████▎     | 72/166 [01:31<02:01,  1.29s/it]avg_loss = 1.7528117486875352:  44%|████▍     | 73/166 [01:31<02:00,  1.29s/it]avg_loss = 1.747293821863226:  44%|████▍     | 73/166 [01:33<02:00,  1.29s/it] avg_loss = 1.747293821863226:  45%|████▍     | 74/166 [01:33<01:59,  1.29s/it]avg_loss = 1.7428955380121867:  45%|████▍     | 74/166 [01:34<01:59,  1.29s/it]avg_loss = 1.7428955380121867:  45%|████▌     | 75/166 [01:34<01:57,  1.30s/it]avg_loss = 1.7421564365688122:  45%|████▌     | 75/166 [01:35<01:57,  1.30s/it]avg_loss = 1.7421564365688122:  46%|████▌     | 76/166 [01:35<01:56,  1.30s/it]avg_loss = 1.7386898591920927:  46%|████▌     | 76/166 [01:37<01:56,  1.30s/it]avg_loss = 1.7386898591920927:  46%|████▋     | 77/166 [01:37<01:55,  1.30s/it]avg_loss = 1.7351240087778141:  46%|████▋     | 77/166 [01:38<01:55,  1.30s/it]avg_loss = 1.7351240087778141:  47%|████▋     | 78/166 [01:38<01:54,  1.30s/it]avg_loss = 1.7324624257751657:  47%|████▋     | 78/166 [01:39<01:54,  1.30s/it]avg_loss = 1.7324624257751657:  48%|████▊     | 79/166 [01:39<01:53,  1.30s/it]avg_loss = 1.7290051206946373:  48%|████▊     | 79/166 [01:41<01:53,  1.30s/it]avg_loss = 1.7290051206946373:  48%|████▊     | 80/166 [01:41<01:51,  1.30s/it]avg_loss = 1.7199896507793002:  48%|████▊     | 80/166 [01:42<01:51,  1.30s/it]avg_loss = 1.7199896507793002:  49%|████▉     | 81/166 [01:42<01:50,  1.30s/it]avg_loss = 1.7214899840878277:  49%|████▉     | 81/166 [01:43<01:50,  1.30s/it]avg_loss = 1.7214899840878277:  49%|████▉     | 82/166 [01:43<01:49,  1.30s/it]avg_loss = 1.723447110997625:  49%|████▉     | 82/166 [01:44<01:49,  1.30s/it] avg_loss = 1.723447110997625:  50%|█████     | 83/166 [01:44<01:47,  1.30s/it]avg_loss = 1.7265934922865458:  50%|█████     | 83/166 [01:46<01:47,  1.30s/it]avg_loss = 1.7265934922865458:  51%|█████     | 84/166 [01:46<01:46,  1.30s/it]avg_loss = 1.7285370693487279:  51%|█████     | 84/166 [01:47<01:46,  1.30s/it]avg_loss = 1.7285370693487279:  51%|█████     | 85/166 [01:47<01:45,  1.30s/it]avg_loss = 1.7274117615333824:  51%|█████     | 85/166 [01:48<01:45,  1.30s/it]avg_loss = 1.7274117615333824:  52%|█████▏    | 86/166 [01:48<01:43,  1.30s/it]avg_loss = 1.727634140129747:  52%|█████▏    | 86/166 [01:50<01:43,  1.30s/it] avg_loss = 1.727634140129747:  52%|█████▏    | 87/166 [01:50<01:42,  1.30s/it]avg_loss = 1.727697080509229:  52%|█████▏    | 87/166 [01:51<01:42,  1.30s/it]avg_loss = 1.727697080509229:  53%|█████▎    | 88/166 [01:51<01:41,  1.30s/it]avg_loss = 1.7287692427635193:  53%|█████▎    | 88/166 [01:52<01:41,  1.30s/it]avg_loss = 1.7287692427635193:  54%|█████▎    | 89/166 [01:52<01:40,  1.30s/it]avg_loss = 1.7286938448747:  54%|█████▎    | 89/166 [01:54<01:40,  1.30s/it]   avg_loss = 1.7286938448747:  54%|█████▍    | 90/166 [01:54<01:38,  1.30s/it]avg_loss = 1.7291239480395892:  54%|█████▍    | 90/166 [01:55<01:38,  1.30s/it]avg_loss = 1.7291239480395892:  55%|█████▍    | 91/166 [01:55<01:37,  1.30s/it]avg_loss = 1.7302317068628643:  55%|█████▍    | 91/166 [01:56<01:37,  1.30s/it]avg_loss = 1.7302317068628643:  55%|█████▌    | 92/166 [01:56<01:36,  1.30s/it]avg_loss = 1.7342009409781425:  55%|█████▌    | 92/166 [01:58<01:36,  1.30s/it]avg_loss = 1.7342009409781425:  56%|█████▌    | 93/166 [01:58<01:35,  1.30s/it]avg_loss = 1.7331276212600952:  56%|█████▌    | 93/166 [01:59<01:35,  1.30s/it]avg_loss = 1.7331276212600952:  57%|█████▋    | 94/166 [01:59<01:33,  1.30s/it]avg_loss = 1.7322906688639992:  57%|█████▋    | 94/166 [02:00<01:33,  1.30s/it]avg_loss = 1.7322906688639992:  57%|█████▋    | 95/166 [02:00<01:32,  1.31s/it]avg_loss = 1.7318673487752676:  57%|█████▋    | 95/166 [02:01<01:32,  1.31s/it]avg_loss = 1.7318673487752676:  58%|█████▊    | 96/166 [02:01<01:31,  1.31s/it]avg_loss = 1.731751547031796:  58%|█████▊    | 96/166 [02:03<01:31,  1.31s/it] avg_loss = 1.731751547031796:  58%|█████▊    | 97/166 [02:03<01:30,  1.30s/it]avg_loss = 1.7301251602416137:  58%|█████▊    | 97/166 [02:04<01:30,  1.30s/it]avg_loss = 1.7301251602416137:  59%|█████▉    | 98/166 [02:04<01:28,  1.31s/it]avg_loss = 1.7277510184230227:  59%|█████▉    | 98/166 [02:05<01:28,  1.31s/it]avg_loss = 1.7277510184230227:  60%|█████▉    | 99/166 [02:05<01:27,  1.31s/it]avg_loss = 1.7251276332139969:  60%|█████▉    | 99/166 [02:07<01:27,  1.31s/it]avg_loss = 1.7251276332139969:  60%|██████    | 100/166 [02:07<01:26,  1.31s/it]avg_loss = 1.7255247494961956:  60%|██████    | 100/166 [02:08<01:26,  1.31s/it]avg_loss = 1.7255247494961956:  61%|██████    | 101/166 [02:08<01:24,  1.31s/it]avg_loss = 1.7264804074577256:  61%|██████    | 101/166 [02:09<01:24,  1.31s/it]avg_loss = 1.7264804074577256:  61%|██████▏   | 102/166 [02:09<01:23,  1.31s/it]avg_loss = 1.7276496545782367:  61%|██████▏   | 102/166 [02:11<01:23,  1.31s/it]avg_loss = 1.7276496545782367:  62%|██████▏   | 103/166 [02:11<01:22,  1.31s/it]avg_loss = 1.7298257368115277:  62%|██████▏   | 103/166 [02:12<01:22,  1.31s/it]avg_loss = 1.7298257368115277:  63%|██████▎   | 104/166 [02:12<01:21,  1.31s/it]avg_loss = 1.7363499340556916:  63%|██████▎   | 104/166 [02:13<01:21,  1.31s/it]avg_loss = 1.7363499340556916:  63%|██████▎   | 105/166 [02:13<01:19,  1.31s/it]avg_loss = 1.7416099934083111:  63%|██████▎   | 105/166 [02:14<01:19,  1.31s/it]avg_loss = 1.7416099934083111:  64%|██████▍   | 106/166 [02:14<01:18,  1.31s/it]avg_loss = 1.7452471985995213:  64%|██████▍   | 106/166 [02:16<01:18,  1.31s/it]avg_loss = 1.7452471985995213:  64%|██████▍   | 107/166 [02:16<01:17,  1.31s/it]avg_loss = 1.7483447011974123:  64%|██████▍   | 107/166 [02:17<01:17,  1.31s/it]avg_loss = 1.7483447011974123:  65%|██████▌   | 108/166 [02:17<01:15,  1.31s/it]avg_loss = 1.7531107932055763:  65%|██████▌   | 108/166 [02:18<01:15,  1.31s/it]avg_loss = 1.7531107932055763:  66%|██████▌   | 109/166 [02:18<01:14,  1.31s/it]avg_loss = 1.756636064160954:  66%|██████▌   | 109/166 [02:20<01:14,  1.31s/it] avg_loss = 1.756636064160954:  66%|██████▋   | 110/166 [02:20<01:13,  1.31s/it]avg_loss = 1.7580477745683343:  66%|██████▋   | 110/166 [02:21<01:13,  1.31s/it]avg_loss = 1.7580477745683343:  67%|██████▋   | 111/166 [02:21<01:11,  1.31s/it]avg_loss = 1.75924303861601:  67%|██████▋   | 111/166 [02:22<01:11,  1.31s/it]  avg_loss = 1.75924303861601:  67%|██████▋   | 112/166 [02:22<01:10,  1.31s/it]avg_loss = 1.7596027160112837:  67%|██████▋   | 112/166 [02:24<01:10,  1.31s/it]avg_loss = 1.7596027160112837:  68%|██████▊   | 113/166 [02:24<01:09,  1.31s/it]avg_loss = 1.7609710886813046:  68%|██████▊   | 113/166 [02:25<01:09,  1.31s/it]avg_loss = 1.7609710886813046:  69%|██████▊   | 114/166 [02:25<01:08,  1.31s/it]avg_loss = 1.7581097856811856:  69%|██████▊   | 114/166 [02:26<01:08,  1.31s/it]avg_loss = 1.7581097856811856:  69%|██████▉   | 115/166 [02:26<01:06,  1.31s/it]avg_loss = 1.7575940001627495:  69%|██████▉   | 115/166 [02:28<01:06,  1.31s/it]avg_loss = 1.7575940001627495:  70%|██████▉   | 116/166 [02:28<01:05,  1.31s/it]avg_loss = 1.7586404324596763:  70%|██████▉   | 116/166 [02:29<01:05,  1.31s/it]avg_loss = 1.7586404324596763:  70%|███████   | 117/166 [02:29<01:04,  1.31s/it]avg_loss = 1.7588582730899422:  70%|███████   | 117/166 [02:30<01:04,  1.31s/it]avg_loss = 1.7588582730899422:  71%|███████   | 118/166 [02:30<01:02,  1.31s/it]avg_loss = 1.7584128324725048:  71%|███████   | 118/166 [02:32<01:02,  1.31s/it]avg_loss = 1.7584128324725048:  72%|███████▏  | 119/166 [02:32<01:01,  1.31s/it]avg_loss = 1.7590863063931466:  72%|███████▏  | 119/166 [02:33<01:01,  1.31s/it]avg_loss = 1.7590863063931466:  72%|███████▏  | 120/166 [02:33<01:00,  1.31s/it]avg_loss = 1.7585533793307533:  72%|███████▏  | 120/166 [02:34<01:00,  1.31s/it]avg_loss = 1.7585533793307533:  73%|███████▎  | 121/166 [02:34<00:59,  1.31s/it]avg_loss = 1.7590012437984592:  73%|███████▎  | 121/166 [02:35<00:59,  1.31s/it]avg_loss = 1.7590012437984592:  73%|███████▎  | 122/166 [02:35<00:57,  1.31s/it]avg_loss = 1.759330927356472:  73%|███████▎  | 122/166 [02:37<00:57,  1.31s/it] avg_loss = 1.759330927356472:  74%|███████▍  | 123/166 [02:37<00:56,  1.31s/it]avg_loss = 1.7578997732170167:  74%|███████▍  | 123/166 [02:38<00:56,  1.31s/it]avg_loss = 1.7578997732170167:  75%|███████▍  | 124/166 [02:38<00:55,  1.31s/it]avg_loss = 1.7562340998649597:  75%|███████▍  | 124/166 [02:39<00:55,  1.31s/it]avg_loss = 1.7562340998649597:  75%|███████▌  | 125/166 [02:39<00:53,  1.31s/it]avg_loss = 1.7540869225585272:  75%|███████▌  | 125/166 [02:41<00:53,  1.31s/it]avg_loss = 1.7540869225585272:  76%|███████▌  | 126/166 [02:41<00:52,  1.31s/it]avg_loss = 1.7519798752829785:  76%|███████▌  | 126/166 [02:42<00:52,  1.31s/it]avg_loss = 1.7519798752829785:  77%|███████▋  | 127/166 [02:42<00:51,  1.31s/it]avg_loss = 1.750626692082733:  77%|███████▋  | 127/166 [02:43<00:51,  1.31s/it] avg_loss = 1.750626692082733:  77%|███████▋  | 128/166 [02:43<00:49,  1.31s/it]avg_loss = 1.749396445677262:  77%|███████▋  | 128/166 [02:45<00:49,  1.31s/it]avg_loss = 1.749396445677262:  78%|███████▊  | 129/166 [02:45<00:48,  1.31s/it]avg_loss = 1.7492760286881373:  78%|███████▊  | 129/166 [02:46<00:48,  1.31s/it]avg_loss = 1.7492760286881373:  78%|███████▊  | 130/166 [02:46<00:47,  1.31s/it]avg_loss = 1.7503097953687188:  78%|███████▊  | 130/166 [02:47<00:47,  1.31s/it]avg_loss = 1.7503097953687188:  79%|███████▉  | 131/166 [02:47<00:45,  1.31s/it]avg_loss = 1.7509512363961248:  79%|███████▉  | 131/166 [02:49<00:45,  1.31s/it]avg_loss = 1.7509512363961248:  80%|███████▉  | 132/166 [02:49<00:44,  1.31s/it]avg_loss = 1.7519463941566926:  80%|███████▉  | 132/166 [02:50<00:44,  1.31s/it]avg_loss = 1.7519463941566926:  80%|████████  | 133/166 [02:50<00:43,  1.31s/it]avg_loss = 1.7532897320256304:  80%|████████  | 133/166 [02:51<00:43,  1.31s/it]avg_loss = 1.7532897320256304:  81%|████████  | 134/166 [02:51<00:42,  1.31s/it]avg_loss = 1.7511793088029932:  81%|████████  | 134/166 [02:53<00:42,  1.31s/it]avg_loss = 1.7511793088029932:  81%|████████▏ | 135/166 [02:53<00:40,  1.31s/it]avg_loss = 1.7514884818126173:  81%|████████▏ | 135/166 [02:54<00:40,  1.31s/it]avg_loss = 1.7514884818126173:  82%|████████▏ | 136/166 [02:54<00:39,  1.31s/it]avg_loss = 1.7518428733749112:  82%|████████▏ | 136/166 [02:55<00:39,  1.31s/it]avg_loss = 1.7518428733749112:  83%|████████▎ | 137/166 [02:55<00:38,  1.32s/it]avg_loss = 1.7526411599871041:  83%|████████▎ | 137/166 [02:56<00:38,  1.32s/it]avg_loss = 1.7526411599871041:  83%|████████▎ | 138/166 [02:56<00:36,  1.32s/it]avg_loss = 1.7516563680532167:  83%|████████▎ | 138/166 [02:58<00:36,  1.32s/it]avg_loss = 1.7516563680532167:  84%|████████▎ | 139/166 [02:58<00:35,  1.32s/it]avg_loss = 1.7503052877528327:  84%|████████▎ | 139/166 [02:59<00:35,  1.32s/it]avg_loss = 1.7503052877528327:  84%|████████▍ | 140/166 [02:59<00:34,  1.32s/it]avg_loss = 1.7488627624004445:  84%|████████▍ | 140/166 [03:00<00:34,  1.32s/it]avg_loss = 1.7488627624004445:  85%|████████▍ | 141/166 [03:00<00:32,  1.32s/it]avg_loss = 1.7485055079762364:  85%|████████▍ | 141/166 [03:02<00:32,  1.32s/it]avg_loss = 1.7485055079762364:  86%|████████▌ | 142/166 [03:02<00:31,  1.31s/it]avg_loss = 1.7468662908027222:  86%|████████▌ | 142/166 [03:03<00:31,  1.31s/it]avg_loss = 1.7468662908027222:  86%|████████▌ | 143/166 [03:03<00:30,  1.31s/it]avg_loss = 1.7479767348203394:  86%|████████▌ | 143/166 [03:04<00:30,  1.31s/it]avg_loss = 1.7479767348203394:  87%|████████▋ | 144/166 [03:04<00:28,  1.31s/it]avg_loss = 1.7472147493526853:  87%|████████▋ | 144/166 [03:06<00:28,  1.31s/it]avg_loss = 1.7472147493526853:  87%|████████▋ | 145/166 [03:06<00:27,  1.31s/it]avg_loss = 1.747115092326517:  87%|████████▋ | 145/166 [03:07<00:27,  1.31s/it] avg_loss = 1.747115092326517:  88%|████████▊ | 146/166 [03:07<00:26,  1.31s/it]avg_loss = 1.7459600697569295:  88%|████████▊ | 146/166 [03:08<00:26,  1.31s/it]avg_loss = 1.7459600697569295:  89%|████████▊ | 147/166 [03:08<00:24,  1.31s/it]avg_loss = 1.7450507222800642:  89%|████████▊ | 147/166 [03:10<00:24,  1.31s/it]avg_loss = 1.7450507222800642:  89%|████████▉ | 148/166 [03:10<00:23,  1.31s/it]avg_loss = 1.7433059387559058:  89%|████████▉ | 148/166 [03:11<00:23,  1.31s/it]avg_loss = 1.7433059387559058:  90%|████████▉ | 149/166 [03:11<00:22,  1.32s/it]avg_loss = 1.7442401961485545:  90%|████████▉ | 149/166 [03:12<00:22,  1.32s/it]avg_loss = 1.7442401961485545:  90%|█████████ | 150/166 [03:12<00:21,  1.31s/it]avg_loss = 1.743311780572727:  90%|█████████ | 150/166 [03:14<00:21,  1.31s/it] avg_loss = 1.743311780572727:  91%|█████████ | 151/166 [03:14<00:19,  1.31s/it]avg_loss = 1.7431311195618229:  91%|█████████ | 151/166 [03:15<00:19,  1.31s/it]avg_loss = 1.7431311195618229:  92%|█████████▏| 152/166 [03:15<00:18,  1.31s/it]avg_loss = 1.742934106611738:  92%|█████████▏| 152/166 [03:16<00:18,  1.31s/it] avg_loss = 1.742934106611738:  92%|█████████▏| 153/166 [03:16<00:17,  1.32s/it]avg_loss = 1.744607830589468:  92%|█████████▏| 153/166 [03:18<00:17,  1.32s/it]avg_loss = 1.744607830589468:  93%|█████████▎| 154/166 [03:18<00:15,  1.31s/it]avg_loss = 1.744110583874487:  93%|█████████▎| 154/166 [03:19<00:15,  1.31s/it]avg_loss = 1.744110583874487:  93%|█████████▎| 155/166 [03:19<00:14,  1.32s/it]avg_loss = 1.7439846713573506:  93%|█████████▎| 155/166 [03:20<00:14,  1.32s/it]avg_loss = 1.7439846713573506:  94%|█████████▍| 156/166 [03:20<00:13,  1.32s/it]avg_loss = 1.7421852953874382:  94%|█████████▍| 156/166 [03:21<00:13,  1.32s/it]avg_loss = 1.7421852953874382:  95%|█████████▍| 157/166 [03:21<00:11,  1.32s/it]avg_loss = 1.737835002473638:  95%|█████████▍| 157/166 [03:23<00:11,  1.32s/it] avg_loss = 1.737835002473638:  95%|█████████▌| 158/166 [03:23<00:10,  1.32s/it]avg_loss = 1.7385944904021498:  95%|█████████▌| 158/166 [03:24<00:10,  1.32s/it]avg_loss = 1.7385944904021498:  96%|█████████▌| 159/166 [03:24<00:09,  1.32s/it]avg_loss = 1.7399463560432196:  96%|█████████▌| 159/166 [03:25<00:09,  1.32s/it]avg_loss = 1.7399463560432196:  96%|█████████▋| 160/166 [03:25<00:07,  1.32s/it]avg_loss = 1.7423162145644242:  96%|█████████▋| 160/166 [03:27<00:07,  1.32s/it]avg_loss = 1.7423162145644242:  97%|█████████▋| 161/166 [03:27<00:06,  1.32s/it]avg_loss = 1.7426624603477525:  97%|█████████▋| 161/166 [03:28<00:06,  1.32s/it]avg_loss = 1.7426624603477525:  98%|█████████▊| 162/166 [03:28<00:05,  1.32s/it]avg_loss = 1.742350390718027:  98%|█████████▊| 162/166 [03:29<00:05,  1.32s/it] avg_loss = 1.742350390718027:  98%|█████████▊| 163/166 [03:29<00:03,  1.32s/it]avg_loss = 1.74302751443735:  98%|█████████▊| 163/166 [03:31<00:03,  1.32s/it] avg_loss = 1.74302751443735:  99%|█████████▉| 164/166 [03:31<00:02,  1.32s/it]avg_loss = 1.7431496038581387:  99%|█████████▉| 164/166 [03:32<00:02,  1.32s/it]avg_loss = 1.7431496038581387:  99%|█████████▉| 165/166 [03:32<00:01,  1.32s/it]avg_loss = 1.7450888483639222:  99%|█████████▉| 165/166 [03:33<00:01,  1.32s/it]avg_loss = 1.7450888483639222: 100%|██████████| 166/166 [03:33<00:00,  1.32s/it]avg_loss = 1.7450888483639222: 100%|██████████| 166/166 [03:33<00:00,  1.29s/it]
I0403 06:23:46.678951 3469241 eval_ppl.py:107] wikitext2 perplexity: 5.726409912109375
wikitext2 perplexity: 5.726
