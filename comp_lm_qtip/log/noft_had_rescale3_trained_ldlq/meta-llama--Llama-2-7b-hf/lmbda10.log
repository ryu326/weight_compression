I0403 05:01:11.430838 3412031 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:01:11.430937 3412031 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:01:11.430979 3412031 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:01:11.768231 3412031 config.py:54] PyTorch version 2.6.0 available.
W0403 05:01:11.969577 3412031 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:01:12.596843 3412031 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  6.79it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.22it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  7.46it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  7.72it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.74it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.58it/s]
I0403 05:01:13.597999 3412031 quantize_finetune_llama.py:152] loaded model
I0403 05:01:13.938513 3412031 quantize_finetune_llama.py:190] loaded compression model
I0403 05:01:28.298845 3412031 quantize_finetune_llama.py:194] loaded dataset and devset
I0403 05:01:31.910288 3412031 quantize_finetune_llama.py:214] layer 0 gpu 0
I0403 05:01:34.339580 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 0 in 2.264383554458618s
Use train scale and shift
tensor(2.2655e-07, device='cuda:0') tensor(0.0204, device='cuda:0')
tensor(0.0204, device='cuda:0') tensor(2.2655e-07, device='cuda:0')
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0403 05:01:50.794861 3412574 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:01:50.794953 3412574 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:01:50.794990 3412574 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:01:51.122707 3412574 config.py:54] PyTorch version 2.6.0 available.
W0403 05:01:51.313019 3412574 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:01:51.899671 3412574 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:01:51.903486 3412031 quantize_finetune_llama.py:214] layer 1 gpu 1
I0403 05:01:52.214932 3412574 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:01:56.499666 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 1 in 4.413776159286499s
I0403 05:02:00.071362 3412729 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:02:00.071457 3412729 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:02:00.071498 3412729 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:02:00.401199 3412729 config.py:54] PyTorch version 2.6.0 available.
W0403 05:02:00.591841 3412729 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:02:01.141640 3412729 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:02:01.145192 3412031 quantize_finetune_llama.py:214] layer 2 gpu 0
I0403 05:02:01.378749 3412729 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.0050268881022930145 err 4.885517597198486 tr(WHW.T) 971.8771362304688
bpp_loss 2.07054009361309
0_q proxy err 2.2946564058656804e-05 err 14.603775978088379 tr(WHW.T) 636425.375
bpp_loss 2.1637195374642033
0_k proxy err 3.110973921138793e-05 err 12.408559799194336 tr(WHW.T) 398864.15625
bpp_loss 2.257880162243964
0_o proxy err 0.00036091773654334247 err 5.747955322265625 tr(WHW.T) 15925.943359375
bpp_loss 1.9778605290339328
0_up proxy err 0.020248454064130783 err 488.335693359375 tr(WHW.T) 24117.18359375
bpp_loss 1.9790652574061653
0_gate proxy err 0.013921046629548073 err 493.1865234375 tr(WHW.T) 35427.40234375
bpp_loss 1.9970757991162151
0_down proxy err 0.009604545310139656 err 343.80755615234375 tr(WHW.T) 35796.33984375
bpp_loss 2.165940874862636
1_v proxy err 0.021542983129620552 err 14.154258728027344 tr(WHW.T) 657.0241088867188
bpp_loss 1.9534356555377599
1_q proxy err 0.0001446052483515814 err 28.258390426635742 tr(WHW.T) 195417.453125
bpp_loss 2.8820022640866227
1_k proxy err 0.00013939304335508496 err 28.477378845214844 tr(WHW.T) 204295.5625
bpp_loss 2.880113154940773
1_o proxy err 0.006954783108085394 err 28.094757080078125 tr(WHW.T) 4039.630859375
bpp_loss 1.9782544945774134
1_up proxy err 0.028619201853871346 err 664.2359008789062 tr(WHW.T) 23209.44921875
bpp_loss 2.0134168816513793
1_gate proxy err 0.014429444447159767 err 677.5209350585938 tr(WHW.T) 46954.0546875
bpp_loss 2.0783993074193945
1_down proxy err 4.0692961192689836e-05 err 1.6594353914260864 tr(WHW.T) 40779.421875
bpp_loss 2.3218210928878467
I0403 05:03:54.381661 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 2 in 0.8245017528533936s
I0403 05:03:57.852583 3413868 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:03:57.852675 3413868 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:03:57.852713 3413868 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:03:58.182315 3413868 config.py:54] PyTorch version 2.6.0 available.
W0403 05:03:58.374926 3413868 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:03:58.950475 3413868 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:03:58.954238 3412031 quantize_finetune_llama.py:214] layer 3 gpu 1
I0403 05:03:59.129871 3413868 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:04:00.314825 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 3 in 0.9727602005004883s
I0403 05:04:03.876563 3413997 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:04:03.876665 3413997 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:04:03.876703 3413997 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:04:04.211503 3413997 config.py:54] PyTorch version 2.6.0 available.
W0403 05:04:04.399499 3413997 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:04:04.972735 3413997 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:04:04.976287 3412031 quantize_finetune_llama.py:214] layer 4 gpu 0
I0403 05:04:05.171734 3413997 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.03309972211718559 err 92.0127182006836 tr(WHW.T) 2779.86376953125
bpp_loss 2.037044585478725
2_q proxy err 0.0007005120860412717 err 111.7374267578125 tr(WHW.T) 159508.203125
bpp_loss 2.825325309589971
2_k proxy err 0.0005435778293758631 err 114.1518783569336 tr(WHW.T) 210000.984375
bpp_loss 2.9234164048102684
2_o proxy err 0.029439009726047516 err 156.0441131591797 tr(WHW.T) 5300.58984375
bpp_loss 2.0208186622476205
2_up proxy err 0.04137079417705536 err 824.6676635742188 tr(WHW.T) 19933.5703125
bpp_loss 2.0088118714995162
2_gate proxy err 0.02659079246222973 err 841.883544921875 tr(WHW.T) 31660.716796875
bpp_loss 2.0849641153025766
2_down proxy err 0.05256509780883789 err 908.5145263671875 tr(WHW.T) 17283.607421875
bpp_loss 2.056672869401789
3_v proxy err 0.05633307248353958 err 167.81117248535156 tr(WHW.T) 2978.910400390625
bpp_loss 1.9479031634691637
3_q proxy err 0.0026546993758529425 err 202.21920776367188 tr(WHW.T) 76174.0546875
bpp_loss 2.6494273892603815
3_k proxy err 0.0019306172616779804 err 205.34158325195312 tr(WHW.T) 106360.5859375
bpp_loss 2.7216817370499484
3_o proxy err 0.031875088810920715 err 167.52212524414062 tr(WHW.T) 5255.58154296875
bpp_loss 1.9780504230293445
3_up proxy err 0.05190642550587654 err 906.69189453125 tr(WHW.T) 17467.81640625
bpp_loss 2.0066227517415616
3_gate proxy err 0.03157505765557289 err 928.211669921875 tr(WHW.T) 29396.990234375
bpp_loss 2.0894780833447397
3_down proxy err 0.05337908864021301 err 902.511962890625 tr(WHW.T) 16907.59375
bpp_loss 2.063834318934485
I0403 05:05:57.005696 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 4 in 0.8909449577331543s
I0403 05:06:00.451008 3415166 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:06:00.451101 3415166 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:06:00.451141 3415166 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:06:00.778169 3415166 config.py:54] PyTorch version 2.6.0 available.
W0403 05:06:00.974454 3415166 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:06:01.543016 3415166 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:06:01.546893 3412031 quantize_finetune_llama.py:214] layer 5 gpu 1
I0403 05:06:01.785155 3415166 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:06:02.784961 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 5 in 0.858802080154419s
I0403 05:06:06.317377 3415292 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:06:06.317474 3415292 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:06:06.317512 3415292 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:06:06.648365 3415292 config.py:54] PyTorch version 2.6.0 available.
W0403 05:06:06.840660 3415292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:06:07.442298 3415292 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:06:07.445986 3412031 quantize_finetune_llama.py:214] layer 6 gpu 0
I0403 05:06:07.629311 3415292 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.0547010600566864 err 169.43955993652344 tr(WHW.T) 3097.555419921875
bpp_loss 1.9847095230070408
4_q proxy err 0.0025688838213682175 err 202.29052734375 tr(WHW.T) 78746.46875
bpp_loss 2.7332328113843687
4_k proxy err 0.0017248226795345545 err 204.6687469482422 tr(WHW.T) 118660.75
bpp_loss 2.7716001700027846
4_o proxy err 0.03977268189191818 err 212.265869140625 tr(WHW.T) 5336.9765625
bpp_loss 1.958401006355416
4_up proxy err 0.05104121193289757 err 901.626953125 tr(WHW.T) 17664.685546875
bpp_loss 2.0021315073637767
4_gate proxy err 0.025445153936743736 err 930.9908447265625 tr(WHW.T) 36588.140625
bpp_loss 2.11630293744248
4_down proxy err 0.05236310139298439 err 881.3197021484375 tr(WHW.T) 16830.9296875
bpp_loss 2.0528578651354237
5_v proxy err 0.058949414640665054 err 186.66757202148438 tr(WHW.T) 3166.572021484375
bpp_loss 1.9895766633562744
5_q proxy err 0.00306879123672843 err 222.59754943847656 tr(WHW.T) 72535.90625
bpp_loss 2.7276396506931633
5_k proxy err 0.0019497163593769073 err 226.57127380371094 tr(WHW.T) 116207.296875
bpp_loss 2.8053249400109053
5_o proxy err 0.04151151701807976 err 156.47964477539062 tr(WHW.T) 3769.5478515625
bpp_loss 2.0225162002898287
5_up proxy err 0.050320155918598175 err 906.600341796875 tr(WHW.T) 18016.64453125
bpp_loss 2.0002041512797044
5_gate proxy err 0.023775536566972733 err 937.1621704101562 tr(WHW.T) 39417.078125
bpp_loss 2.121800029217157
5_down proxy err 0.05786294862627983 err 923.1061401367188 tr(WHW.T) 15953.3203125
bpp_loss 2.0406721623419504
I0403 05:08:00.753015 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 6 in 0.886117696762085s
I0403 05:08:04.289363 3416503 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:08:04.289456 3416503 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:08:04.289494 3416503 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:08:04.617631 3416503 config.py:54] PyTorch version 2.6.0 available.
W0403 05:08:04.808428 3416503 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:08:05.419108 3416503 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:08:05.422684 3412031 quantize_finetune_llama.py:214] layer 7 gpu 1
I0403 05:08:05.642939 3416503 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:08:06.809911 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 7 in 0.9236550331115723s
I0403 05:08:10.420549 3416646 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:08:10.420644 3416646 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:08:10.420686 3416646 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:08:10.761633 3416646 config.py:54] PyTorch version 2.6.0 available.
W0403 05:08:10.952149 3416646 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:08:11.567807 3416646 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:08:11.571443 3412031 quantize_finetune_llama.py:214] layer 8 gpu 0
I0403 05:08:11.811853 3416646 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.06358856707811356 err 202.2646484375 tr(WHW.T) 3180.833740234375
bpp_loss 1.932288255833555
6_q proxy err 0.004461824428290129 err 244.33261108398438 tr(WHW.T) 54760.6953125
bpp_loss 2.609492219227832
6_k proxy err 0.0032682749442756176 err 246.00343322753906 tr(WHW.T) 75270.1171875
bpp_loss 2.6461191261187196
6_o proxy err 0.04590761289000511 err 185.5303497314453 tr(WHW.T) 4041.38525390625
bpp_loss 1.9546280680806376
6_up proxy err 0.05120525881648064 err 920.2453002929688 tr(WHW.T) 17971.6953125
bpp_loss 1.9959080110542302
6_gate proxy err 0.021062009036540985 err 956.8662719726562 tr(WHW.T) 45430.91015625
bpp_loss 2.141122726636917
6_down proxy err 0.0583360493183136 err 900.402587890625 tr(WHW.T) 15434.75390625
bpp_loss 2.038665134329782
7_v proxy err 0.06347206234931946 err 206.33160400390625 tr(WHW.T) 3250.746826171875
bpp_loss 1.936702015256742
7_q proxy err 0.004851492587476969 err 248.88449096679688 tr(WHW.T) 51300.6015625
bpp_loss 2.6031299236929044
7_k proxy err 0.0036600802559405565 err 249.7090301513672 tr(WHW.T) 68225.015625
bpp_loss 2.612796838628128
7_o proxy err 0.05031081661581993 err 177.5162811279297 tr(WHW.T) 3528.39208984375
bpp_loss 1.9608860270527657
7_up proxy err 0.049765560775995255 err 907.229736328125 tr(WHW.T) 18230.072265625
bpp_loss 2.0012000822570433
7_gate proxy err 0.020211391150951385 err 942.8312377929688 tr(WHW.T) 46648.5078125
bpp_loss 2.1420741318183585
7_down proxy err 0.058613136410713196 err 893.2862548828125 tr(WHW.T) 15240.3759765625
bpp_loss 2.0387224136570166
I0403 05:10:03.485286 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 8 in 0.8662023544311523s
I0403 05:10:06.940385 3417766 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:10:06.940485 3417766 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:10:06.940526 3417766 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:10:07.266396 3417766 config.py:54] PyTorch version 2.6.0 available.
W0403 05:10:07.456665 3417766 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:10:08.050886 3417766 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:10:08.054403 3412031 quantize_finetune_llama.py:214] layer 9 gpu 1
I0403 05:10:08.312913 3417766 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:10:09.433734 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 9 in 0.9592342376708984s
I0403 05:10:13.101476 3417904 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:10:13.101571 3417904 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:10:13.101613 3417904 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:10:13.455653 3417904 config.py:54] PyTorch version 2.6.0 available.
W0403 05:10:13.647017 3417904 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:10:14.245710 3417904 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:10:14.249294 3412031 quantize_finetune_llama.py:214] layer 10 gpu 0
I0403 05:10:14.477206 3417904 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.05813226476311684 err 201.7423095703125 tr(WHW.T) 3470.401611328125
bpp_loss 1.958818470040569
8_q proxy err 0.005023890640586615 err 239.0998077392578 tr(WHW.T) 47592.55859375
bpp_loss 2.627738539944403
8_k proxy err 0.003431548597291112 err 240.5513153076172 tr(WHW.T) 70099.9296875
bpp_loss 2.6395555857452564
8_o proxy err 0.05296046659350395 err 165.16757202148438 tr(WHW.T) 3118.695556640625
bpp_loss 1.98589616236859
8_up proxy err 0.04550861194729805 err 903.4622802734375 tr(WHW.T) 19852.556640625
bpp_loss 2.0153812274856624
8_gate proxy err 0.020565465092658997 err 931.85888671875 tr(WHW.T) 45311.83203125
bpp_loss 2.124530979410507
8_down proxy err 0.0583188496530056 err 893.5834350585938 tr(WHW.T) 15322.3779296875
bpp_loss 2.04663855414621
9_v proxy err 0.0586606003344059 err 215.6636505126953 tr(WHW.T) 3676.465087890625
bpp_loss 1.9611098726745695
9_q proxy err 0.005557843949645758 err 253.8624267578125 tr(WHW.T) 45676.421875
bpp_loss 2.618974731420167
9_k proxy err 0.003568490268662572 err 257.127685546875 tr(WHW.T) 72055.03125
bpp_loss 2.66354456305271
9_o proxy err 0.05539071187376976 err 174.40347290039062 tr(WHW.T) 3148.60498046875
bpp_loss 1.9895820121164434
9_up proxy err 0.0440264493227005 err 907.1932983398438 tr(WHW.T) 20605.642578125
bpp_loss 2.0230209507741206
9_gate proxy err 0.020530181005597115 err 932.2059936523438 tr(WHW.T) 45406.61328125
bpp_loss 2.1138405617066596
9_down proxy err 0.05917767807841301 err 906.8425903320312 tr(WHW.T) 15324.0654296875
bpp_loss 2.0481139291077852
I0403 05:12:14.327917 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 10 in 1.1441426277160645s
I0403 05:12:17.793934 3419114 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:12:17.794028 3419114 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:12:17.794066 3419114 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:12:18.138616 3419114 config.py:54] PyTorch version 2.6.0 available.
W0403 05:12:18.333193 3419114 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:12:18.931700 3419114 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:12:18.935535 3412031 quantize_finetune_llama.py:214] layer 11 gpu 1
I0403 05:12:19.159081 3419114 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:12:20.659413 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 11 in 1.25764799118042s
I0403 05:12:24.542795 3419243 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:12:24.542945 3419243 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:12:24.542985 3419243 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:12:24.959625 3419243 config.py:54] PyTorch version 2.6.0 available.
W0403 05:12:25.161278 3419243 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:12:25.956110 3419243 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:12:25.960477 3412031 quantize_finetune_llama.py:214] layer 12 gpu 0
I0403 05:12:26.210499 3419243 data_utils.py:336] using 256 training seqs, 128 validation seqs
10_v proxy err 0.05947841703891754 err 217.1926727294922 tr(WHW.T) 3651.62158203125
bpp_loss 1.9545715471031144
10_q proxy err 0.00582844065502286 err 256.0756530761719 tr(WHW.T) 43935.53515625
bpp_loss 2.6193902298691683
10_k proxy err 0.00371687114238739 err 259.8570861816406 tr(WHW.T) 69912.859375
bpp_loss 2.674069239234086
10_o proxy err 0.05946877598762512 err 181.87240600585938 tr(WHW.T) 3058.283935546875
bpp_loss 1.968969276495045
10_up proxy err 0.04147752374410629 err 908.5416870117188 tr(WHW.T) 21904.43359375
bpp_loss 2.034208301931273
10_gate proxy err 0.020221807062625885 err 929.8606567382812 tr(WHW.T) 45983.0625
bpp_loss 2.110469743002986
10_down proxy err 0.055537138134241104 err 894.766357421875 tr(WHW.T) 16111.1357421875
bpp_loss 2.0595491375600874
11_v proxy err 0.05946243926882744 err 231.35763549804688 tr(WHW.T) 3890.81982421875
bpp_loss 1.9738520478713326
11_q proxy err 0.007036968134343624 err 267.91937255859375 tr(WHW.T) 38073.125
bpp_loss 2.521178620227147
11_k proxy err 0.004721189383417368 err 269.0968017578125 tr(WHW.T) 56997.671875
bpp_loss 2.519421875535045
11_o proxy err 0.06113266199827194 err 186.71246337890625 tr(WHW.T) 3054.2177734375
bpp_loss 1.9892584268236533
11_up proxy err 0.04337212070822716 err 934.595703125 tr(WHW.T) 21548.3046875
bpp_loss 2.040291426486747
11_gate proxy err 0.02103140391409397 err 954.5465698242188 tr(WHW.T) 45386.7265625
bpp_loss 2.1033958895781706
11_down proxy err 0.05861067399382591 err 921.9918212890625 tr(WHW.T) 15730.783203125
bpp_loss 2.0588059516753567
I0403 05:14:28.479016 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 12 in 0.9174563884735107s
I0403 05:14:32.055458 3420464 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:14:32.055555 3420464 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:14:32.055595 3420464 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:14:32.422371 3420464 config.py:54] PyTorch version 2.6.0 available.
W0403 05:14:32.618519 3420464 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:14:33.206586 3420464 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:14:33.210204 3412031 quantize_finetune_llama.py:214] layer 13 gpu 1
I0403 05:14:33.418974 3420464 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:14:34.677744 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 13 in 1.0395681858062744s
I0403 05:14:38.503116 3420604 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:14:38.503243 3420604 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:14:38.503286 3420604 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:14:38.886519 3420604 config.py:54] PyTorch version 2.6.0 available.
W0403 05:14:39.085140 3420604 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:14:39.728475 3420604 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:14:39.732212 3412031 quantize_finetune_llama.py:214] layer 14 gpu 0
I0403 05:14:40.004816 3420604 data_utils.py:336] using 256 training seqs, 128 validation seqs
12_v proxy err 0.06250736117362976 err 237.98760986328125 tr(WHW.T) 3807.353515625
bpp_loss 1.961705348920077
12_q proxy err 0.007205576170235872 err 276.73736572265625 tr(WHW.T) 38406.0
bpp_loss 2.549142134259455
12_k proxy err 0.00472671166062355 err 280.9049377441406 tr(WHW.T) 59429.25
bpp_loss 2.6037847966654226
12_o proxy err 0.06433317810297012 err 192.81419372558594 tr(WHW.T) 2997.118896484375
bpp_loss 1.9753934138570912
12_up proxy err 0.0433913879096508 err 946.2035522460938 tr(WHW.T) 21806.251953125
bpp_loss 2.048542791111178
12_gate proxy err 0.022687029093503952 err 962.2853393554688 tr(WHW.T) 42415.66015625
bpp_loss 2.094571198921564
12_down proxy err 0.058408357203006744 err 921.9027099609375 tr(WHW.T) 15783.7470703125
bpp_loss 2.0699295766738266
13_v proxy err 0.06530982255935669 err 253.66128540039062 tr(WHW.T) 3883.96826171875
bpp_loss 1.9774020373006351
13_q proxy err 0.007661103270947933 err 291.82525634765625 tr(WHW.T) 38091.8046875
bpp_loss 2.5204801040235907
13_k proxy err 0.00516153872013092 err 294.9394226074219 tr(WHW.T) 57141.765625
bpp_loss 2.5511302649392746
13_o proxy err 0.058824311941862106 err 199.54776000976562 tr(WHW.T) 3392.266845703125
bpp_loss 1.9959201634919737
13_up proxy err 0.04126686975359917 err 936.265869140625 tr(WHW.T) 22688.076171875
bpp_loss 2.059749078222139
13_gate proxy err 0.02191734127700329 err 948.7255859375 tr(WHW.T) 43286.52734375
bpp_loss 2.0910620247988505
13_down proxy err 0.05675271898508072 err 893.8875122070312 tr(WHW.T) 15750.5673828125
bpp_loss 2.0871696844697
I0403 05:16:39.339696 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 14 in 1.0185678005218506s
I0403 05:16:42.967944 3421794 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:16:42.968040 3421794 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:16:42.968078 3421794 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:16:43.349489 3421794 config.py:54] PyTorch version 2.6.0 available.
W0403 05:16:43.546015 3421794 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:16:44.242964 3421794 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:16:44.246695 3412031 quantize_finetune_llama.py:214] layer 15 gpu 1
I0403 05:16:44.412448 3421794 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:16:45.839457 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 15 in 1.1783490180969238s
I0403 05:16:49.653517 3421927 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:16:49.653675 3421927 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:16:49.653715 3421927 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:16:50.021706 3421927 config.py:54] PyTorch version 2.6.0 available.
W0403 05:16:50.222717 3421927 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:16:50.933223 3421927 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:16:50.937061 3412031 quantize_finetune_llama.py:214] layer 16 gpu 0
I0403 05:16:51.280667 3421927 data_utils.py:336] using 256 training seqs, 128 validation seqs
14_v proxy err 0.06776514649391174 err 247.17808532714844 tr(WHW.T) 3647.569580078125
bpp_loss 1.964240874920506
14_q proxy err 0.007747589144855738 err 285.3891906738281 tr(WHW.T) 36835.87109375
bpp_loss 2.5201701277983375
14_k proxy err 0.0049158725887537 err 289.2723388671875 tr(WHW.T) 58844.5546875
bpp_loss 2.55342846410349
14_o proxy err 0.06604637950658798 err 202.35853576660156 tr(WHW.T) 3063.885498046875
bpp_loss 1.9718411303765606
14_up proxy err 0.042731236666440964 err 959.430419921875 tr(WHW.T) 22452.671875
bpp_loss 2.05866959361836
14_gate proxy err 0.0235414020717144 err 970.869384765625 tr(WHW.T) 41240.93359375
bpp_loss 2.086513635377551
14_down proxy err 0.05829504132270813 err 898.2967529296875 tr(WHW.T) 15409.48828125
bpp_loss 2.089286358333951
15_v proxy err 0.06164975464344025 err 246.78712463378906 tr(WHW.T) 4003.05126953125
bpp_loss 1.9983793115534354
15_q proxy err 0.007330675609409809 err 281.15594482421875 tr(WHW.T) 38353.34765625
bpp_loss 2.5017067408771254
15_k proxy err 0.004879024811089039 err 285.9154968261719 tr(WHW.T) 58600.94921875
bpp_loss 2.561013505968731
15_o proxy err 0.05832744762301445 err 211.6339111328125 tr(WHW.T) 3628.3759765625
bpp_loss 1.9964680334087461
15_up proxy err 0.04097685217857361 err 945.1866455078125 tr(WHW.T) 23066.35546875
bpp_loss 2.065107309064546
15_gate proxy err 0.023338695988059044 err 955.6329956054688 tr(WHW.T) 40946.2890625
bpp_loss 2.0932708537682543
15_down proxy err 0.056244585663080215 err 867.7999877929688 tr(WHW.T) 15429.0400390625
bpp_loss 2.1019367337616726
I0403 05:18:49.959729 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 16 in 0.8957972526550293s
I0403 05:18:53.559013 3423117 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:18:53.559111 3423117 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:18:53.559151 3423117 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:18:53.898186 3423117 config.py:54] PyTorch version 2.6.0 available.
W0403 05:18:54.088286 3423117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:18:54.656886 3423117 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:18:54.661222 3412031 quantize_finetune_llama.py:214] layer 17 gpu 1
I0403 05:18:54.853484 3423117 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:18:56.135488 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 17 in 0.9963810443878174s
I0403 05:18:59.650428 3423246 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:18:59.650519 3423246 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:18:59.650557 3423246 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:18:59.984898 3423246 config.py:54] PyTorch version 2.6.0 available.
W0403 05:19:00.175725 3423246 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:19:00.752575 3423246 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:19:00.756381 3412031 quantize_finetune_llama.py:214] layer 18 gpu 0
I0403 05:19:00.959254 3423246 data_utils.py:336] using 256 training seqs, 128 validation seqs
16_v proxy err 0.06422051787376404 err 256.1596984863281 tr(WHW.T) 3988.751708984375
bpp_loss 2.0210839479987044
16_q proxy err 0.0077943820506334305 err 288.8959045410156 tr(WHW.T) 37064.6328125
bpp_loss 2.4800027848104946
16_k proxy err 0.004889088217169046 err 293.24017333984375 tr(WHW.T) 59978.5
bpp_loss 2.524857887532562
16_o proxy err 0.05184980109333992 err 243.4464874267578 tr(WHW.T) 4695.22509765625
bpp_loss 2.009160817891825
16_up proxy err 0.04014340043067932 err 947.5289916992188 tr(WHW.T) 23603.60546875
bpp_loss 2.061927071361001
16_gate proxy err 0.022762298583984375 err 959.9939575195312 tr(WHW.T) 42174.73828125
bpp_loss 2.0989510467665835
16_down proxy err 0.0575157105922699 err 875.8778076171875 tr(WHW.T) 15228.4970703125
bpp_loss 2.0996260982613233
17_v proxy err 0.06353317946195602 err 270.8932189941406 tr(WHW.T) 4263.80712890625
bpp_loss 2.0073514621471986
17_q proxy err 0.008375296369194984 err 304.8000183105469 tr(WHW.T) 36392.74609375
bpp_loss 2.4507912941626273
17_k proxy err 0.005675615277141333 err 308.6893005371094 tr(WHW.T) 54388.6953125
bpp_loss 2.487013006641064
17_o proxy err 0.059317756444215775 err 254.94320678710938 tr(WHW.T) 4297.923828125
bpp_loss 2.0099759167351294
17_up proxy err 0.045696523040533066 err 987.7449951171875 tr(WHW.T) 21615.3203125
bpp_loss 2.0536773245521758
17_gate proxy err 0.02490554004907608 err 1003.7033081054688 tr(WHW.T) 40300.40234375
bpp_loss 2.1056875725991504
17_down proxy err 0.06043247878551483 err 927.8457641601562 tr(WHW.T) 15353.4287109375
bpp_loss 2.087742388226785
I0403 05:20:54.673787 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 18 in 0.9210078716278076s
I0403 05:20:58.172185 3424381 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:20:58.172288 3424381 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:20:58.172325 3424381 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:20:58.507604 3424381 config.py:54] PyTorch version 2.6.0 available.
W0403 05:20:58.700478 3424381 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:20:59.263942 3424381 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:20:59.267455 3412031 quantize_finetune_llama.py:214] layer 19 gpu 1
I0403 05:20:59.428814 3424381 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:21:00.487080 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 19 in 0.7921085357666016s
I0403 05:21:03.916318 3424510 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:21:03.916419 3424510 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:21:03.916459 3424510 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:21:04.248142 3424510 config.py:54] PyTorch version 2.6.0 available.
W0403 05:21:04.437699 3424510 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:21:04.980677 3424510 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:21:04.984217 3412031 quantize_finetune_llama.py:214] layer 20 gpu 0
I0403 05:21:05.215290 3424510 data_utils.py:336] using 256 training seqs, 128 validation seqs
18_v proxy err 0.062170516699552536 err 290.5283203125 tr(WHW.T) 4673.08837890625
bpp_loss 2.036873818578897
18_q proxy err 0.009104580618441105 err 320.82537841796875 tr(WHW.T) 35237.796875
bpp_loss 2.4033056229236536
18_k proxy err 0.0065973843447864056 err 324.05828857421875 tr(WHW.T) 49119.20703125
bpp_loss 2.437952146632597
18_o proxy err 0.052419789135456085 err 258.075927734375 tr(WHW.T) 4923.25390625
bpp_loss 2.0496256574988365
18_up proxy err 0.048941370099782944 err 993.5072631835938 tr(WHW.T) 20299.947265625
bpp_loss 2.0491080763641487
18_gate proxy err 0.02658597193658352 err 1012.1881103515625 tr(WHW.T) 38072.26171875
bpp_loss 2.1148017887459245
18_down proxy err 0.05968809127807617 err 911.2026977539062 tr(WHW.T) 15266.072265625
bpp_loss 2.095161941010765
19_v proxy err 0.06107396259903908 err 292.4774475097656 tr(WHW.T) 4788.90576171875
bpp_loss 2.0444778494129423
19_q proxy err 0.009762786328792572 err 320.9981689453125 tr(WHW.T) 32879.76953125
bpp_loss 2.3833818701677956
19_k proxy err 0.00649223243817687 err 324.5126953125 tr(WHW.T) 49984.76171875
bpp_loss 2.412939765432384
19_o proxy err 0.05614295229315758 err 281.006103515625 tr(WHW.T) 5005.189453125
bpp_loss 2.0428125300095417
19_up proxy err 0.04972066730260849 err 1002.9961547851562 tr(WHW.T) 20172.62109375
bpp_loss 2.048056301899081
19_gate proxy err 0.02947784774005413 err 1022.8428344726562 tr(WHW.T) 34698.6953125
bpp_loss 2.117661497230793
19_down proxy err 0.05881906673312187 err 923.3006591796875 tr(WHW.T) 15697.3017578125
bpp_loss 2.096810649712245
I0403 05:22:59.171380 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 20 in 0.8291800022125244s
I0403 05:23:02.676657 3425645 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:23:02.676750 3425645 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:23:02.676789 3425645 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:23:03.014180 3425645 config.py:54] PyTorch version 2.6.0 available.
W0403 05:23:03.210519 3425645 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:23:03.753373 3425645 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:23:03.756952 3412031 quantize_finetune_llama.py:214] layer 21 gpu 1
I0403 05:23:03.948423 3425645 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:23:05.019661 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 21 in 0.8492684364318848s
I0403 05:23:08.534201 3425774 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:23:08.534293 3425774 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:23:08.534331 3425774 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:23:08.863368 3425774 config.py:54] PyTorch version 2.6.0 available.
W0403 05:23:09.052414 3425774 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:23:09.648903 3425774 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:23:09.652509 3412031 quantize_finetune_llama.py:214] layer 22 gpu 0
I0403 05:23:09.906282 3425774 data_utils.py:336] using 256 training seqs, 128 validation seqs
20_v proxy err 0.06437011808156967 err 299.0525817871094 tr(WHW.T) 4645.8291015625
bpp_loss 2.052036270557437
20_q proxy err 0.009702498093247414 err 328.09246826171875 tr(WHW.T) 33815.2578125
bpp_loss 2.3874974721693434
20_k proxy err 0.006745188031345606 err 331.52593994140625 tr(WHW.T) 49149.9921875
bpp_loss 2.4152559282956645
20_o proxy err 0.040165532380342484 err 273.94580078125 tr(WHW.T) 6820.419921875
bpp_loss 2.0697551043122075
20_up proxy err 0.048510607331991196 err 999.4681396484375 tr(WHW.T) 20603.083984375
bpp_loss 2.0472900129768044
20_gate proxy err 0.0287140142172575 err 1019.6340942382812 tr(WHW.T) 35509.98046875
bpp_loss 2.1246373315536697
20_down proxy err 0.05743764340877533 err 907.6925659179688 tr(WHW.T) 15803.095703125
bpp_loss 2.101239532708775
21_v proxy err 0.06328186392784119 err 307.7242736816406 tr(WHW.T) 4862.75634765625
bpp_loss 2.075698997359723
21_q proxy err 0.010979892686009407 err 332.26849365234375 tr(WHW.T) 30261.54296875
bpp_loss 2.3464077032986097
21_k proxy err 0.007827142253518105 err 334.7546081542969 tr(WHW.T) 42768.43359375
bpp_loss 2.36256793490611
21_o proxy err 0.05113142728805542 err 327.2030029296875 tr(WHW.T) 6399.25439453125
bpp_loss 2.0547089215251617
21_up proxy err 0.05200965330004692 err 1017.4588623046875 tr(WHW.T) 19562.884765625
bpp_loss 2.044515014214571
21_gate proxy err 0.03128107637166977 err 1040.14111328125 tr(WHW.T) 33251.44921875
bpp_loss 2.1318218345472286
21_down proxy err 0.06009862944483757 err 949.0914916992188 tr(WHW.T) 15792.2314453125
bpp_loss 2.0943345767120984
I0403 05:25:20.113012 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 22 in 1.0222923755645752s
I0403 05:25:24.546616 3427068 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:25:24.546931 3427068 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:25:24.547058 3427068 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:25:25.001051 3427068 config.py:54] PyTorch version 2.6.0 available.
W0403 05:25:25.204197 3427068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:25:25.895472 3427068 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:25:25.899333 3412031 quantize_finetune_llama.py:214] layer 23 gpu 1
I0403 05:25:26.146434 3427068 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:25:27.595640 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 23 in 1.2314774990081787s
I0403 05:25:31.801792 3427207 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:25:31.801957 3427207 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:25:31.802040 3427207 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:25:32.155332 3427207 config.py:54] PyTorch version 2.6.0 available.
W0403 05:25:32.399288 3427207 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:25:33.064320 3427207 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:25:33.068425 3412031 quantize_finetune_llama.py:214] layer 24 gpu 0
I0403 05:25:33.263519 3427207 data_utils.py:336] using 256 training seqs, 128 validation seqs
22_v proxy err 0.06064845621585846 err 310.0307922363281 tr(WHW.T) 5111.93212890625
bpp_loss 2.080470012675505
22_q proxy err 0.010471334680914879 err 336.1655578613281 tr(WHW.T) 32103.412109375
bpp_loss 2.3781375393737108
22_k proxy err 0.007704213727265596 err 338.7522277832031 tr(WHW.T) 43969.734375
bpp_loss 2.3970526651246473
22_o proxy err 0.039411745965480804 err 300.6126403808594 tr(WHW.T) 7627.48828125
bpp_loss 2.0821687793941237
22_up proxy err 0.05280289053916931 err 1026.4879150390625 tr(WHW.T) 19439.994140625
bpp_loss 2.043431453969936
22_gate proxy err 0.03209548816084862 err 1050.5238037109375 tr(WHW.T) 32731.19921875
bpp_loss 2.1385535511599723
22_down proxy err 0.060709040611982346 err 963.73193359375 tr(WHW.T) 15874.603515625
bpp_loss 2.0912846970956687
23_v proxy err 0.0582246258854866 err 329.9315490722656 tr(WHW.T) 5666.529296875
bpp_loss 2.1187673142412677
23_q proxy err 0.012481511570513248 err 352.2497253417969 tr(WHW.T) 28221.720703125
bpp_loss 2.3533565585385077
23_k proxy err 0.009226561523973942 err 354.07281494140625 tr(WHW.T) 38375.3828125
bpp_loss 2.3653096551424824
23_o proxy err 0.051496438682079315 err 326.7649230957031 tr(WHW.T) 6345.388671875
bpp_loss 2.1177657314110547
23_up proxy err 0.05558423697948456 err 1042.4229736328125 tr(WHW.T) 18753.931640625
bpp_loss 2.0479291560085016
23_gate proxy err 0.03503710776567459 err 1065.1478271484375 tr(WHW.T) 30400.564453125
bpp_loss 2.137134436301367
23_down proxy err 0.06241602078080177 err 987.219970703125 tr(WHW.T) 15816.7724609375
bpp_loss 2.0963551571679324
I0403 05:27:32.470129 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 24 in 0.9415750503540039s
I0403 05:27:36.008446 3428418 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:27:36.008542 3428418 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:27:36.008580 3428418 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:27:36.330655 3428418 config.py:54] PyTorch version 2.6.0 available.
W0403 05:27:36.524837 3428418 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:27:37.109581 3428418 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:27:37.113096 3412031 quantize_finetune_llama.py:214] layer 25 gpu 1
I0403 05:27:37.285728 3428418 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:27:38.314383 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 25 in 0.8090779781341553s
I0403 05:27:41.965986 3428547 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:27:41.966083 3428547 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:27:41.966123 3428547 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:27:42.309523 3428547 config.py:54] PyTorch version 2.6.0 available.
W0403 05:27:42.504544 3428547 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:27:43.112661 3428547 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:27:43.116267 3412031 quantize_finetune_llama.py:214] layer 26 gpu 0
I0403 05:27:43.324307 3428547 data_utils.py:336] using 256 training seqs, 128 validation seqs
24_v proxy err 0.06046726554632187 err 321.97186279296875 tr(WHW.T) 5324.72998046875
bpp_loss 2.116219675343018
24_q proxy err 0.012675995007157326 err 342.3960266113281 tr(WHW.T) 27011.373046875
bpp_loss 2.323096100415569
24_k proxy err 0.008662570267915726 err 344.39288330078125 tr(WHW.T) 39756.4296875
bpp_loss 2.3307493557804264
24_o proxy err 0.03810923174023628 err 306.345458984375 tr(WHW.T) 8038.615234375
bpp_loss 2.106911772454623
24_up proxy err 0.05696557089686394 err 1054.6033935546875 tr(WHW.T) 18512.99609375
bpp_loss 2.050214451022966
24_gate proxy err 0.03570955991744995 err 1077.4168701171875 tr(WHW.T) 30171.666015625
bpp_loss 2.1391690048107574
24_down proxy err 0.0630313828587532 err 993.1380004882812 tr(WHW.T) 15756.2470703125
bpp_loss 2.100470505568177
25_v proxy err 0.058519359678030014 err 346.87396240234375 tr(WHW.T) 5927.5078125
bpp_loss 2.1426195671083406
25_q proxy err 0.014577172696590424 err 365.0360107421875 tr(WHW.T) 25041.619140625
bpp_loss 2.3161975109833293
25_k proxy err 0.010893668048083782 err 366.3863830566406 tr(WHW.T) 33632.96875
bpp_loss 2.320645080122631
25_o proxy err 0.04952478036284447 err 335.7318115234375 tr(WHW.T) 6779.06689453125
bpp_loss 2.123907441040501
25_up proxy err 0.05694331228733063 err 1060.513916015625 tr(WHW.T) 18624.029296875
bpp_loss 2.054725841380829
25_gate proxy err 0.03487836942076683 err 1083.1019287109375 tr(WHW.T) 31053.6875
bpp_loss 2.141149952054717
25_down proxy err 0.06022917479276657 err 956.2835693359375 tr(WHW.T) 15877.4140625
bpp_loss 2.120369045865224
I0403 05:29:42.375939 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 26 in 0.8457119464874268s
I0403 05:29:45.831520 3429744 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:29:45.831614 3429744 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:29:45.831654 3429744 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:29:46.159023 3429744 config.py:54] PyTorch version 2.6.0 available.
W0403 05:29:46.350149 3429744 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:29:46.933437 3429744 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:29:46.937269 3412031 quantize_finetune_llama.py:214] layer 27 gpu 1
I0403 05:29:47.122771 3429744 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:29:48.168981 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 27 in 0.8132681846618652s
I0403 05:29:51.810421 3429870 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:29:51.810517 3429870 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:29:51.810555 3429870 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:29:52.174080 3429870 config.py:54] PyTorch version 2.6.0 available.
W0403 05:29:52.365963 3429870 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:29:52.989788 3429870 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:29:52.993474 3412031 quantize_finetune_llama.py:214] layer 28 gpu 0
I0403 05:29:53.258965 3429870 data_utils.py:336] using 256 training seqs, 128 validation seqs
26_v proxy err 0.057495906949043274 err 340.418212890625 tr(WHW.T) 5920.73828125
bpp_loss 2.1667492743581533
26_q proxy err 0.013327931985259056 err 356.00958251953125 tr(WHW.T) 26711.5390625
bpp_loss 2.301683804136701
26_k proxy err 0.009532506577670574 err 357.789306640625 tr(WHW.T) 37533.6015625
bpp_loss 2.3129397181910463
26_o proxy err 0.026916688308119774 err 265.5616149902344 tr(WHW.T) 9866.05859375
bpp_loss 2.205370829673484
26_up proxy err 0.05341004952788353 err 1060.526611328125 tr(WHW.T) 19856.3125
bpp_loss 2.0582956045779377
26_gate proxy err 0.03236410394310951 err 1082.719482421875 tr(WHW.T) 33454.33203125
bpp_loss 2.1446229138866415
26_down proxy err 0.05996234714984894 err 924.951416015625 tr(WHW.T) 15425.537109375
bpp_loss 2.1315897805399673
27_v proxy err 0.0553971529006958 err 362.1752624511719 tr(WHW.T) 6537.79541015625
bpp_loss 2.152642799948808
27_q proxy err 0.013556084595620632 err 381.46234130859375 tr(WHW.T) 28139.56640625
bpp_loss 2.3317427352885716
27_k proxy err 0.00985359214246273 err 383.0912780761719 tr(WHW.T) 38878.3359375
bpp_loss 2.3469789766240865
27_o proxy err 0.038629692047834396 err 280.6948547363281 tr(WHW.T) 7266.2978515625
bpp_loss 2.2165363843087107
27_up proxy err 0.04824871942400932 err 1052.947509765625 tr(WHW.T) 21823.326171875
bpp_loss 2.0640865518429945
27_gate proxy err 0.03024800680577755 err 1073.531982421875 tr(WHW.T) 35491.0
bpp_loss 2.14601672640027
27_down proxy err 0.05613195523619652 err 848.65966796875 tr(WHW.T) 15119.01171875
bpp_loss 2.1557768805515627
I0403 05:31:51.640110 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 28 in 0.8616287708282471s
I0403 05:31:55.135718 3431053 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:31:55.135854 3431053 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:31:55.135947 3431053 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:31:55.469981 3431053 config.py:54] PyTorch version 2.6.0 available.
W0403 05:31:55.658698 3431053 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:31:56.261254 3431053 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:31:56.264771 3412031 quantize_finetune_llama.py:214] layer 29 gpu 1
I0403 05:31:56.443752 3431053 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:31:57.658332 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 29 in 0.9682722091674805s
I0403 05:32:01.324297 3431182 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:32:01.324389 3431182 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:32:01.324428 3431182 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:32:01.693232 3431182 config.py:54] PyTorch version 2.6.0 available.
W0403 05:32:01.886329 3431182 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:32:02.531580 3431182 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:32:02.535273 3412031 quantize_finetune_llama.py:214] layer 30 gpu 0
I0403 05:32:02.763859 3431182 data_utils.py:336] using 256 training seqs, 128 validation seqs
28_v proxy err 0.051156673580408096 err 362.061767578125 tr(WHW.T) 7077.5078125
bpp_loss 2.190814969537314
28_q proxy err 0.013894530944526196 err 375.1892395019531 tr(WHW.T) 27002.65625
bpp_loss 2.2906814896850847
28_k proxy err 0.010122248902916908 err 376.98828125 tr(WHW.T) 37243.53125
bpp_loss 2.3080634371144697
28_o proxy err 0.029539979994297028 err 262.43353271484375 tr(WHW.T) 8884.01171875
bpp_loss 2.247886371857021
28_up proxy err 0.039860669523477554 err 1042.8017578125 tr(WHW.T) 26161.169921875
bpp_loss 2.0758255618342827
28_gate proxy err 0.028805287554860115 err 1059.863525390625 tr(WHW.T) 36794.0625
bpp_loss 2.1412701158849305
28_down proxy err 0.04964394122362137 err 743.8880004882812 tr(WHW.T) 14984.466796875
bpp_loss 2.188076426101805
29_v proxy err 0.05294562503695488 err 353.8019104003906 tr(WHW.T) 6682.36328125
bpp_loss 2.198742483393289
29_q proxy err 0.013499394059181213 err 364.5653991699219 tr(WHW.T) 27006.056640625
bpp_loss 2.2580494060530327
29_k proxy err 0.009279361926019192 err 366.4358825683594 tr(WHW.T) 39489.33984375
bpp_loss 2.2705989474779926
29_o proxy err 0.029961097985506058 err 317.55914306640625 tr(WHW.T) 10599.048828125
bpp_loss 2.2209902662434615
29_up proxy err 0.0313677042722702 err 1031.4991455078125 tr(WHW.T) 32884.11328125
bpp_loss 2.086789063676152
29_gate proxy err 0.026187874376773834 err 1046.0218505859375 tr(WHW.T) 39942.984375
bpp_loss 2.1450169552117586
29_down proxy err 0.04293203726410866 err 632.4981689453125 tr(WHW.T) 14732.544921875
bpp_loss 2.218941996523807
I0403 05:34:04.458728 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 30 in 0.8493094444274902s
I0403 05:34:08.021132 3432379 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:34:08.021225 3432379 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:34:08.021262 3432379 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:34:08.348376 3432379 config.py:54] PyTorch version 2.6.0 available.
W0403 05:34:08.539455 3432379 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:34:09.103276 3432379 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:34:09.107014 3412031 quantize_finetune_llama.py:214] layer 31 gpu 1
I0403 05:34:09.256713 3432379 data_utils.py:336] using 256 training seqs, 128 validation seqs
I0403 05:34:10.458323 3412031 quantize_finetune_llama.py:245] computed original embedding for layer 31 in 0.8892545700073242s
I0403 05:34:14.170714 3432517 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:34:14.170813 3432517 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:34:14.170850 3432517 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:34:14.565823 3432517 config.py:54] PyTorch version 2.6.0 available.
W0403 05:34:14.762678 3432517 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0403 05:34:15.436830 3432517 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0403 05:34:15.810365 3432517 data_utils.py:336] using 256 training seqs, 128 validation seqs
30_v proxy err 0.04478073492646217 err 367.5390319824219 tr(WHW.T) 8207.525390625
bpp_loss 2.215611745195929
30_q proxy err 0.013145867735147476 err 375.1920471191406 tr(WHW.T) 28540.68359375
bpp_loss 2.2495728197391145
30_k proxy err 0.00981509406119585 err 377.3436584472656 tr(WHW.T) 38445.2421875
bpp_loss 2.2689795570331626
30_o proxy err 0.025109393522143364 err 255.18959045410156 tr(WHW.T) 10163.1123046875
bpp_loss 2.2956650224514306
30_up proxy err 0.01859605684876442 err 1001.8432006835938 tr(WHW.T) 53873.95703125
bpp_loss 2.107204616676236
30_gate proxy err 0.01720072142779827 err 1017.728759765625 tr(WHW.T) 59167.79296875
bpp_loss 2.1742225463913623
30_down proxy err 0.01175552699714899 err 303.79217529296875 tr(WHW.T) 25842.498046875
bpp_loss 2.3001460820263206
31_v proxy err 0.05026189610362053 err 338.7821960449219 tr(WHW.T) 6740.33837890625
bpp_loss 2.1071200923179276
31_q proxy err 0.009761819615960121 err 358.2392578125 tr(WHW.T) 36698.0
bpp_loss 2.2695823129615746
31_k proxy err 0.006616642698645592 err 362.5510559082031 tr(WHW.T) 54793.80859375
bpp_loss 2.3211441602907144
31_o proxy err 0.014437589794397354 err 189.44419860839844 tr(WHW.T) 13121.5947265625
bpp_loss 2.2591352197923698
31_up proxy err 0.009817108511924744 err 940.2659912109375 tr(WHW.T) 95778.3046875
bpp_loss 2.157783147684017
31_gate proxy err 0.00980148371309042 err 956.1390991210938 tr(WHW.T) 97550.4453125
bpp_loss 2.235180591211416
31_down proxy err 0.0032940262462943792 err 121.96688079833984 tr(WHW.T) 37026.6875
bpp_loss 2.3653816912799726
I0403 05:36:25.422539 3433765 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:36:25.422672 3433765 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:36:25.422716 3433765 utils.py:162] NumExpr defaulting to 16 threads.
I0403 05:36:25.752197 3433765 config.py:54] PyTorch version 2.6.0 available.
W0403 05:36:25.970401 3433765 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 05:36:26.084078 3433765 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 32000
}

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  7.63it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.27it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.58it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.92it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.10it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.81it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.94it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.77it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.82it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.54it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.47it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.59it/s]
I0403 05:36:28.876710 3433765 hfize_llama.py:161] loaded layer 0
I0403 05:36:29.890758 3433765 hfize_llama.py:161] loaded layer 1
I0403 05:36:30.974844 3433765 hfize_llama.py:161] loaded layer 2
I0403 05:36:32.001347 3433765 hfize_llama.py:161] loaded layer 3
I0403 05:36:33.052535 3433765 hfize_llama.py:161] loaded layer 4
I0403 05:36:34.001287 3433765 hfize_llama.py:161] loaded layer 5
I0403 05:36:35.011898 3433765 hfize_llama.py:161] loaded layer 6
I0403 05:36:36.024650 3433765 hfize_llama.py:161] loaded layer 7
I0403 05:36:36.902191 3433765 hfize_llama.py:161] loaded layer 8
I0403 05:36:37.890943 3433765 hfize_llama.py:161] loaded layer 9
I0403 05:36:38.796230 3433765 hfize_llama.py:161] loaded layer 10
I0403 05:36:39.756342 3433765 hfize_llama.py:161] loaded layer 11
I0403 05:36:40.666279 3433765 hfize_llama.py:161] loaded layer 12
I0403 05:36:41.544467 3433765 hfize_llama.py:161] loaded layer 13
I0403 05:36:42.427859 3433765 hfize_llama.py:161] loaded layer 14
I0403 05:36:43.331329 3433765 hfize_llama.py:161] loaded layer 15
I0403 05:36:44.309065 3433765 hfize_llama.py:161] loaded layer 16
I0403 05:36:45.290337 3433765 hfize_llama.py:161] loaded layer 17
I0403 05:36:46.220517 3433765 hfize_llama.py:161] loaded layer 18
I0403 05:36:47.152071 3433765 hfize_llama.py:161] loaded layer 19
I0403 05:36:48.070781 3433765 hfize_llama.py:161] loaded layer 20
I0403 05:36:48.966801 3433765 hfize_llama.py:161] loaded layer 21
I0403 05:36:49.881491 3433765 hfize_llama.py:161] loaded layer 22
I0403 05:36:50.802163 3433765 hfize_llama.py:161] loaded layer 23
I0403 05:36:51.747896 3433765 hfize_llama.py:161] loaded layer 24
I0403 05:36:52.584049 3433765 hfize_llama.py:161] loaded layer 25
I0403 05:36:53.456988 3433765 hfize_llama.py:161] loaded layer 26
I0403 05:36:54.366189 3433765 hfize_llama.py:161] loaded layer 27
I0403 05:36:55.604007 3433765 hfize_llama.py:161] loaded layer 28
I0403 05:36:56.575564 3433765 hfize_llama.py:161] loaded layer 29
I0403 05:36:57.422445 3433765 hfize_llama.py:161] loaded layer 30
I0403 05:36:58.346526 3433765 hfize_llama.py:161] loaded layer 31
I0403 05:36:58.346643 3433765 hfize_llama.py:165] saving model...
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:06,  1.24s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.05s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:02,  1.01it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.06it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.08it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.29it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]
I0403 05:37:42.275127 3433765 hfize_llama.py:175] successfully loaded hfized model
I0403 05:37:46.759576 3434827 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0403 05:37:46.759696 3434827 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0403 05:37:46.759734 3434827 utils.py:162] NumExpr defaulting to 16 threads.
W0403 05:37:47.117526 3434827 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0403 05:37:47.527503 3434827 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.05it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.00it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.03s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.03s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.03s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]
I0403 05:37:53.305844 3434827 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.8241832256317139:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.8241832256317139:   1%|          | 1/166 [00:01<04:19,  1.57s/it]avg_loss = 2.0661087036132812:   1%|          | 1/166 [00:02<04:19,  1.57s/it]avg_loss = 2.0661087036132812:   1%|          | 2/166 [00:02<03:39,  1.34s/it]avg_loss = 2.2563525835673013:   1%|          | 2/166 [00:03<03:39,  1.34s/it]avg_loss = 2.2563525835673013:   2%|▏         | 3/166 [00:03<03:26,  1.27s/it]avg_loss = 2.3258639574050903:   2%|▏         | 3/166 [00:05<03:26,  1.27s/it]avg_loss = 2.3258639574050903:   2%|▏         | 4/166 [00:05<03:20,  1.24s/it]avg_loss = 2.2466360569000243:   2%|▏         | 4/166 [00:06<03:20,  1.24s/it]avg_loss = 2.2466360569000243:   3%|▎         | 5/166 [00:06<03:16,  1.22s/it]avg_loss = 2.2445383071899414:   3%|▎         | 5/166 [00:07<03:16,  1.22s/it]avg_loss = 2.2445383071899414:   4%|▎         | 6/166 [00:07<03:13,  1.21s/it]avg_loss = 2.1807182346071516:   4%|▎         | 6/166 [00:08<03:13,  1.21s/it]avg_loss = 2.1807182346071516:   4%|▍         | 7/166 [00:08<03:12,  1.21s/it]avg_loss = 2.1278515458106995:   4%|▍         | 7/166 [00:09<03:12,  1.21s/it]avg_loss = 2.1278515458106995:   5%|▍         | 8/166 [00:09<03:10,  1.20s/it]avg_loss = 2.1273232301076255:   5%|▍         | 8/166 [00:11<03:10,  1.20s/it]avg_loss = 2.1273232301076255:   5%|▌         | 9/166 [00:11<03:08,  1.20s/it]avg_loss = 2.1377320766448973:   5%|▌         | 9/166 [00:12<03:08,  1.20s/it]avg_loss = 2.1377320766448973:   6%|▌         | 10/166 [00:12<03:07,  1.20s/it]avg_loss = 2.156892863186923:   6%|▌         | 10/166 [00:13<03:07,  1.20s/it] avg_loss = 2.156892863186923:   7%|▋         | 11/166 [00:13<03:06,  1.20s/it]avg_loss = 2.154631018638611:   7%|▋         | 11/166 [00:14<03:06,  1.20s/it]avg_loss = 2.154631018638611:   7%|▋         | 12/166 [00:14<03:05,  1.21s/it]avg_loss = 2.1473807371579685:   7%|▋         | 12/166 [00:15<03:05,  1.21s/it]avg_loss = 2.1473807371579685:   8%|▊         | 13/166 [00:15<03:04,  1.21s/it]avg_loss = 2.1560000692095076:   8%|▊         | 13/166 [00:17<03:04,  1.21s/it]avg_loss = 2.1560000692095076:   8%|▊         | 14/166 [00:17<03:03,  1.21s/it]avg_loss = 2.1718567848205566:   8%|▊         | 14/166 [00:18<03:03,  1.21s/it]avg_loss = 2.1718567848205566:   9%|▉         | 15/166 [00:18<03:02,  1.21s/it]avg_loss = 2.189880535006523:   9%|▉         | 15/166 [00:19<03:02,  1.21s/it] avg_loss = 2.189880535006523:  10%|▉         | 16/166 [00:19<03:01,  1.21s/it]avg_loss = 2.2034351124483:  10%|▉         | 16/166 [00:20<03:01,  1.21s/it]  avg_loss = 2.2034351124483:  10%|█         | 17/166 [00:20<03:00,  1.21s/it]avg_loss = 2.220944735738966:  10%|█         | 17/166 [00:22<03:00,  1.21s/it]avg_loss = 2.220944735738966:  11%|█         | 18/166 [00:22<02:59,  1.22s/it]avg_loss = 2.2401757114811947:  11%|█         | 18/166 [00:23<02:59,  1.22s/it]avg_loss = 2.2401757114811947:  11%|█▏        | 19/166 [00:23<02:58,  1.22s/it]avg_loss = 2.248163568973541:  11%|█▏        | 19/166 [00:24<02:58,  1.22s/it] avg_loss = 2.248163568973541:  12%|█▏        | 20/166 [00:24<02:58,  1.22s/it]avg_loss = 2.2493866057623:  12%|█▏        | 20/166 [00:25<02:58,  1.22s/it]  avg_loss = 2.2493866057623:  13%|█▎        | 21/166 [00:25<02:57,  1.22s/it]avg_loss = 2.23606477542357:  13%|█▎        | 21/166 [00:26<02:57,  1.22s/it]avg_loss = 2.23606477542357:  13%|█▎        | 22/166 [00:26<02:56,  1.22s/it]avg_loss = 2.225996945215308:  13%|█▎        | 22/166 [00:28<02:56,  1.22s/it]avg_loss = 2.225996945215308:  14%|█▍        | 23/166 [00:28<02:55,  1.23s/it]avg_loss = 2.2331271916627884:  14%|█▍        | 23/166 [00:29<02:55,  1.23s/it]avg_loss = 2.2331271916627884:  14%|█▍        | 24/166 [00:29<02:54,  1.23s/it]avg_loss = 2.2453509759902954:  14%|█▍        | 24/166 [00:30<02:54,  1.23s/it]avg_loss = 2.2453509759902954:  15%|█▌        | 25/166 [00:30<02:53,  1.23s/it]avg_loss = 2.24885702591676:  15%|█▌        | 25/166 [00:31<02:53,  1.23s/it]  avg_loss = 2.24885702591676:  16%|█▌        | 26/166 [00:31<02:52,  1.23s/it]avg_loss = 2.2539092302322388:  16%|█▌        | 26/166 [00:33<02:52,  1.23s/it]avg_loss = 2.2539092302322388:  16%|█▋        | 27/166 [00:33<02:51,  1.23s/it]avg_loss = 2.256742532764162:  16%|█▋        | 27/166 [00:34<02:51,  1.23s/it] avg_loss = 2.256742532764162:  17%|█▋        | 28/166 [00:34<02:50,  1.23s/it]avg_loss = 2.266582468460346:  17%|█▋        | 28/166 [00:35<02:50,  1.23s/it]avg_loss = 2.266582468460346:  17%|█▋        | 29/166 [00:35<02:49,  1.24s/it]avg_loss = 2.2684579650561014:  17%|█▋        | 29/166 [00:36<02:49,  1.24s/it]avg_loss = 2.2684579650561014:  18%|█▊        | 30/166 [00:36<02:48,  1.24s/it]avg_loss = 2.2831351564776514:  18%|█▊        | 30/166 [00:38<02:48,  1.24s/it]avg_loss = 2.2831351564776514:  19%|█▊        | 31/166 [00:38<02:47,  1.24s/it]avg_loss = 2.289284247905016:  19%|█▊        | 31/166 [00:39<02:47,  1.24s/it] avg_loss = 2.289284247905016:  19%|█▉        | 32/166 [00:39<02:46,  1.24s/it]avg_loss = 2.2940491437911987:  19%|█▉        | 32/166 [00:40<02:46,  1.24s/it]avg_loss = 2.2940491437911987:  20%|█▉        | 33/166 [00:40<02:45,  1.24s/it]avg_loss = 2.297207681571736:  20%|█▉        | 33/166 [00:41<02:45,  1.24s/it] avg_loss = 2.297207681571736:  20%|██        | 34/166 [00:41<02:44,  1.24s/it]avg_loss = 2.290916269166129:  20%|██        | 34/166 [00:43<02:44,  1.24s/it]avg_loss = 2.290916269166129:  21%|██        | 35/166 [00:43<02:43,  1.25s/it]avg_loss = 2.287500265571806:  21%|██        | 35/166 [00:44<02:43,  1.25s/it]avg_loss = 2.287500265571806:  22%|██▏       | 36/166 [00:44<02:42,  1.25s/it]avg_loss = 2.280305073067949:  22%|██▏       | 36/166 [00:45<02:42,  1.25s/it]avg_loss = 2.280305073067949:  22%|██▏       | 37/166 [00:45<02:41,  1.25s/it]avg_loss = 2.2788968431322196:  22%|██▏       | 37/166 [00:46<02:41,  1.25s/it]avg_loss = 2.2788968431322196:  23%|██▎       | 38/166 [00:46<02:40,  1.25s/it]avg_loss = 2.278248368165432:  23%|██▎       | 38/166 [00:48<02:40,  1.25s/it] avg_loss = 2.278248368165432:  23%|██▎       | 39/166 [00:48<02:39,  1.25s/it]avg_loss = 2.2802170723676682:  23%|██▎       | 39/166 [00:49<02:39,  1.25s/it]avg_loss = 2.2802170723676682:  24%|██▍       | 40/166 [00:49<02:37,  1.25s/it]avg_loss = 2.2821024830748393:  24%|██▍       | 40/166 [00:50<02:37,  1.25s/it]avg_loss = 2.2821024830748393:  25%|██▍       | 41/166 [00:50<02:36,  1.26s/it]avg_loss = 2.2675554553667703:  25%|██▍       | 41/166 [00:51<02:36,  1.26s/it]avg_loss = 2.2675554553667703:  25%|██▌       | 42/166 [00:51<02:35,  1.26s/it]avg_loss = 2.2509679822034614:  25%|██▌       | 42/166 [00:53<02:35,  1.26s/it]avg_loss = 2.2509679822034614:  26%|██▌       | 43/166 [00:53<02:34,  1.26s/it]avg_loss = 2.239519116553393:  26%|██▌       | 43/166 [00:54<02:34,  1.26s/it] avg_loss = 2.239519116553393:  27%|██▋       | 44/166 [00:54<02:33,  1.26s/it]avg_loss = 2.2253190490934585:  27%|██▋       | 44/166 [00:55<02:33,  1.26s/it]avg_loss = 2.2253190490934585:  27%|██▋       | 45/166 [00:55<02:32,  1.26s/it]avg_loss = 2.215762418249379:  27%|██▋       | 45/166 [00:56<02:32,  1.26s/it] avg_loss = 2.215762418249379:  28%|██▊       | 46/166 [00:56<02:31,  1.26s/it]avg_loss = 2.210075938955266:  28%|██▊       | 46/166 [00:58<02:31,  1.26s/it]avg_loss = 2.210075938955266:  28%|██▊       | 47/166 [00:58<02:30,  1.26s/it]avg_loss = 2.2113943422834077:  28%|██▊       | 47/166 [00:59<02:30,  1.26s/it]avg_loss = 2.2113943422834077:  29%|██▉       | 48/166 [00:59<02:29,  1.26s/it]avg_loss = 2.221564353728781:  29%|██▉       | 48/166 [01:00<02:29,  1.26s/it] avg_loss = 2.221564353728781:  30%|██▉       | 49/166 [01:00<02:27,  1.26s/it]avg_loss = 2.2321872782707213:  30%|██▉       | 49/166 [01:01<02:27,  1.26s/it]avg_loss = 2.2321872782707213:  30%|███       | 50/166 [01:01<02:26,  1.27s/it]avg_loss = 2.2409848115023445:  30%|███       | 50/166 [01:03<02:26,  1.27s/it]avg_loss = 2.2409848115023445:  31%|███       | 51/166 [01:03<02:25,  1.27s/it]avg_loss = 2.2483029388464413:  31%|███       | 51/166 [01:04<02:25,  1.27s/it]avg_loss = 2.2483029388464413:  31%|███▏      | 52/166 [01:04<02:24,  1.27s/it]avg_loss = 2.2513039044614107:  31%|███▏      | 52/166 [01:05<02:24,  1.27s/it]avg_loss = 2.2513039044614107:  32%|███▏      | 53/166 [01:05<02:23,  1.27s/it]avg_loss = 2.2499316687937134:  32%|███▏      | 53/166 [01:07<02:23,  1.27s/it]avg_loss = 2.2499316687937134:  33%|███▎      | 54/166 [01:07<02:22,  1.27s/it]avg_loss = 2.252134841138666:  33%|███▎      | 54/166 [01:08<02:22,  1.27s/it] avg_loss = 2.252134841138666:  33%|███▎      | 55/166 [01:08<02:21,  1.27s/it]avg_loss = 2.2537507734128406:  33%|███▎      | 55/166 [01:09<02:21,  1.27s/it]avg_loss = 2.2537507734128406:  34%|███▎      | 56/166 [01:09<02:20,  1.27s/it]avg_loss = 2.24726420745515:  34%|███▎      | 56/166 [01:10<02:20,  1.27s/it]  avg_loss = 2.24726420745515:  34%|███▍      | 57/166 [01:10<02:18,  1.27s/it]avg_loss = 2.2494716911480346:  34%|███▍      | 57/166 [01:12<02:18,  1.27s/it]avg_loss = 2.2494716911480346:  35%|███▍      | 58/166 [01:12<02:17,  1.28s/it]avg_loss = 2.2460761090456427:  35%|███▍      | 58/166 [01:13<02:17,  1.28s/it]avg_loss = 2.2460761090456427:  36%|███▌      | 59/166 [01:13<02:16,  1.28s/it]avg_loss = 2.2415661752223968:  36%|███▌      | 59/166 [01:14<02:16,  1.28s/it]avg_loss = 2.2415661752223968:  36%|███▌      | 60/166 [01:14<02:15,  1.28s/it]avg_loss = 2.238141311973822:  36%|███▌      | 60/166 [01:15<02:15,  1.28s/it] avg_loss = 2.238141311973822:  37%|███▋      | 61/166 [01:15<02:14,  1.28s/it]avg_loss = 2.234538226358352:  37%|███▋      | 61/166 [01:17<02:14,  1.28s/it]avg_loss = 2.234538226358352:  37%|███▋      | 62/166 [01:17<02:13,  1.28s/it]avg_loss = 2.2297050309559654:  37%|███▋      | 62/166 [01:18<02:13,  1.28s/it]avg_loss = 2.2297050309559654:  38%|███▊      | 63/166 [01:18<02:11,  1.28s/it]avg_loss = 2.2260939609259367:  38%|███▊      | 63/166 [01:19<02:11,  1.28s/it]avg_loss = 2.2260939609259367:  39%|███▊      | 64/166 [01:19<02:10,  1.28s/it]avg_loss = 2.2187381359247063:  39%|███▊      | 64/166 [01:21<02:10,  1.28s/it]avg_loss = 2.2187381359247063:  39%|███▉      | 65/166 [01:21<02:09,  1.28s/it]avg_loss = 2.212464421084433:  39%|███▉      | 65/166 [01:22<02:09,  1.28s/it] avg_loss = 2.212464421084433:  40%|███▉      | 66/166 [01:22<02:08,  1.28s/it]avg_loss = 2.210368400189414:  40%|███▉      | 66/166 [01:23<02:08,  1.28s/it]avg_loss = 2.210368400189414:  40%|████      | 67/166 [01:23<02:07,  1.28s/it]avg_loss = 2.209831534063115:  40%|████      | 67/166 [01:24<02:07,  1.28s/it]avg_loss = 2.209831534063115:  41%|████      | 68/166 [01:24<02:05,  1.28s/it]avg_loss = 2.2143373333889507:  41%|████      | 68/166 [01:26<02:05,  1.28s/it]avg_loss = 2.2143373333889507:  42%|████▏     | 69/166 [01:26<02:04,  1.28s/it]avg_loss = 2.21852959053857:  42%|████▏     | 69/166 [01:27<02:04,  1.28s/it]  avg_loss = 2.21852959053857:  42%|████▏     | 70/166 [01:27<02:03,  1.29s/it]avg_loss = 2.2219516777656447:  42%|████▏     | 70/166 [01:28<02:03,  1.29s/it]avg_loss = 2.2219516777656447:  43%|████▎     | 71/166 [01:28<02:02,  1.29s/it]avg_loss = 2.2269643197456994:  43%|████▎     | 71/166 [01:30<02:02,  1.29s/it]avg_loss = 2.2269643197456994:  43%|████▎     | 72/166 [01:30<02:00,  1.29s/it]avg_loss = 2.2336633874945444:  43%|████▎     | 72/166 [01:31<02:00,  1.29s/it]avg_loss = 2.2336633874945444:  44%|████▍     | 73/166 [01:31<01:59,  1.29s/it]avg_loss = 2.2286583152977197:  44%|████▍     | 73/166 [01:32<01:59,  1.29s/it]avg_loss = 2.2286583152977197:  45%|████▍     | 74/166 [01:32<01:58,  1.29s/it]avg_loss = 2.2242802874247234:  45%|████▍     | 74/166 [01:33<01:58,  1.29s/it]avg_loss = 2.2242802874247234:  45%|████▌     | 75/166 [01:33<01:57,  1.29s/it]avg_loss = 2.2240802959391943:  45%|████▌     | 75/166 [01:35<01:57,  1.29s/it]avg_loss = 2.2240802959391943:  46%|████▌     | 76/166 [01:35<01:56,  1.29s/it]avg_loss = 2.2207430523711365:  46%|████▌     | 76/166 [01:36<01:56,  1.29s/it]avg_loss = 2.2207430523711365:  46%|████▋     | 77/166 [01:36<01:54,  1.29s/it]avg_loss = 2.217408252068055:  46%|████▋     | 77/166 [01:37<01:54,  1.29s/it] avg_loss = 2.217408252068055:  47%|████▋     | 78/166 [01:37<01:53,  1.29s/it]avg_loss = 2.21382102936129:  47%|████▋     | 78/166 [01:39<01:53,  1.29s/it] avg_loss = 2.21382102936129:  48%|████▊     | 79/166 [01:39<01:52,  1.29s/it]avg_loss = 2.2100848719477653:  48%|████▊     | 79/166 [01:40<01:52,  1.29s/it]avg_loss = 2.2100848719477653:  48%|████▊     | 80/166 [01:40<01:51,  1.29s/it]avg_loss = 2.2022894915239313:  48%|████▊     | 80/166 [01:41<01:51,  1.29s/it]avg_loss = 2.2022894915239313:  49%|████▉     | 81/166 [01:41<01:49,  1.29s/it]avg_loss = 2.204188182586577:  49%|████▉     | 81/166 [01:43<01:49,  1.29s/it] avg_loss = 2.204188182586577:  49%|████▉     | 82/166 [01:43<01:48,  1.29s/it]avg_loss = 2.205614461956254:  49%|████▉     | 82/166 [01:44<01:48,  1.29s/it]avg_loss = 2.205614461956254:  50%|█████     | 83/166 [01:44<01:47,  1.30s/it]avg_loss = 2.209225993780863:  50%|█████     | 83/166 [01:45<01:47,  1.30s/it]avg_loss = 2.209225993780863:  51%|█████     | 84/166 [01:45<01:46,  1.30s/it]avg_loss = 2.211485235831317:  51%|█████     | 84/166 [01:46<01:46,  1.30s/it]avg_loss = 2.211485235831317:  51%|█████     | 85/166 [01:46<01:45,  1.30s/it]avg_loss = 2.2093189053757247:  51%|█████     | 85/166 [01:48<01:45,  1.30s/it]avg_loss = 2.2093189053757247:  52%|█████▏    | 86/166 [01:48<01:43,  1.30s/it]avg_loss = 2.2083598649364777:  52%|█████▏    | 86/166 [01:49<01:43,  1.30s/it]avg_loss = 2.2083598649364777:  52%|█████▏    | 87/166 [01:49<01:42,  1.30s/it]avg_loss = 2.2077719501473685:  52%|█████▏    | 87/166 [01:50<01:42,  1.30s/it]avg_loss = 2.2077719501473685:  53%|█████▎    | 88/166 [01:50<01:41,  1.30s/it]avg_loss = 2.2086789782127636:  53%|█████▎    | 88/166 [01:52<01:41,  1.30s/it]avg_loss = 2.2086789782127636:  54%|█████▎    | 89/166 [01:52<01:40,  1.30s/it]avg_loss = 2.2094659977489046:  54%|█████▎    | 89/166 [01:53<01:40,  1.30s/it]avg_loss = 2.2094659977489046:  54%|█████▍    | 90/166 [01:53<01:38,  1.30s/it]avg_loss = 2.2087714763788076:  54%|█████▍    | 90/166 [01:54<01:38,  1.30s/it]avg_loss = 2.2087714763788076:  55%|█████▍    | 91/166 [01:54<01:37,  1.30s/it]avg_loss = 2.209855873947558:  55%|█████▍    | 91/166 [01:56<01:37,  1.30s/it] avg_loss = 2.209855873947558:  55%|█████▌    | 92/166 [01:56<01:36,  1.30s/it]avg_loss = 2.2138315131587367:  55%|█████▌    | 92/166 [01:57<01:36,  1.30s/it]avg_loss = 2.2138315131587367:  56%|█████▌    | 93/166 [01:57<01:34,  1.30s/it]avg_loss = 2.2111391551951143:  56%|█████▌    | 93/166 [01:58<01:34,  1.30s/it]avg_loss = 2.2111391551951143:  57%|█████▋    | 94/166 [01:58<01:33,  1.30s/it]avg_loss = 2.2099259363977533:  57%|█████▋    | 94/166 [01:59<01:33,  1.30s/it]avg_loss = 2.2099259363977533:  57%|█████▋    | 95/166 [01:59<01:32,  1.30s/it]avg_loss = 2.2099468347926936:  57%|█████▋    | 95/166 [02:01<01:32,  1.30s/it]avg_loss = 2.2099468347926936:  58%|█████▊    | 96/166 [02:01<01:30,  1.30s/it]avg_loss = 2.209666767071203:  58%|█████▊    | 96/166 [02:02<01:30,  1.30s/it] avg_loss = 2.209666767071203:  58%|█████▊    | 97/166 [02:02<01:29,  1.30s/it]avg_loss = 2.207262842022643:  58%|█████▊    | 97/166 [02:03<01:29,  1.30s/it]avg_loss = 2.207262842022643:  59%|█████▉    | 98/166 [02:03<01:28,  1.30s/it]avg_loss = 2.2045717913695055:  59%|█████▉    | 98/166 [02:05<01:28,  1.30s/it]avg_loss = 2.2045717913695055:  60%|█████▉    | 99/166 [02:05<01:27,  1.30s/it]avg_loss = 2.2025664949417116:  60%|█████▉    | 99/166 [02:06<01:27,  1.30s/it]avg_loss = 2.2025664949417116:  60%|██████    | 100/166 [02:06<01:25,  1.30s/it]avg_loss = 2.202812135809719:  60%|██████    | 100/166 [02:07<01:25,  1.30s/it] avg_loss = 2.202812135809719:  61%|██████    | 101/166 [02:07<01:24,  1.30s/it]avg_loss = 2.2034538096072627:  61%|██████    | 101/166 [02:09<01:24,  1.30s/it]avg_loss = 2.2034538096072627:  61%|██████▏   | 102/166 [02:09<01:23,  1.30s/it]avg_loss = 2.204485011332243:  61%|██████▏   | 102/166 [02:10<01:23,  1.30s/it] avg_loss = 2.204485011332243:  62%|██████▏   | 103/166 [02:10<01:21,  1.30s/it]avg_loss = 2.206476832811649:  62%|██████▏   | 103/166 [02:11<01:21,  1.30s/it]avg_loss = 2.206476832811649:  63%|██████▎   | 104/166 [02:11<01:20,  1.30s/it]avg_loss = 2.2136399700528098:  63%|██████▎   | 104/166 [02:12<01:20,  1.30s/it]avg_loss = 2.2136399700528098:  63%|██████▎   | 105/166 [02:12<01:19,  1.30s/it]avg_loss = 2.219082735619455:  63%|██████▎   | 105/166 [02:14<01:19,  1.30s/it] avg_loss = 2.219082735619455:  64%|██████▍   | 106/166 [02:14<01:17,  1.30s/it]avg_loss = 2.2228693605583403:  64%|██████▍   | 106/166 [02:15<01:17,  1.30s/it]avg_loss = 2.2228693605583403:  64%|██████▍   | 107/166 [02:15<01:16,  1.30s/it]avg_loss = 2.226246392285382:  64%|██████▍   | 107/166 [02:16<01:16,  1.30s/it] avg_loss = 2.226246392285382:  65%|██████▌   | 108/166 [02:16<01:15,  1.30s/it]avg_loss = 2.2318103050966873:  65%|██████▌   | 108/166 [02:18<01:15,  1.30s/it]avg_loss = 2.2318103050966873:  66%|██████▌   | 109/166 [02:18<01:14,  1.30s/it]avg_loss = 2.2354870666157116:  66%|██████▌   | 109/166 [02:19<01:14,  1.30s/it]avg_loss = 2.2354870666157116:  66%|██████▋   | 110/166 [02:19<01:12,  1.30s/it]avg_loss = 2.23572529328836:  66%|██████▋   | 110/166 [02:20<01:12,  1.30s/it]  avg_loss = 2.23572529328836:  67%|██████▋   | 111/166 [02:20<01:11,  1.30s/it]avg_loss = 2.2366463201386586:  67%|██████▋   | 111/166 [02:22<01:11,  1.30s/it]avg_loss = 2.2366463201386586:  67%|██████▋   | 112/166 [02:22<01:10,  1.30s/it]avg_loss = 2.235993102588485:  67%|██████▋   | 112/166 [02:23<01:10,  1.30s/it] avg_loss = 2.235993102588485:  68%|██████▊   | 113/166 [02:23<01:09,  1.30s/it]avg_loss = 2.2368936455040647:  68%|██████▊   | 113/166 [02:24<01:09,  1.30s/it]avg_loss = 2.2368936455040647:  69%|██████▊   | 114/166 [02:24<01:07,  1.30s/it]avg_loss = 2.235309302288553:  69%|██████▊   | 114/166 [02:25<01:07,  1.30s/it] avg_loss = 2.235309302288553:  69%|██████▉   | 115/166 [02:25<01:06,  1.30s/it]avg_loss = 2.2355202826960334:  69%|██████▉   | 115/166 [02:27<01:06,  1.30s/it]avg_loss = 2.2355202826960334:  70%|██████▉   | 116/166 [02:27<01:05,  1.30s/it]avg_loss = 2.2366926507053213:  70%|██████▉   | 116/166 [02:28<01:05,  1.30s/it]avg_loss = 2.2366926507053213:  70%|███████   | 117/166 [02:28<01:03,  1.30s/it]avg_loss = 2.2367662736925027:  70%|███████   | 117/166 [02:29<01:03,  1.30s/it]avg_loss = 2.2367662736925027:  71%|███████   | 118/166 [02:29<01:02,  1.31s/it]avg_loss = 2.2374252191110817:  71%|███████   | 118/166 [02:31<01:02,  1.31s/it]avg_loss = 2.2374252191110817:  72%|███████▏  | 119/166 [02:31<01:01,  1.30s/it]avg_loss = 2.238543067375819:  72%|███████▏  | 119/166 [02:32<01:01,  1.30s/it] avg_loss = 2.238543067375819:  72%|███████▏  | 120/166 [02:32<01:00,  1.30s/it]avg_loss = 2.2388597579041787:  72%|███████▏  | 120/166 [02:33<01:00,  1.30s/it]avg_loss = 2.2388597579041787:  73%|███████▎  | 121/166 [02:33<00:58,  1.30s/it]avg_loss = 2.2400458699367087:  73%|███████▎  | 121/166 [02:35<00:58,  1.30s/it]avg_loss = 2.2400458699367087:  73%|███████▎  | 122/166 [02:35<00:57,  1.31s/it]avg_loss = 2.2398853612139944:  73%|███████▎  | 122/166 [02:36<00:57,  1.31s/it]avg_loss = 2.2398853612139944:  74%|███████▍  | 123/166 [02:36<00:56,  1.30s/it]avg_loss = 2.238641050554091:  74%|███████▍  | 123/166 [02:37<00:56,  1.30s/it] avg_loss = 2.238641050554091:  75%|███████▍  | 124/166 [02:37<00:54,  1.31s/it]avg_loss = 2.2369810256958007:  75%|███████▍  | 124/166 [02:38<00:54,  1.31s/it]avg_loss = 2.2369810256958007:  75%|███████▌  | 125/166 [02:38<00:53,  1.31s/it]avg_loss = 2.2350849386245484:  75%|███████▌  | 125/166 [02:40<00:53,  1.31s/it]avg_loss = 2.2350849386245484:  76%|███████▌  | 126/166 [02:40<00:52,  1.31s/it]avg_loss = 2.232908306159372:  76%|███████▌  | 126/166 [02:41<00:52,  1.31s/it] avg_loss = 2.232908306159372:  77%|███████▋  | 127/166 [02:41<00:50,  1.31s/it]avg_loss = 2.231690843589604:  77%|███████▋  | 127/166 [02:42<00:50,  1.31s/it]avg_loss = 2.231690843589604:  77%|███████▋  | 128/166 [02:42<00:49,  1.31s/it]avg_loss = 2.231837120167045:  77%|███████▋  | 128/166 [02:44<00:49,  1.31s/it]avg_loss = 2.231837120167045:  78%|███████▊  | 129/166 [02:44<00:48,  1.31s/it]avg_loss = 2.232033754312075:  78%|███████▊  | 129/166 [02:45<00:48,  1.31s/it]avg_loss = 2.232033754312075:  78%|███████▊  | 130/166 [02:45<00:47,  1.31s/it]avg_loss = 2.232910883335667:  78%|███████▊  | 130/166 [02:46<00:47,  1.31s/it]avg_loss = 2.232910883335667:  79%|███████▉  | 131/166 [02:46<00:45,  1.31s/it]avg_loss = 2.233456254908533:  79%|███████▉  | 131/166 [02:48<00:45,  1.31s/it]avg_loss = 2.233456254908533:  80%|███████▉  | 132/166 [02:48<00:44,  1.31s/it]avg_loss = 2.2341920979937218:  80%|███████▉  | 132/166 [02:49<00:44,  1.31s/it]avg_loss = 2.2341920979937218:  80%|████████  | 133/166 [02:49<00:43,  1.31s/it]avg_loss = 2.235173913080301:  80%|████████  | 133/166 [02:50<00:43,  1.31s/it] avg_loss = 2.235173913080301:  81%|████████  | 134/166 [02:50<00:41,  1.31s/it]avg_loss = 2.2321849275518346:  81%|████████  | 134/166 [02:52<00:41,  1.31s/it]avg_loss = 2.2321849275518346:  81%|████████▏ | 135/166 [02:52<00:40,  1.31s/it]avg_loss = 2.2313587332473084:  81%|████████▏ | 135/166 [02:53<00:40,  1.31s/it]avg_loss = 2.2313587332473084:  82%|████████▏ | 136/166 [02:53<00:39,  1.31s/it]avg_loss = 2.231482732034948:  82%|████████▏ | 136/166 [02:54<00:39,  1.31s/it] avg_loss = 2.231482732034948:  83%|████████▎ | 137/166 [02:54<00:37,  1.31s/it]avg_loss = 2.231975543326226:  83%|████████▎ | 137/166 [02:55<00:37,  1.31s/it]avg_loss = 2.231975543326226:  83%|████████▎ | 138/166 [02:55<00:36,  1.31s/it]avg_loss = 2.230279919912489:  83%|████████▎ | 138/166 [02:57<00:36,  1.31s/it]avg_loss = 2.230279919912489:  84%|████████▎ | 139/166 [02:57<00:35,  1.31s/it]avg_loss = 2.228028883252825:  84%|████████▎ | 139/166 [02:58<00:35,  1.31s/it]avg_loss = 2.228028883252825:  84%|████████▍ | 140/166 [02:58<00:34,  1.31s/it]avg_loss = 2.225706415818938:  84%|████████▍ | 140/166 [02:59<00:34,  1.31s/it]avg_loss = 2.225706415818938:  85%|████████▍ | 141/166 [02:59<00:32,  1.31s/it]avg_loss = 2.225099097675001:  85%|████████▍ | 141/166 [03:01<00:32,  1.31s/it]avg_loss = 2.225099097675001:  86%|████████▌ | 142/166 [03:01<00:31,  1.31s/it]avg_loss = 2.2232824747379007:  86%|████████▌ | 142/166 [03:02<00:31,  1.31s/it]avg_loss = 2.2232824747379007:  86%|████████▌ | 143/166 [03:02<00:30,  1.31s/it]avg_loss = 2.2244442279140153:  86%|████████▌ | 143/166 [03:03<00:30,  1.31s/it]avg_loss = 2.2244442279140153:  87%|████████▋ | 144/166 [03:03<00:28,  1.31s/it]avg_loss = 2.222833678640168:  87%|████████▋ | 144/166 [03:05<00:28,  1.31s/it] avg_loss = 2.222833678640168:  87%|████████▋ | 145/166 [03:05<00:27,  1.31s/it]avg_loss = 2.222226431108501:  87%|████████▋ | 145/166 [03:06<00:27,  1.31s/it]avg_loss = 2.222226431108501:  88%|████████▊ | 146/166 [03:06<00:26,  1.31s/it]avg_loss = 2.2204358934545194:  88%|████████▊ | 146/166 [03:07<00:26,  1.31s/it]avg_loss = 2.2204358934545194:  89%|████████▊ | 147/166 [03:07<00:24,  1.31s/it]avg_loss = 2.2186672776132017:  89%|████████▊ | 147/166 [03:09<00:24,  1.31s/it]avg_loss = 2.2186672776132017:  89%|████████▉ | 148/166 [03:09<00:23,  1.31s/it]avg_loss = 2.216809771204955:  89%|████████▉ | 148/166 [03:10<00:23,  1.31s/it] avg_loss = 2.216809771204955:  90%|████████▉ | 149/166 [03:10<00:22,  1.31s/it]avg_loss = 2.2173183385531106:  90%|████████▉ | 149/166 [03:11<00:22,  1.31s/it]avg_loss = 2.2173183385531106:  90%|█████████ | 150/166 [03:11<00:20,  1.31s/it]avg_loss = 2.2160022645596635:  90%|█████████ | 150/166 [03:13<00:20,  1.31s/it]avg_loss = 2.2160022645596635:  91%|█████████ | 151/166 [03:13<00:19,  1.31s/it]avg_loss = 2.215399346069286:  91%|█████████ | 151/166 [03:14<00:19,  1.31s/it] avg_loss = 2.215399346069286:  92%|█████████▏| 152/166 [03:14<00:18,  1.31s/it]avg_loss = 2.21484306045607:  92%|█████████▏| 152/166 [03:15<00:18,  1.31s/it] avg_loss = 2.21484306045607:  92%|█████████▏| 153/166 [03:15<00:17,  1.31s/it]avg_loss = 2.216877300243873:  92%|█████████▏| 153/166 [03:16<00:17,  1.31s/it]avg_loss = 2.216877300243873:  93%|█████████▎| 154/166 [03:16<00:15,  1.31s/it]avg_loss = 2.2158259414857433:  93%|█████████▎| 154/166 [03:18<00:15,  1.31s/it]avg_loss = 2.2158259414857433:  93%|█████████▎| 155/166 [03:18<00:14,  1.31s/it]avg_loss = 2.215408309147908:  93%|█████████▎| 155/166 [03:19<00:14,  1.31s/it] avg_loss = 2.215408309147908:  94%|█████████▍| 156/166 [03:19<00:13,  1.31s/it]avg_loss = 2.2131706400282063:  94%|█████████▍| 156/166 [03:20<00:13,  1.31s/it]avg_loss = 2.2131706400282063:  95%|█████████▍| 157/166 [03:20<00:11,  1.31s/it]avg_loss = 2.2074631120585186:  95%|█████████▍| 157/166 [03:22<00:11,  1.31s/it]avg_loss = 2.2074631120585186:  95%|█████████▌| 158/166 [03:22<00:10,  1.31s/it]avg_loss = 2.208216869606162:  95%|█████████▌| 158/166 [03:23<00:10,  1.31s/it] avg_loss = 2.208216869606162:  96%|█████████▌| 159/166 [03:23<00:09,  1.31s/it]avg_loss = 2.2093170657753944:  96%|█████████▌| 159/166 [03:24<00:09,  1.31s/it]avg_loss = 2.2093170657753944:  96%|█████████▋| 160/166 [03:24<00:07,  1.31s/it]avg_loss = 2.211499584387548:  96%|█████████▋| 160/166 [03:26<00:07,  1.31s/it] avg_loss = 2.211499584387548:  97%|█████████▋| 161/166 [03:26<00:06,  1.31s/it]avg_loss = 2.2124500465981756:  97%|█████████▋| 161/166 [03:27<00:06,  1.31s/it]avg_loss = 2.2124500465981756:  98%|█████████▊| 162/166 [03:27<00:05,  1.31s/it]avg_loss = 2.2129448103758453:  98%|█████████▊| 162/166 [03:28<00:05,  1.31s/it]avg_loss = 2.2129448103758453:  98%|█████████▊| 163/166 [03:28<00:03,  1.31s/it]avg_loss = 2.214146539932344:  98%|█████████▊| 163/166 [03:30<00:03,  1.31s/it] avg_loss = 2.214146539932344:  99%|█████████▉| 164/166 [03:30<00:02,  1.31s/it]avg_loss = 2.214610900300922:  99%|█████████▉| 164/166 [03:31<00:02,  1.31s/it]avg_loss = 2.214610900300922:  99%|█████████▉| 165/166 [03:31<00:01,  1.31s/it]avg_loss = 2.2166807881320816:  99%|█████████▉| 165/166 [03:32<00:01,  1.31s/it]avg_loss = 2.2166807881320816: 100%|██████████| 166/166 [03:32<00:00,  1.31s/it]avg_loss = 2.2166807881320816: 100%|██████████| 166/166 [03:32<00:00,  1.28s/it]
I0403 05:42:14.338807 3434827 eval_ppl.py:107] wikitext2 perplexity: 9.176819801330566
wikitext2 perplexity: 9.177
