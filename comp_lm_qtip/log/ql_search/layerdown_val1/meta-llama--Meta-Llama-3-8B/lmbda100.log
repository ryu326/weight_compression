I0409 16:46:33.628942 1491532 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:46:33.629030 1491532 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:46:33.629070 1491532 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:46:33.960138 1491532 config.py:54] PyTorch version 2.6.0 available.
W0409 16:46:34.161035 1491532 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:46:34.778190 1491532 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.12it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.75it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.85it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.97it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.98it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.93it/s]
I0409 16:46:36.261878 1491532 quantize_finetune_llama.py:160] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:21,  1.46it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:21,  1.42it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:20,  1.42it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:17,  1.57it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:15,  1.69it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:14,  1.77it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:13,  1.82it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:12,  1.88it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:05<00:12,  1.90it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:05<00:11,  1.91it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:10,  1.92it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:06<00:10,  1.94it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:09,  1.92it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:07<00:09,  1.93it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:08,  1.93it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:08<00:08,  1.93it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:07,  1.95it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:09<00:07,  1.94it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.95it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:10<00:06,  1.95it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:05,  1.95it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:11<00:05,  1.96it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:04,  1.96it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:12<00:04,  1.94it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:13<00:03,  1.94it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:13<00:02,  2.04it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:14<00:02,  2.06it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:14<00:01,  2.01it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:15<00:01,  2.02it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:15<00:01,  1.98it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:16<00:00,  1.97it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.99it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.90it/s]
I0409 16:47:02.796107 1491532 quantize_finetune_llama.py:198] loaded compression model
I0409 16:47:22.295559 1491532 quantize_finetune_llama.py:202] loaded dataset and devset
I0409 16:47:24.766504 1491532 quantize_finetune_llama.py:222] layer 0 gpu 0
I0409 16:47:27.085761 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 0 in 2.172196626663208s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0409 16:47:37.711910 1493800 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:47:37.712012 1493800 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:47:37.712054 1493800 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:47:38.067470 1493800 config.py:54] PyTorch version 2.6.0 available.
W0409 16:47:38.276462 1493800 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:47:38.883607 1493800 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:47:38.891392 1491532 quantize_finetune_llama.py:222] layer 1 gpu 0
I0409 16:47:38.901263 1493800 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:47:41.467480 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 1 in 0.7472538948059082s
I0409 16:47:45.007161 1494128 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:47:45.007262 1494128 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:47:45.007302 1494128 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:47:45.344781 1494128 config.py:54] PyTorch version 2.6.0 available.
W0409 16:47:45.544261 1494128 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:47:46.114305 1494128 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:47:46.117999 1491532 quantize_finetune_llama.py:222] layer 2 gpu 0
I0409 16:47:46.131076 1494128 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-2:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:47:48.708932 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 2 in 0.8627059459686279s
I0409 16:47:52.369066 1494454 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:47:52.369158 1494454 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:47:52.369198 1494454 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:47:52.713732 1494454 config.py:54] PyTorch version 2.6.0 available.
W0409 16:47:52.906936 1494454 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:47:53.471757 1494454 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:47:53.475429 1491532 quantize_finetune_llama.py:222] layer 3 gpu 0
I0409 16:47:53.488279 1494454 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-3:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:47:56.280049 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 3 in 0.9503772258758545s
I0409 16:47:59.899386 1494770 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:47:59.899482 1494770 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:47:59.899522 1494770 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:00.237724 1494770 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:00.445198 1494770 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:01.029183 1494770 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:01.032885 1491532 quantize_finetune_llama.py:222] layer 4 gpu 0
I0409 16:48:01.049052 1494770 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-4:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:03.882243 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 4 in 1.0196704864501953s
I0409 16:48:07.468386 1495101 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:07.468478 1495101 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:07.468520 1495101 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:07.793455 1495101 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:07.981707 1495101 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:08.552975 1495101 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:08.557036 1491532 quantize_finetune_llama.py:222] layer 5 gpu 0
I0409 16:48:08.570696 1495101 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-5:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:11.397026 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 5 in 0.942068338394165s
I0409 16:48:15.041793 1495431 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:15.041887 1495431 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:15.041924 1495431 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:15.367938 1495431 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:15.564119 1495431 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:16.130321 1495431 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:16.134079 1491532 quantize_finetune_llama.py:222] layer 6 gpu 0
I0409 16:48:16.150539 1495431 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-6:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:18.823313 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 6 in 0.8666064739227295s
I0409 16:48:22.381842 1495750 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:22.381931 1495750 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:22.381970 1495750 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:22.713929 1495750 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:22.910180 1495750 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:23.567258 1495750 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:23.571342 1491532 quantize_finetune_llama.py:222] layer 7 gpu 0
I0409 16:48:23.608219 1495750 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-7:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:26.338927 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 7 in 0.9766099452972412s
I0409 16:48:29.845326 1496076 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:29.845414 1496076 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:29.845452 1496076 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:30.177345 1496076 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:30.384500 1496076 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:31.004567 1496076 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:31.008563 1491532 quantize_finetune_llama.py:222] layer 8 gpu 0
I0409 16:48:31.044147 1496076 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-8:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:33.940600 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 8 in 1.1108520030975342s
I0409 16:48:37.526187 1496458 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:37.526304 1496458 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:37.526349 1496458 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:37.859442 1496458 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:38.065750 1496458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:38.702180 1496458 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:38.706402 1491532 quantize_finetune_llama.py:222] layer 9 gpu 0
I0409 16:48:38.720986 1496458 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-9:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:41.278017 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 9 in 0.7971901893615723s
I0409 16:48:44.888767 1496782 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:44.888854 1496782 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:44.888891 1496782 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:45.226401 1496782 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:45.448045 1496782 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:46.042259 1496782 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:46.045949 1491532 quantize_finetune_llama.py:222] layer 10 gpu 0
I0409 16:48:46.058774 1496782 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-10:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:48.474280 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 10 in 0.734534502029419s
I0409 16:48:52.049320 1497100 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:52.049417 1497100 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:52.049456 1497100 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:52.394899 1497100 config.py:54] PyTorch version 2.6.0 available.
W0409 16:48:52.583180 1497100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:48:53.243937 1497100 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:48:53.248370 1491532 quantize_finetune_llama.py:222] layer 11 gpu 0
I0409 16:48:53.261470 1497100 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-11:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:48:55.948867 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 11 in 0.8784985542297363s
I0409 16:48:59.534239 1497421 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:48:59.534339 1497421 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:48:59.534379 1497421 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:48:59.902281 1497421 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:00.111757 1497421 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:00.719990 1497421 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:00.725665 1491532 quantize_finetune_llama.py:222] layer 12 gpu 0
I0409 16:49:00.737695 1497421 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-12:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:03.412081 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 12 in 0.9470701217651367s
I0409 16:49:07.044226 1497787 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:07.044327 1497787 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:07.044371 1497787 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:07.468248 1497787 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:07.668432 1497787 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:08.243498 1497787 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:08.247239 1491532 quantize_finetune_llama.py:222] layer 13 gpu 0
I0409 16:49:08.260906 1497787 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-13:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:10.928047 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 13 in 0.9198312759399414s
I0409 16:49:14.587486 1498119 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:14.587588 1498119 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:14.587626 1498119 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:14.912760 1498119 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:15.104465 1498119 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:15.706116 1498119 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:15.709864 1491532 quantize_finetune_llama.py:222] layer 14 gpu 0
I0409 16:49:15.726055 1498119 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-14:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:18.563657 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 14 in 1.0950109958648682s
I0409 16:49:22.190337 1498455 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:22.190426 1498455 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:22.190463 1498455 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:22.513268 1498455 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:22.699267 1498455 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:23.295495 1498455 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:23.299462 1491532 quantize_finetune_llama.py:222] layer 15 gpu 0
I0409 16:49:23.314656 1498455 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-15:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:26.051907 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 15 in 0.9436566829681396s
I0409 16:49:29.671417 1498828 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:29.671511 1498828 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:29.671548 1498828 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:29.993970 1498828 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:30.183707 1498828 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:30.792002 1498828 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:30.795801 1491532 quantize_finetune_llama.py:222] layer 16 gpu 0
I0409 16:49:30.812301 1498828 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-16:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:33.452168 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 16 in 0.93894362449646s
I0409 16:49:37.164689 1499148 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:37.164782 1499148 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:37.164820 1499148 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:37.487734 1499148 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:37.694277 1499148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:38.276291 1499148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:38.280359 1491532 quantize_finetune_llama.py:222] layer 17 gpu 0
I0409 16:49:38.299523 1499148 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-17:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:40.777949 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 17 in 0.7351644039154053s
I0409 16:49:44.351310 1499474 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:44.351401 1499474 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:44.351443 1499474 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:44.675305 1499474 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:44.865971 1499474 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:45.439564 1499474 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:45.443295 1491532 quantize_finetune_llama.py:222] layer 18 gpu 0
I0409 16:49:45.459442 1499474 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-18:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:47.731317 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 18 in 0.5221776962280273s
I0409 16:49:51.252636 1499718 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:51.252732 1499718 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:51.252770 1499718 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:51.576149 1499718 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:51.762620 1499718 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:52.319052 1499718 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:52.322723 1491532 quantize_finetune_llama.py:222] layer 19 gpu 0
I0409 16:49:52.335676 1499718 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-19:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:49:54.661002 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 19 in 0.6382720470428467s
I0409 16:49:58.211887 1500025 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:49:58.211978 1500025 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:49:58.212016 1500025 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:49:58.539690 1500025 config.py:54] PyTorch version 2.6.0 available.
W0409 16:49:58.728596 1500025 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:49:59.294924 1500025 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:49:59.298652 1491532 quantize_finetune_llama.py:222] layer 20 gpu 0
I0409 16:49:59.311259 1500025 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-20:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:01.974261 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 20 in 0.9928576946258545s
I0409 16:50:05.415708 1500249 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:05.415796 1500249 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:05.415846 1500249 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:05.737790 1500249 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:05.930318 1500249 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:06.468945 1500249 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:06.472758 1491532 quantize_finetune_llama.py:222] layer 21 gpu 0
I0409 16:50:06.485748 1500249 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-21:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:08.971925 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 21 in 0.8295457363128662s
I0409 16:50:12.371940 1500466 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:12.372038 1500466 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:12.372075 1500466 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:12.695619 1500466 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:12.883474 1500466 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:13.432159 1500466 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:13.435904 1491532 quantize_finetune_llama.py:222] layer 22 gpu 0
I0409 16:50:13.448894 1500466 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-22:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:15.941158 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 22 in 0.8413252830505371s
I0409 16:50:19.334099 1500593 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:19.334191 1500593 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:19.334233 1500593 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:19.656161 1500593 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:19.843278 1500593 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:20.377872 1500593 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:20.381654 1491532 quantize_finetune_llama.py:222] layer 23 gpu 0
I0409 16:50:20.394575 1500593 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-23:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:22.839567 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 23 in 0.8136491775512695s
I0409 16:50:26.247609 1500714 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:26.247705 1500714 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:26.247745 1500714 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:26.571379 1500714 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:26.760366 1500714 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:27.303762 1500714 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:27.307548 1491532 quantize_finetune_llama.py:222] layer 24 gpu 0
I0409 16:50:27.320421 1500714 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-24:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:29.783708 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 24 in 0.8319065570831299s
I0409 16:50:33.156198 1500837 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:33.156292 1500837 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:33.156328 1500837 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:33.476592 1500837 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:33.663398 1500837 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:34.200544 1500837 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:34.204413 1491532 quantize_finetune_llama.py:222] layer 25 gpu 0
I0409 16:50:34.219711 1500837 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-25:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:36.539748 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 25 in 0.6868908405303955s
I0409 16:50:40.002293 1500955 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:40.002389 1500955 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:40.002426 1500955 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:40.321724 1500955 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:40.508759 1500955 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:41.051527 1500955 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:41.055315 1491532 quantize_finetune_llama.py:222] layer 26 gpu 0
I0409 16:50:41.068206 1500955 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-26:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:43.221799 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 26 in 0.49350953102111816s
I0409 16:50:46.627466 1501069 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:46.627566 1501069 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:46.627604 1501069 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:46.950175 1501069 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:47.137682 1501069 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:47.674100 1501069 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:47.677879 1491532 quantize_finetune_llama.py:222] layer 27 gpu 0
I0409 16:50:47.690652 1501069 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-27:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:49.859759 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 27 in 0.5185642242431641s
I0409 16:50:53.188616 1501193 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:53.188709 1501193 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:53.188748 1501193 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:50:53.511596 1501193 config.py:54] PyTorch version 2.6.0 available.
W0409 16:50:53.697756 1501193 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:50:54.258055 1501193 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:50:54.261842 1491532 quantize_finetune_llama.py:222] layer 28 gpu 0
I0409 16:50:54.274744 1501193 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-28:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:50:56.478997 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 28 in 0.513472318649292s
I0409 16:50:59.845033 1501313 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:50:59.845129 1501313 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:50:59.845171 1501313 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:51:00.168534 1501313 config.py:54] PyTorch version 2.6.0 available.
W0409 16:51:00.356086 1501313 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:51:00.899434 1501313 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:51:00.903229 1491532 quantize_finetune_llama.py:222] layer 29 gpu 0
I0409 16:51:00.917081 1501313 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-29:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:51:03.178508 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 29 in 0.5877761840820312s
I0409 16:51:06.555759 1501438 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:51:06.555871 1501438 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:51:06.555910 1501438 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:51:06.880077 1501438 config.py:54] PyTorch version 2.6.0 available.
W0409 16:51:07.067284 1501438 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:51:07.632373 1501438 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:51:07.636143 1491532 quantize_finetune_llama.py:222] layer 30 gpu 0
I0409 16:51:07.648919 1501438 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-30:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:51:09.893974 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 30 in 0.6003828048706055s
I0409 16:51:13.284192 1501556 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:51:13.284286 1501556 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:51:13.284328 1501556 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:51:13.608485 1501556 config.py:54] PyTorch version 2.6.0 available.
W0409 16:51:13.795750 1501556 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:51:14.379734 1501556 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:51:14.383496 1491532 quantize_finetune_llama.py:222] layer 31 gpu 0
I0409 16:51:14.396302 1501556 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-31:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:51:16.839929 1491532 quantize_finetune_llama.py:253] computed original embedding for layer 31 in 0.7881882190704346s
I0409 16:51:20.210806 1501681 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:51:20.210897 1501681 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:51:20.210936 1501681 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:51:20.533487 1501681 config.py:54] PyTorch version 2.6.0 available.
W0409 16:51:20.721183 1501681 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0409 16:51:21.255287 1501681 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0409 16:51:21.271915 1501681 data_utils.py:336] using 256 training seqs, 128 validation seqs
Process Process-32:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/quantize_finetune_llama.py", line 131, in compress_llama_decoder
    finetune.compress_finetune_decoder_layer(layer, quant_order, idx, comp_model, ql_i, args,
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/finetune.py", line 132, in compress_finetune_decoder_layer
    W_hat, bpp_loss_sum, num_pixels, SU, SV, scaleWH, ft_result = nwc.compress_linear(W.clone(), HR, comp_model, ql, args, device)
  File "/workspace/Weight_compression/comp_lm_qtip/lib/algo/nwc.py", line 256, in compress_linear
    if args.ql_tuned is not None:
AttributeError: 'Namespace' object has no attribute 'ql_tuned'
I0409 16:51:32.286964 1501981 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0409 16:51:32.287110 1501981 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0409 16:51:32.287148 1501981 utils.py:162] NumExpr defaulting to 16 threads.
I0409 16:51:32.699999 1501981 config.py:54] PyTorch version 2.6.0 available.
W0409 16:51:32.905538 1501981 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0409 16:51:33.015000 1501981 hfize_llama.py:27] LlamaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "../Wparam_dataset/hf_model/meta-llama--Meta-Llama-3-8B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "quip_params": {},
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.47.1",
  "use_cache": true,
  "vocab_size": 128256
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:01,  3.32it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:01,  4.16it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  4.58it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  5.00it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:01<00:00,  4.49it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:01<00:00,  5.13it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  6.02it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  5.10it/s]
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  8.56it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  8.73it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  8.53it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.77it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.99it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.92it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s]
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 194, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/quantize_llama/hfize_llama.py", line 85, in main
    saved_layer = torch.load(f'{args.quantized_path}/{ii}_q.pt',
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 1425, in load
    with _open_file_like(f, "rb") as opened_file:
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 751, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 732, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '../hf_model_comp/comp_qtip/ckpt/ql_search/layerdown_val1/meta-llama--Meta-Llama-3-8B/lmbda100/0_q.pt'
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../hf_model_comp/comp_qtip/hf/ql_search/layerdown_val1/meta-llama--Meta-Llama-3-8B/lmbda100'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 34, in model_from_hf_path
    bad_config = transformers.AutoConfig.from_pretrained(path)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '../hf_model_comp/comp_qtip/hf/ql_search/layerdown_val1/meta-llama--Meta-Llama-3-8B/lmbda100'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
