I0410 06:32:02.497566 2016382 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:32:02.497664 2016382 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:32:02.497704 2016382 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:32:02.821629 2016382 config.py:54] PyTorch version 2.6.0 available.
W0410 06:32:03.010542 2016382 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:32:03.572740 2016382 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  7.17it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  7.47it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.72it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.89it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  8.03it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  8.08it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.21it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.98it/s]
I0410 06:32:05.008082 2016382 quantize_finetune_llama.py:163] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:21,  1.45it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:19,  1.52it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:19,  1.50it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:16,  1.68it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:02<00:14,  1.82it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:13,  1.89it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:03<00:13,  1.88it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:13,  1.79it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:05<00:12,  1.79it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:05<00:12,  1.73it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:12,  1.69it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:07<00:13,  1.53it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:11,  1.59it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:08<00:10,  1.66it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:09,  1.74it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:09<00:08,  1.80it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:07,  1.88it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:10<00:07,  1.95it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.95it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:11<00:07,  1.58it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:12<00:06,  1.66it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:12<00:05,  1.72it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:13<00:05,  1.77it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:13<00:04,  1.81it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:14<00:03,  1.84it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:14<00:03,  1.85it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:15<00:02,  1.81it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:16<00:02,  1.80it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:16<00:01,  1.83it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:17<00:01,  1.89it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:17<00:00,  1.87it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:18<00:00,  1.89it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:18<00:00,  1.77it/s]
I0410 06:32:33.289741 2016382 quantize_finetune_llama.py:201] loaded compression model
I0410 06:32:58.030903 2016382 quantize_finetune_llama.py:205] loaded dataset and devset
I0410 06:33:01.086599 2016382 quantize_finetune_llama.py:225] layer 0 gpu 0
I0410 06:33:05.185171 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 0 in 3.872609853744507s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0410 06:33:19.349131 2017695 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:33:19.349247 2017695 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:33:19.349288 2017695 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:33:19.709287 2017695 config.py:54] PyTorch version 2.6.0 available.
W0410 06:33:19.905663 2017695 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:33:20.501339 2017695 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:33:20.505532 2016382 quantize_finetune_llama.py:225] layer 1 gpu 0
I0410 06:33:20.519043 2017695 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.20893007516860962 err 12.721094131469727 tr(WHW.T) 60.88684844970703
bpp_loss 1.6846774220466614
0_q proxy err 0.0004110773734282702 err 118.42919158935547 tr(WHW.T) 288094.65625
bpp_loss 2.4519084692001343
0_k proxy err 0.00036382683902047575 err 36.44844055175781 tr(WHW.T) 100180.734375
bpp_loss 2.9445894956588745
0_o proxy err 0.029903067275881767 err 93.39378356933594 tr(WHW.T) 3123.217529296875
bpp_loss 1.8001657128334045
0_up proxy err 0.060492753982543945 err 539.8646240234375 tr(WHW.T) 8924.451171875
bpp_loss 2.0922208513532365
0_gate proxy err 0.03555373474955559 err 560.990478515625 tr(WHW.T) 15778.666015625
bpp_loss 2.1976406233651296
0_down proxy err 0.04266523942351341 err 461.5613098144531 tr(WHW.T) 10818.205078125
bpp_loss 2.086120912006923
I0410 06:33:58.129104 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 1 in 0.7773334980010986s
I0410 06:34:02.411059 2018531 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:34:02.411186 2018531 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:34:02.411228 2018531 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:34:02.827659 2018531 config.py:54] PyTorch version 2.6.0 available.
W0410 06:34:03.036957 2018531 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:34:03.679376 2018531 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:34:03.683540 2016382 quantize_finetune_llama.py:225] layer 2 gpu 0
I0410 06:34:03.700761 2018531 data_utils.py:336] using 256 training seqs, 128 validation seqs
1_v proxy err 0.14767533540725708 err 16.10708999633789 tr(WHW.T) 109.07096099853516
bpp_loss 1.8151487112045288
1_q proxy err 0.0007187006995081902 err 104.08689880371094 tr(WHW.T) 144826.484375
bpp_loss 2.7218306064605713
1_k proxy err 0.00039947102777659893 err 30.175661087036133 tr(WHW.T) 75539.046875
bpp_loss 3.3235710859298706
1_o proxy err 0.060156140476465225 err 119.33968353271484 tr(WHW.T) 1983.8321533203125
bpp_loss 1.8821290731430054
1_up proxy err 0.06633812934160233 err 546.0172119140625 tr(WHW.T) 8230.8203125
bpp_loss 2.1065331867762973
1_gate proxy err 0.040670640766620636 err 567.45166015625 tr(WHW.T) 13952.365234375
bpp_loss 2.208733218056815
1_down proxy err 0.0020061370451003313 err 28.041845321655273 tr(WHW.T) 13978.03125
bpp_loss 2.10089533669608
I0410 06:34:46.678569 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 2 in 0.9110910892486572s
I0410 06:34:50.820764 2019236 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:34:50.820873 2019236 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:34:50.820914 2019236 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:34:51.234721 2019236 config.py:54] PyTorch version 2.6.0 available.
W0410 06:34:51.447097 2019236 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:34:52.151362 2019236 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:34:52.155487 2016382 quantize_finetune_llama.py:225] layer 3 gpu 0
I0410 06:34:52.171036 2019236 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.14844438433647156 err 23.15131187438965 tr(WHW.T) 155.95950317382812
bpp_loss 1.71983003616333
2_q proxy err 0.003331081010401249 err 138.1571044921875 tr(WHW.T) 41475.15625
bpp_loss 2.679665446281433
2_k proxy err 0.0017732592532411218 err 40.1014289855957 tr(WHW.T) 22614.533203125
bpp_loss 3.4244394302368164
2_o proxy err 0.05404764413833618 err 106.32915496826172 tr(WHW.T) 1967.3226318359375
bpp_loss 1.8369559049606323
2_up proxy err 0.07307139039039612 err 555.3772583007812 tr(WHW.T) 7600.474609375
bpp_loss 2.0987893513270786
2_gate proxy err 0.03851804882287979 err 582.1354370117188 tr(WHW.T) 15113.31640625
bpp_loss 2.2398565156119212
2_down proxy err 0.06431978195905685 err 496.9812927246094 tr(WHW.T) 7726.72509765625
bpp_loss 2.1033995832715715
I0410 06:35:34.893100 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 3 in 1.2195384502410889s
I0410 06:35:39.235839 2019950 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:35:39.235996 2019950 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:35:39.236038 2019950 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:35:39.677099 2019950 config.py:54] PyTorch version 2.6.0 available.
W0410 06:35:39.914747 2019950 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:35:40.648940 2019950 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:35:40.653160 2016382 quantize_finetune_llama.py:225] layer 4 gpu 0
I0410 06:35:40.667992 2019950 data_utils.py:336] using 256 training seqs, 128 validation seqs
3_v proxy err 0.10121957212686539 err 29.286178588867188 tr(WHW.T) 289.3331604003906
bpp_loss 1.8263331055641174
3_q proxy err 0.0033984885085374117 err 161.6896514892578 tr(WHW.T) 47576.9296875
bpp_loss 2.720979690551758
3_k proxy err 0.0017719612224027514 err 46.380226135253906 tr(WHW.T) 26174.515625
bpp_loss 3.497908353805542
3_o proxy err 0.07010843604803085 err 130.20242309570312 tr(WHW.T) 1857.15771484375
bpp_loss 1.94123375415802
3_up proxy err 0.07272423803806305 err 548.0836791992188 tr(WHW.T) 7536.46484375
bpp_loss 2.0815252576555525
3_gate proxy err 0.028355702757835388 err 592.1903686523438 tr(WHW.T) 20884.34765625
bpp_loss 2.309978485107422
3_down proxy err 0.0737491324543953 err 516.1414184570312 tr(WHW.T) 6998.6103515625
bpp_loss 2.081653050013951
I0410 06:36:25.476621 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 4 in 1.1444323062896729s
I0410 06:36:29.704581 2020627 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:36:29.704701 2020627 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:36:29.704743 2020627 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:36:30.117210 2020627 config.py:54] PyTorch version 2.6.0 available.
W0410 06:36:30.330942 2020627 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:36:30.989270 2020627 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:36:30.993402 2016382 quantize_finetune_llama.py:225] layer 5 gpu 0
I0410 06:36:31.007366 2020627 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.09478600323200226 err 27.043123245239258 tr(WHW.T) 285.30712890625
bpp_loss 1.8702280521392822
4_q proxy err 0.0028963619843125343 err 145.15077209472656 tr(WHW.T) 50114.859375
bpp_loss 2.6876137256622314
4_k proxy err 0.0014453609474003315 err 42.3519287109375 tr(WHW.T) 29301.974609375
bpp_loss 3.4828044176101685
4_o proxy err 0.09127691388130188 err 118.4088134765625 tr(WHW.T) 1297.2481689453125
bpp_loss 1.9493895173072815
4_up proxy err 0.07220988720655441 err 533.1608276367188 tr(WHW.T) 7383.48779296875
bpp_loss 2.054471901484898
4_gate proxy err 0.02028506062924862 err 590.923583984375 tr(WHW.T) 29130.974609375
bpp_loss 2.3770216533115933
4_down proxy err 0.0827142596244812 err 529.0174560546875 tr(WHW.T) 6395.72265625
bpp_loss 2.0577762808118547
I0410 06:37:14.636114 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 5 in 1.180058479309082s
I0410 06:37:18.883910 2021428 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 06:37:18.884026 2021428 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 06:37:18.884066 2021428 utils.py:162] NumExpr defaulting to 16 threads.
I0410 06:37:19.329668 2021428 config.py:54] PyTorch version 2.6.0 available.
W0410 06:37:19.559839 2021428 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 06:37:20.298937 2021428 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 06:37:20.303241 2016382 quantize_finetune_llama.py:225] layer 6 gpu 0
I0410 06:37:20.322946 2021428 data_utils.py:336] using 256 training seqs, 128 validation seqs
5_v proxy err 0.011569229885935783 err 2.4158852100372314 tr(WHW.T) 208.81988525390625
bpp_loss 4.1424643993377686
5_q proxy err 0.0003150749544147402 err 11.340059280395508 tr(WHW.T) 35991.625
bpp_loss 7.472173452377319
5_k proxy err 0.0001580159441800788 err 3.634011745452881 tr(WHW.T) 22997.75390625
bpp_loss 9.6822190284729
5_o proxy err 0.009244853630661964 err 9.758743286132812 tr(WHW.T) 1055.5865478515625
bpp_loss 4.7618749141693115
5_up proxy err 0.004408819135278463 err 33.755828857421875 tr(WHW.T) 7656.43310546875
bpp_loss 5.573656627110073
5_gate proxy err 0.0011672003893181682 err 35.467655181884766 tr(WHW.T) 30386.947265625
bpp_loss 6.704706736973354
5_down proxy err 0.00525139132514596 err 33.66735076904297 tr(WHW.T) 6411.12939453125
bpp_loss 5.555137634277344
I0410 06:38:03.142083 2016382 quantize_finetune_llama.py:256] computed original embedding for layer 6 in 1.2554454803466797s
