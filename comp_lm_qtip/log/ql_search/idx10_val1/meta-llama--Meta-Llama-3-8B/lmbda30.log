I0410 04:15:07.581507 1917765 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:15:07.581695 1917765 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:15:07.581779 1917765 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:15:07.965054 1917765 config.py:54] PyTorch version 2.6.0 available.
W0410 04:15:08.195610 1917765 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:15:08.828714 1917765 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:00,  6.08it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:00<00:00,  6.76it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:00<00:00,  7.38it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:00<00:00,  7.73it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:00<00:00,  7.90it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:00<00:00,  7.93it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.69it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.55it/s]
I0410 04:15:10.791741 1917765 quantize_finetune_llama.py:163] loaded model
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:23,  1.31it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:22,  1.33it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:21,  1.38it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:18,  1.53it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:16,  1.66it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:03<00:14,  1.73it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:14,  1.78it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:04<00:13,  1.83it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:05<00:12,  1.84it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:05<00:11,  1.86it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:11,  1.89it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:06<00:10,  1.89it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:10,  1.89it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:07<00:09,  1.91it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:08,  1.92it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:09<00:08,  1.91it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:07,  1.94it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:10<00:07,  1.93it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.92it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:11<00:06,  1.93it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:05,  1.91it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:12<00:05,  1.90it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:04,  1.94it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:13<00:04,  1.95it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:14<00:04,  1.62it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:14<00:03,  1.67it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:15<00:02,  1.69it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:15<00:02,  1.82it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:16<00:01,  1.89it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:16<00:01,  1.94it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:17<00:00,  1.99it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:17<00:00,  2.02it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:17<00:00,  1.83it/s]
I0410 04:15:41.586275 1917765 quantize_finetune_llama.py:201] loaded compression model
I0410 04:16:03.481177 1917765 quantize_finetune_llama.py:205] loaded dataset and devset
I0410 04:16:05.773723 1917765 quantize_finetune_llama.py:225] layer 0 gpu 0
I0410 04:16:08.228926 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 0 in 2.226285219192505s
tensor(-4.7143e-06) tensor(0.0125)
tensor(0.0125) tensor(-4.7143e-06)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
I0410 04:16:19.657457 1919039 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:16:19.657570 1919039 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:16:19.657613 1919039 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:16:20.103193 1919039 config.py:54] PyTorch version 2.6.0 available.
W0410 04:16:20.341688 1919039 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:16:21.578152 1919039 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:16:21.582406 1917765 quantize_finetune_llama.py:225] layer 1 gpu 0
I0410 04:16:21.640432 1919039 data_utils.py:336] using 256 training seqs, 128 validation seqs
0_v proxy err 0.20893007516860962 err 12.721094131469727 tr(WHW.T) 60.88684844970703
bpp_loss 1.6846774220466614
0_q proxy err 0.0004110773734282702 err 118.42919158935547 tr(WHW.T) 288094.65625
bpp_loss 2.4519084692001343
0_k proxy err 0.00036382683902047575 err 36.44844055175781 tr(WHW.T) 100180.734375
bpp_loss 2.9445894956588745
0_o proxy err 0.029903067275881767 err 93.39378356933594 tr(WHW.T) 3123.217529296875
bpp_loss 1.8001657128334045
0_up proxy err 0.060492753982543945 err 539.8646240234375 tr(WHW.T) 8924.451171875
bpp_loss 2.0922208513532365
0_gate proxy err 0.03555373474955559 err 560.990478515625 tr(WHW.T) 15778.666015625
bpp_loss 2.1976406233651296
0_down proxy err 0.04266523942351341 err 461.5613098144531 tr(WHW.T) 10818.205078125
bpp_loss 2.086120912006923
I0410 04:16:59.947683 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 1 in 0.8379364013671875s
I0410 04:17:04.128014 1919712 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:17:04.128138 1919712 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:17:04.128183 1919712 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:17:04.546406 1919712 config.py:54] PyTorch version 2.6.0 available.
W0410 04:17:04.779397 1919712 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:17:05.455396 1919712 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:17:05.459952 1917765 quantize_finetune_llama.py:225] layer 2 gpu 0
I0410 04:17:05.480551 1919712 data_utils.py:336] using 256 training seqs, 128 validation seqs
1_v proxy err 0.14767533540725708 err 16.10708999633789 tr(WHW.T) 109.07096099853516
bpp_loss 1.8151487112045288
1_q proxy err 0.0007187006995081902 err 104.08689880371094 tr(WHW.T) 144826.484375
bpp_loss 2.7218306064605713
1_k proxy err 0.00039947102777659893 err 30.175661087036133 tr(WHW.T) 75539.046875
bpp_loss 3.3235710859298706
1_o proxy err 0.060156140476465225 err 119.33968353271484 tr(WHW.T) 1983.8321533203125
bpp_loss 1.8821290731430054
1_up proxy err 0.06633812934160233 err 546.0172119140625 tr(WHW.T) 8230.8203125
bpp_loss 2.1065331867762973
1_gate proxy err 0.040670640766620636 err 567.45166015625 tr(WHW.T) 13952.365234375
bpp_loss 2.208733218056815
1_down proxy err 0.0020061370451003313 err 28.041845321655273 tr(WHW.T) 13978.03125
bpp_loss 2.10089533669608
I0410 04:17:43.024851 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 2 in 1.0129780769348145s
I0410 04:17:47.266480 1920369 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:17:47.266599 1920369 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:17:47.266640 1920369 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:17:47.676733 1920369 config.py:54] PyTorch version 2.6.0 available.
W0410 04:17:47.904100 1920369 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:17:48.586701 1920369 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:17:48.591377 1917765 quantize_finetune_llama.py:225] layer 3 gpu 0
I0410 04:17:48.620502 1920369 data_utils.py:336] using 256 training seqs, 128 validation seqs
2_v proxy err 0.14844438433647156 err 23.15131187438965 tr(WHW.T) 155.95950317382812
bpp_loss 1.71983003616333
2_q proxy err 0.003331081010401249 err 138.1571044921875 tr(WHW.T) 41475.15625
bpp_loss 2.679665446281433
2_k proxy err 0.0017732592532411218 err 40.1014289855957 tr(WHW.T) 22614.533203125
bpp_loss 3.4244394302368164
2_o proxy err 0.05404764413833618 err 106.32915496826172 tr(WHW.T) 1967.3226318359375
bpp_loss 1.8369559049606323
2_up proxy err 0.07307139039039612 err 555.3772583007812 tr(WHW.T) 7600.474609375
bpp_loss 2.0987893513270786
2_gate proxy err 0.03851804882287979 err 582.1354370117188 tr(WHW.T) 15113.31640625
bpp_loss 2.2398565156119212
2_down proxy err 0.06431978195905685 err 496.9812927246094 tr(WHW.T) 7726.72509765625
bpp_loss 2.1033995832715715
I0410 04:18:25.715733 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 3 in 0.8722167015075684s
I0410 04:18:29.966800 1921056 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:18:29.966931 1921056 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:18:29.966981 1921056 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:18:30.380654 1921056 config.py:54] PyTorch version 2.6.0 available.
W0410 04:18:30.605407 1921056 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:18:31.274814 1921056 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:18:31.279444 1917765 quantize_finetune_llama.py:225] layer 4 gpu 0
I0410 04:18:31.312704 1921056 data_utils.py:336] using 256 training seqs, 128 validation seqs
3_v proxy err 0.10121957212686539 err 29.286178588867188 tr(WHW.T) 289.3331604003906
bpp_loss 1.8263331055641174
3_q proxy err 0.0033984885085374117 err 161.6896514892578 tr(WHW.T) 47576.9296875
bpp_loss 2.720979690551758
3_k proxy err 0.0017719612224027514 err 46.380226135253906 tr(WHW.T) 26174.515625
bpp_loss 3.497908353805542
3_o proxy err 0.07010843604803085 err 130.20242309570312 tr(WHW.T) 1857.15771484375
bpp_loss 1.94123375415802
3_up proxy err 0.07272423803806305 err 548.0836791992188 tr(WHW.T) 7536.46484375
bpp_loss 2.0815252576555525
3_gate proxy err 0.028355702757835388 err 592.1903686523438 tr(WHW.T) 20884.34765625
bpp_loss 2.309978485107422
3_down proxy err 0.0737491324543953 err 516.1414184570312 tr(WHW.T) 6998.6103515625
bpp_loss 2.081653050013951
I0410 04:19:08.574369 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 4 in 0.9098453521728516s
I0410 04:19:12.793498 1921716 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:19:12.793618 1921716 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:19:12.793659 1921716 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:19:13.205230 1921716 config.py:54] PyTorch version 2.6.0 available.
W0410 04:19:13.436796 1921716 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:19:14.101894 1921716 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:19:14.106453 1917765 quantize_finetune_llama.py:225] layer 5 gpu 0
I0410 04:19:14.136692 1921716 data_utils.py:336] using 256 training seqs, 128 validation seqs
4_v proxy err 0.09478600323200226 err 27.043123245239258 tr(WHW.T) 285.30712890625
bpp_loss 1.8702280521392822
4_q proxy err 0.0028963619843125343 err 145.15077209472656 tr(WHW.T) 50114.859375
bpp_loss 2.6876137256622314
4_k proxy err 0.0014453609474003315 err 42.3519287109375 tr(WHW.T) 29301.974609375
bpp_loss 3.4828044176101685
4_o proxy err 0.09127691388130188 err 118.4088134765625 tr(WHW.T) 1297.2481689453125
bpp_loss 1.9493895173072815
4_up proxy err 0.07220988720655441 err 533.1608276367188 tr(WHW.T) 7383.48779296875
bpp_loss 2.054471901484898
4_gate proxy err 0.02028506062924862 err 590.923583984375 tr(WHW.T) 29130.974609375
bpp_loss 2.3770216533115933
4_down proxy err 0.0827142596244812 err 529.0174560546875 tr(WHW.T) 6395.72265625
bpp_loss 2.0577762808118547
I0410 04:19:51.631906 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 5 in 0.9196138381958008s
I0410 04:19:55.785612 1922390 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:19:55.785728 1922390 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:19:55.785773 1922390 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:19:56.185676 1922390 config.py:54] PyTorch version 2.6.0 available.
W0410 04:19:56.405818 1922390 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:19:57.058778 1922390 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:19:57.062893 1917765 quantize_finetune_llama.py:225] layer 6 gpu 0
I0410 04:19:57.077602 1922390 data_utils.py:336] using 256 training seqs, 128 validation seqs
5_v proxy err 0.12709644436836243 err 26.540266036987305 tr(WHW.T) 208.81988525390625
bpp_loss 1.7567432522773743
5_q proxy err 0.004023056477308273 err 144.7963409423828 tr(WHW.T) 35991.625
bpp_loss 2.6631250381469727
5_k proxy err 0.001828203909099102 err 42.04458236694336 tr(WHW.T) 22997.75390625
bpp_loss 3.4552531242370605
5_o proxy err 0.10626985132694244 err 112.1770248413086 tr(WHW.T) 1055.5865478515625
bpp_loss 1.896180808544159
5_up proxy err 0.0692036971449852 err 529.8534545898438 tr(WHW.T) 7656.43310546875
bpp_loss 2.0598603657313754
5_gate proxy err 0.019317856058478355 err 587.0106811523438 tr(WHW.T) 30386.947265625
bpp_loss 2.3799495697021484
5_down proxy err 0.0811571255326271 err 520.308837890625 tr(WHW.T) 6411.12939453125
bpp_loss 2.0622627053942
I0410 04:20:34.968245 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 6 in 0.7928087711334229s
I0410 04:20:39.124805 1923113 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:20:39.124921 1923113 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:20:39.124962 1923113 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:20:39.531188 1923113 config.py:54] PyTorch version 2.6.0 available.
W0410 04:20:39.748885 1923113 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:20:40.431638 1923113 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:20:40.436000 1917765 quantize_finetune_llama.py:225] layer 7 gpu 0
I0410 04:20:40.454470 1923113 data_utils.py:336] using 256 training seqs, 128 validation seqs
6_v proxy err 0.10847195237874985 err 27.512149810791016 tr(WHW.T) 253.63377380371094
bpp_loss 1.8044180870056152
6_q proxy err 0.004205327946692705 err 149.8761444091797 tr(WHW.T) 35639.5859375
bpp_loss 2.707595109939575
6_k proxy err 0.0016935544554144144 err 44.309574127197266 tr(WHW.T) 26163.654296875
bpp_loss 3.5229077339172363
6_o proxy err 0.12149108201265335 err 122.60253143310547 tr(WHW.T) 1009.1483764648438
bpp_loss 1.9305211901664734
6_up proxy err 0.06576671451330185 err 521.1049194335938 tr(WHW.T) 7923.53564453125
bpp_loss 2.0591941561017717
6_gate proxy err 0.016202248632907867 err 579.204345703125 tr(WHW.T) 35748.39453125
bpp_loss 2.3841202599661693
6_down proxy err 0.08064228296279907 err 522.8490600585938 tr(WHW.T) 6483.5595703125
bpp_loss 2.063042095729283
I0410 04:21:21.782805 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 7 in 0.902562141418457s
I0410 04:21:25.962015 1923799 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:21:25.962130 1923799 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:21:25.962170 1923799 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:21:26.373568 1923799 config.py:54] PyTorch version 2.6.0 available.
W0410 04:21:26.594386 1923799 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:21:27.253793 1923799 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:21:27.258137 1917765 quantize_finetune_llama.py:225] layer 8 gpu 0
I0410 04:21:27.273702 1923799 data_utils.py:336] using 256 training seqs, 128 validation seqs
7_v proxy err 0.09107766300439835 err 28.181896209716797 tr(WHW.T) 309.4270935058594
bpp_loss 1.8025281429290771
7_q proxy err 0.0044327848590910435 err 155.79000854492188 tr(WHW.T) 35144.953125
bpp_loss 2.637367844581604
7_k proxy err 0.0017545598093420267 err 47.11079406738281 tr(WHW.T) 26850.4921875
bpp_loss 3.5417085886001587
7_o proxy err 0.1235940232872963 err 118.55330657958984 tr(WHW.T) 959.2155151367188
bpp_loss 1.9409180879592896
7_up proxy err 0.05993662029504776 err 517.1002197265625 tr(WHW.T) 8627.4501953125
bpp_loss 2.0713579995291576
7_gate proxy err 0.01628594659268856 err 568.4371337890625 tr(WHW.T) 34903.53515625
bpp_loss 2.356522423880441
7_down proxy err 0.08096864819526672 err 529.0999755859375 tr(WHW.T) 6534.6279296875
bpp_loss 2.0766972473689487
I0410 04:22:08.680521 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 8 in 1.1524877548217773s
I0410 04:22:12.965802 1924519 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:22:12.965917 1924519 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:22:12.965958 1924519 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:22:13.379295 1924519 config.py:54] PyTorch version 2.6.0 available.
W0410 04:22:13.603589 1924519 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:22:14.271218 1924519 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:22:14.275457 1917765 quantize_finetune_llama.py:225] layer 9 gpu 0
I0410 04:22:14.291061 1924519 data_utils.py:336] using 256 training seqs, 128 validation seqs
8_v proxy err 0.10259221494197845 err 26.43855094909668 tr(WHW.T) 257.7052307128906
bpp_loss 1.821737289428711
8_q proxy err 0.005092139821499586 err 135.4558868408203 tr(WHW.T) 26600.9765625
bpp_loss 2.6248672008514404
8_k proxy err 0.0017942605772987008 err 40.42244338989258 tr(WHW.T) 22528.748046875
bpp_loss 3.461038112640381
8_o proxy err 0.16101223230361938 err 120.05170440673828 tr(WHW.T) 745.6061401367188
bpp_loss 1.9507015347480774
8_up proxy err 0.06059904769062996 err 514.792236328125 tr(WHW.T) 8495.0546875
bpp_loss 2.06728458404541
8_gate proxy err 0.015206586569547653 err 566.26513671875 tr(WHW.T) 37238.1484375
bpp_loss 2.360641751970564
8_down proxy err 0.0825096145272255 err 535.3898315429688 tr(WHW.T) 6488.8173828125
bpp_loss 2.074810368674142
I0410 04:22:55.498695 1917765 quantize_finetune_llama.py:256] computed original embedding for layer 9 in 0.7936389446258545s
I0410 04:22:59.363052 1925232 utils.py:146] Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
I0410 04:22:59.363173 1925232 utils.py:149] Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
I0410 04:22:59.363216 1925232 utils.py:162] NumExpr defaulting to 16 threads.
I0410 04:22:59.730731 1925232 config.py:54] PyTorch version 2.6.0 available.
W0410 04:22:59.949736 1925232 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

W0410 04:23:00.561335 1925232 warnings.py:109] /opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)

I0410 04:23:00.565376 1917765 quantize_finetune_llama.py:225] layer 10 gpu 0
I0410 04:23:00.579428 1925232 data_utils.py:336] using 256 training seqs, 128 validation seqs
9_v proxy err 0.07706370204687119 err 27.08240509033203 tr(WHW.T) 351.4288024902344
bpp_loss 1.9205366373062134
9_q proxy err 0.005267934408038855 err 135.13954162597656 tr(WHW.T) 25653.232421875
bpp_loss 2.6363896131515503
9_k proxy err 0.0019091354915872216 err 39.98233413696289 tr(WHW.T) 20942.638671875
bpp_loss 3.4791146516799927
9_o proxy err 0.15230780839920044 err 118.28250885009766 tr(WHW.T) 776.6017456054688
bpp_loss 2.0042662024497986
9_up proxy err 0.05780329927802086 err 518.5328979492188 tr(WHW.T) 8970.6455078125
bpp_loss 2.0763224193028043
9_gate proxy err 0.014508519321680069 err 571.8637084960938 tr(WHW.T) 39415.71875
bpp_loss 2.373028482709612
9_down proxy err 0.08360347896814346 err 524.4365844726562 tr(WHW.T) 6272.90380859375
bpp_loss 2.075998749051775
