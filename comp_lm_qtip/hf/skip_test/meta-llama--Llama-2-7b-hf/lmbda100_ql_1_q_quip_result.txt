W0318 12:40:23.600162 628031 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 12:40:24.127986 628031 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  6.46it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  9.71it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00, 10.81it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.54it/s]
W0318 12:40:24.935446 628031 big_modeling.py:439] Some parameters are on the meta device because they were offloaded to the cpu.
I0318 12:40:25.331400 628031 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.446164608001709:   0%|          | 0/166 [00:10<?, ?it/s]avg_loss = 1.446164608001709:   1%|          | 1/166 [00:10<28:38, 10.42s/it]avg_loss = 1.446164608001709:   1%|          | 1/166 [00:25<1:09:53, 25.42s/it]
Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 93, in main
    output = model(input,
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1163, in forward
    outputs = self.model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 913, in forward
    layer_outputs = decoder_layer(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 656, in forward
    hidden_states = self.mlp(hidden_states)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 242, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 171, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 361, in pre_forward
    set_module_tensor_to_device(
  File "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 339, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 139.25 MiB is free. Process 3347854 has 26.65 GiB memory in use. Process 3350306 has 18.73 GiB memory in use. Process 3352425 has 1.54 GiB memory in use. Process 3352427 has 424.00 MiB memory in use. Of the allocated memory 974.19 MiB is allocated by PyTorch, and 101.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0318 15:25:35.892333 722495 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 15:25:36.964991 722495 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.04s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.28s/it]
Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 49, in model_from_hf_path
    model = maybe_wrap(use_cuda_graph)(model_cls).from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 942, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 339, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 18.00 MiB is free. Process 3515056 has 9.62 GiB memory in use. Process 3515035 has 5.74 GiB memory in use. Process 3515025 has 8.86 GiB memory in use. Process 3515018 has 5.55 GiB memory in use. Process 3515042 has 6.26 GiB memory in use. Process 3515049 has 5.87 GiB memory in use. Process 3515063 has 5.55 GiB memory in use. Of the allocated memory 5.32 GiB is allocated by PyTorch, and 1.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0318 15:34:46.134602 730148 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 15:34:46.602915 730148 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.45it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:04,  1.01s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.07it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.10it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]
I0318 15:34:52.465378 730148 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.446164608001709:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.446164608001709:   1%|          | 1/166 [00:01<04:23,  1.60s/it]avg_loss = 1.7003368735313416:   1%|          | 1/166 [00:02<04:23,  1.60s/it]avg_loss = 1.7003368735313416:   1%|          | 2/166 [00:02<03:46,  1.38s/it]avg_loss = 1.8632477521896362:   1%|          | 2/166 [00:04<03:46,  1.38s/it]avg_loss = 1.8632477521896362:   2%|▏         | 3/166 [00:04<03:34,  1.32s/it]avg_loss = 1.8955800533294678:   2%|▏         | 3/166 [00:05<03:34,  1.32s/it]avg_loss = 1.8955800533294678:   2%|▏         | 4/166 [00:05<03:28,  1.29s/it]avg_loss = 1.8228048086166382:   2%|▏         | 4/166 [00:06<03:28,  1.29s/it]avg_loss = 1.8228048086166382:   3%|▎         | 5/166 [00:06<03:24,  1.27s/it]avg_loss = 1.7995076775550842:   3%|▎         | 5/166 [00:07<03:24,  1.27s/it]avg_loss = 1.7995076775550842:   4%|▎         | 6/166 [00:07<03:21,  1.26s/it]avg_loss = 1.7386879920959473:   4%|▎         | 6/166 [00:09<03:21,  1.26s/it]avg_loss = 1.7386879920959473:   4%|▍         | 7/166 [00:09<03:19,  1.26s/it]avg_loss = 1.681942656636238:   4%|▍         | 7/166 [00:10<03:19,  1.26s/it] avg_loss = 1.681942656636238:   5%|▍         | 8/166 [00:10<03:18,  1.26s/it]avg_loss = 1.6781019237306383:   5%|▍         | 8/166 [00:11<03:18,  1.26s/it]avg_loss = 1.6781019237306383:   5%|▌         | 9/166 [00:11<03:16,  1.25s/it]avg_loss = 1.684411108493805:   5%|▌         | 9/166 [00:12<03:16,  1.25s/it] avg_loss = 1.684411108493805:   6%|▌         | 10/166 [00:12<03:15,  1.25s/it]avg_loss = 1.7000882842323997:   6%|▌         | 10/166 [00:14<03:15,  1.25s/it]avg_loss = 1.7000882842323997:   7%|▋         | 11/166 [00:14<03:14,  1.26s/it]avg_loss = 1.7083848118782043:   7%|▋         | 11/166 [00:15<03:14,  1.26s/it]avg_loss = 1.7083848118782043:   7%|▋         | 12/166 [00:15<03:13,  1.26s/it]avg_loss = 1.702635379937979:   7%|▋         | 12/166 [00:16<03:13,  1.26s/it] avg_loss = 1.702635379937979:   8%|▊         | 13/166 [00:16<03:12,  1.26s/it]avg_loss = 1.712289307798658:   8%|▊         | 13/166 [00:17<03:12,  1.26s/it]avg_loss = 1.712289307798658:   8%|▊         | 14/166 [00:17<03:11,  1.26s/it]avg_loss = 1.7290208339691162:   8%|▊         | 14/166 [00:19<03:11,  1.26s/it]avg_loss = 1.7290208339691162:   9%|▉         | 15/166 [00:19<03:10,  1.26s/it]avg_loss = 1.748288944363594:   9%|▉         | 15/166 [00:20<03:10,  1.26s/it] avg_loss = 1.748288944363594:  10%|▉         | 16/166 [00:20<03:08,  1.26s/it]avg_loss = 1.7606718119452982:  10%|▉         | 16/166 [00:21<03:08,  1.26s/it]avg_loss = 1.7606718119452982:  10%|█         | 17/166 [00:21<03:07,  1.26s/it]avg_loss = 1.774732814894782:  10%|█         | 17/166 [00:22<03:07,  1.26s/it] avg_loss = 1.774732814894782:  11%|█         | 18/166 [00:22<03:06,  1.26s/it]avg_loss = 1.7946943860304982:  11%|█         | 18/166 [00:24<03:06,  1.26s/it]avg_loss = 1.7946943860304982:  11%|█▏        | 19/166 [00:24<03:05,  1.26s/it]avg_loss = 1.8009474515914916:  11%|█▏        | 19/166 [00:25<03:05,  1.26s/it]avg_loss = 1.8009474515914916:  12%|█▏        | 20/166 [00:25<03:04,  1.26s/it]avg_loss = 1.801649536405291:  12%|█▏        | 20/166 [00:26<03:04,  1.26s/it] avg_loss = 1.801649536405291:  13%|█▎        | 21/166 [00:26<03:03,  1.26s/it]avg_loss = 1.791344165802002:  13%|█▎        | 21/166 [00:27<03:03,  1.26s/it]avg_loss = 1.791344165802002:  13%|█▎        | 22/166 [00:27<03:02,  1.26s/it]avg_loss = 1.7809098337007605:  13%|█▎        | 22/166 [00:29<03:02,  1.26s/it]avg_loss = 1.7809098337007605:  14%|█▍        | 23/166 [00:29<03:01,  1.27s/it]avg_loss = 1.7883313844601314:  14%|█▍        | 23/166 [00:30<03:01,  1.27s/it]avg_loss = 1.7883313844601314:  14%|█▍        | 24/166 [00:30<02:59,  1.27s/it]avg_loss = 1.7960556650161743:  14%|█▍        | 24/166 [00:31<02:59,  1.27s/it]avg_loss = 1.7960556650161743:  15%|█▌        | 25/166 [00:31<02:58,  1.27s/it]avg_loss = 1.8009377717971802:  15%|█▌        | 25/166 [00:33<02:58,  1.27s/it]avg_loss = 1.8009377717971802:  16%|█▌        | 26/166 [00:33<02:57,  1.27s/it]avg_loss = 1.8078018956714206:  16%|█▌        | 26/166 [00:34<02:57,  1.27s/it]avg_loss = 1.8078018956714206:  16%|█▋        | 27/166 [00:34<02:56,  1.27s/it]avg_loss = 1.8102057533604758:  16%|█▋        | 27/166 [00:35<02:56,  1.27s/it]avg_loss = 1.8102057533604758:  17%|█▋        | 28/166 [00:35<02:55,  1.27s/it]avg_loss = 1.819174885749817:  17%|█▋        | 28/166 [00:36<02:55,  1.27s/it] avg_loss = 1.819174885749817:  17%|█▋        | 29/166 [00:36<02:54,  1.27s/it]avg_loss = 1.819782284895579:  17%|█▋        | 29/166 [00:38<02:54,  1.27s/it]avg_loss = 1.819782284895579:  18%|█▊        | 30/166 [00:38<02:53,  1.27s/it]avg_loss = 1.8338051265285862:  18%|█▊        | 30/166 [00:39<02:53,  1.27s/it]avg_loss = 1.8338051265285862:  19%|█▊        | 31/166 [00:39<02:52,  1.27s/it]avg_loss = 1.8398599065840244:  19%|█▊        | 31/166 [00:40<02:52,  1.27s/it]avg_loss = 1.8398599065840244:  19%|█▉        | 32/166 [00:40<02:50,  1.28s/it]avg_loss = 1.844756866946365:  19%|█▉        | 32/166 [00:41<02:50,  1.28s/it] avg_loss = 1.844756866946365:  20%|█▉        | 33/166 [00:41<02:49,  1.28s/it]avg_loss = 1.843886747079737:  20%|█▉        | 33/166 [00:43<02:49,  1.28s/it]avg_loss = 1.843886747079737:  20%|██        | 34/166 [00:43<02:48,  1.28s/it]avg_loss = 1.8374018839427404:  20%|██        | 34/166 [00:44<02:48,  1.28s/it]avg_loss = 1.8374018839427404:  21%|██        | 35/166 [00:44<02:47,  1.28s/it]avg_loss = 1.8293924960825179:  21%|██        | 35/166 [00:45<02:47,  1.28s/it]avg_loss = 1.8293924960825179:  22%|██▏       | 36/166 [00:45<02:46,  1.28s/it]avg_loss = 1.820033759684176:  22%|██▏       | 36/166 [00:47<02:46,  1.28s/it] avg_loss = 1.820033759684176:  22%|██▏       | 37/166 [00:47<02:45,  1.28s/it]avg_loss = 1.8172250609648855:  22%|██▏       | 37/166 [00:48<02:45,  1.28s/it]avg_loss = 1.8172250609648855:  23%|██▎       | 38/166 [00:48<02:43,  1.28s/it]avg_loss = 1.8148105113934248:  23%|██▎       | 38/166 [00:49<02:43,  1.28s/it]avg_loss = 1.8148105113934248:  23%|██▎       | 39/166 [00:49<02:42,  1.28s/it]avg_loss = 1.8181140393018722:  23%|██▎       | 39/166 [00:50<02:42,  1.28s/it]avg_loss = 1.8181140393018722:  24%|██▍       | 40/166 [00:50<02:41,  1.28s/it]avg_loss = 1.8178946768365256:  24%|██▍       | 40/166 [00:52<02:41,  1.28s/it]avg_loss = 1.8178946768365256:  25%|██▍       | 41/166 [00:52<02:40,  1.28s/it]avg_loss = 1.8053509451094127:  25%|██▍       | 41/166 [00:53<02:40,  1.28s/it]avg_loss = 1.8053509451094127:  25%|██▌       | 42/166 [00:53<02:38,  1.28s/it]avg_loss = 1.7898432293603586:  25%|██▌       | 42/166 [00:54<02:38,  1.28s/it]avg_loss = 1.7898432293603586:  26%|██▌       | 43/166 [00:54<02:37,  1.28s/it]avg_loss = 1.7793669185855172:  26%|██▌       | 43/166 [00:56<02:37,  1.28s/it]avg_loss = 1.7793669185855172:  27%|██▋       | 44/166 [00:56<02:36,  1.28s/it]avg_loss = 1.7655139949586656:  27%|██▋       | 44/166 [00:57<02:36,  1.28s/it]avg_loss = 1.7655139949586656:  27%|██▋       | 45/166 [00:57<02:34,  1.28s/it]avg_loss = 1.755046266576518:  27%|██▋       | 45/166 [00:58<02:34,  1.28s/it] avg_loss = 1.755046266576518:  28%|██▊       | 46/166 [00:58<02:33,  1.28s/it]avg_loss = 1.747673511505127:  28%|██▊       | 46/166 [00:59<02:33,  1.28s/it]avg_loss = 1.747673511505127:  28%|██▊       | 47/166 [00:59<02:32,  1.28s/it]avg_loss = 1.7491110215584438:  28%|██▊       | 47/166 [01:01<02:32,  1.28s/it]avg_loss = 1.7491110215584438:  29%|██▉       | 48/166 [01:01<02:31,  1.28s/it]avg_loss = 1.759747130530221:  29%|██▉       | 48/166 [01:02<02:31,  1.28s/it] avg_loss = 1.759747130530221:  30%|██▉       | 49/166 [01:02<02:30,  1.28s/it]avg_loss = 1.7703398180007934:  30%|██▉       | 49/166 [01:03<02:30,  1.28s/it]avg_loss = 1.7703398180007934:  30%|███       | 50/166 [01:03<02:29,  1.28s/it]avg_loss = 1.777269671945011:  30%|███       | 50/166 [01:05<02:29,  1.28s/it] avg_loss = 1.777269671945011:  31%|███       | 51/166 [01:05<02:27,  1.28s/it]avg_loss = 1.782632080408243:  31%|███       | 51/166 [01:06<02:27,  1.28s/it]avg_loss = 1.782632080408243:  31%|███▏      | 52/166 [01:06<02:26,  1.28s/it]avg_loss = 1.786173696787852:  31%|███▏      | 52/166 [01:07<02:26,  1.28s/it]avg_loss = 1.786173696787852:  32%|███▏      | 53/166 [01:07<02:25,  1.28s/it]avg_loss = 1.7865393514986392:  32%|███▏      | 53/166 [01:08<02:25,  1.28s/it]avg_loss = 1.7865393514986392:  33%|███▎      | 54/166 [01:08<02:23,  1.29s/it]avg_loss = 1.7889662222428755:  33%|███▎      | 54/166 [01:10<02:23,  1.29s/it]avg_loss = 1.7889662222428755:  33%|███▎      | 55/166 [01:10<02:22,  1.29s/it]avg_loss = 1.7921774004186903:  33%|███▎      | 55/166 [01:11<02:22,  1.29s/it]avg_loss = 1.7921774004186903:  34%|███▎      | 56/166 [01:11<02:21,  1.29s/it]avg_loss = 1.7872287076816225:  34%|███▎      | 56/166 [01:12<02:21,  1.29s/it]avg_loss = 1.7872287076816225:  34%|███▍      | 57/166 [01:12<02:20,  1.29s/it]avg_loss = 1.7909456799770225:  34%|███▍      | 57/166 [01:14<02:20,  1.29s/it]avg_loss = 1.7909456799770225:  35%|███▍      | 58/166 [01:14<02:18,  1.29s/it]avg_loss = 1.7892751915980194:  35%|███▍      | 58/166 [01:15<02:18,  1.29s/it]avg_loss = 1.7892751915980194:  36%|███▌      | 59/166 [01:15<02:17,  1.29s/it]avg_loss = 1.7847963174184163:  36%|███▌      | 59/166 [01:16<02:17,  1.29s/it]avg_loss = 1.7847963174184163:  36%|███▌      | 60/166 [01:16<02:16,  1.29s/it]avg_loss = 1.7804475436445142:  36%|███▌      | 60/166 [01:17<02:16,  1.29s/it]avg_loss = 1.7804475436445142:  37%|███▋      | 61/166 [01:17<02:14,  1.29s/it]avg_loss = 1.7764218545729114:  37%|███▋      | 61/166 [01:19<02:14,  1.29s/it]avg_loss = 1.7764218545729114:  37%|███▋      | 62/166 [01:19<02:13,  1.28s/it]avg_loss = 1.770502485926189:  37%|███▋      | 62/166 [01:20<02:13,  1.28s/it] avg_loss = 1.770502485926189:  38%|███▊      | 63/166 [01:20<02:12,  1.29s/it]avg_loss = 1.7660040482878685:  38%|███▊      | 63/166 [01:21<02:12,  1.29s/it]avg_loss = 1.7660040482878685:  39%|███▊      | 64/166 [01:21<02:11,  1.29s/it]avg_loss = 1.75903767989232:  39%|███▊      | 64/166 [01:23<02:11,  1.29s/it]  avg_loss = 1.75903767989232:  39%|███▉      | 65/166 [01:23<02:09,  1.29s/it]avg_loss = 1.751973619966796:  39%|███▉      | 65/166 [01:24<02:09,  1.29s/it]avg_loss = 1.751973619966796:  40%|███▉      | 66/166 [01:24<02:08,  1.29s/it]avg_loss = 1.7471563816070557:  40%|███▉      | 66/166 [01:25<02:08,  1.29s/it]avg_loss = 1.7471563816070557:  40%|████      | 67/166 [01:25<02:07,  1.29s/it]avg_loss = 1.7460024795111488:  40%|████      | 67/166 [01:26<02:07,  1.29s/it]avg_loss = 1.7460024795111488:  41%|████      | 68/166 [01:26<02:06,  1.29s/it]avg_loss = 1.748009723165761:  41%|████      | 68/166 [01:28<02:06,  1.29s/it] avg_loss = 1.748009723165761:  42%|████▏     | 69/166 [01:28<02:04,  1.29s/it]avg_loss = 1.750984823703766:  42%|████▏     | 69/166 [01:29<02:04,  1.29s/it]avg_loss = 1.750984823703766:  42%|████▏     | 70/166 [01:29<02:03,  1.29s/it]avg_loss = 1.7549580066976413:  42%|████▏     | 70/166 [01:30<02:03,  1.29s/it]avg_loss = 1.7549580066976413:  43%|████▎     | 71/166 [01:30<02:02,  1.29s/it]avg_loss = 1.7597556594345305:  43%|████▎     | 71/166 [01:32<02:02,  1.29s/it]avg_loss = 1.7597556594345305:  43%|████▎     | 72/166 [01:32<02:01,  1.29s/it]avg_loss = 1.7657650545851824:  43%|████▎     | 72/166 [01:33<02:01,  1.29s/it]avg_loss = 1.7657650545851824:  44%|████▍     | 73/166 [01:33<01:59,  1.29s/it]avg_loss = 1.760228105493494:  44%|████▍     | 73/166 [01:34<01:59,  1.29s/it] avg_loss = 1.760228105493494:  45%|████▍     | 74/166 [01:34<01:58,  1.29s/it]avg_loss = 1.7556487433115642:  45%|████▍     | 74/166 [01:35<01:58,  1.29s/it]avg_loss = 1.7556487433115642:  45%|████▌     | 75/166 [01:35<01:57,  1.29s/it]avg_loss = 1.754795331703989:  45%|████▌     | 75/166 [01:37<01:57,  1.29s/it] avg_loss = 1.754795331703989:  46%|████▌     | 76/166 [01:37<01:56,  1.29s/it]avg_loss = 1.7512861552176537:  46%|████▌     | 76/166 [01:38<01:56,  1.29s/it]avg_loss = 1.7512861552176537:  46%|████▋     | 77/166 [01:38<01:54,  1.29s/it]avg_loss = 1.747578535324488:  46%|████▋     | 77/166 [01:39<01:54,  1.29s/it] avg_loss = 1.747578535324488:  47%|████▋     | 78/166 [01:39<01:53,  1.29s/it]avg_loss = 1.7449712436410445:  47%|████▋     | 78/166 [01:41<01:53,  1.29s/it]avg_loss = 1.7449712436410445:  48%|████▊     | 79/166 [01:41<01:52,  1.29s/it]avg_loss = 1.7414740562438964:  48%|████▊     | 79/166 [01:42<01:52,  1.29s/it]avg_loss = 1.7414740562438964:  48%|████▊     | 80/166 [01:42<01:50,  1.29s/it]avg_loss = 1.732449973071063:  48%|████▊     | 80/166 [01:43<01:50,  1.29s/it] avg_loss = 1.732449973071063:  49%|████▉     | 81/166 [01:43<01:49,  1.29s/it]avg_loss = 1.7341702594989683:  49%|████▉     | 81/166 [01:44<01:49,  1.29s/it]avg_loss = 1.7341702594989683:  49%|████▉     | 82/166 [01:44<01:48,  1.29s/it]avg_loss = 1.7361964102250984:  49%|████▉     | 82/166 [01:46<01:48,  1.29s/it]avg_loss = 1.7361964102250984:  50%|█████     | 83/166 [01:46<01:47,  1.29s/it]avg_loss = 1.7393527243818556:  50%|█████     | 83/166 [01:47<01:47,  1.29s/it]avg_loss = 1.7393527243818556:  51%|█████     | 84/166 [01:47<01:46,  1.30s/it]avg_loss = 1.7412214812110451:  51%|█████     | 84/166 [01:48<01:46,  1.30s/it]avg_loss = 1.7412214812110451:  51%|█████     | 85/166 [01:48<01:44,  1.29s/it]avg_loss = 1.7400004794431287:  51%|█████     | 85/166 [01:50<01:44,  1.29s/it]avg_loss = 1.7400004794431287:  52%|█████▏    | 86/166 [01:50<01:43,  1.29s/it]avg_loss = 1.7401792427589153:  52%|█████▏    | 86/166 [01:51<01:43,  1.29s/it]avg_loss = 1.7401792427589153:  52%|█████▏    | 87/166 [01:51<01:42,  1.29s/it]avg_loss = 1.7402510141784495:  52%|█████▏    | 87/166 [01:52<01:42,  1.29s/it]avg_loss = 1.7402510141784495:  53%|█████▎    | 88/166 [01:52<01:40,  1.29s/it]avg_loss = 1.7414530823739727:  53%|█████▎    | 88/166 [01:54<01:40,  1.29s/it]avg_loss = 1.7414530823739727:  54%|█████▎    | 89/166 [01:54<01:39,  1.29s/it]avg_loss = 1.741160147719913:  54%|█████▎    | 89/166 [01:55<01:39,  1.29s/it] avg_loss = 1.741160147719913:  54%|█████▍    | 90/166 [01:55<01:38,  1.29s/it]avg_loss = 1.741503268807799:  54%|█████▍    | 90/166 [01:56<01:38,  1.29s/it]avg_loss = 1.741503268807799:  55%|█████▍    | 91/166 [01:56<01:37,  1.29s/it]avg_loss = 1.7425055257652118:  55%|█████▍    | 91/166 [01:57<01:37,  1.29s/it]avg_loss = 1.7425055257652118:  55%|█████▌    | 92/166 [01:57<01:35,  1.30s/it]avg_loss = 1.7464294497684767:  55%|█████▌    | 92/166 [01:59<01:35,  1.30s/it]avg_loss = 1.7464294497684767:  56%|█████▌    | 93/166 [01:59<01:34,  1.30s/it]avg_loss = 1.74540679885986:  56%|█████▌    | 93/166 [02:00<01:34,  1.30s/it]  avg_loss = 1.74540679885986:  57%|█████▋    | 94/166 [02:00<01:33,  1.30s/it]avg_loss = 1.7446051133306404:  57%|█████▋    | 94/166 [02:01<01:33,  1.30s/it]avg_loss = 1.7446051133306404:  57%|█████▋    | 95/166 [02:01<01:32,  1.30s/it]avg_loss = 1.7441514084736507:  57%|█████▋    | 95/166 [02:03<01:32,  1.30s/it]avg_loss = 1.7441514084736507:  58%|█████▊    | 96/166 [02:03<01:30,  1.29s/it]avg_loss = 1.7439227337689744:  58%|█████▊    | 96/166 [02:04<01:30,  1.29s/it]avg_loss = 1.7439227337689744:  58%|█████▊    | 97/166 [02:04<01:29,  1.30s/it]avg_loss = 1.7421527991489487:  58%|█████▊    | 97/166 [02:05<01:29,  1.30s/it]avg_loss = 1.7421527991489487:  59%|█████▉    | 98/166 [02:05<01:27,  1.29s/it]avg_loss = 1.739713657986034:  59%|█████▉    | 98/166 [02:06<01:27,  1.29s/it] avg_loss = 1.739713657986034:  60%|█████▉    | 99/166 [02:06<01:26,  1.29s/it]avg_loss = 1.7370855724811554:  60%|█████▉    | 99/166 [02:08<01:26,  1.29s/it]avg_loss = 1.7370855724811554:  60%|██████    | 100/166 [02:08<01:25,  1.29s/it]avg_loss = 1.7375634271319549:  60%|██████    | 100/166 [02:09<01:25,  1.29s/it]avg_loss = 1.7375634271319549:  61%|██████    | 101/166 [02:09<01:24,  1.30s/it]avg_loss = 1.7383999871272666:  61%|██████    | 101/166 [02:10<01:24,  1.30s/it]avg_loss = 1.7383999871272666:  61%|██████▏   | 102/166 [02:10<01:23,  1.30s/it]avg_loss = 1.7394761854005092:  61%|██████▏   | 102/166 [02:12<01:23,  1.30s/it]avg_loss = 1.7394761854005092:  62%|██████▏   | 103/166 [02:12<01:21,  1.30s/it]avg_loss = 1.7417717702113664:  62%|██████▏   | 103/166 [02:13<01:21,  1.30s/it]avg_loss = 1.7417717702113664:  63%|██████▎   | 104/166 [02:13<01:20,  1.29s/it]avg_loss = 1.7484951325825282:  63%|██████▎   | 104/166 [02:14<01:20,  1.29s/it]avg_loss = 1.7484951325825282:  63%|██████▎   | 105/166 [02:14<01:18,  1.29s/it]avg_loss = 1.7537412902094283:  63%|██████▎   | 105/166 [02:16<01:18,  1.29s/it]avg_loss = 1.7537412902094283:  64%|██████▍   | 106/166 [02:16<01:17,  1.29s/it]avg_loss = 1.7572856272492454:  64%|██████▍   | 106/166 [02:17<01:17,  1.29s/it]avg_loss = 1.7572856272492454:  64%|██████▍   | 107/166 [02:17<01:16,  1.29s/it]avg_loss = 1.7604336837927501:  64%|██████▍   | 107/166 [02:18<01:16,  1.29s/it]avg_loss = 1.7604336837927501:  65%|██████▌   | 108/166 [02:18<01:15,  1.29s/it]avg_loss = 1.7652594266681496:  65%|██████▌   | 108/166 [02:19<01:15,  1.29s/it]avg_loss = 1.7652594266681496:  66%|██████▌   | 109/166 [02:19<01:13,  1.29s/it]avg_loss = 1.768740707094019:  66%|██████▌   | 109/166 [02:21<01:13,  1.29s/it] avg_loss = 1.768740707094019:  66%|██████▋   | 110/166 [02:21<01:12,  1.29s/it]avg_loss = 1.770070338034415:  66%|██████▋   | 110/166 [02:22<01:12,  1.29s/it]avg_loss = 1.770070338034415:  67%|██████▋   | 111/166 [02:22<01:11,  1.29s/it]avg_loss = 1.7713820785284042:  67%|██████▋   | 111/166 [02:23<01:11,  1.29s/it]avg_loss = 1.7713820785284042:  67%|██████▋   | 112/166 [02:23<01:09,  1.29s/it]avg_loss = 1.7716750645004542:  67%|██████▋   | 112/166 [02:25<01:09,  1.29s/it]avg_loss = 1.7716750645004542:  68%|██████▊   | 113/166 [02:25<01:08,  1.30s/it]avg_loss = 1.7729816227628474:  68%|██████▊   | 113/166 [02:26<01:08,  1.30s/it]avg_loss = 1.7729816227628474:  69%|██████▊   | 114/166 [02:26<01:07,  1.30s/it]avg_loss = 1.770286602559297:  69%|██████▊   | 114/166 [02:27<01:07,  1.30s/it] avg_loss = 1.770286602559297:  69%|██████▉   | 115/166 [02:27<01:06,  1.30s/it]avg_loss = 1.7697239662038868:  69%|██████▉   | 115/166 [02:29<01:06,  1.30s/it]avg_loss = 1.7697239662038868:  70%|██████▉   | 116/166 [02:29<01:04,  1.30s/it]avg_loss = 1.77075048083933:  70%|██████▉   | 116/166 [02:30<01:04,  1.30s/it]  avg_loss = 1.77075048083933:  70%|███████   | 117/166 [02:30<01:03,  1.29s/it]avg_loss = 1.7708803566835694:  70%|███████   | 117/166 [02:31<01:03,  1.29s/it]avg_loss = 1.7708803566835694:  71%|███████   | 118/166 [02:31<01:02,  1.30s/it]avg_loss = 1.7704521537828846:  71%|███████   | 118/166 [02:32<01:02,  1.30s/it]avg_loss = 1.7704521537828846:  72%|███████▏  | 119/166 [02:32<01:00,  1.30s/it]avg_loss = 1.7710330377022425:  72%|███████▏  | 119/166 [02:34<01:00,  1.30s/it]avg_loss = 1.7710330377022425:  72%|███████▏  | 120/166 [02:34<00:59,  1.30s/it]avg_loss = 1.770623908555212:  72%|███████▏  | 120/166 [02:35<00:59,  1.30s/it] avg_loss = 1.770623908555212:  73%|███████▎  | 121/166 [02:35<00:58,  1.30s/it]avg_loss = 1.7711989948006928:  73%|███████▎  | 121/166 [02:36<00:58,  1.30s/it]avg_loss = 1.7711989948006928:  73%|███████▎  | 122/166 [02:36<00:57,  1.30s/it]avg_loss = 1.7715268299831608:  73%|███████▎  | 122/166 [02:38<00:57,  1.30s/it]avg_loss = 1.7715268299831608:  74%|███████▍  | 123/166 [02:38<00:55,  1.30s/it]avg_loss = 1.7701301555479727:  74%|███████▍  | 123/166 [02:39<00:55,  1.30s/it]avg_loss = 1.7701301555479727:  75%|███████▍  | 124/166 [02:39<00:54,  1.30s/it]avg_loss = 1.7685194034576417:  75%|███████▍  | 124/166 [02:40<00:54,  1.30s/it]avg_loss = 1.7685194034576417:  75%|███████▌  | 125/166 [02:40<00:53,  1.30s/it]avg_loss = 1.7663128054331219:  75%|███████▌  | 125/166 [02:41<00:53,  1.30s/it]avg_loss = 1.7663128054331219:  76%|███████▌  | 126/166 [02:41<00:51,  1.30s/it]avg_loss = 1.7641909770139559:  76%|███████▌  | 126/166 [02:43<00:51,  1.30s/it]avg_loss = 1.7641909770139559:  77%|███████▋  | 127/166 [02:43<00:50,  1.30s/it]avg_loss = 1.762815780006349:  77%|███████▋  | 127/166 [02:44<00:50,  1.30s/it] avg_loss = 1.762815780006349:  77%|███████▋  | 128/166 [02:44<00:49,  1.30s/it]avg_loss = 1.7615869886191315:  77%|███████▋  | 128/166 [02:45<00:49,  1.30s/it]avg_loss = 1.7615869886191315:  78%|███████▊  | 129/166 [02:45<00:48,  1.30s/it]avg_loss = 1.7615741197879498:  78%|███████▊  | 129/166 [02:47<00:48,  1.30s/it]avg_loss = 1.7615741197879498:  78%|███████▊  | 130/166 [02:47<00:46,  1.30s/it]avg_loss = 1.762693136702967:  78%|███████▊  | 130/166 [02:48<00:46,  1.30s/it] avg_loss = 1.762693136702967:  79%|███████▉  | 131/166 [02:48<00:45,  1.30s/it]avg_loss = 1.7633814811706543:  79%|███████▉  | 131/166 [02:49<00:45,  1.30s/it]avg_loss = 1.7633814811706543:  80%|███████▉  | 132/166 [02:49<00:44,  1.30s/it]avg_loss = 1.7642551929430854:  80%|███████▉  | 132/166 [02:51<00:44,  1.30s/it]avg_loss = 1.7642551929430854:  80%|████████  | 133/166 [02:51<00:42,  1.30s/it]avg_loss = 1.7655922930632064:  80%|████████  | 133/166 [02:52<00:42,  1.30s/it]avg_loss = 1.7655922930632064:  81%|████████  | 134/166 [02:52<00:41,  1.30s/it]avg_loss = 1.7634339111822623:  81%|████████  | 134/166 [02:53<00:41,  1.30s/it]avg_loss = 1.7634339111822623:  81%|████████▏ | 135/166 [02:53<00:40,  1.30s/it]avg_loss = 1.763674400308553:  81%|████████▏ | 135/166 [02:54<00:40,  1.30s/it] avg_loss = 1.763674400308553:  82%|████████▏ | 136/166 [02:54<00:38,  1.30s/it]avg_loss = 1.7639719465353194:  82%|████████▏ | 136/166 [02:56<00:38,  1.30s/it]avg_loss = 1.7639719465353194:  83%|████████▎ | 137/166 [02:56<00:37,  1.30s/it]avg_loss = 1.764725324900254:  83%|████████▎ | 137/166 [02:57<00:37,  1.30s/it] avg_loss = 1.764725324900254:  83%|████████▎ | 138/166 [02:57<00:36,  1.30s/it]avg_loss = 1.763775964435056:  83%|████████▎ | 138/166 [02:58<00:36,  1.30s/it]avg_loss = 1.763775964435056:  84%|████████▎ | 139/166 [02:58<00:35,  1.30s/it]avg_loss = 1.762392748253686:  84%|████████▎ | 139/166 [03:00<00:35,  1.30s/it]avg_loss = 1.762392748253686:  84%|████████▍ | 140/166 [03:00<00:33,  1.30s/it]avg_loss = 1.7609749279969127:  84%|████████▍ | 140/166 [03:01<00:33,  1.30s/it]avg_loss = 1.7609749279969127:  85%|████████▍ | 141/166 [03:01<00:32,  1.30s/it]avg_loss = 1.7605843636351572:  85%|████████▍ | 141/166 [03:02<00:32,  1.30s/it]avg_loss = 1.7605843636351572:  86%|████████▌ | 142/166 [03:02<00:31,  1.30s/it]avg_loss = 1.7589306714651467:  86%|████████▌ | 142/166 [03:04<00:31,  1.30s/it]avg_loss = 1.7589306714651467:  86%|████████▌ | 143/166 [03:04<00:29,  1.30s/it]avg_loss = 1.760102187593778:  86%|████████▌ | 143/166 [03:05<00:29,  1.30s/it] avg_loss = 1.760102187593778:  87%|████████▋ | 144/166 [03:05<00:28,  1.30s/it]avg_loss = 1.759282446729726:  87%|████████▋ | 144/166 [03:06<00:28,  1.30s/it]avg_loss = 1.759282446729726:  87%|████████▋ | 145/166 [03:06<00:27,  1.30s/it]avg_loss = 1.7591300329116926:  87%|████████▋ | 145/166 [03:07<00:27,  1.30s/it]avg_loss = 1.7591300329116926:  88%|████████▊ | 146/166 [03:07<00:25,  1.30s/it]avg_loss = 1.757945965747444:  88%|████████▊ | 146/166 [03:09<00:25,  1.30s/it] avg_loss = 1.757945965747444:  89%|████████▊ | 147/166 [03:09<00:24,  1.30s/it]avg_loss = 1.7569330866272386:  89%|████████▊ | 147/166 [03:10<00:24,  1.30s/it]avg_loss = 1.7569330866272386:  89%|████████▉ | 148/166 [03:10<00:23,  1.30s/it]avg_loss = 1.7551686987780886:  89%|████████▉ | 148/166 [03:11<00:23,  1.30s/it]avg_loss = 1.7551686987780886:  90%|████████▉ | 149/166 [03:11<00:22,  1.30s/it]avg_loss = 1.7561717120806377:  90%|████████▉ | 149/166 [03:13<00:22,  1.30s/it]avg_loss = 1.7561717120806377:  90%|█████████ | 150/166 [03:13<00:20,  1.30s/it]avg_loss = 1.7553022468326898:  90%|█████████ | 150/166 [03:14<00:20,  1.30s/it]avg_loss = 1.7553022468326898:  91%|█████████ | 151/166 [03:14<00:19,  1.29s/it]avg_loss = 1.7551209707009165:  91%|█████████ | 151/166 [03:15<00:19,  1.29s/it]avg_loss = 1.7551209707009165:  92%|█████████▏| 152/166 [03:15<00:18,  1.30s/it]avg_loss = 1.7549346638660805:  92%|█████████▏| 152/166 [03:17<00:18,  1.30s/it]avg_loss = 1.7549346638660805:  92%|█████████▏| 153/166 [03:17<00:16,  1.30s/it]avg_loss = 1.7565892075563405:  92%|█████████▏| 153/166 [03:18<00:16,  1.30s/it]avg_loss = 1.7565892075563405:  93%|█████████▎| 154/166 [03:18<00:15,  1.30s/it]avg_loss = 1.7560966891627159:  93%|█████████▎| 154/166 [03:19<00:15,  1.30s/it]avg_loss = 1.7560966891627159:  93%|█████████▎| 155/166 [03:19<00:14,  1.30s/it]avg_loss = 1.755899524077391:  93%|█████████▎| 155/166 [03:20<00:14,  1.30s/it] avg_loss = 1.755899524077391:  94%|█████████▍| 156/166 [03:20<00:12,  1.30s/it]avg_loss = 1.754020202691388:  94%|█████████▍| 156/166 [03:22<00:12,  1.30s/it]avg_loss = 1.754020202691388:  95%|█████████▍| 157/166 [03:22<00:11,  1.30s/it]avg_loss = 1.7496642425090452:  95%|█████████▍| 157/166 [03:23<00:11,  1.30s/it]avg_loss = 1.7496642425090452:  95%|█████████▌| 158/166 [03:23<00:10,  1.30s/it]avg_loss = 1.750367710425419:  95%|█████████▌| 158/166 [03:24<00:10,  1.30s/it] avg_loss = 1.750367710425419:  96%|█████████▌| 159/166 [03:24<00:09,  1.30s/it]avg_loss = 1.7518463842570782:  96%|█████████▌| 159/166 [03:26<00:09,  1.30s/it]avg_loss = 1.7518463842570782:  96%|█████████▋| 160/166 [03:26<00:07,  1.30s/it]avg_loss = 1.7542736478473828:  96%|█████████▋| 160/166 [03:27<00:07,  1.30s/it]avg_loss = 1.7542736478473828:  97%|█████████▋| 161/166 [03:27<00:06,  1.30s/it]avg_loss = 1.7546570713137404:  97%|█████████▋| 161/166 [03:28<00:06,  1.30s/it]avg_loss = 1.7546570713137404:  98%|█████████▊| 162/166 [03:28<00:05,  1.30s/it]avg_loss = 1.7543045216542812:  98%|█████████▊| 162/166 [03:30<00:05,  1.30s/it]avg_loss = 1.7543045216542812:  98%|█████████▊| 163/166 [03:30<00:03,  1.30s/it]avg_loss = 1.7550056729374863:  98%|█████████▊| 163/166 [03:31<00:03,  1.30s/it]avg_loss = 1.7550056729374863:  99%|█████████▉| 164/166 [03:31<00:02,  1.30s/it]avg_loss = 1.7552249352137248:  99%|█████████▉| 164/166 [03:32<00:02,  1.30s/it]avg_loss = 1.7552249352137248:  99%|█████████▉| 165/166 [03:32<00:01,  1.30s/it]avg_loss = 1.7571954691266438:  99%|█████████▉| 165/166 [03:33<00:01,  1.30s/it]avg_loss = 1.7571954691266438: 100%|██████████| 166/166 [03:33<00:00,  1.30s/it]avg_loss = 1.7571954691266438: 100%|██████████| 166/166 [03:33<00:00,  1.29s/it]
I0318 15:39:10.340292 730148 eval_ppl.py:107] wikitext2 perplexity: 5.796159267425537
wikitext2 perplexity: 5.796
