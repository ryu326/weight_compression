W0318 12:41:41.421180 629672 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 12:41:41.926251 629672 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  3.13it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  6.93it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.02it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.32it/s]
W0318 12:41:42.850316 629672 big_modeling.py:439] Some parameters are on the meta device because they were offloaded to the cpu.
I0318 12:41:43.240423 629672 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]  0%|          | 0/166 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 93, in main
    output = model(input,
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1163, in forward
    outputs = self.model(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 913, in forward
    layer_outputs = decoder_layer(
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 656, in forward
    hidden_states = self.mlp(hidden_states)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 242, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 77.00 MiB is free. Process 3347854 has 26.65 GiB memory in use. Process 3350306 has 18.73 GiB memory in use. Process 3354593 has 2.02 GiB memory in use. Of the allocated memory 1.51 GiB is allocated by PyTorch, and 15.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0318 15:25:35.895575 722502 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 15:25:37.040992 722502 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:09,  1.88s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.18s/it]
Traceback (most recent call last):
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 124, in <module>
    main(args)
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 71, in main
    model, model_str = model_from_hf_path(
  File "/workspace/Weight_compression/comp_lm_qtip/eval_ppl.py", line 49, in model_from_hf_path
    model = maybe_wrap(use_cuda_graph)(model_cls).from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4777, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py", line 942, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 339, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 47.51 GiB of which 18.00 MiB is free. Process 3515056 has 9.62 GiB memory in use. Process 3515035 has 5.74 GiB memory in use. Process 3515025 has 8.86 GiB memory in use. Process 3515018 has 5.55 GiB memory in use. Process 3515042 has 6.26 GiB memory in use. Process 3515049 has 5.87 GiB memory in use. Process 3515063 has 5.55 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 1.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0318 15:39:13.883541 733586 warnings.py:109] /opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(

I0318 15:39:14.329668 733586 modeling.py:990] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:06,  1.22s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.10s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.02s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:01,  1.01it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:04<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.09it/s]
I0318 15:39:20.293113 733586 config.py:54] PyTorch version 2.6.0 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.4455915689468384:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.4455915689468384:   1%|          | 1/166 [00:01<04:22,  1.59s/it]avg_loss = 1.7000537514686584:   1%|          | 1/166 [00:02<04:22,  1.59s/it]avg_loss = 1.7000537514686584:   1%|          | 2/166 [00:02<03:46,  1.38s/it]avg_loss = 1.8626047372817993:   1%|          | 2/166 [00:04<03:46,  1.38s/it]avg_loss = 1.8626047372817993:   2%|▏         | 3/166 [00:04<03:34,  1.32s/it]avg_loss = 1.8948616981506348:   2%|▏         | 3/166 [00:05<03:34,  1.32s/it]avg_loss = 1.8948616981506348:   2%|▏         | 4/166 [00:05<03:28,  1.29s/it]avg_loss = 1.8221255779266357:   2%|▏         | 4/166 [00:06<03:28,  1.29s/it]avg_loss = 1.8221255779266357:   3%|▎         | 5/166 [00:06<03:24,  1.27s/it]avg_loss = 1.7986867030461628:   3%|▎         | 5/166 [00:07<03:24,  1.27s/it]avg_loss = 1.7986867030461628:   4%|▎         | 6/166 [00:07<03:22,  1.26s/it]avg_loss = 1.7379511765071325:   4%|▎         | 6/166 [00:09<03:22,  1.26s/it]avg_loss = 1.7379511765071325:   4%|▍         | 7/166 [00:09<03:20,  1.26s/it]avg_loss = 1.6812929660081863:   4%|▍         | 7/166 [00:10<03:20,  1.26s/it]avg_loss = 1.6812929660081863:   5%|▍         | 8/166 [00:10<03:18,  1.26s/it]avg_loss = 1.6775164074367948:   5%|▍         | 8/166 [00:11<03:18,  1.26s/it]avg_loss = 1.6775164074367948:   5%|▌         | 9/166 [00:11<03:17,  1.26s/it]avg_loss = 1.683819556236267:   5%|▌         | 9/166 [00:12<03:17,  1.26s/it] avg_loss = 1.683819556236267:   6%|▌         | 10/166 [00:12<03:16,  1.26s/it]avg_loss = 1.6994295553727583:   6%|▌         | 10/166 [00:14<03:16,  1.26s/it]avg_loss = 1.6994295553727583:   7%|▋         | 11/166 [00:14<03:14,  1.26s/it]avg_loss = 1.707773317893346:   7%|▋         | 11/166 [00:15<03:14,  1.26s/it] avg_loss = 1.707773317893346:   7%|▋         | 12/166 [00:15<03:13,  1.26s/it]avg_loss = 1.7020862561005812:   7%|▋         | 12/166 [00:16<03:13,  1.26s/it]avg_loss = 1.7020862561005812:   8%|▊         | 13/166 [00:16<03:12,  1.26s/it]avg_loss = 1.7117677075522286:   8%|▊         | 13/166 [00:17<03:12,  1.26s/it]avg_loss = 1.7117677075522286:   8%|▊         | 14/166 [00:17<03:11,  1.26s/it]avg_loss = 1.7285252730051677:   8%|▊         | 14/166 [00:19<03:11,  1.26s/it]avg_loss = 1.7285252730051677:   9%|▉         | 15/166 [00:19<03:10,  1.26s/it]avg_loss = 1.7478400021791458:   9%|▉         | 15/166 [00:20<03:10,  1.26s/it]avg_loss = 1.7478400021791458:  10%|▉         | 16/166 [00:20<03:09,  1.26s/it]avg_loss = 1.7602859244627111:  10%|▉         | 16/166 [00:21<03:09,  1.26s/it]avg_loss = 1.7602859244627111:  10%|█         | 17/166 [00:21<03:08,  1.26s/it]avg_loss = 1.774393876393636:  10%|█         | 17/166 [00:22<03:08,  1.26s/it] avg_loss = 1.774393876393636:  11%|█         | 18/166 [00:22<03:07,  1.26s/it]avg_loss = 1.7943584542525441:  11%|█         | 18/166 [00:24<03:07,  1.26s/it]avg_loss = 1.7943584542525441:  11%|█▏        | 19/166 [00:24<03:05,  1.26s/it]avg_loss = 1.8006407856941222:  11%|█▏        | 19/166 [00:25<03:05,  1.26s/it]avg_loss = 1.8006407856941222:  12%|█▏        | 20/166 [00:25<03:04,  1.27s/it]avg_loss = 1.801394990512303:  12%|█▏        | 20/166 [00:26<03:04,  1.27s/it] avg_loss = 1.801394990512303:  13%|█▎        | 21/166 [00:26<03:03,  1.27s/it]avg_loss = 1.791136627847498:  13%|█▎        | 21/166 [00:27<03:03,  1.27s/it]avg_loss = 1.791136627847498:  13%|█▎        | 22/166 [00:27<03:02,  1.27s/it]avg_loss = 1.7806472726490186:  13%|█▎        | 22/166 [00:29<03:02,  1.27s/it]avg_loss = 1.7806472726490186:  14%|█▍        | 23/166 [00:29<03:01,  1.27s/it]avg_loss = 1.7880672216415405:  14%|█▍        | 23/166 [00:30<03:01,  1.27s/it]avg_loss = 1.7880672216415405:  14%|█▍        | 24/166 [00:30<03:00,  1.27s/it]avg_loss = 1.7957843732833862:  14%|█▍        | 24/166 [00:31<03:00,  1.27s/it]avg_loss = 1.7957843732833862:  15%|█▌        | 25/166 [00:31<02:58,  1.27s/it]avg_loss = 1.8006261724692125:  15%|█▌        | 25/166 [00:33<02:58,  1.27s/it]avg_loss = 1.8006261724692125:  16%|█▌        | 26/166 [00:33<02:57,  1.27s/it]avg_loss = 1.807480017344157:  16%|█▌        | 26/166 [00:34<02:57,  1.27s/it] avg_loss = 1.807480017344157:  16%|█▋        | 27/166 [00:34<02:56,  1.27s/it]avg_loss = 1.8098901893411363:  16%|█▋        | 27/166 [00:35<02:56,  1.27s/it]avg_loss = 1.8098901893411363:  17%|█▋        | 28/166 [00:35<02:55,  1.27s/it]avg_loss = 1.8188416259042148:  17%|█▋        | 28/166 [00:36<02:55,  1.27s/it]avg_loss = 1.8188416259042148:  17%|█▋        | 29/166 [00:36<02:54,  1.27s/it]avg_loss = 1.8194274266560873:  17%|█▋        | 29/166 [00:38<02:54,  1.27s/it]avg_loss = 1.8194274266560873:  18%|█▊        | 30/166 [00:38<02:53,  1.27s/it]avg_loss = 1.83343522010311:  18%|█▊        | 30/166 [00:39<02:53,  1.27s/it]  avg_loss = 1.83343522010311:  19%|█▊        | 31/166 [00:39<02:52,  1.28s/it]avg_loss = 1.8394999206066132:  19%|█▊        | 31/166 [00:40<02:52,  1.28s/it]avg_loss = 1.8394999206066132:  19%|█▉        | 32/166 [00:40<02:50,  1.28s/it]avg_loss = 1.84441369230097:  19%|█▉        | 32/166 [00:42<02:50,  1.28s/it]  avg_loss = 1.84441369230097:  20%|█▉        | 33/166 [00:42<02:49,  1.28s/it]avg_loss = 1.8434946922694935:  20%|█▉        | 33/166 [00:43<02:49,  1.28s/it]avg_loss = 1.8434946922694935:  20%|██        | 34/166 [00:43<02:48,  1.28s/it]avg_loss = 1.8369932583400181:  20%|██        | 34/166 [00:44<02:48,  1.28s/it]avg_loss = 1.8369932583400181:  21%|██        | 35/166 [00:44<02:47,  1.28s/it]avg_loss = 1.828944120142195:  21%|██        | 35/166 [00:45<02:47,  1.28s/it] avg_loss = 1.828944120142195:  22%|██▏       | 36/166 [00:45<02:45,  1.28s/it]avg_loss = 1.8196028535430495:  22%|██▏       | 36/166 [00:47<02:45,  1.28s/it]avg_loss = 1.8196028535430495:  22%|██▏       | 37/166 [00:47<02:44,  1.28s/it]avg_loss = 1.8167388815628855:  22%|██▏       | 37/166 [00:48<02:44,  1.28s/it]avg_loss = 1.8167388815628855:  23%|██▎       | 38/166 [00:48<02:43,  1.28s/it]avg_loss = 1.8142841412470891:  23%|██▎       | 38/166 [00:49<02:43,  1.28s/it]avg_loss = 1.8142841412470891:  23%|██▎       | 39/166 [00:49<02:42,  1.28s/it]avg_loss = 1.8176118582487106:  23%|██▎       | 39/166 [00:50<02:42,  1.28s/it]avg_loss = 1.8176118582487106:  24%|██▍       | 40/166 [00:50<02:41,  1.28s/it]avg_loss = 1.8174339329324118:  24%|██▍       | 40/166 [00:52<02:41,  1.28s/it]avg_loss = 1.8174339329324118:  25%|██▍       | 41/166 [00:52<02:40,  1.28s/it]avg_loss = 1.804890391372499:  25%|██▍       | 41/166 [00:53<02:40,  1.28s/it] avg_loss = 1.804890391372499:  25%|██▌       | 42/166 [00:53<02:38,  1.28s/it]avg_loss = 1.7893035716788714:  25%|██▌       | 42/166 [00:54<02:38,  1.28s/it]avg_loss = 1.7893035716788714:  26%|██▌       | 43/166 [00:54<02:37,  1.28s/it]avg_loss = 1.7788306312127546:  26%|██▌       | 43/166 [00:56<02:37,  1.28s/it]avg_loss = 1.7788306312127546:  27%|██▋       | 44/166 [00:56<02:36,  1.28s/it]avg_loss = 1.7650029102961222:  27%|██▋       | 44/166 [00:57<02:36,  1.28s/it]avg_loss = 1.7650029102961222:  27%|██▋       | 45/166 [00:57<02:35,  1.28s/it]avg_loss = 1.7545169488243435:  27%|██▋       | 45/166 [00:58<02:35,  1.28s/it]avg_loss = 1.7545169488243435:  28%|██▊       | 46/166 [00:58<02:33,  1.28s/it]avg_loss = 1.7471343633976388:  28%|██▊       | 46/166 [00:59<02:33,  1.28s/it]avg_loss = 1.7471343633976388:  28%|██▊       | 47/166 [00:59<02:32,  1.28s/it]avg_loss = 1.748536432782809:  28%|██▊       | 47/166 [01:01<02:32,  1.28s/it] avg_loss = 1.748536432782809:  29%|██▉       | 48/166 [01:01<02:31,  1.28s/it]avg_loss = 1.7591813973018102:  29%|██▉       | 48/166 [01:02<02:31,  1.28s/it]avg_loss = 1.7591813973018102:  30%|██▉       | 49/166 [01:02<02:30,  1.28s/it]avg_loss = 1.7697741889953613:  30%|██▉       | 49/166 [01:03<02:30,  1.28s/it]avg_loss = 1.7697741889953613:  30%|███       | 50/166 [01:03<02:28,  1.28s/it]avg_loss = 1.776720121795056:  30%|███       | 50/166 [01:05<02:28,  1.28s/it] avg_loss = 1.776720121795056:  31%|███       | 51/166 [01:05<02:27,  1.28s/it]avg_loss = 1.782087702017564:  31%|███       | 51/166 [01:06<02:27,  1.28s/it]avg_loss = 1.782087702017564:  31%|███▏      | 52/166 [01:06<02:26,  1.28s/it]avg_loss = 1.7856203250165255:  31%|███▏      | 52/166 [01:07<02:26,  1.28s/it]avg_loss = 1.7856203250165255:  32%|███▏      | 53/166 [01:07<02:24,  1.28s/it]avg_loss = 1.7859886686007183:  32%|███▏      | 53/166 [01:08<02:24,  1.28s/it]avg_loss = 1.7859886686007183:  33%|███▎      | 54/166 [01:08<02:23,  1.28s/it]avg_loss = 1.7884221467104826:  33%|███▎      | 54/166 [01:10<02:23,  1.28s/it]avg_loss = 1.7884221467104826:  33%|███▎      | 55/166 [01:10<02:22,  1.28s/it]avg_loss = 1.791657343506813:  33%|███▎      | 55/166 [01:11<02:22,  1.28s/it] avg_loss = 1.791657343506813:  34%|███▎      | 56/166 [01:11<02:21,  1.29s/it]avg_loss = 1.7867375403119807:  34%|███▎      | 56/166 [01:12<02:21,  1.29s/it]avg_loss = 1.7867375403119807:  34%|███▍      | 57/166 [01:12<02:20,  1.29s/it]avg_loss = 1.7904525399208069:  34%|███▍      | 57/166 [01:14<02:20,  1.29s/it]avg_loss = 1.7904525399208069:  35%|███▍      | 58/166 [01:14<02:18,  1.29s/it]avg_loss = 1.788789456173525:  35%|███▍      | 58/166 [01:15<02:18,  1.29s/it] avg_loss = 1.788789456173525:  36%|███▌      | 59/166 [01:15<02:17,  1.28s/it]avg_loss = 1.784303738673528:  36%|███▌      | 59/166 [01:16<02:17,  1.28s/it]avg_loss = 1.784303738673528:  36%|███▌      | 60/166 [01:16<02:16,  1.28s/it]avg_loss = 1.7799683555227812:  36%|███▌      | 60/166 [01:17<02:16,  1.28s/it]avg_loss = 1.7799683555227812:  37%|███▋      | 61/166 [01:17<02:14,  1.29s/it]avg_loss = 1.7759267803161376:  37%|███▋      | 61/166 [01:19<02:14,  1.29s/it]avg_loss = 1.7759267803161376:  37%|███▋      | 62/166 [01:19<02:13,  1.29s/it]avg_loss = 1.7700129066194807:  37%|███▋      | 62/166 [01:20<02:13,  1.29s/it]avg_loss = 1.7700129066194807:  38%|███▊      | 63/166 [01:20<02:12,  1.29s/it]avg_loss = 1.765527157112956:  38%|███▊      | 63/166 [01:21<02:12,  1.29s/it] avg_loss = 1.765527157112956:  39%|███▊      | 64/166 [01:21<02:11,  1.29s/it]avg_loss = 1.7585473537445069:  39%|███▊      | 64/166 [01:23<02:11,  1.29s/it]avg_loss = 1.7585473537445069:  39%|███▉      | 65/166 [01:23<02:09,  1.29s/it]avg_loss = 1.7514923449718591:  39%|███▉      | 65/166 [01:24<02:09,  1.29s/it]avg_loss = 1.7514923449718591:  40%|███▉      | 66/166 [01:24<02:08,  1.29s/it]avg_loss = 1.7466512687170683:  40%|███▉      | 66/166 [01:25<02:08,  1.29s/it]avg_loss = 1.7466512687170683:  40%|████      | 67/166 [01:25<02:07,  1.29s/it]avg_loss = 1.7455080467111923:  40%|████      | 67/166 [01:26<02:07,  1.29s/it]avg_loss = 1.7455080467111923:  41%|████      | 68/166 [01:26<02:06,  1.29s/it]avg_loss = 1.7475330155828726:  41%|████      | 68/166 [01:28<02:06,  1.29s/it]avg_loss = 1.7475330155828726:  42%|████▏     | 69/166 [01:28<02:04,  1.29s/it]avg_loss = 1.7505022202219283:  42%|████▏     | 69/166 [01:29<02:04,  1.29s/it]avg_loss = 1.7505022202219283:  42%|████▏     | 70/166 [01:29<02:03,  1.29s/it]avg_loss = 1.7544906055423575:  42%|████▏     | 70/166 [01:30<02:03,  1.29s/it]avg_loss = 1.7544906055423575:  43%|████▎     | 71/166 [01:30<02:02,  1.29s/it]avg_loss = 1.7592791931496725:  43%|████▎     | 71/166 [01:32<02:02,  1.29s/it]avg_loss = 1.7592791931496725:  43%|████▎     | 72/166 [01:32<02:01,  1.29s/it]avg_loss = 1.7652919961981577:  43%|████▎     | 72/166 [01:33<02:01,  1.29s/it]avg_loss = 1.7652919961981577:  44%|████▍     | 73/166 [01:33<02:00,  1.29s/it]avg_loss = 1.7596954300596908:  44%|████▍     | 73/166 [01:34<02:00,  1.29s/it]avg_loss = 1.7596954300596908:  45%|████▍     | 74/166 [01:34<01:58,  1.29s/it]avg_loss = 1.7551245911916098:  45%|████▍     | 74/166 [01:35<01:58,  1.29s/it]avg_loss = 1.7551245911916098:  45%|████▌     | 75/166 [01:35<01:57,  1.29s/it]avg_loss = 1.7542762097559477:  45%|████▌     | 75/166 [01:37<01:57,  1.29s/it]avg_loss = 1.7542762097559477:  46%|████▌     | 76/166 [01:37<01:56,  1.29s/it]avg_loss = 1.7507687590338967:  46%|████▌     | 76/166 [01:38<01:56,  1.29s/it]avg_loss = 1.7507687590338967:  46%|████▋     | 77/166 [01:38<01:54,  1.29s/it]avg_loss = 1.7470464752270625:  46%|████▋     | 77/166 [01:39<01:54,  1.29s/it]avg_loss = 1.7470464752270625:  47%|████▋     | 78/166 [01:39<01:53,  1.29s/it]avg_loss = 1.7444455321831038:  47%|████▋     | 78/166 [01:41<01:53,  1.29s/it]avg_loss = 1.7444455321831038:  48%|████▊     | 79/166 [01:41<01:52,  1.29s/it]avg_loss = 1.740933994948864:  48%|████▊     | 79/166 [01:42<01:52,  1.29s/it] avg_loss = 1.740933994948864:  48%|████▊     | 80/166 [01:42<01:50,  1.29s/it]avg_loss = 1.731904614118882:  48%|████▊     | 80/166 [01:43<01:50,  1.29s/it]avg_loss = 1.731904614118882:  49%|████▉     | 81/166 [01:43<01:49,  1.29s/it]avg_loss = 1.7336360143452156:  49%|████▉     | 81/166 [01:44<01:49,  1.29s/it]avg_loss = 1.7336360143452156:  49%|████▉     | 82/166 [01:44<01:48,  1.29s/it]avg_loss = 1.7356444281267833:  49%|████▉     | 82/166 [01:46<01:48,  1.29s/it]avg_loss = 1.7356444281267833:  50%|█████     | 83/166 [01:46<01:47,  1.29s/it]avg_loss = 1.738800109851928:  50%|█████     | 83/166 [01:47<01:47,  1.29s/it] avg_loss = 1.738800109851928:  51%|█████     | 84/166 [01:47<01:45,  1.29s/it]avg_loss = 1.7406613728579352:  51%|█████     | 84/166 [01:48<01:45,  1.29s/it]avg_loss = 1.7406613728579352:  51%|█████     | 85/166 [01:48<01:44,  1.29s/it]avg_loss = 1.7394374747608983:  51%|█████     | 85/166 [01:50<01:44,  1.29s/it]avg_loss = 1.7394374747608983:  52%|█████▏    | 86/166 [01:50<01:43,  1.29s/it]avg_loss = 1.7396227737952923:  52%|█████▏    | 86/166 [01:51<01:43,  1.29s/it]avg_loss = 1.7396227737952923:  52%|█████▏    | 87/166 [01:51<01:42,  1.29s/it]avg_loss = 1.7397033396092327:  52%|█████▏    | 87/166 [01:52<01:42,  1.29s/it]avg_loss = 1.7397033396092327:  53%|█████▎    | 88/166 [01:52<01:40,  1.29s/it]avg_loss = 1.7409111676591167:  53%|█████▎    | 88/166 [01:54<01:40,  1.29s/it]avg_loss = 1.7409111676591167:  54%|█████▎    | 89/166 [01:54<01:39,  1.29s/it]avg_loss = 1.7406284875339932:  54%|█████▎    | 89/166 [01:55<01:39,  1.29s/it]avg_loss = 1.7406284875339932:  54%|█████▍    | 90/166 [01:55<01:38,  1.29s/it]avg_loss = 1.740970445203257:  54%|█████▍    | 90/166 [01:56<01:38,  1.29s/it] avg_loss = 1.740970445203257:  55%|█████▍    | 91/166 [01:56<01:37,  1.29s/it]avg_loss = 1.7419723414856454:  55%|█████▍    | 91/166 [01:57<01:37,  1.29s/it]avg_loss = 1.7419723414856454:  55%|█████▌    | 92/166 [01:57<01:35,  1.29s/it]avg_loss = 1.7458949512050999:  55%|█████▌    | 92/166 [01:59<01:35,  1.29s/it]avg_loss = 1.7458949512050999:  56%|█████▌    | 93/166 [01:59<01:34,  1.29s/it]avg_loss = 1.7448779953287004:  56%|█████▌    | 93/166 [02:00<01:34,  1.29s/it]avg_loss = 1.7448779953287004:  57%|█████▋    | 94/166 [02:00<01:33,  1.29s/it]avg_loss = 1.7440846292596115:  57%|█████▋    | 94/166 [02:01<01:33,  1.29s/it]avg_loss = 1.7440846292596115:  57%|█████▋    | 95/166 [02:01<01:31,  1.29s/it]avg_loss = 1.7436315429707367:  57%|█████▋    | 95/166 [02:03<01:31,  1.29s/it]avg_loss = 1.7436315429707367:  58%|█████▊    | 96/166 [02:03<01:30,  1.29s/it]avg_loss = 1.7433994148195404:  58%|█████▊    | 96/166 [02:04<01:30,  1.29s/it]avg_loss = 1.7433994148195404:  58%|█████▊    | 97/166 [02:04<01:29,  1.30s/it]avg_loss = 1.7416137164952803:  58%|█████▊    | 97/166 [02:05<01:29,  1.30s/it]avg_loss = 1.7416137164952803:  59%|█████▉    | 98/166 [02:05<01:27,  1.29s/it]avg_loss = 1.7391747356665255:  59%|█████▉    | 98/166 [02:06<01:27,  1.29s/it]avg_loss = 1.7391747356665255:  60%|█████▉    | 99/166 [02:06<01:26,  1.29s/it]avg_loss = 1.736542776823044:  60%|█████▉    | 99/166 [02:08<01:26,  1.29s/it] avg_loss = 1.736542776823044:  60%|██████    | 100/166 [02:08<01:25,  1.29s/it]avg_loss = 1.7370101166243601:  60%|██████    | 100/166 [02:09<01:25,  1.29s/it]avg_loss = 1.7370101166243601:  61%|██████    | 101/166 [02:09<01:23,  1.29s/it]avg_loss = 1.7378593788427465:  61%|██████    | 101/166 [02:10<01:23,  1.29s/it]avg_loss = 1.7378593788427465:  61%|██████▏   | 102/166 [02:10<01:22,  1.29s/it]avg_loss = 1.7389334012003779:  61%|██████▏   | 102/166 [02:12<01:22,  1.29s/it]avg_loss = 1.7389334012003779:  62%|██████▏   | 103/166 [02:12<01:21,  1.29s/it]avg_loss = 1.7412247508764267:  62%|██████▏   | 103/166 [02:13<01:21,  1.29s/it]avg_loss = 1.7412247508764267:  63%|██████▎   | 104/166 [02:13<01:20,  1.29s/it]avg_loss = 1.747945525532677:  63%|██████▎   | 104/166 [02:14<01:20,  1.29s/it] avg_loss = 1.747945525532677:  63%|██████▎   | 105/166 [02:14<01:18,  1.29s/it]avg_loss = 1.7531856849508465:  63%|██████▎   | 105/166 [02:16<01:18,  1.29s/it]avg_loss = 1.7531856849508465:  64%|██████▍   | 106/166 [02:16<01:17,  1.29s/it]avg_loss = 1.7567276230482298:  64%|██████▍   | 106/166 [02:17<01:17,  1.29s/it]avg_loss = 1.7567276230482298:  64%|██████▍   | 107/166 [02:17<01:16,  1.29s/it]avg_loss = 1.7598808529200378:  64%|██████▍   | 107/166 [02:18<01:16,  1.29s/it]avg_loss = 1.7598808529200378:  65%|██████▌   | 108/166 [02:18<01:15,  1.29s/it]avg_loss = 1.7647130784638432:  65%|██████▌   | 108/166 [02:19<01:15,  1.29s/it]avg_loss = 1.7647130784638432:  66%|██████▌   | 109/166 [02:19<01:13,  1.30s/it]avg_loss = 1.7681717601689426:  66%|██████▌   | 109/166 [02:21<01:13,  1.30s/it]avg_loss = 1.7681717601689426:  66%|██████▋   | 110/166 [02:21<01:12,  1.30s/it]avg_loss = 1.7695001116744034:  66%|██████▋   | 110/166 [02:22<01:12,  1.30s/it]avg_loss = 1.7695001116744034:  67%|██████▋   | 111/166 [02:22<01:11,  1.30s/it]avg_loss = 1.7708057558962278:  67%|██████▋   | 111/166 [02:23<01:11,  1.30s/it]avg_loss = 1.7708057558962278:  67%|██████▋   | 112/166 [02:23<01:10,  1.30s/it]avg_loss = 1.7710985620464899:  67%|██████▋   | 112/166 [02:25<01:10,  1.30s/it]avg_loss = 1.7710985620464899:  68%|██████▊   | 113/166 [02:25<01:08,  1.30s/it]avg_loss = 1.7724083452893977:  68%|██████▊   | 113/166 [02:26<01:08,  1.30s/it]avg_loss = 1.7724083452893977:  69%|██████▊   | 114/166 [02:26<01:07,  1.30s/it]avg_loss = 1.7697094585584559:  69%|██████▊   | 114/166 [02:27<01:07,  1.30s/it]avg_loss = 1.7697094585584559:  69%|██████▉   | 115/166 [02:27<01:06,  1.30s/it]avg_loss = 1.769150819244056:  69%|██████▉   | 115/166 [02:28<01:06,  1.30s/it] avg_loss = 1.769150819244056:  70%|██████▉   | 116/166 [02:28<01:04,  1.30s/it]avg_loss = 1.770173954148578:  70%|██████▉   | 116/166 [02:30<01:04,  1.30s/it]avg_loss = 1.770173954148578:  70%|███████   | 117/166 [02:30<01:03,  1.30s/it]avg_loss = 1.7703052819785425:  70%|███████   | 117/166 [02:31<01:03,  1.30s/it]avg_loss = 1.7703052819785425:  71%|███████   | 118/166 [02:31<01:02,  1.29s/it]avg_loss = 1.7698793020568977:  71%|███████   | 118/166 [02:32<01:02,  1.29s/it]avg_loss = 1.7698793020568977:  72%|███████▏  | 119/166 [02:32<01:00,  1.30s/it]avg_loss = 1.7704671770334244:  72%|███████▏  | 119/166 [02:34<01:00,  1.30s/it]avg_loss = 1.7704671770334244:  72%|███████▏  | 120/166 [02:34<00:59,  1.30s/it]avg_loss = 1.7700605126451854:  72%|███████▏  | 120/166 [02:35<00:59,  1.30s/it]avg_loss = 1.7700605126451854:  73%|███████▎  | 121/166 [02:35<00:58,  1.30s/it]avg_loss = 1.7706319816776963:  73%|███████▎  | 121/166 [02:36<00:58,  1.30s/it]avg_loss = 1.7706319816776963:  73%|███████▎  | 122/166 [02:36<00:57,  1.30s/it]avg_loss = 1.7709646632031697:  73%|███████▎  | 122/166 [02:38<00:57,  1.30s/it]avg_loss = 1.7709646632031697:  74%|███████▍  | 123/166 [02:38<00:55,  1.30s/it]avg_loss = 1.769572704069076:  74%|███████▍  | 123/166 [02:39<00:55,  1.30s/it] avg_loss = 1.769572704069076:  75%|███████▍  | 124/166 [02:39<00:54,  1.30s/it]avg_loss = 1.767965365409851:  75%|███████▍  | 124/166 [02:40<00:54,  1.30s/it]avg_loss = 1.767965365409851:  75%|███████▌  | 125/166 [02:40<00:53,  1.29s/it]avg_loss = 1.7657628031004042:  75%|███████▌  | 125/166 [02:41<00:53,  1.29s/it]avg_loss = 1.7657628031004042:  76%|███████▌  | 126/166 [02:41<00:51,  1.30s/it]avg_loss = 1.7636470785291176:  76%|███████▌  | 126/166 [02:43<00:51,  1.30s/it]avg_loss = 1.7636470785291176:  77%|███████▋  | 127/166 [02:43<00:50,  1.30s/it]avg_loss = 1.7622649371623993:  77%|███████▋  | 127/166 [02:44<00:50,  1.30s/it]avg_loss = 1.7622649371623993:  77%|███████▋  | 128/166 [02:44<00:49,  1.30s/it]avg_loss = 1.7610392755316209:  77%|███████▋  | 128/166 [02:45<00:49,  1.30s/it]avg_loss = 1.7610392755316209:  78%|███████▊  | 129/166 [02:45<00:47,  1.30s/it]avg_loss = 1.761021427007822:  78%|███████▊  | 129/166 [02:47<00:47,  1.30s/it] avg_loss = 1.761021427007822:  78%|███████▊  | 130/166 [02:47<00:46,  1.29s/it]avg_loss = 1.762141356941398:  78%|███████▊  | 130/166 [02:48<00:46,  1.29s/it]avg_loss = 1.762141356941398:  79%|███████▉  | 131/166 [02:48<00:45,  1.30s/it]avg_loss = 1.7628349029656611:  79%|███████▉  | 131/166 [02:49<00:45,  1.30s/it]avg_loss = 1.7628349029656611:  80%|███████▉  | 132/166 [02:49<00:44,  1.30s/it]avg_loss = 1.7637211882082142:  80%|███████▉  | 132/166 [02:51<00:44,  1.30s/it]avg_loss = 1.7637211882082142:  80%|████████  | 133/166 [02:51<00:42,  1.30s/it]avg_loss = 1.765061596436287:  80%|████████  | 133/166 [02:52<00:42,  1.30s/it] avg_loss = 1.765061596436287:  81%|████████  | 134/166 [02:52<00:41,  1.30s/it]avg_loss = 1.7628988204178986:  81%|████████  | 134/166 [02:53<00:41,  1.30s/it]avg_loss = 1.7628988204178986:  81%|████████▏ | 135/166 [02:53<00:40,  1.30s/it]avg_loss = 1.7631471805712755:  81%|████████▏ | 135/166 [02:54<00:40,  1.30s/it]avg_loss = 1.7631471805712755:  82%|████████▏ | 136/166 [02:54<00:38,  1.30s/it]avg_loss = 1.7634448039270665:  82%|████████▏ | 136/166 [02:56<00:38,  1.30s/it]avg_loss = 1.7634448039270665:  83%|████████▎ | 137/166 [02:56<00:37,  1.30s/it]avg_loss = 1.7642058963360994:  83%|████████▎ | 137/166 [02:57<00:37,  1.30s/it]avg_loss = 1.7642058963360994:  83%|████████▎ | 138/166 [02:57<00:36,  1.30s/it]avg_loss = 1.7632650034033137:  83%|████████▎ | 138/166 [02:58<00:36,  1.30s/it]avg_loss = 1.7632650034033137:  84%|████████▎ | 139/166 [02:58<00:34,  1.29s/it]avg_loss = 1.7618810977254595:  84%|████████▎ | 139/166 [03:00<00:34,  1.29s/it]avg_loss = 1.7618810977254595:  84%|████████▍ | 140/166 [03:00<00:33,  1.30s/it]avg_loss = 1.7604586325638683:  84%|████████▍ | 140/166 [03:01<00:33,  1.30s/it]avg_loss = 1.7604586325638683:  85%|████████▍ | 141/166 [03:01<00:32,  1.30s/it]avg_loss = 1.7600718501587989:  85%|████████▍ | 141/166 [03:02<00:32,  1.30s/it]avg_loss = 1.7600718501587989:  86%|████████▌ | 142/166 [03:02<00:31,  1.30s/it]avg_loss = 1.7584296148140113:  86%|████████▌ | 142/166 [03:03<00:31,  1.30s/it]avg_loss = 1.7584296148140113:  86%|████████▌ | 143/166 [03:03<00:29,  1.30s/it]avg_loss = 1.7595974910590384:  86%|████████▌ | 143/166 [03:05<00:29,  1.30s/it]avg_loss = 1.7595974910590384:  87%|████████▋ | 144/166 [03:05<00:28,  1.29s/it]avg_loss = 1.7587708670517495:  87%|████████▋ | 144/166 [03:06<00:28,  1.29s/it]avg_loss = 1.7587708670517495:  87%|████████▋ | 145/166 [03:06<00:27,  1.30s/it]avg_loss = 1.7586124490385187:  87%|████████▋ | 145/166 [03:07<00:27,  1.30s/it]avg_loss = 1.7586124490385187:  88%|████████▊ | 146/166 [03:07<00:25,  1.30s/it]avg_loss = 1.7574202089893574:  88%|████████▊ | 146/166 [03:09<00:25,  1.30s/it]avg_loss = 1.7574202089893574:  89%|████████▊ | 147/166 [03:09<00:24,  1.30s/it]avg_loss = 1.7564064989218842:  89%|████████▊ | 147/166 [03:10<00:24,  1.30s/it]avg_loss = 1.7564064989218842:  89%|████████▉ | 148/166 [03:10<00:23,  1.30s/it]avg_loss = 1.7546445731348639:  89%|████████▉ | 148/166 [03:11<00:23,  1.30s/it]avg_loss = 1.7546445731348639:  90%|████████▉ | 149/166 [03:11<00:22,  1.30s/it]avg_loss = 1.7556441005071004:  90%|████████▉ | 149/166 [03:13<00:22,  1.30s/it]avg_loss = 1.7556441005071004:  90%|█████████ | 150/166 [03:13<00:20,  1.30s/it]avg_loss = 1.7547844735202411:  90%|█████████ | 150/166 [03:14<00:20,  1.30s/it]avg_loss = 1.7547844735202411:  91%|█████████ | 151/166 [03:14<00:19,  1.30s/it]avg_loss = 1.7545967776524394:  91%|█████████ | 151/166 [03:15<00:19,  1.30s/it]avg_loss = 1.7545967776524394:  92%|█████████▏| 152/166 [03:15<00:18,  1.30s/it]avg_loss = 1.7544153531392415:  92%|█████████▏| 152/166 [03:16<00:18,  1.30s/it]avg_loss = 1.7544153531392415:  92%|█████████▏| 153/166 [03:16<00:16,  1.29s/it]avg_loss = 1.7560566369589272:  92%|█████████▏| 153/166 [03:18<00:16,  1.29s/it]avg_loss = 1.7560566369589272:  93%|█████████▎| 154/166 [03:18<00:15,  1.30s/it]avg_loss = 1.7555630353189284:  93%|█████████▎| 154/166 [03:19<00:15,  1.30s/it]avg_loss = 1.7555630353189284:  93%|█████████▎| 155/166 [03:19<00:14,  1.30s/it]avg_loss = 1.7553698435807839:  93%|█████████▎| 155/166 [03:20<00:14,  1.30s/it]avg_loss = 1.7553698435807839:  94%|█████████▍| 156/166 [03:20<00:12,  1.30s/it]avg_loss = 1.7534886568215242:  94%|█████████▍| 156/166 [03:22<00:12,  1.30s/it]avg_loss = 1.7534886568215242:  95%|█████████▍| 157/166 [03:22<00:11,  1.30s/it]avg_loss = 1.7491343934324723:  95%|█████████▍| 157/166 [03:23<00:11,  1.30s/it]avg_loss = 1.7491343934324723:  95%|█████████▌| 158/166 [03:23<00:10,  1.29s/it]avg_loss = 1.7498389332549378:  95%|█████████▌| 158/166 [03:24<00:10,  1.29s/it]avg_loss = 1.7498389332549378:  96%|█████████▌| 159/166 [03:24<00:09,  1.30s/it]avg_loss = 1.7513124339282513:  96%|█████████▌| 159/166 [03:26<00:09,  1.30s/it]avg_loss = 1.7513124339282513:  96%|█████████▋| 160/166 [03:26<00:07,  1.30s/it]avg_loss = 1.7537400641056322:  96%|█████████▋| 160/166 [03:27<00:07,  1.30s/it]avg_loss = 1.7537400641056322:  97%|█████████▋| 161/166 [03:27<00:06,  1.30s/it]avg_loss = 1.7541193167368572:  97%|█████████▋| 161/166 [03:28<00:06,  1.30s/it]avg_loss = 1.7541193167368572:  98%|█████████▊| 162/166 [03:28<00:05,  1.30s/it]avg_loss = 1.7537699769611008:  98%|█████████▊| 162/166 [03:29<00:05,  1.30s/it]avg_loss = 1.7537699769611008:  98%|█████████▊| 163/166 [03:29<00:03,  1.30s/it]avg_loss = 1.7544731032557603:  98%|█████████▊| 163/166 [03:31<00:03,  1.30s/it]avg_loss = 1.7544731032557603:  99%|█████████▉| 164/166 [03:31<00:02,  1.30s/it]avg_loss = 1.7546909650166829:  99%|█████████▉| 164/166 [03:32<00:02,  1.30s/it]avg_loss = 1.7546909650166829:  99%|█████████▉| 165/166 [03:32<00:01,  1.30s/it]avg_loss = 1.7566672491740032:  99%|█████████▉| 165/166 [03:33<00:01,  1.30s/it]avg_loss = 1.7566672491740032: 100%|██████████| 166/166 [03:33<00:00,  1.30s/it]avg_loss = 1.7566672491740032: 100%|██████████| 166/166 [03:33<00:00,  1.29s/it]
I0318 15:43:39.375417 733586 eval_ppl.py:107] wikitext2 perplexity: 5.793098449707031
wikitext2 perplexity: 5.793
