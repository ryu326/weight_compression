Running with lmbda=200
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  9.72it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.34it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.09it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.13it/s]
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:24,  1.28it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:23,  1.30it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:21,  1.32it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:03<00:20,  1.35it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:20,  1.33it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:04<00:19,  1.33it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:05<00:18,  1.33it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:06<00:18,  1.31it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:06<00:17,  1.32it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:07<00:16,  1.30it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:08<00:16,  1.27it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:08<00:13,  1.43it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:09<00:12,  1.52it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:10<00:11,  1.63it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:10<00:09,  1.75it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:10<00:08,  1.80it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:11<00:08,  1.86it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:12<00:07,  1.83it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:12<00:07,  1.78it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:13<00:06,  1.74it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:13<00:06,  1.76it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:14<00:05,  1.78it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:14<00:04,  1.84it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:15<00:04,  1.93it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:15<00:03,  1.99it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:16<00:02,  2.04it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:16<00:02,  2.09it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:17<00:01,  2.11it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:17<00:01,  2.14it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:18<00:01,  1.79it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:19<00:00,  1.48it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:20<00:00,  1.35it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]
pseudo compress quantization...:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-03 03:24:14 - INFO - layer0_self_attn.q_proj | mse: 0.03887422355597164, bpp_loss: 3.212625314015895, bpp: 0
2025-03-03 03:24:24 - INFO - layer0_self_attn.k_proj | mse: 0.03634832690411287, bpp_loss: 3.3348986839409918, bpp: 0
2025-03-03 03:24:35 - INFO - layer0_self_attn.v_proj | mse: 0.029282582032125165, bpp_loss: 3.122926580836065, bpp: 0
2025-03-03 03:24:48 - INFO - layer0_self_attn.o_proj | mse: 0.03257899640507303, bpp_loss: 2.9964248161995783, bpp: 0
2025-03-03 03:25:02 - INFO - layer0_mlp.gate_proj | mse: 0.031112333502874307, bpp_loss: 3.474915154364913, bpp: 0
2025-03-03 03:25:15 - INFO - layer0_mlp.up_proj | mse: 0.031080473041410157, bpp_loss: 3.4564286851605703, bpp: 0
2025-03-03 03:25:51 - INFO - layer0_mlp.down_proj | mse: 0.034330158185084655, bpp_loss: 3.5037653506192012, bpp: 0
pseudo compress quantization...:   3%|▎         | 1/32 [01:47<55:47, 108.00s/it]2025-03-03 03:26:02 - INFO - layer1_self_attn.q_proj | mse: 0.04299408751479641, bpp_loss: 3.938714569201693, bpp: 0
2025-03-03 03:26:13 - INFO - layer1_self_attn.k_proj | mse: 0.045651596810588745, bpp_loss: 3.9536119968397543, bpp: 0
2025-03-03 03:26:24 - INFO - layer1_self_attn.v_proj | mse: 0.034134285296693274, bpp_loss: 3.0772786026936956, bpp: 0
2025-03-03 03:26:34 - INFO - layer1_self_attn.o_proj | mse: 0.03795421843829502, bpp_loss: 3.0375336036086082, bpp: 0
2025-03-03 03:26:46 - INFO - layer1_mlp.gate_proj | mse: 0.03315470162272427, bpp_loss: 3.5946145226182633, bpp: 0
2025-03-03 03:26:59 - INFO - layer1_mlp.up_proj | mse: 0.03299046221588038, bpp_loss: 3.5222180962216023, bpp: 0
2025-03-03 03:27:35 - INFO - layer1_mlp.down_proj | mse: 0.024125085077277234, bpp_loss: 3.5383455896923364, bpp: 0
pseudo compress quantization...:   6%|▋         | 2/32 [03:32<52:54, 105.82s/it]2025-03-03 03:27:47 - INFO - layer2_self_attn.q_proj | mse: 0.03191890235856399, bpp_loss: 4.094135600607842, bpp: 0
2025-03-03 03:28:01 - INFO - layer2_self_attn.k_proj | mse: 0.032106749495814615, bpp_loss: 4.160257195180748, bpp: 0
2025-03-03 03:28:14 - INFO - layer2_self_attn.v_proj | mse: 0.03004952769972603, bpp_loss: 3.3285428535891697, bpp: 0
2025-03-03 03:28:25 - INFO - layer2_self_attn.o_proj | mse: 0.03074823642664428, bpp_loss: 3.3138824249617755, bpp: 0
2025-03-03 03:28:37 - INFO - layer2_mlp.gate_proj | mse: 0.0303626856048445, bpp_loss: 3.636254459229666, bpp: 0
2025-03-03 03:28:49 - INFO - layer2_mlp.up_proj | mse: 0.030175422929089007, bpp_loss: 3.54577397892988, bpp: 0
2025-03-03 03:29:21 - INFO - layer2_mlp.down_proj | mse: 0.026083645393737302, bpp_loss: 3.5547792993182705, bpp: 0
pseudo compress quantization...:   9%|▉         | 3/32 [05:18<51:11, 105.92s/it]2025-03-03 03:29:34 - INFO - layer3_self_attn.q_proj | mse: 0.029216767019030677, bpp_loss: 4.020548406930175, bpp: 0
2025-03-03 03:29:47 - INFO - layer3_self_attn.k_proj | mse: 0.029307826861076015, bpp_loss: 4.082469444256276, bpp: 0
2025-03-03 03:29:58 - INFO - layer3_self_attn.v_proj | mse: 0.02758671125277611, bpp_loss: 3.2829012359143235, bpp: 0
2025-03-03 03:30:11 - INFO - layer3_self_attn.o_proj | mse: 0.02658907987944904, bpp_loss: 3.2721123624942265, bpp: 0
2025-03-03 03:30:26 - INFO - layer3_mlp.gate_proj | mse: 0.02804188231939891, bpp_loss: 3.65324363398344, bpp: 0
2025-03-03 03:30:39 - INFO - layer3_mlp.up_proj | mse: 0.027844346595945705, bpp_loss: 3.5515508932862865, bpp: 0
2025-03-03 03:31:10 - INFO - layer3_mlp.down_proj | mse: 0.02555899340982715, bpp_loss: 3.5549771154819187, bpp: 0
pseudo compress quantization...:  12%|█▎        | 4/32 [07:07<49:56, 107.02s/it]2025-03-03 03:31:21 - INFO - layer4_self_attn.q_proj | mse: 0.0287366169776426, bpp_loss: 4.111813359893858, bpp: 0
2025-03-03 03:31:32 - INFO - layer4_self_attn.k_proj | mse: 0.028838167010832187, bpp_loss: 4.145006876438856, bpp: 0
2025-03-03 03:31:45 - INFO - layer4_self_attn.v_proj | mse: 0.027074317127589207, bpp_loss: 3.3296461146092042, bpp: 0
2025-03-03 03:31:58 - INFO - layer4_self_attn.o_proj | mse: 0.026948828831647623, bpp_loss: 3.325157523038797, bpp: 0
2025-03-03 03:32:11 - INFO - layer4_mlp.gate_proj | mse: 0.02768597781006317, bpp_loss: 3.678773821699758, bpp: 0
2025-03-03 03:32:23 - INFO - layer4_mlp.up_proj | mse: 0.027407363701559058, bpp_loss: 3.5419028944574125, bpp: 0
2025-03-03 03:33:00 - INFO - layer4_mlp.down_proj | mse: 0.025577722048935225, bpp_loss: 3.5405571845165174, bpp: 0
pseudo compress quantization...:  16%|█▌        | 5/32 [08:57<48:42, 108.23s/it]2025-03-03 03:33:11 - INFO - layer5_self_attn.q_proj | mse: 0.02829024645261519, bpp_loss: 4.132554622832686, bpp: 0
2025-03-03 03:33:22 - INFO - layer5_self_attn.k_proj | mse: 0.028464547018810713, bpp_loss: 4.197048278409056, bpp: 0
2025-03-03 03:33:33 - INFO - layer5_self_attn.v_proj | mse: 0.02670572640146843, bpp_loss: 3.3505577375763096, bpp: 0
2025-03-03 03:33:44 - INFO - layer5_self_attn.o_proj | mse: 0.027770102738554805, bpp_loss: 3.3355833634268492, bpp: 0
2025-03-03 03:33:57 - INFO - layer5_mlp.gate_proj | mse: 0.02758820599199582, bpp_loss: 3.6862884308536383, bpp: 0
2025-03-03 03:34:11 - INFO - layer5_mlp.up_proj | mse: 0.02731270937078885, bpp_loss: 3.5426051939815975, bpp: 0
2025-03-03 03:34:46 - INFO - layer5_mlp.down_proj | mse: 0.025420996088308858, bpp_loss: 3.5426844490778655, bpp: 0
pseudo compress quantization...:  19%|█▉        | 6/32 [10:42<46:29, 107.28s/it]2025-03-03 03:35:00 - INFO - layer6_self_attn.q_proj | mse: 0.027712900633019517, bpp_loss: 4.00234636006644, bpp: 0
2025-03-03 03:35:13 - INFO - layer6_self_attn.k_proj | mse: 0.027786421779348945, bpp_loss: 4.032960903190542, bpp: 0
2025-03-03 03:35:24 - INFO - layer6_self_attn.v_proj | mse: 0.02630018389737335, bpp_loss: 3.2849017526605166, bpp: 0
2025-03-03 03:35:34 - INFO - layer6_self_attn.o_proj | mse: 0.027231840920264608, bpp_loss: 3.290698927710764, bpp: 0
2025-03-03 03:35:46 - INFO - layer6_mlp.gate_proj | mse: 0.027187296263207907, bpp_loss: 3.7086624577641487, bpp: 0
2025-03-03 03:35:59 - INFO - layer6_mlp.up_proj | mse: 0.026858987768673976, bpp_loss: 3.5382341805758863, bpp: 0
2025-03-03 03:36:33 - INFO - layer6_mlp.down_proj | mse: 0.02545996252358447, bpp_loss: 3.5368873877450824, bpp: 0
pseudo compress quantization...:  22%|██▏       | 7/32 [12:30<44:44, 107.39s/it]2025-03-03 03:36:47 - INFO - layer7_self_attn.q_proj | mse: 0.027534231326629147, bpp_loss: 3.9957767648156732, bpp: 0
2025-03-03 03:36:57 - INFO - layer7_self_attn.k_proj | mse: 0.027557607563122654, bpp_loss: 4.007387353514787, bpp: 0
2025-03-03 03:37:10 - INFO - layer7_self_attn.v_proj | mse: 0.026145209502159133, bpp_loss: 3.2940186749910936, bpp: 0
2025-03-03 03:37:24 - INFO - layer7_self_attn.o_proj | mse: 0.0261900644122631, bpp_loss: 3.2962681567296386, bpp: 0
2025-03-03 03:37:37 - INFO - layer7_mlp.gate_proj | mse: 0.026972918346970975, bpp_loss: 3.706668451948221, bpp: 0
2025-03-03 03:37:49 - INFO - layer7_mlp.up_proj | mse: 0.026659983850995772, bpp_loss: 3.541868436128594, bpp: 0
2025-03-03 03:38:21 - INFO - layer7_mlp.down_proj | mse: 0.02558031564313886, bpp_loss: 3.5381229267953787, bpp: 0
pseudo compress quantization...:  25%|██▌       | 8/32 [14:18<43:00, 107.53s/it]2025-03-03 03:38:33 - INFO - layer8_self_attn.q_proj | mse: 0.027596430830596867, bpp_loss: 4.013900252408348, bpp: 0
2025-03-03 03:38:46 - INFO - layer8_self_attn.k_proj | mse: 0.027636650472589595, bpp_loss: 4.032968518033158, bpp: 0
2025-03-03 03:38:58 - INFO - layer8_self_attn.v_proj | mse: 0.02620633130629099, bpp_loss: 3.3192002081195824, bpp: 0
2025-03-03 03:39:10 - INFO - layer8_self_attn.o_proj | mse: 0.027113015822232932, bpp_loss: 3.3208780965651385, bpp: 0
2025-03-03 03:39:23 - INFO - layer8_mlp.gate_proj | mse: 0.026857303980583336, bpp_loss: 3.684676110484572, bpp: 0
2025-03-03 03:39:37 - INFO - layer8_mlp.up_proj | mse: 0.02661153559750935, bpp_loss: 3.5565944869331148, bpp: 0
2025-03-03 03:40:12 - INFO - layer8_mlp.down_proj | mse: 0.02565159097511916, bpp_loss: 3.549604671790676, bpp: 0
pseudo compress quantization...:  28%|██▊       | 9/32 [16:08<41:33, 108.42s/it]2025-03-03 03:40:23 - INFO - layer9_self_attn.q_proj | mse: 0.027517095319830404, bpp_loss: 4.040018404426519, bpp: 0
2025-03-03 03:40:34 - INFO - layer9_self_attn.k_proj | mse: 0.02760633292209951, bpp_loss: 4.080168558575679, bpp: 0
2025-03-03 03:40:44 - INFO - layer9_self_attn.v_proj | mse: 0.026122140352177997, bpp_loss: 3.3364308223244734, bpp: 0
2025-03-03 03:40:56 - INFO - layer9_self_attn.o_proj | mse: 0.02737761720532058, bpp_loss: 3.336072596372105, bpp: 0
2025-03-03 03:41:11 - INFO - layer9_mlp.gate_proj | mse: 0.026721065905008657, bpp_loss: 3.670260242684636, bpp: 0
2025-03-03 03:41:25 - INFO - layer9_mlp.up_proj | mse: 0.02654048879502663, bpp_loss: 3.564411647617817, bpp: 0
2025-03-03 03:41:59 - INFO - layer9_mlp.down_proj | mse: 0.025643128915892825, bpp_loss: 3.556892778724432, bpp: 0
pseudo compress quantization...:  31%|███▏      | 10/32 [17:56<39:40, 108.22s/it]2025-03-03 03:42:12 - INFO - layer10_self_attn.q_proj | mse: 0.02741440095482585, bpp_loss: 4.030374912486877, bpp: 0
2025-03-03 03:42:23 - INFO - layer10_self_attn.k_proj | mse: 0.02753654026955706, bpp_loss: 4.0753116542473435, bpp: 0
2025-03-03 03:42:34 - INFO - layer10_self_attn.v_proj | mse: 0.026064706483237148, bpp_loss: 3.329099056951236, bpp: 0
2025-03-03 03:42:44 - INFO - layer10_self_attn.o_proj | mse: 0.027971925209160826, bpp_loss: 3.334767285210546, bpp: 0
2025-03-03 03:42:57 - INFO - layer10_mlp.gate_proj | mse: 0.026730224332421, bpp_loss: 3.6631415788690713, bpp: 0
2025-03-03 03:43:09 - INFO - layer10_mlp.up_proj | mse: 0.026569180026665883, bpp_loss: 3.5775399372674697, bpp: 0
2025-03-03 03:43:46 - INFO - layer10_mlp.down_proj | mse: 0.025712297895805827, bpp_loss: 3.566578014948687, bpp: 0
pseudo compress quantization...:  34%|███▍      | 11/32 [19:42<37:40, 107.63s/it]2025-03-03 03:43:57 - INFO - layer11_self_attn.q_proj | mse: 0.02719300896166268, bpp_loss: 3.9155297730467282, bpp: 0
2025-03-03 03:44:10 - INFO - layer11_self_attn.k_proj | mse: 0.027215886906834227, bpp_loss: 3.920841072453186, bpp: 0
2025-03-03 03:44:24 - INFO - layer11_self_attn.v_proj | mse: 0.026114764481795984, bpp_loss: 3.3637044734787196, bpp: 0
2025-03-03 03:44:35 - INFO - layer11_self_attn.o_proj | mse: 0.02706243635601158, bpp_loss: 3.36878823582083, bpp: 0
2025-03-03 03:44:47 - INFO - layer11_mlp.gate_proj | mse: 0.026514897803175265, bpp_loss: 3.6599805668689482, bpp: 0
2025-03-03 03:44:59 - INFO - layer11_mlp.up_proj | mse: 0.02638214803634662, bpp_loss: 3.587865671446157, bpp: 0
2025-03-03 03:45:31 - INFO - layer11_mlp.down_proj | mse: 0.025603017677190663, bpp_loss: 3.574883950982503, bpp: 0
pseudo compress quantization...:  38%|███▊      | 12/32 [21:28<35:38, 106.93s/it]2025-03-03 03:45:44 - INFO - layer12_self_attn.q_proj | mse: 0.027110860422561205, bpp_loss: 3.977574909629766, bpp: 0
2025-03-03 03:45:57 - INFO - layer12_self_attn.k_proj | mse: 0.027213267980351376, bpp_loss: 4.026661355455872, bpp: 0
2025-03-03 03:46:08 - INFO - layer12_self_attn.v_proj | mse: 0.025890278447168565, bpp_loss: 3.3533434257260524, bpp: 0
2025-03-03 03:46:20 - INFO - layer12_self_attn.o_proj | mse: 0.02775090114040399, bpp_loss: 3.360147053608671, bpp: 0
2025-03-03 03:46:34 - INFO - layer12_mlp.gate_proj | mse: 0.026449232223578895, bpp_loss: 3.6529578780538814, bpp: 0
2025-03-03 03:46:48 - INFO - layer12_mlp.up_proj | mse: 0.026365530061183154, bpp_loss: 3.5996338875834333, bpp: 0
2025-03-03 03:47:20 - INFO - layer12_mlp.down_proj | mse: 0.02553081960346543, bpp_loss: 3.585115309046625, bpp: 0
pseudo compress quantization...:  41%|████      | 13/32 [23:16<34:02, 107.50s/it]2025-03-03 03:47:31 - INFO - layer13_self_attn.q_proj | mse: 0.026971136059432972, bpp_loss: 3.9658571091131307, bpp: 0
2025-03-03 03:47:42 - INFO - layer13_self_attn.k_proj | mse: 0.027044277693185792, bpp_loss: 3.9944497205433436, bpp: 0
2025-03-03 03:47:53 - INFO - layer13_self_attn.v_proj | mse: 0.02586995859058591, bpp_loss: 3.387174711737316, bpp: 0
2025-03-03 03:48:06 - INFO - layer13_self_attn.o_proj | mse: 0.02726261910052325, bpp_loss: 3.388080591626931, bpp: 0
2025-03-03 03:48:20 - INFO - layer13_mlp.gate_proj | mse: 0.026505161584202998, bpp_loss: 3.648151640282121, bpp: 0
2025-03-03 03:48:32 - INFO - layer13_mlp.up_proj | mse: 0.02645207159478936, bpp_loss: 3.6121204038865344, bpp: 0
2025-03-03 03:49:09 - INFO - layer13_mlp.down_proj | mse: 0.025671537719568094, bpp_loss: 3.594161356972574, bpp: 0
pseudo compress quantization...:  44%|████▍     | 14/32 [25:05<32:23, 107.97s/it]2025-03-03 03:49:20 - INFO - layer14_self_attn.q_proj | mse: 0.027145509051692735, bpp_loss: 3.957612423284445, bpp: 0
2025-03-03 03:49:30 - INFO - layer14_self_attn.k_proj | mse: 0.027213809727311876, bpp_loss: 3.990918332186993, bpp: 0
2025-03-03 03:49:41 - INFO - layer14_self_attn.v_proj | mse: 0.026019217120810453, bpp_loss: 3.3701940199243836, bpp: 0
2025-03-03 03:49:51 - INFO - layer14_self_attn.o_proj | mse: 0.027099912498690967, bpp_loss: 3.3733102263649926, bpp: 0
2025-03-03 03:50:03 - INFO - layer14_mlp.gate_proj | mse: 0.026445442083420957, bpp_loss: 3.645423896610737, bpp: 0
2025-03-03 03:50:18 - INFO - layer14_mlp.up_proj | mse: 0.026391718248042345, bpp_loss: 3.6140543213763903, bpp: 0
2025-03-03 03:50:53 - INFO - layer14_mlp.down_proj | mse: 0.025549427510008743, bpp_loss: 3.5967801731556306, bpp: 0
pseudo compress quantization...:  47%|████▋     | 15/32 [26:49<30:13, 106.70s/it]2025-03-03 03:51:06 - INFO - layer15_self_attn.q_proj | mse: 0.027066385025033845, bpp_loss: 3.9473985194345005, bpp: 0
2025-03-03 03:51:20 - INFO - layer15_self_attn.k_proj | mse: 0.02717908287803097, bpp_loss: 4.001834008900914, bpp: 0
2025-03-03 03:51:30 - INFO - layer15_self_attn.v_proj | mse: 0.026024049387816422, bpp_loss: 3.4083805000409484, bpp: 0
2025-03-03 03:51:41 - INFO - layer15_self_attn.o_proj | mse: 0.027745556096863213, bpp_loss: 3.4026195458718576, bpp: 0
2025-03-03 03:51:53 - INFO - layer15_mlp.gate_proj | mse: 0.026521117686198952, bpp_loss: 3.651581164882627, bpp: 0
2025-03-03 03:52:05 - INFO - layer15_mlp.up_proj | mse: 0.02648579263131398, bpp_loss: 3.620813070861406, bpp: 0
2025-03-03 03:52:38 - INFO - layer15_mlp.down_proj | mse: 0.025637098755470898, bpp_loss: 3.5996135760445234, bpp: 0
pseudo compress quantization...:  50%|█████     | 16/32 [28:35<28:22, 106.40s/it]2025-03-03 03:52:51 - INFO - layer16_self_attn.q_proj | mse: 0.027186099515134364, bpp_loss: 3.9281059083295986, bpp: 0
2025-03-03 03:53:02 - INFO - layer16_self_attn.k_proj | mse: 0.027271240699210157, bpp_loss: 3.9726919191889465, bpp: 0
2025-03-03 03:53:14 - INFO - layer16_self_attn.v_proj | mse: 0.02626694323093061, bpp_loss: 3.450586117687635, bpp: 0
2025-03-03 03:53:27 - INFO - layer16_self_attn.o_proj | mse: 0.02670860316473997, bpp_loss: 3.4561469524051063, bpp: 0
2025-03-03 03:53:42 - INFO - layer16_mlp.gate_proj | mse: 0.02689532180285014, bpp_loss: 3.661190300833347, bpp: 0
2025-03-03 03:53:53 - INFO - layer16_mlp.up_proj | mse: 0.026831661246204216, bpp_loss: 3.620729817380739, bpp: 0
2025-03-03 03:54:24 - INFO - layer16_mlp.down_proj | mse: 0.02564949971462246, bpp_loss: 3.6001411424300005, bpp: 0
pseudo compress quantization...:  53%|█████▎    | 17/32 [30:21<26:34, 106.29s/it]2025-03-03 03:54:35 - INFO - layer17_self_attn.q_proj | mse: 0.027256022534592438, bpp_loss: 3.9266694559482858, bpp: 0
2025-03-03 03:54:47 - INFO - layer17_self_attn.k_proj | mse: 0.027323674272676006, bpp_loss: 3.9614019250730053, bpp: 0
2025-03-03 03:54:59 - INFO - layer17_self_attn.v_proj | mse: 0.026350766260637273, bpp_loss: 3.4490920482203364, bpp: 0
2025-03-03 03:55:13 - INFO - layer17_self_attn.o_proj | mse: 0.026517754691387313, bpp_loss: 3.4524785458343104, bpp: 0
2025-03-03 03:55:24 - INFO - layer17_mlp.gate_proj | mse: 0.026697369983236255, bpp_loss: 3.675490893510192, bpp: 0
2025-03-03 03:55:37 - INFO - layer17_mlp.up_proj | mse: 0.026592873792499624, bpp_loss: 3.6169160605343276, bpp: 0
2025-03-03 03:56:13 - INFO - layer17_mlp.down_proj | mse: 0.025383243446496787, bpp_loss: 3.600612877673188, bpp: 0
pseudo compress quantization...:  56%|█████▋    | 18/32 [32:10<24:59, 107.12s/it]2025-03-03 03:56:24 - INFO - layer18_self_attn.q_proj | mse: 0.026953420644120322, bpp_loss: 3.897466598311439, bpp: 0
2025-03-03 03:56:34 - INFO - layer18_self_attn.k_proj | mse: 0.02702762838953873, bpp_loss: 3.92901976138819, bpp: 0
2025-03-03 03:56:45 - INFO - layer18_self_attn.v_proj | mse: 0.02622050074149854, bpp_loss: 3.499237571784761, bpp: 0
2025-03-03 03:56:56 - INFO - layer18_self_attn.o_proj | mse: 0.02604842220695384, bpp_loss: 3.4984779244987294, bpp: 0
2025-03-03 03:57:10 - INFO - layer18_mlp.gate_proj | mse: 0.02674783835124372, bpp_loss: 3.6873307482794275, bpp: 0
2025-03-03 03:57:24 - INFO - layer18_mlp.up_proj | mse: 0.026629011636258054, bpp_loss: 3.6133579185535742, bpp: 0
2025-03-03 03:57:57 - INFO - layer18_mlp.down_proj | mse: 0.025219599078722055, bpp_loss: 3.5995704997980664, bpp: 0
pseudo compress quantization...:  59%|█████▉    | 19/32 [33:54<22:58, 106.05s/it]2025-03-03 03:58:11 - INFO - layer19_self_attn.q_proj | mse: 0.02700764169285157, bpp_loss: 3.8744339771801606, bpp: 0
2025-03-03 03:58:22 - INFO - layer19_self_attn.k_proj | mse: 0.027062453738267, bpp_loss: 3.9034951239591464, bpp: 0
2025-03-03 03:58:33 - INFO - layer19_self_attn.v_proj | mse: 0.02633141691331541, bpp_loss: 3.509733576909639, bpp: 0
2025-03-03 03:58:44 - INFO - layer19_self_attn.o_proj | mse: 0.02560257604663152, bpp_loss: 3.5048072929494083, bpp: 0
2025-03-03 03:58:56 - INFO - layer19_mlp.gate_proj | mse: 0.026654826845729687, bpp_loss: 3.6925411680063536, bpp: 0
2025-03-03 03:59:08 - INFO - layer19_mlp.up_proj | mse: 0.02650549359875608, bpp_loss: 3.6133213047544626, bpp: 0
2025-03-03 03:59:43 - INFO - layer19_mlp.down_proj | mse: 0.02510892181185755, bpp_loss: 3.602989704153219, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 20/32 [35:40<21:12, 106.07s/it]2025-03-03 03:59:55 - INFO - layer20_self_attn.q_proj | mse: 0.02696853451520554, bpp_loss: 3.882444948423654, bpp: 0
2025-03-03 04:00:07 - INFO - layer20_self_attn.k_proj | mse: 0.027026579660128558, bpp_loss: 3.910060050606262, bpp: 0
2025-03-03 04:00:20 - INFO - layer20_self_attn.v_proj | mse: 0.026325078184173286, bpp_loss: 3.52786149980966, bpp: 0
2025-03-03 04:00:34 - INFO - layer20_self_attn.o_proj | mse: 0.025836642601036363, bpp_loss: 3.5301050731213763, bpp: 0
2025-03-03 04:00:45 - INFO - layer20_mlp.gate_proj | mse: 0.026834520020862593, bpp_loss: 3.7018656392776688, bpp: 0
2025-03-03 04:00:58 - INFO - layer20_mlp.up_proj | mse: 0.02666229932911274, bpp_loss: 3.6134997965811295, bpp: 0
2025-03-03 04:01:29 - INFO - layer20_mlp.down_proj | mse: 0.025164585992026922, bpp_loss: 3.6043013952195992, bpp: 0
pseudo compress quantization...:  66%|██████▌   | 21/32 [37:25<19:25, 105.97s/it]2025-03-03 04:01:40 - INFO - layer21_self_attn.q_proj | mse: 0.026917282935108058, bpp_loss: 3.8464719451148994, bpp: 0
2025-03-03 04:01:53 - INFO - layer21_self_attn.k_proj | mse: 0.026950958157936227, bpp_loss: 3.8624865392339416, bpp: 0
2025-03-03 04:02:07 - INFO - layer21_self_attn.v_proj | mse: 0.026425423047653954, bpp_loss: 3.5645087709999643, bpp: 0
2025-03-03 04:02:17 - INFO - layer21_self_attn.o_proj | mse: 0.025395049299206104, bpp_loss: 3.560951739898883, bpp: 0
2025-03-03 04:02:30 - INFO - layer21_mlp.gate_proj | mse: 0.026660716870138945, bpp_loss: 3.711330407580664, bpp: 0
2025-03-03 04:02:44 - INFO - layer21_mlp.up_proj | mse: 0.02648102800688335, bpp_loss: 3.6115758054304954, bpp: 0
2025-03-03 04:03:17 - INFO - layer21_mlp.down_proj | mse: 0.024897844637703555, bpp_loss: 3.604597178287804, bpp: 0
pseudo compress quantization...:  69%|██████▉   | 22/32 [39:14<17:47, 106.75s/it]2025-03-03 04:03:28 - INFO - layer22_self_attn.q_proj | mse: 0.02675368404416436, bpp_loss: 3.8852307819761336, bpp: 0
2025-03-03 04:03:39 - INFO - layer22_self_attn.k_proj | mse: 0.026797910296030743, bpp_loss: 3.9043155594263226, bpp: 0
2025-03-03 04:03:50 - INFO - layer22_self_attn.v_proj | mse: 0.026176315048228132, bpp_loss: 3.5687524824752472, bpp: 0
2025-03-03 04:04:02 - INFO - layer22_self_attn.o_proj | mse: 0.025270273675736622, bpp_loss: 3.553155143861659, bpp: 0
2025-03-03 04:04:16 - INFO - layer22_mlp.gate_proj | mse: 0.02659707571694093, bpp_loss: 3.720253048334704, bpp: 0
2025-03-03 04:04:30 - INFO - layer22_mlp.up_proj | mse: 0.026390996008592453, bpp_loss: 3.6116589183031125, bpp: 0
2025-03-03 04:05:05 - INFO - layer22_mlp.down_proj | mse: 0.02490897790492516, bpp_loss: 3.605231454964121, bpp: 0
pseudo compress quantization...:  72%|███████▏  | 23/32 [41:01<16:01, 106.89s/it]2025-03-03 04:05:16 - INFO - layer23_self_attn.q_proj | mse: 0.026609431603499958, bpp_loss: 3.8795955934911035, bpp: 0
2025-03-03 04:05:27 - INFO - layer23_self_attn.k_proj | mse: 0.02664504205076457, bpp_loss: 3.8910858788294718, bpp: 0
2025-03-03 04:05:38 - INFO - layer23_self_attn.v_proj | mse: 0.026162417935022116, bpp_loss: 3.627427863655612, bpp: 0
2025-03-03 04:05:48 - INFO - layer23_self_attn.o_proj | mse: 0.024682652046146843, bpp_loss: 3.6109354269574396, bpp: 0
2025-03-03 04:06:00 - INFO - layer23_mlp.gate_proj | mse: 0.02637746533758494, bpp_loss: 3.720515585309544, bpp: 0
2025-03-03 04:06:13 - INFO - layer23_mlp.up_proj | mse: 0.026183433014448376, bpp_loss: 3.617739319368157, bpp: 0
2025-03-03 04:06:49 - INFO - layer23_mlp.down_proj | mse: 0.024676876016994035, bpp_loss: 3.612693179333799, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 24/32 [42:46<14:09, 106.13s/it]2025-03-03 04:07:00 - INFO - layer24_self_attn.q_proj | mse: 0.02630518998693349, bpp_loss: 3.821473570424132, bpp: 0
2025-03-03 04:07:13 - INFO - layer24_self_attn.k_proj | mse: 0.02631491246179682, bpp_loss: 3.8288586197886616, bpp: 0
2025-03-03 04:07:27 - INFO - layer24_self_attn.v_proj | mse: 0.025960430332989632, bpp_loss: 3.616125339176506, bpp: 0
2025-03-03 04:07:38 - INFO - layer24_self_attn.o_proj | mse: 0.025181737157769342, bpp_loss: 3.600902376580052, bpp: 0
2025-03-03 04:07:50 - INFO - layer24_mlp.gate_proj | mse: 0.026218150094632242, bpp_loss: 3.7237715882270837, bpp: 0
2025-03-03 04:08:02 - INFO - layer24_mlp.up_proj | mse: 0.026037624727177973, bpp_loss: 3.6216739068717456, bpp: 0
2025-03-03 04:08:33 - INFO - layer24_mlp.down_proj | mse: 0.02452381730802219, bpp_loss: 3.617219546788134, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 25/32 [44:30<12:19, 105.64s/it]2025-03-03 04:08:47 - INFO - layer25_self_attn.q_proj | mse: 0.02617505773175296, bpp_loss: 3.845477439404931, bpp: 0
2025-03-03 04:09:00 - INFO - layer25_self_attn.k_proj | mse: 0.02617560237575603, bpp_loss: 3.8508830482605845, bpp: 0
2025-03-03 04:09:11 - INFO - layer25_self_attn.v_proj | mse: 0.025893317444823996, bpp_loss: 3.665715912473388, bpp: 0
2025-03-03 04:09:22 - INFO - layer25_self_attn.o_proj | mse: 0.025026102236849274, bpp_loss: 3.6572121552890167, bpp: 0
2025-03-03 04:09:36 - INFO - layer25_mlp.gate_proj | mse: 0.02602808469862344, bpp_loss: 3.72516609685019, bpp: 0
2025-03-03 04:09:51 - INFO - layer25_mlp.up_proj | mse: 0.025857819443234936, bpp_loss: 3.6266807018844194, bpp: 0
2025-03-03 04:10:22 - INFO - layer25_mlp.down_proj | mse: 0.024386451676530214, bpp_loss: 3.6217058787858765, bpp: 0
pseudo compress quantization...:  81%|████████▏ | 26/32 [46:19<10:39, 106.59s/it]2025-03-03 04:10:33 - INFO - layer26_self_attn.q_proj | mse: 0.025994647302778305, bpp_loss: 3.8186286435229704, bpp: 0
2025-03-03 04:10:44 - INFO - layer26_self_attn.k_proj | mse: 0.026019141797703645, bpp_loss: 3.830246208643075, bpp: 0
2025-03-03 04:10:56 - INFO - layer26_self_attn.v_proj | mse: 0.025787236437055668, bpp_loss: 3.6825303021469153, bpp: 0
2025-03-03 04:11:08 - INFO - layer26_self_attn.o_proj | mse: 0.02569202803005077, bpp_loss: 3.6751517363009043, bpp: 0
2025-03-03 04:11:23 - INFO - layer26_mlp.gate_proj | mse: 0.025974623887760905, bpp_loss: 3.7274220680254837, bpp: 0
2025-03-03 04:11:35 - INFO - layer26_mlp.up_proj | mse: 0.025791489834532395, bpp_loss: 3.6315655664129314, bpp: 0
2025-03-03 04:12:11 - INFO - layer26_mlp.down_proj | mse: 0.024357613841062324, bpp_loss: 3.6232280781449275, bpp: 0
pseudo compress quantization...:  84%|████████▍ | 27/32 [48:08<08:56, 107.35s/it]2025-03-03 04:12:22 - INFO - layer27_self_attn.q_proj | mse: 0.026066302753692955, bpp_loss: 3.8895250343484804, bpp: 0
2025-03-03 04:12:33 - INFO - layer27_self_attn.k_proj | mse: 0.026097921076296764, bpp_loss: 3.9059943900210783, bpp: 0
2025-03-03 04:12:43 - INFO - layer27_self_attn.v_proj | mse: 0.025744835322008087, bpp_loss: 3.6899698727647774, bpp: 0
2025-03-03 04:12:54 - INFO - layer27_self_attn.o_proj | mse: 0.024956613773776625, bpp_loss: 3.6904795440495946, bpp: 0
2025-03-03 04:13:06 - INFO - layer27_mlp.gate_proj | mse: 0.02591052136369042, bpp_loss: 3.726440258843954, bpp: 0
2025-03-03 04:13:21 - INFO - layer27_mlp.up_proj | mse: 0.025745846457237934, bpp_loss: 3.637913619016492, bpp: 0
2025-03-03 04:13:55 - INFO - layer27_mlp.down_proj | mse: 0.024390627729707643, bpp_loss: 3.627163317336073, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 28/32 [49:52<07:05, 106.34s/it]2025-03-03 04:14:08 - INFO - layer28_self_attn.q_proj | mse: 0.025992242757445598, bpp_loss: 3.837912965740543, bpp: 0
2025-03-03 04:14:22 - INFO - layer28_self_attn.k_proj | mse: 0.026040136665204997, bpp_loss: 3.857710594544187, bpp: 0
2025-03-03 04:14:33 - INFO - layer28_self_attn.v_proj | mse: 0.025856246888104343, bpp_loss: 3.730947543575894, bpp: 0
2025-03-03 04:14:44 - INFO - layer28_self_attn.o_proj | mse: 0.025724567612191683, bpp_loss: 3.734735485399142, bpp: 0
2025-03-03 04:14:56 - INFO - layer28_mlp.gate_proj | mse: 0.025877897699941907, bpp_loss: 3.718242771230465, bpp: 0
2025-03-03 04:15:07 - INFO - layer28_mlp.up_proj | mse: 0.025756796469673743, bpp_loss: 3.6503367888372997, bpp: 0
2025-03-03 04:15:40 - INFO - layer28_mlp.down_proj | mse: 0.024566058614116867, bpp_loss: 3.6319544270721287, bpp: 0
pseudo compress quantization...:  91%|█████████ | 29/32 [51:37<05:17, 105.97s/it]2025-03-03 04:15:53 - INFO - layer29_self_attn.q_proj | mse: 0.025977676427406022, bpp_loss: 3.790619925421197, bpp: 0
2025-03-03 04:16:04 - INFO - layer29_self_attn.k_proj | mse: 0.025976844976188566, bpp_loss: 3.806919868569821, bpp: 0
2025-03-03 04:16:16 - INFO - layer29_self_attn.v_proj | mse: 0.02593736697709364, bpp_loss: 3.736316723981872, bpp: 0
2025-03-03 04:16:29 - INFO - layer29_self_attn.o_proj | mse: 0.02540251787495034, bpp_loss: 3.7537270189495757, bpp: 0
2025-03-03 04:16:44 - INFO - layer29_mlp.gate_proj | mse: 0.025907673368725327, bpp_loss: 3.718795886913011, bpp: 0
2025-03-03 04:16:56 - INFO - layer29_mlp.up_proj | mse: 0.02580844413612626, bpp_loss: 3.6612871592474536, bpp: 0
2025-03-03 04:17:26 - INFO - layer29_mlp.down_proj | mse: 0.024794193574920232, bpp_loss: 3.632669912261325, bpp: 0
pseudo compress quantization...:  94%|█████████▍| 30/32 [53:23<03:31, 105.92s/it]2025-03-03 04:17:37 - INFO - layer30_self_attn.q_proj | mse: 0.026106638277388464, bpp_loss: 3.8102990681072697, bpp: 0
2025-03-03 04:17:48 - INFO - layer30_self_attn.k_proj | mse: 0.02613502350048468, bpp_loss: 3.8351062232395634, bpp: 0
2025-03-03 04:18:01 - INFO - layer30_self_attn.v_proj | mse: 0.026082937572127173, bpp_loss: 3.774544937594328, bpp: 0
2025-03-03 04:18:14 - INFO - layer30_self_attn.o_proj | mse: 0.025694232679446177, bpp_loss: 3.787313538021408, bpp: 0
2025-03-03 04:18:26 - INFO - layer30_mlp.gate_proj | mse: 0.026087392415122108, bpp_loss: 3.7389033248778, bpp: 0
2025-03-03 04:18:39 - INFO - layer30_mlp.up_proj | mse: 0.02595030705565546, bpp_loss: 3.6731567405337513, bpp: 0
2025-03-03 04:19:16 - INFO - layer30_mlp.down_proj | mse: 0.025516963385720806, bpp_loss: 3.6158874391816385, bpp: 0
pseudo compress quantization...:  97%|█████████▋| 31/32 [55:12<01:46, 106.92s/it]2025-03-03 04:19:26 - INFO - layer31_self_attn.q_proj | mse: 0.026642944591944235, bpp_loss: 3.831100524752401, bpp: 0
2025-03-03 04:19:37 - INFO - layer31_self_attn.k_proj | mse: 0.02671946128029055, bpp_loss: 3.87966979801422, bpp: 0
2025-03-03 04:19:48 - INFO - layer31_self_attn.v_proj | mse: 0.02632836922453227, bpp_loss: 3.639959199936129, bpp: 0
2025-03-03 04:19:58 - INFO - layer31_self_attn.o_proj | mse: 0.02836479894609937, bpp_loss: 3.6379081803024746, bpp: 0
2025-03-03 04:20:12 - INFO - layer31_mlp.gate_proj | mse: 0.02672938351634501, bpp_loss: 3.814798254519701, bpp: 0
2025-03-03 04:20:26 - INFO - layer31_mlp.up_proj | mse: 0.026574250794385718, bpp_loss: 3.7362998913713668, bpp: 0
2025-03-03 04:20:59 - INFO - layer31_mlp.down_proj | mse: 0.028681146158221475, bpp_loss: 3.6078110231129927, bpp: 0
pseudo compress quantization...: 100%|██████████| 32/32 [56:56<00:00, 105.92s/it]pseudo compress quantization...: 100%|██████████| 32/32 [56:56<00:00, 106.76s/it]
2025-03-03 04:20:59 - INFO - #### Total | mse: 0.026860357864897447, bpp_loss: 3.645083585761275, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda200_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_4.97679_bpp_5.524_MSE_0.00426_total_iter_95000.pth.tar/COL_MSE0.02686_bpploss3.6451_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda200_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_4.97679_bpp_5.524_MSE_0.00426_total_iter_95000.pth.tar/COL_MSE0.02686_bpploss3.6451_bpp0
I0303 04:21:25.142637 2964374 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.13it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]
I0303 04:21:27.788827 2964374 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.390625:   0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.390625:   1%|          | 1/166 [00:00<01:38,  1.68it/s]avg_loss = 1.65234375:   1%|          | 1/166 [00:01<01:38,  1.68it/s]avg_loss = 1.65234375:   1%|          | 2/166 [00:01<01:27,  1.86it/s]avg_loss = 1.8151041666666667:   1%|          | 2/166 [00:01<01:27,  1.86it/s]avg_loss = 1.8151041666666667:   2%|▏         | 3/166 [00:01<01:24,  1.94it/s]avg_loss = 1.84765625:   2%|▏         | 3/166 [00:02<01:24,  1.94it/s]        avg_loss = 1.84765625:   2%|▏         | 4/166 [00:02<01:22,  1.97it/s]avg_loss = 1.7796875:   2%|▏         | 4/166 [00:02<01:22,  1.97it/s] avg_loss = 1.7796875:   3%|▎         | 5/166 [00:02<01:21,  1.99it/s]avg_loss = 1.7565104166666667:   3%|▎         | 5/166 [00:03<01:21,  1.99it/s]avg_loss = 1.7565104166666667:   4%|▎         | 6/166 [00:03<01:20,  1.99it/s]avg_loss = 1.6964285714285714:   4%|▎         | 6/166 [00:03<01:20,  1.99it/s]avg_loss = 1.6964285714285714:   4%|▍         | 7/166 [00:03<01:19,  2.01it/s]avg_loss = 1.6396484375:   4%|▍         | 7/166 [00:04<01:19,  2.01it/s]      avg_loss = 1.6396484375:   5%|▍         | 8/166 [00:04<01:18,  2.00it/s]avg_loss = 1.6345486111111112:   5%|▍         | 8/166 [00:04<01:18,  2.00it/s]avg_loss = 1.6345486111111112:   5%|▌         | 9/166 [00:04<01:18,  2.01it/s]avg_loss = 1.64140625:   5%|▌         | 9/166 [00:05<01:18,  2.01it/s]        avg_loss = 1.64140625:   6%|▌         | 10/166 [00:05<01:17,  2.00it/s]avg_loss = 1.6576704545454546:   6%|▌         | 10/166 [00:05<01:17,  2.00it/s]avg_loss = 1.6576704545454546:   7%|▋         | 11/166 [00:05<01:17,  2.00it/s]avg_loss = 1.6673177083333333:   7%|▋         | 11/166 [00:06<01:17,  2.00it/s]avg_loss = 1.6673177083333333:   7%|▋         | 12/166 [00:06<01:17,  2.00it/s]avg_loss = 1.6628605769230769:   7%|▋         | 12/166 [00:06<01:17,  2.00it/s]avg_loss = 1.6628605769230769:   8%|▊         | 13/166 [00:06<01:16,  1.99it/s]avg_loss = 1.6752232142857142:   8%|▊         | 13/166 [00:07<01:16,  1.99it/s]avg_loss = 1.6752232142857142:   8%|▊         | 14/166 [00:07<01:16,  1.99it/s]avg_loss = 1.6932291666666666:   8%|▊         | 14/166 [00:07<01:16,  1.99it/s]avg_loss = 1.6932291666666666:   9%|▉         | 15/166 [00:07<01:15,  1.99it/s]avg_loss = 1.71240234375:   9%|▉         | 15/166 [00:08<01:15,  1.99it/s]     avg_loss = 1.71240234375:  10%|▉         | 16/166 [00:08<01:15,  1.99it/s]avg_loss = 1.7256433823529411:  10%|▉         | 16/166 [00:08<01:15,  1.99it/s]avg_loss = 1.7256433823529411:  10%|█         | 17/166 [00:08<01:09,  2.14it/s]avg_loss = 1.7404513888888888:  10%|█         | 17/166 [00:08<01:09,  2.14it/s]avg_loss = 1.7404513888888888:  11%|█         | 18/166 [00:08<01:10,  2.10it/s]avg_loss = 1.7606907894736843:  11%|█         | 18/166 [00:09<01:10,  2.10it/s]avg_loss = 1.7606907894736843:  11%|█▏        | 19/166 [00:09<01:10,  2.09it/s]avg_loss = 1.7671875:  11%|█▏        | 19/166 [00:09<01:10,  2.09it/s]         avg_loss = 1.7671875:  12%|█▏        | 20/166 [00:09<01:10,  2.07it/s]avg_loss = 1.7682291666666667:  12%|█▏        | 20/166 [00:10<01:10,  2.07it/s]avg_loss = 1.7682291666666667:  13%|█▎        | 21/166 [00:10<01:10,  2.05it/s]avg_loss = 1.7581676136363635:  13%|█▎        | 21/166 [00:10<01:10,  2.05it/s]avg_loss = 1.7581676136363635:  13%|█▎        | 22/166 [00:10<01:10,  2.03it/s]avg_loss = 1.7469429347826086:  13%|█▎        | 22/166 [00:11<01:10,  2.03it/s]avg_loss = 1.7469429347826086:  14%|█▍        | 23/166 [00:11<01:10,  2.02it/s]avg_loss = 1.75390625:  14%|█▍        | 23/166 [00:11<01:10,  2.02it/s]        avg_loss = 1.75390625:  14%|█▍        | 24/166 [00:11<01:10,  2.01it/s]avg_loss = 1.7609375:  14%|█▍        | 24/166 [00:12<01:10,  2.01it/s] avg_loss = 1.7609375:  15%|█▌        | 25/166 [00:12<01:10,  2.01it/s]avg_loss = 1.7653245192307692:  15%|█▌        | 25/166 [00:12<01:10,  2.01it/s]avg_loss = 1.7653245192307692:  16%|█▌        | 26/166 [00:12<01:10,  2.00it/s]avg_loss = 1.771412037037037:  16%|█▌        | 26/166 [00:13<01:10,  2.00it/s] avg_loss = 1.771412037037037:  16%|█▋        | 27/166 [00:13<01:09,  1.99it/s]avg_loss = 1.7739955357142858:  16%|█▋        | 27/166 [00:13<01:09,  1.99it/s]avg_loss = 1.7739955357142858:  17%|█▋        | 28/166 [00:13<01:09,  1.98it/s]avg_loss = 1.7834051724137931:  17%|█▋        | 28/166 [00:14<01:09,  1.98it/s]avg_loss = 1.7834051724137931:  17%|█▋        | 29/166 [00:14<01:09,  1.97it/s]avg_loss = 1.7833333333333334:  17%|█▋        | 29/166 [00:14<01:09,  1.97it/s]avg_loss = 1.7833333333333334:  18%|█▊        | 30/166 [00:14<01:09,  1.96it/s]avg_loss = 1.7973790322580645:  18%|█▊        | 30/166 [00:15<01:09,  1.96it/s]avg_loss = 1.7973790322580645:  19%|█▊        | 31/166 [00:15<01:08,  1.96it/s]avg_loss = 1.8037109375:  19%|█▊        | 31/166 [00:16<01:08,  1.96it/s]      avg_loss = 1.8037109375:  19%|█▉        | 32/166 [00:16<01:08,  1.94it/s]avg_loss = 1.808475378787879:  19%|█▉        | 32/166 [00:16<01:08,  1.94it/s]avg_loss = 1.808475378787879:  20%|█▉        | 33/166 [00:16<01:08,  1.94it/s]avg_loss = 1.8076746323529411:  20%|█▉        | 33/166 [00:17<01:08,  1.94it/s]avg_loss = 1.8076746323529411:  20%|██        | 34/166 [00:17<01:08,  1.93it/s]avg_loss = 1.8011160714285714:  20%|██        | 34/166 [00:17<01:08,  1.93it/s]avg_loss = 1.8011160714285714:  21%|██        | 35/166 [00:17<01:08,  1.92it/s]avg_loss = 1.7931857638888888:  21%|██        | 35/166 [00:18<01:08,  1.92it/s]avg_loss = 1.7931857638888888:  22%|██▏       | 36/166 [00:18<01:08,  1.91it/s]avg_loss = 1.7833614864864864:  22%|██▏       | 36/166 [00:18<01:08,  1.91it/s]avg_loss = 1.7833614864864864:  22%|██▏       | 37/166 [00:18<01:07,  1.90it/s]avg_loss = 1.7806332236842106:  22%|██▏       | 37/166 [00:19<01:07,  1.90it/s]avg_loss = 1.7806332236842106:  23%|██▎       | 38/166 [00:19<01:07,  1.89it/s]avg_loss = 1.7784455128205128:  23%|██▎       | 38/166 [00:19<01:07,  1.89it/s]avg_loss = 1.7784455128205128:  23%|██▎       | 39/166 [00:19<01:07,  1.89it/s]avg_loss = 1.7818359375:  23%|██▎       | 39/166 [00:20<01:07,  1.89it/s]      avg_loss = 1.7818359375:  24%|██▍       | 40/166 [00:20<01:06,  1.89it/s]avg_loss = 1.7818216463414633:  24%|██▍       | 40/166 [00:20<01:06,  1.89it/s]avg_loss = 1.7818216463414633:  25%|██▍       | 41/166 [00:20<01:06,  1.87it/s]avg_loss = 1.7693452380952381:  25%|██▍       | 41/166 [00:21<01:06,  1.87it/s]avg_loss = 1.7693452380952381:  25%|██▌       | 42/166 [00:21<01:06,  1.87it/s]avg_loss = 1.7538154069767442:  25%|██▌       | 42/166 [00:21<01:06,  1.87it/s]avg_loss = 1.7538154069767442:  26%|██▌       | 43/166 [00:21<01:06,  1.85it/s]avg_loss = 1.7436079545454546:  26%|██▌       | 43/166 [00:22<01:06,  1.85it/s]avg_loss = 1.7436079545454546:  27%|██▋       | 44/166 [00:22<01:05,  1.85it/s]avg_loss = 1.729861111111111:  27%|██▋       | 44/166 [00:22<01:05,  1.85it/s] avg_loss = 1.729861111111111:  27%|██▋       | 45/166 [00:22<01:05,  1.84it/s]avg_loss = 1.719429347826087:  27%|██▋       | 45/166 [00:23<01:05,  1.84it/s]avg_loss = 1.719429347826087:  28%|██▊       | 46/166 [00:23<01:05,  1.83it/s]avg_loss = 1.7122672872340425:  28%|██▊       | 46/166 [00:24<01:05,  1.83it/s]avg_loss = 1.7122672872340425:  28%|██▊       | 47/166 [00:24<01:04,  1.83it/s]avg_loss = 1.71337890625:  28%|██▊       | 47/166 [00:24<01:04,  1.83it/s]     avg_loss = 1.71337890625:  29%|██▉       | 48/166 [00:24<01:04,  1.82it/s]avg_loss = 1.7243303571428572:  29%|██▉       | 48/166 [00:25<01:04,  1.82it/s]avg_loss = 1.7243303571428572:  30%|██▉       | 49/166 [00:25<01:04,  1.82it/s]avg_loss = 1.73484375:  30%|██▉       | 49/166 [00:25<01:04,  1.82it/s]        avg_loss = 1.73484375:  30%|███       | 50/166 [00:25<01:04,  1.81it/s]avg_loss = 1.7418811274509804:  30%|███       | 50/166 [00:26<01:04,  1.81it/s]avg_loss = 1.7418811274509804:  31%|███       | 51/166 [00:26<01:03,  1.80it/s]avg_loss = 1.7468449519230769:  31%|███       | 51/166 [00:26<01:03,  1.80it/s]avg_loss = 1.7468449519230769:  31%|███▏      | 52/166 [00:26<01:03,  1.79it/s]avg_loss = 1.7502948113207548:  31%|███▏      | 52/166 [00:27<01:03,  1.79it/s]avg_loss = 1.7502948113207548:  32%|███▏      | 53/166 [00:27<01:02,  1.80it/s]avg_loss = 1.7510127314814814:  32%|███▏      | 53/166 [00:28<01:02,  1.80it/s]avg_loss = 1.7510127314814814:  33%|███▎      | 54/166 [00:28<01:02,  1.78it/s]avg_loss = 1.7535511363636365:  33%|███▎      | 54/166 [00:28<01:02,  1.78it/s]avg_loss = 1.7535511363636365:  33%|███▎      | 55/166 [00:28<01:02,  1.78it/s]avg_loss = 1.7571149553571428:  33%|███▎      | 55/166 [00:29<01:02,  1.78it/s]avg_loss = 1.7571149553571428:  34%|███▎      | 56/166 [00:29<01:02,  1.76it/s]avg_loss = 1.7519188596491229:  34%|███▎      | 56/166 [00:29<01:02,  1.76it/s]avg_loss = 1.7519188596491229:  34%|███▍      | 57/166 [00:29<01:01,  1.78it/s]avg_loss = 1.7556573275862069:  34%|███▍      | 57/166 [00:30<01:01,  1.78it/s]avg_loss = 1.7556573275862069:  35%|███▍      | 58/166 [00:30<01:01,  1.76it/s]avg_loss = 1.7539724576271187:  35%|███▍      | 58/166 [00:30<01:01,  1.76it/s]avg_loss = 1.7539724576271187:  36%|███▌      | 59/166 [00:30<01:01,  1.74it/s]avg_loss = 1.74921875:  36%|███▌      | 59/166 [00:31<01:01,  1.74it/s]        avg_loss = 1.74921875:  36%|███▌      | 60/166 [00:31<01:00,  1.74it/s]avg_loss = 1.744748975409836:  36%|███▌      | 60/166 [00:32<01:00,  1.74it/s]avg_loss = 1.744748975409836:  37%|███▋      | 61/166 [00:32<01:00,  1.73it/s]avg_loss = 1.7408014112903225:  37%|███▋      | 61/166 [00:32<01:00,  1.73it/s]avg_loss = 1.7408014112903225:  37%|███▋      | 62/166 [00:32<01:00,  1.72it/s]avg_loss = 1.7349950396825398:  37%|███▋      | 62/166 [00:33<01:00,  1.72it/s]avg_loss = 1.7349950396825398:  38%|███▊      | 63/166 [00:33<00:59,  1.72it/s]avg_loss = 1.730712890625:  38%|███▊      | 63/166 [00:33<00:59,  1.72it/s]    avg_loss = 1.730712890625:  39%|███▊      | 64/166 [00:33<00:59,  1.71it/s]avg_loss = 1.7241586538461537:  39%|███▊      | 64/166 [00:34<00:59,  1.71it/s]avg_loss = 1.7241586538461537:  39%|███▉      | 65/166 [00:34<00:59,  1.71it/s]avg_loss = 1.7169744318181819:  39%|███▉      | 65/166 [00:34<00:59,  1.71it/s]avg_loss = 1.7169744318181819:  40%|███▉      | 66/166 [00:34<00:58,  1.70it/s]avg_loss = 1.711287313432836:  40%|███▉      | 66/166 [00:35<00:58,  1.70it/s] avg_loss = 1.711287313432836:  40%|████      | 67/166 [00:35<00:58,  1.70it/s]avg_loss = 1.7100183823529411:  40%|████      | 67/166 [00:36<00:58,  1.70it/s]avg_loss = 1.7100183823529411:  41%|████      | 68/166 [00:36<00:58,  1.69it/s]avg_loss = 1.7119565217391304:  41%|████      | 68/166 [00:36<00:58,  1.69it/s]avg_loss = 1.7119565217391304:  42%|████▏     | 69/166 [00:36<00:57,  1.68it/s]avg_loss = 1.714955357142857:  42%|████▏     | 69/166 [00:37<00:57,  1.68it/s] avg_loss = 1.714955357142857:  42%|████▏     | 70/166 [00:37<00:57,  1.67it/s]avg_loss = 1.7188600352112675:  42%|████▏     | 70/166 [00:37<00:57,  1.67it/s]avg_loss = 1.7188600352112675:  43%|████▎     | 71/166 [00:37<00:56,  1.68it/s]avg_loss = 1.7238498263888888:  43%|████▎     | 71/166 [00:38<00:56,  1.68it/s]avg_loss = 1.7238498263888888:  43%|████▎     | 72/166 [00:38<00:56,  1.66it/s]avg_loss = 1.7299871575342465:  43%|████▎     | 72/166 [00:39<00:56,  1.66it/s]avg_loss = 1.7299871575342465:  44%|████▍     | 73/166 [00:39<00:56,  1.66it/s]avg_loss = 1.7243454391891893:  44%|████▍     | 73/166 [00:39<00:56,  1.66it/s]avg_loss = 1.7243454391891893:  45%|████▍     | 74/166 [00:39<00:55,  1.65it/s]avg_loss = 1.7197916666666666:  45%|████▍     | 74/166 [00:40<00:55,  1.65it/s]avg_loss = 1.7197916666666666:  45%|████▌     | 75/166 [00:40<00:55,  1.64it/s]avg_loss = 1.718955592105263:  45%|████▌     | 75/166 [00:41<00:55,  1.64it/s] avg_loss = 1.718955592105263:  46%|████▌     | 76/166 [00:41<00:55,  1.64it/s]avg_loss = 1.7154017857142858:  46%|████▌     | 76/166 [00:41<00:55,  1.64it/s]avg_loss = 1.7154017857142858:  46%|████▋     | 77/166 [00:41<00:54,  1.63it/s]avg_loss = 1.7118389423076923:  46%|████▋     | 77/166 [00:42<00:54,  1.63it/s]avg_loss = 1.7118389423076923:  47%|████▋     | 78/166 [00:42<00:50,  1.76it/s]avg_loss = 1.709256329113924:  47%|████▋     | 78/166 [00:42<00:50,  1.76it/s] avg_loss = 1.709256329113924:  48%|████▊     | 79/166 [00:42<00:46,  1.89it/s]avg_loss = 1.70576171875:  48%|████▊     | 79/166 [00:43<00:46,  1.89it/s]    avg_loss = 1.70576171875:  48%|████▊     | 80/166 [00:43<00:44,  1.92it/s]avg_loss = 1.6966628086419753:  48%|████▊     | 80/166 [00:43<00:44,  1.92it/s]avg_loss = 1.6966628086419753:  49%|████▉     | 81/166 [00:43<00:43,  1.94it/s]avg_loss = 1.6983612804878048:  49%|████▉     | 81/166 [00:44<00:43,  1.94it/s]avg_loss = 1.6983612804878048:  49%|████▉     | 82/166 [00:44<00:42,  1.96it/s]avg_loss = 1.7003012048192772:  49%|████▉     | 82/166 [00:44<00:42,  1.96it/s]avg_loss = 1.7003012048192772:  50%|█████     | 83/166 [00:44<00:42,  1.97it/s]avg_loss = 1.7034970238095237:  50%|█████     | 83/166 [00:45<00:42,  1.97it/s]avg_loss = 1.7034970238095237:  51%|█████     | 84/166 [00:45<00:41,  1.97it/s]avg_loss = 1.7053308823529412:  51%|█████     | 84/166 [00:45<00:41,  1.97it/s]avg_loss = 1.7053308823529412:  51%|█████     | 85/166 [00:45<00:41,  1.97it/s]avg_loss = 1.704124273255814:  51%|█████     | 85/166 [00:46<00:41,  1.97it/s] avg_loss = 1.704124273255814:  52%|█████▏    | 86/166 [00:46<00:40,  1.97it/s]avg_loss = 1.704382183908046:  52%|█████▏    | 86/166 [00:46<00:40,  1.97it/s]avg_loss = 1.704382183908046:  52%|█████▏    | 87/166 [00:46<00:40,  1.96it/s]avg_loss = 1.7046342329545454:  52%|█████▏    | 87/166 [00:47<00:40,  1.96it/s]avg_loss = 1.7046342329545454:  53%|█████▎    | 88/166 [00:47<00:39,  1.96it/s]avg_loss = 1.7056706460674158:  53%|█████▎    | 88/166 [00:47<00:39,  1.96it/s]avg_loss = 1.7056706460674158:  54%|█████▎    | 89/166 [00:47<00:39,  1.95it/s]avg_loss = 1.70546875:  54%|█████▎    | 89/166 [00:48<00:39,  1.95it/s]        avg_loss = 1.70546875:  54%|█████▍    | 90/166 [00:48<00:39,  1.94it/s]avg_loss = 1.7058722527472527:  54%|█████▍    | 90/166 [00:48<00:39,  1.94it/s]avg_loss = 1.7058722527472527:  55%|█████▍    | 91/166 [00:48<00:38,  1.93it/s]avg_loss = 1.706946331521739:  55%|█████▍    | 91/166 [00:49<00:38,  1.93it/s] avg_loss = 1.706946331521739:  55%|█████▌    | 92/166 [00:49<00:38,  1.92it/s]avg_loss = 1.7109375:  55%|█████▌    | 92/166 [00:49<00:38,  1.92it/s]        avg_loss = 1.7109375:  56%|█████▌    | 93/166 [00:49<00:38,  1.92it/s]avg_loss = 1.7100232712765957:  56%|█████▌    | 93/166 [00:50<00:38,  1.92it/s]avg_loss = 1.7100232712765957:  57%|█████▋    | 94/166 [00:50<00:37,  1.91it/s]avg_loss = 1.7092105263157895:  57%|█████▋    | 94/166 [00:50<00:37,  1.91it/s]avg_loss = 1.7092105263157895:  57%|█████▋    | 95/166 [00:50<00:37,  1.90it/s]avg_loss = 1.7089029947916667:  57%|█████▋    | 95/166 [00:51<00:37,  1.90it/s]avg_loss = 1.7089029947916667:  58%|█████▊    | 96/166 [00:51<00:36,  1.90it/s]avg_loss = 1.7088434278350515:  58%|█████▊    | 96/166 [00:51<00:36,  1.90it/s]avg_loss = 1.7088434278350515:  58%|█████▊    | 97/166 [00:51<00:36,  1.89it/s]avg_loss = 1.7072704081632653:  58%|█████▊    | 97/166 [00:52<00:36,  1.89it/s]avg_loss = 1.7072704081632653:  59%|█████▉    | 98/166 [00:52<00:36,  1.88it/s]avg_loss = 1.7049400252525253:  59%|█████▉    | 98/166 [00:52<00:36,  1.88it/s]avg_loss = 1.7049400252525253:  60%|█████▉    | 99/166 [00:52<00:35,  1.88it/s]avg_loss = 1.702265625:  60%|█████▉    | 99/166 [00:53<00:35,  1.88it/s]       avg_loss = 1.702265625:  60%|██████    | 100/166 [00:53<00:35,  1.86it/s]avg_loss = 1.702660891089109:  60%|██████    | 100/166 [00:54<00:35,  1.86it/s]avg_loss = 1.702660891089109:  61%|██████    | 101/166 [00:54<00:34,  1.86it/s]avg_loss = 1.7035845588235294:  61%|██████    | 101/166 [00:54<00:34,  1.86it/s]avg_loss = 1.7035845588235294:  61%|██████▏   | 102/166 [00:54<00:34,  1.86it/s]avg_loss = 1.7046419902912622:  61%|██████▏   | 102/166 [00:55<00:34,  1.86it/s]avg_loss = 1.7046419902912622:  62%|██████▏   | 103/166 [00:55<00:34,  1.84it/s]avg_loss = 1.7068810096153846:  62%|██████▏   | 103/166 [00:55<00:34,  1.84it/s]avg_loss = 1.7068810096153846:  63%|██████▎   | 104/166 [00:55<00:33,  1.84it/s]avg_loss = 1.7133928571428572:  63%|██████▎   | 104/166 [00:56<00:33,  1.84it/s]avg_loss = 1.7133928571428572:  63%|██████▎   | 105/166 [00:56<00:33,  1.83it/s]avg_loss = 1.7186025943396226:  63%|██████▎   | 105/166 [00:56<00:33,  1.83it/s]avg_loss = 1.7186025943396226:  64%|██████▍   | 106/166 [00:56<00:32,  1.83it/s]avg_loss = 1.7222546728971964:  64%|██████▍   | 106/166 [00:57<00:32,  1.83it/s]avg_loss = 1.7222546728971964:  64%|██████▍   | 107/166 [00:57<00:32,  1.82it/s]avg_loss = 1.7254050925925926:  64%|██████▍   | 107/166 [00:57<00:32,  1.82it/s]avg_loss = 1.7254050925925926:  65%|██████▌   | 108/166 [00:57<00:31,  1.82it/s]avg_loss = 1.7300745412844036:  65%|██████▌   | 108/166 [00:58<00:31,  1.82it/s]avg_loss = 1.7300745412844036:  66%|██████▌   | 109/166 [00:58<00:31,  1.81it/s]avg_loss = 1.7333806818181818:  66%|██████▌   | 109/166 [00:58<00:31,  1.81it/s]avg_loss = 1.7333806818181818:  66%|██████▋   | 110/166 [00:58<00:31,  1.79it/s]avg_loss = 1.7348676801801801:  66%|██████▋   | 110/166 [00:59<00:31,  1.79it/s]avg_loss = 1.7348676801801801:  67%|██████▋   | 111/166 [00:59<00:30,  1.80it/s]avg_loss = 1.7361886160714286:  67%|██████▋   | 111/166 [01:00<00:30,  1.80it/s]avg_loss = 1.7361886160714286:  67%|██████▋   | 112/166 [01:00<00:30,  1.78it/s]avg_loss = 1.736587389380531:  67%|██████▋   | 112/166 [01:00<00:30,  1.78it/s] avg_loss = 1.736587389380531:  68%|██████▊   | 113/166 [01:00<00:29,  1.77it/s]avg_loss = 1.7380071271929824:  68%|██████▊   | 113/166 [01:01<00:29,  1.77it/s]avg_loss = 1.7380071271929824:  69%|██████▊   | 114/166 [01:01<00:29,  1.77it/s]avg_loss = 1.7349864130434782:  69%|██████▊   | 114/166 [01:01<00:29,  1.77it/s]avg_loss = 1.7349864130434782:  69%|██████▉   | 115/166 [01:01<00:28,  1.76it/s]avg_loss = 1.734375:  69%|██████▉   | 115/166 [01:02<00:28,  1.76it/s]          avg_loss = 1.734375:  70%|██████▉   | 116/166 [01:02<00:28,  1.75it/s]avg_loss = 1.7353766025641026:  70%|██████▉   | 116/166 [01:02<00:28,  1.75it/s]avg_loss = 1.7353766025641026:  70%|███████   | 117/166 [01:02<00:28,  1.74it/s]avg_loss = 1.7355667372881356:  70%|███████   | 117/166 [01:03<00:28,  1.74it/s]avg_loss = 1.7355667372881356:  71%|███████   | 118/166 [01:03<00:27,  1.74it/s]avg_loss = 1.735031512605042:  71%|███████   | 118/166 [01:04<00:27,  1.74it/s] avg_loss = 1.735031512605042:  72%|███████▏  | 119/166 [01:04<00:27,  1.73it/s]avg_loss = 1.7356770833333333:  72%|███████▏  | 119/166 [01:04<00:27,  1.73it/s]avg_loss = 1.7356770833333333:  72%|███████▏  | 120/166 [01:04<00:26,  1.72it/s]avg_loss = 1.7350852272727273:  72%|███████▏  | 120/166 [01:05<00:26,  1.72it/s]avg_loss = 1.7350852272727273:  73%|███████▎  | 121/166 [01:05<00:26,  1.72it/s]avg_loss = 1.7355917008196722:  73%|███████▎  | 121/166 [01:05<00:26,  1.72it/s]avg_loss = 1.7355917008196722:  73%|███████▎  | 122/166 [01:05<00:25,  1.71it/s]avg_loss = 1.7358993902439024:  73%|███████▎  | 122/166 [01:06<00:25,  1.71it/s]avg_loss = 1.7358993902439024:  74%|███████▍  | 123/166 [01:06<00:25,  1.71it/s]avg_loss = 1.7345010080645162:  74%|███████▍  | 123/166 [01:07<00:25,  1.71it/s]avg_loss = 1.7345010080645162:  75%|███████▍  | 124/166 [01:07<00:24,  1.70it/s]avg_loss = 1.7328125:  75%|███████▍  | 124/166 [01:07<00:24,  1.70it/s]         avg_loss = 1.7328125:  75%|███████▌  | 125/166 [01:07<00:24,  1.69it/s]avg_loss = 1.730592757936508:  75%|███████▌  | 125/166 [01:08<00:24,  1.69it/s]avg_loss = 1.730592757936508:  76%|███████▌  | 126/166 [01:08<00:23,  1.69it/s]avg_loss = 1.7284694881889764:  76%|███████▌  | 126/166 [01:08<00:23,  1.69it/s]avg_loss = 1.7284694881889764:  77%|███████▋  | 127/166 [01:08<00:23,  1.69it/s]avg_loss = 1.72705078125:  77%|███████▋  | 127/166 [01:09<00:23,  1.69it/s]     avg_loss = 1.72705078125:  77%|███████▋  | 128/166 [01:09<00:22,  1.69it/s]avg_loss = 1.7257146317829457:  77%|███████▋  | 128/166 [01:10<00:22,  1.69it/s]avg_loss = 1.7257146317829457:  78%|███████▊  | 129/166 [01:10<00:22,  1.68it/s]avg_loss = 1.7256009615384615:  78%|███████▊  | 129/166 [01:10<00:22,  1.68it/s]avg_loss = 1.7256009615384615:  78%|███████▊  | 130/166 [01:10<00:21,  1.66it/s]avg_loss = 1.7266817748091603:  78%|███████▊  | 130/166 [01:11<00:21,  1.66it/s]avg_loss = 1.7266817748091603:  79%|███████▉  | 131/166 [01:11<00:21,  1.66it/s]avg_loss = 1.7272727272727273:  79%|███████▉  | 131/166 [01:11<00:21,  1.66it/s]avg_loss = 1.7272727272727273:  80%|███████▉  | 132/166 [01:11<00:20,  1.66it/s]avg_loss = 1.7282072368421053:  80%|███████▉  | 132/166 [01:12<00:20,  1.66it/s]avg_loss = 1.7282072368421053:  80%|████████  | 133/166 [01:12<00:20,  1.64it/s]avg_loss = 1.7295359141791045:  80%|████████  | 133/166 [01:13<00:20,  1.64it/s]avg_loss = 1.7295359141791045:  81%|████████  | 134/166 [01:13<00:19,  1.64it/s]avg_loss = 1.727488425925926:  81%|████████  | 134/166 [01:13<00:19,  1.64it/s] avg_loss = 1.727488425925926:  81%|████████▏ | 135/166 [01:13<00:18,  1.63it/s]avg_loss = 1.7277113970588236:  81%|████████▏ | 135/166 [01:14<00:18,  1.63it/s]avg_loss = 1.7277113970588236:  82%|████████▏ | 136/166 [01:14<00:18,  1.63it/s]avg_loss = 1.7279881386861313:  82%|████████▏ | 136/166 [01:14<00:18,  1.63it/s]avg_loss = 1.7279881386861313:  83%|████████▎ | 137/166 [01:14<00:17,  1.62it/s]avg_loss = 1.7288269927536233:  83%|████████▎ | 137/166 [01:15<00:17,  1.62it/s]avg_loss = 1.7288269927536233:  83%|████████▎ | 138/166 [01:15<00:17,  1.61it/s]avg_loss = 1.7279676258992807:  83%|████████▎ | 138/166 [01:16<00:17,  1.61it/s]avg_loss = 1.7279676258992807:  84%|████████▎ | 139/166 [01:16<00:15,  1.76it/s]avg_loss = 1.7266183035714286:  84%|████████▎ | 139/166 [01:16<00:15,  1.76it/s]avg_loss = 1.7266183035714286:  84%|████████▍ | 140/166 [01:16<00:13,  1.94it/s]avg_loss = 1.7252327127659575:  84%|████████▍ | 140/166 [01:16<00:13,  1.94it/s]avg_loss = 1.7252327127659575:  85%|████████▍ | 141/166 [01:16<00:11,  2.09it/s]avg_loss = 1.7248019366197183:  85%|████████▍ | 141/166 [01:17<00:11,  2.09it/s]avg_loss = 1.7248019366197183:  86%|████████▌ | 142/166 [01:17<00:12,  1.99it/s]avg_loss = 1.7232298951048952:  86%|████████▌ | 142/166 [01:17<00:12,  1.99it/s]avg_loss = 1.7232298951048952:  86%|████████▌ | 143/166 [01:17<00:11,  2.03it/s]avg_loss = 1.7244466145833333:  86%|████████▌ | 143/166 [01:18<00:11,  2.03it/s]avg_loss = 1.7244466145833333:  87%|████████▋ | 144/166 [01:18<00:10,  2.06it/s]avg_loss = 1.7236530172413793:  87%|████████▋ | 144/166 [01:18<00:10,  2.06it/s]avg_loss = 1.7236530172413793:  87%|████████▋ | 145/166 [01:18<00:10,  2.09it/s]avg_loss = 1.7235659246575343:  87%|████████▋ | 145/166 [01:19<00:10,  2.09it/s]avg_loss = 1.7235659246575343:  88%|████████▊ | 146/166 [01:19<00:09,  2.10it/s]avg_loss = 1.7224170918367347:  88%|████████▊ | 146/166 [01:19<00:09,  2.10it/s]avg_loss = 1.7224170918367347:  89%|████████▊ | 147/166 [01:19<00:09,  2.11it/s]avg_loss = 1.7215477195945945:  89%|████████▊ | 147/166 [01:20<00:09,  2.11it/s]avg_loss = 1.7215477195945945:  89%|████████▉ | 148/166 [01:20<00:08,  2.11it/s]avg_loss = 1.7198510906040267:  89%|████████▉ | 148/166 [01:20<00:08,  2.11it/s]avg_loss = 1.7198510906040267:  90%|████████▉ | 149/166 [01:20<00:08,  2.11it/s]avg_loss = 1.72078125:  90%|████████▉ | 149/166 [01:21<00:08,  2.11it/s]        avg_loss = 1.72078125:  90%|█████████ | 150/166 [01:21<00:07,  2.12it/s]avg_loss = 1.7198882450331126:  90%|█████████ | 150/166 [01:21<00:07,  2.12it/s]avg_loss = 1.7198882450331126:  91%|█████████ | 151/166 [01:21<00:07,  2.11it/s]avg_loss = 1.7196751644736843:  91%|█████████ | 151/166 [01:22<00:07,  2.11it/s]avg_loss = 1.7196751644736843:  92%|█████████▏| 152/166 [01:22<00:06,  2.11it/s]avg_loss = 1.7194648692810457:  92%|█████████▏| 152/166 [01:22<00:06,  2.11it/s]avg_loss = 1.7194648692810457:  92%|█████████▏| 153/166 [01:22<00:06,  2.11it/s]avg_loss = 1.721083603896104:  92%|█████████▏| 153/166 [01:23<00:06,  2.11it/s] avg_loss = 1.721083603896104:  93%|█████████▎| 154/166 [01:23<00:05,  2.11it/s]avg_loss = 1.7205141129032258:  93%|█████████▎| 154/166 [01:23<00:05,  2.11it/s]avg_loss = 1.7205141129032258:  93%|█████████▎| 155/166 [01:23<00:05,  2.11it/s]avg_loss = 1.720352564102564:  93%|█████████▎| 155/166 [01:24<00:05,  2.11it/s] avg_loss = 1.720352564102564:  94%|█████████▍| 156/166 [01:24<00:04,  2.10it/s]avg_loss = 1.7185509554140128:  94%|█████████▍| 156/166 [01:24<00:04,  2.10it/s]avg_loss = 1.7185509554140128:  95%|█████████▍| 157/166 [01:24<00:04,  2.10it/s]avg_loss = 1.7142503955696202:  95%|█████████▍| 157/166 [01:24<00:04,  2.10it/s]avg_loss = 1.7142503955696202:  95%|█████████▌| 158/166 [01:24<00:03,  2.09it/s]avg_loss = 1.7150157232704402:  95%|█████████▌| 158/166 [01:25<00:03,  2.09it/s]avg_loss = 1.7150157232704402:  96%|█████████▌| 159/166 [01:25<00:03,  2.10it/s]avg_loss = 1.71640625:  96%|█████████▌| 159/166 [01:25<00:03,  2.10it/s]        avg_loss = 1.71640625:  96%|█████████▋| 160/166 [01:25<00:02,  2.09it/s]avg_loss = 1.71875:  96%|█████████▋| 160/166 [01:26<00:02,  2.09it/s]   avg_loss = 1.71875:  97%|█████████▋| 161/166 [01:26<00:02,  2.09it/s]avg_loss = 1.7189911265432098:  97%|█████████▋| 161/166 [01:26<00:02,  2.09it/s]avg_loss = 1.7189911265432098:  98%|█████████▊| 162/166 [01:26<00:01,  2.08it/s]avg_loss = 1.7186062116564418:  98%|█████████▊| 162/166 [01:27<00:01,  2.08it/s]avg_loss = 1.7186062116564418:  98%|█████████▊| 163/166 [01:27<00:01,  2.08it/s]avg_loss = 1.7192740091463414:  98%|█████████▊| 163/166 [01:27<00:01,  2.08it/s]avg_loss = 1.7192740091463414:  99%|█████████▉| 164/166 [01:27<00:00,  2.07it/s]avg_loss = 1.7194128787878789:  99%|█████████▉| 164/166 [01:28<00:00,  2.07it/s]avg_loss = 1.7194128787878789:  99%|█████████▉| 165/166 [01:28<00:00,  2.08it/s]avg_loss = 1.7213855421686748:  99%|█████████▉| 165/166 [01:28<00:00,  2.08it/s]avg_loss = 1.7213855421686748: 100%|██████████| 166/166 [01:28<00:00,  2.06it/s]avg_loss = 1.7213855421686748: 100%|██████████| 166/166 [01:28<00:00,  1.87it/s]
I0303 04:23:34.897206 2964374 eval_ppl.py:105] wikitext2 perplexity: 5.59227180480957
wikitext2 perplexity: 5.592
Running with lmbda=300
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.43it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.42it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.82it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.54it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.57it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.30it/s]
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:20,  1.49it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:19,  1.50it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:19,  1.51it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:18,  1.51it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:17,  1.51it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:04<00:17,  1.48it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:16,  1.49it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:05<00:17,  1.37it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:06<00:18,  1.26it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:07<00:18,  1.20it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:08<00:18,  1.14it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:09<00:17,  1.15it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:10<00:16,  1.13it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:10<00:15,  1.14it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:11<00:12,  1.34it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:11<00:10,  1.52it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:12<00:08,  1.67it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:12<00:07,  1.76it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:13<00:07,  1.80it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:13<00:06,  1.84it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:14<00:05,  1.90it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:14<00:05,  1.97it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:15<00:04,  2.00it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:15<00:03,  2.08it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:16<00:03,  2.14it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:16<00:02,  2.19it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:17<00:02,  2.23it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:17<00:01,  2.27it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:17<00:01,  2.32it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:18<00:00,  2.32it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:18<00:00,  2.34it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:19<00:00,  2.34it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]
pseudo compress quantization...:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-03 04:24:25 - INFO - layer0_self_attn.q_proj | mse: 0.03444226989225957, bpp_loss: 3.5020538786775433, bpp: 0
2025-03-03 04:24:35 - INFO - layer0_self_attn.k_proj | mse: 0.030744696240624318, bpp_loss: 3.6223064952064306, bpp: 0
2025-03-03 04:24:46 - INFO - layer0_self_attn.v_proj | mse: 0.020139811181043594, bpp_loss: 3.4133273102343082, bpp: 0
2025-03-03 04:24:57 - INFO - layer0_self_attn.o_proj | mse: 0.022590593313159706, bpp_loss: 3.286953149130568, bpp: 0
2025-03-03 04:25:09 - INFO - layer0_mlp.gate_proj | mse: 0.021109192077440473, bpp_loss: 3.761906192226465, bpp: 0
2025-03-03 04:25:23 - INFO - layer0_mlp.up_proj | mse: 0.021072411763962438, bpp_loss: 3.742887761790392, bpp: 0
2025-03-03 04:25:58 - INFO - layer0_mlp.down_proj | mse: 0.023346849432663682, bpp_loss: 3.7902989984425, bpp: 0
pseudo compress quantization...:   3%|▎         | 1/32 [01:43<53:35, 103.71s/it]2025-03-03 04:26:10 - INFO - layer1_self_attn.q_proj | mse: 0.03305330600864095, bpp_loss: 4.242994233092759, bpp: 0
2025-03-03 04:26:24 - INFO - layer1_self_attn.k_proj | mse: 0.036588361366210936, bpp_loss: 4.261368578823749, bpp: 0
2025-03-03 04:26:36 - INFO - layer1_self_attn.v_proj | mse: 0.023472931083347352, bpp_loss: 3.366413868032396, bpp: 0
2025-03-03 04:26:46 - INFO - layer1_self_attn.o_proj | mse: 0.026176184681312505, bpp_loss: 3.326392962830141, bpp: 0
2025-03-03 04:26:59 - INFO - layer1_mlp.gate_proj | mse: 0.022425144694221907, bpp_loss: 3.8818940929202146, bpp: 0
2025-03-03 04:27:10 - INFO - layer1_mlp.up_proj | mse: 0.022335028614323404, bpp_loss: 3.8086285094708896, bpp: 0
2025-03-03 04:27:44 - INFO - layer1_mlp.down_proj | mse: 0.016169160477731592, bpp_loss: 3.8264659353596873, bpp: 0
pseudo compress quantization...:   6%|▋         | 2/32 [03:30<52:37, 105.26s/it]2025-03-03 04:27:57 - INFO - layer2_self_attn.q_proj | mse: 0.021711427804585688, bpp_loss: 4.402359744068235, bpp: 0
2025-03-03 04:28:08 - INFO - layer2_self_attn.k_proj | mse: 0.021880281930750502, bpp_loss: 4.475530028576031, bpp: 0
2025-03-03 04:28:20 - INFO - layer2_self_attn.v_proj | mse: 0.020434954635420468, bpp_loss: 3.615549761976581, bpp: 0
2025-03-03 04:28:33 - INFO - layer2_self_attn.o_proj | mse: 0.020956868442490832, bpp_loss: 3.6008788468316197, bpp: 0
2025-03-03 04:28:48 - INFO - layer2_mlp.gate_proj | mse: 0.020508073261265438, bpp_loss: 3.923548684217209, bpp: 0
2025-03-03 04:29:00 - INFO - layer2_mlp.up_proj | mse: 0.020402078693162615, bpp_loss: 3.832601549233808, bpp: 0
2025-03-03 04:29:32 - INFO - layer2_mlp.down_proj | mse: 0.017622919615460232, bpp_loss: 3.8424433080782725, bpp: 0
pseudo compress quantization...:   9%|▉         | 3/32 [05:17<51:24, 106.37s/it]2025-03-03 04:29:43 - INFO - layer3_self_attn.q_proj | mse: 0.019763317322793152, bpp_loss: 4.32187531638192, bpp: 0
2025-03-03 04:29:54 - INFO - layer3_self_attn.k_proj | mse: 0.019841589618936603, bpp_loss: 4.387157576566096, bpp: 0
2025-03-03 04:30:07 - INFO - layer3_self_attn.v_proj | mse: 0.01879139865079191, bpp_loss: 3.5703283892944455, bpp: 0
2025-03-03 04:30:21 - INFO - layer3_self_attn.o_proj | mse: 0.01810853819525025, bpp_loss: 3.55966157320654, bpp: 0
2025-03-03 04:30:32 - INFO - layer3_mlp.gate_proj | mse: 0.018936652693394913, bpp_loss: 3.941770013421774, bpp: 0
2025-03-03 04:30:46 - INFO - layer3_mlp.up_proj | mse: 0.01882360820588569, bpp_loss: 3.8390540152268353, bpp: 0
2025-03-03 04:31:22 - INFO - layer3_mlp.down_proj | mse: 0.017272242179396914, bpp_loss: 3.842825230384289, bpp: 0
pseudo compress quantization...:  12%|█▎        | 4/32 [07:08<50:22, 107.94s/it]2025-03-03 04:31:33 - INFO - layer4_self_attn.q_proj | mse: 0.019448739058338615, bpp_loss: 4.414599655487109, bpp: 0
2025-03-03 04:31:43 - INFO - layer4_self_attn.k_proj | mse: 0.019544008303237475, bpp_loss: 4.450933871790767, bpp: 0
2025-03-03 04:31:54 - INFO - layer4_self_attn.v_proj | mse: 0.018409439521734055, bpp_loss: 3.6170825068256818, bpp: 0
2025-03-03 04:32:05 - INFO - layer4_self_attn.o_proj | mse: 0.018316114192399348, bpp_loss: 3.6122814470436424, bpp: 0
2025-03-03 04:32:20 - INFO - layer4_mlp.gate_proj | mse: 0.018680697500169475, bpp_loss: 3.9680580256810023, bpp: 0
2025-03-03 04:32:33 - INFO - layer4_mlp.up_proj | mse: 0.01852877928274686, bpp_loss: 3.829504370689392, bpp: 0
2025-03-03 04:33:07 - INFO - layer4_mlp.down_proj | mse: 0.01729154753209557, bpp_loss: 3.82837505305056, bpp: 0
pseudo compress quantization...:  16%|█▌        | 5/32 [08:52<48:01, 106.73s/it]2025-03-03 04:33:21 - INFO - layer5_self_attn.q_proj | mse: 0.01909809551093605, bpp_loss: 4.434812700317707, bpp: 0
2025-03-03 04:33:32 - INFO - layer5_self_attn.k_proj | mse: 0.01925617843282737, bpp_loss: 4.5033822324476205, bpp: 0
2025-03-03 04:33:43 - INFO - layer5_self_attn.v_proj | mse: 0.01813483609917512, bpp_loss: 3.638162183284294, bpp: 0
2025-03-03 04:33:54 - INFO - layer5_self_attn.o_proj | mse: 0.018885343947236493, bpp_loss: 3.6229410060914233, bpp: 0
2025-03-03 04:34:06 - INFO - layer5_mlp.gate_proj | mse: 0.018618923389847893, bpp_loss: 3.9761423571685026, bpp: 0
2025-03-03 04:34:18 - INFO - layer5_mlp.up_proj | mse: 0.018470950540166474, bpp_loss: 3.8302004207358804, bpp: 0
2025-03-03 04:34:54 - INFO - layer5_mlp.down_proj | mse: 0.017175455625295537, bpp_loss: 3.8305397274535755, bpp: 0
pseudo compress quantization...:  19%|█▉        | 6/32 [10:40<46:24, 107.08s/it]2025-03-03 04:35:06 - INFO - layer6_self_attn.q_proj | mse: 0.018730359412373283, bpp_loss: 4.300913122075144, bpp: 0
2025-03-03 04:35:18 - INFO - layer6_self_attn.k_proj | mse: 0.018785536485152472, bpp_loss: 4.333120322786272, bpp: 0
2025-03-03 04:35:31 - INFO - layer6_self_attn.v_proj | mse: 0.017883116415872872, bpp_loss: 3.572697284806054, bpp: 0
2025-03-03 04:35:45 - INFO - layer6_self_attn.o_proj | mse: 0.018552992326617918, bpp_loss: 3.578009927587118, bpp: 0
2025-03-03 04:35:57 - INFO - layer6_mlp.gate_proj | mse: 0.01832737580534409, bpp_loss: 3.999124347383893, bpp: 0
2025-03-03 04:36:09 - INFO - layer6_mlp.up_proj | mse: 0.01815476057682012, bpp_loss: 3.825955018054607, bpp: 0
2025-03-03 04:36:41 - INFO - layer6_mlp.down_proj | mse: 0.017208015688853686, bpp_loss: 3.824671735423942, bpp: 0
pseudo compress quantization...:  22%|██▏       | 7/32 [12:26<44:31, 106.87s/it]2025-03-03 04:36:53 - INFO - layer7_self_attn.q_proj | mse: 0.01858520019738462, bpp_loss: 4.294380144565366, bpp: 0
2025-03-03 04:37:06 - INFO - layer7_self_attn.k_proj | mse: 0.018614054741377097, bpp_loss: 4.306588120118249, bpp: 0
2025-03-03 04:37:19 - INFO - layer7_self_attn.v_proj | mse: 0.01776891210073959, bpp_loss: 3.581832413736265, bpp: 0
2025-03-03 04:37:30 - INFO - layer7_self_attn.o_proj | mse: 0.017824150011412743, bpp_loss: 3.583711265353486, bpp: 0
2025-03-03 04:37:43 - INFO - layer7_mlp.gate_proj | mse: 0.018198614525029775, bpp_loss: 3.9972243117558404, bpp: 0
2025-03-03 04:37:58 - INFO - layer7_mlp.up_proj | mse: 0.018019634965592134, bpp_loss: 3.8296840149302813, bpp: 0
2025-03-03 04:38:30 - INFO - layer7_mlp.down_proj | mse: 0.017290630180197275, bpp_loss: 3.8259423450935026, bpp: 0
pseudo compress quantization...:  25%|██▌       | 8/32 [14:16<43:05, 107.73s/it]2025-03-03 04:38:41 - INFO - layer8_self_attn.q_proj | mse: 0.01862319491068395, bpp_loss: 4.312557147757616, bpp: 0
2025-03-03 04:38:52 - INFO - layer8_self_attn.k_proj | mse: 0.0186969231955571, bpp_loss: 4.332668296643533, bpp: 0
2025-03-03 04:39:03 - INFO - layer8_self_attn.v_proj | mse: 0.017807042975039693, bpp_loss: 3.606826690142043, bpp: 0
2025-03-03 04:39:16 - INFO - layer8_self_attn.o_proj | mse: 0.018448012195026006, bpp_loss: 3.608072832983453, bpp: 0
2025-03-03 04:39:31 - INFO - layer8_mlp.gate_proj | mse: 0.018120047808513562, bpp_loss: 3.9753147909461064, bpp: 0
2025-03-03 04:39:43 - INFO - layer8_mlp.up_proj | mse: 0.017987222583831945, bpp_loss: 3.8444972779861715, bpp: 0
2025-03-03 04:40:20 - INFO - layer8_mlp.down_proj | mse: 0.017331818310258304, bpp_loss: 3.8374771726166093, bpp: 0
pseudo compress quantization...:  28%|██▊       | 9/32 [16:06<41:34, 108.43s/it]2025-03-03 04:40:31 - INFO - layer9_self_attn.q_proj | mse: 0.018558231628104903, bpp_loss: 4.338363475864753, bpp: 0
2025-03-03 04:40:42 - INFO - layer9_self_attn.k_proj | mse: 0.01865263320875419, bpp_loss: 4.38027800002601, bpp: 0
2025-03-03 04:40:52 - INFO - layer9_self_attn.v_proj | mse: 0.017738330919375676, bpp_loss: 3.6241481466568075, bpp: 0
2025-03-03 04:41:03 - INFO - layer9_self_attn.o_proj | mse: 0.018606791855655298, bpp_loss: 3.623354515468236, bpp: 0
2025-03-03 04:41:16 - INFO - layer9_mlp.gate_proj | mse: 0.01804278112300715, bpp_loss: 3.9608940232631773, bpp: 0
2025-03-03 04:41:30 - INFO - layer9_mlp.up_proj | mse: 0.017930580685481905, bpp_loss: 3.8525018549069414, bpp: 0
2025-03-03 04:42:05 - INFO - layer9_mlp.down_proj | mse: 0.017329272146705106, bpp_loss: 3.844871662817029, bpp: 0
pseudo compress quantization...:  31%|███▏      | 10/32 [17:51<39:20, 107.29s/it]2025-03-03 04:42:18 - INFO - layer10_self_attn.q_proj | mse: 0.018495652611560574, bpp_loss: 4.328457752184477, bpp: 0
2025-03-03 04:42:33 - INFO - layer10_self_attn.k_proj | mse: 0.01861318852564881, bpp_loss: 4.375604402332101, bpp: 0
2025-03-03 04:42:43 - INFO - layer10_self_attn.v_proj | mse: 0.017696196332244493, bpp_loss: 3.6167010359931737, bpp: 0
2025-03-03 04:42:54 - INFO - layer10_self_attn.o_proj | mse: 0.01901037740749466, bpp_loss: 3.6220510940183885, bpp: 0
2025-03-03 04:43:07 - INFO - layer10_mlp.gate_proj | mse: 0.01804378040057439, bpp_loss: 3.9542332923169745, bpp: 0
2025-03-03 04:43:19 - INFO - layer10_mlp.up_proj | mse: 0.017952039820898297, bpp_loss: 3.8657062953814516, bpp: 0
2025-03-03 04:43:53 - INFO - layer10_mlp.down_proj | mse: 0.01736576572034184, bpp_loss: 3.8547000569226437, bpp: 0
pseudo compress quantization...:  34%|███▍      | 11/32 [19:38<37:36, 107.46s/it]2025-03-03 04:44:07 - INFO - layer11_self_attn.q_proj | mse: 0.01835353094570606, bpp_loss: 4.211899962334428, bpp: 0
2025-03-03 04:44:17 - INFO - layer11_self_attn.k_proj | mse: 0.01841400236378106, bpp_loss: 4.217663956456818, bpp: 0
2025-03-03 04:44:29 - INFO - layer11_self_attn.v_proj | mse: 0.01772170479206917, bpp_loss: 3.6514367108466104, bpp: 0
2025-03-03 04:44:43 - INFO - layer11_self_attn.o_proj | mse: 0.01837256596390913, bpp_loss: 3.656337004620582, bpp: 0
2025-03-03 04:44:57 - INFO - layer11_mlp.gate_proj | mse: 0.017891014899259813, bpp_loss: 3.950858600524276, bpp: 0
2025-03-03 04:45:10 - INFO - layer11_mlp.up_proj | mse: 0.01781648625584702, bpp_loss: 3.8761780048005803, bpp: 0
2025-03-03 04:45:42 - INFO - layer11_mlp.down_proj | mse: 0.01729533659428418, bpp_loss: 3.863034373474156, bpp: 0
pseudo compress quantization...:  38%|███▊      | 12/32 [21:27<35:57, 107.86s/it]2025-03-03 04:45:53 - INFO - layer12_self_attn.q_proj | mse: 0.0182722080637369, bpp_loss: 4.274275985429995, bpp: 0
2025-03-03 04:46:06 - INFO - layer12_self_attn.k_proj | mse: 0.018379692688630163, bpp_loss: 4.325307340477593, bpp: 0
2025-03-03 04:46:19 - INFO - layer12_self_attn.v_proj | mse: 0.017572908340134464, bpp_loss: 3.6410868997336365, bpp: 0
2025-03-03 04:46:31 - INFO - layer12_self_attn.o_proj | mse: 0.018857987174252463, bpp_loss: 3.6474966501118615, bpp: 0
2025-03-03 04:46:43 - INFO - layer12_mlp.gate_proj | mse: 0.01785184796168915, bpp_loss: 3.9434647039445334, bpp: 0
2025-03-03 04:46:57 - INFO - layer12_mlp.up_proj | mse: 0.017800392173777057, bpp_loss: 3.888034601024417, bpp: 0
2025-03-03 04:47:32 - INFO - layer12_mlp.down_proj | mse: 0.017240940106044766, bpp_loss: 3.8733321958719644, bpp: 0
pseudo compress quantization...:  41%|████      | 13/32 [23:18<34:25, 108.73s/it]2025-03-03 04:47:44 - INFO - layer13_self_attn.q_proj | mse: 0.018179689560757804, bpp_loss: 4.262164823536295, bpp: 0
2025-03-03 04:47:55 - INFO - layer13_self_attn.k_proj | mse: 0.018251507246056353, bpp_loss: 4.292183032201137, bpp: 0
2025-03-03 04:48:05 - INFO - layer13_self_attn.v_proj | mse: 0.017527304544526272, bpp_loss: 3.6750372837414034, bpp: 0
2025-03-03 04:48:17 - INFO - layer13_self_attn.o_proj | mse: 0.018494811020694127, bpp_loss: 3.6755353800253943, bpp: 0
2025-03-03 04:48:32 - INFO - layer13_mlp.gate_proj | mse: 0.017894412658582284, bpp_loss: 3.9385456250504007, bpp: 0
2025-03-03 04:48:46 - INFO - layer13_mlp.up_proj | mse: 0.01786031756670078, bpp_loss: 3.900684195808893, bpp: 0
2025-03-03 04:49:21 - INFO - layer13_mlp.down_proj | mse: 0.01732811117373864, bpp_loss: 3.882511802515838, bpp: 0
pseudo compress quantization...:  44%|████▍     | 14/32 [25:07<32:38, 108.83s/it]2025-03-03 04:49:34 - INFO - layer14_self_attn.q_proj | mse: 0.018296315803479207, bpp_loss: 4.253647153265774, bpp: 0
2025-03-03 04:49:45 - INFO - layer14_self_attn.k_proj | mse: 0.01837192716602255, bpp_loss: 4.2882652543485165, bpp: 0
2025-03-03 04:49:56 - INFO - layer14_self_attn.v_proj | mse: 0.01764951628532172, bpp_loss: 3.6579045699327253, bpp: 0
2025-03-03 04:50:06 - INFO - layer14_self_attn.o_proj | mse: 0.018390639163979115, bpp_loss: 3.6606377521529794, bpp: 0
2025-03-03 04:50:18 - INFO - layer14_mlp.gate_proj | mse: 0.017844303254361107, bpp_loss: 3.9358022865341153, bpp: 0
2025-03-03 04:50:31 - INFO - layer14_mlp.up_proj | mse: 0.017813798878311825, bpp_loss: 3.9025779607337574, bpp: 0
2025-03-03 04:51:07 - INFO - layer14_mlp.down_proj | mse: 0.01724358005292952, bpp_loss: 3.8851601965508835, bpp: 0
pseudo compress quantization...:  47%|████▋     | 15/32 [26:53<30:35, 107.99s/it]2025-03-03 04:51:19 - INFO - layer15_self_attn.q_proj | mse: 0.01824507146598815, bpp_loss: 4.243236950482242, bpp: 0
2025-03-03 04:51:32 - INFO - layer15_self_attn.k_proj | mse: 0.018351029349447275, bpp_loss: 4.299475447915029, bpp: 0
2025-03-03 04:51:46 - INFO - layer15_self_attn.v_proj | mse: 0.01763618554393805, bpp_loss: 3.6961475588032044, bpp: 0
2025-03-03 04:51:57 - INFO - layer15_self_attn.o_proj | mse: 0.01881097251891291, bpp_loss: 3.6901305207866244, bpp: 0
2025-03-03 04:52:09 - INFO - layer15_mlp.gate_proj | mse: 0.017902926460336373, bpp_loss: 3.9422089202806005, bpp: 0
2025-03-03 04:52:21 - INFO - layer15_mlp.up_proj | mse: 0.01787068978757668, bpp_loss: 3.909415847773469, bpp: 0
2025-03-03 04:52:53 - INFO - layer15_mlp.down_proj | mse: 0.017302895315213486, bpp_loss: 3.888036640534221, bpp: 0
pseudo compress quantization...:  50%|█████     | 16/32 [28:39<28:38, 107.40s/it]2025-03-03 04:53:07 - INFO - layer16_self_attn.q_proj | mse: 0.018334905859026578, bpp_loss: 4.223905274877325, bpp: 0
2025-03-03 04:53:20 - INFO - layer16_self_attn.k_proj | mse: 0.018434497491439168, bpp_loss: 4.270241900230758, bpp: 0
2025-03-03 04:53:31 - INFO - layer16_self_attn.v_proj | mse: 0.017792436086404143, bpp_loss: 3.738587445288431, bpp: 0
2025-03-03 04:53:43 - INFO - layer16_self_attn.o_proj | mse: 0.018075965297119787, bpp_loss: 3.7434376566670835, bpp: 0
2025-03-03 04:53:58 - INFO - layer16_mlp.gate_proj | mse: 0.018144491840999727, bpp_loss: 3.951571168854486, bpp: 0
2025-03-03 04:54:11 - INFO - layer16_mlp.up_proj | mse: 0.01810507050266761, bpp_loss: 3.909143255980209, bpp: 0
2025-03-03 04:54:43 - INFO - layer16_mlp.down_proj | mse: 0.01732155712022321, bpp_loss: 3.8885157883253902, bpp: 0
pseudo compress quantization...:  53%|█████▎    | 17/32 [30:29<26:59, 108.00s/it]2025-03-03 04:54:54 - INFO - layer17_self_attn.q_proj | mse: 0.018373071497837512, bpp_loss: 4.221822346211411, bpp: 0
2025-03-03 04:55:05 - INFO - layer17_self_attn.k_proj | mse: 0.01844821064244202, bpp_loss: 4.257947921694722, bpp: 0
2025-03-03 04:55:18 - INFO - layer17_self_attn.v_proj | mse: 0.017840044635470446, bpp_loss: 3.7370133836520836, bpp: 0
2025-03-03 04:55:30 - INFO - layer17_self_attn.o_proj | mse: 0.01796132642560108, bpp_loss: 3.739995186740998, bpp: 0
2025-03-03 04:55:44 - INFO - layer17_mlp.gate_proj | mse: 0.018007419417165018, bpp_loss: 3.965853485863569, bpp: 0
2025-03-03 04:55:56 - INFO - layer17_mlp.up_proj | mse: 0.017950351720930343, bpp_loss: 3.9052651701278465, bpp: 0
2025-03-03 04:56:33 - INFO - layer17_mlp.down_proj | mse: 0.017135113701157143, bpp_loss: 3.8888837050126734, bpp: 0
pseudo compress quantization...:  56%|█████▋    | 18/32 [32:18<25:19, 108.57s/it]2025-03-03 04:56:42 - INFO - layer18_self_attn.q_proj | mse: 0.018167378578358605, bpp_loss: 4.192085897899233, bpp: 0
2025-03-03 04:56:51 - INFO - layer18_self_attn.k_proj | mse: 0.01822907109987666, bpp_loss: 4.2248391371103935, bpp: 0
2025-03-03 04:57:00 - INFO - layer18_self_attn.v_proj | mse: 0.017730752256013796, bpp_loss: 3.787359254260082, bpp: 0
2025-03-03 04:57:09 - INFO - layer18_self_attn.o_proj | mse: 0.017647836000631398, bpp_loss: 3.7862232460756786, bpp: 0
2025-03-03 04:57:19 - INFO - layer18_mlp.gate_proj | mse: 0.018039413546825867, bpp_loss: 3.9777848931072755, bpp: 0
2025-03-03 04:57:30 - INFO - layer18_mlp.up_proj | mse: 0.01796758952845752, bpp_loss: 3.9016888954265174, bpp: 0
2025-03-03 04:57:58 - INFO - layer18_mlp.down_proj | mse: 0.01702632827046362, bpp_loss: 3.8878583042817407, bpp: 0
pseudo compress quantization...:  59%|█████▉    | 19/32 [33:43<21:59, 101.51s/it]2025-03-03 04:58:07 - INFO - layer19_self_attn.q_proj | mse: 0.018220343759135962, bpp_loss: 4.168647128157318, bpp: 0
2025-03-03 04:58:16 - INFO - layer19_self_attn.k_proj | mse: 0.01828260410099764, bpp_loss: 4.198877935879864, bpp: 0
2025-03-03 04:58:25 - INFO - layer19_self_attn.v_proj | mse: 0.017808198895024933, bpp_loss: 3.7978851390071213, bpp: 0
2025-03-03 04:58:34 - INFO - layer19_self_attn.o_proj | mse: 0.01731404889541962, bpp_loss: 3.792836896958761, bpp: 0
2025-03-03 04:58:44 - INFO - layer19_mlp.gate_proj | mse: 0.017970093651206918, bpp_loss: 3.9827930406602317, bpp: 0
2025-03-03 04:58:55 - INFO - layer19_mlp.up_proj | mse: 0.017896557817545393, bpp_loss: 3.901637184758519, bpp: 0
2025-03-03 04:59:23 - INFO - layer19_mlp.down_proj | mse: 0.016950660213470924, bpp_loss: 3.891293928308716, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 20/32 [35:08<19:18, 96.55s/it] 2025-03-03 04:59:35 - INFO - layer20_self_attn.q_proj | mse: 0.018193856098922788, bpp_loss: 4.176991184707731, bpp: 0
2025-03-03 04:59:47 - INFO - layer20_self_attn.k_proj | mse: 0.018251392812874856, bpp_loss: 4.205741013691295, bpp: 0
2025-03-03 04:59:59 - INFO - layer20_self_attn.v_proj | mse: 0.01778615529811341, bpp_loss: 3.816138915834017, bpp: 0
2025-03-03 05:00:12 - INFO - layer20_self_attn.o_proj | mse: 0.017474017792023698, bpp_loss: 3.817841335083358, bpp: 0
2025-03-03 05:00:27 - INFO - layer20_mlp.gate_proj | mse: 0.018085764071999626, bpp_loss: 3.9918589165737464, bpp: 0
2025-03-03 05:00:41 - INFO - layer20_mlp.up_proj | mse: 0.01799595629132899, bpp_loss: 3.9016435854136944, bpp: 0
2025-03-03 05:01:20 - INFO - layer20_mlp.down_proj | mse: 0.01698861120163938, bpp_loss: 3.8924992964927885, bpp: 0
pseudo compress quantization...:  66%|██████▌   | 21/32 [37:05<18:49, 102.69s/it]2025-03-03 05:01:32 - INFO - layer21_self_attn.q_proj | mse: 0.018164679983205093, bpp_loss: 4.140170193335507, bpp: 0
2025-03-03 05:01:45 - INFO - layer21_self_attn.k_proj | mse: 0.018199438699954263, bpp_loss: 4.157106297207065, bpp: 0
2025-03-03 05:01:57 - INFO - layer21_self_attn.v_proj | mse: 0.01783188946063723, bpp_loss: 3.853169020381756, bpp: 0
2025-03-03 05:02:09 - INFO - layer21_self_attn.o_proj | mse: 0.017165433508645512, bpp_loss: 3.8488729964010417, bpp: 0
2025-03-03 05:02:25 - INFO - layer21_mlp.gate_proj | mse: 0.01797257082472311, bpp_loss: 4.001344229592833, bpp: 0
2025-03-03 05:02:39 - INFO - layer21_mlp.up_proj | mse: 0.01787466749439772, bpp_loss: 3.8997607711962488, bpp: 0
2025-03-03 05:03:18 - INFO - layer21_mlp.down_proj | mse: 0.016805357493815443, bpp_loss: 3.892828343371146, bpp: 0
pseudo compress quantization...:  69%|██████▉   | 22/32 [39:04<17:53, 107.36s/it]2025-03-03 05:03:31 - INFO - layer22_self_attn.q_proj | mse: 0.018037737371893608, bpp_loss: 4.179598817019723, bpp: 0
2025-03-03 05:03:43 - INFO - layer22_self_attn.k_proj | mse: 0.018083232528405442, bpp_loss: 4.199525428004563, bpp: 0
2025-03-03 05:03:55 - INFO - layer22_self_attn.v_proj | mse: 0.017673079381060962, bpp_loss: 3.8573504560627043, bpp: 0
2025-03-03 05:04:08 - INFO - layer22_self_attn.o_proj | mse: 0.017082131946601364, bpp_loss: 3.8414088279823773, bpp: 0
2025-03-03 05:04:21 - INFO - layer22_mlp.gate_proj | mse: 0.017919979935108427, bpp_loss: 4.0102375845403175, bpp: 0
2025-03-03 05:04:31 - INFO - layer22_mlp.up_proj | mse: 0.017812883682352187, bpp_loss: 3.89978998734854, bpp: 0
2025-03-03 05:04:59 - INFO - layer22_mlp.down_proj | mse: 0.016809683384729494, bpp_loss: 3.89344501322092, bpp: 0
pseudo compress quantization...:  72%|███████▏  | 23/32 [40:45<15:49, 105.48s/it]2025-03-03 05:05:09 - INFO - layer23_self_attn.q_proj | mse: 0.017932603697045513, bpp_loss: 4.1732400440378115, bpp: 0
2025-03-03 05:05:18 - INFO - layer23_self_attn.k_proj | mse: 0.01796134525637778, bpp_loss: 4.185392506537028, bpp: 0
2025-03-03 05:05:27 - INFO - layer23_self_attn.v_proj | mse: 0.017657953921805466, bpp_loss: 3.9165858938358724, bpp: 0
2025-03-03 05:05:37 - INFO - layer23_self_attn.o_proj | mse: 0.016647548039268073, bpp_loss: 3.8999969668802805, bpp: 0
2025-03-03 05:05:50 - INFO - layer23_mlp.gate_proj | mse: 0.017774530611624314, bpp_loss: 4.0103097558021545, bpp: 0
2025-03-03 05:06:02 - INFO - layer23_mlp.up_proj | mse: 0.017669174201363783, bpp_loss: 3.905915279201297, bpp: 0
2025-03-03 05:06:34 - INFO - layer23_mlp.down_proj | mse: 0.01665343388654619, bpp_loss: 3.901057249736474, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 24/32 [42:19<13:37, 102.17s/it]2025-03-03 05:06:46 - INFO - layer24_self_attn.q_proj | mse: 0.01774672799726345, bpp_loss: 4.115248624293599, bpp: 0
2025-03-03 05:07:00 - INFO - layer24_self_attn.k_proj | mse: 0.017777742286491507, bpp_loss: 4.123001674131956, bpp: 0
2025-03-03 05:07:10 - INFO - layer24_self_attn.v_proj | mse: 0.01752194791281522, bpp_loss: 3.905169010802638, bpp: 0
2025-03-03 05:07:22 - INFO - layer24_self_attn.o_proj | mse: 0.01701094147101912, bpp_loss: 3.889598573150579, bpp: 0
2025-03-03 05:07:37 - INFO - layer24_mlp.gate_proj | mse: 0.01766826655118944, bpp_loss: 4.013595596995464, bpp: 0
2025-03-03 05:07:50 - INFO - layer24_mlp.up_proj | mse: 0.017568204048299677, bpp_loss: 3.9099279154351976, bpp: 0
2025-03-03 05:08:22 - INFO - layer24_mlp.down_proj | mse: 0.016555821607939412, bpp_loss: 3.905617887110904, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 25/32 [44:08<12:08, 104.01s/it]2025-03-03 05:08:33 - INFO - layer25_self_attn.q_proj | mse: 0.01764299214545515, bpp_loss: 4.138843565306161, bpp: 0
2025-03-03 05:08:44 - INFO - layer25_self_attn.k_proj | mse: 0.017658092979848803, bpp_loss: 4.144712201261427, bpp: 0
2025-03-03 05:08:57 - INFO - layer25_self_attn.v_proj | mse: 0.01744996799313278, bpp_loss: 3.955280290392693, bpp: 0
2025-03-03 05:09:09 - INFO - layer25_self_attn.o_proj | mse: 0.016864038236403603, bpp_loss: 3.9463083549635485, bpp: 0
2025-03-03 05:09:23 - INFO - layer25_mlp.gate_proj | mse: 0.01753792496783999, bpp_loss: 4.015319992376622, bpp: 0
2025-03-03 05:09:35 - INFO - layer25_mlp.up_proj | mse: 0.017436268148313824, bpp_loss: 3.915099353031364, bpp: 0
2025-03-03 05:10:12 - INFO - layer25_mlp.down_proj | mse: 0.016458753703843376, bpp_loss: 3.9102451990163605, bpp: 0
pseudo compress quantization...:  81%|████████▏ | 26/32 [45:58<10:35, 105.86s/it]2025-03-03 05:10:23 - INFO - layer26_self_attn.q_proj | mse: 0.01754111040089135, bpp_loss: 4.111701919231564, bpp: 0
2025-03-03 05:10:34 - INFO - layer26_self_attn.k_proj | mse: 0.017568193403352562, bpp_loss: 4.124033296480775, bpp: 0
2025-03-03 05:10:45 - INFO - layer26_self_attn.v_proj | mse: 0.017385043820628422, bpp_loss: 3.972470070817508, bpp: 0
2025-03-03 05:10:55 - INFO - layer26_self_attn.o_proj | mse: 0.017334601963929122, bpp_loss: 3.964786743570585, bpp: 0
2025-03-03 05:11:08 - INFO - layer26_mlp.gate_proj | mse: 0.017498386130851102, bpp_loss: 4.018044815507046, bpp: 0
2025-03-03 05:11:23 - INFO - layer26_mlp.up_proj | mse: 0.017404907864617958, bpp_loss: 3.919969459259233, bpp: 0
2025-03-03 05:11:57 - INFO - layer26_mlp.down_proj | mse: 0.01643139915417108, bpp_loss: 3.9118286416714274, bpp: 0
pseudo compress quantization...:  84%|████████▍ | 27/32 [47:42<08:47, 105.45s/it]2025-03-03 05:12:11 - INFO - layer27_self_attn.q_proj | mse: 0.017560420638138525, bpp_loss: 4.182918243401218, bpp: 0
2025-03-03 05:12:23 - INFO - layer27_self_attn.k_proj | mse: 0.017567860243457065, bpp_loss: 4.199983745405916, bpp: 0
2025-03-03 05:12:35 - INFO - layer27_self_attn.v_proj | mse: 0.017349446410055373, bpp_loss: 3.979674799425993, bpp: 0
2025-03-03 05:12:45 - INFO - layer27_self_attn.o_proj | mse: 0.016812049358972177, bpp_loss: 3.9801249131560326, bpp: 0
2025-03-03 05:12:58 - INFO - layer27_mlp.gate_proj | mse: 0.017456592182027626, bpp_loss: 4.017669013593086, bpp: 0
2025-03-03 05:13:10 - INFO - layer27_mlp.up_proj | mse: 0.017368172825851704, bpp_loss: 3.926491129363692, bpp: 0
2025-03-03 05:13:44 - INFO - layer27_mlp.down_proj | mse: 0.016456488890284837, bpp_loss: 3.9160260438355943, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 28/32 [49:30<07:04, 106.11s/it]2025-03-03 05:13:57 - INFO - layer28_self_attn.q_proj | mse: 0.017527305993047557, bpp_loss: 4.131034809048288, bpp: 0
2025-03-03 05:14:08 - INFO - layer28_self_attn.k_proj | mse: 0.017542797928188098, bpp_loss: 4.151228652568534, bpp: 0
2025-03-03 05:14:21 - INFO - layer28_self_attn.v_proj | mse: 0.017400332962789093, bpp_loss: 4.02129056956619, bpp: 0
2025-03-03 05:14:35 - INFO - layer28_self_attn.o_proj | mse: 0.017351843712781655, bpp_loss: 4.024891868641134, bpp: 0
2025-03-03 05:14:48 - INFO - layer28_mlp.gate_proj | mse: 0.01743708201515661, bpp_loss: 4.01007184100359, bpp: 0
2025-03-03 05:15:00 - INFO - layer28_mlp.up_proj | mse: 0.01736218362826425, bpp_loss: 3.939085862750924, bpp: 0
2025-03-03 05:15:32 - INFO - layer28_mlp.down_proj | mse: 0.016570540201146598, bpp_loss: 3.9209864851044016, bpp: 0
pseudo compress quantization...:  91%|█████████ | 29/32 [51:17<05:19, 106.50s/it]2025-03-03 05:15:43 - INFO - layer29_self_attn.q_proj | mse: 0.017515081921925444, bpp_loss: 4.083220808883198, bpp: 0
2025-03-03 05:15:56 - INFO - layer29_self_attn.k_proj | mse: 0.017529364341793207, bpp_loss: 4.1000479540089145, bpp: 0
2025-03-03 05:16:09 - INFO - layer29_self_attn.v_proj | mse: 0.01745085883372291, bpp_loss: 4.0269347775611095, bpp: 0
2025-03-03 05:16:20 - INFO - layer29_self_attn.o_proj | mse: 0.017109907342236694, bpp_loss: 4.043895155889913, bpp: 0
2025-03-03 05:16:33 - INFO - layer29_mlp.gate_proj | mse: 0.017458183264756042, bpp_loss: 4.010947346860586, bpp: 0
2025-03-03 05:16:47 - INFO - layer29_mlp.up_proj | mse: 0.01739685112185902, bpp_loss: 3.950278882370439, bpp: 0
2025-03-03 05:17:21 - INFO - layer29_mlp.down_proj | mse: 0.016723896429653027, bpp_loss: 3.92189110070467, bpp: 0
pseudo compress quantization...:  94%|█████████▍| 30/32 [53:07<03:34, 107.34s/it]2025-03-03 05:17:32 - INFO - layer30_self_attn.q_proj | mse: 0.017591841961847602, bpp_loss: 4.102576261560898, bpp: 0
2025-03-03 05:17:43 - INFO - layer30_self_attn.k_proj | mse: 0.017616227817676584, bpp_loss: 4.127977651776746, bpp: 0
2025-03-03 05:17:54 - INFO - layer30_self_attn.v_proj | mse: 0.01756236020813882, bpp_loss: 4.065250170009676, bpp: 0
2025-03-03 05:18:06 - INFO - layer30_self_attn.o_proj | mse: 0.017327592569432154, bpp_loss: 4.078381900093518, bpp: 0
2025-03-03 05:18:20 - INFO - layer30_mlp.gate_proj | mse: 0.01757799524370768, bpp_loss: 4.03286190382963, bpp: 0
2025-03-03 05:18:34 - INFO - layer30_mlp.up_proj | mse: 0.017502673214869334, bpp_loss: 3.96360232923613, bpp: 0
2025-03-03 05:19:09 - INFO - layer30_mlp.down_proj | mse: 0.01722995020874381, bpp_loss: 3.905615030592957, bpp: 0
pseudo compress quantization...:  97%|█████████▋| 31/32 [54:55<01:47, 107.55s/it]2025-03-03 05:19:21 - INFO - layer31_self_attn.q_proj | mse: 0.017956779517288208, bpp_loss: 4.12347149499692, bpp: 0
2025-03-03 05:19:32 - INFO - layer31_self_attn.k_proj | mse: 0.018027268908568626, bpp_loss: 4.174138980451971, bpp: 0
2025-03-03 05:19:43 - INFO - layer31_self_attn.v_proj | mse: 0.017759159206929283, bpp_loss: 3.9292866056784987, bpp: 0
2025-03-03 05:19:54 - INFO - layer31_self_attn.o_proj | mse: 0.019197255484005783, bpp_loss: 3.9291706568328664, bpp: 0
2025-03-03 05:20:06 - INFO - layer31_mlp.gate_proj | mse: 0.01799470045706164, bpp_loss: 4.108992098549078, bpp: 0
2025-03-03 05:20:19 - INFO - layer31_mlp.up_proj | mse: 0.017901438862663464, bpp_loss: 4.02731628456088, bpp: 0
2025-03-03 05:20:55 - INFO - layer31_mlp.down_proj | mse: 0.019531799559491744, bpp_loss: 3.897965426296862, bpp: 0
pseudo compress quantization...: 100%|██████████| 32/32 [56:41<00:00, 107.16s/it]pseudo compress quantization...: 100%|██████████| 32/32 [56:41<00:00, 106.29s/it]
2025-03-03 05:20:55 - INFO - #### Total | mse: 0.01821091322510649, bpp_loss: 3.9352911305229283, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda300_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_5.34295_bpp_5.7068_MSE_0.00302_total_iter_95000.pth.tar/COL_MSE0.01821_bpploss3.9353_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda300_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_5.34295_bpp_5.7068_MSE_0.00302_total_iter_95000.pth.tar/COL_MSE0.01821_bpploss3.9353_bpp0
I0303 05:21:26.304887 3001608 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.31it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.43it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]
I0303 05:21:28.395720 3001608 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.375:   0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.375:   1%|          | 1/166 [00:00<01:43,  1.59it/s]avg_loss = 1.640625:   1%|          | 1/166 [00:01<01:43,  1.59it/s]avg_loss = 1.640625:   1%|          | 2/166 [00:01<01:30,  1.81it/s]avg_loss = 1.8072916666666667:   1%|          | 2/166 [00:01<01:30,  1.81it/s]avg_loss = 1.8072916666666667:   2%|▏         | 3/166 [00:01<01:26,  1.88it/s]avg_loss = 1.83984375:   2%|▏         | 3/166 [00:02<01:26,  1.88it/s]        avg_loss = 1.83984375:   2%|▏         | 4/166 [00:02<01:24,  1.93it/s]avg_loss = 1.771875:   2%|▏         | 4/166 [00:02<01:24,  1.93it/s]  avg_loss = 1.771875:   3%|▎         | 5/166 [00:02<01:21,  1.98it/s]avg_loss = 1.7486979166666667:   3%|▎         | 5/166 [00:03<01:21,  1.98it/s]avg_loss = 1.7486979166666667:   4%|▎         | 6/166 [00:03<01:17,  2.07it/s]avg_loss = 1.6886160714285714:   4%|▎         | 6/166 [00:03<01:17,  2.07it/s]avg_loss = 1.6886160714285714:   4%|▍         | 7/166 [00:03<01:15,  2.11it/s]avg_loss = 1.6318359375:   4%|▍         | 7/166 [00:03<01:15,  2.11it/s]      avg_loss = 1.6318359375:   5%|▍         | 8/166 [00:03<01:14,  2.13it/s]avg_loss = 1.6267361111111112:   5%|▍         | 8/166 [00:04<01:14,  2.13it/s]avg_loss = 1.6267361111111112:   5%|▌         | 9/166 [00:04<01:13,  2.15it/s]avg_loss = 1.63359375:   5%|▌         | 9/166 [00:04<01:13,  2.15it/s]        avg_loss = 1.63359375:   6%|▌         | 10/166 [00:04<01:12,  2.15it/s]avg_loss = 1.6491477272727273:   6%|▌         | 10/166 [00:05<01:12,  2.15it/s]avg_loss = 1.6491477272727273:   7%|▋         | 11/166 [00:05<01:11,  2.15it/s]avg_loss = 1.6588541666666667:   7%|▋         | 11/166 [00:05<01:11,  2.15it/s]avg_loss = 1.6588541666666667:   7%|▋         | 12/166 [00:05<01:11,  2.16it/s]avg_loss = 1.6544471153846154:   7%|▋         | 12/166 [00:06<01:11,  2.16it/s]avg_loss = 1.6544471153846154:   8%|▊         | 13/166 [00:06<01:10,  2.16it/s]avg_loss = 1.6674107142857142:   8%|▊         | 13/166 [00:06<01:10,  2.16it/s]avg_loss = 1.6674107142857142:   8%|▊         | 14/166 [00:06<01:10,  2.16it/s]avg_loss = 1.6854166666666666:   8%|▊         | 14/166 [00:07<01:10,  2.16it/s]avg_loss = 1.6854166666666666:   9%|▉         | 15/166 [00:07<01:10,  2.15it/s]avg_loss = 1.705078125:   9%|▉         | 15/166 [00:07<01:10,  2.15it/s]       avg_loss = 1.705078125:  10%|▉         | 16/166 [00:07<01:09,  2.15it/s]avg_loss = 1.71875:  10%|▉         | 16/166 [00:08<01:09,  2.15it/s]    avg_loss = 1.71875:  10%|█         | 17/166 [00:08<01:09,  2.15it/s]avg_loss = 1.7335069444444444:  10%|█         | 17/166 [00:08<01:09,  2.15it/s]avg_loss = 1.7335069444444444:  11%|█         | 18/166 [00:08<01:09,  2.14it/s]avg_loss = 1.7532894736842106:  11%|█         | 18/166 [00:09<01:09,  2.14it/s]avg_loss = 1.7532894736842106:  11%|█▏        | 19/166 [00:09<01:08,  2.14it/s]avg_loss = 1.759765625:  11%|█▏        | 19/166 [00:09<01:08,  2.14it/s]       avg_loss = 1.759765625:  12%|█▏        | 20/166 [00:09<01:08,  2.14it/s]avg_loss = 1.7611607142857142:  12%|█▏        | 20/166 [00:10<01:08,  2.14it/s]avg_loss = 1.7611607142857142:  13%|█▎        | 21/166 [00:10<01:07,  2.13it/s]avg_loss = 1.7514204545454546:  13%|█▎        | 21/166 [00:10<01:07,  2.13it/s]avg_loss = 1.7514204545454546:  13%|█▎        | 22/166 [00:10<01:07,  2.13it/s]avg_loss = 1.7408288043478262:  13%|█▎        | 22/166 [00:10<01:07,  2.13it/s]avg_loss = 1.7408288043478262:  14%|█▍        | 23/166 [00:10<01:07,  2.13it/s]avg_loss = 1.748046875:  14%|█▍        | 23/166 [00:11<01:07,  2.13it/s]       avg_loss = 1.748046875:  14%|█▍        | 24/166 [00:11<01:06,  2.12it/s]avg_loss = 1.755625:  14%|█▍        | 24/166 [00:11<01:06,  2.12it/s]   avg_loss = 1.755625:  15%|█▌        | 25/166 [00:11<01:06,  2.12it/s]avg_loss = 1.7599158653846154:  15%|█▌        | 25/166 [00:12<01:06,  2.12it/s]avg_loss = 1.7599158653846154:  16%|█▌        | 26/166 [00:12<01:06,  2.11it/s]avg_loss = 1.7664930555555556:  16%|█▌        | 26/166 [00:12<01:06,  2.11it/s]avg_loss = 1.7664930555555556:  16%|█▋        | 27/166 [00:12<01:05,  2.11it/s]avg_loss = 1.7698102678571428:  16%|█▋        | 27/166 [00:13<01:05,  2.11it/s]avg_loss = 1.7698102678571428:  17%|█▋        | 28/166 [00:13<01:05,  2.11it/s]avg_loss = 1.779364224137931:  17%|█▋        | 28/166 [00:13<01:05,  2.11it/s] avg_loss = 1.779364224137931:  17%|█▋        | 29/166 [00:13<01:05,  2.10it/s]avg_loss = 1.7794270833333334:  17%|█▋        | 29/166 [00:14<01:05,  2.10it/s]avg_loss = 1.7794270833333334:  18%|█▊        | 30/166 [00:14<01:04,  2.10it/s]avg_loss = 1.7935987903225807:  18%|█▊        | 30/166 [00:14<01:04,  2.10it/s]avg_loss = 1.7935987903225807:  19%|█▊        | 31/166 [00:14<01:04,  2.10it/s]avg_loss = 1.800048828125:  19%|█▊        | 31/166 [00:15<01:04,  2.10it/s]    avg_loss = 1.800048828125:  19%|█▉        | 32/166 [00:15<01:04,  2.09it/s]avg_loss = 1.8051609848484849:  19%|█▉        | 32/166 [00:15<01:04,  2.09it/s]avg_loss = 1.8051609848484849:  20%|█▉        | 33/166 [00:15<01:03,  2.08it/s]avg_loss = 1.8042279411764706:  20%|█▉        | 33/166 [00:16<01:03,  2.08it/s]avg_loss = 1.8042279411764706:  20%|██        | 34/166 [00:16<01:03,  2.08it/s]avg_loss = 1.7975446428571429:  20%|██        | 34/166 [00:16<01:03,  2.08it/s]avg_loss = 1.7975446428571429:  21%|██        | 35/166 [00:16<01:03,  2.07it/s]avg_loss = 1.7892795138888888:  21%|██        | 35/166 [00:17<01:03,  2.07it/s]avg_loss = 1.7892795138888888:  22%|██▏       | 36/166 [00:17<01:02,  2.08it/s]avg_loss = 1.779349662162162:  22%|██▏       | 36/166 [00:17<01:02,  2.08it/s] avg_loss = 1.779349662162162:  22%|██▏       | 37/166 [00:17<01:02,  2.07it/s]avg_loss = 1.7767269736842106:  22%|██▏       | 37/166 [00:18<01:02,  2.07it/s]avg_loss = 1.7767269736842106:  23%|██▎       | 38/166 [00:18<01:01,  2.07it/s]avg_loss = 1.7746394230769231:  23%|██▎       | 38/166 [00:18<01:01,  2.07it/s]avg_loss = 1.7746394230769231:  23%|██▎       | 39/166 [00:18<01:01,  2.07it/s]avg_loss = 1.7779296875:  23%|██▎       | 39/166 [00:19<01:01,  2.07it/s]      avg_loss = 1.7779296875:  24%|██▍       | 40/166 [00:19<01:01,  2.06it/s]avg_loss = 1.7778201219512195:  24%|██▍       | 40/166 [00:19<01:01,  2.06it/s]avg_loss = 1.7778201219512195:  25%|██▍       | 41/166 [00:19<01:00,  2.06it/s]avg_loss = 1.7652529761904763:  25%|██▍       | 41/166 [00:20<01:00,  2.06it/s]avg_loss = 1.7652529761904763:  25%|██▌       | 42/166 [00:20<01:00,  2.05it/s]avg_loss = 1.7498183139534884:  25%|██▌       | 42/166 [00:20<01:00,  2.05it/s]avg_loss = 1.7498183139534884:  26%|██▌       | 43/166 [00:20<01:00,  2.05it/s]avg_loss = 1.7393465909090908:  26%|██▌       | 43/166 [00:21<01:00,  2.05it/s]avg_loss = 1.7393465909090908:  27%|██▋       | 44/166 [00:21<00:59,  2.05it/s]avg_loss = 1.7255208333333334:  27%|██▋       | 44/166 [00:21<00:59,  2.05it/s]avg_loss = 1.7255208333333334:  27%|██▋       | 45/166 [00:21<00:59,  2.04it/s]avg_loss = 1.7150135869565217:  27%|██▋       | 45/166 [00:22<00:59,  2.04it/s]avg_loss = 1.7150135869565217:  28%|██▊       | 46/166 [00:22<00:58,  2.04it/s]avg_loss = 1.7077792553191489:  28%|██▊       | 46/166 [00:22<00:58,  2.04it/s]avg_loss = 1.7077792553191489:  28%|██▊       | 47/166 [00:22<00:58,  2.04it/s]avg_loss = 1.7088216145833333:  28%|██▊       | 47/166 [00:23<00:58,  2.04it/s]avg_loss = 1.7088216145833333:  29%|██▉       | 48/166 [00:23<00:58,  2.03it/s]avg_loss = 1.719547193877551:  29%|██▉       | 48/166 [00:23<00:58,  2.03it/s] avg_loss = 1.719547193877551:  30%|██▉       | 49/166 [00:23<00:57,  2.03it/s]avg_loss = 1.73015625:  30%|██▉       | 49/166 [00:24<00:57,  2.03it/s]       avg_loss = 1.73015625:  30%|███       | 50/166 [00:24<00:57,  2.03it/s]avg_loss = 1.7372855392156863:  30%|███       | 50/166 [00:24<00:57,  2.03it/s]avg_loss = 1.7372855392156863:  31%|███       | 51/166 [00:24<00:56,  2.02it/s]avg_loss = 1.7423377403846154:  31%|███       | 51/166 [00:25<00:56,  2.02it/s]avg_loss = 1.7423377403846154:  31%|███▏      | 52/166 [00:25<00:56,  2.01it/s]avg_loss = 1.7455778301886793:  31%|███▏      | 52/166 [00:25<00:56,  2.01it/s]avg_loss = 1.7455778301886793:  32%|███▏      | 53/166 [00:25<00:56,  2.01it/s]avg_loss = 1.7463831018518519:  32%|███▏      | 53/166 [00:26<00:56,  2.01it/s]avg_loss = 1.7463831018518519:  33%|███▎      | 54/166 [00:26<00:55,  2.01it/s]avg_loss = 1.7488636363636363:  33%|███▎      | 54/166 [00:26<00:55,  2.01it/s]avg_loss = 1.7488636363636363:  33%|███▎      | 55/166 [00:26<00:55,  2.00it/s]avg_loss = 1.7522321428571428:  33%|███▎      | 55/166 [00:27<00:55,  2.00it/s]avg_loss = 1.7522321428571428:  34%|███▎      | 56/166 [00:27<00:54,  2.00it/s]avg_loss = 1.7473958333333333:  34%|███▎      | 56/166 [00:27<00:54,  2.00it/s]avg_loss = 1.7473958333333333:  34%|███▍      | 57/166 [00:27<00:54,  2.00it/s]avg_loss = 1.7509428879310345:  34%|███▍      | 57/166 [00:28<00:54,  2.00it/s]avg_loss = 1.7509428879310345:  35%|███▍      | 58/166 [00:28<00:54,  2.00it/s]avg_loss = 1.7492055084745763:  35%|███▍      | 58/166 [00:28<00:54,  2.00it/s]avg_loss = 1.7492055084745763:  36%|███▌      | 59/166 [00:28<00:53,  1.99it/s]avg_loss = 1.7444010416666667:  36%|███▌      | 59/166 [00:29<00:53,  1.99it/s]avg_loss = 1.7444010416666667:  36%|███▌      | 60/166 [00:29<00:53,  1.99it/s]avg_loss = 1.7400102459016393:  36%|███▌      | 60/166 [00:29<00:53,  1.99it/s]avg_loss = 1.7400102459016393:  37%|███▋      | 61/166 [00:29<00:52,  1.98it/s]avg_loss = 1.736265120967742:  37%|███▋      | 61/166 [00:30<00:52,  1.98it/s] avg_loss = 1.736265120967742:  37%|███▋      | 62/166 [00:30<00:52,  1.98it/s]avg_loss = 1.730530753968254:  37%|███▋      | 62/166 [00:30<00:52,  1.98it/s]avg_loss = 1.730530753968254:  38%|███▊      | 63/166 [00:30<00:52,  1.98it/s]avg_loss = 1.7261962890625:  38%|███▊      | 63/166 [00:31<00:52,  1.98it/s]  avg_loss = 1.7261962890625:  39%|███▊      | 64/166 [00:31<00:51,  1.98it/s]avg_loss = 1.7194711538461538:  39%|███▊      | 64/166 [00:31<00:51,  1.98it/s]avg_loss = 1.7194711538461538:  39%|███▉      | 65/166 [00:31<00:51,  1.97it/s]avg_loss = 1.7123579545454546:  39%|███▉      | 65/166 [00:32<00:51,  1.97it/s]avg_loss = 1.7123579545454546:  40%|███▉      | 66/166 [00:32<00:48,  2.08it/s]avg_loss = 1.7067397388059702:  40%|███▉      | 66/166 [00:32<00:48,  2.08it/s]avg_loss = 1.7067397388059702:  40%|████      | 67/166 [00:32<00:47,  2.06it/s]avg_loss = 1.7055376838235294:  40%|████      | 67/166 [00:33<00:47,  2.06it/s]avg_loss = 1.7055376838235294:  41%|████      | 68/166 [00:33<00:47,  2.05it/s]avg_loss = 1.707427536231884:  41%|████      | 68/166 [00:33<00:47,  2.05it/s] avg_loss = 1.707427536231884:  42%|████▏     | 69/166 [00:33<00:47,  2.03it/s]avg_loss = 1.7103794642857142:  42%|████▏     | 69/166 [00:34<00:47,  2.03it/s]avg_loss = 1.7103794642857142:  42%|████▏     | 70/166 [00:34<00:47,  2.01it/s]avg_loss = 1.7143485915492958:  42%|████▏     | 70/166 [00:34<00:47,  2.01it/s]avg_loss = 1.7143485915492958:  43%|████▎     | 71/166 [00:34<00:47,  2.00it/s]avg_loss = 1.7191840277777777:  43%|████▎     | 71/166 [00:35<00:47,  2.00it/s]avg_loss = 1.7191840277777777:  43%|████▎     | 72/166 [00:35<00:47,  1.99it/s]avg_loss = 1.7251712328767124:  43%|████▎     | 72/166 [00:35<00:47,  1.99it/s]avg_loss = 1.7251712328767124:  44%|████▍     | 73/166 [00:35<00:46,  1.99it/s]avg_loss = 1.7195945945945945:  44%|████▍     | 73/166 [00:36<00:46,  1.99it/s]avg_loss = 1.7195945945945945:  45%|████▍     | 74/166 [00:36<00:46,  1.97it/s]avg_loss = 1.7151041666666667:  45%|████▍     | 74/166 [00:36<00:46,  1.97it/s]avg_loss = 1.7151041666666667:  45%|████▌     | 75/166 [00:36<00:46,  1.96it/s]avg_loss = 1.7142269736842106:  45%|████▌     | 75/166 [00:37<00:46,  1.96it/s]avg_loss = 1.7142269736842106:  46%|████▌     | 76/166 [00:37<00:46,  1.96it/s]avg_loss = 1.7108360389610389:  46%|████▌     | 76/166 [00:37<00:46,  1.96it/s]avg_loss = 1.7108360389610389:  46%|████▋     | 77/166 [00:37<00:45,  1.95it/s]avg_loss = 1.7073317307692308:  46%|████▋     | 77/166 [00:38<00:45,  1.95it/s]avg_loss = 1.7073317307692308:  47%|████▋     | 78/166 [00:38<00:45,  1.94it/s]avg_loss = 1.704806170886076:  47%|████▋     | 78/166 [00:38<00:45,  1.94it/s] avg_loss = 1.704806170886076:  48%|████▊     | 79/166 [00:38<00:45,  1.93it/s]avg_loss = 1.7013671875:  48%|████▊     | 79/166 [00:39<00:45,  1.93it/s]     avg_loss = 1.7013671875:  48%|████▊     | 80/166 [00:39<00:44,  1.93it/s]avg_loss = 1.6920814043209877:  48%|████▊     | 80/166 [00:39<00:44,  1.93it/s]avg_loss = 1.6920814043209877:  49%|████▉     | 81/166 [00:39<00:44,  1.91it/s]avg_loss = 1.6937404725609757:  49%|████▉     | 81/166 [00:40<00:44,  1.91it/s]avg_loss = 1.6937404725609757:  49%|████▉     | 82/166 [00:40<00:43,  1.91it/s]avg_loss = 1.6957360692771084:  49%|████▉     | 82/166 [00:40<00:43,  1.91it/s]avg_loss = 1.6957360692771084:  50%|█████     | 83/166 [00:40<00:43,  1.90it/s]avg_loss = 1.6989862351190477:  50%|█████     | 83/166 [00:41<00:43,  1.90it/s]avg_loss = 1.6989862351190477:  51%|█████     | 84/166 [00:41<00:43,  1.89it/s]avg_loss = 1.700873161764706:  51%|█████     | 84/166 [00:41<00:43,  1.89it/s] avg_loss = 1.700873161764706:  51%|█████     | 85/166 [00:41<00:43,  1.88it/s]avg_loss = 1.6998092296511629:  51%|█████     | 85/166 [00:42<00:43,  1.88it/s]avg_loss = 1.6998092296511629:  52%|█████▏    | 86/166 [00:42<00:42,  1.87it/s]avg_loss = 1.7001167385057472:  52%|█████▏    | 86/166 [00:42<00:42,  1.87it/s]avg_loss = 1.7001167385057472:  52%|█████▏    | 87/166 [00:42<00:42,  1.87it/s]avg_loss = 1.7003284801136365:  52%|█████▏    | 87/166 [00:43<00:42,  1.87it/s]avg_loss = 1.7003284801136365:  53%|█████▎    | 88/166 [00:43<00:42,  1.85it/s]avg_loss = 1.7014132724719102:  53%|█████▎    | 88/166 [00:44<00:42,  1.85it/s]avg_loss = 1.7014132724719102:  54%|█████▎    | 89/166 [00:44<00:41,  1.85it/s]avg_loss = 1.7012586805555556:  54%|█████▎    | 89/166 [00:44<00:41,  1.85it/s]avg_loss = 1.7012586805555556:  54%|█████▍    | 90/166 [00:44<00:41,  1.85it/s]avg_loss = 1.7017084478021978:  54%|█████▍    | 90/166 [00:45<00:41,  1.85it/s]avg_loss = 1.7017084478021978:  55%|█████▍    | 91/166 [00:45<00:40,  1.84it/s]avg_loss = 1.702827785326087:  55%|█████▍    | 91/166 [00:45<00:40,  1.84it/s] avg_loss = 1.702827785326087:  55%|█████▌    | 92/166 [00:45<00:40,  1.84it/s]avg_loss = 1.7066952284946237:  55%|█████▌    | 92/166 [00:46<00:40,  1.84it/s]avg_loss = 1.7066952284946237:  56%|█████▌    | 93/166 [00:46<00:39,  1.83it/s]avg_loss = 1.7057430186170213:  56%|█████▌    | 93/166 [00:46<00:39,  1.83it/s]avg_loss = 1.7057430186170213:  57%|█████▋    | 94/166 [00:46<00:39,  1.81it/s]avg_loss = 1.7048930921052632:  57%|█████▋    | 94/166 [00:47<00:39,  1.81it/s]avg_loss = 1.7048930921052632:  57%|█████▋    | 95/166 [00:47<00:39,  1.81it/s]avg_loss = 1.7045491536458333:  57%|█████▋    | 95/166 [00:47<00:39,  1.81it/s]avg_loss = 1.7045491536458333:  58%|█████▊    | 96/166 [00:47<00:38,  1.80it/s]avg_loss = 1.7043733891752577:  58%|█████▊    | 96/166 [00:48<00:38,  1.80it/s]avg_loss = 1.7043733891752577:  58%|█████▊    | 97/166 [00:48<00:38,  1.80it/s]avg_loss = 1.702686543367347:  58%|█████▊    | 97/166 [00:49<00:38,  1.80it/s] avg_loss = 1.702686543367347:  59%|█████▉    | 98/166 [00:49<00:38,  1.78it/s]avg_loss = 1.700323547979798:  59%|█████▉    | 98/166 [00:49<00:38,  1.78it/s]avg_loss = 1.700323547979798:  60%|█████▉    | 99/166 [00:49<00:37,  1.77it/s]avg_loss = 1.6976953125:  60%|█████▉    | 99/166 [00:50<00:37,  1.77it/s]     avg_loss = 1.6976953125:  60%|██████    | 100/166 [00:50<00:37,  1.76it/s]avg_loss = 1.6982131806930694:  60%|██████    | 100/166 [00:50<00:37,  1.76it/s]avg_loss = 1.6982131806930694:  61%|██████    | 101/166 [00:50<00:37,  1.75it/s]avg_loss = 1.6991038602941178:  61%|██████    | 101/166 [00:51<00:37,  1.75it/s]avg_loss = 1.6991038602941178:  61%|██████▏   | 102/166 [00:51<00:36,  1.76it/s]avg_loss = 1.7001289441747574:  61%|██████▏   | 102/166 [00:51<00:36,  1.76it/s]avg_loss = 1.7001289441747574:  62%|██████▏   | 103/166 [00:51<00:36,  1.75it/s]avg_loss = 1.7024113581730769:  62%|██████▏   | 103/166 [00:52<00:36,  1.75it/s]avg_loss = 1.7024113581730769:  63%|██████▎   | 104/166 [00:52<00:35,  1.74it/s]avg_loss = 1.7089657738095239:  63%|██████▎   | 104/166 [00:53<00:35,  1.74it/s]avg_loss = 1.7089657738095239:  63%|██████▎   | 105/166 [00:53<00:35,  1.74it/s]avg_loss = 1.7142172759433962:  63%|██████▎   | 105/166 [00:53<00:35,  1.74it/s]avg_loss = 1.7142172759433962:  64%|██████▍   | 106/166 [00:53<00:34,  1.73it/s]avg_loss = 1.7177643107476634:  64%|██████▍   | 106/166 [00:54<00:34,  1.73it/s]avg_loss = 1.7177643107476634:  64%|██████▍   | 107/166 [00:54<00:33,  1.74it/s]avg_loss = 1.7209563078703705:  64%|██████▍   | 107/166 [00:54<00:33,  1.74it/s]avg_loss = 1.7209563078703705:  65%|██████▌   | 108/166 [00:54<00:33,  1.72it/s]avg_loss = 1.7256665711009174:  65%|██████▌   | 108/166 [00:55<00:33,  1.72it/s]avg_loss = 1.7256665711009174:  66%|██████▌   | 109/166 [00:55<00:33,  1.71it/s]avg_loss = 1.7291548295454546:  66%|██████▌   | 109/166 [00:55<00:33,  1.71it/s]avg_loss = 1.7291548295454546:  66%|██████▋   | 110/166 [00:55<00:32,  1.71it/s]avg_loss = 1.7306798986486487:  66%|██████▋   | 110/166 [00:56<00:32,  1.71it/s]avg_loss = 1.7306798986486487:  67%|██████▋   | 111/166 [00:56<00:32,  1.71it/s]avg_loss = 1.7319684709821428:  67%|██████▋   | 111/166 [00:57<00:32,  1.71it/s]avg_loss = 1.7319684709821428:  67%|██████▋   | 112/166 [00:57<00:31,  1.69it/s]avg_loss = 1.7322663163716814:  67%|██████▋   | 112/166 [00:57<00:31,  1.69it/s]avg_loss = 1.7322663163716814:  68%|██████▊   | 113/166 [00:57<00:31,  1.69it/s]avg_loss = 1.733655427631579:  68%|██████▊   | 113/166 [00:58<00:31,  1.69it/s] avg_loss = 1.733655427631579:  69%|██████▊   | 114/166 [00:58<00:30,  1.68it/s]avg_loss = 1.730672554347826:  69%|██████▊   | 114/166 [00:58<00:30,  1.68it/s]avg_loss = 1.730672554347826:  69%|██████▉   | 115/166 [00:58<00:30,  1.67it/s]avg_loss = 1.7299636314655173:  69%|██████▉   | 115/166 [00:59<00:30,  1.67it/s]avg_loss = 1.7299636314655173:  70%|██████▉   | 116/166 [00:59<00:30,  1.66it/s]avg_loss = 1.7309361645299146:  70%|██████▉   | 116/166 [01:00<00:30,  1.66it/s]avg_loss = 1.7309361645299146:  70%|███████   | 117/166 [01:00<00:29,  1.67it/s]avg_loss = 1.7310977224576272:  70%|███████   | 117/166 [01:00<00:29,  1.67it/s]avg_loss = 1.7310977224576272:  71%|███████   | 118/166 [01:00<00:29,  1.65it/s]avg_loss = 1.73046875:  71%|███████   | 118/166 [01:01<00:29,  1.65it/s]        avg_loss = 1.73046875:  72%|███████▏  | 119/166 [01:01<00:28,  1.65it/s]avg_loss = 1.7310221354166666:  72%|███████▏  | 119/166 [01:01<00:28,  1.65it/s]avg_loss = 1.7310221354166666:  72%|███████▏  | 120/166 [01:01<00:27,  1.65it/s]avg_loss = 1.73046875:  72%|███████▏  | 120/166 [01:02<00:27,  1.65it/s]        avg_loss = 1.73046875:  73%|███████▎  | 121/166 [01:02<00:27,  1.64it/s]avg_loss = 1.7307569159836065:  73%|███████▎  | 121/166 [01:03<00:27,  1.64it/s]avg_loss = 1.7307569159836065:  73%|███████▎  | 122/166 [01:03<00:26,  1.63it/s]avg_loss = 1.7309768800813008:  73%|███████▎  | 122/166 [01:03<00:26,  1.63it/s]avg_loss = 1.7309768800813008:  74%|███████▍  | 123/166 [01:03<00:26,  1.62it/s]avg_loss = 1.729555191532258:  74%|███████▍  | 123/166 [01:04<00:26,  1.62it/s] avg_loss = 1.729555191532258:  75%|███████▍  | 124/166 [01:04<00:25,  1.62it/s]avg_loss = 1.72790625:  75%|███████▍  | 124/166 [01:05<00:25,  1.62it/s]       avg_loss = 1.72790625:  75%|███████▌  | 125/166 [01:05<00:25,  1.61it/s]avg_loss = 1.7256634424603174:  75%|███████▌  | 125/166 [01:05<00:25,  1.61it/s]avg_loss = 1.7256634424603174:  76%|███████▌  | 126/166 [01:05<00:22,  1.77it/s]avg_loss = 1.7234559547244095:  76%|███████▌  | 126/166 [01:05<00:22,  1.77it/s]avg_loss = 1.7234559547244095:  77%|███████▋  | 127/166 [01:05<00:20,  1.89it/s]avg_loss = 1.721954345703125:  77%|███████▋  | 127/166 [01:06<00:20,  1.89it/s] avg_loss = 1.721954345703125:  77%|███████▋  | 128/166 [01:06<00:19,  1.92it/s]avg_loss = 1.7205971414728682:  77%|███████▋  | 128/166 [01:06<00:19,  1.92it/s]avg_loss = 1.7205971414728682:  78%|███████▊  | 129/166 [01:06<00:19,  1.94it/s]avg_loss = 1.7204627403846153:  78%|███████▊  | 129/166 [01:07<00:19,  1.94it/s]avg_loss = 1.7204627403846153:  78%|███████▊  | 130/166 [01:07<00:18,  1.95it/s]avg_loss = 1.721463501908397:  78%|███████▊  | 130/166 [01:07<00:18,  1.95it/s] avg_loss = 1.721463501908397:  79%|███████▉  | 131/166 [01:07<00:17,  1.96it/s]avg_loss = 1.7220348011363635:  79%|███████▉  | 131/166 [01:08<00:17,  1.96it/s]avg_loss = 1.7220348011363635:  80%|███████▉  | 132/166 [01:08<00:17,  1.96it/s]avg_loss = 1.7229499530075187:  80%|███████▉  | 132/166 [01:09<00:17,  1.96it/s]avg_loss = 1.7229499530075187:  80%|████████  | 133/166 [01:09<00:16,  1.96it/s]avg_loss = 1.724259561567164:  80%|████████  | 133/166 [01:09<00:16,  1.96it/s] avg_loss = 1.724259561567164:  81%|████████  | 134/166 [01:09<00:16,  1.96it/s]avg_loss = 1.7221932870370371:  81%|████████  | 134/166 [01:10<00:16,  1.96it/s]avg_loss = 1.7221932870370371:  81%|████████▏ | 135/166 [01:10<00:15,  1.95it/s]avg_loss = 1.7224551930147058:  81%|████████▏ | 135/166 [01:10<00:15,  1.95it/s]avg_loss = 1.7224551930147058:  82%|████████▏ | 136/166 [01:10<00:15,  1.94it/s]avg_loss = 1.72265625:  82%|████████▏ | 136/166 [01:11<00:15,  1.94it/s]        avg_loss = 1.72265625:  83%|████████▎ | 137/166 [01:11<00:14,  1.94it/s]avg_loss = 1.7234771286231885:  83%|████████▎ | 137/166 [01:11<00:14,  1.94it/s]avg_loss = 1.7234771286231885:  83%|████████▎ | 138/166 [01:11<00:14,  1.93it/s]avg_loss = 1.72265625:  83%|████████▎ | 138/166 [01:12<00:14,  1.93it/s]        avg_loss = 1.72265625:  84%|████████▎ | 139/166 [01:12<00:14,  1.93it/s]avg_loss = 1.7213448660714286:  84%|████████▎ | 139/166 [01:12<00:14,  1.93it/s]avg_loss = 1.7213448660714286:  84%|████████▍ | 140/166 [01:12<00:13,  1.92it/s]avg_loss = 1.719996675531915:  84%|████████▍ | 140/166 [01:13<00:13,  1.92it/s] avg_loss = 1.719996675531915:  85%|████████▍ | 141/166 [01:13<00:13,  1.92it/s]avg_loss = 1.719602772887324:  85%|████████▍ | 141/166 [01:13<00:13,  1.92it/s]avg_loss = 1.719602772887324:  86%|████████▌ | 142/166 [01:13<00:12,  1.91it/s]avg_loss = 1.7179578234265733:  86%|████████▌ | 142/166 [01:14<00:12,  1.91it/s]avg_loss = 1.7179578234265733:  86%|████████▌ | 143/166 [01:14<00:12,  1.90it/s]avg_loss = 1.7191569010416667:  86%|████████▌ | 143/166 [01:14<00:12,  1.90it/s]avg_loss = 1.7191569010416667:  87%|████████▋ | 144/166 [01:14<00:11,  1.89it/s]avg_loss = 1.7183997844827585:  87%|████████▋ | 144/166 [01:15<00:11,  1.89it/s]avg_loss = 1.7183997844827585:  87%|████████▋ | 145/166 [01:15<00:11,  1.88it/s]avg_loss = 1.7182416523972603:  87%|████████▋ | 145/166 [01:15<00:11,  1.88it/s]avg_loss = 1.7182416523972603:  88%|████████▊ | 146/166 [01:15<00:10,  1.87it/s]avg_loss = 1.7171290391156462:  88%|████████▊ | 146/166 [01:16<00:10,  1.87it/s]avg_loss = 1.7171290391156462:  89%|████████▊ | 147/166 [01:16<00:10,  1.86it/s]avg_loss = 1.7162426097972974:  89%|████████▊ | 147/166 [01:16<00:10,  1.86it/s]avg_loss = 1.7162426097972974:  89%|████████▉ | 148/166 [01:16<00:09,  1.85it/s]avg_loss = 1.7145291526845639:  89%|████████▉ | 148/166 [01:17<00:09,  1.85it/s]avg_loss = 1.7145291526845639:  90%|████████▉ | 149/166 [01:17<00:09,  1.84it/s]avg_loss = 1.7154947916666667:  90%|████████▉ | 149/166 [01:18<00:09,  1.84it/s]avg_loss = 1.7154947916666667:  90%|█████████ | 150/166 [01:18<00:08,  1.84it/s]avg_loss = 1.714636796357616:  90%|█████████ | 150/166 [01:18<00:08,  1.84it/s] avg_loss = 1.714636796357616:  91%|█████████ | 151/166 [01:18<00:08,  1.84it/s]avg_loss = 1.7144582648026316:  91%|█████████ | 151/166 [01:19<00:08,  1.84it/s]avg_loss = 1.7144582648026316:  92%|█████████▏| 152/166 [01:19<00:07,  1.83it/s]avg_loss = 1.7142310049019607:  92%|█████████▏| 152/166 [01:19<00:07,  1.83it/s]avg_loss = 1.7142310049019607:  92%|█████████▏| 153/166 [01:19<00:07,  1.81it/s]avg_loss = 1.7157315340909092:  92%|█████████▏| 153/166 [01:20<00:07,  1.81it/s]avg_loss = 1.7157315340909092:  93%|█████████▎| 154/166 [01:20<00:06,  1.82it/s]avg_loss = 1.715196572580645:  93%|█████████▎| 154/166 [01:20<00:06,  1.82it/s] avg_loss = 1.715196572580645:  93%|█████████▎| 155/166 [01:20<00:06,  1.81it/s]avg_loss = 1.7150691105769231:  93%|█████████▎| 155/166 [01:21<00:06,  1.81it/s]avg_loss = 1.7150691105769231:  94%|█████████▍| 156/166 [01:21<00:05,  1.80it/s]avg_loss = 1.7132513933121019:  94%|█████████▍| 156/166 [01:21<00:05,  1.80it/s]avg_loss = 1.7132513933121019:  95%|█████████▍| 157/166 [01:21<00:05,  1.80it/s]avg_loss = 1.7089349287974684:  95%|█████████▍| 157/166 [01:22<00:05,  1.80it/s]avg_loss = 1.7089349287974684:  95%|█████████▌| 158/166 [01:22<00:04,  1.78it/s]avg_loss = 1.7096845518867925:  95%|█████████▌| 158/166 [01:23<00:04,  1.78it/s]avg_loss = 1.7096845518867925:  96%|█████████▌| 159/166 [01:23<00:03,  1.78it/s]avg_loss = 1.7111083984375:  96%|█████████▌| 159/166 [01:23<00:03,  1.78it/s]   avg_loss = 1.7111083984375:  96%|█████████▋| 160/166 [01:23<00:03,  1.77it/s]avg_loss = 1.7134850543478262:  96%|█████████▋| 160/166 [01:24<00:03,  1.77it/s]avg_loss = 1.7134850543478262:  97%|█████████▋| 161/166 [01:24<00:02,  1.76it/s]avg_loss = 1.7136622299382716:  97%|█████████▋| 161/166 [01:24<00:02,  1.76it/s]avg_loss = 1.7136622299382716:  98%|█████████▊| 162/166 [01:24<00:02,  1.75it/s]avg_loss = 1.713262078220859:  98%|█████████▊| 162/166 [01:25<00:02,  1.75it/s] avg_loss = 1.713262078220859:  98%|█████████▊| 163/166 [01:25<00:01,  1.74it/s]avg_loss = 1.7138671875:  98%|█████████▊| 163/166 [01:25<00:01,  1.74it/s]     avg_loss = 1.7138671875:  99%|█████████▉| 164/166 [01:25<00:01,  1.74it/s]avg_loss = 1.7139914772727274:  99%|█████████▉| 164/166 [01:26<00:01,  1.74it/s]avg_loss = 1.7139914772727274:  99%|█████████▉| 165/166 [01:26<00:00,  1.73it/s]avg_loss = 1.7159967996987953:  99%|█████████▉| 165/166 [01:27<00:00,  1.73it/s]avg_loss = 1.7159967996987953: 100%|██████████| 166/166 [01:27<00:00,  1.73it/s]avg_loss = 1.7159967996987953: 100%|██████████| 166/166 [01:27<00:00,  1.91it/s]
I0303 05:23:30.958069 3001608 eval_ppl.py:105] wikitext2 perplexity: 5.562216758728027
wikitext2 perplexity: 5.562
Running with lmbda=1000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.43it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  9.13it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  9.70it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.62it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.68it/s]
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:21,  1.46it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:21,  1.41it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:20,  1.40it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:19,  1.42it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:20,  1.30it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:04<00:21,  1.23it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:05<00:21,  1.17it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:06<00:19,  1.23it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:06<00:17,  1.35it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:07<00:14,  1.49it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:07<00:13,  1.60it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:08<00:11,  1.72it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:08<00:10,  1.80it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:09<00:09,  1.84it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:09<00:08,  1.97it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:10<00:07,  2.07it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:10<00:06,  2.17it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:11<00:06,  2.15it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:11<00:06,  2.16it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:12<00:05,  2.18it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:12<00:05,  2.20it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:12<00:04,  2.15it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:13<00:04,  2.15it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:13<00:03,  2.12it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:14<00:03,  2.15it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:14<00:02,  2.13it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:15<00:02,  2.18it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:15<00:01,  2.23it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:16<00:01,  2.29it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:16<00:00,  2.29it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:17<00:00,  2.16it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:17<00:00,  2.12it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:17<00:00,  1.82it/s]
pseudo compress quantization...:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-03 05:24:20 - INFO - layer0_self_attn.q_proj | mse: 0.013335575099200568, bpp_loss: 4.336262124590576, bpp: 0
2025-03-03 05:24:31 - INFO - layer0_self_attn.k_proj | mse: 0.011307243335875935, bpp_loss: 4.454912415065337, bpp: 0
2025-03-03 05:24:41 - INFO - layer0_self_attn.v_proj | mse: 0.006523879132741014, bpp_loss: 4.25505034532398, bpp: 0
2025-03-03 05:24:52 - INFO - layer0_self_attn.o_proj | mse: 0.007249799780514821, bpp_loss: 4.12412007607054, bpp: 0
2025-03-03 05:25:04 - INFO - layer0_mlp.gate_proj | mse: 0.00661196957352567, bpp_loss: 4.5946824778477815, bpp: 0
2025-03-03 05:25:16 - INFO - layer0_mlp.up_proj | mse: 0.006602841868239174, bpp_loss: 4.5752797597196215, bpp: 0
2025-03-03 05:25:53 - INFO - layer0_mlp.down_proj | mse: 0.007342762710036004, bpp_loss: 4.6215109453471594, bpp: 0
pseudo compress quantization...:   3%|▎         | 1/32 [01:46<54:48, 106.07s/it]2025-03-03 05:26:04 - INFO - layer1_self_attn.q_proj | mse: 0.012121187000821574, bpp_loss: 5.105159106373321, bpp: 0
2025-03-03 05:26:17 - INFO - layer1_self_attn.k_proj | mse: 0.01369662772055544, bpp_loss: 5.130988970573526, bpp: 0
2025-03-03 05:26:31 - INFO - layer1_self_attn.v_proj | mse: 0.007583327600416626, bpp_loss: 4.2066712861415, bpp: 0
2025-03-03 05:26:42 - INFO - layer1_self_attn.o_proj | mse: 0.008285901706383266, bpp_loss: 4.161497461493127, bpp: 0
2025-03-03 05:26:54 - INFO - layer1_mlp.gate_proj | mse: 0.007014311923550752, bpp_loss: 4.714062458034172, bpp: 0
2025-03-03 05:27:06 - INFO - layer1_mlp.up_proj | mse: 0.006988692904496854, bpp_loss: 4.640480771920709, bpp: 0
2025-03-03 05:27:38 - INFO - layer1_mlp.down_proj | mse: 0.005450910908497337, bpp_loss: 4.659764350500217, bpp: 0
pseudo compress quantization...:   6%|▋         | 2/32 [03:31<52:51, 105.72s/it]2025-03-03 05:27:52 - INFO - layer2_self_attn.q_proj | mse: 0.006793089710556775, bpp_loss: 5.267951658926904, bpp: 0
2025-03-03 05:28:05 - INFO - layer2_self_attn.k_proj | mse: 0.006849716753142013, bpp_loss: 5.354628489294555, bpp: 0
2025-03-03 05:28:16 - INFO - layer2_self_attn.v_proj | mse: 0.006418429680252842, bpp_loss: 4.4518967032199726, bpp: 0
2025-03-03 05:28:27 - INFO - layer2_self_attn.o_proj | mse: 0.006566185369644442, bpp_loss: 4.435233067139052, bpp: 0
2025-03-03 05:28:42 - INFO - layer2_mlp.gate_proj | mse: 0.006408197797508857, bpp_loss: 4.754166325510934, bpp: 0
2025-03-03 05:28:56 - INFO - layer2_mlp.up_proj | mse: 0.006377837330364891, bpp_loss: 4.664172564914753, bpp: 0
2025-03-03 05:29:28 - INFO - layer2_mlp.down_proj | mse: 0.0055072725348220474, bpp_loss: 4.674082499127402, bpp: 0
pseudo compress quantization...:   9%|▉         | 3/32 [05:21<52:03, 107.70s/it]2025-03-03 05:29:39 - INFO - layer3_self_attn.q_proj | mse: 0.0061754380619519315, bpp_loss: 5.174301990598906, bpp: 0
2025-03-03 05:29:50 - INFO - layer3_self_attn.k_proj | mse: 0.006206992649619207, bpp_loss: 5.245902188413311, bpp: 0
2025-03-03 05:30:02 - INFO - layer3_self_attn.v_proj | mse: 0.005887518383222172, bpp_loss: 4.40763963671634, bpp: 0
2025-03-03 05:30:15 - INFO - layer3_self_attn.o_proj | mse: 0.0056721902622873435, bpp_loss: 4.395302366814576, bpp: 0
2025-03-03 05:30:29 - INFO - layer3_mlp.gate_proj | mse: 0.005910869102160485, bpp_loss: 4.773576170725878, bpp: 0
2025-03-03 05:30:41 - INFO - layer3_mlp.up_proj | mse: 0.005883006828934612, bpp_loss: 4.671590831217378, bpp: 0
2025-03-03 05:31:18 - INFO - layer3_mlp.down_proj | mse: 0.005395800265577997, bpp_loss: 4.6750451323338025, bpp: 0
pseudo compress quantization...:  12%|█▎        | 4/32 [07:11<50:39, 108.57s/it]2025-03-03 05:31:29 - INFO - layer4_self_attn.q_proj | mse: 0.006082673310354428, bpp_loss: 5.269374366267584, bpp: 0
2025-03-03 05:31:40 - INFO - layer4_self_attn.k_proj | mse: 0.006119689547525902, bpp_loss: 5.311404600506648, bpp: 0
2025-03-03 05:31:51 - INFO - layer4_self_attn.v_proj | mse: 0.005765779222495877, bpp_loss: 4.453770352236461, bpp: 0
2025-03-03 05:32:01 - INFO - layer4_self_attn.o_proj | mse: 0.005735110043463912, bpp_loss: 4.446495687123388, bpp: 0
2025-03-03 05:32:14 - INFO - layer4_mlp.gate_proj | mse: 0.005836799673681504, bpp_loss: 4.800995802463487, bpp: 0
2025-03-03 05:32:29 - INFO - layer4_mlp.up_proj | mse: 0.005791396683547231, bpp_loss: 4.662376560097517, bpp: 0
2025-03-03 05:33:03 - INFO - layer4_mlp.down_proj | mse: 0.0053974905214846085, bpp_loss: 4.660804015389362, bpp: 0
pseudo compress quantization...:  16%|█▌        | 5/32 [08:56<48:17, 107.33s/it]2025-03-03 05:33:17 - INFO - layer5_self_attn.q_proj | mse: 0.005973037631353291, bpp_loss: 5.287833591515664, bpp: 0
2025-03-03 05:33:31 - INFO - layer5_self_attn.k_proj | mse: 0.006032096741175646, bpp_loss: 5.363503533881158, bpp: 0
2025-03-03 05:33:41 - INFO - layer5_self_attn.v_proj | mse: 0.005680345437120559, bpp_loss: 4.474899188848212, bpp: 0
2025-03-03 05:33:52 - INFO - layer5_self_attn.o_proj | mse: 0.005920937217782938, bpp_loss: 4.458484567003325, bpp: 0
2025-03-03 05:34:04 - INFO - layer5_mlp.gate_proj | mse: 0.005820295963266829, bpp_loss: 4.80977128220852, bpp: 0
2025-03-03 05:34:16 - INFO - layer5_mlp.up_proj | mse: 0.005772768834571345, bpp_loss: 4.663047613186198, bpp: 0
2025-03-03 05:34:51 - INFO - layer5_mlp.down_proj | mse: 0.005362967475779814, bpp_loss: 4.662732903910584, bpp: 0
pseudo compress quantization...:  19%|█▉        | 6/32 [10:44<46:31, 107.38s/it]2025-03-03 05:35:04 - INFO - layer6_self_attn.q_proj | mse: 0.005855589352802785, bpp_loss: 5.150267703458667, bpp: 0
2025-03-03 05:35:15 - INFO - layer6_self_attn.k_proj | mse: 0.005875476101521295, bpp_loss: 5.184892685734667, bpp: 0
2025-03-03 05:35:27 - INFO - layer6_self_attn.v_proj | mse: 0.005598334507541136, bpp_loss: 4.410166619345546, bpp: 0
2025-03-03 05:35:42 - INFO - layer6_self_attn.o_proj | mse: 0.005803413616125624, bpp_loss: 4.412594872293994, bpp: 0
2025-03-03 05:35:55 - INFO - layer6_mlp.gate_proj | mse: 0.005729941113162131, bpp_loss: 4.833474420530852, bpp: 0
2025-03-03 05:36:07 - INFO - layer6_mlp.up_proj | mse: 0.00567485256861402, bpp_loss: 4.658930837674889, bpp: 0
2025-03-03 05:36:39 - INFO - layer6_mlp.down_proj | mse: 0.005374321726713698, bpp_loss: 4.656875477540631, bpp: 0
pseudo compress quantization...:  22%|██▏       | 7/32 [12:32<44:49, 107.57s/it]2025-03-03 05:36:50 - INFO - layer7_self_attn.q_proj | mse: 0.005809615460006337, bpp_loss: 5.143061850394588, bpp: 0
2025-03-03 05:37:03 - INFO - layer7_self_attn.k_proj | mse: 0.0058217685535854975, bpp_loss: 5.155895418138243, bpp: 0
2025-03-03 05:37:17 - INFO - layer7_self_attn.v_proj | mse: 0.005567882968832207, bpp_loss: 4.419259477988817, bpp: 0
2025-03-03 05:37:27 - INFO - layer7_self_attn.o_proj | mse: 0.005570536659825893, bpp_loss: 4.4182809757767245, bpp: 0
2025-03-03 05:37:40 - INFO - layer7_mlp.gate_proj | mse: 0.005683533455613979, bpp_loss: 4.832115682145191, bpp: 0
2025-03-03 05:37:55 - INFO - layer7_mlp.up_proj | mse: 0.005632637672767884, bpp_loss: 4.662756380733362, bpp: 0
2025-03-03 05:38:28 - INFO - layer7_mlp.down_proj | mse: 0.005398542080564264, bpp_loss: 4.658361340894602, bpp: 0
pseudo compress quantization...:  25%|██▌       | 8/32 [14:21<43:16, 108.20s/it]2025-03-03 05:38:39 - INFO - layer8_self_attn.q_proj | mse: 0.0058308004459263155, bpp_loss: 5.161244346410967, bpp: 0
2025-03-03 05:38:50 - INFO - layer8_self_attn.k_proj | mse: 0.005853377098670631, bpp_loss: 5.182373441697564, bpp: 0
2025-03-03 05:39:01 - INFO - layer8_self_attn.v_proj | mse: 0.005577361367859053, bpp_loss: 4.443842029839288, bpp: 0
2025-03-03 05:39:14 - INFO - layer8_self_attn.o_proj | mse: 0.005767433795933397, bpp_loss: 4.442165925400332, bpp: 0
2025-03-03 05:39:28 - INFO - layer8_mlp.gate_proj | mse: 0.005662210683317605, bpp_loss: 4.809976075970849, bpp: 0
2025-03-03 05:39:42 - INFO - layer8_mlp.up_proj | mse: 0.005621017163409935, bpp_loss: 4.677521092427331, bpp: 0
2025-03-03 05:40:18 - INFO - layer8_mlp.down_proj | mse: 0.005413807743205506, bpp_loss: 4.669955445973333, bpp: 0
pseudo compress quantization...:  28%|██▊       | 9/32 [16:11<41:40, 108.73s/it]2025-03-03 05:40:29 - INFO - layer9_self_attn.q_proj | mse: 0.005795335937181143, bpp_loss: 5.185411048762035, bpp: 0
2025-03-03 05:40:40 - INFO - layer9_self_attn.k_proj | mse: 0.005833485280127624, bpp_loss: 5.230395778082311, bpp: 0
2025-03-03 05:40:51 - INFO - layer9_self_attn.v_proj | mse: 0.005557740060665975, bpp_loss: 4.461050411686301, bpp: 0
2025-03-03 05:41:02 - INFO - layer9_self_attn.o_proj | mse: 0.005816112440098819, bpp_loss: 4.457513602799736, bpp: 0
2025-03-03 05:41:14 - INFO - layer9_mlp.gate_proj | mse: 0.005637846420561725, bpp_loss: 4.796080458649369, bpp: 0
2025-03-03 05:41:27 - INFO - layer9_mlp.up_proj | mse: 0.005603377812308005, bpp_loss: 4.685570780707653, bpp: 0
2025-03-03 05:42:03 - INFO - layer9_mlp.down_proj | mse: 0.005410219722296607, bpp_loss: 4.677514154464006, bpp: 0
pseudo compress quantization...:  31%|███▏      | 10/32 [17:56<39:23, 107.44s/it]2025-03-03 05:42:15 - INFO - layer10_self_attn.q_proj | mse: 0.005782803331025374, bpp_loss: 5.175305312674027, bpp: 0
2025-03-03 05:42:29 - INFO - layer10_self_attn.k_proj | mse: 0.005820887128383719, bpp_loss: 5.226591521757655, bpp: 0
2025-03-03 05:42:41 - INFO - layer10_self_attn.v_proj | mse: 0.005544444445923458, bpp_loss: 4.4535589081351645, bpp: 0
2025-03-03 05:42:52 - INFO - layer10_self_attn.o_proj | mse: 0.005946214276332372, bpp_loss: 4.455912604113109, bpp: 0
2025-03-03 05:43:04 - INFO - layer10_mlp.gate_proj | mse: 0.005638198377547382, bpp_loss: 4.790596703803817, bpp: 0
2025-03-03 05:43:16 - INFO - layer10_mlp.up_proj | mse: 0.005609496366214844, bpp_loss: 4.698704912218937, bpp: 0
2025-03-03 05:43:49 - INFO - layer10_mlp.down_proj | mse: 0.005422349572162128, bpp_loss: 4.687275092399051, bpp: 0
pseudo compress quantization...:  34%|███▍      | 11/32 [19:42<37:31, 107.22s/it]2025-03-03 05:44:02 - INFO - layer11_self_attn.q_proj | mse: 0.005743998532197539, bpp_loss: 5.057708986569196, bpp: 0
2025-03-03 05:44:14 - INFO - layer11_self_attn.k_proj | mse: 0.0057636390322976395, bpp_loss: 5.063798689574469, bpp: 0
2025-03-03 05:44:25 - INFO - layer11_self_attn.v_proj | mse: 0.005546801190053767, bpp_loss: 4.488300842756871, bpp: 0
2025-03-03 05:44:38 - INFO - layer11_self_attn.o_proj | mse: 0.005742158185905248, bpp_loss: 4.4904563972959295, bpp: 0
2025-03-03 05:44:54 - INFO - layer11_mlp.gate_proj | mse: 0.005589452604526373, bpp_loss: 4.78663075299457, bpp: 0
2025-03-03 05:45:06 - INFO - layer11_mlp.up_proj | mse: 0.005566353338777133, bpp_loss: 4.709283231822557, bpp: 0
2025-03-03 05:45:37 - INFO - layer11_mlp.down_proj | mse: 0.005401877856650365, bpp_loss: 4.695621964283461, bpp: 0
pseudo compress quantization...:  38%|███▊      | 12/32 [21:30<35:47, 107.37s/it]2025-03-03 05:45:48 - INFO - layer12_self_attn.q_proj | mse: 0.005710661176959041, bpp_loss: 5.119124080287293, bpp: 0
2025-03-03 05:46:00 - INFO - layer12_self_attn.k_proj | mse: 0.005744930293513963, bpp_loss: 5.173448038636707, bpp: 0
2025-03-03 05:46:13 - INFO - layer12_self_attn.v_proj | mse: 0.0054987396159556536, bpp_loss: 4.477883010811638, bpp: 0
2025-03-03 05:46:26 - INFO - layer12_self_attn.o_proj | mse: 0.005898318557921364, bpp_loss: 4.481311159208417, bpp: 0
2025-03-03 05:46:38 - INFO - layer12_mlp.gate_proj | mse: 0.005579235611233735, bpp_loss: 4.778700862686302, bpp: 0
2025-03-03 05:46:51 - INFO - layer12_mlp.up_proj | mse: 0.005559665078080343, bpp_loss: 4.720969396708316, bpp: 0
2025-03-03 05:47:27 - INFO - layer12_mlp.down_proj | mse: 0.005380831044502008, bpp_loss: 4.705739961850435, bpp: 0
pseudo compress quantization...:  41%|████      | 13/32 [23:20<34:15, 108.20s/it]2025-03-03 05:47:38 - INFO - layer13_self_attn.q_proj | mse: 0.005682578694811342, bpp_loss: 5.106222142989282, bpp: 0
2025-03-03 05:47:49 - INFO - layer13_self_attn.k_proj | mse: 0.0057085101228511684, bpp_loss: 5.1381553037208505, bpp: 0
2025-03-03 05:47:59 - INFO - layer13_self_attn.v_proj | mse: 0.005490388166488353, bpp_loss: 4.511535034340341, bpp: 0
2025-03-03 05:48:11 - INFO - layer13_self_attn.o_proj | mse: 0.005785050349668363, bpp_loss: 4.509427151759155, bpp: 0
2025-03-03 05:48:26 - INFO - layer13_mlp.gate_proj | mse: 0.005592306528322771, bpp_loss: 4.773701461941697, bpp: 0
2025-03-03 05:48:41 - INFO - layer13_mlp.up_proj | mse: 0.00557727909690306, bpp_loss: 4.733760845695818, bpp: 0
2025-03-03 05:49:14 - INFO - layer13_mlp.down_proj | mse: 0.005411591438266736, bpp_loss: 4.715006473149325, bpp: 0
pseudo compress quantization...:  44%|████▍     | 14/32 [25:07<32:18, 107.67s/it]2025-03-03 05:49:27 - INFO - layer14_self_attn.q_proj | mse: 0.005714323038766921, bpp_loss: 5.097433716873638, bpp: 0
2025-03-03 05:49:38 - INFO - layer14_self_attn.k_proj | mse: 0.005746833650482141, bpp_loss: 5.1342934606364, bpp: 0
2025-03-03 05:49:49 - INFO - layer14_self_attn.v_proj | mse: 0.0055251396406311, bpp_loss: 4.4945064703933895, bpp: 0
2025-03-03 05:49:59 - INFO - layer14_self_attn.o_proj | mse: 0.005745851190920751, bpp_loss: 4.494394006440416, bpp: 0
2025-03-03 05:50:11 - INFO - layer14_mlp.gate_proj | mse: 0.005577473131382135, bpp_loss: 4.770883156636427, bpp: 0
2025-03-03 05:50:24 - INFO - layer14_mlp.up_proj | mse: 0.005568376687206156, bpp_loss: 4.73549968809929, bpp: 0
2025-03-03 05:51:00 - INFO - layer14_mlp.down_proj | mse: 0.005383424099720983, bpp_loss: 4.717504772379301, bpp: 0
pseudo compress quantization...:  47%|████▋     | 15/32 [26:53<30:25, 107.35s/it]2025-03-03 05:51:12 - INFO - layer15_self_attn.q_proj | mse: 0.0057083478884672745, bpp_loss: 5.085874743410386, bpp: 0
2025-03-03 05:51:24 - INFO - layer15_self_attn.k_proj | mse: 0.005739476973007152, bpp_loss: 5.145187111455016, bpp: 0
2025-03-03 05:51:39 - INFO - layer15_self_attn.v_proj | mse: 0.005521256879327294, bpp_loss: 4.532246234477498, bpp: 0
2025-03-03 05:51:49 - INFO - layer15_self_attn.o_proj | mse: 0.0058868611166892106, bpp_loss: 4.524113430292346, bpp: 0
2025-03-03 05:52:02 - INFO - layer15_mlp.gate_proj | mse: 0.005594379463340892, bpp_loss: 4.7776381652369055, bpp: 0
2025-03-03 05:52:14 - INFO - layer15_mlp.up_proj | mse: 0.005584364050312626, bpp_loss: 4.742475678754407, bpp: 0
2025-03-03 05:52:46 - INFO - layer15_mlp.down_proj | mse: 0.005404771665311906, bpp_loss: 4.720553291225156, bpp: 0
pseudo compress quantization...:  50%|█████     | 16/32 [28:39<28:28, 106.78s/it]2025-03-03 05:52:59 - INFO - layer16_self_attn.q_proj | mse: 0.005731527488196372, bpp_loss: 5.066396659705788, bpp: 0
2025-03-03 05:53:12 - INFO - layer16_self_attn.k_proj | mse: 0.00577321918994474, bpp_loss: 5.11533817963209, bpp: 0
2025-03-03 05:53:23 - INFO - layer16_self_attn.v_proj | mse: 0.005568753530124349, bpp_loss: 4.574450214044191, bpp: 0
2025-03-03 05:53:35 - INFO - layer16_self_attn.o_proj | mse: 0.005653490938892018, bpp_loss: 4.576244256575592, bpp: 0
2025-03-03 05:53:50 - INFO - layer16_mlp.gate_proj | mse: 0.005669737065167066, bpp_loss: 4.786738873481057, bpp: 0
2025-03-03 05:54:03 - INFO - layer16_mlp.up_proj | mse: 0.005656913542038852, bpp_loss: 4.741858750755011, bpp: 0
2025-03-03 05:54:35 - INFO - layer16_mlp.down_proj | mse: 0.0054093082992296175, bpp_loss: 4.720905843125873, bpp: 0
pseudo compress quantization...:  53%|█████▎    | 17/32 [30:28<26:53, 107.58s/it]2025-03-03 05:54:46 - INFO - layer17_self_attn.q_proj | mse: 0.005745162419049846, bpp_loss: 5.063235012290534, bpp: 0
2025-03-03 05:54:57 - INFO - layer17_self_attn.k_proj | mse: 0.005772476460655978, bpp_loss: 5.101563502568752, bpp: 0
2025-03-03 05:55:11 - INFO - layer17_self_attn.v_proj | mse: 0.005581910448953851, bpp_loss: 4.5725068565807305, bpp: 0
2025-03-03 05:55:23 - INFO - layer17_self_attn.o_proj | mse: 0.005616100983229074, bpp_loss: 4.573376243584789, bpp: 0
2025-03-03 05:55:37 - INFO - layer17_mlp.gate_proj | mse: 0.005625350600109281, bpp_loss: 4.8006409797384295, bpp: 0
2025-03-03 05:55:49 - INFO - layer17_mlp.up_proj | mse: 0.00560512250566569, bpp_loss: 4.737801837973123, bpp: 0
2025-03-03 05:56:26 - INFO - layer17_mlp.down_proj | mse: 0.005349346255348733, bpp_loss: 4.721011270184157, bpp: 0
pseudo compress quantization...:  56%|█████▋    | 18/32 [32:19<25:20, 108.58s/it]2025-03-03 05:56:37 - INFO - layer18_self_attn.q_proj | mse: 0.005676968209745134, bpp_loss: 5.0319140435312875, bpp: 0
2025-03-03 05:56:48 - INFO - layer18_self_attn.k_proj | mse: 0.005697951126945888, bpp_loss: 5.06671487953281, bpp: 0
2025-03-03 05:56:59 - INFO - layer18_self_attn.v_proj | mse: 0.005545052462732737, bpp_loss: 4.622507753549144, bpp: 0
2025-03-03 05:57:10 - INFO - layer18_self_attn.o_proj | mse: 0.005513499323586746, bpp_loss: 4.619098720722832, bpp: 0
2025-03-03 05:57:23 - INFO - layer18_mlp.gate_proj | mse: 0.005634271874269429, bpp_loss: 4.8125628704248475, bpp: 0
2025-03-03 05:57:38 - INFO - layer18_mlp.up_proj | mse: 0.005613693439794174, bpp_loss: 4.734146682502225, bpp: 0
2025-03-03 05:58:12 - INFO - layer18_mlp.down_proj | mse: 0.005315523889707265, bpp_loss: 4.72003045041374, bpp: 0
pseudo compress quantization...:  59%|█████▉    | 19/32 [34:05<23:20, 107.76s/it]2025-03-03 05:58:26 - INFO - layer19_self_attn.q_proj | mse: 0.005693455641138627, bpp_loss: 5.008480728487484, bpp: 0
2025-03-03 05:58:38 - INFO - layer19_self_attn.k_proj | mse: 0.00571756736431447, bpp_loss: 5.040683264436666, bpp: 0
2025-03-03 05:58:49 - INFO - layer19_self_attn.v_proj | mse: 0.005566922237090087, bpp_loss: 4.632853824645281, bpp: 0
2025-03-03 05:59:00 - INFO - layer19_self_attn.o_proj | mse: 0.005409741743959176, bpp_loss: 4.626223328988999, bpp: 0
2025-03-03 05:59:12 - INFO - layer19_mlp.gate_proj | mse: 0.0056114421008522375, bpp_loss: 4.817271216317665, bpp: 0
2025-03-03 05:59:24 - INFO - layer19_mlp.up_proj | mse: 0.005587036336277223, bpp_loss: 4.734150787079057, bpp: 0
2025-03-03 06:00:00 - INFO - layer19_mlp.down_proj | mse: 0.005291392468326277, bpp_loss: 4.723400657303458, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 20/32 [35:53<21:33, 107.80s/it]2025-03-03 06:00:12 - INFO - layer20_self_attn.q_proj | mse: 0.005685335955076888, bpp_loss: 5.017373432870954, bpp: 0
2025-03-03 06:00:23 - INFO - layer20_self_attn.k_proj | mse: 0.005707708728450373, bpp_loss: 5.047931085864548, bpp: 0
2025-03-03 06:00:37 - INFO - layer20_self_attn.v_proj | mse: 0.005563290794229187, bpp_loss: 4.651238833321258, bpp: 0
2025-03-03 06:00:50 - INFO - layer20_self_attn.o_proj | mse: 0.005460089084644646, bpp_loss: 4.650704143452458, bpp: 0
2025-03-03 06:01:02 - INFO - layer20_mlp.gate_proj | mse: 0.005649015260771161, bpp_loss: 4.825630706323441, bpp: 0
2025-03-03 06:01:14 - INFO - layer20_mlp.up_proj | mse: 0.005620002255287439, bpp_loss: 4.733920824649029, bpp: 0
2025-03-03 06:01:46 - INFO - layer20_mlp.down_proj | mse: 0.0053054502663352765, bpp_loss: 4.724359687720967, bpp: 0
pseudo compress quantization...:  66%|██████▌   | 21/32 [37:38<19:38, 107.18s/it]2025-03-03 06:01:58 - INFO - layer21_self_attn.q_proj | mse: 0.005675308566483117, bpp_loss: 4.979674913280178, bpp: 0
2025-03-03 06:02:10 - INFO - layer21_self_attn.k_proj | mse: 0.005686713498818698, bpp_loss: 4.997730912466068, bpp: 0
2025-03-03 06:02:24 - INFO - layer21_self_attn.v_proj | mse: 0.005576993081322402, bpp_loss: 4.688035530445632, bpp: 0
2025-03-03 06:02:34 - INFO - layer21_self_attn.o_proj | mse: 0.005361584205325948, bpp_loss: 4.681543925427832, bpp: 0
2025-03-03 06:02:48 - INFO - layer21_mlp.gate_proj | mse: 0.005610822807473189, bpp_loss: 4.834954121604908, bpp: 0
2025-03-03 06:03:03 - INFO - layer21_mlp.up_proj | mse: 0.005582298661079803, bpp_loss: 4.731927309878344, bpp: 0
2025-03-03 06:03:35 - INFO - layer21_mlp.down_proj | mse: 0.005246241184030137, bpp_loss: 4.724750640997013, bpp: 0
pseudo compress quantization...:  69%|██████▉   | 22/32 [39:28<17:58, 107.80s/it]2025-03-03 06:03:46 - INFO - layer22_self_attn.q_proj | mse: 0.005636604077754251, bpp_loss: 5.019086292188149, bpp: 0
2025-03-03 06:03:56 - INFO - layer22_self_attn.k_proj | mse: 0.005648670260056326, bpp_loss: 5.0404932191595435, bpp: 0
2025-03-03 06:04:07 - INFO - layer22_self_attn.v_proj | mse: 0.005524715586024987, bpp_loss: 4.692157617770135, bpp: 0
2025-03-03 06:04:21 - INFO - layer22_self_attn.o_proj | mse: 0.005335809217584876, bpp_loss: 4.674757034284994, bpp: 0
2025-03-03 06:04:36 - INFO - layer22_mlp.gate_proj | mse: 0.005594785857777621, bpp_loss: 4.843679131030343, bpp: 0
2025-03-03 06:04:48 - INFO - layer22_mlp.up_proj | mse: 0.00556317009535097, bpp_loss: 4.731839732981698, bpp: 0
2025-03-03 06:05:25 - INFO - layer22_mlp.down_proj | mse: 0.005248016060529011, bpp_loss: 4.725276127977427, bpp: 0
pseudo compress quantization...:  72%|███████▏  | 23/32 [41:18<16:15, 108.40s/it]2025-03-03 06:05:36 - INFO - layer23_self_attn.q_proj | mse: 0.005603108471565393, bpp_loss: 5.0119664066587575, bpp: 0
2025-03-03 06:05:46 - INFO - layer23_self_attn.k_proj | mse: 0.005612371765181452, bpp_loss: 5.024878272030037, bpp: 0
2025-03-03 06:05:56 - INFO - layer23_self_attn.v_proj | mse: 0.005517479135816632, bpp_loss: 4.751248927670531, bpp: 0
2025-03-03 06:06:07 - INFO - layer23_self_attn.o_proj | mse: 0.005194049682051552, bpp_loss: 4.733849471434951, bpp: 0
2025-03-03 06:06:19 - INFO - layer23_mlp.gate_proj | mse: 0.00554856900080056, bpp_loss: 4.843330208558676, bpp: 0
2025-03-03 06:06:34 - INFO - layer23_mlp.up_proj | mse: 0.00551730842926755, bpp_loss: 4.738059150098368, bpp: 0
2025-03-03 06:07:08 - INFO - layer23_mlp.down_proj | mse: 0.00519816105706929, bpp_loss: 4.732951591960912, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 24/32 [43:01<14:15, 106.96s/it]2025-03-03 06:07:21 - INFO - layer24_self_attn.q_proj | mse: 0.005542204669886893, bpp_loss: 4.954379729053471, bpp: 0
2025-03-03 06:07:35 - INFO - layer24_self_attn.k_proj | mse: 0.005555711044476344, bpp_loss: 4.962987164792139, bpp: 0
2025-03-03 06:07:46 - INFO - layer24_self_attn.v_proj | mse: 0.005474494628821613, bpp_loss: 4.739832159073558, bpp: 0
2025-03-03 06:07:57 - INFO - layer24_self_attn.o_proj | mse: 0.005315208347872978, bpp_loss: 4.7226627971976995, bpp: 0
2025-03-03 06:08:09 - INFO - layer24_mlp.gate_proj | mse: 0.005515654824318098, bpp_loss: 4.846907848275678, bpp: 0
2025-03-03 06:08:21 - INFO - layer24_mlp.up_proj | mse: 0.005484892274614714, bpp_loss: 4.742082031660302, bpp: 0
2025-03-03 06:08:55 - INFO - layer24_mlp.down_proj | mse: 0.005165596142649162, bpp_loss: 4.737535888329148, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 25/32 [44:48<12:27, 106.82s/it]2025-03-03 06:09:09 - INFO - layer25_self_attn.q_proj | mse: 0.005506471822573718, bpp_loss: 4.977144397154916, bpp: 0
2025-03-03 06:09:19 - INFO - layer25_self_attn.k_proj | mse: 0.005515642410827553, bpp_loss: 4.983355582400691, bpp: 0
2025-03-03 06:09:31 - INFO - layer25_self_attn.v_proj | mse: 0.005454532919126616, bpp_loss: 4.789958094654139, bpp: 0
2025-03-03 06:09:44 - INFO - layer25_self_attn.o_proj | mse: 0.005268282052331798, bpp_loss: 4.7790868690935895, bpp: 0
2025-03-03 06:09:59 - INFO - layer25_mlp.gate_proj | mse: 0.005474787929116871, bpp_loss: 4.848991428436928, bpp: 0
2025-03-03 06:10:11 - INFO - layer25_mlp.up_proj | mse: 0.00544395207749917, bpp_loss: 4.747386480919843, bpp: 0
2025-03-03 06:10:43 - INFO - layer25_mlp.down_proj | mse: 0.005137677276033558, bpp_loss: 4.742404232364755, bpp: 0
pseudo compress quantization...:  81%|████████▏ | 26/32 [46:36<10:43, 107.18s/it]2025-03-03 06:10:54 - INFO - layer26_self_attn.q_proj | mse: 0.005478910808088534, bpp_loss: 4.949922229279764, bpp: 0
2025-03-03 06:11:07 - INFO - layer26_self_attn.k_proj | mse: 0.005486248292656501, bpp_loss: 4.9629237309563905, bpp: 0
2025-03-03 06:11:19 - INFO - layer26_self_attn.v_proj | mse: 0.005426268647557679, bpp_loss: 4.807807667995803, bpp: 0
2025-03-03 06:11:31 - INFO - layer26_self_attn.o_proj | mse: 0.00541348653361061, bpp_loss: 4.799137020483613, bpp: 0
2025-03-03 06:11:44 - INFO - layer26_mlp.gate_proj | mse: 0.005462396132704599, bpp_loss: 4.852802512517502, bpp: 0
2025-03-03 06:11:58 - INFO - layer26_mlp.up_proj | mse: 0.0054305599255503306, bpp_loss: 4.7522594054597755, bpp: 0
2025-03-03 06:12:33 - INFO - layer26_mlp.down_proj | mse: 0.005129913740931893, bpp_loss: 4.744207300505666, bpp: 0
pseudo compress quantization...:  84%|████████▍ | 27/32 [48:26<09:00, 108.03s/it]2025-03-03 06:12:44 - INFO - layer27_self_attn.q_proj | mse: 0.005482048667321652, bpp_loss: 5.020697358006146, bpp: 0
2025-03-03 06:12:55 - INFO - layer27_self_attn.k_proj | mse: 0.005485484197678788, bpp_loss: 5.038610345567577, bpp: 0
2025-03-03 06:13:05 - INFO - layer27_self_attn.v_proj | mse: 0.005415449279951464, bpp_loss: 4.814205644419417, bpp: 0
2025-03-03 06:13:17 - INFO - layer27_self_attn.o_proj | mse: 0.0052506709305516494, bpp_loss: 4.813560439506546, bpp: 0
2025-03-03 06:13:31 - INFO - layer27_mlp.gate_proj | mse: 0.005449499307662065, bpp_loss: 4.853342446043741, bpp: 0
2025-03-03 06:13:46 - INFO - layer27_mlp.up_proj | mse: 0.00542060164489646, bpp_loss: 4.75878568348843, bpp: 0
2025-03-03 06:14:20 - INFO - layer27_mlp.down_proj | mse: 0.005137474617799858, bpp_loss: 4.748587201414413, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 28/32 [50:13<07:11, 107.78s/it]2025-03-03 06:14:33 - INFO - layer28_self_attn.q_proj | mse: 0.005471185119816251, bpp_loss: 4.968415086972527, bpp: 0
2025-03-03 06:14:44 - INFO - layer28_self_attn.k_proj | mse: 0.0054758471855712604, bpp_loss: 4.989369111484848, bpp: 0
2025-03-03 06:14:54 - INFO - layer28_self_attn.v_proj | mse: 0.005437407776237507, bpp_loss: 4.856532932026312, bpp: 0
2025-03-03 06:15:05 - INFO - layer28_self_attn.o_proj | mse: 0.005423830786235423, bpp_loss: 4.858748957514763, bpp: 0
2025-03-03 06:15:17 - INFO - layer28_mlp.gate_proj | mse: 0.005443414170804401, bpp_loss: 4.846431636446437, bpp: 0
2025-03-03 06:15:29 - INFO - layer28_mlp.up_proj | mse: 0.00542339142951783, bpp_loss: 4.771595804670523, bpp: 0
2025-03-03 06:16:06 - INFO - layer28_mlp.down_proj | mse: 0.005175063408274041, bpp_loss: 4.7538454519628095, bpp: 0
pseudo compress quantization...:  91%|█████████ | 29/32 [51:59<05:21, 107.25s/it]2025-03-03 06:16:18 - INFO - layer29_self_attn.q_proj | mse: 0.0054685364986470615, bpp_loss: 4.9206097851274535, bpp: 0
2025-03-03 06:16:31 - INFO - layer29_self_attn.k_proj | mse: 0.005475806989105608, bpp_loss: 4.938053937628865, bpp: 0
2025-03-03 06:16:45 - INFO - layer29_self_attn.v_proj | mse: 0.0054495159656568395, bpp_loss: 4.8621601349441335, bpp: 0
2025-03-03 06:16:56 - INFO - layer29_self_attn.o_proj | mse: 0.005341490680194037, bpp_loss: 4.877780046197586, bpp: 0
2025-03-03 06:17:08 - INFO - layer29_mlp.gate_proj | mse: 0.005449952054779906, bpp_loss: 4.848594167031521, bpp: 0
2025-03-03 06:17:20 - INFO - layer29_mlp.up_proj | mse: 0.0054313182769727165, bpp_loss: 4.783261786713156, bpp: 0
2025-03-03 06:17:52 - INFO - layer29_mlp.down_proj | mse: 0.0052248235504328815, bpp_loss: 4.754974125992766, bpp: 0
pseudo compress quantization...:  94%|█████████▍| 30/32 [53:45<03:33, 106.98s/it]2025-03-03 06:18:05 - INFO - layer30_self_attn.q_proj | mse: 0.005491445949156551, bpp_loss: 4.939074455644004, bpp: 0
2025-03-03 06:18:19 - INFO - layer30_self_attn.k_proj | mse: 0.00549344671918113, bpp_loss: 4.964952616428491, bpp: 0
2025-03-03 06:18:29 - INFO - layer30_self_attn.v_proj | mse: 0.0054769256096677665, bpp_loss: 4.900349449715577, bpp: 0
2025-03-03 06:18:42 - INFO - layer30_self_attn.o_proj | mse: 0.005415506134411891, bpp_loss: 4.913280205568299, bpp: 0
2025-03-03 06:18:57 - INFO - layer30_mlp.gate_proj | mse: 0.005487666967665489, bpp_loss: 4.872929868309996, bpp: 0
2025-03-03 06:19:10 - INFO - layer30_mlp.up_proj | mse: 0.005463170114682243, bpp_loss: 4.798129911859368, bpp: 0
2025-03-03 06:19:42 - INFO - layer30_mlp.down_proj | mse: 0.0054129847136234295, bpp_loss: 4.739750489289331, bpp: 0
pseudo compress quantization...:  97%|█████████▋| 31/32 [55:35<01:47, 107.87s/it]2025-03-03 06:19:53 - INFO - layer31_self_attn.q_proj | mse: 0.005609215799432275, bpp_loss: 4.96039585408289, bpp: 0
2025-03-03 06:20:04 - INFO - layer31_self_attn.k_proj | mse: 0.005628238143074103, bpp_loss: 5.014299925183877, bpp: 0
2025-03-03 06:20:18 - INFO - layer31_self_attn.v_proj | mse: 0.005545906366030104, bpp_loss: 4.76386160380207, bpp: 0
2025-03-03 06:20:31 - INFO - layer31_self_attn.o_proj | mse: 0.006012753187938921, bpp_loss: 4.765116537921131, bpp: 0
2025-03-03 06:20:44 - INFO - layer31_mlp.gate_proj | mse: 0.005617533166541207, bpp_loss: 4.94831744451509, bpp: 0
2025-03-03 06:20:57 - INFO - layer31_mlp.up_proj | mse: 0.005588361160581575, bpp_loss: 4.861969976317744, bpp: 0
2025-03-03 06:21:34 - INFO - layer31_mlp.down_proj | mse: 0.006229287228108221, bpp_loss: 4.732626689121473, bpp: 0
pseudo compress quantization...: 100%|██████████| 32/32 [57:26<00:00, 108.91s/it]pseudo compress quantization...: 100%|██████████| 32/32 [57:26<00:00, 107.72s/it]
2025-03-03 06:21:34 - INFO - #### Total | mse: 0.005718048355939219, bpp_loss: 4.770861741460449, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda1000_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_6.59649_bpp_6.05166_MSE_0.00106_total_iter_140000.pth.tar/COL_MSE0.00572_bpploss4.7709_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda1000_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_6.59649_bpp_6.05166_MSE_0.00106_total_iter_140000.pth.tar/COL_MSE0.00572_bpploss4.7709_bpp0
I0303 06:22:07.132665 3039882 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.31it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]
I0303 06:22:09.382455 3039882 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.375:   0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.375:   1%|          | 1/166 [00:00<01:35,  1.74it/s]avg_loss = 1.63671875:   1%|          | 1/166 [00:01<01:35,  1.74it/s]avg_loss = 1.63671875:   1%|          | 2/166 [00:01<01:27,  1.88it/s]avg_loss = 1.7994791666666667:   1%|          | 2/166 [00:01<01:27,  1.88it/s]avg_loss = 1.7994791666666667:   2%|▏         | 3/166 [00:01<01:23,  1.94it/s]avg_loss = 1.830078125:   2%|▏         | 3/166 [00:02<01:23,  1.94it/s]       avg_loss = 1.830078125:   2%|▏         | 4/166 [00:02<01:22,  1.97it/s]avg_loss = 1.7625:   2%|▏         | 4/166 [00:02<01:22,  1.97it/s]     avg_loss = 1.7625:   3%|▎         | 5/166 [00:02<01:21,  1.98it/s]avg_loss = 1.73828125:   3%|▎         | 5/166 [00:03<01:21,  1.98it/s]avg_loss = 1.73828125:   4%|▎         | 6/166 [00:03<01:19,  2.00it/s]avg_loss = 1.6774553571428572:   4%|▎         | 6/166 [00:03<01:19,  2.00it/s]avg_loss = 1.6774553571428572:   4%|▍         | 7/166 [00:03<01:19,  1.99it/s]avg_loss = 1.6201171875:   4%|▍         | 7/166 [00:04<01:19,  1.99it/s]      avg_loss = 1.6201171875:   5%|▍         | 8/166 [00:04<01:19,  1.99it/s]avg_loss = 1.6154513888888888:   5%|▍         | 8/166 [00:04<01:19,  1.99it/s]avg_loss = 1.6154513888888888:   5%|▌         | 9/166 [00:04<01:18,  1.99it/s]avg_loss = 1.621875:   5%|▌         | 9/166 [00:05<01:18,  1.99it/s]          avg_loss = 1.621875:   6%|▌         | 10/166 [00:05<01:18,  1.98it/s]avg_loss = 1.6384943181818181:   6%|▌         | 10/166 [00:05<01:18,  1.98it/s]avg_loss = 1.6384943181818181:   7%|▋         | 11/166 [00:05<01:18,  1.98it/s]avg_loss = 1.6484375:   7%|▋         | 11/166 [00:06<01:18,  1.98it/s]         avg_loss = 1.6484375:   7%|▋         | 12/166 [00:06<01:17,  1.98it/s]avg_loss = 1.6436298076923077:   7%|▋         | 12/166 [00:06<01:17,  1.98it/s]avg_loss = 1.6436298076923077:   8%|▊         | 13/166 [00:06<01:17,  1.98it/s]avg_loss = 1.6568080357142858:   8%|▊         | 13/166 [00:07<01:17,  1.98it/s]avg_loss = 1.6568080357142858:   8%|▊         | 14/166 [00:07<01:16,  1.98it/s]avg_loss = 1.675:   8%|▊         | 14/166 [00:07<01:16,  1.98it/s]             avg_loss = 1.675:   9%|▉         | 15/166 [00:07<01:16,  1.98it/s]avg_loss = 1.69482421875:   9%|▉         | 15/166 [00:08<01:16,  1.98it/s]avg_loss = 1.69482421875:  10%|▉         | 16/166 [00:08<01:11,  2.09it/s]avg_loss = 1.708639705882353:  10%|▉         | 16/166 [00:08<01:11,  2.09it/s]avg_loss = 1.708639705882353:  10%|█         | 17/166 [00:08<01:11,  2.09it/s]avg_loss = 1.7230902777777777:  10%|█         | 17/166 [00:08<01:11,  2.09it/s]avg_loss = 1.7230902777777777:  11%|█         | 18/166 [00:08<01:10,  2.11it/s]avg_loss = 1.743421052631579:  11%|█         | 18/166 [00:09<01:10,  2.11it/s] avg_loss = 1.743421052631579:  11%|█▏        | 19/166 [00:09<01:09,  2.12it/s]avg_loss = 1.749609375:  11%|█▏        | 19/166 [00:09<01:09,  2.12it/s]      avg_loss = 1.749609375:  12%|█▏        | 20/166 [00:09<01:08,  2.13it/s]avg_loss = 1.7503720238095237:  12%|█▏        | 20/166 [00:10<01:08,  2.13it/s]avg_loss = 1.7503720238095237:  13%|█▎        | 21/166 [00:10<01:08,  2.13it/s]avg_loss = 1.7404119318181819:  13%|█▎        | 21/166 [00:10<01:08,  2.13it/s]avg_loss = 1.7404119318181819:  13%|█▎        | 22/166 [00:10<01:07,  2.14it/s]avg_loss = 1.7296195652173914:  13%|█▎        | 22/166 [00:11<01:07,  2.14it/s]avg_loss = 1.7296195652173914:  14%|█▍        | 23/166 [00:11<01:06,  2.13it/s]avg_loss = 1.7369791666666667:  14%|█▍        | 23/166 [00:11<01:06,  2.13it/s]avg_loss = 1.7369791666666667:  14%|█▍        | 24/166 [00:11<01:06,  2.14it/s]avg_loss = 1.744375:  14%|█▍        | 24/166 [00:12<01:06,  2.14it/s]          avg_loss = 1.744375:  15%|█▌        | 25/166 [00:12<01:06,  2.13it/s]avg_loss = 1.7490985576923077:  15%|█▌        | 25/166 [00:12<01:06,  2.13it/s]avg_loss = 1.7490985576923077:  16%|█▌        | 26/166 [00:12<01:05,  2.13it/s]avg_loss = 1.755787037037037:  16%|█▌        | 26/166 [00:13<01:05,  2.13it/s] avg_loss = 1.755787037037037:  16%|█▋        | 27/166 [00:13<01:05,  2.13it/s]avg_loss = 1.7589285714285714:  16%|█▋        | 27/166 [00:13<01:05,  2.13it/s]avg_loss = 1.7589285714285714:  17%|█▋        | 28/166 [00:13<01:05,  2.12it/s]avg_loss = 1.7683189655172413:  17%|█▋        | 28/166 [00:14<01:05,  2.12it/s]avg_loss = 1.7683189655172413:  17%|█▋        | 29/166 [00:14<01:04,  2.12it/s]avg_loss = 1.7682291666666667:  17%|█▋        | 29/166 [00:14<01:04,  2.12it/s]avg_loss = 1.7682291666666667:  18%|█▊        | 30/166 [00:14<01:04,  2.12it/s]avg_loss = 1.7827620967741935:  18%|█▊        | 30/166 [00:15<01:04,  2.12it/s]avg_loss = 1.7827620967741935:  19%|█▊        | 31/166 [00:15<01:03,  2.11it/s]avg_loss = 1.789306640625:  19%|█▊        | 31/166 [00:15<01:03,  2.11it/s]    avg_loss = 1.789306640625:  19%|█▉        | 32/166 [00:15<01:03,  2.11it/s]avg_loss = 1.7945075757575757:  19%|█▉        | 32/166 [00:16<01:03,  2.11it/s]avg_loss = 1.7945075757575757:  20%|█▉        | 33/166 [00:16<01:03,  2.10it/s]avg_loss = 1.7934283088235294:  20%|█▉        | 33/166 [00:16<01:03,  2.10it/s]avg_loss = 1.7934283088235294:  20%|██        | 34/166 [00:16<01:02,  2.10it/s]avg_loss = 1.7870535714285714:  20%|██        | 34/166 [00:16<01:02,  2.10it/s]avg_loss = 1.7870535714285714:  21%|██        | 35/166 [00:16<01:02,  2.10it/s]avg_loss = 1.7786458333333333:  21%|██        | 35/166 [00:17<01:02,  2.10it/s]avg_loss = 1.7786458333333333:  22%|██▏       | 36/166 [00:17<01:02,  2.09it/s]avg_loss = 1.7687922297297298:  22%|██▏       | 36/166 [00:17<01:02,  2.09it/s]avg_loss = 1.7687922297297298:  22%|██▏       | 37/166 [00:17<01:01,  2.09it/s]avg_loss = 1.7660361842105263:  22%|██▏       | 37/166 [00:18<01:01,  2.09it/s]avg_loss = 1.7660361842105263:  23%|██▎       | 38/166 [00:18<01:01,  2.09it/s]avg_loss = 1.7638221153846154:  23%|██▎       | 38/166 [00:18<01:01,  2.09it/s]avg_loss = 1.7638221153846154:  23%|██▎       | 39/166 [00:18<01:01,  2.08it/s]avg_loss = 1.7671875:  23%|██▎       | 39/166 [00:19<01:01,  2.08it/s]         avg_loss = 1.7671875:  24%|██▍       | 40/166 [00:19<01:00,  2.08it/s]avg_loss = 1.7669588414634145:  24%|██▍       | 40/166 [00:19<01:00,  2.08it/s]avg_loss = 1.7669588414634145:  25%|██▍       | 41/166 [00:19<01:00,  2.08it/s]avg_loss = 1.7546502976190477:  25%|██▍       | 41/166 [00:20<01:00,  2.08it/s]avg_loss = 1.7546502976190477:  25%|██▌       | 42/166 [00:20<00:59,  2.07it/s]avg_loss = 1.7390988372093024:  25%|██▌       | 42/166 [00:20<00:59,  2.07it/s]avg_loss = 1.7390988372093024:  26%|██▌       | 43/166 [00:20<00:59,  2.07it/s]avg_loss = 1.7288707386363635:  26%|██▌       | 43/166 [00:21<00:59,  2.07it/s]avg_loss = 1.7288707386363635:  27%|██▋       | 44/166 [00:21<00:59,  2.06it/s]avg_loss = 1.7151041666666667:  27%|██▋       | 44/166 [00:21<00:59,  2.06it/s]avg_loss = 1.7151041666666667:  27%|██▋       | 45/166 [00:21<00:58,  2.06it/s]avg_loss = 1.7046535326086956:  27%|██▋       | 45/166 [00:22<00:58,  2.06it/s]avg_loss = 1.7046535326086956:  28%|██▊       | 46/166 [00:22<00:58,  2.06it/s]avg_loss = 1.6976396276595744:  28%|██▊       | 46/166 [00:22<00:58,  2.06it/s]avg_loss = 1.6976396276595744:  28%|██▊       | 47/166 [00:22<00:57,  2.05it/s]avg_loss = 1.6985677083333333:  28%|██▊       | 47/166 [00:23<00:57,  2.05it/s]avg_loss = 1.6985677083333333:  29%|██▉       | 48/166 [00:23<00:57,  2.05it/s]avg_loss = 1.7095025510204083:  29%|██▉       | 48/166 [00:23<00:57,  2.05it/s]avg_loss = 1.7095025510204083:  30%|██▉       | 49/166 [00:23<00:57,  2.05it/s]avg_loss = 1.72:  30%|██▉       | 49/166 [00:24<00:57,  2.05it/s]              avg_loss = 1.72:  30%|███       | 50/166 [00:24<00:56,  2.04it/s]avg_loss = 1.7270220588235294:  30%|███       | 50/166 [00:24<00:56,  2.04it/s]avg_loss = 1.7270220588235294:  31%|███       | 51/166 [00:24<00:56,  2.04it/s]avg_loss = 1.7319711538461537:  31%|███       | 51/166 [00:25<00:56,  2.04it/s]avg_loss = 1.7319711538461537:  31%|███▏      | 52/166 [00:25<00:56,  2.03it/s]avg_loss = 1.7354068396226414:  31%|███▏      | 52/166 [00:25<00:56,  2.03it/s]avg_loss = 1.7354068396226414:  32%|███▏      | 53/166 [00:25<00:55,  2.04it/s]avg_loss = 1.736400462962963:  32%|███▏      | 53/166 [00:26<00:55,  2.04it/s] avg_loss = 1.736400462962963:  33%|███▎      | 54/166 [00:26<00:55,  2.03it/s]avg_loss = 1.7389204545454546:  33%|███▎      | 54/166 [00:26<00:55,  2.03it/s]avg_loss = 1.7389204545454546:  33%|███▎      | 55/166 [00:26<00:54,  2.02it/s]avg_loss = 1.7424665178571428:  33%|███▎      | 55/166 [00:27<00:54,  2.02it/s]avg_loss = 1.7424665178571428:  34%|███▎      | 56/166 [00:27<00:54,  2.02it/s]avg_loss = 1.7375274122807018:  34%|███▎      | 56/166 [00:27<00:54,  2.02it/s]avg_loss = 1.7375274122807018:  34%|███▍      | 57/166 [00:27<00:53,  2.02it/s]avg_loss = 1.7411099137931034:  34%|███▍      | 57/166 [00:28<00:53,  2.02it/s]avg_loss = 1.7411099137931034:  35%|███▍      | 58/166 [00:28<00:53,  2.01it/s]avg_loss = 1.7394067796610169:  35%|███▍      | 58/166 [00:28<00:53,  2.01it/s]avg_loss = 1.7394067796610169:  36%|███▌      | 59/166 [00:28<00:53,  2.01it/s]avg_loss = 1.734375:  36%|███▌      | 59/166 [00:29<00:53,  2.01it/s]          avg_loss = 1.734375:  36%|███▌      | 60/166 [00:29<00:52,  2.01it/s]avg_loss = 1.7298924180327868:  36%|███▌      | 60/166 [00:29<00:52,  2.01it/s]avg_loss = 1.7298924180327868:  37%|███▋      | 61/166 [00:29<00:52,  2.01it/s]avg_loss = 1.7259324596774193:  37%|███▋      | 61/166 [00:30<00:52,  2.01it/s]avg_loss = 1.7259324596774193:  37%|███▋      | 62/166 [00:30<00:51,  2.00it/s]avg_loss = 1.7199900793650793:  37%|███▋      | 62/166 [00:30<00:51,  2.00it/s]avg_loss = 1.7199900793650793:  38%|███▊      | 63/166 [00:30<00:51,  2.00it/s]avg_loss = 1.7156982421875:  38%|███▊      | 63/166 [00:31<00:51,  2.00it/s]   avg_loss = 1.7156982421875:  39%|███▊      | 64/166 [00:31<00:51,  1.99it/s]avg_loss = 1.7088942307692307:  39%|███▊      | 64/166 [00:31<00:51,  1.99it/s]avg_loss = 1.7088942307692307:  39%|███▉      | 65/166 [00:31<00:50,  1.99it/s]avg_loss = 1.7017045454545454:  39%|███▉      | 65/166 [00:32<00:50,  1.99it/s]avg_loss = 1.7017045454545454:  40%|███▉      | 66/166 [00:32<00:50,  1.99it/s]avg_loss = 1.6957789179104477:  40%|███▉      | 66/166 [00:32<00:50,  1.99it/s]avg_loss = 1.6957789179104477:  40%|████      | 67/166 [00:32<00:49,  1.98it/s]avg_loss = 1.6946231617647058:  40%|████      | 67/166 [00:33<00:49,  1.98it/s]avg_loss = 1.6946231617647058:  41%|████      | 68/166 [00:33<00:49,  1.98it/s]avg_loss = 1.6965579710144927:  41%|████      | 68/166 [00:33<00:49,  1.98it/s]avg_loss = 1.6965579710144927:  42%|████▏     | 69/166 [00:33<00:49,  1.98it/s]avg_loss = 1.6995535714285714:  42%|████▏     | 69/166 [00:34<00:49,  1.98it/s]avg_loss = 1.6995535714285714:  42%|████▏     | 70/166 [00:34<00:48,  1.98it/s]avg_loss = 1.7035651408450705:  42%|████▏     | 70/166 [00:34<00:48,  1.98it/s]avg_loss = 1.7035651408450705:  43%|████▎     | 71/166 [00:34<00:48,  1.97it/s]avg_loss = 1.7085503472222223:  43%|████▎     | 71/166 [00:35<00:48,  1.97it/s]avg_loss = 1.7085503472222223:  43%|████▎     | 72/166 [00:35<00:47,  1.97it/s]avg_loss = 1.714683219178082:  43%|████▎     | 72/166 [00:35<00:47,  1.97it/s] avg_loss = 1.714683219178082:  44%|████▍     | 73/166 [00:35<00:47,  1.97it/s]avg_loss = 1.709037162162162:  44%|████▍     | 73/166 [00:36<00:47,  1.97it/s]avg_loss = 1.709037162162162:  45%|████▍     | 74/166 [00:36<00:46,  1.97it/s]avg_loss = 1.7044791666666668:  45%|████▍     | 74/166 [00:36<00:46,  1.97it/s]avg_loss = 1.7044791666666668:  45%|████▌     | 75/166 [00:36<00:46,  1.96it/s]avg_loss = 1.7035361842105263:  45%|████▌     | 75/166 [00:37<00:46,  1.96it/s]avg_loss = 1.7035361842105263:  46%|████▌     | 76/166 [00:37<00:43,  2.06it/s]avg_loss = 1.7000811688311688:  46%|████▌     | 76/166 [00:37<00:43,  2.06it/s]avg_loss = 1.7000811688311688:  46%|████▋     | 77/166 [00:37<00:42,  2.08it/s]avg_loss = 1.6964142628205128:  46%|████▋     | 77/166 [00:38<00:42,  2.08it/s]avg_loss = 1.6964142628205128:  47%|████▋     | 78/166 [00:38<00:41,  2.10it/s]avg_loss = 1.6938291139240507:  47%|████▋     | 78/166 [00:38<00:41,  2.10it/s]avg_loss = 1.6938291139240507:  48%|████▊     | 79/166 [00:38<00:41,  2.11it/s]avg_loss = 1.69033203125:  48%|████▊     | 79/166 [00:39<00:41,  2.11it/s]     avg_loss = 1.69033203125:  48%|████▊     | 80/166 [00:39<00:40,  2.12it/s]avg_loss = 1.6809895833333333:  48%|████▊     | 80/166 [00:39<00:40,  2.12it/s]avg_loss = 1.6809895833333333:  49%|████▉     | 81/166 [00:39<00:40,  2.12it/s]avg_loss = 1.6826886432926829:  49%|████▉     | 81/166 [00:40<00:40,  2.12it/s]avg_loss = 1.6826886432926829:  49%|████▉     | 82/166 [00:40<00:39,  2.12it/s]avg_loss = 1.6847232680722892:  49%|████▉     | 82/166 [00:40<00:39,  2.12it/s]avg_loss = 1.6847232680722892:  50%|█████     | 83/166 [00:40<00:39,  2.12it/s]avg_loss = 1.6878255208333333:  50%|█████     | 83/166 [00:41<00:39,  2.12it/s]avg_loss = 1.6878255208333333:  51%|█████     | 84/166 [00:41<00:38,  2.12it/s]avg_loss = 1.6896599264705883:  51%|█████     | 84/166 [00:41<00:38,  2.12it/s]avg_loss = 1.6896599264705883:  51%|█████     | 85/166 [00:41<00:38,  2.12it/s]avg_loss = 1.6885446947674418:  51%|█████     | 85/166 [00:41<00:38,  2.12it/s]avg_loss = 1.6885446947674418:  52%|█████▏    | 86/166 [00:41<00:37,  2.12it/s]avg_loss = 1.6888020833333333:  52%|█████▏    | 86/166 [00:42<00:37,  2.12it/s]avg_loss = 1.6888020833333333:  52%|█████▏    | 87/166 [00:42<00:37,  2.11it/s]avg_loss = 1.6890536221590908:  52%|█████▏    | 87/166 [00:42<00:37,  2.11it/s]avg_loss = 1.6890536221590908:  53%|█████▎    | 88/166 [00:42<00:36,  2.11it/s]avg_loss = 1.6902650983146068:  53%|█████▎    | 88/166 [00:43<00:36,  2.11it/s]avg_loss = 1.6902650983146068:  54%|█████▎    | 89/166 [00:43<00:36,  2.11it/s]avg_loss = 1.6901475694444446:  54%|█████▎    | 89/166 [00:43<00:36,  2.11it/s]avg_loss = 1.6901475694444446:  54%|█████▍    | 90/166 [00:43<00:36,  2.10it/s]avg_loss = 1.690633585164835:  54%|█████▍    | 90/166 [00:44<00:36,  2.10it/s] avg_loss = 1.690633585164835:  55%|█████▍    | 91/166 [00:44<00:35,  2.10it/s]avg_loss = 1.6917883831521738:  55%|█████▍    | 91/166 [00:44<00:35,  2.10it/s]avg_loss = 1.6917883831521738:  55%|█████▌    | 92/166 [00:44<00:35,  2.10it/s]avg_loss = 1.6956065188172043:  55%|█████▌    | 92/166 [00:45<00:35,  2.10it/s]avg_loss = 1.6956065188172043:  56%|█████▌    | 93/166 [00:45<00:34,  2.10it/s]avg_loss = 1.6947722739361701:  56%|█████▌    | 93/166 [00:45<00:34,  2.10it/s]avg_loss = 1.6947722739361701:  57%|█████▋    | 94/166 [00:45<00:34,  2.09it/s]avg_loss = 1.6940378289473683:  57%|█████▋    | 94/166 [00:46<00:34,  2.09it/s]avg_loss = 1.6940378289473683:  57%|█████▋    | 95/166 [00:46<00:33,  2.09it/s]avg_loss = 1.6937255859375:  57%|█████▋    | 95/166 [00:46<00:33,  2.09it/s]   avg_loss = 1.6937255859375:  58%|█████▊    | 96/166 [00:46<00:33,  2.08it/s]avg_loss = 1.693580863402062:  58%|█████▊    | 96/166 [00:47<00:33,  2.08it/s]avg_loss = 1.693580863402062:  58%|█████▊    | 97/166 [00:47<00:33,  2.08it/s]avg_loss = 1.6919244260204083:  58%|█████▊    | 97/166 [00:47<00:33,  2.08it/s]avg_loss = 1.6919244260204083:  59%|█████▉    | 98/166 [00:47<00:32,  2.08it/s]avg_loss = 1.6895123106060606:  59%|█████▉    | 98/166 [00:48<00:32,  2.08it/s]avg_loss = 1.6895123106060606:  60%|█████▉    | 99/166 [00:48<00:32,  2.08it/s]avg_loss = 1.6868359375:  60%|█████▉    | 99/166 [00:48<00:32,  2.08it/s]      avg_loss = 1.6868359375:  60%|██████    | 100/166 [00:48<00:31,  2.07it/s]avg_loss = 1.6873066212871286:  60%|██████    | 100/166 [00:49<00:31,  2.07it/s]avg_loss = 1.6873066212871286:  61%|██████    | 101/166 [00:49<00:31,  2.07it/s]avg_loss = 1.6883042279411764:  61%|██████    | 101/166 [00:49<00:31,  2.07it/s]avg_loss = 1.6883042279411764:  61%|██████▏   | 102/166 [00:49<00:31,  2.06it/s]avg_loss = 1.6893583131067962:  61%|██████▏   | 102/166 [00:50<00:31,  2.06it/s]avg_loss = 1.6893583131067962:  62%|██████▏   | 103/166 [00:50<00:30,  2.06it/s]avg_loss = 1.6915189302884615:  62%|██████▏   | 103/166 [00:50<00:30,  2.06it/s]avg_loss = 1.6915189302884615:  63%|██████▎   | 104/166 [00:50<00:30,  2.06it/s]avg_loss = 1.6981770833333334:  63%|██████▎   | 104/166 [00:51<00:30,  2.06it/s]avg_loss = 1.6981770833333334:  63%|██████▎   | 105/166 [00:51<00:29,  2.06it/s]avg_loss = 1.7033829599056605:  63%|██████▎   | 105/166 [00:51<00:29,  2.06it/s]avg_loss = 1.7033829599056605:  64%|██████▍   | 106/166 [00:51<00:29,  2.05it/s]avg_loss = 1.70703125:  64%|██████▍   | 106/166 [00:52<00:29,  2.05it/s]        avg_loss = 1.70703125:  64%|██████▍   | 107/166 [00:52<00:28,  2.05it/s]avg_loss = 1.7101779513888888:  64%|██████▍   | 107/166 [00:52<00:28,  2.05it/s]avg_loss = 1.7101779513888888:  65%|██████▌   | 108/166 [00:52<00:28,  2.04it/s]avg_loss = 1.71484375:  65%|██████▌   | 108/166 [00:53<00:28,  2.04it/s]        avg_loss = 1.71484375:  66%|██████▌   | 109/166 [00:53<00:27,  2.04it/s]avg_loss = 1.7182883522727272:  66%|██████▌   | 109/166 [00:53<00:27,  2.04it/s]avg_loss = 1.7182883522727272:  66%|██████▋   | 110/166 [00:53<00:27,  2.04it/s]avg_loss = 1.7198409346846846:  66%|██████▋   | 110/166 [00:54<00:27,  2.04it/s]avg_loss = 1.7198409346846846:  67%|██████▋   | 111/166 [00:54<00:27,  2.03it/s]avg_loss = 1.7211565290178572:  67%|██████▋   | 111/166 [00:54<00:27,  2.03it/s]avg_loss = 1.7211565290178572:  67%|██████▋   | 112/166 [00:54<00:26,  2.03it/s]avg_loss = 1.7215500553097345:  67%|██████▋   | 112/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7215500553097345:  68%|██████▊   | 113/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7229646381578947:  68%|██████▊   | 113/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7229646381578947:  69%|██████▊   | 114/166 [00:55<00:25,  2.02it/s]avg_loss = 1.7198029891304347:  69%|██████▊   | 114/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7198029891304347:  69%|██████▉   | 115/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7190530711206897:  69%|██████▉   | 115/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7190530711206897:  70%|██████▉   | 116/166 [00:56<00:24,  2.02it/s]avg_loss = 1.7200520833333333:  70%|██████▉   | 116/166 [00:57<00:24,  2.02it/s]avg_loss = 1.7200520833333333:  70%|███████   | 117/166 [00:57<00:24,  2.01it/s]avg_loss = 1.7201734639830508:  70%|███████   | 117/166 [00:57<00:24,  2.01it/s]avg_loss = 1.7201734639830508:  71%|███████   | 118/166 [00:57<00:23,  2.01it/s]avg_loss = 1.7195049894957983:  71%|███████   | 118/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7195049894957983:  72%|███████▏  | 119/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7200846354166666:  72%|███████▏  | 119/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7200846354166666:  72%|███████▏  | 120/166 [00:58<00:22,  2.01it/s]avg_loss = 1.7193633780991735:  72%|███████▏  | 120/166 [00:59<00:22,  2.01it/s]avg_loss = 1.7193633780991735:  73%|███████▎  | 121/166 [00:59<00:22,  2.00it/s]avg_loss = 1.7196144979508197:  73%|███████▎  | 121/166 [00:59<00:22,  2.00it/s]avg_loss = 1.7196144979508197:  73%|███████▎  | 122/166 [00:59<00:21,  2.00it/s]avg_loss = 1.7198615345528456:  73%|███████▎  | 122/166 [01:00<00:21,  2.00it/s]avg_loss = 1.7198615345528456:  74%|███████▍  | 123/166 [01:00<00:21,  1.99it/s]avg_loss = 1.7183404737903225:  74%|███████▍  | 123/166 [01:00<00:21,  1.99it/s]avg_loss = 1.7183404737903225:  75%|███████▍  | 124/166 [01:00<00:21,  1.99it/s]avg_loss = 1.71665625:  75%|███████▍  | 124/166 [01:01<00:21,  1.99it/s]        avg_loss = 1.71665625:  75%|███████▌  | 125/166 [01:01<00:20,  1.99it/s]avg_loss = 1.7144407242063493:  75%|███████▌  | 125/166 [01:01<00:20,  1.99it/s]avg_loss = 1.7144407242063493:  76%|███████▌  | 126/166 [01:01<00:20,  1.98it/s]avg_loss = 1.7121985728346456:  76%|███████▌  | 126/166 [01:02<00:20,  1.98it/s]avg_loss = 1.7121985728346456:  77%|███████▋  | 127/166 [01:02<00:19,  1.99it/s]avg_loss = 1.710662841796875:  77%|███████▋  | 127/166 [01:02<00:19,  1.99it/s] avg_loss = 1.710662841796875:  77%|███████▋  | 128/166 [01:02<00:19,  1.98it/s]avg_loss = 1.7093326065891472:  77%|███████▋  | 128/166 [01:03<00:19,  1.98it/s]avg_loss = 1.7093326065891472:  78%|███████▊  | 129/166 [01:03<00:18,  1.97it/s]avg_loss = 1.7091646634615385:  78%|███████▊  | 129/166 [01:03<00:18,  1.97it/s]avg_loss = 1.7091646634615385:  78%|███████▊  | 130/166 [01:03<00:18,  1.98it/s]avg_loss = 1.7101920324427482:  78%|███████▊  | 130/166 [01:04<00:18,  1.98it/s]avg_loss = 1.7101920324427482:  79%|███████▉  | 131/166 [01:04<00:17,  1.97it/s]avg_loss = 1.7107895359848484:  79%|███████▉  | 131/166 [01:04<00:17,  1.97it/s]avg_loss = 1.7107895359848484:  80%|███████▉  | 132/166 [01:04<00:17,  1.97it/s]avg_loss = 1.7117304981203008:  80%|███████▉  | 132/166 [01:05<00:17,  1.97it/s]avg_loss = 1.7117304981203008:  80%|████████  | 133/166 [01:05<00:16,  1.96it/s]avg_loss = 1.713007229477612:  80%|████████  | 133/166 [01:05<00:16,  1.96it/s] avg_loss = 1.713007229477612:  81%|████████  | 134/166 [01:05<00:16,  1.96it/s]avg_loss = 1.7109664351851852:  81%|████████  | 134/166 [01:06<00:16,  1.96it/s]avg_loss = 1.7109664351851852:  81%|████████▏ | 135/166 [01:06<00:15,  1.95it/s]avg_loss = 1.7112534466911764:  81%|████████▏ | 135/166 [01:06<00:15,  1.95it/s]avg_loss = 1.7112534466911764:  82%|████████▏ | 136/166 [01:06<00:14,  2.04it/s]avg_loss = 1.7115362682481752:  82%|████████▏ | 136/166 [01:07<00:14,  2.04it/s]avg_loss = 1.7115362682481752:  83%|████████▎ | 137/166 [01:07<00:14,  2.07it/s]avg_loss = 1.7123811141304348:  83%|████████▎ | 137/166 [01:07<00:14,  2.07it/s]avg_loss = 1.7123811141304348:  83%|████████▎ | 138/166 [01:07<00:13,  2.09it/s]avg_loss = 1.711527652877698:  83%|████████▎ | 138/166 [01:07<00:13,  2.09it/s] avg_loss = 1.711527652877698:  84%|████████▎ | 139/166 [01:07<00:12,  2.10it/s]avg_loss = 1.7102399553571428:  84%|████████▎ | 139/166 [01:08<00:12,  2.10it/s]avg_loss = 1.7102399553571428:  84%|████████▍ | 140/166 [01:08<00:12,  2.11it/s]avg_loss = 1.708915115248227:  84%|████████▍ | 140/166 [01:08<00:12,  2.11it/s] avg_loss = 1.708915115248227:  85%|████████▍ | 141/166 [01:08<00:11,  2.12it/s]avg_loss = 1.7084892165492958:  85%|████████▍ | 141/166 [01:09<00:11,  2.12it/s]avg_loss = 1.7084892165492958:  86%|████████▌ | 142/166 [01:09<00:11,  2.12it/s]avg_loss = 1.7068673513986015:  86%|████████▌ | 142/166 [01:09<00:11,  2.12it/s]avg_loss = 1.7068673513986015:  86%|████████▌ | 143/166 [01:09<00:10,  2.12it/s]avg_loss = 1.7080349392361112:  86%|████████▌ | 143/166 [01:10<00:10,  2.12it/s]avg_loss = 1.7080349392361112:  87%|████████▋ | 144/166 [01:10<00:10,  2.12it/s]avg_loss = 1.7073006465517242:  87%|████████▋ | 144/166 [01:10<00:10,  2.12it/s]avg_loss = 1.7073006465517242:  87%|████████▋ | 145/166 [01:10<00:09,  2.12it/s]avg_loss = 1.707218535958904:  87%|████████▋ | 145/166 [01:11<00:09,  2.12it/s] avg_loss = 1.707218535958904:  88%|████████▊ | 146/166 [01:11<00:09,  2.11it/s]avg_loss = 1.7060746173469388:  88%|████████▊ | 146/166 [01:11<00:09,  2.11it/s]avg_loss = 1.7060746173469388:  89%|████████▊ | 147/166 [01:11<00:09,  2.11it/s]avg_loss = 1.7052100929054055:  89%|████████▊ | 147/166 [01:12<00:09,  2.11it/s]avg_loss = 1.7052100929054055:  89%|████████▉ | 148/166 [01:12<00:08,  2.11it/s]avg_loss = 1.7035182466442953:  89%|████████▉ | 148/166 [01:12<00:08,  2.11it/s]avg_loss = 1.7035182466442953:  90%|████████▉ | 149/166 [01:12<00:08,  2.11it/s]avg_loss = 1.704453125:  90%|████████▉ | 149/166 [01:13<00:08,  2.11it/s]       avg_loss = 1.704453125:  90%|█████████ | 150/166 [01:13<00:07,  2.10it/s]avg_loss = 1.7035647764900663:  90%|█████████ | 150/166 [01:13<00:07,  2.10it/s]avg_loss = 1.7035647764900663:  91%|█████████ | 151/166 [01:13<00:07,  2.10it/s]avg_loss = 1.7033048930921053:  91%|█████████ | 151/166 [01:14<00:07,  2.10it/s]avg_loss = 1.7033048930921053:  92%|█████████▏| 152/166 [01:14<00:06,  2.10it/s]avg_loss = 1.7030484068627452:  92%|█████████▏| 152/166 [01:14<00:06,  2.10it/s]avg_loss = 1.7030484068627452:  92%|█████████▏| 153/166 [01:14<00:06,  2.09it/s]avg_loss = 1.7045708198051948:  92%|█████████▏| 153/166 [01:15<00:06,  2.09it/s]avg_loss = 1.7045708198051948:  93%|█████████▎| 154/166 [01:15<00:05,  2.09it/s]avg_loss = 1.7040574596774194:  93%|█████████▎| 154/166 [01:15<00:05,  2.09it/s]avg_loss = 1.7040574596774194:  93%|█████████▎| 155/166 [01:15<00:05,  2.08it/s]avg_loss = 1.7038511618589745:  93%|█████████▎| 155/166 [01:16<00:05,  2.08it/s]avg_loss = 1.7038511618589745:  94%|█████████▍| 156/166 [01:16<00:04,  2.08it/s]avg_loss = 1.7020551353503184:  94%|█████████▍| 156/166 [01:16<00:04,  2.08it/s]avg_loss = 1.7020551353503184:  95%|█████████▍| 157/166 [01:16<00:04,  2.08it/s]avg_loss = 1.6977600870253164:  95%|█████████▍| 157/166 [01:17<00:04,  2.08it/s]avg_loss = 1.6977600870253164:  95%|█████████▌| 158/166 [01:17<00:03,  2.07it/s]avg_loss = 1.6985799921383649:  95%|█████████▌| 158/166 [01:17<00:03,  2.07it/s]avg_loss = 1.6985799921383649:  96%|█████████▌| 159/166 [01:17<00:03,  2.07it/s]avg_loss = 1.6999755859375:  96%|█████████▌| 159/166 [01:18<00:03,  2.07it/s]   avg_loss = 1.6999755859375:  96%|█████████▋| 160/166 [01:18<00:02,  2.06it/s]avg_loss = 1.7023243400621118:  96%|█████████▋| 160/166 [01:18<00:02,  2.06it/s]avg_loss = 1.7023243400621118:  97%|█████████▋| 161/166 [01:18<00:02,  2.06it/s]avg_loss = 1.7024739583333333:  97%|█████████▋| 161/166 [01:18<00:02,  2.06it/s]avg_loss = 1.7024739583333333:  98%|█████████▊| 162/166 [01:18<00:01,  2.06it/s]avg_loss = 1.7020465874233128:  98%|█████████▊| 162/166 [01:19<00:01,  2.06it/s]avg_loss = 1.7020465874233128:  98%|█████████▊| 163/166 [01:19<00:01,  2.06it/s]avg_loss = 1.7026248094512195:  98%|█████████▊| 163/166 [01:19<00:01,  2.06it/s]avg_loss = 1.7026248094512195:  99%|█████████▉| 164/166 [01:19<00:00,  2.05it/s]avg_loss = 1.7027225378787878:  99%|█████████▉| 164/166 [01:20<00:00,  2.05it/s]avg_loss = 1.7027225378787878:  99%|█████████▉| 165/166 [01:20<00:00,  2.05it/s]avg_loss = 1.7047016189759037:  99%|█████████▉| 165/166 [01:20<00:00,  2.05it/s]avg_loss = 1.7047016189759037: 100%|██████████| 166/166 [01:20<00:00,  2.04it/s]avg_loss = 1.7047016189759037: 100%|██████████| 166/166 [01:20<00:00,  2.05it/s]
I0303 06:24:51.373660 3039882 eval_ppl.py:105] wikitext2 perplexity: 5.499744415283203
wikitext2 perplexity: 5.500
Running with lmbda=10000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.86it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.96it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  9.69it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.77it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.51it/s]
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:10,  2.87it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:00<00:10,  2.93it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:01<00:09,  2.94it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:01<00:09,  2.95it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:01<00:12,  2.24it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:02<00:12,  2.03it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:03<00:12,  1.96it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:03<00:12,  1.89it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:04<00:12,  1.84it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:04<00:12,  1.79it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:05<00:13,  1.61it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:06<00:13,  1.51it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:13,  1.42it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:08<00:13,  1.35it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:11,  1.52it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:08<00:09,  1.68it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:08,  1.81it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:09<00:07,  1.92it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:06,  1.96it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:10<00:06,  1.93it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:06,  1.83it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:11<00:05,  1.95it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:04,  2.05it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:12<00:03,  2.13it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:13<00:03,  2.13it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:13<00:02,  2.20it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:14<00:02,  2.23it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:14<00:01,  2.27it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:14<00:01,  2.30it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:15<00:00,  2.34it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:15<00:00,  2.35it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  2.26it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]
pseudo compress quantization...:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-03 06:25:38 - INFO - layer0_self_attn.q_proj | mse: 0.008301455203678408, bpp_loss: 5.505130859557539, bpp: 0
2025-03-03 06:25:49 - INFO - layer0_self_attn.k_proj | mse: 0.006363606046667134, bpp_loss: 5.6215608700877056, bpp: 0
2025-03-03 06:26:03 - INFO - layer0_self_attn.v_proj | mse: 0.0017188396192312216, bpp_loss: 5.458283241488971, bpp: 0
2025-03-03 06:26:16 - INFO - layer0_self_attn.o_proj | mse: 0.0018167728758379197, bpp_loss: 5.3093317206949, bpp: 0
2025-03-03 06:26:28 - INFO - layer0_mlp.gate_proj | mse: 0.0015144967805411616, bpp_loss: 5.78640927469661, bpp: 0
2025-03-03 06:26:40 - INFO - layer0_mlp.up_proj | mse: 0.0015030065707257578, bpp_loss: 5.76865584654517, bpp: 0
2025-03-03 06:27:11 - INFO - layer0_mlp.down_proj | mse: 0.0017368003315174844, bpp_loss: 5.813162673394694, bpp: 0
pseudo compress quantization...:   3%|▎         | 1/32 [01:43<53:32, 103.63s/it]2025-03-03 06:27:24 - INFO - layer1_self_attn.q_proj | mse: 0.00526404657609515, bpp_loss: 6.344914811546914, bpp: 0
2025-03-03 06:27:36 - INFO - layer1_self_attn.k_proj | mse: 0.00735514783651306, bpp_loss: 6.365758671192452, bpp: 0
2025-03-03 06:27:49 - INFO - layer1_self_attn.v_proj | mse: 0.0019030122201127266, bpp_loss: 5.411703811376356, bpp: 0
2025-03-03 06:28:00 - INFO - layer1_self_attn.o_proj | mse: 0.0018711766193162066, bpp_loss: 5.34635351493489, bpp: 0
2025-03-03 06:28:13 - INFO - layer1_mlp.gate_proj | mse: 0.001630601892465465, bpp_loss: 5.907603639242954, bpp: 0
2025-03-03 06:28:29 - INFO - layer1_mlp.up_proj | mse: 0.001596026430502087, bpp_loss: 5.835759971204192, bpp: 0
2025-03-03 06:29:01 - INFO - layer1_mlp.down_proj | mse: 0.0016694621477622552, bpp_loss: 5.853214336429224, bpp: 0
pseudo compress quantization...:   6%|▋         | 2/32 [03:33<53:36, 107.20s/it]2025-03-03 06:29:12 - INFO - layer2_self_attn.q_proj | mse: 0.001911372722838057, bpp_loss: 6.493927440606058, bpp: 0
2025-03-03 06:29:22 - INFO - layer2_self_attn.k_proj | mse: 0.0019757363176052135, bpp_loss: 6.591984045342542, bpp: 0
2025-03-03 06:29:33 - INFO - layer2_self_attn.v_proj | mse: 0.001439847177179456, bpp_loss: 5.65180957922712, bpp: 0
2025-03-03 06:29:46 - INFO - layer2_self_attn.o_proj | mse: 0.0015002800283752476, bpp_loss: 5.626860026852228, bpp: 0
2025-03-03 06:30:01 - INFO - layer2_mlp.gate_proj | mse: 0.0015204182008071063, bpp_loss: 5.946753232371669, bpp: 0
2025-03-03 06:30:13 - INFO - layer2_mlp.up_proj | mse: 0.0014832153233524173, bpp_loss: 5.858032025570093, bpp: 0
2025-03-03 06:30:50 - INFO - layer2_mlp.down_proj | mse: 0.0012967403736835002, bpp_loss: 5.865778512126485, bpp: 0
pseudo compress quantization...:   9%|▉         | 3/32 [05:22<52:17, 108.18s/it]2025-03-03 06:31:01 - INFO - layer3_self_attn.q_proj | mse: 0.0016970344851362034, bpp_loss: 6.390781204216182, bpp: 0
2025-03-03 06:31:11 - INFO - layer3_self_attn.k_proj | mse: 0.0017277909375755748, bpp_loss: 6.468061011750251, bpp: 0
2025-03-03 06:31:22 - INFO - layer3_self_attn.v_proj | mse: 0.0013023948196863738, bpp_loss: 5.6074273905251175, bpp: 0
2025-03-03 06:31:33 - INFO - layer3_self_attn.o_proj | mse: 0.0012704567360089568, bpp_loss: 5.589736877242103, bpp: 0
2025-03-03 06:31:45 - INFO - layer3_mlp.gate_proj | mse: 0.001429688621614695, bpp_loss: 5.966507724724536, bpp: 0
2025-03-03 06:32:00 - INFO - layer3_mlp.up_proj | mse: 0.001387158150247731, bpp_loss: 5.8663370650868085, bpp: 0
2025-03-03 06:32:34 - INFO - layer3_mlp.down_proj | mse: 0.0012762384750305467, bpp_loss: 5.868281898326998, bpp: 0
pseudo compress quantization...:  12%|█▎        | 4/32 [07:06<49:44, 106.59s/it]2025-03-03 06:32:47 - INFO - layer4_self_attn.q_proj | mse: 0.0017137018952993281, bpp_loss: 6.489040427724831, bpp: 0
2025-03-03 06:33:02 - INFO - layer4_self_attn.k_proj | mse: 0.001746901459950613, bpp_loss: 6.5326629497576505, bpp: 0
2025-03-03 06:33:12 - INFO - layer4_self_attn.v_proj | mse: 0.001297225771481697, bpp_loss: 5.653380300849676, bpp: 0
2025-03-03 06:33:23 - INFO - layer4_self_attn.o_proj | mse: 0.0012870719088732498, bpp_loss: 5.637079787440598, bpp: 0
2025-03-03 06:33:35 - INFO - layer4_mlp.gate_proj | mse: 0.0014258346117740634, bpp_loss: 5.994672466156095, bpp: 0
2025-03-03 06:33:47 - INFO - layer4_mlp.up_proj | mse: 0.0013660168810369913, bpp_loss: 5.857695275527793, bpp: 0
2025-03-03 06:34:21 - INFO - layer4_mlp.down_proj | mse: 0.001272935038024291, bpp_loss: 5.854046610032404, bpp: 0
pseudo compress quantization...:  16%|█▌        | 5/32 [08:53<48:02, 106.75s/it]2025-03-03 06:34:35 - INFO - layer5_self_attn.q_proj | mse: 0.0016857046948422693, bpp_loss: 6.507946021272801, bpp: 0
2025-03-03 06:34:45 - INFO - layer5_self_attn.k_proj | mse: 0.001746941656416265, bpp_loss: 6.589032516581938, bpp: 0
2025-03-03 06:34:57 - INFO - layer5_self_attn.v_proj | mse: 0.0012874711575523625, bpp_loss: 5.6749717828352, bpp: 0
2025-03-03 06:35:11 - INFO - layer5_self_attn.o_proj | mse: 0.0013699868967995258, bpp_loss: 5.655088619561866, bpp: 0
2025-03-03 06:35:25 - INFO - layer5_mlp.gate_proj | mse: 0.0014276046374109609, bpp_loss: 6.002908606168836, bpp: 0
2025-03-03 06:35:37 - INFO - layer5_mlp.up_proj | mse: 0.001364345354847458, bpp_loss: 5.8577599368642925, bpp: 0
2025-03-03 06:36:09 - INFO - layer5_mlp.down_proj | mse: 0.0012660892590594184, bpp_loss: 5.8552922728623065, bpp: 0
pseudo compress quantization...:  19%|█▉        | 6/32 [10:41<46:26, 107.18s/it]2025-03-03 06:36:20 - INFO - layer6_self_attn.q_proj | mse: 0.001590779111618221, bpp_loss: 6.367777629755437, bpp: 0
2025-03-03 06:36:34 - INFO - layer6_self_attn.k_proj | mse: 0.0016103118779477673, bpp_loss: 6.404037054860964, bpp: 0
2025-03-03 06:36:46 - INFO - layer6_self_attn.v_proj | mse: 0.001243831375741149, bpp_loss: 5.610028964700177, bpp: 0
2025-03-03 06:36:58 - INFO - layer6_self_attn.o_proj | mse: 0.0012939972891357013, bpp_loss: 5.602680251235142, bpp: 0
2025-03-03 06:37:10 - INFO - layer6_mlp.gate_proj | mse: 0.0014147308539628179, bpp_loss: 6.026971355773682, bpp: 0
2025-03-03 06:37:24 - INFO - layer6_mlp.up_proj | mse: 0.0013394980270863815, bpp_loss: 5.853654154684654, bpp: 0
2025-03-03 06:37:57 - INFO - layer6_mlp.down_proj | mse: 0.0012674508690670955, bpp_loss: 5.8489251667850235, bpp: 0
pseudo compress quantization...:  22%|██▏       | 7/32 [12:30<44:48, 107.56s/it]2025-03-03 06:38:07 - INFO - layer7_self_attn.q_proj | mse: 0.0015688169940289666, bpp_loss: 6.362558103632182, bpp: 0
2025-03-03 06:38:16 - INFO - layer7_self_attn.k_proj | mse: 0.0015783513421904368, bpp_loss: 6.37348375224974, bpp: 0
2025-03-03 06:38:24 - INFO - layer7_self_attn.v_proj | mse: 0.0012399128540681243, bpp_loss: 5.619476773077622, bpp: 0
2025-03-03 06:38:33 - INFO - layer7_self_attn.o_proj | mse: 0.0012380617343987776, bpp_loss: 5.608427309198305, bpp: 0
2025-03-03 06:38:44 - INFO - layer7_mlp.gate_proj | mse: 0.0014032704230501057, bpp_loss: 6.025974350526583, bpp: 0
2025-03-03 06:38:54 - INFO - layer7_mlp.up_proj | mse: 0.0013316708917943528, bpp_loss: 5.857745121124872, bpp: 0
2025-03-03 06:39:22 - INFO - layer7_mlp.down_proj | mse: 0.0012738246322123844, bpp_loss: 5.850865546180758, bpp: 0
pseudo compress quantization...:  25%|██▌       | 8/32 [13:55<40:07, 100.33s/it]2025-03-03 06:39:35 - INFO - layer8_self_attn.q_proj | mse: 0.0015933205422123376, bpp_loss: 6.38102534157224, bpp: 0
2025-03-03 06:39:48 - INFO - layer8_self_attn.k_proj | mse: 0.0016132033074973148, bpp_loss: 6.399312208755873, bpp: 0
2025-03-03 06:40:00 - INFO - layer8_self_attn.v_proj | mse: 0.0012532797179513366, bpp_loss: 5.643539246288128, bpp: 0
2025-03-03 06:40:12 - INFO - layer8_self_attn.o_proj | mse: 0.0012980961517086791, bpp_loss: 5.6328510829480365, bpp: 0
2025-03-03 06:40:27 - INFO - layer8_mlp.gate_proj | mse: 0.0013889664437957791, bpp_loss: 6.003167251948008, bpp: 0
2025-03-03 06:40:42 - INFO - layer8_mlp.up_proj | mse: 0.0013342363240492923, bpp_loss: 5.872560431011195, bpp: 0
2025-03-03 06:41:21 - INFO - layer8_mlp.down_proj | mse: 0.0012828135489478761, bpp_loss: 5.862905869953508, bpp: 0
pseudo compress quantization...:  28%|██▊       | 9/32 [15:53<40:41, 106.14s/it]2025-03-03 06:41:34 - INFO - layer9_self_attn.q_proj | mse: 0.0015798199617080258, bpp_loss: 6.402058937237598, bpp: 0
2025-03-03 06:41:46 - INFO - layer9_self_attn.k_proj | mse: 0.0016226232224772889, bpp_loss: 6.448106382275, bpp: 0
2025-03-03 06:41:59 - INFO - layer9_self_attn.v_proj | mse: 0.0012514285077494095, bpp_loss: 5.660548036801629, bpp: 0
2025-03-03 06:42:11 - INFO - layer9_self_attn.o_proj | mse: 0.001318039664355036, bpp_loss: 5.650028260424733, bpp: 0
2025-03-03 06:42:26 - INFO - layer9_mlp.gate_proj | mse: 0.0013766183051412977, bpp_loss: 5.989231302467889, bpp: 0
2025-03-03 06:42:41 - INFO - layer9_mlp.up_proj | mse: 0.0013314668860989916, bpp_loss: 5.880831733345985, bpp: 0
2025-03-03 06:43:20 - INFO - layer9_mlp.down_proj | mse: 0.0012828422498812394, bpp_loss: 5.870962906022404, bpp: 0
pseudo compress quantization...:  31%|███▏      | 10/32 [17:52<40:21, 110.05s/it]2025-03-03 06:43:33 - INFO - layer10_self_attn.q_proj | mse: 0.0015681189878348715, bpp_loss: 6.3929076043423265, bpp: 0
2025-03-03 06:43:45 - INFO - layer10_self_attn.k_proj | mse: 0.0016147590193571503, bpp_loss: 6.446470860391855, bpp: 0
2025-03-03 06:43:57 - INFO - layer10_self_attn.v_proj | mse: 0.001244376925070023, bpp_loss: 5.652575980871916, bpp: 0
2025-03-03 06:44:10 - INFO - layer10_self_attn.o_proj | mse: 0.0013455374870991728, bpp_loss: 5.6477483419002965, bpp: 0
2025-03-03 06:44:21 - INFO - layer10_mlp.gate_proj | mse: 0.001374813245501234, bpp_loss: 5.9842685750404065, bpp: 0
2025-03-03 06:44:31 - INFO - layer10_mlp.up_proj | mse: 0.0013373226849820827, bpp_loss: 5.89390386259833, bpp: 0
2025-03-03 06:44:59 - INFO - layer10_mlp.down_proj | mse: 0.0012911184941446277, bpp_loss: 5.881103495872298, bpp: 0
pseudo compress quantization...:  34%|███▍      | 11/32 [19:32<37:21, 106.76s/it]2025-03-03 06:45:09 - INFO - layer11_self_attn.q_proj | mse: 0.0015220996476831134, bpp_loss: 6.274106529075652, bpp: 0
2025-03-03 06:45:18 - INFO - layer11_self_attn.k_proj | mse: 0.001532100962893759, bpp_loss: 6.275522939511575, bpp: 0
2025-03-03 06:45:28 - INFO - layer11_self_attn.v_proj | mse: 0.0012572004124062884, bpp_loss: 5.688603124581277, bpp: 0
2025-03-03 06:45:39 - INFO - layer11_self_attn.o_proj | mse: 0.001313429473768537, bpp_loss: 5.682238437002525, bpp: 0
2025-03-03 06:45:51 - INFO - layer11_mlp.gate_proj | mse: 0.00136375045052446, bpp_loss: 5.979692212544208, bpp: 0
2025-03-03 06:46:03 - INFO - layer11_mlp.up_proj | mse: 0.0013321476237297474, bpp_loss: 5.904599574676086, bpp: 0
2025-03-03 06:46:36 - INFO - layer11_mlp.down_proj | mse: 0.0012890799193988436, bpp_loss: 5.8893719784655545, bpp: 0
pseudo compress quantization...:  38%|███▊      | 12/32 [21:08<34:32, 103.62s/it]2025-03-03 06:46:48 - INFO - layer12_self_attn.q_proj | mse: 0.0015348140432601201, bpp_loss: 6.333961158525199, bpp: 0
2025-03-03 06:47:01 - INFO - layer12_self_attn.k_proj | mse: 0.001567071163750506, bpp_loss: 6.389351747231558, bpp: 0
2025-03-03 06:47:12 - INFO - layer12_self_attn.v_proj | mse: 0.0012420467069857407, bpp_loss: 5.6775412280112505, bpp: 0
2025-03-03 06:47:24 - INFO - layer12_self_attn.o_proj | mse: 0.0013462541430048092, bpp_loss: 5.67256135889329, bpp: 0
2025-03-03 06:47:40 - INFO - layer12_mlp.gate_proj | mse: 0.0013577395588042747, bpp_loss: 5.971153748416623, bpp: 0
2025-03-03 06:47:52 - INFO - layer12_mlp.up_proj | mse: 0.001336651244836783, bpp_loss: 5.916259230742621, bpp: 0
2025-03-03 06:48:23 - INFO - layer12_mlp.down_proj | mse: 0.0012886972402873342, bpp_loss: 5.899598317870567, bpp: 0
pseudo compress quantization...:  41%|████      | 13/32 [22:55<33:08, 104.66s/it]2025-03-03 06:48:33 - INFO - layer13_self_attn.q_proj | mse: 0.0015222678572173066, bpp_loss: 6.318461913848296, bpp: 0
2025-03-03 06:48:44 - INFO - layer13_self_attn.k_proj | mse: 0.0015513246509941694, bpp_loss: 6.350340032600798, bpp: 0
2025-03-03 06:48:57 - INFO - layer13_self_attn.v_proj | mse: 0.0012548634043784838, bpp_loss: 5.711363941663876, bpp: 0
2025-03-03 06:49:11 - INFO - layer13_self_attn.o_proj | mse: 0.0013373845755804649, bpp_loss: 5.702883748454042, bpp: 0
2025-03-03 06:49:23 - INFO - layer13_mlp.gate_proj | mse: 0.0013603830090893427, bpp_loss: 5.966066563025463, bpp: 0
2025-03-03 06:49:36 - INFO - layer13_mlp.up_proj | mse: 0.0013454633746024505, bpp_loss: 5.929322129072145, bpp: 0
2025-03-03 06:50:12 - INFO - layer13_mlp.down_proj | mse: 0.0013006928829714956, bpp_loss: 5.909425409467414, bpp: 0
pseudo compress quantization...:  44%|████▍     | 14/32 [24:44<31:47, 105.99s/it]2025-03-03 06:50:22 - INFO - layer14_self_attn.q_proj | mse: 0.0015207280790916035, bpp_loss: 6.310938261565752, bpp: 0
2025-03-03 06:50:33 - INFO - layer14_self_attn.k_proj | mse: 0.0015494560585368252, bpp_loss: 6.346238618716598, bpp: 0
2025-03-03 06:50:44 - INFO - layer14_self_attn.v_proj | mse: 0.001255140796204516, bpp_loss: 5.694220860954374, bpp: 0
2025-03-03 06:50:55 - INFO - layer14_self_attn.o_proj | mse: 0.0013110632237172965, bpp_loss: 5.686097925994545, bpp: 0
2025-03-03 06:51:09 - INFO - layer14_mlp.gate_proj | mse: 0.0013538342106743878, bpp_loss: 5.963330245815044, bpp: 0
2025-03-03 06:51:23 - INFO - layer14_mlp.up_proj | mse: 0.0013423869848859461, bpp_loss: 5.930910412741955, bpp: 0
2025-03-03 06:51:56 - INFO - layer14_mlp.down_proj | mse: 0.0012965313823799962, bpp_loss: 5.911254639412428, bpp: 0
pseudo compress quantization...:  47%|████▋     | 15/32 [26:28<29:50, 105.32s/it]2025-03-03 06:52:10 - INFO - layer15_self_attn.q_proj | mse: 0.001523970775052706, bpp_loss: 6.296748856198974, bpp: 0
2025-03-03 06:52:21 - INFO - layer15_self_attn.k_proj | mse: 0.0015571764959194509, bpp_loss: 6.357041903305799, bpp: 0
2025-03-03 06:52:32 - INFO - layer15_self_attn.v_proj | mse: 0.0012706335461382782, bpp_loss: 5.732241761637852, bpp: 0
2025-03-03 06:52:43 - INFO - layer15_self_attn.o_proj | mse: 0.0013660894692177105, bpp_loss: 5.7190873340005055, bpp: 0
2025-03-03 06:52:55 - INFO - layer15_mlp.gate_proj | mse: 0.0013613037296417879, bpp_loss: 5.9704426122439465, bpp: 0
2025-03-03 06:53:06 - INFO - layer15_mlp.up_proj | mse: 0.0013488294685759074, bpp_loss: 5.93794150589857, bpp: 0
2025-03-03 06:53:42 - INFO - layer15_mlp.down_proj | mse: 0.001303620782413041, bpp_loss: 5.915092787856972, bpp: 0
pseudo compress quantization...:  50%|█████     | 16/32 [28:14<28:11, 105.69s/it]2025-03-03 06:53:53 - INFO - layer16_self_attn.q_proj | mse: 0.0015299433904401047, bpp_loss: 6.276541194529273, bpp: 0
2025-03-03 06:54:05 - INFO - layer16_self_attn.k_proj | mse: 0.0015643207839610624, bpp_loss: 6.325088209239766, bpp: 0
2025-03-03 06:54:18 - INFO - layer16_self_attn.v_proj | mse: 0.0013032791419307214, bpp_loss: 5.774800530751236, bpp: 0
2025-03-03 06:54:32 - INFO - layer16_self_attn.o_proj | mse: 0.0013063543526182731, bpp_loss: 5.767539084074087, bpp: 0
2025-03-03 06:54:44 - INFO - layer16_mlp.gate_proj | mse: 0.0013805659635673163, bpp_loss: 5.979937017743671, bpp: 0
2025-03-03 06:54:55 - INFO - layer16_mlp.up_proj | mse: 0.0013640115885942155, bpp_loss: 5.9370882432301375, bpp: 0
2025-03-03 06:55:27 - INFO - layer16_mlp.down_proj | mse: 0.0013045796361304712, bpp_loss: 5.914787540168956, bpp: 0
pseudo compress quantization...:  53%|█████▎    | 17/32 [29:59<26:19, 105.32s/it]2025-03-03 06:55:39 - INFO - layer17_self_attn.q_proj | mse: 0.0015245237480531642, bpp_loss: 6.2710663503967226, bpp: 0
2025-03-03 06:55:52 - INFO - layer17_self_attn.k_proj | mse: 0.0015507919572916977, bpp_loss: 6.309136451338418, bpp: 0
2025-03-03 06:56:04 - INFO - layer17_self_attn.v_proj | mse: 0.0013006312450221749, bpp_loss: 5.772002678830177, bpp: 0
2025-03-03 06:56:15 - INFO - layer17_self_attn.o_proj | mse: 0.0013145638469996672, bpp_loss: 5.766516103758477, bpp: 0
2025-03-03 06:56:29 - INFO - layer17_mlp.gate_proj | mse: 0.0013754096320320582, bpp_loss: 5.993409427445989, bpp: 0
2025-03-03 06:56:44 - INFO - layer17_mlp.up_proj | mse: 0.0013502457855269906, bpp_loss: 5.932405995075093, bpp: 0
2025-03-03 06:57:16 - INFO - layer17_mlp.down_proj | mse: 0.0012877281458612863, bpp_loss: 5.914209665903865, bpp: 0
pseudo compress quantization...:  56%|█████▋    | 18/32 [31:48<24:49, 106.39s/it]2025-03-03 06:57:26 - INFO - layer18_self_attn.q_proj | mse: 0.0014977764403996954, bpp_loss: 6.236176668549888, bpp: 0
2025-03-03 06:57:36 - INFO - layer18_self_attn.k_proj | mse: 0.0015197789355197626, bpp_loss: 6.272150623379275, bpp: 0
2025-03-03 06:57:48 - INFO - layer18_self_attn.v_proj | mse: 0.0013116213570748317, bpp_loss: 5.8221593137132, bpp: 0
2025-03-03 06:58:01 - INFO - layer18_self_attn.o_proj | mse: 0.001301471296834757, bpp_loss: 5.810343493940309, bpp: 0
2025-03-03 06:58:16 - INFO - layer18_mlp.gate_proj | mse: 0.0013836466651611335, bpp_loss: 6.005735191928093, bpp: 0
2025-03-03 06:58:27 - INFO - layer18_mlp.up_proj | mse: 0.0013518878023061646, bpp_loss: 5.928560725651508, bpp: 0
2025-03-03 06:59:04 - INFO - layer18_mlp.down_proj | mse: 0.0012822620328903382, bpp_loss: 5.913169015242263, bpp: 0
pseudo compress quantization...:  59%|█████▉    | 19/32 [33:36<23:10, 106.98s/it]2025-03-03 06:59:15 - INFO - layer19_self_attn.q_proj | mse: 0.0014924049613454732, bpp_loss: 6.21150666999165, bpp: 0
2025-03-03 06:59:25 - INFO - layer19_self_attn.k_proj | mse: 0.001511184858737264, bpp_loss: 6.243491153349169, bpp: 0
2025-03-03 06:59:36 - INFO - layer19_self_attn.v_proj | mse: 0.0013164293613492813, bpp_loss: 5.832259215880185, bpp: 0
2025-03-03 06:59:47 - INFO - layer19_self_attn.o_proj | mse: 0.0012816270078964062, bpp_loss: 5.8210900409612805, bpp: 0
2025-03-03 06:59:59 - INFO - layer19_mlp.gate_proj | mse: 0.0013816024310763766, bpp_loss: 6.01101729291123, bpp: 0
2025-03-03 07:00:13 - INFO - layer19_mlp.up_proj | mse: 0.0013459966999275752, bpp_loss: 5.928591492997352, bpp: 0
2025-03-03 07:00:48 - INFO - layer19_mlp.down_proj | mse: 0.0012766226363498823, bpp_loss: 5.916297728239104, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 20/32 [35:20<21:13, 106.17s/it]2025-03-03 07:01:01 - INFO - layer20_self_attn.q_proj | mse: 0.0014899549686574573, bpp_loss: 6.2208759357454255, bpp: 0
2025-03-03 07:01:15 - INFO - layer20_self_attn.k_proj | mse: 0.0015088731092993627, bpp_loss: 6.2512156828306615, bpp: 0
2025-03-03 07:01:27 - INFO - layer20_self_attn.v_proj | mse: 0.0013264144712280537, bpp_loss: 5.851212158566341, bpp: 0
2025-03-03 07:01:38 - INFO - layer20_self_attn.o_proj | mse: 0.00130341856210438, bpp_loss: 5.844345567282289, bpp: 0
2025-03-03 07:01:50 - INFO - layer20_mlp.gate_proj | mse: 0.0013908360468493685, bpp_loss: 6.019049461671086, bpp: 0
2025-03-03 07:02:01 - INFO - layer20_mlp.up_proj | mse: 0.0013514191551407316, bpp_loss: 5.9279645725564905, bpp: 0
2025-03-03 07:02:35 - INFO - layer20_mlp.down_proj | mse: 0.0012789819069708047, bpp_loss: 5.916561692519936, bpp: 0
pseudo compress quantization...:  66%|██████▌   | 21/32 [37:07<19:28, 106.26s/it]2025-03-03 07:02:47 - INFO - layer21_self_attn.q_proj | mse: 0.0014718326999289487, bpp_loss: 6.181889488128945, bpp: 0
2025-03-03 07:02:58 - INFO - layer21_self_attn.k_proj | mse: 0.0014866471797711207, bpp_loss: 6.199048807611689, bpp: 0
2025-03-03 07:03:10 - INFO - layer21_self_attn.v_proj | mse: 0.0013408161225040682, bpp_loss: 5.888253191369586, bpp: 0
2025-03-03 07:03:23 - INFO - layer21_self_attn.o_proj | mse: 0.0012824655206551234, bpp_loss: 5.873433142201975, bpp: 0
2025-03-03 07:03:37 - INFO - layer21_mlp.gate_proj | mse: 0.0013864774126169754, bpp_loss: 6.02875344619848, bpp: 0
2025-03-03 07:03:49 - INFO - layer21_mlp.up_proj | mse: 0.0013415954859067182, bpp_loss: 5.925847333531047, bpp: 0
2025-03-03 07:04:21 - INFO - layer21_mlp.down_proj | mse: 0.0012636380915532674, bpp_loss: 5.9168011932958695, bpp: 0
pseudo compress quantization...:  69%|██████▉   | 22/32 [38:53<17:42, 106.26s/it]2025-03-03 07:04:32 - INFO - layer22_self_attn.q_proj | mse: 0.001484766184350276, bpp_loss: 6.2215509585803375, bpp: 0
2025-03-03 07:04:43 - INFO - layer22_self_attn.k_proj | mse: 0.0014949456676789474, bpp_loss: 6.242909214110114, bpp: 0
2025-03-03 07:04:56 - INFO - layer22_self_attn.v_proj | mse: 0.0013312262778708754, bpp_loss: 5.892136557842605, bpp: 0
2025-03-03 07:05:09 - INFO - layer22_self_attn.o_proj | mse: 0.0013409032148463146, bpp_loss: 5.870064723538235, bpp: 0
2025-03-03 07:05:20 - INFO - layer22_mlp.gate_proj | mse: 0.0013865784722414938, bpp_loss: 6.037458488934262, bpp: 0
2025-03-03 07:05:33 - INFO - layer22_mlp.up_proj | mse: 0.0013365512631815927, bpp_loss: 5.925410427066476, bpp: 0
2025-03-03 07:06:09 - INFO - layer22_mlp.down_proj | mse: 0.0012639641772750467, bpp_loss: 5.917365251282273, bpp: 0
pseudo compress quantization...:  72%|███████▏  | 23/32 [40:41<16:01, 106.85s/it]2025-03-03 07:06:20 - INFO - layer23_self_attn.q_proj | mse: 0.001471730307580632, bpp_loss: 6.213168999762274, bpp: 0
2025-03-03 07:06:30 - INFO - layer23_self_attn.k_proj | mse: 0.0014778478656290875, bpp_loss: 6.2263807888375595, bpp: 0
2025-03-03 07:06:41 - INFO - layer23_self_attn.v_proj | mse: 0.0013480537496359665, bpp_loss: 5.951852004160173, bpp: 0
2025-03-03 07:06:52 - INFO - layer23_self_attn.o_proj | mse: 0.0012698310653465196, bpp_loss: 5.9333345998311415, bpp: 0
2025-03-03 07:07:06 - INFO - layer23_mlp.gate_proj | mse: 0.0013753378123255674, bpp_loss: 6.037213923279629, bpp: 0
2025-03-03 07:07:20 - INFO - layer23_mlp.up_proj | mse: 0.0013296360899412174, bpp_loss: 5.931758277638014, bpp: 0
2025-03-03 07:07:53 - INFO - layer23_mlp.down_proj | mse: 0.0012560481095134416, bpp_loss: 5.925072632253516, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 24/32 [42:25<14:07, 105.92s/it]2025-03-03 07:08:07 - INFO - layer24_self_attn.q_proj | mse: 0.0014317107425903623, bpp_loss: 6.155593173811212, bpp: 0
2025-03-03 07:08:18 - INFO - layer24_self_attn.k_proj | mse: 0.0014411672327327766, bpp_loss: 6.163045140216127, bpp: 0
2025-03-03 07:08:29 - INFO - layer24_self_attn.v_proj | mse: 0.0013369635085495003, bpp_loss: 5.940197507617995, bpp: 0
2025-03-03 07:08:40 - INFO - layer24_self_attn.o_proj | mse: 0.0013025762469772903, bpp_loss: 5.9173617992782965, bpp: 0
2025-03-03 07:08:52 - INFO - layer24_mlp.gate_proj | mse: 0.0013693399909834865, bpp_loss: 6.040820228325766, bpp: 0
2025-03-03 07:09:04 - INFO - layer24_mlp.up_proj | mse: 0.0013229829979937598, bpp_loss: 5.935770627804274, bpp: 0
2025-03-03 07:09:39 - INFO - layer24_mlp.down_proj | mse: 0.0012513845447073351, bpp_loss: 5.9297934760621125, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 25/32 [44:11<12:22, 106.00s/it]2025-03-03 07:09:51 - INFO - layer25_self_attn.q_proj | mse: 0.001430996259466653, bpp_loss: 6.177314061671495, bpp: 0
2025-03-03 07:10:02 - INFO - layer25_self_attn.k_proj | mse: 0.001436033763832157, bpp_loss: 6.183225067681633, bpp: 0
2025-03-03 07:10:15 - INFO - layer25_self_attn.v_proj | mse: 0.0013516281569712796, bpp_loss: 5.990761975059286, bpp: 0
2025-03-03 07:10:29 - INFO - layer25_self_attn.o_proj | mse: 0.0012972316560994166, bpp_loss: 5.973622116725892, bpp: 0
2025-03-03 07:10:41 - INFO - layer25_mlp.gate_proj | mse: 0.0013629776812623096, bpp_loss: 6.043311359317497, bpp: 0
2025-03-03 07:10:53 - INFO - layer25_mlp.up_proj | mse: 0.0013176894948614887, bpp_loss: 5.941444619450459, bpp: 0
2025-03-03 07:11:24 - INFO - layer25_mlp.down_proj | mse: 0.0012497886111169413, bpp_loss: 5.9356659108902825, bpp: 0
pseudo compress quantization...:  81%|████████▏ | 26/32 [45:56<10:34, 105.75s/it]2025-03-03 07:11:36 - INFO - layer26_self_attn.q_proj | mse: 0.0014123082526438643, bpp_loss: 6.148722718120553, bpp: 0
2025-03-03 07:11:49 - INFO - layer26_self_attn.k_proj | mse: 0.0014187472918849567, bpp_loss: 6.16173611942213, bpp: 0
2025-03-03 07:12:02 - INFO - layer26_self_attn.v_proj | mse: 0.0013549297896421559, bpp_loss: 6.0104545204667374, bpp: 0
2025-03-03 07:12:12 - INFO - layer26_self_attn.o_proj | mse: 0.0013557635041741172, bpp_loss: 5.9980902201496065, bpp: 0
2025-03-03 07:12:25 - INFO - layer26_mlp.gate_proj | mse: 0.0013625848961883484, bpp_loss: 6.047452575505473, bpp: 0
2025-03-03 07:12:40 - INFO - layer26_mlp.up_proj | mse: 0.0013168171481826466, bpp_loss: 5.946163547246955, bpp: 0
2025-03-03 07:13:13 - INFO - layer26_mlp.down_proj | mse: 0.0012491400778198657, bpp_loss: 5.938777926832784, bpp: 0
pseudo compress quantization...:  84%|████████▍ | 27/32 [47:45<08:53, 106.66s/it]2025-03-03 07:13:24 - INFO - layer27_self_attn.q_proj | mse: 0.0014455806054897082, bpp_loss: 6.219761574175209, bpp: 0
2025-03-03 07:13:35 - INFO - layer27_self_attn.k_proj | mse: 0.0014466503384585056, bpp_loss: 6.238662116462365, bpp: 0
2025-03-03 07:13:46 - INFO - layer27_self_attn.v_proj | mse: 0.0013482818012057363, bpp_loss: 6.015267334878445, bpp: 0
2025-03-03 07:13:58 - INFO - layer27_self_attn.o_proj | mse: 0.0013163343021399686, bpp_loss: 6.011766380281188, bpp: 0
2025-03-03 07:14:12 - INFO - layer27_mlp.gate_proj | mse: 0.0013601488202527922, bpp_loss: 6.048717912026616, bpp: 0
2025-03-03 07:14:26 - INFO - layer27_mlp.up_proj | mse: 0.0013180355230158398, bpp_loss: 5.952852364109699, bpp: 0
2025-03-03 07:15:01 - INFO - layer27_mlp.down_proj | mse: 0.001254480337871747, bpp_loss: 5.944581656002028, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 28/32 [49:33<07:08, 107.10s/it]2025-03-03 07:15:12 - INFO - layer28_self_attn.q_proj | mse: 0.0014159945582484252, bpp_loss: 6.166528549045324, bpp: 0
2025-03-03 07:15:23 - INFO - layer28_self_attn.k_proj | mse: 0.0014267320844020518, bpp_loss: 6.1879623755812645, bpp: 0
2025-03-03 07:15:34 - INFO - layer28_self_attn.v_proj | mse: 0.0013716883661136405, bpp_loss: 6.059222569921985, bpp: 0
2025-03-03 07:15:45 - INFO - layer28_self_attn.o_proj | mse: 0.001386040133937911, bpp_loss: 6.055734247667715, bpp: 0
2025-03-03 07:15:57 - INFO - layer28_mlp.gate_proj | mse: 0.001355156205309254, bpp_loss: 6.042155731469393, bpp: 0
2025-03-03 07:16:10 - INFO - layer28_mlp.up_proj | mse: 0.0013229976853258564, bpp_loss: 5.965924647831639, bpp: 0
2025-03-03 07:16:46 - INFO - layer28_mlp.down_proj | mse: 0.0012711135393519723, bpp_loss: 5.951239691180891, bpp: 0
pseudo compress quantization...:  91%|█████████ | 29/32 [51:18<05:19, 106.42s/it]2025-03-03 07:16:58 - INFO - layer29_self_attn.q_proj | mse: 0.0013975707254949453, bpp_loss: 6.117851141723804, bpp: 0
2025-03-03 07:17:12 - INFO - layer29_self_attn.k_proj | mse: 0.0014003128668195817, bpp_loss: 6.134525880916044, bpp: 0
2025-03-03 07:17:25 - INFO - layer29_self_attn.v_proj | mse: 0.00137931872357887, bpp_loss: 6.065733137656935, bpp: 0
2025-03-03 07:17:36 - INFO - layer29_self_attn.o_proj | mse: 0.0013604814285311704, bpp_loss: 6.074228849844076, bpp: 0
2025-03-03 07:17:47 - INFO - layer29_mlp.gate_proj | mse: 0.0013606452251284263, bpp_loss: 6.044982336115005, bpp: 0
2025-03-03 07:17:59 - INFO - layer29_mlp.up_proj | mse: 0.0013293765688254544, bpp_loss: 5.977847493665163, bpp: 0
2025-03-03 07:18:32 - INFO - layer29_mlp.down_proj | mse: 0.0012883442053323502, bpp_loss: 5.953764219876638, bpp: 0
pseudo compress quantization...:  94%|█████████▍| 30/32 [53:04<03:32, 106.29s/it]2025-03-03 07:18:44 - INFO - layer30_self_attn.q_proj | mse: 0.0014106041578849208, bpp_loss: 6.134276468772441, bpp: 0
2025-03-03 07:18:57 - INFO - layer30_self_attn.k_proj | mse: 0.0014149489974785673, bpp_loss: 6.160812483285554, bpp: 0
2025-03-03 07:19:08 - INFO - layer30_self_attn.v_proj | mse: 0.0013972429070216873, bpp_loss: 6.103276214329526, bpp: 0
2025-03-03 07:19:20 - INFO - layer30_self_attn.o_proj | mse: 0.0014082066740934776, bpp_loss: 6.112423055339605, bpp: 0
2025-03-03 07:19:36 - INFO - layer30_mlp.gate_proj | mse: 0.0013812375384587821, bpp_loss: 6.072014918420897, bpp: 0
2025-03-03 07:19:48 - INFO - layer30_mlp.up_proj | mse: 0.0013448103946818958, bpp_loss: 5.9943902031626815, bpp: 0
2025-03-03 07:20:20 - INFO - layer30_mlp.down_proj | mse: 0.0013617062164397028, bpp_loss: 5.941816196971854, bpp: 0
pseudo compress quantization...:  97%|█████████▋| 31/32 [54:52<01:46, 106.69s/it]2025-03-03 07:20:30 - INFO - layer31_self_attn.q_proj | mse: 0.0014436626727761018, bpp_loss: 6.155010725022294, bpp: 0
2025-03-03 07:20:41 - INFO - layer31_self_attn.k_proj | mse: 0.0014687104122996424, bpp_loss: 6.212582060834393, bpp: 0
2025-03-03 07:20:55 - INFO - layer31_self_attn.v_proj | mse: 0.0013566558838181116, bpp_loss: 5.9645030468236655, bpp: 0
2025-03-03 07:21:07 - INFO - layer31_self_attn.o_proj | mse: 0.0015531398292291379, bpp_loss: 5.965927003300749, bpp: 0
2025-03-03 07:21:20 - INFO - layer31_mlp.gate_proj | mse: 0.0014401963971336145, bpp_loss: 6.146169824309127, bpp: 0
2025-03-03 07:21:33 - INFO - layer31_mlp.up_proj | mse: 0.0013949997033795244, bpp_loss: 6.056517180228649, bpp: 0
2025-03-03 07:22:09 - INFO - layer31_mlp.down_proj | mse: 0.0016975036333889413, bpp_loss: 5.936413638250426, bpp: 0
pseudo compress quantization...: 100%|██████████| 32/32 [56:41<00:00, 107.55s/it]pseudo compress quantization...: 100%|██████████| 32/32 [56:41<00:00, 106.31s/it]
2025-03-03 07:22:09 - INFO - #### Total | mse: 0.0014431848397064274, bpp_loss: 5.967929169395999, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda10000_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_10.96029_bpp_6.2788_MSE_0.0004_total_iter_140000.pth.tar/COL_MSE0.00144_bpploss5.9679_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda10000_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_10.96029_bpp_6.2788_MSE_0.0004_total_iter_140000.pth.tar/COL_MSE0.00144_bpploss5.9679_bpp0
I0303 07:22:39.630745 3069716 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.35it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]
I0303 07:22:41.745030 3069716 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.359375:   0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.359375:   1%|          | 1/166 [00:00<01:52,  1.46it/s]avg_loss = 1.625:   1%|          | 1/166 [00:01<01:52,  1.46it/s]   avg_loss = 1.625:   1%|          | 2/166 [00:01<01:42,  1.60it/s]avg_loss = 1.7916666666666667:   1%|          | 2/166 [00:01<01:42,  1.60it/s]avg_loss = 1.7916666666666667:   2%|▏         | 3/166 [00:01<01:37,  1.66it/s]avg_loss = 1.82421875:   2%|▏         | 3/166 [00:02<01:37,  1.66it/s]        avg_loss = 1.82421875:   2%|▏         | 4/166 [00:02<01:36,  1.68it/s]avg_loss = 1.759375:   2%|▏         | 4/166 [00:03<01:36,  1.68it/s]  avg_loss = 1.759375:   3%|▎         | 5/166 [00:03<01:34,  1.70it/s]avg_loss = 1.7356770833333333:   3%|▎         | 5/166 [00:03<01:34,  1.70it/s]avg_loss = 1.7356770833333333:   4%|▎         | 6/166 [00:03<01:33,  1.70it/s]avg_loss = 1.6741071428571428:   4%|▎         | 6/166 [00:04<01:33,  1.70it/s]avg_loss = 1.6741071428571428:   4%|▍         | 7/166 [00:04<01:33,  1.71it/s]avg_loss = 1.6162109375:   4%|▍         | 7/166 [00:04<01:33,  1.71it/s]      avg_loss = 1.6162109375:   5%|▍         | 8/166 [00:04<01:32,  1.70it/s]avg_loss = 1.6119791666666667:   5%|▍         | 8/166 [00:05<01:32,  1.70it/s]avg_loss = 1.6119791666666667:   5%|▌         | 9/166 [00:05<01:31,  1.71it/s]avg_loss = 1.61796875:   5%|▌         | 9/166 [00:05<01:31,  1.71it/s]        avg_loss = 1.61796875:   6%|▌         | 10/166 [00:05<01:31,  1.71it/s]avg_loss = 1.6342329545454546:   6%|▌         | 10/166 [00:06<01:31,  1.71it/s]avg_loss = 1.6342329545454546:   7%|▋         | 11/166 [00:06<01:31,  1.70it/s]avg_loss = 1.64453125:   7%|▋         | 11/166 [00:07<01:31,  1.70it/s]        avg_loss = 1.64453125:   7%|▋         | 12/166 [00:07<01:30,  1.70it/s]avg_loss = 1.6400240384615385:   7%|▋         | 12/166 [00:07<01:30,  1.70it/s]avg_loss = 1.6400240384615385:   8%|▊         | 13/166 [00:07<01:30,  1.70it/s]avg_loss = 1.6529017857142858:   8%|▊         | 13/166 [00:08<01:30,  1.70it/s]avg_loss = 1.6529017857142858:   8%|▊         | 14/166 [00:08<01:22,  1.84it/s]avg_loss = 1.6708333333333334:   8%|▊         | 14/166 [00:08<01:22,  1.84it/s]avg_loss = 1.6708333333333334:   9%|▉         | 15/166 [00:08<01:14,  2.02it/s]avg_loss = 1.6904296875:   9%|▉         | 15/166 [00:08<01:14,  2.02it/s]      avg_loss = 1.6904296875:  10%|▉         | 16/166 [00:08<01:12,  2.07it/s]avg_loss = 1.7040441176470589:  10%|▉         | 16/166 [00:09<01:12,  2.07it/s]avg_loss = 1.7040441176470589:  10%|█         | 17/166 [00:09<01:11,  2.09it/s]avg_loss = 1.7183159722222223:  10%|█         | 17/166 [00:09<01:11,  2.09it/s]avg_loss = 1.7183159722222223:  11%|█         | 18/166 [00:09<01:10,  2.11it/s]avg_loss = 1.738075657894737:  11%|█         | 18/166 [00:10<01:10,  2.11it/s] avg_loss = 1.738075657894737:  11%|█▏        | 19/166 [00:10<01:09,  2.13it/s]avg_loss = 1.74453125:  11%|█▏        | 19/166 [00:10<01:09,  2.13it/s]       avg_loss = 1.74453125:  12%|█▏        | 20/166 [00:10<01:08,  2.12it/s]avg_loss = 1.7455357142857142:  12%|█▏        | 20/166 [00:11<01:08,  2.12it/s]avg_loss = 1.7455357142857142:  13%|█▎        | 21/166 [00:11<01:08,  2.13it/s]avg_loss = 1.7357954545454546:  13%|█▎        | 21/166 [00:11<01:08,  2.13it/s]avg_loss = 1.7357954545454546:  13%|█▎        | 22/166 [00:11<01:07,  2.13it/s]avg_loss = 1.7248641304347827:  13%|█▎        | 22/166 [00:12<01:07,  2.13it/s]avg_loss = 1.7248641304347827:  14%|█▍        | 23/166 [00:12<01:07,  2.13it/s]avg_loss = 1.732421875:  14%|█▍        | 23/166 [00:12<01:07,  2.13it/s]       avg_loss = 1.732421875:  14%|█▍        | 24/166 [00:12<01:06,  2.12it/s]avg_loss = 1.7396875:  14%|█▍        | 24/166 [00:13<01:06,  2.12it/s]  avg_loss = 1.7396875:  15%|█▌        | 25/166 [00:13<01:06,  2.13it/s]avg_loss = 1.7442908653846154:  15%|█▌        | 25/166 [00:13<01:06,  2.13it/s]avg_loss = 1.7442908653846154:  16%|█▌        | 26/166 [00:13<01:05,  2.12it/s]avg_loss = 1.7511574074074074:  16%|█▌        | 26/166 [00:14<01:05,  2.12it/s]avg_loss = 1.7511574074074074:  16%|█▋        | 27/166 [00:14<01:05,  2.12it/s]avg_loss = 1.7541852678571428:  16%|█▋        | 27/166 [00:14<01:05,  2.12it/s]avg_loss = 1.7541852678571428:  17%|█▋        | 28/166 [00:14<01:05,  2.12it/s]avg_loss = 1.763739224137931:  17%|█▋        | 28/166 [00:15<01:05,  2.12it/s] avg_loss = 1.763739224137931:  17%|█▋        | 29/166 [00:15<01:04,  2.12it/s]avg_loss = 1.7635416666666666:  17%|█▋        | 29/166 [00:15<01:04,  2.12it/s]avg_loss = 1.7635416666666666:  18%|█▊        | 30/166 [00:15<01:04,  2.11it/s]avg_loss = 1.7777217741935485:  18%|█▊        | 30/166 [00:16<01:04,  2.11it/s]avg_loss = 1.7777217741935485:  19%|█▊        | 31/166 [00:16<01:03,  2.11it/s]avg_loss = 1.7841796875:  19%|█▊        | 31/166 [00:16<01:03,  2.11it/s]      avg_loss = 1.7841796875:  19%|█▉        | 32/166 [00:16<01:03,  2.10it/s]avg_loss = 1.7892992424242424:  19%|█▉        | 32/166 [00:16<01:03,  2.10it/s]avg_loss = 1.7892992424242424:  20%|█▉        | 33/166 [00:16<01:03,  2.10it/s]avg_loss = 1.7883731617647058:  20%|█▉        | 33/166 [00:17<01:03,  2.10it/s]avg_loss = 1.7883731617647058:  20%|██        | 34/166 [00:17<01:02,  2.10it/s]avg_loss = 1.7819196428571429:  20%|██        | 34/166 [00:17<01:02,  2.10it/s]avg_loss = 1.7819196428571429:  21%|██        | 35/166 [00:17<01:02,  2.10it/s]avg_loss = 1.7734375:  21%|██        | 35/166 [00:18<01:02,  2.10it/s]         avg_loss = 1.7734375:  22%|██▏       | 36/166 [00:18<01:02,  2.09it/s]avg_loss = 1.7635135135135136:  22%|██▏       | 36/166 [00:18<01:02,  2.09it/s]avg_loss = 1.7635135135135136:  22%|██▏       | 37/166 [00:18<01:01,  2.09it/s]avg_loss = 1.7606907894736843:  22%|██▏       | 37/166 [00:19<01:01,  2.09it/s]avg_loss = 1.7606907894736843:  23%|██▎       | 38/166 [00:19<01:01,  2.08it/s]avg_loss = 1.7586137820512822:  23%|██▎       | 38/166 [00:19<01:01,  2.08it/s]avg_loss = 1.7586137820512822:  23%|██▎       | 39/166 [00:19<01:00,  2.09it/s]avg_loss = 1.762109375:  23%|██▎       | 39/166 [00:20<01:00,  2.09it/s]       avg_loss = 1.762109375:  24%|██▍       | 40/166 [00:20<01:00,  2.08it/s]avg_loss = 1.7620045731707317:  24%|██▍       | 40/166 [00:20<01:00,  2.08it/s]avg_loss = 1.7620045731707317:  25%|██▍       | 41/166 [00:20<01:00,  2.08it/s]avg_loss = 1.7496279761904763:  25%|██▍       | 41/166 [00:21<01:00,  2.08it/s]avg_loss = 1.7496279761904763:  25%|██▌       | 42/166 [00:21<00:59,  2.07it/s]avg_loss = 1.7341933139534884:  25%|██▌       | 42/166 [00:21<00:59,  2.07it/s]avg_loss = 1.7341933139534884:  26%|██▌       | 43/166 [00:21<00:59,  2.07it/s]avg_loss = 1.7240767045454546:  26%|██▌       | 43/166 [00:22<00:59,  2.07it/s]avg_loss = 1.7240767045454546:  27%|██▋       | 44/166 [00:22<00:59,  2.06it/s]avg_loss = 1.7104166666666667:  27%|██▋       | 44/166 [00:22<00:59,  2.06it/s]avg_loss = 1.7104166666666667:  27%|██▋       | 45/166 [00:22<00:58,  2.06it/s]avg_loss = 1.699898097826087:  27%|██▋       | 45/166 [00:23<00:58,  2.06it/s] avg_loss = 1.699898097826087:  28%|██▊       | 46/166 [00:23<00:58,  2.06it/s]avg_loss = 1.6928191489361701:  28%|██▊       | 46/166 [00:23<00:58,  2.06it/s]avg_loss = 1.6928191489361701:  28%|██▊       | 47/166 [00:23<00:57,  2.05it/s]avg_loss = 1.6936848958333333:  28%|██▊       | 47/166 [00:24<00:57,  2.05it/s]avg_loss = 1.6936848958333333:  29%|██▉       | 48/166 [00:24<00:57,  2.05it/s]avg_loss = 1.7044005102040816:  29%|██▉       | 48/166 [00:24<00:57,  2.05it/s]avg_loss = 1.7044005102040816:  30%|██▉       | 49/166 [00:24<00:57,  2.05it/s]avg_loss = 1.715:  30%|██▉       | 49/166 [00:25<00:57,  2.05it/s]             avg_loss = 1.715:  30%|███       | 50/166 [00:25<00:56,  2.04it/s]avg_loss = 1.7221200980392157:  30%|███       | 50/166 [00:25<00:56,  2.04it/s]avg_loss = 1.7221200980392157:  31%|███       | 51/166 [00:25<00:56,  2.04it/s]avg_loss = 1.7271634615384615:  31%|███       | 51/166 [00:26<00:56,  2.04it/s]avg_loss = 1.7271634615384615:  31%|███▏      | 52/166 [00:26<00:56,  2.03it/s]avg_loss = 1.7305424528301887:  31%|███▏      | 52/166 [00:26<00:56,  2.03it/s]avg_loss = 1.7305424528301887:  32%|███▏      | 53/166 [00:26<00:55,  2.04it/s]avg_loss = 1.7316261574074074:  32%|███▏      | 53/166 [00:27<00:55,  2.04it/s]avg_loss = 1.7316261574074074:  33%|███▎      | 54/166 [00:27<00:55,  2.03it/s]avg_loss = 1.7342329545454545:  33%|███▎      | 54/166 [00:27<00:55,  2.03it/s]avg_loss = 1.7342329545454545:  33%|███▎      | 55/166 [00:27<00:54,  2.03it/s]avg_loss = 1.7377232142857142:  33%|███▎      | 55/166 [00:28<00:54,  2.03it/s]avg_loss = 1.7377232142857142:  34%|███▎      | 56/166 [00:28<00:54,  2.03it/s]avg_loss = 1.7327302631578947:  34%|███▎      | 56/166 [00:28<00:54,  2.03it/s]avg_loss = 1.7327302631578947:  34%|███▍      | 57/166 [00:28<00:53,  2.02it/s]avg_loss = 1.736395474137931:  34%|███▍      | 57/166 [00:29<00:53,  2.02it/s] avg_loss = 1.736395474137931:  35%|███▍      | 58/166 [00:29<00:53,  2.02it/s]avg_loss = 1.734772245762712:  35%|███▍      | 58/166 [00:29<00:53,  2.02it/s]avg_loss = 1.734772245762712:  36%|███▌      | 59/166 [00:29<00:53,  2.02it/s]avg_loss = 1.7298177083333333:  36%|███▌      | 59/166 [00:30<00:53,  2.02it/s]avg_loss = 1.7298177083333333:  36%|███▌      | 60/166 [00:30<00:52,  2.01it/s]avg_loss = 1.7254098360655739:  36%|███▌      | 60/166 [00:30<00:52,  2.01it/s]avg_loss = 1.7254098360655739:  37%|███▋      | 61/166 [00:30<00:52,  2.01it/s]avg_loss = 1.7215221774193548:  37%|███▋      | 61/166 [00:31<00:52,  2.01it/s]avg_loss = 1.7215221774193548:  37%|███▋      | 62/166 [00:31<00:51,  2.01it/s]avg_loss = 1.7156498015873016:  37%|███▋      | 62/166 [00:31<00:51,  2.01it/s]avg_loss = 1.7156498015873016:  38%|███▊      | 63/166 [00:31<00:51,  2.00it/s]avg_loss = 1.71142578125:  38%|███▊      | 63/166 [00:32<00:51,  2.00it/s]     avg_loss = 1.71142578125:  39%|███▊      | 64/166 [00:32<00:51,  2.00it/s]avg_loss = 1.7048076923076922:  39%|███▊      | 64/166 [00:32<00:51,  2.00it/s]avg_loss = 1.7048076923076922:  39%|███▉      | 65/166 [00:32<00:50,  1.99it/s]avg_loss = 1.6976799242424243:  39%|███▉      | 65/166 [00:33<00:50,  1.99it/s]avg_loss = 1.6976799242424243:  40%|███▉      | 66/166 [00:33<00:50,  1.99it/s]avg_loss = 1.6915811567164178:  40%|███▉      | 66/166 [00:33<00:50,  1.99it/s]avg_loss = 1.6915811567164178:  40%|████      | 67/166 [00:33<00:49,  1.99it/s]avg_loss = 1.6903722426470589:  40%|████      | 67/166 [00:34<00:49,  1.99it/s]avg_loss = 1.6903722426470589:  41%|████      | 68/166 [00:34<00:49,  1.98it/s]avg_loss = 1.6923686594202898:  41%|████      | 68/166 [00:34<00:49,  1.98it/s]avg_loss = 1.6923686594202898:  42%|████▏     | 69/166 [00:34<00:48,  1.98it/s]avg_loss = 1.6953125:  42%|████▏     | 69/166 [00:35<00:48,  1.98it/s]         avg_loss = 1.6953125:  42%|████▏     | 70/166 [00:35<00:48,  1.98it/s]avg_loss = 1.6992737676056338:  42%|████▏     | 70/166 [00:35<00:48,  1.98it/s]avg_loss = 1.6992737676056338:  43%|████▎     | 71/166 [00:35<00:48,  1.97it/s]avg_loss = 1.7041015625:  43%|████▎     | 71/166 [00:36<00:48,  1.97it/s]      avg_loss = 1.7041015625:  43%|████▎     | 72/166 [00:36<00:47,  1.97it/s]avg_loss = 1.7102953767123288:  43%|████▎     | 72/166 [00:36<00:47,  1.97it/s]avg_loss = 1.7102953767123288:  44%|████▍     | 73/166 [00:36<00:47,  1.97it/s]avg_loss = 1.7046030405405406:  44%|████▍     | 73/166 [00:37<00:47,  1.97it/s]avg_loss = 1.7046030405405406:  45%|████▍     | 74/166 [00:37<00:46,  1.96it/s]avg_loss = 1.7:  45%|████▍     | 74/166 [00:37<00:46,  1.96it/s]               avg_loss = 1.7:  45%|████▌     | 75/166 [00:37<00:46,  1.96it/s]avg_loss = 1.6991159539473684:  45%|████▌     | 75/166 [00:38<00:46,  1.96it/s]avg_loss = 1.6991159539473684:  46%|████▌     | 76/166 [00:38<00:43,  2.07it/s]avg_loss = 1.6956168831168832:  46%|████▌     | 76/166 [00:38<00:43,  2.07it/s]avg_loss = 1.6956168831168832:  46%|████▋     | 77/166 [00:38<00:42,  2.09it/s]avg_loss = 1.6920072115384615:  46%|████▋     | 77/166 [00:39<00:42,  2.09it/s]avg_loss = 1.6920072115384615:  47%|████▋     | 78/166 [00:39<00:41,  2.10it/s]avg_loss = 1.6892800632911393:  47%|████▋     | 78/166 [00:39<00:41,  2.10it/s]avg_loss = 1.6892800632911393:  48%|████▊     | 79/166 [00:39<00:41,  2.11it/s]avg_loss = 1.6857421875:  48%|████▊     | 79/166 [00:40<00:41,  2.11it/s]      avg_loss = 1.6857421875:  48%|████▊     | 80/166 [00:40<00:40,  2.12it/s]avg_loss = 1.6763599537037037:  48%|████▊     | 80/166 [00:40<00:40,  2.12it/s]avg_loss = 1.6763599537037037:  49%|████▉     | 81/166 [00:40<00:40,  2.12it/s]avg_loss = 1.6781154725609757:  49%|████▉     | 81/166 [00:41<00:40,  2.12it/s]avg_loss = 1.6781154725609757:  49%|████▉     | 82/166 [00:41<00:39,  2.13it/s]avg_loss = 1.6800169427710843:  49%|████▉     | 82/166 [00:41<00:39,  2.13it/s]avg_loss = 1.6800169427710843:  50%|█████     | 83/166 [00:41<00:39,  2.13it/s]avg_loss = 1.6831752232142858:  50%|█████     | 83/166 [00:41<00:39,  2.13it/s]avg_loss = 1.6831752232142858:  51%|█████     | 84/166 [00:41<00:38,  2.12it/s]avg_loss = 1.6850643382352941:  51%|█████     | 84/166 [00:42<00:38,  2.12it/s]avg_loss = 1.6850643382352941:  51%|█████     | 85/166 [00:42<00:38,  2.12it/s]avg_loss = 1.684002543604651:  51%|█████     | 85/166 [00:42<00:38,  2.12it/s] avg_loss = 1.684002543604651:  52%|█████▏    | 86/166 [00:42<00:37,  2.12it/s]avg_loss = 1.6843121408045978:  52%|█████▏    | 86/166 [00:43<00:37,  2.12it/s]avg_loss = 1.6843121408045978:  52%|█████▏    | 87/166 [00:43<00:37,  2.11it/s]avg_loss = 1.6846147017045454:  52%|█████▏    | 87/166 [00:43<00:37,  2.11it/s]avg_loss = 1.6846147017045454:  53%|█████▎    | 88/166 [00:43<00:36,  2.11it/s]avg_loss = 1.6858760533707866:  53%|█████▎    | 88/166 [00:44<00:36,  2.11it/s]avg_loss = 1.6858760533707866:  54%|█████▎    | 89/166 [00:44<00:36,  2.11it/s]avg_loss = 1.685720486111111:  54%|█████▎    | 89/166 [00:44<00:36,  2.11it/s] avg_loss = 1.685720486111111:  54%|█████▍    | 90/166 [00:44<00:36,  2.11it/s]avg_loss = 1.6861692994505495:  54%|█████▍    | 90/166 [00:45<00:36,  2.11it/s]avg_loss = 1.6861692994505495:  55%|█████▍    | 91/166 [00:45<00:35,  2.11it/s]avg_loss = 1.6873726222826086:  55%|█████▍    | 91/166 [00:45<00:35,  2.11it/s]avg_loss = 1.6873726222826086:  55%|█████▌    | 92/166 [00:45<00:35,  2.10it/s]avg_loss = 1.6912382392473118:  55%|█████▌    | 92/166 [00:46<00:35,  2.10it/s]avg_loss = 1.6912382392473118:  56%|█████▌    | 93/166 [00:46<00:34,  2.09it/s]avg_loss = 1.6903673537234043:  56%|█████▌    | 93/166 [00:46<00:34,  2.09it/s]avg_loss = 1.6903673537234043:  57%|█████▋    | 94/166 [00:46<00:34,  2.09it/s]avg_loss = 1.6896792763157895:  57%|█████▋    | 94/166 [00:47<00:34,  2.09it/s]avg_loss = 1.6896792763157895:  57%|█████▋    | 95/166 [00:47<00:34,  2.09it/s]avg_loss = 1.6893310546875:  57%|█████▋    | 95/166 [00:47<00:34,  2.09it/s]   avg_loss = 1.6893310546875:  58%|█████▊    | 96/166 [00:47<00:33,  2.09it/s]avg_loss = 1.689231636597938:  58%|█████▊    | 96/166 [00:48<00:33,  2.09it/s]avg_loss = 1.689231636597938:  58%|█████▊    | 97/166 [00:48<00:33,  2.08it/s]avg_loss = 1.6876195790816326:  58%|█████▊    | 97/166 [00:48<00:33,  2.08it/s]avg_loss = 1.6876195790816326:  59%|█████▉    | 98/166 [00:48<00:32,  2.07it/s]avg_loss = 1.685250946969697:  59%|█████▉    | 98/166 [00:49<00:32,  2.07it/s] avg_loss = 1.685250946969697:  60%|█████▉    | 99/166 [00:49<00:32,  2.07it/s]avg_loss = 1.6825390625:  60%|█████▉    | 99/166 [00:49<00:32,  2.07it/s]     avg_loss = 1.6825390625:  60%|██████    | 100/166 [00:49<00:31,  2.07it/s]avg_loss = 1.682974938118812:  60%|██████    | 100/166 [00:50<00:31,  2.07it/s]avg_loss = 1.682974938118812:  61%|██████    | 101/166 [00:50<00:31,  2.06it/s]avg_loss = 1.684015012254902:  61%|██████    | 101/166 [00:50<00:31,  2.06it/s]avg_loss = 1.684015012254902:  61%|██████▏   | 102/166 [00:50<00:31,  2.06it/s]avg_loss = 1.6851107402912622:  61%|██████▏   | 102/166 [00:51<00:31,  2.06it/s]avg_loss = 1.6851107402912622:  62%|██████▏   | 103/166 [00:51<00:30,  2.06it/s]avg_loss = 1.6873121995192308:  62%|██████▏   | 103/166 [00:51<00:30,  2.06it/s]avg_loss = 1.6873121995192308:  63%|██████▎   | 104/166 [00:51<00:30,  2.06it/s]avg_loss = 1.6940104166666667:  63%|██████▎   | 104/166 [00:52<00:30,  2.06it/s]avg_loss = 1.6940104166666667:  63%|██████▎   | 105/166 [00:52<00:29,  2.05it/s]avg_loss = 1.6992556014150944:  63%|██████▎   | 105/166 [00:52<00:29,  2.05it/s]avg_loss = 1.6992556014150944:  64%|██████▍   | 106/166 [00:52<00:29,  2.05it/s]avg_loss = 1.702796436915888:  64%|██████▍   | 106/166 [00:53<00:29,  2.05it/s] avg_loss = 1.702796436915888:  64%|██████▍   | 107/166 [00:53<00:28,  2.05it/s]avg_loss = 1.705982349537037:  64%|██████▍   | 107/166 [00:53<00:28,  2.05it/s]avg_loss = 1.705982349537037:  65%|██████▌   | 108/166 [00:53<00:28,  2.04it/s]avg_loss = 1.710686639908257:  65%|██████▌   | 108/166 [00:54<00:28,  2.04it/s]avg_loss = 1.710686639908257:  66%|██████▌   | 109/166 [00:54<00:27,  2.04it/s]avg_loss = 1.714169034090909:  66%|██████▌   | 109/166 [00:54<00:27,  2.04it/s]avg_loss = 1.714169034090909:  66%|██████▋   | 110/166 [00:54<00:27,  2.04it/s]avg_loss = 1.7157587274774775:  66%|██████▋   | 110/166 [00:54<00:27,  2.04it/s]avg_loss = 1.7157587274774775:  67%|██████▋   | 111/166 [00:54<00:27,  2.03it/s]avg_loss = 1.717041015625:  67%|██████▋   | 111/166 [00:55<00:27,  2.03it/s]    avg_loss = 1.717041015625:  67%|██████▋   | 112/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7174018252212389:  67%|██████▋   | 112/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7174018252212389:  68%|██████▊   | 113/166 [00:55<00:26,  2.03it/s]avg_loss = 1.7187842653508771:  68%|██████▊   | 113/166 [00:56<00:26,  2.03it/s]avg_loss = 1.7187842653508771:  69%|██████▊   | 114/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7155910326086956:  69%|██████▊   | 114/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7155910326086956:  69%|██████▉   | 115/166 [00:56<00:25,  2.02it/s]avg_loss = 1.7148774245689655:  69%|██████▉   | 115/166 [00:57<00:25,  2.02it/s]avg_loss = 1.7148774245689655:  70%|██████▉   | 116/166 [00:57<00:24,  2.01it/s]avg_loss = 1.7158453525641026:  70%|██████▉   | 116/166 [00:57<00:24,  2.01it/s]avg_loss = 1.7158453525641026:  70%|███████   | 117/166 [00:57<00:24,  2.02it/s]avg_loss = 1.7159361758474576:  70%|███████   | 117/166 [00:58<00:24,  2.02it/s]avg_loss = 1.7159361758474576:  71%|███████   | 118/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7153033088235294:  71%|███████   | 118/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7153033088235294:  72%|███████▏  | 119/166 [00:58<00:23,  2.01it/s]avg_loss = 1.7158528645833333:  72%|███████▏  | 119/166 [00:59<00:23,  2.01it/s]avg_loss = 1.7158528645833333:  72%|███████▏  | 120/166 [00:59<00:22,  2.00it/s]avg_loss = 1.71510201446281:  72%|███████▏  | 120/166 [00:59<00:22,  2.00it/s]  avg_loss = 1.71510201446281:  73%|███████▎  | 121/166 [00:59<00:22,  2.00it/s]avg_loss = 1.7153880635245902:  73%|███████▎  | 121/166 [01:00<00:22,  2.00it/s]avg_loss = 1.7153880635245902:  73%|███████▎  | 122/166 [01:00<00:21,  2.00it/s]avg_loss = 1.7156059451219512:  73%|███████▎  | 122/166 [01:00<00:21,  2.00it/s]avg_loss = 1.7156059451219512:  74%|███████▍  | 123/166 [01:00<00:21,  1.99it/s]avg_loss = 1.7141192036290323:  74%|███████▍  | 123/166 [01:01<00:21,  1.99it/s]avg_loss = 1.7141192036290323:  75%|███████▍  | 124/166 [01:01<00:21,  1.99it/s]avg_loss = 1.71240625:  75%|███████▍  | 124/166 [01:01<00:21,  1.99it/s]        avg_loss = 1.71240625:  75%|███████▌  | 125/166 [01:01<00:20,  1.99it/s]avg_loss = 1.7101004464285714:  75%|███████▌  | 125/166 [01:02<00:20,  1.99it/s]avg_loss = 1.7101004464285714:  76%|███████▌  | 126/166 [01:02<00:20,  1.98it/s]avg_loss = 1.707892470472441:  76%|███████▌  | 126/166 [01:03<00:20,  1.98it/s] avg_loss = 1.707892470472441:  77%|███████▋  | 127/166 [01:03<00:19,  1.99it/s]avg_loss = 1.706329345703125:  77%|███████▋  | 127/166 [01:03<00:19,  1.99it/s]avg_loss = 1.706329345703125:  77%|███████▋  | 128/166 [01:03<00:19,  1.98it/s]avg_loss = 1.7049721414728682:  77%|███████▋  | 128/166 [01:04<00:19,  1.98it/s]avg_loss = 1.7049721414728682:  78%|███████▊  | 129/166 [01:04<00:18,  1.97it/s]avg_loss = 1.7048377403846153:  78%|███████▊  | 129/166 [01:04<00:18,  1.97it/s]avg_loss = 1.7048377403846153:  78%|███████▊  | 130/166 [01:04<00:18,  1.97it/s]avg_loss = 1.705838501908397:  78%|███████▊  | 130/166 [01:05<00:18,  1.97it/s] avg_loss = 1.705838501908397:  79%|███████▉  | 131/166 [01:05<00:17,  1.96it/s]avg_loss = 1.7064098011363635:  79%|███████▉  | 131/166 [01:05<00:17,  1.96it/s]avg_loss = 1.7064098011363635:  80%|███████▉  | 132/166 [01:05<00:17,  1.96it/s]avg_loss = 1.7073249530075187:  80%|███████▉  | 132/166 [01:06<00:17,  1.96it/s]avg_loss = 1.7073249530075187:  80%|████████  | 133/166 [01:06<00:16,  1.96it/s]avg_loss = 1.708634561567164:  80%|████████  | 133/166 [01:06<00:16,  1.96it/s] avg_loss = 1.708634561567164:  81%|████████  | 134/166 [01:06<00:16,  1.96it/s]avg_loss = 1.7066261574074073:  81%|████████  | 134/166 [01:07<00:16,  1.96it/s]avg_loss = 1.7066261574074073:  81%|████████▏ | 135/166 [01:07<00:15,  1.96it/s]avg_loss = 1.7069450827205883:  81%|████████▏ | 135/166 [01:07<00:15,  1.96it/s]avg_loss = 1.7069450827205883:  82%|████████▏ | 136/166 [01:07<00:14,  2.05it/s]avg_loss = 1.7072023266423357:  82%|████████▏ | 136/166 [01:07<00:14,  2.05it/s]avg_loss = 1.7072023266423357:  83%|████████▎ | 137/166 [01:07<00:13,  2.07it/s]avg_loss = 1.7080219655797102:  83%|████████▎ | 137/166 [01:08<00:13,  2.07it/s]avg_loss = 1.7080219655797102:  83%|████████▎ | 138/166 [01:08<00:13,  2.09it/s]avg_loss = 1.7071998651079137:  83%|████████▎ | 138/166 [01:08<00:13,  2.09it/s]avg_loss = 1.7071998651079137:  84%|████████▎ | 139/166 [01:08<00:12,  2.11it/s]avg_loss = 1.705943080357143:  84%|████████▎ | 139/166 [01:09<00:12,  2.11it/s] avg_loss = 1.705943080357143:  84%|████████▍ | 140/166 [01:09<00:12,  2.11it/s]avg_loss = 1.7045933067375887:  84%|████████▍ | 140/166 [01:09<00:12,  2.11it/s]avg_loss = 1.7045933067375887:  85%|████████▍ | 141/166 [01:09<00:11,  2.11it/s]avg_loss = 1.7041978433098592:  85%|████████▍ | 141/166 [01:10<00:11,  2.11it/s]avg_loss = 1.7041978433098592:  86%|████████▌ | 142/166 [01:10<00:11,  2.12it/s]avg_loss = 1.7026059877622377:  86%|████████▌ | 142/166 [01:10<00:11,  2.12it/s]avg_loss = 1.7026059877622377:  86%|████████▌ | 143/166 [01:10<00:10,  2.12it/s]avg_loss = 1.7038031684027777:  86%|████████▌ | 143/166 [01:11<00:10,  2.12it/s]avg_loss = 1.7038031684027777:  87%|████████▋ | 144/166 [01:11<00:10,  2.13it/s]avg_loss = 1.7030441810344827:  87%|████████▋ | 144/166 [01:11<00:10,  2.13it/s]avg_loss = 1.7030441810344827:  87%|████████▋ | 145/166 [01:11<00:09,  2.12it/s]avg_loss = 1.7029912243150684:  87%|████████▋ | 145/166 [01:12<00:09,  2.12it/s]avg_loss = 1.7029912243150684:  88%|████████▊ | 146/166 [01:12<00:09,  2.11it/s]avg_loss = 1.7018760629251701:  88%|████████▊ | 146/166 [01:12<00:09,  2.11it/s]avg_loss = 1.7018760629251701:  89%|████████▊ | 147/166 [01:12<00:08,  2.12it/s]avg_loss = 1.7009871199324325:  89%|████████▊ | 147/166 [01:13<00:08,  2.12it/s]avg_loss = 1.7009871199324325:  89%|████████▉ | 148/166 [01:13<00:08,  2.11it/s]avg_loss = 1.699271182885906:  89%|████████▉ | 148/166 [01:13<00:08,  2.11it/s] avg_loss = 1.699271182885906:  90%|████████▉ | 149/166 [01:13<00:08,  2.10it/s]avg_loss = 1.700234375:  90%|████████▉ | 149/166 [01:14<00:08,  2.10it/s]      avg_loss = 1.700234375:  90%|█████████ | 150/166 [01:14<00:07,  2.10it/s]avg_loss = 1.699373965231788:  90%|█████████ | 150/166 [01:14<00:07,  2.10it/s]avg_loss = 1.699373965231788:  91%|█████████ | 151/166 [01:14<00:07,  2.10it/s]avg_loss = 1.6991416529605263:  91%|█████████ | 151/166 [01:15<00:07,  2.10it/s]avg_loss = 1.6991416529605263:  92%|█████████▏| 152/166 [01:15<00:06,  2.09it/s]avg_loss = 1.6989123774509804:  92%|█████████▏| 152/166 [01:15<00:06,  2.09it/s]avg_loss = 1.6989123774509804:  92%|█████████▏| 153/166 [01:15<00:06,  2.09it/s]avg_loss = 1.7004109172077921:  92%|█████████▏| 153/166 [01:16<00:06,  2.09it/s]avg_loss = 1.7004109172077921:  93%|█████████▎| 154/166 [01:16<00:05,  2.09it/s]avg_loss = 1.699873991935484:  93%|█████████▎| 154/166 [01:16<00:05,  2.09it/s] avg_loss = 1.699873991935484:  93%|█████████▎| 155/166 [01:16<00:05,  2.08it/s]avg_loss = 1.6997445913461537:  93%|█████████▎| 155/166 [01:17<00:05,  2.08it/s]avg_loss = 1.6997445913461537:  94%|█████████▍| 156/166 [01:17<00:04,  2.08it/s]avg_loss = 1.6979747213375795:  94%|█████████▍| 156/166 [01:17<00:04,  2.08it/s]avg_loss = 1.6979747213375795:  95%|█████████▍| 157/166 [01:17<00:04,  2.08it/s]avg_loss = 1.6937054984177216:  95%|█████████▍| 157/166 [01:17<00:04,  2.08it/s]avg_loss = 1.6937054984177216:  95%|█████████▌| 158/166 [01:17<00:03,  2.07it/s]avg_loss = 1.6945509040880504:  95%|█████████▌| 158/166 [01:18<00:03,  2.07it/s]avg_loss = 1.6945509040880504:  96%|█████████▌| 159/166 [01:18<00:03,  2.06it/s]avg_loss = 1.6959716796875:  96%|█████████▌| 159/166 [01:18<00:03,  2.06it/s]   avg_loss = 1.6959716796875:  96%|█████████▋| 160/166 [01:18<00:02,  2.06it/s]avg_loss = 1.698345302795031:  96%|█████████▋| 160/166 [01:19<00:02,  2.06it/s]avg_loss = 1.698345302795031:  97%|█████████▋| 161/166 [01:19<00:02,  2.06it/s]avg_loss = 1.6984712577160495:  97%|█████████▋| 161/166 [01:19<00:02,  2.06it/s]avg_loss = 1.6984712577160495:  98%|█████████▊| 162/166 [01:19<00:01,  2.06it/s]avg_loss = 1.698020513803681:  98%|█████████▊| 162/166 [01:20<00:01,  2.06it/s] avg_loss = 1.698020513803681:  98%|█████████▊| 163/166 [01:20<00:01,  2.05it/s]avg_loss = 1.6986232850609757:  98%|█████████▊| 163/166 [01:20<00:01,  2.05it/s]avg_loss = 1.6986232850609757:  99%|█████████▉| 164/166 [01:20<00:00,  2.05it/s]avg_loss = 1.6987452651515151:  99%|█████████▉| 164/166 [01:21<00:00,  2.05it/s]avg_loss = 1.6987452651515151:  99%|█████████▉| 165/166 [01:21<00:00,  2.05it/s]avg_loss = 1.7006541792168675:  99%|█████████▉| 165/166 [01:21<00:00,  2.05it/s]avg_loss = 1.7006541792168675: 100%|██████████| 166/166 [01:21<00:00,  2.04it/s]avg_loss = 1.7006541792168675: 100%|██████████| 166/166 [01:21<00:00,  2.03it/s]
I0303 07:25:15.139293 3069716 eval_ppl.py:105] wikitext2 perplexity: 5.477529525756836
wikitext2 perplexity: 5.478
Running with lmbda=100000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  8.53it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  8.63it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  9.29it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.90it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.60it/s]
calculating model weight mean & std:   0%|          | 0/32 [00:00<?, ?it/s]calculating model weight mean & std:   3%|▎         | 1/32 [00:00<00:20,  1.51it/s]calculating model weight mean & std:   6%|▋         | 2/32 [00:01<00:19,  1.51it/s]calculating model weight mean & std:   9%|▉         | 3/32 [00:02<00:19,  1.47it/s]calculating model weight mean & std:  12%|█▎        | 4/32 [00:02<00:21,  1.29it/s]calculating model weight mean & std:  16%|█▌        | 5/32 [00:03<00:19,  1.42it/s]calculating model weight mean & std:  19%|█▉        | 6/32 [00:04<00:17,  1.45it/s]calculating model weight mean & std:  22%|██▏       | 7/32 [00:04<00:17,  1.47it/s]calculating model weight mean & std:  25%|██▌       | 8/32 [00:05<00:15,  1.54it/s]calculating model weight mean & std:  28%|██▊       | 9/32 [00:06<00:14,  1.57it/s]calculating model weight mean & std:  31%|███▏      | 10/32 [00:06<00:13,  1.68it/s]calculating model weight mean & std:  34%|███▍      | 11/32 [00:06<00:11,  1.83it/s]calculating model weight mean & std:  38%|███▊      | 12/32 [00:07<00:10,  1.96it/s]calculating model weight mean & std:  41%|████      | 13/32 [00:07<00:09,  1.96it/s]calculating model weight mean & std:  44%|████▍     | 14/32 [00:08<00:08,  2.09it/s]calculating model weight mean & std:  47%|████▋     | 15/32 [00:08<00:07,  2.16it/s]calculating model weight mean & std:  50%|█████     | 16/32 [00:09<00:07,  2.24it/s]calculating model weight mean & std:  53%|█████▎    | 17/32 [00:09<00:06,  2.25it/s]calculating model weight mean & std:  56%|█████▋    | 18/32 [00:09<00:06,  2.33it/s]calculating model weight mean & std:  59%|█████▉    | 19/32 [00:10<00:05,  2.37it/s]calculating model weight mean & std:  62%|██████▎   | 20/32 [00:10<00:05,  2.29it/s]calculating model weight mean & std:  66%|██████▌   | 21/32 [00:11<00:04,  2.31it/s]calculating model weight mean & std:  69%|██████▉   | 22/32 [00:11<00:04,  2.34it/s]calculating model weight mean & std:  72%|███████▏  | 23/32 [00:12<00:03,  2.33it/s]calculating model weight mean & std:  75%|███████▌  | 24/32 [00:12<00:03,  2.26it/s]calculating model weight mean & std:  78%|███████▊  | 25/32 [00:13<00:03,  2.26it/s]calculating model weight mean & std:  81%|████████▏ | 26/32 [00:13<00:02,  2.16it/s]calculating model weight mean & std:  84%|████████▍ | 27/32 [00:14<00:02,  2.13it/s]calculating model weight mean & std:  88%|████████▊ | 28/32 [00:14<00:01,  2.15it/s]calculating model weight mean & std:  91%|█████████ | 29/32 [00:14<00:01,  2.18it/s]calculating model weight mean & std:  94%|█████████▍| 30/32 [00:15<00:00,  2.18it/s]calculating model weight mean & std:  97%|█████████▋| 31/32 [00:15<00:00,  2.27it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  2.27it/s]calculating model weight mean & std: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]
pseudo compress quantization...:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-03 07:26:05 - INFO - layer0_self_attn.q_proj | mse: 0.009724989496279186, bpp_loss: 5.728229610947892, bpp: 0
2025-03-03 07:26:15 - INFO - layer0_self_attn.k_proj | mse: 0.007447737317035107, bpp_loss: 5.840769947506487, bpp: 0
2025-03-03 07:26:27 - INFO - layer0_self_attn.v_proj | mse: 0.0016204404819663116, bpp_loss: 5.700670313090086, bpp: 0
2025-03-03 07:26:40 - INFO - layer0_self_attn.o_proj | mse: 0.001692574125970097, bpp_loss: 5.542070319526829, bpp: 0
2025-03-03 07:26:54 - INFO - layer0_mlp.gate_proj | mse: 0.0013067181925314453, bpp_loss: 6.024213773479988, bpp: 0
2025-03-03 07:27:06 - INFO - layer0_mlp.up_proj | mse: 0.0012924068022379875, bpp_loss: 6.007183545550634, bpp: 0
2025-03-03 07:27:38 - INFO - layer0_mlp.down_proj | mse: 0.0015354141016239685, bpp_loss: 6.051168358863094, bpp: 0
pseudo compress quantization...:   3%|▎         | 1/32 [01:46<55:01, 106.49s/it]2025-03-03 07:27:49 - INFO - layer1_self_attn.q_proj | mse: 0.00635321000940639, bpp_loss: 6.588591849897057, bpp: 0
2025-03-03 07:28:02 - INFO - layer1_self_attn.k_proj | mse: 0.008093931353295562, bpp_loss: 6.6051005714107305, bpp: 0
2025-03-03 07:28:14 - INFO - layer1_self_attn.v_proj | mse: 0.001739691083125384, bpp_loss: 5.656693717115559, bpp: 0
2025-03-03 07:28:26 - INFO - layer1_self_attn.o_proj | mse: 0.0016504292181247588, bpp_loss: 5.58097706863191, bpp: 0
2025-03-03 07:28:38 - INFO - layer1_mlp.gate_proj | mse: 0.0014100185110446106, bpp_loss: 6.145522441715002, bpp: 0
2025-03-03 07:28:52 - INFO - layer1_mlp.up_proj | mse: 0.001372196609703205, bpp_loss: 6.074638278591771, bpp: 0
2025-03-03 07:29:28 - INFO - layer1_mlp.down_proj | mse: 0.0014393523471496372, bpp_loss: 6.091411729841385, bpp: 0
pseudo compress quantization...:   6%|▋         | 2/32 [03:36<54:14, 108.49s/it]2025-03-03 07:29:39 - INFO - layer2_self_attn.q_proj | mse: 0.0017965880938650694, bpp_loss: 6.736670304089785, bpp: 0
2025-03-03 07:29:50 - INFO - layer2_self_attn.k_proj | mse: 0.001883626297628423, bpp_loss: 6.836336453212425, bpp: 0
2025-03-03 07:30:00 - INFO - layer2_self_attn.v_proj | mse: 0.0012353281936692694, bpp_loss: 5.892891189898364, bpp: 0
2025-03-03 07:30:11 - INFO - layer2_self_attn.o_proj | mse: 0.0012937363742392836, bpp_loss: 5.865684014861472, bpp: 0
2025-03-03 07:30:26 - INFO - layer2_mlp.gate_proj | mse: 0.0013232435970788512, bpp_loss: 6.1842554854445675, bpp: 0
2025-03-03 07:30:41 - INFO - layer2_mlp.up_proj | mse: 0.0012842368726995925, bpp_loss: 6.0964706162380615, bpp: 0
2025-03-03 07:31:15 - INFO - layer2_mlp.down_proj | mse: 0.0011298820403567557, bpp_loss: 6.103762410147938, bpp: 0
pseudo compress quantization...:   9%|▉         | 3/32 [05:23<52:05, 107.77s/it]2025-03-03 07:31:28 - INFO - layer3_self_attn.q_proj | mse: 0.0015651118576477036, bpp_loss: 6.632441111258231, bpp: 0
2025-03-03 07:31:39 - INFO - layer3_self_attn.k_proj | mse: 0.0016088314891947396, bpp_loss: 6.710873594856821, bpp: 0
2025-03-03 07:31:50 - INFO - layer3_self_attn.v_proj | mse: 0.0011104146890799965, bpp_loss: 5.848733077873476, bpp: 0
2025-03-03 07:32:00 - INFO - layer3_self_attn.o_proj | mse: 0.0010891501250219358, bpp_loss: 5.830171853303909, bpp: 0
2025-03-03 07:32:12 - INFO - layer3_mlp.gate_proj | mse: 0.0012580853367975655, bpp_loss: 6.20405122811018, bpp: 0
2025-03-03 07:32:25 - INFO - layer3_mlp.up_proj | mse: 0.0012069988881265462, bpp_loss: 6.104910366670337, bpp: 0
2025-03-03 07:33:02 - INFO - layer3_mlp.down_proj | mse: 0.0011131202910341432, bpp_loss: 6.1068967376337495, bpp: 0
pseudo compress quantization...:  12%|█▎        | 4/32 [07:10<50:10, 107.50s/it]2025-03-03 07:33:13 - INFO - layer4_self_attn.q_proj | mse: 0.001605420221569123, bpp_loss: 6.73118514334783, bpp: 0
2025-03-03 07:33:26 - INFO - layer4_self_attn.k_proj | mse: 0.001651733068346206, bpp_loss: 6.774480191990733, bpp: 0
2025-03-03 07:33:40 - INFO - layer4_self_attn.v_proj | mse: 0.0011128185101520606, bpp_loss: 5.89424911653623, bpp: 0
2025-03-03 07:33:51 - INFO - layer4_self_attn.o_proj | mse: 0.0011020196029089924, bpp_loss: 5.875167985446751, bpp: 0
2025-03-03 07:34:03 - INFO - layer4_mlp.gate_proj | mse: 0.0012611004170085289, bpp_loss: 6.232109682504521, bpp: 0
2025-03-03 07:34:15 - INFO - layer4_mlp.up_proj | mse: 0.0011898959615115597, bpp_loss: 6.096501665752988, bpp: 0
2025-03-03 07:34:47 - INFO - layer4_mlp.down_proj | mse: 0.0011085042916246432, bpp_loss: 6.092765556345152, bpp: 0
pseudo compress quantization...:  16%|█▌        | 5/32 [08:55<48:02, 106.75s/it]2025-03-03 07:35:01 - INFO - layer5_self_attn.q_proj | mse: 0.0015760480122825032, bpp_loss: 6.750063981628045, bpp: 0
2025-03-03 07:35:14 - INFO - layer5_self_attn.k_proj | mse: 0.0016565492205528822, bpp_loss: 6.831900317338295, bpp: 0
2025-03-03 07:35:24 - INFO - layer5_self_attn.v_proj | mse: 0.0011055168764858919, bpp_loss: 5.916020641918294, bpp: 0
2025-03-03 07:35:36 - INFO - layer5_self_attn.o_proj | mse: 0.0011880306240162884, bpp_loss: 5.895983921131119, bpp: 0
2025-03-03 07:35:51 - INFO - layer5_mlp.gate_proj | mse: 0.0012656979561932833, bpp_loss: 6.2401158322775085, bpp: 0
2025-03-03 07:36:05 - INFO - layer5_mlp.up_proj | mse: 0.00118931466655133, bpp_loss: 6.096428273808818, bpp: 0
2025-03-03 07:36:36 - INFO - layer5_mlp.down_proj | mse: 0.001102447451461844, bpp_loss: 6.093774301757993, bpp: 0
pseudo compress quantization...:  19%|█▉        | 6/32 [10:45<46:38, 107.63s/it]2025-03-03 07:36:48 - INFO - layer6_self_attn.q_proj | mse: 0.0014682566630071902, bpp_loss: 6.609638657886535, bpp: 0
2025-03-03 07:36:58 - INFO - layer6_self_attn.k_proj | mse: 0.001492580956681572, bpp_loss: 6.646171016385779, bpp: 0
2025-03-03 07:37:11 - INFO - layer6_self_attn.v_proj | mse: 0.0010624778688775338, bpp_loss: 5.851380198728293, bpp: 0
2025-03-03 07:37:23 - INFO - layer6_self_attn.o_proj | mse: 0.0011066789526865929, bpp_loss: 5.8404975878074765, bpp: 0
2025-03-03 07:37:37 - INFO - layer6_mlp.gate_proj | mse: 0.0012546406858093162, bpp_loss: 6.264111340045929, bpp: 0
2025-03-03 07:37:50 - INFO - layer6_mlp.up_proj | mse: 0.0011671746587580173, bpp_loss: 6.092329775957867, bpp: 0
2025-03-03 07:38:26 - INFO - layer6_mlp.down_proj | mse: 0.001103726327323582, bpp_loss: 6.0871352416918025, bpp: 0
pseudo compress quantization...:  22%|██▏       | 7/32 [12:35<45:10, 108.41s/it]2025-03-03 07:38:38 - INFO - layer7_self_attn.q_proj | mse: 0.0014446524654764964, bpp_loss: 6.605914430343546, bpp: 0
2025-03-03 07:38:48 - INFO - layer7_self_attn.k_proj | mse: 0.0014592799955403537, bpp_loss: 6.616076922975481, bpp: 0
2025-03-03 07:38:59 - INFO - layer7_self_attn.v_proj | mse: 0.001059729299739696, bpp_loss: 5.860965587082319, bpp: 0
2025-03-03 07:39:09 - INFO - layer7_self_attn.o_proj | mse: 0.0010535011108781169, bpp_loss: 5.846448490046896, bpp: 0
2025-03-03 07:39:22 - INFO - layer7_mlp.gate_proj | mse: 0.0012446058693331428, bpp_loss: 6.2632104370656405, bpp: 0
2025-03-03 07:39:37 - INFO - layer7_mlp.up_proj | mse: 0.0011617439840287335, bpp_loss: 6.096480983374423, bpp: 0
2025-03-03 07:40:11 - INFO - layer7_mlp.down_proj | mse: 0.0011087763441338468, bpp_loss: 6.089156040921807, bpp: 0
pseudo compress quantization...:  25%|██▌       | 8/32 [14:19<42:50, 107.11s/it]2025-03-03 07:40:24 - INFO - layer8_self_attn.q_proj | mse: 0.0014732316093597085, bpp_loss: 6.624152390169911, bpp: 0
2025-03-03 07:40:38 - INFO - layer8_self_attn.k_proj | mse: 0.0015016804768598724, bpp_loss: 6.641561960568652, bpp: 0
2025-03-03 07:40:48 - INFO - layer8_self_attn.v_proj | mse: 0.0010745487588737844, bpp_loss: 5.884682714473456, bpp: 0
2025-03-03 07:40:58 - INFO - layer8_self_attn.o_proj | mse: 0.0011137894720757533, bpp_loss: 5.871414662688039, bpp: 0
2025-03-03 07:41:11 - INFO - layer8_mlp.gate_proj | mse: 0.001228913061345602, bpp_loss: 6.240421931237676, bpp: 0
2025-03-03 07:41:23 - INFO - layer8_mlp.up_proj | mse: 0.0011648351958235006, bpp_loss: 6.111206952395827, bpp: 0
2025-03-03 07:41:56 - INFO - layer8_mlp.down_proj | mse: 0.0011182502123208602, bpp_loss: 6.101300739834821, bpp: 0
pseudo compress quantization...:  28%|██▊       | 9/32 [16:05<40:52, 106.64s/it]2025-03-03 07:42:10 - INFO - layer9_self_attn.q_proj | mse: 0.0014571671461813664, bpp_loss: 6.644785392330959, bpp: 0
2025-03-03 07:42:20 - INFO - layer9_self_attn.k_proj | mse: 0.0015079834456327775, bpp_loss: 6.690412393887527, bpp: 0
2025-03-03 07:42:32 - INFO - layer9_self_attn.v_proj | mse: 0.0010728261049358801, bpp_loss: 5.901463184389286, bpp: 0
2025-03-03 07:42:46 - INFO - layer9_self_attn.o_proj | mse: 0.0011295836049693266, bpp_loss: 5.8896961328573525, bpp: 0
2025-03-03 07:43:00 - INFO - layer9_mlp.gate_proj | mse: 0.0012169087949068151, bpp_loss: 6.226587255507014, bpp: 0
2025-03-03 07:43:11 - INFO - layer9_mlp.up_proj | mse: 0.0011639861602313803, bpp_loss: 6.119549498655076, bpp: 0
2025-03-03 07:43:43 - INFO - layer9_mlp.down_proj | mse: 0.001119828292044256, bpp_loss: 6.109438311005401, bpp: 0
pseudo compress quantization...:  31%|███▏      | 10/32 [17:51<39:04, 106.55s/it]2025-03-03 07:43:54 - INFO - layer10_self_attn.q_proj | mse: 0.0014438310633754555, bpp_loss: 6.635898231877945, bpp: 0
2025-03-03 07:44:07 - INFO - layer10_self_attn.k_proj | mse: 0.0015043535418257418, bpp_loss: 6.689621771336533, bpp: 0
2025-03-03 07:44:19 - INFO - layer10_self_attn.v_proj | mse: 0.0010671695387863005, bpp_loss: 5.893291589571163, bpp: 0
2025-03-03 07:44:31 - INFO - layer10_self_attn.o_proj | mse: 0.001156095708979182, bpp_loss: 5.887130679329857, bpp: 0
2025-03-03 07:44:43 - INFO - layer10_mlp.gate_proj | mse: 0.0012153915530773796, bpp_loss: 6.221570702312991, bpp: 0
2025-03-03 07:44:57 - INFO - layer10_mlp.up_proj | mse: 0.0011711115374907538, bpp_loss: 6.132526052725869, bpp: 0
2025-03-03 07:45:31 - INFO - layer10_mlp.down_proj | mse: 0.0011274881399711654, bpp_loss: 6.119761309218268, bpp: 0
pseudo compress quantization...:  34%|███▍      | 11/32 [19:39<37:30, 107.16s/it]2025-03-03 07:45:42 - INFO - layer11_self_attn.q_proj | mse: 0.001394044934155252, bpp_loss: 6.5168325315462425, bpp: 0
2025-03-03 07:45:53 - INFO - layer11_self_attn.k_proj | mse: 0.0014068192623004157, bpp_loss: 6.516566599602811, bpp: 0
2025-03-03 07:46:03 - INFO - layer11_self_attn.v_proj | mse: 0.0010807976796962519, bpp_loss: 5.929613043903373, bpp: 0
2025-03-03 07:46:14 - INFO - layer11_self_attn.o_proj | mse: 0.0011314539175456965, bpp_loss: 5.920889185741544, bpp: 0
2025-03-03 07:46:29 - INFO - layer11_mlp.gate_proj | mse: 0.0012035404930293625, bpp_loss: 6.2166259874438135, bpp: 0
2025-03-03 07:46:43 - INFO - layer11_mlp.up_proj | mse: 0.0011671543120869475, bpp_loss: 6.1431826143417245, bpp: 0
2025-03-03 07:47:15 - INFO - layer11_mlp.down_proj | mse: 0.0011275881216263554, bpp_loss: 6.127897110442783, bpp: 0
pseudo compress quantization...:  38%|███▊      | 12/32 [21:23<35:22, 106.12s/it]2025-03-03 07:47:29 - INFO - layer12_self_attn.q_proj | mse: 0.0014072753654399554, bpp_loss: 6.576026895665564, bpp: 0
2025-03-03 07:47:40 - INFO - layer12_self_attn.k_proj | mse: 0.0014502365150292577, bpp_loss: 6.63111434399616, bpp: 0
2025-03-03 07:47:50 - INFO - layer12_self_attn.v_proj | mse: 0.0010654163753688359, bpp_loss: 5.918363020988181, bpp: 0
2025-03-03 07:48:01 - INFO - layer12_self_attn.o_proj | mse: 0.0011575378929833242, bpp_loss: 5.9112955898744985, bpp: 0
2025-03-03 07:48:13 - INFO - layer12_mlp.gate_proj | mse: 0.0011973117167587157, bpp_loss: 6.208278967197551, bpp: 0
2025-03-03 07:48:24 - INFO - layer12_mlp.up_proj | mse: 0.0011713507119354473, bpp_loss: 6.154838038045306, bpp: 0
2025-03-03 07:49:01 - INFO - layer12_mlp.down_proj | mse: 0.001128082505309499, bpp_loss: 6.138238754383353, bpp: 0
pseudo compress quantization...:  41%|████      | 13/32 [23:09<33:32, 105.94s/it]2025-03-03 07:49:11 - INFO - layer13_self_attn.q_proj | mse: 0.0013893735435444718, bpp_loss: 6.559784316108562, bpp: 0
2025-03-03 07:49:23 - INFO - layer13_self_attn.k_proj | mse: 0.0014255834070232348, bpp_loss: 6.5910868413047865, bpp: 0
2025-03-03 07:49:37 - INFO - layer13_self_attn.v_proj | mse: 0.0010807131222662536, bpp_loss: 5.9521648534573615, bpp: 0
2025-03-03 07:49:49 - INFO - layer13_self_attn.o_proj | mse: 0.0011563071930867574, bpp_loss: 5.942774206865579, bpp: 0
2025-03-03 07:50:01 - INFO - layer13_mlp.gate_proj | mse: 0.0011981988855158208, bpp_loss: 6.203031250730503, bpp: 0
2025-03-03 07:50:13 - INFO - layer13_mlp.up_proj | mse: 0.0011817447616902421, bpp_loss: 6.167950767417286, bpp: 0
2025-03-03 07:50:44 - INFO - layer13_mlp.down_proj | mse: 0.001141358640809391, bpp_loss: 6.148234274238348, bpp: 0
pseudo compress quantization...:  44%|████▍     | 14/32 [24:52<31:30, 105.03s/it]2025-03-03 07:50:56 - INFO - layer14_self_attn.q_proj | mse: 0.0013861658836919445, bpp_loss: 6.5531610287725925, bpp: 0
2025-03-03 07:51:08 - INFO - layer14_self_attn.k_proj | mse: 0.0014256842603176864, bpp_loss: 6.586845107958652, bpp: 0
2025-03-03 07:51:21 - INFO - layer14_self_attn.v_proj | mse: 0.0010794581596381672, bpp_loss: 5.935093776672147, bpp: 0
2025-03-03 07:51:32 - INFO - layer14_self_attn.o_proj | mse: 0.0011271009300198233, bpp_loss: 5.925136754056439, bpp: 0
2025-03-03 07:51:45 - INFO - layer14_mlp.gate_proj | mse: 0.0011927117521429726, bpp_loss: 6.200601271938446, bpp: 0
2025-03-03 07:52:00 - INFO - layer14_mlp.up_proj | mse: 0.0011793147493321568, bpp_loss: 6.169474986490122, bpp: 0
2025-03-03 07:52:31 - INFO - layer14_mlp.down_proj | mse: 0.0011378189937740946, bpp_loss: 6.149771586147159, bpp: 0
pseudo compress quantization...:  47%|████▋     | 15/32 [26:39<29:59, 105.82s/it]2025-03-03 07:52:42 - INFO - layer15_self_attn.q_proj | mse: 0.0013922355500054224, bpp_loss: 6.538513310719281, bpp: 0
2025-03-03 07:52:52 - INFO - layer15_self_attn.k_proj | mse: 0.0014353478890038217, bpp_loss: 6.598034174065106, bpp: 0
2025-03-03 07:53:03 - INFO - layer15_self_attn.v_proj | mse: 0.0010973674052052354, bpp_loss: 5.9731702317949384, bpp: 0
2025-03-03 07:53:16 - INFO - layer15_self_attn.o_proj | mse: 0.0011835838447372268, bpp_loss: 5.959851495339535, bpp: 0
2025-03-03 07:53:31 - INFO - layer15_mlp.gate_proj | mse: 0.0011989009130408082, bpp_loss: 6.207618638006753, bpp: 0
2025-03-03 07:53:43 - INFO - layer15_mlp.up_proj | mse: 0.0011864033408882056, bpp_loss: 6.176423993914626, bpp: 0
2025-03-03 07:54:19 - INFO - layer15_mlp.down_proj | mse: 0.0011449093370303016, bpp_loss: 6.153951048634426, bpp: 0
pseudo compress quantization...:  50%|█████     | 16/32 [28:28<28:25, 106.57s/it]2025-03-03 07:54:30 - INFO - layer16_self_attn.q_proj | mse: 0.0013957212354120437, bpp_loss: 6.517811640514992, bpp: 0
2025-03-03 07:54:41 - INFO - layer16_self_attn.k_proj | mse: 0.001440521373304933, bpp_loss: 6.565009747981094, bpp: 0
2025-03-03 07:54:51 - INFO - layer16_self_attn.v_proj | mse: 0.0011324360149767658, bpp_loss: 6.0156646211398765, bpp: 0
2025-03-03 07:55:02 - INFO - layer16_self_attn.o_proj | mse: 0.0011274802615312705, bpp_loss: 6.005570595036261, bpp: 0
2025-03-03 07:55:14 - INFO - layer16_mlp.gate_proj | mse: 0.001214959017884441, bpp_loss: 6.217290742626024, bpp: 0
2025-03-03 07:55:29 - INFO - layer16_mlp.up_proj | mse: 0.0011986770996590416, bpp_loss: 6.175623804504095, bpp: 0
2025-03-03 07:56:03 - INFO - layer16_mlp.down_proj | mse: 0.0011457752158931748, bpp_loss: 6.153434144506274, bpp: 0
pseudo compress quantization...:  53%|█████▎    | 17/32 [30:11<26:24, 105.66s/it]2025-03-03 07:56:16 - INFO - layer17_self_attn.q_proj | mse: 0.0013885350307857546, bpp_loss: 6.511385986232199, bpp: 0
2025-03-03 07:56:30 - INFO - layer17_self_attn.k_proj | mse: 0.001425293340635961, bpp_loss: 6.5486062719719484, bpp: 0
2025-03-03 07:56:41 - INFO - layer17_self_attn.v_proj | mse: 0.0011272579135140593, bpp_loss: 6.012647464172915, bpp: 0
2025-03-03 07:56:51 - INFO - layer17_self_attn.o_proj | mse: 0.0011392755703530952, bpp_loss: 6.005663146846928, bpp: 0
2025-03-03 07:57:03 - INFO - layer17_mlp.gate_proj | mse: 0.0012135633170967596, bpp_loss: 6.2306192829165346, bpp: 0
2025-03-03 07:57:15 - INFO - layer17_mlp.up_proj | mse: 0.0011859563878555024, bpp_loss: 6.1707059136310285, bpp: 0
2025-03-03 07:57:48 - INFO - layer17_mlp.down_proj | mse: 0.0011306185629002456, bpp_loss: 6.152485536584674, bpp: 0
pseudo compress quantization...:  56%|█████▋    | 18/32 [31:56<24:36, 105.47s/it]2025-03-03 07:58:02 - INFO - layer18_self_attn.q_proj | mse: 0.0013596485287924317, bpp_loss: 6.476099195308052, bpp: 0
2025-03-03 07:58:12 - INFO - layer18_self_attn.k_proj | mse: 0.001385886862279467, bpp_loss: 6.511997657362372, bpp: 0
2025-03-03 07:58:24 - INFO - layer18_self_attn.v_proj | mse: 0.0011423598342986765, bpp_loss: 6.062606856459752, bpp: 0
2025-03-03 07:58:38 - INFO - layer18_self_attn.o_proj | mse: 0.0011323487415693587, bpp_loss: 6.047888105851598, bpp: 0
2025-03-03 07:58:52 - INFO - layer18_mlp.gate_proj | mse: 0.0012207118706966894, bpp_loss: 6.242898029296897, bpp: 0
2025-03-03 07:59:03 - INFO - layer18_mlp.up_proj | mse: 0.0011860024710442828, bpp_loss: 6.166831900473944, bpp: 0
2025-03-03 07:59:35 - INFO - layer18_mlp.down_proj | mse: 0.001126003978325489, bpp_loss: 6.1513534506219765, bpp: 0
pseudo compress quantization...:  59%|█████▉    | 19/32 [33:43<22:56, 105.88s/it]2025-03-03 07:59:46 - INFO - layer19_self_attn.q_proj | mse: 0.0013529248551188834, bpp_loss: 6.4508387700188905, bpp: 0
2025-03-03 07:59:59 - INFO - layer19_self_attn.k_proj | mse: 0.001380704596318067, bpp_loss: 6.482007999904454, bpp: 0
2025-03-03 08:00:11 - INFO - layer19_self_attn.v_proj | mse: 0.0011496310490178654, bpp_loss: 6.072552581084892, bpp: 0
2025-03-03 08:00:23 - INFO - layer19_self_attn.o_proj | mse: 0.001115607728418452, bpp_loss: 6.060701407724991, bpp: 0
2025-03-03 08:00:35 - INFO - layer19_mlp.gate_proj | mse: 0.0012189565323918888, bpp_loss: 6.2482233307389325, bpp: 0
2025-03-03 08:00:49 - INFO - layer19_mlp.up_proj | mse: 0.00118109474618534, bpp_loss: 6.166774617378102, bpp: 0
2025-03-03 08:01:24 - INFO - layer19_mlp.down_proj | mse: 0.0011206426304986247, bpp_loss: 6.15438570320433, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 20/32 [35:32<21:21, 106.81s/it]2025-03-03 08:01:35 - INFO - layer20_self_attn.q_proj | mse: 0.0013526730840130756, bpp_loss: 6.460325553198345, bpp: 0
2025-03-03 08:01:46 - INFO - layer20_self_attn.k_proj | mse: 0.0013784253480764925, bpp_loss: 6.4896012207027525, bpp: 0
2025-03-03 08:01:56 - INFO - layer20_self_attn.v_proj | mse: 0.0011593138706110237, bpp_loss: 6.091583136701956, bpp: 0
2025-03-03 08:02:07 - INFO - layer20_self_attn.o_proj | mse: 0.0011361033087394642, bpp_loss: 6.082889739307575, bpp: 0
2025-03-03 08:02:22 - INFO - layer20_mlp.gate_proj | mse: 0.0012284414497645165, bpp_loss: 6.256233390853849, bpp: 0
2025-03-03 08:02:36 - INFO - layer20_mlp.up_proj | mse: 0.0011859123258592126, bpp_loss: 6.166127023741949, bpp: 0
2025-03-03 08:03:10 - INFO - layer20_mlp.down_proj | mse: 0.0011233405182347663, bpp_loss: 6.154395993972241, bpp: 0
pseudo compress quantization...:  66%|██████▌   | 21/32 [37:18<19:32, 106.58s/it]2025-03-03 08:03:23 - INFO - layer21_self_attn.q_proj | mse: 0.001332560637571883, bpp_loss: 6.4208642090670764, bpp: 0
2025-03-03 08:03:33 - INFO - layer21_self_attn.k_proj | mse: 0.0013504545831328808, bpp_loss: 6.4371056203963235, bpp: 0
2025-03-03 08:03:44 - INFO - layer21_self_attn.v_proj | mse: 0.0011775228695514576, bpp_loss: 6.128394529107027, bpp: 0
2025-03-03 08:03:54 - INFO - layer21_self_attn.o_proj | mse: 0.0011195348506866049, bpp_loss: 6.110701965051703, bpp: 0
2025-03-03 08:04:06 - INFO - layer21_mlp.gate_proj | mse: 0.0012252567241305284, bpp_loss: 6.266124714945638, bpp: 0
2025-03-03 08:04:18 - INFO - layer21_mlp.up_proj | mse: 0.0011759579528441556, bpp_loss: 6.163944340289333, bpp: 0
2025-03-03 08:04:54 - INFO - layer21_mlp.down_proj | mse: 0.0011092650684780174, bpp_loss: 6.154526900240155, bpp: 0
pseudo compress quantization...:  69%|██████▉   | 22/32 [39:03<17:39, 105.99s/it]2025-03-03 08:05:06 - INFO - layer22_self_attn.q_proj | mse: 0.0013463324536867668, bpp_loss: 6.460191923310049, bpp: 0
2025-03-03 08:05:19 - INFO - layer22_self_attn.k_proj | mse: 0.0013630661336986693, bpp_loss: 6.481173878884874, bpp: 0
2025-03-03 08:05:33 - INFO - layer22_self_attn.v_proj | mse: 0.0011668259925263847, bpp_loss: 6.132287317654118, bpp: 0
2025-03-03 08:05:43 - INFO - layer22_self_attn.o_proj | mse: 0.0011594587227395001, bpp_loss: 6.10935242054984, bpp: 0
2025-03-03 08:05:55 - INFO - layer22_mlp.gate_proj | mse: 0.0012252964742495056, bpp_loss: 6.2748268563733545, bpp: 0
2025-03-03 08:06:08 - INFO - layer22_mlp.up_proj | mse: 0.001171943999304453, bpp_loss: 6.163432970469774, bpp: 0
2025-03-03 08:06:40 - INFO - layer22_mlp.down_proj | mse: 0.001108905835199396, bpp_loss: 6.155116542957203, bpp: 0
pseudo compress quantization...:  72%|███████▏  | 23/32 [40:48<15:51, 105.71s/it]2025-03-03 08:06:53 - INFO - layer23_self_attn.q_proj | mse: 0.0013331460212360879, bpp_loss: 6.451579807209782, bpp: 0
2025-03-03 08:07:06 - INFO - layer23_self_attn.k_proj | mse: 0.0013431811956317648, bpp_loss: 6.464663544087671, bpp: 0
2025-03-03 08:07:16 - INFO - layer23_self_attn.v_proj | mse: 0.0011901018283883389, bpp_loss: 6.19176500022877, bpp: 0
2025-03-03 08:07:28 - INFO - layer23_self_attn.o_proj | mse: 0.0011154879538147183, bpp_loss: 6.174287747242488, bpp: 0
2025-03-03 08:07:43 - INFO - layer23_mlp.gate_proj | mse: 0.0012163649593807404, bpp_loss: 6.274745146722295, bpp: 0
2025-03-03 08:07:57 - INFO - layer23_mlp.up_proj | mse: 0.0011667683990674534, bpp_loss: 6.169742086945578, bpp: 0
2025-03-03 08:08:28 - INFO - layer23_mlp.down_proj | mse: 0.0011034051598368627, bpp_loss: 6.162716415775723, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 24/32 [42:36<14:12, 106.59s/it]2025-03-03 08:08:39 - INFO - layer24_self_attn.q_proj | mse: 0.0012934250326956398, bpp_loss: 6.394402932142839, bpp: 0
2025-03-03 08:08:50 - INFO - layer24_self_attn.k_proj | mse: 0.0013055645463877562, bpp_loss: 6.401200394728221, bpp: 0
2025-03-03 08:09:03 - INFO - layer24_self_attn.v_proj | mse: 0.0011803004996475707, bpp_loss: 6.180200400878675, bpp: 0
2025-03-03 08:09:15 - INFO - layer24_self_attn.o_proj | mse: 0.0011488935706187604, bpp_loss: 6.155880897422321, bpp: 0
2025-03-03 08:09:29 - INFO - layer24_mlp.gate_proj | mse: 0.0012118412610949672, bpp_loss: 6.278187583178975, bpp: 0
2025-03-03 08:09:41 - INFO - layer24_mlp.up_proj | mse: 0.0011619671236796699, bpp_loss: 6.17376692263886, bpp: 0
2025-03-03 08:10:18 - INFO - layer24_mlp.down_proj | mse: 0.0011000255912468032, bpp_loss: 6.1674617026001215, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 25/32 [44:26<12:32, 107.53s/it]2025-03-03 08:10:29 - INFO - layer25_self_attn.q_proj | mse: 0.0012915841432078667, bpp_loss: 6.415689098415896, bpp: 0
2025-03-03 08:10:40 - INFO - layer25_self_attn.k_proj | mse: 0.0012990262834386575, bpp_loss: 6.421475461800583, bpp: 0
2025-03-03 08:10:51 - INFO - layer25_self_attn.v_proj | mse: 0.0011969767820035648, bpp_loss: 6.2305507159326226, bpp: 0
2025-03-03 08:11:01 - INFO - layer25_self_attn.o_proj | mse: 0.0011476177854972056, bpp_loss: 6.211532873800024, bpp: 0
2025-03-03 08:11:14 - INFO - layer25_mlp.gate_proj | mse: 0.0012060628065111742, bpp_loss: 6.2806628769220305, bpp: 0
2025-03-03 08:11:29 - INFO - layer25_mlp.up_proj | mse: 0.0011579751337650293, bpp_loss: 6.179535085205422, bpp: 0
2025-03-03 08:12:03 - INFO - layer25_mlp.down_proj | mse: 0.0011016610728369252, bpp_loss: 6.173779160347443, bpp: 0
pseudo compress quantization...:  81%|████████▏ | 26/32 [46:11<10:40, 106.75s/it]2025-03-03 08:12:17 - INFO - layer26_self_attn.q_proj | mse: 0.001275598624439544, bpp_loss: 6.386803452624008, bpp: 0
2025-03-03 08:12:30 - INFO - layer26_self_attn.k_proj | mse: 0.0012850968501014757, bpp_loss: 6.3994729882106185, bpp: 0
2025-03-03 08:12:41 - INFO - layer26_self_attn.v_proj | mse: 0.0012046977625816723, bpp_loss: 6.25082303781528, bpp: 0
2025-03-03 08:12:51 - INFO - layer26_self_attn.o_proj | mse: 0.0012037434586527544, bpp_loss: 6.237453121109866, bpp: 0
2025-03-03 08:13:03 - INFO - layer26_mlp.gate_proj | mse: 0.0012074182181952143, bpp_loss: 6.284698633780313, bpp: 0
2025-03-03 08:13:15 - INFO - layer26_mlp.up_proj | mse: 0.001157941042985025, bpp_loss: 6.18414220621073, bpp: 0
2025-03-03 08:13:50 - INFO - layer26_mlp.down_proj | mse: 0.001100134129283536, bpp_loss: 6.1775001037519335, bpp: 0
pseudo compress quantization...:  84%|████████▍ | 27/32 [47:59<08:54, 106.97s/it]2025-03-03 08:14:03 - INFO - layer27_self_attn.q_proj | mse: 0.0013070088126412452, bpp_loss: 6.457815822446719, bpp: 0
2025-03-03 08:14:14 - INFO - layer27_self_attn.k_proj | mse: 0.001312905109063453, bpp_loss: 6.4767617989564314, bpp: 0
2025-03-03 08:14:27 - INFO - layer27_self_attn.v_proj | mse: 0.0011969871932502988, bpp_loss: 6.255205367342569, bpp: 0
2025-03-03 08:14:42 - INFO - layer27_self_attn.o_proj | mse: 0.00116960733445829, bpp_loss: 6.2516269760672, bpp: 0
2025-03-03 08:14:54 - INFO - layer27_mlp.gate_proj | mse: 0.001206898502232858, bpp_loss: 6.286287794279498, bpp: 0
2025-03-03 08:15:06 - INFO - layer27_mlp.up_proj | mse: 0.001159856594481229, bpp_loss: 6.190894112684006, bpp: 0
2025-03-03 08:15:37 - INFO - layer27_mlp.down_proj | mse: 0.0011069669726164702, bpp_loss: 6.184078633785248, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 28/32 [49:45<07:07, 106.90s/it]2025-03-03 08:15:49 - INFO - layer28_self_attn.q_proj | mse: 0.0012763868010836157, bpp_loss: 6.40419313381426, bpp: 0
2025-03-03 08:16:02 - INFO - layer28_self_attn.k_proj | mse: 0.0012883887052536796, bpp_loss: 6.425646789139137, bpp: 0
2025-03-03 08:16:15 - INFO - layer28_self_attn.v_proj | mse: 0.001223513782473002, bpp_loss: 6.299641526071355, bpp: 0
2025-03-03 08:16:26 - INFO - layer28_self_attn.o_proj | mse: 0.0012431723890891622, bpp_loss: 6.293500449159183, bpp: 0
2025-03-03 08:16:39 - INFO - layer28_mlp.gate_proj | mse: 0.0012040607479763827, bpp_loss: 6.280029878020287, bpp: 0
2025-03-03 08:16:54 - INFO - layer28_mlp.up_proj | mse: 0.0011668741748077827, bpp_loss: 6.203947705758172, bpp: 0
2025-03-03 08:17:24 - INFO - layer28_mlp.down_proj | mse: 0.0011230727102297929, bpp_loss: 6.191472251358074, bpp: 0
pseudo compress quantization...:  91%|█████████ | 29/32 [51:32<05:20, 106.91s/it]2025-03-03 08:17:33 - INFO - layer29_self_attn.q_proj | mse: 0.0012556834484908203, bpp_loss: 6.355631642974913, bpp: 0
2025-03-03 08:17:42 - INFO - layer29_self_attn.k_proj | mse: 0.0012616266407896224, bpp_loss: 6.3715789339039475, bpp: 0
2025-03-03 08:17:51 - INFO - layer29_self_attn.v_proj | mse: 0.001231594086862311, bpp_loss: 6.306416231673211, bpp: 0
2025-03-03 08:18:00 - INFO - layer29_self_attn.o_proj | mse: 0.0012140940485581885, bpp_loss: 6.311838525347412, bpp: 0
2025-03-03 08:18:10 - INFO - layer29_mlp.gate_proj | mse: 0.0012093186781208232, bpp_loss: 6.282981050568957, bpp: 0
2025-03-03 08:18:21 - INFO - layer29_mlp.up_proj | mse: 0.001174907606479995, bpp_loss: 6.215979158531788, bpp: 0
2025-03-03 08:18:53 - INFO - layer29_mlp.down_proj | mse: 0.0011410042583927466, bpp_loss: 6.195069654736408, bpp: 0
pseudo compress quantization...:  94%|█████████▍| 30/32 [53:01<03:23, 101.56s/it]2025-03-03 08:19:06 - INFO - layer30_self_attn.q_proj | mse: 0.001268507297957407, bpp_loss: 6.3713399356929585, bpp: 0
2025-03-03 08:19:18 - INFO - layer30_self_attn.k_proj | mse: 0.0012725299320977739, bpp_loss: 6.3979671583510935, bpp: 0
2025-03-03 08:19:30 - INFO - layer30_self_attn.v_proj | mse: 0.0012523733057573962, bpp_loss: 6.343397685792297, bpp: 0
2025-03-03 08:19:43 - INFO - layer30_self_attn.o_proj | mse: 0.0012716058660506753, bpp_loss: 6.3504981809528545, bpp: 0
2025-03-03 08:19:58 - INFO - layer30_mlp.gate_proj | mse: 0.001235314447454926, bpp_loss: 6.310638506225375, bpp: 0
2025-03-03 08:20:12 - INFO - layer30_mlp.up_proj | mse: 0.0011967145217508953, bpp_loss: 6.232899267919535, bpp: 0
2025-03-03 08:20:51 - INFO - layer30_mlp.down_proj | mse: 0.0012197481661172824, bpp_loss: 6.184750052515504, bpp: 0
pseudo compress quantization...:  97%|█████████▋| 31/32 [54:59<01:46, 106.55s/it]2025-03-03 08:21:04 - INFO - layer31_self_attn.q_proj | mse: 0.0013005108366903788, bpp_loss: 6.391321622184478, bpp: 0
2025-03-03 08:21:17 - INFO - layer31_self_attn.k_proj | mse: 0.0013288449088787251, bpp_loss: 6.449646024731919, bpp: 0
2025-03-03 08:21:29 - INFO - layer31_self_attn.v_proj | mse: 0.0011988259099561449, bpp_loss: 6.204644540208392, bpp: 0
2025-03-03 08:21:42 - INFO - layer31_self_attn.o_proj | mse: 0.0014191289772434916, bpp_loss: 6.207542620948516, bpp: 0
2025-03-03 08:21:57 - INFO - layer31_mlp.gate_proj | mse: 0.001287920159147871, bpp_loss: 6.383913891086745, bpp: 0
2025-03-03 08:22:12 - INFO - layer31_mlp.up_proj | mse: 0.0012408929387283387, bpp_loss: 6.2940397725202315, bpp: 0
2025-03-03 08:22:50 - INFO - layer31_mlp.down_proj | mse: 0.0015950790302087692, bpp_loss: 6.18020134432198, bpp: 0
pseudo compress quantization...: 100%|██████████| 32/32 [56:58<00:00, 110.21s/it]pseudo compress quantization...: 100%|██████████| 32/32 [56:58<00:00, 106.83s/it]
2025-03-03 08:22:50 - INFO - #### Total | mse: 0.00129693146343195, bpp_loss: 6.206625022993898, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/best_loss_model_loss_49.72731_bpp_6.30559_MSE_0.00042_total_iter_140000.pth.tar/COL_MSE0.0013_bpploss6.2066_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-7b-hf/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/best_loss_model_loss_49.72731_bpp_6.30559_MSE_0.00042_total_iter_140000.pth.tar/COL_MSE0.0013_bpploss6.2066_bpp0
I0303 08:23:22.195540 3099700 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.05it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.23it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s]
W0303 08:23:24.157733 3099700 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 08:23:24.171439 3099700 config.py:54] PyTorch version 2.4.1 available.
Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub
W0303 08:23:48.919445 3099700 load.py:1444] Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /home/jgryu/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Thu Feb  6 17:01:08 2025).
W0303 08:23:48.921550 3099700 cache.py:94] Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /home/jgryu/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Thu Feb  6 17:01:08 2025).
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.3671875:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.3671875:   1%|          | 1/166 [00:01<03:01,  1.10s/it]avg_loss = 1.6328125:   1%|          | 1/166 [00:01<03:01,  1.10s/it]avg_loss = 1.6328125:   1%|          | 2/166 [00:01<02:11,  1.25it/s]avg_loss = 1.796875:   1%|          | 2/166 [00:02<02:11,  1.25it/s] avg_loss = 1.796875:   2%|▏         | 3/166 [00:02<01:59,  1.37it/s]avg_loss = 1.828125:   2%|▏         | 3/166 [00:03<01:59,  1.37it/s]avg_loss = 1.828125:   2%|▏         | 4/166 [00:03<01:59,  1.36it/s]avg_loss = 1.7609375:   2%|▏         | 4/166 [00:03<01:59,  1.36it/s]avg_loss = 1.7609375:   3%|▎         | 5/166 [00:03<01:52,  1.43it/s]avg_loss = 1.7369791666666667:   3%|▎         | 5/166 [00:04<01:52,  1.43it/s]avg_loss = 1.7369791666666667:   4%|▎         | 6/166 [00:04<01:51,  1.43it/s]avg_loss = 1.6752232142857142:   4%|▎         | 6/166 [00:05<01:51,  1.43it/s]avg_loss = 1.6752232142857142:   4%|▍         | 7/166 [00:05<01:49,  1.46it/s]avg_loss = 1.6171875:   4%|▍         | 7/166 [00:05<01:49,  1.46it/s]         avg_loss = 1.6171875:   5%|▍         | 8/166 [00:05<01:48,  1.45it/s]avg_loss = 1.6128472222222223:   5%|▍         | 8/166 [00:06<01:48,  1.45it/s]avg_loss = 1.6128472222222223:   5%|▌         | 9/166 [00:06<01:46,  1.48it/s]avg_loss = 1.61953125:   5%|▌         | 9/166 [00:07<01:46,  1.48it/s]        avg_loss = 1.61953125:   6%|▌         | 10/166 [00:07<01:47,  1.45it/s]avg_loss = 1.6363636363636365:   6%|▌         | 10/166 [00:07<01:47,  1.45it/s]avg_loss = 1.6363636363636365:   7%|▋         | 11/166 [00:07<01:43,  1.50it/s]avg_loss = 1.646484375:   7%|▋         | 11/166 [00:08<01:43,  1.50it/s]       avg_loss = 1.646484375:   7%|▋         | 12/166 [00:08<01:42,  1.50it/s]avg_loss = 1.6418269230769231:   7%|▋         | 12/166 [00:09<01:42,  1.50it/s]avg_loss = 1.6418269230769231:   8%|▊         | 13/166 [00:09<01:41,  1.51it/s]avg_loss = 1.6545758928571428:   8%|▊         | 13/166 [00:09<01:41,  1.51it/s]avg_loss = 1.6545758928571428:   8%|▊         | 14/166 [00:09<01:40,  1.52it/s]avg_loss = 1.6723958333333333:   8%|▊         | 14/166 [00:10<01:40,  1.52it/s]avg_loss = 1.6723958333333333:   9%|▉         | 15/166 [00:10<01:37,  1.55it/s]avg_loss = 1.69189453125:   9%|▉         | 15/166 [00:10<01:37,  1.55it/s]     avg_loss = 1.69189453125:  10%|▉         | 16/166 [00:10<01:37,  1.54it/s]avg_loss = 1.705422794117647:  10%|▉         | 16/166 [00:11<01:37,  1.54it/s]avg_loss = 1.705422794117647:  10%|█         | 17/166 [00:11<01:37,  1.53it/s]avg_loss = 1.7200520833333333:  10%|█         | 17/166 [00:12<01:37,  1.53it/s]avg_loss = 1.7200520833333333:  11%|█         | 18/166 [00:12<01:38,  1.50it/s]avg_loss = 1.739720394736842:  11%|█         | 18/166 [00:13<01:38,  1.50it/s] avg_loss = 1.739720394736842:  11%|█▏        | 19/166 [00:13<01:38,  1.49it/s]avg_loss = 1.74609375:  11%|█▏        | 19/166 [00:13<01:38,  1.49it/s]       avg_loss = 1.74609375:  12%|█▏        | 20/166 [00:13<01:40,  1.46it/s]avg_loss = 1.7466517857142858:  12%|█▏        | 20/166 [00:14<01:40,  1.46it/s]avg_loss = 1.7466517857142858:  13%|█▎        | 21/166 [00:14<01:39,  1.46it/s]avg_loss = 1.7368607954545454:  13%|█▎        | 21/166 [00:15<01:39,  1.46it/s]avg_loss = 1.7368607954545454:  13%|█▎        | 22/166 [00:15<01:41,  1.42it/s]avg_loss = 1.725883152173913:  13%|█▎        | 22/166 [00:15<01:41,  1.42it/s] avg_loss = 1.725883152173913:  14%|█▍        | 23/166 [00:15<01:39,  1.43it/s]avg_loss = 1.7333984375:  14%|█▍        | 23/166 [00:16<01:39,  1.43it/s]     avg_loss = 1.7333984375:  14%|█▍        | 24/166 [00:16<01:40,  1.41it/s]avg_loss = 1.7409375:  14%|█▍        | 24/166 [00:17<01:40,  1.41it/s]   avg_loss = 1.7409375:  15%|█▌        | 25/166 [00:17<01:41,  1.39it/s]avg_loss = 1.7454927884615385:  15%|█▌        | 25/166 [00:18<01:41,  1.39it/s]avg_loss = 1.7454927884615385:  16%|█▌        | 26/166 [00:18<01:41,  1.37it/s]avg_loss = 1.7523148148148149:  16%|█▌        | 26/166 [00:18<01:41,  1.37it/s]avg_loss = 1.7523148148148149:  16%|█▋        | 27/166 [00:18<01:39,  1.40it/s]avg_loss = 1.7553013392857142:  16%|█▋        | 27/166 [00:19<01:39,  1.40it/s]avg_loss = 1.7553013392857142:  17%|█▋        | 28/166 [00:19<01:40,  1.37it/s]avg_loss = 1.7648168103448276:  17%|█▋        | 28/166 [00:20<01:40,  1.37it/s]avg_loss = 1.7648168103448276:  17%|█▋        | 29/166 [00:20<01:39,  1.38it/s]avg_loss = 1.76484375:  17%|█▋        | 29/166 [00:20<01:39,  1.38it/s]        avg_loss = 1.76484375:  18%|█▊        | 30/166 [00:20<01:37,  1.40it/s]avg_loss = 1.7789818548387097:  18%|█▊        | 30/166 [00:21<01:37,  1.40it/s]avg_loss = 1.7789818548387097:  19%|█▊        | 31/166 [00:21<01:36,  1.40it/s]avg_loss = 1.78564453125:  19%|█▊        | 31/166 [00:22<01:36,  1.40it/s]     avg_loss = 1.78564453125:  19%|█▉        | 32/166 [00:22<01:36,  1.38it/s]avg_loss = 1.7909564393939394:  19%|█▉        | 32/166 [00:23<01:36,  1.38it/s]avg_loss = 1.7909564393939394:  20%|█▉        | 33/166 [00:23<01:35,  1.40it/s]avg_loss = 1.7899816176470589:  20%|█▉        | 33/166 [00:23<01:35,  1.40it/s]avg_loss = 1.7899816176470589:  20%|██        | 34/166 [00:23<01:34,  1.40it/s]avg_loss = 1.7837053571428572:  20%|██        | 34/166 [00:24<01:34,  1.40it/s]avg_loss = 1.7837053571428572:  21%|██        | 35/166 [00:24<01:34,  1.38it/s]avg_loss = 1.7751736111111112:  21%|██        | 35/166 [00:25<01:34,  1.38it/s]avg_loss = 1.7751736111111112:  22%|██▏       | 36/166 [00:25<01:33,  1.39it/s]avg_loss = 1.7652027027027026:  22%|██▏       | 36/166 [00:26<01:33,  1.39it/s]avg_loss = 1.7652027027027026:  22%|██▏       | 37/166 [00:26<01:33,  1.38it/s]avg_loss = 1.7623355263157894:  22%|██▏       | 37/166 [00:26<01:33,  1.38it/s]avg_loss = 1.7623355263157894:  23%|██▎       | 38/166 [00:26<01:32,  1.38it/s]avg_loss = 1.7602163461538463:  23%|██▎       | 38/166 [00:27<01:32,  1.38it/s]avg_loss = 1.7602163461538463:  23%|██▎       | 39/166 [00:27<01:30,  1.40it/s]avg_loss = 1.763671875:  23%|██▎       | 39/166 [00:28<01:30,  1.40it/s]       avg_loss = 1.763671875:  24%|██▍       | 40/166 [00:28<01:30,  1.40it/s]avg_loss = 1.763528963414634:  24%|██▍       | 40/166 [00:28<01:30,  1.40it/s]avg_loss = 1.763528963414634:  25%|██▍       | 41/166 [00:28<01:29,  1.39it/s]avg_loss = 1.7511160714285714:  25%|██▍       | 41/166 [00:29<01:29,  1.39it/s]avg_loss = 1.7511160714285714:  25%|██▌       | 42/166 [00:29<01:29,  1.38it/s]avg_loss = 1.7356468023255813:  25%|██▌       | 42/166 [00:30<01:29,  1.38it/s]avg_loss = 1.7356468023255813:  26%|██▌       | 43/166 [00:30<01:28,  1.39it/s]avg_loss = 1.7254971590909092:  26%|██▌       | 43/166 [00:31<01:28,  1.39it/s]avg_loss = 1.7254971590909092:  27%|██▋       | 44/166 [00:31<01:26,  1.41it/s]avg_loss = 1.7118055555555556:  27%|██▋       | 44/166 [00:31<01:26,  1.41it/s]avg_loss = 1.7118055555555556:  27%|██▋       | 45/166 [00:31<01:25,  1.41it/s]avg_loss = 1.7014266304347827:  27%|██▋       | 45/166 [00:32<01:25,  1.41it/s]avg_loss = 1.7014266304347827:  28%|██▊       | 46/166 [00:32<01:24,  1.43it/s]avg_loss = 1.694315159574468:  28%|██▊       | 46/166 [00:33<01:24,  1.43it/s] avg_loss = 1.694315159574468:  28%|██▊       | 47/166 [00:33<01:22,  1.44it/s]avg_loss = 1.6951497395833333:  28%|██▊       | 47/166 [00:33<01:22,  1.44it/s]avg_loss = 1.6951497395833333:  29%|██▉       | 48/166 [00:33<01:23,  1.41it/s]avg_loss = 1.7061543367346939:  29%|██▉       | 48/166 [00:34<01:23,  1.41it/s]avg_loss = 1.7061543367346939:  30%|██▉       | 49/166 [00:34<01:22,  1.42it/s]avg_loss = 1.71671875:  30%|██▉       | 49/166 [00:35<01:22,  1.42it/s]        avg_loss = 1.71671875:  30%|███       | 50/166 [00:35<01:22,  1.40it/s]avg_loss = 1.7234987745098038:  30%|███       | 50/166 [00:35<01:22,  1.40it/s]avg_loss = 1.7234987745098038:  31%|███       | 51/166 [00:35<01:22,  1.39it/s]avg_loss = 1.728515625:  31%|███       | 51/166 [00:36<01:22,  1.39it/s]       avg_loss = 1.728515625:  31%|███▏      | 52/166 [00:36<01:21,  1.41it/s]avg_loss = 1.731869103773585:  31%|███▏      | 52/166 [00:37<01:21,  1.41it/s]avg_loss = 1.731869103773585:  32%|███▏      | 53/166 [00:37<01:21,  1.39it/s]avg_loss = 1.7329282407407407:  32%|███▏      | 53/166 [00:38<01:21,  1.39it/s]avg_loss = 1.7329282407407407:  33%|███▎      | 54/166 [00:38<01:20,  1.38it/s]avg_loss = 1.7353693181818182:  33%|███▎      | 54/166 [00:38<01:20,  1.38it/s]avg_loss = 1.7353693181818182:  33%|███▎      | 55/166 [00:38<01:20,  1.37it/s]avg_loss = 1.7388392857142858:  33%|███▎      | 55/166 [00:39<01:20,  1.37it/s]avg_loss = 1.7388392857142858:  34%|███▎      | 56/166 [00:39<01:19,  1.39it/s]avg_loss = 1.7339638157894737:  34%|███▎      | 56/166 [00:40<01:19,  1.39it/s]avg_loss = 1.7339638157894737:  34%|███▍      | 57/166 [00:40<01:19,  1.37it/s]avg_loss = 1.7376077586206897:  34%|███▍      | 57/166 [00:41<01:19,  1.37it/s]avg_loss = 1.7376077586206897:  35%|███▍      | 58/166 [00:41<01:18,  1.37it/s]avg_loss = 1.7359639830508475:  35%|███▍      | 58/166 [00:41<01:18,  1.37it/s]avg_loss = 1.7359639830508475:  36%|███▌      | 59/166 [00:41<01:19,  1.35it/s]avg_loss = 1.7309895833333333:  36%|███▌      | 59/166 [00:42<01:19,  1.35it/s]avg_loss = 1.7309895833333333:  36%|███▌      | 60/166 [00:42<01:17,  1.37it/s]avg_loss = 1.7265625:  36%|███▌      | 60/166 [00:43<01:17,  1.37it/s]         avg_loss = 1.7265625:  37%|███▋      | 61/166 [00:43<01:16,  1.38it/s]avg_loss = 1.72265625:  37%|███▋      | 61/166 [00:44<01:16,  1.38it/s]avg_loss = 1.72265625:  37%|███▋      | 62/166 [00:44<01:17,  1.35it/s]avg_loss = 1.716765873015873:  37%|███▋      | 62/166 [00:44<01:17,  1.35it/s]avg_loss = 1.716765873015873:  38%|███▊      | 63/166 [00:44<01:15,  1.36it/s]avg_loss = 1.7125244140625:  38%|███▊      | 63/166 [00:45<01:15,  1.36it/s]  avg_loss = 1.7125244140625:  39%|███▊      | 64/166 [00:45<01:15,  1.35it/s]avg_loss = 1.705889423076923:  39%|███▊      | 64/166 [00:46<01:15,  1.35it/s]avg_loss = 1.705889423076923:  39%|███▉      | 65/166 [00:46<01:14,  1.35it/s]avg_loss = 1.6987452651515151:  39%|███▉      | 65/166 [00:47<01:14,  1.35it/s]avg_loss = 1.6987452651515151:  40%|███▉      | 66/166 [00:47<01:14,  1.34it/s]avg_loss = 1.6927472014925373:  40%|███▉      | 66/166 [00:47<01:14,  1.34it/s]avg_loss = 1.6927472014925373:  40%|████      | 67/166 [00:47<01:12,  1.36it/s]avg_loss = 1.6916360294117647:  40%|████      | 67/166 [00:48<01:12,  1.36it/s]avg_loss = 1.6916360294117647:  41%|████      | 68/166 [00:48<01:13,  1.34it/s]avg_loss = 1.6935009057971016:  41%|████      | 68/166 [00:49<01:13,  1.34it/s]avg_loss = 1.6935009057971016:  42%|████▏     | 69/166 [00:49<01:11,  1.35it/s]avg_loss = 1.6965401785714285:  42%|████▏     | 69/166 [00:49<01:11,  1.35it/s]avg_loss = 1.6965401785714285:  42%|████▏     | 70/166 [00:49<01:10,  1.36it/s]avg_loss = 1.7004841549295775:  42%|████▏     | 70/166 [00:50<01:10,  1.36it/s]avg_loss = 1.7004841549295775:  43%|████▎     | 71/166 [00:50<01:08,  1.39it/s]avg_loss = 1.7052951388888888:  43%|████▎     | 71/166 [00:51<01:08,  1.39it/s]avg_loss = 1.7052951388888888:  43%|████▎     | 72/166 [00:51<01:07,  1.40it/s]avg_loss = 1.7112585616438356:  43%|████▎     | 72/166 [00:52<01:07,  1.40it/s]avg_loss = 1.7112585616438356:  44%|████▍     | 73/166 [00:52<01:07,  1.39it/s]avg_loss = 1.7055532094594594:  44%|████▍     | 73/166 [00:52<01:07,  1.39it/s]avg_loss = 1.7055532094594594:  45%|████▍     | 74/166 [00:52<01:05,  1.40it/s]avg_loss = 1.7009375:  45%|████▍     | 74/166 [00:53<01:05,  1.40it/s]         avg_loss = 1.7009375:  45%|████▌     | 75/166 [00:53<01:05,  1.38it/s]avg_loss = 1.7000411184210527:  45%|████▌     | 75/166 [00:54<01:05,  1.38it/s]avg_loss = 1.7000411184210527:  46%|████▌     | 76/166 [00:54<01:04,  1.39it/s]avg_loss = 1.6965300324675325:  46%|████▌     | 76/166 [00:54<01:04,  1.39it/s]avg_loss = 1.6965300324675325:  46%|████▋     | 77/166 [00:54<01:04,  1.37it/s]avg_loss = 1.6929086538461537:  46%|████▋     | 77/166 [00:55<01:04,  1.37it/s]avg_loss = 1.6929086538461537:  47%|████▋     | 78/166 [00:55<01:03,  1.39it/s]avg_loss = 1.6902689873417722:  47%|████▋     | 78/166 [00:56<01:03,  1.39it/s]avg_loss = 1.6902689873417722:  48%|████▊     | 79/166 [00:56<01:02,  1.40it/s]avg_loss = 1.68681640625:  48%|████▊     | 79/166 [00:57<01:02,  1.40it/s]     avg_loss = 1.68681640625:  48%|████▊     | 80/166 [00:57<01:01,  1.40it/s]avg_loss = 1.6774691358024691:  48%|████▊     | 80/166 [00:57<01:01,  1.40it/s]avg_loss = 1.6774691358024691:  49%|████▉     | 81/166 [00:57<01:00,  1.40it/s]avg_loss = 1.6792111280487805:  49%|████▉     | 81/166 [00:58<01:00,  1.40it/s]avg_loss = 1.6792111280487805:  49%|████▉     | 82/166 [00:58<01:00,  1.39it/s]avg_loss = 1.6811935240963856:  49%|████▉     | 82/166 [00:59<01:00,  1.39it/s]avg_loss = 1.6811935240963856:  50%|█████     | 83/166 [00:59<00:59,  1.40it/s]avg_loss = 1.6843377976190477:  50%|█████     | 83/166 [00:59<00:59,  1.40it/s]avg_loss = 1.6843377976190477:  51%|█████     | 84/166 [00:59<00:58,  1.40it/s]avg_loss = 1.6862132352941177:  51%|█████     | 84/166 [01:00<00:58,  1.40it/s]avg_loss = 1.6862132352941177:  51%|█████     | 85/166 [01:00<00:58,  1.39it/s]avg_loss = 1.6852289244186047:  51%|█████     | 85/166 [01:01<00:58,  1.39it/s]avg_loss = 1.6852289244186047:  52%|█████▏    | 86/166 [01:01<00:58,  1.37it/s]avg_loss = 1.6855244252873562:  52%|█████▏    | 86/166 [01:02<00:58,  1.37it/s]avg_loss = 1.6855244252873562:  52%|█████▏    | 87/166 [01:02<00:56,  1.39it/s]avg_loss = 1.6857244318181819:  52%|█████▏    | 87/166 [01:02<00:56,  1.39it/s]avg_loss = 1.6857244318181819:  53%|█████▎    | 88/166 [01:02<00:57,  1.36it/s]avg_loss = 1.6869733146067416:  53%|█████▎    | 88/166 [01:03<00:57,  1.36it/s]avg_loss = 1.6869733146067416:  54%|█████▎    | 89/166 [01:03<00:56,  1.37it/s]avg_loss = 1.686892361111111:  54%|█████▎    | 89/166 [01:04<00:56,  1.37it/s] avg_loss = 1.686892361111111:  54%|█████▍    | 90/166 [01:04<00:55,  1.37it/s]avg_loss = 1.6873282967032968:  54%|█████▍    | 90/166 [01:05<00:55,  1.37it/s]avg_loss = 1.6873282967032968:  55%|█████▍    | 91/166 [01:05<00:54,  1.37it/s]avg_loss = 1.6885190217391304:  55%|█████▍    | 91/166 [01:05<00:54,  1.37it/s]avg_loss = 1.6885190217391304:  55%|█████▌    | 92/166 [01:05<00:53,  1.38it/s]avg_loss = 1.692372311827957:  55%|█████▌    | 92/166 [01:06<00:53,  1.38it/s] avg_loss = 1.692372311827957:  56%|█████▌    | 93/166 [01:06<00:52,  1.38it/s]avg_loss = 1.6914893617021276:  56%|█████▌    | 93/166 [01:07<00:52,  1.38it/s]avg_loss = 1.6914893617021276:  57%|█████▋    | 94/166 [01:07<00:52,  1.38it/s]avg_loss = 1.6907894736842106:  57%|█████▋    | 94/166 [01:07<00:52,  1.38it/s]avg_loss = 1.6907894736842106:  57%|█████▋    | 95/166 [01:07<00:51,  1.38it/s]avg_loss = 1.6905110677083333:  57%|█████▋    | 95/166 [01:08<00:51,  1.38it/s]avg_loss = 1.6905110677083333:  58%|█████▊    | 96/166 [01:08<00:50,  1.40it/s]avg_loss = 1.6903994845360826:  58%|█████▊    | 96/166 [01:09<00:50,  1.40it/s]avg_loss = 1.6903994845360826:  58%|█████▊    | 97/166 [01:09<00:48,  1.41it/s]avg_loss = 1.6887755102040816:  58%|█████▊    | 97/166 [01:10<00:48,  1.41it/s]avg_loss = 1.6887755102040816:  59%|█████▉    | 98/166 [01:10<00:47,  1.43it/s]avg_loss = 1.686395202020202:  59%|█████▉    | 98/166 [01:10<00:47,  1.43it/s] avg_loss = 1.686395202020202:  60%|█████▉    | 99/166 [01:10<00:46,  1.43it/s]avg_loss = 1.68375:  60%|█████▉    | 99/166 [01:11<00:46,  1.43it/s]          avg_loss = 1.68375:  60%|██████    | 100/166 [01:11<00:45,  1.44it/s]avg_loss = 1.684173886138614:  60%|██████    | 100/166 [01:12<00:45,  1.44it/s]avg_loss = 1.684173886138614:  61%|██████    | 101/166 [01:12<00:45,  1.42it/s]avg_loss = 1.685202205882353:  61%|██████    | 101/166 [01:12<00:45,  1.42it/s]avg_loss = 1.685202205882353:  61%|██████▏   | 102/166 [01:12<00:44,  1.43it/s]avg_loss = 1.6862864077669903:  61%|██████▏   | 102/166 [01:13<00:44,  1.43it/s]avg_loss = 1.6862864077669903:  62%|██████▏   | 103/166 [01:13<00:44,  1.41it/s]avg_loss = 1.6884765625:  62%|██████▏   | 103/166 [01:14<00:44,  1.41it/s]      avg_loss = 1.6884765625:  63%|██████▎   | 104/166 [01:14<00:44,  1.41it/s]avg_loss = 1.6951636904761904:  63%|██████▎   | 104/166 [01:15<00:44,  1.41it/s]avg_loss = 1.6951636904761904:  63%|██████▎   | 105/166 [01:15<00:43,  1.39it/s]avg_loss = 1.7003979952830188:  63%|██████▎   | 105/166 [01:15<00:43,  1.39it/s]avg_loss = 1.7003979952830188:  64%|██████▍   | 106/166 [01:15<00:43,  1.37it/s]avg_loss = 1.7040741822429906:  64%|██████▍   | 106/166 [01:16<00:43,  1.37it/s]avg_loss = 1.7040741822429906:  64%|██████▍   | 107/166 [01:16<00:42,  1.39it/s]avg_loss = 1.7072482638888888:  64%|██████▍   | 107/166 [01:17<00:42,  1.39it/s]avg_loss = 1.7072482638888888:  65%|██████▌   | 108/166 [01:17<00:42,  1.37it/s]avg_loss = 1.7119409403669725:  65%|██████▌   | 108/166 [01:17<00:42,  1.37it/s]avg_loss = 1.7119409403669725:  66%|██████▌   | 109/166 [01:17<00:41,  1.38it/s]avg_loss = 1.7154119318181817:  66%|██████▌   | 109/166 [01:18<00:41,  1.38it/s]avg_loss = 1.7154119318181817:  66%|██████▋   | 110/166 [01:18<00:40,  1.37it/s]avg_loss = 1.716920045045045:  66%|██████▋   | 110/166 [01:19<00:40,  1.37it/s] avg_loss = 1.716920045045045:  67%|██████▋   | 111/166 [01:19<00:40,  1.35it/s]avg_loss = 1.7181919642857142:  67%|██████▋   | 111/166 [01:20<00:40,  1.35it/s]avg_loss = 1.7181919642857142:  67%|██████▋   | 112/166 [01:20<00:39,  1.37it/s]avg_loss = 1.7186117256637168:  67%|██████▋   | 112/166 [01:20<00:39,  1.37it/s]avg_loss = 1.7186117256637168:  68%|██████▊   | 113/166 [01:20<00:39,  1.36it/s]avg_loss = 1.719983552631579:  68%|██████▊   | 113/166 [01:21<00:39,  1.36it/s] avg_loss = 1.719983552631579:  69%|██████▊   | 114/166 [01:21<00:37,  1.38it/s]avg_loss = 1.7167798913043477:  69%|██████▊   | 114/166 [01:22<00:37,  1.38it/s]avg_loss = 1.7167798913043477:  69%|██████▉   | 115/166 [01:22<00:37,  1.36it/s]avg_loss = 1.7160560344827587:  69%|██████▉   | 115/166 [01:23<00:37,  1.36it/s]avg_loss = 1.7160560344827587:  70%|██████▉   | 116/166 [01:23<00:36,  1.36it/s]avg_loss = 1.7170138888888888:  70%|██████▉   | 116/166 [01:23<00:36,  1.36it/s]avg_loss = 1.7170138888888888:  70%|███████   | 117/166 [01:23<00:36,  1.35it/s]avg_loss = 1.717094809322034:  70%|███████   | 117/166 [01:24<00:36,  1.35it/s] avg_loss = 1.717094809322034:  71%|███████   | 118/166 [01:24<00:35,  1.36it/s]avg_loss = 1.716452205882353:  71%|███████   | 118/166 [01:25<00:35,  1.36it/s]avg_loss = 1.716452205882353:  72%|███████▏  | 119/166 [01:25<00:35,  1.34it/s]avg_loss = 1.7169921875:  72%|███████▏  | 119/166 [01:26<00:35,  1.34it/s]     avg_loss = 1.7169921875:  72%|███████▏  | 120/166 [01:26<00:34,  1.35it/s]avg_loss = 1.7162319214876034:  72%|███████▏  | 120/166 [01:26<00:34,  1.35it/s]avg_loss = 1.7162319214876034:  73%|███████▎  | 121/166 [01:26<00:34,  1.31it/s]avg_loss = 1.7164446721311475:  73%|███████▎  | 121/166 [01:27<00:34,  1.31it/s]avg_loss = 1.7164446721311475:  73%|███████▎  | 122/166 [01:27<00:32,  1.34it/s]avg_loss = 1.716653963414634:  73%|███████▎  | 122/166 [01:28<00:32,  1.34it/s] avg_loss = 1.716653963414634:  74%|███████▍  | 123/166 [01:28<00:31,  1.35it/s]avg_loss = 1.7151587701612903:  74%|███████▍  | 123/166 [01:29<00:31,  1.35it/s]avg_loss = 1.7151587701612903:  75%|███████▍  | 124/166 [01:29<00:31,  1.34it/s]avg_loss = 1.7134375:  75%|███████▍  | 124/166 [01:29<00:31,  1.34it/s]         avg_loss = 1.7134375:  75%|███████▌  | 125/166 [01:29<00:30,  1.36it/s]avg_loss = 1.7111855158730158:  75%|███████▌  | 125/166 [01:30<00:30,  1.36it/s]avg_loss = 1.7111855158730158:  76%|███████▌  | 126/166 [01:30<00:29,  1.34it/s]avg_loss = 1.7089689960629921:  76%|███████▌  | 126/166 [01:31<00:29,  1.34it/s]avg_loss = 1.7089689960629921:  77%|███████▋  | 127/166 [01:31<00:29,  1.34it/s]avg_loss = 1.70745849609375:  77%|███████▋  | 127/166 [01:32<00:29,  1.34it/s]  avg_loss = 1.70745849609375:  77%|███████▋  | 128/166 [01:32<00:28,  1.32it/s]avg_loss = 1.7061531007751938:  77%|███████▋  | 128/166 [01:32<00:28,  1.32it/s]avg_loss = 1.7061531007751938:  78%|███████▊  | 129/166 [01:32<00:27,  1.34it/s]avg_loss = 1.7060096153846154:  78%|███████▊  | 129/166 [01:33<00:27,  1.34it/s]avg_loss = 1.7060096153846154:  78%|███████▊  | 130/166 [01:33<00:27,  1.32it/s]avg_loss = 1.70700143129771:  78%|███████▊  | 130/166 [01:34<00:27,  1.32it/s]  avg_loss = 1.70700143129771:  79%|███████▉  | 131/166 [01:34<00:26,  1.32it/s]avg_loss = 1.7075639204545454:  79%|███████▉  | 131/166 [01:35<00:26,  1.32it/s]avg_loss = 1.7075639204545454:  80%|███████▉  | 132/166 [01:35<00:25,  1.32it/s]avg_loss = 1.708470394736842:  80%|███████▉  | 132/166 [01:35<00:25,  1.32it/s] avg_loss = 1.708470394736842:  80%|████████  | 133/166 [01:35<00:25,  1.31it/s]avg_loss = 1.7097714552238805:  80%|████████  | 133/166 [01:36<00:25,  1.31it/s]avg_loss = 1.7097714552238805:  81%|████████  | 134/166 [01:36<00:24,  1.32it/s]avg_loss = 1.7077546296296295:  81%|████████  | 134/166 [01:37<00:24,  1.32it/s]avg_loss = 1.7077546296296295:  81%|████████▏ | 135/166 [01:37<00:23,  1.30it/s]avg_loss = 1.7080652573529411:  81%|████████▏ | 135/166 [01:38<00:23,  1.30it/s]avg_loss = 1.7080652573529411:  82%|████████▏ | 136/166 [01:38<00:23,  1.30it/s]avg_loss = 1.7083143248175183:  82%|████████▏ | 136/166 [01:38<00:23,  1.30it/s]avg_loss = 1.7083143248175183:  83%|████████▎ | 137/166 [01:38<00:22,  1.30it/s]avg_loss = 1.7091259057971016:  83%|████████▎ | 137/166 [01:39<00:22,  1.30it/s]avg_loss = 1.7091259057971016:  83%|████████▎ | 138/166 [01:39<00:22,  1.27it/s]avg_loss = 1.7082958633093526:  83%|████████▎ | 138/166 [01:40<00:22,  1.27it/s]avg_loss = 1.7082958633093526:  84%|████████▎ | 139/166 [01:40<00:21,  1.27it/s]avg_loss = 1.70703125:  84%|████████▎ | 139/166 [01:41<00:21,  1.27it/s]        avg_loss = 1.70703125:  84%|████████▍ | 140/166 [01:41<00:20,  1.24it/s]avg_loss = 1.7057291666666667:  84%|████████▍ | 140/166 [01:42<00:20,  1.24it/s]avg_loss = 1.7057291666666667:  85%|████████▍ | 141/166 [01:42<00:20,  1.24it/s]avg_loss = 1.705325704225352:  85%|████████▍ | 141/166 [01:43<00:20,  1.24it/s] avg_loss = 1.705325704225352:  86%|████████▌ | 142/166 [01:43<00:19,  1.23it/s]avg_loss = 1.7036713286713288:  86%|████████▌ | 142/166 [01:43<00:19,  1.23it/s]avg_loss = 1.7036713286713288:  86%|████████▌ | 143/166 [01:43<00:18,  1.23it/s]avg_loss = 1.7048611111111112:  86%|████████▌ | 143/166 [01:44<00:18,  1.23it/s]avg_loss = 1.7048611111111112:  87%|████████▋ | 144/166 [01:44<00:18,  1.22it/s]avg_loss = 1.704094827586207:  87%|████████▋ | 144/166 [01:45<00:18,  1.22it/s] avg_loss = 1.704094827586207:  87%|████████▋ | 145/166 [01:45<00:17,  1.22it/s]avg_loss = 1.7040346746575343:  87%|████████▋ | 145/166 [01:46<00:17,  1.22it/s]avg_loss = 1.7040346746575343:  88%|████████▊ | 146/166 [01:46<00:16,  1.22it/s]avg_loss = 1.7029124149659864:  88%|████████▊ | 146/166 [01:47<00:16,  1.22it/s]avg_loss = 1.7029124149659864:  89%|████████▊ | 147/166 [01:47<00:15,  1.22it/s]avg_loss = 1.7020164695945945:  89%|████████▊ | 147/166 [01:48<00:15,  1.22it/s]avg_loss = 1.7020164695945945:  89%|████████▉ | 148/166 [01:48<00:14,  1.21it/s]avg_loss = 1.70034605704698:  89%|████████▉ | 148/166 [01:48<00:14,  1.21it/s]  avg_loss = 1.70034605704698:  90%|████████▉ | 149/166 [01:48<00:14,  1.20it/s]avg_loss = 1.7013020833333334:  90%|████████▉ | 149/166 [01:49<00:14,  1.20it/s]avg_loss = 1.7013020833333334:  90%|█████████ | 150/166 [01:49<00:13,  1.19it/s]avg_loss = 1.7003828642384107:  90%|█████████ | 150/166 [01:50<00:13,  1.19it/s]avg_loss = 1.7003828642384107:  91%|█████████ | 151/166 [01:50<00:11,  1.28it/s]avg_loss = 1.7001439144736843:  91%|█████████ | 151/166 [01:51<00:11,  1.28it/s]avg_loss = 1.7001439144736843:  92%|█████████▏| 152/166 [01:51<00:10,  1.30it/s]avg_loss = 1.6999591503267975:  92%|█████████▏| 152/166 [01:51<00:10,  1.30it/s]avg_loss = 1.6999591503267975:  92%|█████████▏| 153/166 [01:51<00:09,  1.32it/s]avg_loss = 1.7014508928571428:  92%|█████████▏| 153/166 [01:52<00:09,  1.32it/s]avg_loss = 1.7014508928571428:  93%|█████████▎| 154/166 [01:52<00:09,  1.32it/s]avg_loss = 1.7009072580645161:  93%|█████████▎| 154/166 [01:53<00:09,  1.32it/s]avg_loss = 1.7009072580645161:  93%|█████████▎| 155/166 [01:53<00:08,  1.34it/s]avg_loss = 1.700771233974359:  93%|█████████▎| 155/166 [01:54<00:08,  1.34it/s] avg_loss = 1.700771233974359:  94%|█████████▍| 156/166 [01:54<00:07,  1.35it/s]avg_loss = 1.6989948248407643:  94%|█████████▍| 156/166 [01:54<00:07,  1.35it/s]avg_loss = 1.6989948248407643:  95%|█████████▍| 157/166 [01:54<00:06,  1.32it/s]avg_loss = 1.6947191455696202:  95%|█████████▍| 157/166 [01:55<00:06,  1.32it/s]avg_loss = 1.6947191455696202:  95%|█████████▌| 158/166 [01:55<00:06,  1.33it/s]avg_loss = 1.6955090408805031:  95%|█████████▌| 158/166 [01:56<00:06,  1.33it/s]avg_loss = 1.6955090408805031:  96%|█████████▌| 159/166 [01:56<00:05,  1.31it/s]avg_loss = 1.696923828125:  96%|█████████▌| 159/166 [01:57<00:05,  1.31it/s]    avg_loss = 1.696923828125:  96%|█████████▋| 160/166 [01:57<00:04,  1.32it/s]avg_loss = 1.6992915372670807:  96%|█████████▋| 160/166 [01:57<00:04,  1.32it/s]avg_loss = 1.6992915372670807:  97%|█████████▋| 161/166 [01:57<00:03,  1.30it/s]avg_loss = 1.6994116512345678:  97%|█████████▋| 161/166 [01:58<00:03,  1.30it/s]avg_loss = 1.6994116512345678:  98%|█████████▊| 162/166 [01:58<00:03,  1.30it/s]avg_loss = 1.6989551380368098:  98%|█████████▊| 162/166 [01:59<00:03,  1.30it/s]avg_loss = 1.6989551380368098:  98%|█████████▊| 163/166 [01:59<00:02,  1.29it/s]avg_loss = 1.6995522103658536:  98%|█████████▊| 163/166 [02:00<00:02,  1.29it/s]avg_loss = 1.6995522103658536:  99%|█████████▉| 164/166 [02:00<00:01,  1.30it/s]avg_loss = 1.6996685606060606:  99%|█████████▉| 164/166 [02:01<00:01,  1.30it/s]avg_loss = 1.6996685606060606:  99%|█████████▉| 165/166 [02:01<00:00,  1.28it/s]avg_loss = 1.7015719126506024:  99%|█████████▉| 165/166 [02:01<00:00,  1.28it/s]avg_loss = 1.7015719126506024: 100%|██████████| 166/166 [02:01<00:00,  1.28it/s]avg_loss = 1.7015719126506024: 100%|██████████| 166/166 [02:01<00:00,  1.36it/s]
I0303 08:26:20.531599 3099700 eval_ppl.py:105] wikitext2 perplexity: 5.482558727264404
wikitext2 perplexity: 5.483
Running with lmbda=50
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  9.15it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00, 10.12it/s]Loading checkpoint shards:  36%|███▋      | 4/11 [00:00<00:00,  9.71it/s]Loading checkpoint shards:  55%|█████▍    | 6/11 [00:00<00:00,  9.74it/s]Loading checkpoint shards:  73%|███████▎  | 8/11 [00:00<00:00,  9.96it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00,  9.76it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.01it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.90it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:24,  1.61it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:01<00:22,  1.66it/s]calculating model weight mean & std:   8%|▊         | 3/40 [00:01<00:22,  1.65it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:02<00:22,  1.59it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:03<00:29,  1.18it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:04<00:25,  1.32it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:04<00:23,  1.39it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:05<00:21,  1.47it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:06<00:21,  1.47it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:06<00:20,  1.49it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:07<00:19,  1.52it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:08<00:18,  1.54it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:08<00:17,  1.51it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:09<00:16,  1.53it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:10<00:16,  1.54it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:10<00:15,  1.55it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:11<00:14,  1.61it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:11<00:13,  1.67it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:12<00:12,  1.64it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:13<00:12,  1.59it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:13<00:12,  1.51it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:14<00:13,  1.30it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:15<00:12,  1.33it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:16<00:13,  1.22it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:17<00:13,  1.10it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:18<00:13,  1.00it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:20<00:16,  1.28s/it]calculating model weight mean & std:  70%|███████   | 28/40 [00:22<00:17,  1.44s/it]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:24<00:15,  1.43s/it]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:25<00:12,  1.28s/it]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:25<00:10,  1.16s/it]calculating model weight mean & std:  80%|████████  | 32/40 [00:26<00:08,  1.05s/it]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:27<00:06,  1.04it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:28<00:05,  1.13it/s]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:28<00:04,  1.19it/s]calculating model weight mean & std:  90%|█████████ | 36/40 [00:29<00:03,  1.21it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:30<00:02,  1.21it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:31<00:01,  1.21it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:32<00:00,  1.21it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:32<00:00,  1.22it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:32<00:00,  1.21it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 08:29:51 - INFO - layer0_self_attn.q_proj | mse: 0.10397638375054588, bpp_loss: 2.152759731337428, bpp: 0
2025-03-03 08:30:05 - INFO - layer0_self_attn.k_proj | mse: 0.09903452788178352, bpp_loss: 2.2257077833265067, bpp: 0
2025-03-03 08:30:22 - INFO - layer0_self_attn.v_proj | mse: 0.09440725468098038, bpp_loss: 2.1103410990536213, bpp: 0
2025-03-03 08:30:38 - INFO - layer0_self_attn.o_proj | mse: 0.09553048768255436, bpp_loss: 2.0275585290044544, bpp: 0
2025-03-03 08:30:56 - INFO - layer0_mlp.gate_proj | mse: 0.11717035950564553, bpp_loss: 2.4524232864379885, bpp: 0
2025-03-03 08:31:16 - INFO - layer0_mlp.up_proj | mse: 0.11655574080846096, bpp_loss: 2.427316593295998, bpp: 0
2025-03-03 08:32:01 - INFO - layer0_mlp.down_proj | mse: 0.13556771803797105, bpp_loss: 2.536919879168272, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [02:24<1:33:37, 144.04s/it]2025-03-03 08:32:15 - INFO - layer1_self_attn.q_proj | mse: 0.12060234882267098, bpp_loss: 2.628250590823591, bpp: 0
2025-03-03 08:32:30 - INFO - layer1_self_attn.k_proj | mse: 0.12160507968621065, bpp_loss: 2.6613325434550643, bpp: 0
2025-03-03 08:32:46 - INFO - layer1_self_attn.v_proj | mse: 0.11123398990196855, bpp_loss: 2.193410807698965, bpp: 0
2025-03-03 08:33:02 - INFO - layer1_self_attn.o_proj | mse: 0.13884618562705686, bpp_loss: 2.162919636182487, bpp: 0
2025-03-03 08:33:20 - INFO - layer1_mlp.gate_proj | mse: 0.1342690189191592, bpp_loss: 2.629728601762542, bpp: 0
2025-03-03 08:33:40 - INFO - layer1_mlp.up_proj | mse: 0.13264535935078753, bpp_loss: 2.5652021442850432, bpp: 0
2025-03-03 08:34:24 - INFO - layer1_mlp.down_proj | mse: 0.10583055169988705, bpp_loss: 2.5807963717038986, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [04:47<1:31:00, 143.70s/it]2025-03-03 08:34:39 - INFO - layer2_self_attn.q_proj | mse: 0.12298993463641206, bpp_loss: 2.949758545868099, bpp: 0
2025-03-03 08:34:54 - INFO - layer2_self_attn.k_proj | mse: 0.12358938234141574, bpp_loss: 2.983059785589576, bpp: 0
2025-03-03 08:35:10 - INFO - layer2_self_attn.v_proj | mse: 0.10830766727083758, bpp_loss: 2.330048765875399, bpp: 0
2025-03-03 08:35:26 - INFO - layer2_self_attn.o_proj | mse: 0.10757825406442367, bpp_loss: 2.317799796015024, bpp: 0
2025-03-03 08:35:44 - INFO - layer2_mlp.gate_proj | mse: 0.1180257099938044, bpp_loss: 2.676975433362855, bpp: 0
2025-03-03 08:36:05 - INFO - layer2_mlp.up_proj | mse: 0.11589438212776183, bpp_loss: 2.5835627488791943, bpp: 0
2025-03-03 08:36:48 - INFO - layer2_mlp.down_proj | mse: 0.09671175012064274, bpp_loss: 2.588368047332322, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [07:11<1:28:44, 143.90s/it]2025-03-03 08:37:03 - INFO - layer3_self_attn.q_proj | mse: 0.11442280220391739, bpp_loss: 3.004314015135169, bpp: 0
2025-03-03 08:37:18 - INFO - layer3_self_attn.k_proj | mse: 0.11552397132928184, bpp_loss: 3.063822342567146, bpp: 0
2025-03-03 08:37:35 - INFO - layer3_self_attn.v_proj | mse: 0.10093388275947476, bpp_loss: 2.3641718912497165, bpp: 0
2025-03-03 08:37:49 - INFO - layer3_self_attn.o_proj | mse: 0.09957336111275011, bpp_loss: 2.3339788942039013, bpp: 0
2025-03-03 08:38:08 - INFO - layer3_mlp.gate_proj | mse: 0.10812934802590367, bpp_loss: 2.683447770498417, bpp: 0
2025-03-03 08:38:28 - INFO - layer3_mlp.up_proj | mse: 0.10610360813390321, bpp_loss: 2.586986598869165, bpp: 0
2025-03-03 08:39:12 - INFO - layer3_mlp.down_proj | mse: 0.10531200597304843, bpp_loss: 2.5855020618411126, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [09:35<1:26:18, 143.86s/it]2025-03-03 08:39:26 - INFO - layer4_self_attn.q_proj | mse: 0.10966279717369523, bpp_loss: 2.954735299833119, bpp: 0
2025-03-03 08:39:42 - INFO - layer4_self_attn.k_proj | mse: 0.10983379777664067, bpp_loss: 2.968088414557278, bpp: 0
2025-03-03 08:39:59 - INFO - layer4_self_attn.v_proj | mse: 0.09743235672966914, bpp_loss: 2.3510139857232573, bpp: 0
2025-03-03 08:40:12 - INFO - layer4_self_attn.o_proj | mse: 0.09392698157322395, bpp_loss: 2.3438112909346818, bpp: 0
2025-03-03 08:40:31 - INFO - layer4_mlp.gate_proj | mse: 0.10505528765738821, bpp_loss: 2.6891740357986205, bpp: 0
2025-03-03 08:40:51 - INFO - layer4_mlp.up_proj | mse: 0.1030224499681733, bpp_loss: 2.587941004446259, bpp: 0
2025-03-03 08:41:35 - INFO - layer4_mlp.down_proj | mse: 0.09364090903166886, bpp_loss: 2.5880403316131346, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [11:58<1:23:44, 143.57s/it]2025-03-03 08:41:49 - INFO - layer5_self_attn.q_proj | mse: 0.10635007117638222, bpp_loss: 2.9180398191139103, bpp: 0
2025-03-03 08:42:06 - INFO - layer5_self_attn.k_proj | mse: 0.10593149534129363, bpp_loss: 2.9096275148540736, bpp: 0
2025-03-03 08:42:23 - INFO - layer5_self_attn.v_proj | mse: 0.09571813075212637, bpp_loss: 2.370984508730471, bpp: 0
2025-03-03 08:42:36 - INFO - layer5_self_attn.o_proj | mse: 0.09741235462071551, bpp_loss: 2.360574959926307, bpp: 0
2025-03-03 08:42:56 - INFO - layer5_mlp.gate_proj | mse: 0.10310876621417486, bpp_loss: 2.7017038164867295, bpp: 0
2025-03-03 08:43:15 - INFO - layer5_mlp.up_proj | mse: 0.10081589204403843, bpp_loss: 2.584465898131883, bpp: 0
2025-03-03 08:43:59 - INFO - layer5_mlp.down_proj | mse: 0.09342709613105905, bpp_loss: 2.585532666577233, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [14:22<1:21:25, 143.70s/it]2025-03-03 08:44:14 - INFO - layer6_self_attn.q_proj | mse: 0.1053034573025798, bpp_loss: 2.9380355352535843, bpp: 0
2025-03-03 08:44:30 - INFO - layer6_self_attn.k_proj | mse: 0.10555204116906396, bpp_loss: 2.9584073675051332, bpp: 0
2025-03-03 08:44:47 - INFO - layer6_self_attn.v_proj | mse: 0.09473980735635329, bpp_loss: 2.3927063285931944, bpp: 0
2025-03-03 08:45:01 - INFO - layer6_self_attn.o_proj | mse: 0.09610422262829137, bpp_loss: 2.3859242886677383, bpp: 0
2025-03-03 08:45:22 - INFO - layer6_mlp.gate_proj | mse: 0.10157128005687625, bpp_loss: 2.713044400844309, bpp: 0
2025-03-03 08:45:40 - INFO - layer6_mlp.up_proj | mse: 0.09905241905530396, bpp_loss: 2.5804680383867686, bpp: 0
2025-03-03 08:46:24 - INFO - layer6_mlp.down_proj | mse: 0.09322966529801398, bpp_loss: 2.5808894213013076, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [16:47<1:19:14, 144.08s/it]2025-03-03 08:46:39 - INFO - layer7_self_attn.q_proj | mse: 0.1046527398240513, bpp_loss: 2.963513785749674, bpp: 0
2025-03-03 08:46:56 - INFO - layer7_self_attn.k_proj | mse: 0.10488810019766769, bpp_loss: 2.9833445988222955, bpp: 0
2025-03-03 08:47:12 - INFO - layer7_self_attn.v_proj | mse: 0.09411007837183247, bpp_loss: 2.4094903422147036, bpp: 0
2025-03-03 08:47:27 - INFO - layer7_self_attn.o_proj | mse: 0.09658641659115311, bpp_loss: 2.3987079133465885, bpp: 0
2025-03-03 08:47:48 - INFO - layer7_mlp.gate_proj | mse: 0.10060958347082415, bpp_loss: 2.7168570939037533, bpp: 0
2025-03-03 08:48:05 - INFO - layer7_mlp.up_proj | mse: 0.09808164695764324, bpp_loss: 2.5811010005297486, bpp: 0
2025-03-03 08:48:50 - INFO - layer7_mlp.down_proj | mse: 0.09358948845742149, bpp_loss: 2.579439771782469, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [19:12<1:17:04, 144.51s/it]2025-03-03 08:49:06 - INFO - layer8_self_attn.q_proj | mse: 0.10363775701984002, bpp_loss: 2.930913693346083, bpp: 0
2025-03-03 08:49:22 - INFO - layer8_self_attn.k_proj | mse: 0.10388908496504601, bpp_loss: 2.951139597967267, bpp: 0
2025-03-03 08:49:37 - INFO - layer8_self_attn.v_proj | mse: 0.0939293548304969, bpp_loss: 2.416167994253337, bpp: 0
2025-03-03 08:49:53 - INFO - layer8_self_attn.o_proj | mse: 0.09735363133606782, bpp_loss: 2.407593948058784, bpp: 0
2025-03-03 08:50:14 - INFO - layer8_mlp.gate_proj | mse: 0.10005201084660804, bpp_loss: 2.712064410249392, bpp: 0
2025-03-03 08:50:30 - INFO - layer8_mlp.up_proj | mse: 0.09782452211180198, bpp_loss: 2.590892109495622, bpp: 0
2025-03-03 08:51:14 - INFO - layer8_mlp.down_proj | mse: 0.0934148013399089, bpp_loss: 2.5877142273441507, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [21:37<1:14:43, 144.62s/it]2025-03-03 08:51:31 - INFO - layer9_self_attn.q_proj | mse: 0.1032176089018081, bpp_loss: 2.9197219740226865, bpp: 0
2025-03-03 08:51:47 - INFO - layer9_self_attn.k_proj | mse: 0.10329155811514762, bpp_loss: 2.927415935173631, bpp: 0
2025-03-03 08:52:01 - INFO - layer9_self_attn.v_proj | mse: 0.09344993461207293, bpp_loss: 2.4119131887704133, bpp: 0
2025-03-03 08:52:17 - INFO - layer9_self_attn.o_proj | mse: 0.09695048167325347, bpp_loss: 2.4074832217395308, bpp: 0
2025-03-03 08:52:38 - INFO - layer9_mlp.gate_proj | mse: 0.09910696002337319, bpp_loss: 2.69965377913581, bpp: 0
2025-03-03 08:52:55 - INFO - layer9_mlp.up_proj | mse: 0.09741704702279816, bpp_loss: 2.6022302409565006, bpp: 0
2025-03-03 08:53:39 - INFO - layer9_mlp.down_proj | mse: 0.09324682746403415, bpp_loss: 2.5968197984551944, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [24:02<1:12:21, 144.71s/it]2025-03-03 08:53:56 - INFO - layer10_self_attn.q_proj | mse: 0.10275425266855047, bpp_loss: 2.9151846285536887, bpp: 0
2025-03-03 08:54:13 - INFO - layer10_self_attn.k_proj | mse: 0.10301441358066925, bpp_loss: 2.9346273431926964, bpp: 0
2025-03-03 08:54:27 - INFO - layer10_self_attn.v_proj | mse: 0.09315388560012969, bpp_loss: 2.405441943816841, bpp: 0
2025-03-03 08:54:43 - INFO - layer10_self_attn.o_proj | mse: 0.09541180256961963, bpp_loss: 2.40530056219548, bpp: 0
2025-03-03 08:55:03 - INFO - layer10_mlp.gate_proj | mse: 0.09865218459844306, bpp_loss: 2.687144980110504, bpp: 0
2025-03-03 08:55:20 - INFO - layer10_mlp.up_proj | mse: 0.09741037773036905, bpp_loss: 2.6117167173160447, bpp: 0
2025-03-03 08:56:04 - INFO - layer10_mlp.down_proj | mse: 0.09376069260013997, bpp_loss: 2.6052746224596546, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [26:27<1:09:59, 144.81s/it]2025-03-03 08:56:21 - INFO - layer11_self_attn.q_proj | mse: 0.10346265513166975, bpp_loss: 2.9631089383363722, bpp: 0
2025-03-03 08:56:38 - INFO - layer11_self_attn.k_proj | mse: 0.10388773517497202, bpp_loss: 2.9892814587801695, bpp: 0
2025-03-03 08:56:52 - INFO - layer11_self_attn.v_proj | mse: 0.09301607351686074, bpp_loss: 2.4155100594088434, bpp: 0
2025-03-03 08:57:09 - INFO - layer11_self_attn.o_proj | mse: 0.09855679119273755, bpp_loss: 2.403152959048748, bpp: 0
2025-03-03 08:57:28 - INFO - layer11_mlp.gate_proj | mse: 0.09790211443986502, bpp_loss: 2.6730198739855378, bpp: 0
2025-03-03 08:57:45 - INFO - layer11_mlp.up_proj | mse: 0.09709671222746008, bpp_loss: 2.6202690497592642, bpp: 0
2025-03-03 08:58:30 - INFO - layer11_mlp.down_proj | mse: 0.0940791485668036, bpp_loss: 2.6118903701090153, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [28:53<1:07:44, 145.16s/it]2025-03-03 08:58:47 - INFO - layer12_self_attn.q_proj | mse: 0.10222491246667569, bpp_loss: 2.9106187247484923, bpp: 0
2025-03-03 08:59:04 - INFO - layer12_self_attn.k_proj | mse: 0.10250977750372012, bpp_loss: 2.9295867550745607, bpp: 0
2025-03-03 08:59:19 - INFO - layer12_self_attn.v_proj | mse: 0.09325804192869652, bpp_loss: 2.4376378057897092, bpp: 0
2025-03-03 08:59:36 - INFO - layer12_self_attn.o_proj | mse: 0.10135127196592686, bpp_loss: 2.429993044510484, bpp: 0
2025-03-03 08:59:54 - INFO - layer12_mlp.gate_proj | mse: 0.09771620928681682, bpp_loss: 2.667067680038788, bpp: 0
2025-03-03 09:00:11 - INFO - layer12_mlp.up_proj | mse: 0.09717328273641947, bpp_loss: 2.6282112212644684, bpp: 0
2025-03-03 09:00:56 - INFO - layer12_mlp.down_proj | mse: 0.0939500477660757, bpp_loss: 2.6191207473476728, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [31:19<1:05:26, 145.41s/it]2025-03-03 09:01:13 - INFO - layer13_self_attn.q_proj | mse: 0.1012811792956559, bpp_loss: 2.861383032724261, bpp: 0
2025-03-03 09:01:29 - INFO - layer13_self_attn.k_proj | mse: 0.10093079010859095, bpp_loss: 2.8590512186288835, bpp: 0
2025-03-03 09:01:44 - INFO - layer13_self_attn.v_proj | mse: 0.09367518639299234, bpp_loss: 2.4538041716068983, bpp: 0
2025-03-03 09:02:02 - INFO - layer13_self_attn.o_proj | mse: 0.0971533506715173, bpp_loss: 2.451943670026958, bpp: 0
2025-03-03 09:02:19 - INFO - layer13_mlp.gate_proj | mse: 0.09770845225147096, bpp_loss: 2.6641879260815955, bpp: 0
2025-03-03 09:02:36 - INFO - layer13_mlp.up_proj | mse: 0.0974232218866287, bpp_loss: 2.6358690741989346, bpp: 0
2025-03-03 09:03:22 - INFO - layer13_mlp.down_proj | mse: 0.09397407699596438, bpp_loss: 2.625974338391313, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [33:45<1:03:03, 145.51s/it]2025-03-03 09:03:39 - INFO - layer14_self_attn.q_proj | mse: 0.1019849984056668, bpp_loss: 2.8982299895584585, bpp: 0
2025-03-03 09:03:53 - INFO - layer14_self_attn.k_proj | mse: 0.10219619605367292, bpp_loss: 2.921250665523112, bpp: 0
2025-03-03 09:04:09 - INFO - layer14_self_attn.v_proj | mse: 0.09347383776266899, bpp_loss: 2.4439616809412836, bpp: 0
2025-03-03 09:04:27 - INFO - layer14_self_attn.o_proj | mse: 0.09645773413195606, bpp_loss: 2.439681224524975, bpp: 0
2025-03-03 09:04:44 - INFO - layer14_mlp.gate_proj | mse: 0.09751736109178927, bpp_loss: 2.6607372537255287, bpp: 0
2025-03-03 09:05:01 - INFO - layer14_mlp.up_proj | mse: 0.0974361209793993, bpp_loss: 2.641090975701809, bpp: 0
2025-03-03 09:05:48 - INFO - layer14_mlp.down_proj | mse: 0.09385877624678662, bpp_loss: 2.6299062428789006, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [36:11<1:00:43, 145.74s/it]2025-03-03 09:06:05 - INFO - layer15_self_attn.q_proj | mse: 0.10142660805148523, bpp_loss: 2.8805464236438274, bpp: 0
2025-03-03 09:06:19 - INFO - layer15_self_attn.k_proj | mse: 0.1018208950816709, bpp_loss: 2.9159099402278663, bpp: 0
2025-03-03 09:06:36 - INFO - layer15_self_attn.v_proj | mse: 0.09395437044543965, bpp_loss: 2.4762515518814325, bpp: 0
2025-03-03 09:06:53 - INFO - layer15_self_attn.o_proj | mse: 0.10315725400278528, bpp_loss: 2.4721865110471843, bpp: 0
2025-03-03 09:07:10 - INFO - layer15_mlp.gate_proj | mse: 0.09754934512846324, bpp_loss: 2.661730756058737, bpp: 0
2025-03-03 09:07:27 - INFO - layer15_mlp.up_proj | mse: 0.09754686199816838, bpp_loss: 2.648143613421255, bpp: 0
2025-03-03 09:08:14 - INFO - layer15_mlp.down_proj | mse: 0.09387757552083305, bpp_loss: 2.636432171806141, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [38:37<58:17, 145.73s/it]  2025-03-03 09:08:31 - INFO - layer16_self_attn.q_proj | mse: 0.1012425026185357, bpp_loss: 2.868354365974665, bpp: 0
2025-03-03 09:08:45 - INFO - layer16_self_attn.k_proj | mse: 0.10146226624201139, bpp_loss: 2.894011317640543, bpp: 0
2025-03-03 09:09:03 - INFO - layer16_self_attn.v_proj | mse: 0.09414581814307739, bpp_loss: 2.480216518715024, bpp: 0
2025-03-03 09:09:18 - INFO - layer16_self_attn.o_proj | mse: 0.09719534249239066, bpp_loss: 2.4758257296308877, bpp: 0
2025-03-03 09:09:35 - INFO - layer16_mlp.gate_proj | mse: 0.09768164323412831, bpp_loss: 2.6657023750797464, bpp: 0
2025-03-03 09:09:52 - INFO - layer16_mlp.up_proj | mse: 0.0976274099105204, bpp_loss: 2.6480009014407795, bpp: 0
2025-03-03 09:10:40 - INFO - layer16_mlp.down_proj | mse: 0.09413954576693989, bpp_loss: 2.6364435565278486, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [41:02<55:50, 145.66s/it]2025-03-03 09:10:56 - INFO - layer17_self_attn.q_proj | mse: 0.10105009078513083, bpp_loss: 2.859107156544924, bpp: 0
2025-03-03 09:11:11 - INFO - layer17_self_attn.k_proj | mse: 0.10134565031276155, bpp_loss: 2.8860481560975315, bpp: 0
2025-03-03 09:11:29 - INFO - layer17_self_attn.v_proj | mse: 0.09439712383899646, bpp_loss: 2.490113556161523, bpp: 0
2025-03-03 09:11:43 - INFO - layer17_self_attn.o_proj | mse: 0.09639505047423412, bpp_loss: 2.490307823717594, bpp: 0
2025-03-03 09:12:00 - INFO - layer17_mlp.gate_proj | mse: 0.09762991501541964, bpp_loss: 2.6762505786562407, bpp: 0
2025-03-03 09:12:17 - INFO - layer17_mlp.up_proj | mse: 0.0972486556294402, bpp_loss: 2.6432495133468397, bpp: 0
2025-03-03 09:13:05 - INFO - layer17_mlp.down_proj | mse: 0.09344124777627928, bpp_loss: 2.6334432182074696, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [43:27<53:19, 145.44s/it]2025-03-03 09:13:20 - INFO - layer18_self_attn.q_proj | mse: 0.10080985781767592, bpp_loss: 2.8713430993258955, bpp: 0
2025-03-03 09:13:35 - INFO - layer18_self_attn.k_proj | mse: 0.10116963620382699, bpp_loss: 2.898644577413797, bpp: 0
2025-03-03 09:13:54 - INFO - layer18_self_attn.v_proj | mse: 0.09452141577223852, bpp_loss: 2.523098201453686, bpp: 0
2025-03-03 09:14:07 - INFO - layer18_self_attn.o_proj | mse: 0.09662998811139877, bpp_loss: 2.514499866552651, bpp: 0
2025-03-03 09:14:24 - INFO - layer18_mlp.gate_proj | mse: 0.09770066225421853, bpp_loss: 2.6827186275411536, bpp: 0
2025-03-03 09:14:41 - INFO - layer18_mlp.up_proj | mse: 0.09705638882842423, bpp_loss: 2.6374612985661736, bpp: 0
2025-03-03 09:15:30 - INFO - layer18_mlp.down_proj | mse: 0.0927498827733003, bpp_loss: 2.6301036187206153, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [45:53<50:57, 145.60s/it]2025-03-03 09:15:45 - INFO - layer19_self_attn.q_proj | mse: 0.0999508647641586, bpp_loss: 2.8283895756676793, bpp: 0
2025-03-03 09:16:01 - INFO - layer19_self_attn.k_proj | mse: 0.10015914033914738, bpp_loss: 2.8494210155680775, bpp: 0
2025-03-03 09:16:18 - INFO - layer19_self_attn.v_proj | mse: 0.09457692774313875, bpp_loss: 2.5206271697953344, bpp: 0
2025-03-03 09:16:33 - INFO - layer19_self_attn.o_proj | mse: 0.09451991023715599, bpp_loss: 2.5158654875680804, bpp: 0
2025-03-03 09:16:50 - INFO - layer19_mlp.gate_proj | mse: 0.09784818876071841, bpp_loss: 2.6893631418270094, bpp: 0
2025-03-03 09:17:07 - INFO - layer19_mlp.up_proj | mse: 0.09700568242881917, bpp_loss: 2.636392325907946, bpp: 0
2025-03-03 09:17:56 - INFO - layer19_mlp.down_proj | mse: 0.09252801618018552, bpp_loss: 2.628922715631348, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [48:19<48:32, 145.63s/it]2025-03-03 09:18:11 - INFO - layer20_self_attn.q_proj | mse: 0.10070630963628527, bpp_loss: 2.850710068754852, bpp: 0
2025-03-03 09:18:28 - INFO - layer20_self_attn.k_proj | mse: 0.10093000396711929, bpp_loss: 2.8754501673579216, bpp: 0
2025-03-03 09:18:44 - INFO - layer20_self_attn.v_proj | mse: 0.09465666177108108, bpp_loss: 2.5202170107513666, bpp: 0
2025-03-03 09:18:58 - INFO - layer20_self_attn.o_proj | mse: 0.09655128496708437, bpp_loss: 2.519359179884195, bpp: 0
2025-03-03 09:19:15 - INFO - layer20_mlp.gate_proj | mse: 0.09811565265792008, bpp_loss: 2.6923789894139327, bpp: 0
2025-03-03 09:19:32 - INFO - layer20_mlp.up_proj | mse: 0.09714350714748562, bpp_loss: 2.6360791499140084, bpp: 0
2025-03-03 09:20:22 - INFO - layer20_mlp.down_proj | mse: 0.09236495362838953, bpp_loss: 2.627901010380851, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [50:44<46:07, 145.64s/it]2025-03-03 09:20:37 - INFO - layer21_self_attn.q_proj | mse: 0.10026159088904929, bpp_loss: 2.8195416742935775, bpp: 0
2025-03-03 09:20:56 - INFO - layer21_self_attn.k_proj | mse: 0.10033389365515567, bpp_loss: 2.8365599809214475, bpp: 0
2025-03-03 09:21:09 - INFO - layer21_self_attn.v_proj | mse: 0.0955448236397688, bpp_loss: 2.5467843552678824, bpp: 0
2025-03-03 09:21:23 - INFO - layer21_self_attn.o_proj | mse: 0.09509047095129043, bpp_loss: 2.5464772180095316, bpp: 0
2025-03-03 09:21:40 - INFO - layer21_mlp.gate_proj | mse: 0.09926459484788751, bpp_loss: 2.701291615902274, bpp: 0
2025-03-03 09:21:57 - INFO - layer21_mlp.up_proj | mse: 0.09801427282061653, bpp_loss: 2.631050140079525, bpp: 0
2025-03-03 09:22:47 - INFO - layer21_mlp.down_proj | mse: 0.0927171076508687, bpp_loss: 2.627127362553168, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [53:10<43:39, 145.50s/it]2025-03-03 09:23:03 - INFO - layer22_self_attn.q_proj | mse: 0.1007760314851073, bpp_loss: 2.8178224904462694, bpp: 0
2025-03-03 09:23:21 - INFO - layer22_self_attn.k_proj | mse: 0.10113999273720198, bpp_loss: 2.8419874865561723, bpp: 0
2025-03-03 09:23:35 - INFO - layer22_self_attn.v_proj | mse: 0.09716133074909762, bpp_loss: 2.601727196574211, bpp: 0
2025-03-03 09:23:49 - INFO - layer22_self_attn.o_proj | mse: 0.094224105967369, bpp_loss: 2.591466491445899, bpp: 0
2025-03-03 09:24:06 - INFO - layer22_mlp.gate_proj | mse: 0.09902706036185034, bpp_loss: 2.709297647520348, bpp: 0
2025-03-03 09:24:24 - INFO - layer22_mlp.up_proj | mse: 0.09753663281982984, bpp_loss: 2.6270792199781647, bpp: 0
2025-03-03 09:25:13 - INFO - layer22_mlp.down_proj | mse: 0.09193476229210867, bpp_loss: 2.62479241065405, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [55:36<41:16, 145.66s/it]2025-03-03 09:25:30 - INFO - layer23_self_attn.q_proj | mse: 0.09987389706422506, bpp_loss: 2.791958553418517, bpp: 0
2025-03-03 09:25:47 - INFO - layer23_self_attn.k_proj | mse: 0.10000597624789402, bpp_loss: 2.80618167899549, bpp: 0
2025-03-03 09:26:01 - INFO - layer23_self_attn.v_proj | mse: 0.0967471157742481, bpp_loss: 2.5951992085948588, bpp: 0
2025-03-03 09:26:15 - INFO - layer23_self_attn.o_proj | mse: 0.09179525514279444, bpp_loss: 2.591403006017208, bpp: 0
2025-03-03 09:26:32 - INFO - layer23_mlp.gate_proj | mse: 0.09897142066356215, bpp_loss: 2.716489402204752, bpp: 0
2025-03-03 09:26:50 - INFO - layer23_mlp.up_proj | mse: 0.09721058462735319, bpp_loss: 2.623647211105735, bpp: 0
2025-03-03 09:27:39 - INFO - layer23_mlp.down_proj | mse: 0.09138402376985451, bpp_loss: 2.622850737941486, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [58:02<38:52, 145.75s/it]2025-03-03 09:27:57 - INFO - layer24_self_attn.q_proj | mse: 0.09977390135231488, bpp_loss: 2.8050580224767327, bpp: 0
2025-03-03 09:28:12 - INFO - layer24_self_attn.k_proj | mse: 0.09994631849319509, bpp_loss: 2.8203325188905, bpp: 0
2025-03-03 09:28:26 - INFO - layer24_self_attn.v_proj | mse: 0.09653104553240345, bpp_loss: 2.604794141575694, bpp: 0
2025-03-03 09:28:40 - INFO - layer24_self_attn.o_proj | mse: 0.0916983372489101, bpp_loss: 2.599791601449251, bpp: 0
2025-03-03 09:28:57 - INFO - layer24_mlp.gate_proj | mse: 0.09881047866108877, bpp_loss: 2.722390627861023, bpp: 0
2025-03-03 09:29:17 - INFO - layer24_mlp.up_proj | mse: 0.09693507802494875, bpp_loss: 2.6228995369816266, bpp: 0
2025-03-03 09:30:05 - INFO - layer24_mlp.down_proj | mse: 0.09093923580261475, bpp_loss: 2.6236899758516636, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [1:00:27<36:25, 145.71s/it]2025-03-03 09:30:23 - INFO - layer25_self_attn.q_proj | mse: 0.09913588080019668, bpp_loss: 2.7949476101621986, bpp: 0
2025-03-03 09:30:37 - INFO - layer25_self_attn.k_proj | mse: 0.09923463796846753, bpp_loss: 2.806739875115454, bpp: 0
2025-03-03 09:30:51 - INFO - layer25_self_attn.v_proj | mse: 0.09661770650501122, bpp_loss: 2.628533178642392, bpp: 0
2025-03-03 09:31:04 - INFO - layer25_self_attn.o_proj | mse: 0.09142337314455126, bpp_loss: 2.6269836681336165, bpp: 0
2025-03-03 09:31:21 - INFO - layer25_mlp.gate_proj | mse: 0.09857108732098158, bpp_loss: 2.7261737917584403, bpp: 0
2025-03-03 09:31:42 - INFO - layer25_mlp.up_proj | mse: 0.09657309036700988, bpp_loss: 2.621872695894153, bpp: 0
2025-03-03 09:32:30 - INFO - layer25_mlp.down_proj | mse: 0.09060458455252363, bpp_loss: 2.623200758353428, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [1:02:52<33:57, 145.52s/it]2025-03-03 09:32:48 - INFO - layer26_self_attn.q_proj | mse: 0.09902230560682779, bpp_loss: 2.8049435335025192, bpp: 0
2025-03-03 09:33:02 - INFO - layer26_self_attn.k_proj | mse: 0.09919338779049197, bpp_loss: 2.8171033765748144, bpp: 0
2025-03-03 09:33:16 - INFO - layer26_self_attn.v_proj | mse: 0.09664044527625773, bpp_loss: 2.645933193154633, bpp: 0
2025-03-03 09:33:30 - INFO - layer26_self_attn.o_proj | mse: 0.09236323493964453, bpp_loss: 2.620207380540669, bpp: 0
2025-03-03 09:33:47 - INFO - layer26_mlp.gate_proj | mse: 0.09841723212842046, bpp_loss: 2.7295634696329083, bpp: 0
2025-03-03 09:34:08 - INFO - layer26_mlp.up_proj | mse: 0.09643872664853315, bpp_loss: 2.6227145066415822, bpp: 0
2025-03-03 09:34:56 - INFO - layer26_mlp.down_proj | mse: 0.09039858362377065, bpp_loss: 2.6240848497384124, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [1:05:19<31:36, 145.88s/it]2025-03-03 09:35:14 - INFO - layer27_self_attn.q_proj | mse: 0.09877697013623601, bpp_loss: 2.8058781166002156, bpp: 0
2025-03-03 09:35:28 - INFO - layer27_self_attn.k_proj | mse: 0.09885334452185131, bpp_loss: 2.8152893864363433, bpp: 0
2025-03-03 09:35:42 - INFO - layer27_self_attn.v_proj | mse: 0.09623217086101958, bpp_loss: 2.6411994843930007, bpp: 0
2025-03-03 09:35:56 - INFO - layer27_self_attn.o_proj | mse: 0.09157136798480699, bpp_loss: 2.6331097247451543, bpp: 0
2025-03-03 09:36:14 - INFO - layer27_mlp.gate_proj | mse: 0.0980943592662766, bpp_loss: 2.732809802337929, bpp: 0
2025-03-03 09:36:35 - INFO - layer27_mlp.up_proj | mse: 0.09605185275113481, bpp_loss: 2.6232799716017863, bpp: 0
2025-03-03 09:37:23 - INFO - layer27_mlp.down_proj | mse: 0.0900730628217991, bpp_loss: 2.6248942697213757, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [1:07:46<29:12, 146.05s/it]2025-03-03 09:37:39 - INFO - layer28_self_attn.q_proj | mse: 0.09811573616141671, bpp_loss: 2.7991009550914168, bpp: 0
2025-03-03 09:37:52 - INFO - layer28_self_attn.k_proj | mse: 0.09819977171816627, bpp_loss: 2.807943215854466, bpp: 0
2025-03-03 09:38:06 - INFO - layer28_self_attn.v_proj | mse: 0.09584467727977776, bpp_loss: 2.648400809466839, bpp: 0
2025-03-03 09:38:20 - INFO - layer28_self_attn.o_proj | mse: 0.09192013297392576, bpp_loss: 2.640587311945856, bpp: 0
2025-03-03 09:38:40 - INFO - layer28_mlp.gate_proj | mse: 0.09755702525269376, bpp_loss: 2.7338736311705025, bpp: 0
2025-03-03 09:39:00 - INFO - layer28_mlp.up_proj | mse: 0.09556446701330594, bpp_loss: 2.6258506666179056, bpp: 0
2025-03-03 09:39:47 - INFO - layer28_mlp.down_proj | mse: 0.08963407065646435, bpp_loss: 2.6265374298448916, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [1:10:10<26:41, 145.60s/it]2025-03-03 09:40:02 - INFO - layer29_self_attn.q_proj | mse: 0.0980987228733412, bpp_loss: 2.8206608052551747, bpp: 0
2025-03-03 09:40:16 - INFO - layer29_self_attn.k_proj | mse: 0.09826247020874616, bpp_loss: 2.8365670968964696, bpp: 0
2025-03-03 09:40:29 - INFO - layer29_self_attn.v_proj | mse: 0.09546063233801069, bpp_loss: 2.6520831579715014, bpp: 0
2025-03-03 09:40:43 - INFO - layer29_self_attn.o_proj | mse: 0.09160807930824802, bpp_loss: 2.6459813417494296, bpp: 0
2025-03-03 09:41:03 - INFO - layer29_mlp.gate_proj | mse: 0.0972582475442517, bpp_loss: 2.732097483371143, bpp: 0
2025-03-03 09:41:23 - INFO - layer29_mlp.up_proj | mse: 0.09534093035025834, bpp_loss: 2.6292059703557578, bpp: 0
2025-03-03 09:42:10 - INFO - layer29_mlp.down_proj | mse: 0.08940541940424748, bpp_loss: 2.6303644021490107, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [1:12:32<24:05, 144.58s/it]2025-03-03 09:42:24 - INFO - layer30_self_attn.q_proj | mse: 0.0974237759213416, bpp_loss: 2.8012068948894737, bpp: 0
2025-03-03 09:42:37 - INFO - layer30_self_attn.k_proj | mse: 0.09755421607420643, bpp_loss: 2.80888462189585, bpp: 0
2025-03-03 09:42:51 - INFO - layer30_self_attn.v_proj | mse: 0.09611995287415367, bpp_loss: 2.696876661069691, bpp: 0
2025-03-03 09:43:05 - INFO - layer30_self_attn.o_proj | mse: 0.0914275708433528, bpp_loss: 2.6931239227205515, bpp: 0
2025-03-03 09:43:25 - INFO - layer30_mlp.gate_proj | mse: 0.09677594892733664, bpp_loss: 2.7333065112431845, bpp: 0
2025-03-03 09:43:45 - INFO - layer30_mlp.up_proj | mse: 0.09487763976613127, bpp_loss: 2.630552083060697, bpp: 0
2025-03-03 09:44:32 - INFO - layer30_mlp.down_proj | mse: 0.08922623848013934, bpp_loss: 2.6308704068815265, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [1:14:55<21:35, 144.00s/it]2025-03-03 09:44:46 - INFO - layer31_self_attn.q_proj | mse: 0.09735240762528645, bpp_loss: 2.81493844460696, bpp: 0
2025-03-03 09:45:00 - INFO - layer31_self_attn.k_proj | mse: 0.09767143273420352, bpp_loss: 2.836534695737064, bpp: 0
2025-03-03 09:45:13 - INFO - layer31_self_attn.v_proj | mse: 0.09516276630096784, bpp_loss: 2.6647304060310124, bpp: 0
2025-03-03 09:45:27 - INFO - layer31_self_attn.o_proj | mse: 0.09231884761221128, bpp_loss: 2.6538097817078232, bpp: 0
2025-03-03 09:45:47 - INFO - layer31_mlp.gate_proj | mse: 0.09655263201033282, bpp_loss: 2.733545586190842, bpp: 0
2025-03-03 09:46:07 - INFO - layer31_mlp.up_proj | mse: 0.09469851377853407, bpp_loss: 2.6332808482150236, bpp: 0
2025-03-03 09:46:54 - INFO - layer31_mlp.down_proj | mse: 0.08902178676099509, bpp_loss: 2.633364129728741, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:17:17<19:06, 143.36s/it]2025-03-03 09:47:08 - INFO - layer32_self_attn.q_proj | mse: 0.09646209499219512, bpp_loss: 2.781434791199863, bpp: 0
2025-03-03 09:47:22 - INFO - layer32_self_attn.k_proj | mse: 0.09648687328141058, bpp_loss: 2.7893595569580794, bpp: 0
2025-03-03 09:47:36 - INFO - layer32_self_attn.v_proj | mse: 0.09566077209041063, bpp_loss: 2.699543432444334, bpp: 0
2025-03-03 09:47:50 - INFO - layer32_self_attn.o_proj | mse: 0.09297520157676306, bpp_loss: 2.696950426325202, bpp: 0
2025-03-03 09:48:10 - INFO - layer32_mlp.gate_proj | mse: 0.09615144165818144, bpp_loss: 2.7303357753212807, bpp: 0
2025-03-03 09:48:30 - INFO - layer32_mlp.up_proj | mse: 0.09443964195164468, bpp_loss: 2.63771770886249, bpp: 0
2025-03-03 09:49:19 - INFO - layer32_mlp.down_proj | mse: 0.08906813669528196, bpp_loss: 2.637783373257628, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:19:41<16:45, 143.71s/it]2025-03-03 09:49:33 - INFO - layer33_self_attn.q_proj | mse: 0.09632690090835541, bpp_loss: 2.785634158179164, bpp: 0
2025-03-03 09:49:47 - INFO - layer33_self_attn.k_proj | mse: 0.09650124632076991, bpp_loss: 2.8005060248449443, bpp: 0
2025-03-03 09:50:01 - INFO - layer33_self_attn.v_proj | mse: 0.09509282937570543, bpp_loss: 2.6806829550862314, bpp: 0
2025-03-03 09:50:16 - INFO - layer33_self_attn.o_proj | mse: 0.09240375830758024, bpp_loss: 2.67664034768939, bpp: 0
2025-03-03 09:50:36 - INFO - layer33_mlp.gate_proj | mse: 0.09592446596954848, bpp_loss: 2.728274310021489, bpp: 0
2025-03-03 09:50:55 - INFO - layer33_mlp.up_proj | mse: 0.0943480627878943, bpp_loss: 2.6423288501247213, bpp: 0
2025-03-03 09:51:44 - INFO - layer33_mlp.down_proj | mse: 0.0891256002857336, bpp_loss: 2.641944357187108, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:22:07<14:25, 144.27s/it]2025-03-03 09:51:59 - INFO - layer34_self_attn.q_proj | mse: 0.0954724244600857, bpp_loss: 2.747998065762222, bpp: 0
2025-03-03 09:52:13 - INFO - layer34_self_attn.k_proj | mse: 0.09561939583314245, bpp_loss: 2.760732128433883, bpp: 0
2025-03-03 09:52:27 - INFO - layer34_self_attn.v_proj | mse: 0.09549747715717334, bpp_loss: 2.7048153675720097, bpp: 0
2025-03-03 09:52:42 - INFO - layer34_self_attn.o_proj | mse: 0.09298029666347095, bpp_loss: 2.7133912781998517, bpp: 0
2025-03-03 09:53:03 - INFO - layer34_mlp.gate_proj | mse: 0.0957305071239953, bpp_loss: 2.722758472241737, bpp: 0
2025-03-03 09:53:21 - INFO - layer34_mlp.up_proj | mse: 0.09443914752304616, bpp_loss: 2.650231983760993, bpp: 0
2025-03-03 09:54:10 - INFO - layer34_mlp.down_proj | mse: 0.0894071059551336, bpp_loss: 2.6500794645122907, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:24:33<12:03, 144.71s/it]2025-03-03 09:54:24 - INFO - layer35_self_attn.q_proj | mse: 0.09534371975160172, bpp_loss: 2.7406428188085554, bpp: 0
2025-03-03 09:54:38 - INFO - layer35_self_attn.k_proj | mse: 0.0954952003134771, bpp_loss: 2.7546979109570384, bpp: 0
2025-03-03 09:54:51 - INFO - layer35_self_attn.v_proj | mse: 0.09550711109841574, bpp_loss: 2.7054259216785432, bpp: 0
2025-03-03 09:55:07 - INFO - layer35_self_attn.o_proj | mse: 0.0942192927049623, bpp_loss: 2.7086351422220467, bpp: 0
2025-03-03 09:55:28 - INFO - layer35_mlp.gate_proj | mse: 0.09556900476911025, bpp_loss: 2.7167271881191817, bpp: 0
2025-03-03 09:55:45 - INFO - layer35_mlp.up_proj | mse: 0.09454107672545917, bpp_loss: 2.6590200902135286, bpp: 0
2025-03-03 09:56:34 - INFO - layer35_mlp.down_proj | mse: 0.08986391403096879, bpp_loss: 2.6580766034209065, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:26:57<09:38, 144.51s/it]2025-03-03 09:56:48 - INFO - layer36_self_attn.q_proj | mse: 0.09542757731405582, bpp_loss: 2.743295767605305, bpp: 0
2025-03-03 09:57:02 - INFO - layer36_self_attn.k_proj | mse: 0.09565638898088465, bpp_loss: 2.7627539673447608, bpp: 0
2025-03-03 09:57:15 - INFO - layer36_self_attn.v_proj | mse: 0.09609356521984999, bpp_loss: 2.7259651446342468, bpp: 0
2025-03-03 09:57:32 - INFO - layer36_self_attn.o_proj | mse: 0.09558823199857695, bpp_loss: 2.7297138886898757, bpp: 0
2025-03-03 09:57:52 - INFO - layer36_mlp.gate_proj | mse: 0.09566007851695991, bpp_loss: 2.7122899760526638, bpp: 0
2025-03-03 09:58:09 - INFO - layer36_mlp.up_proj | mse: 0.09477921551311676, bpp_loss: 2.6643690497510963, bpp: 0
2025-03-03 09:58:57 - INFO - layer36_mlp.down_proj | mse: 0.09044575211207063, bpp_loss: 2.6585300555245746, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:29:20<07:12, 144.18s/it]2025-03-03 09:59:09 - INFO - layer37_self_attn.q_proj | mse: 0.09452504240600876, bpp_loss: 2.6820327446237204, bpp: 0
2025-03-03 09:59:21 - INFO - layer37_self_attn.k_proj | mse: 0.09446818806146351, bpp_loss: 2.6806904058903456, bpp: 0
2025-03-03 09:59:33 - INFO - layer37_self_attn.v_proj | mse: 0.0967661537474346, bpp_loss: 2.7495942705869676, bpp: 0
2025-03-03 09:59:45 - INFO - layer37_self_attn.o_proj | mse: 0.09843714194403569, bpp_loss: 2.751057984828949, bpp: 0
2025-03-03 10:00:00 - INFO - layer37_mlp.gate_proj | mse: 0.0958803629385594, bpp_loss: 2.715858025269376, bpp: 0
2025-03-03 10:00:15 - INFO - layer37_mlp.up_proj | mse: 0.09510119840378325, bpp_loss: 2.6722464842376885, bpp: 0
2025-03-03 10:01:06 - INFO - layer37_mlp.down_proj | mse: 0.09134683724559377, bpp_loss: 2.6582128570863492, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:31:29<04:39, 139.62s/it]2025-03-03 10:01:25 - INFO - layer38_self_attn.q_proj | mse: 0.09434172311453089, bpp_loss: 2.658957768753171, bpp: 0
2025-03-03 10:01:43 - INFO - layer38_self_attn.k_proj | mse: 0.09438906959712637, bpp_loss: 2.665404459759593, bpp: 0
2025-03-03 10:02:01 - INFO - layer38_self_attn.v_proj | mse: 0.09820333160407571, bpp_loss: 2.7983812404423953, bpp: 0
2025-03-03 10:02:19 - INFO - layer38_self_attn.o_proj | mse: 0.10078487928487803, bpp_loss: 2.8099309891089796, bpp: 0
2025-03-03 10:02:41 - INFO - layer38_mlp.gate_proj | mse: 0.09719267532478414, bpp_loss: 2.746450841537228, bpp: 0
2025-03-03 10:03:03 - INFO - layer38_mlp.up_proj | mse: 0.09581235153800571, bpp_loss: 2.6761098807332693, bpp: 0
2025-03-03 10:04:01 - INFO - layer38_mlp.down_proj | mse: 0.09319333028967293, bpp_loss: 2.6411037150770427, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:34:24<02:30, 150.20s/it]2025-03-03 10:04:20 - INFO - layer39_self_attn.q_proj | mse: 0.09558570299629546, bpp_loss: 2.657749018333852, bpp: 0
2025-03-03 10:04:37 - INFO - layer39_self_attn.k_proj | mse: 0.09562074562321644, bpp_loss: 2.668613970540464, bpp: 0
2025-03-03 10:04:52 - INFO - layer39_self_attn.v_proj | mse: 0.09729075485119246, bpp_loss: 2.6916444088891147, bpp: 0
2025-03-03 10:05:03 - INFO - layer39_self_attn.o_proj | mse: 0.11408368598889897, bpp_loss: 2.6961768516525626, bpp: 0
2025-03-03 10:05:18 - INFO - layer39_mlp.gate_proj | mse: 0.09995735523824456, bpp_loss: 2.817799871718442, bpp: 0
2025-03-03 10:05:33 - INFO - layer39_mlp.up_proj | mse: 0.0979541612903372, bpp_loss: 2.7199501794245506, bpp: 0
2025-03-03 10:06:13 - INFO - layer39_mlp.down_proj | mse: 0.09967489367355409, bpp_loss: 2.628787712849401, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:36:36<00:00, 144.79s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:36:36<00:00, 144.91s/it]
2025-03-03 10:06:13 - INFO - #### Total | mse: 0.0982339072882415, bpp_loss: 2.6567669872557054, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda50_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_3.84823_bpp_4.61283_MSE_0.01614_total_iter_95000.pth.tar/COL_MSE0.09823_bpploss2.6568_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda50_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_3.84823_bpp_4.61283_MSE_0.01614_total_iter_95000.pth.tar/COL_MSE0.09823_bpploss2.6568_bpp0
I0303 10:07:12.387879 3151050 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.07it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.12it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.10it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.19it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.52it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  2.12it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.54it/s]
W0303 10:07:16.504507 3151050 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 10:07:16.526500 3151050 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.375:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.375:   1%|          | 1/166 [00:01<04:05,  1.49s/it]avg_loss = 1.65234375:   1%|          | 1/166 [00:02<04:05,  1.49s/it]avg_loss = 1.65234375:   1%|          | 2/166 [00:02<03:36,  1.32s/it]avg_loss = 1.8151041666666667:   1%|          | 2/166 [00:03<03:36,  1.32s/it]avg_loss = 1.8151041666666667:   2%|▏         | 3/166 [00:03<03:34,  1.31s/it]avg_loss = 1.845703125:   2%|▏         | 3/166 [00:05<03:34,  1.31s/it]       avg_loss = 1.845703125:   2%|▏         | 4/166 [00:05<03:21,  1.24s/it]avg_loss = 1.7671875:   2%|▏         | 4/166 [00:06<03:21,  1.24s/it]  avg_loss = 1.7671875:   3%|▎         | 5/166 [00:06<03:25,  1.28s/it]avg_loss = 1.7356770833333333:   3%|▎         | 5/166 [00:07<03:25,  1.28s/it]avg_loss = 1.7356770833333333:   4%|▎         | 6/166 [00:07<03:26,  1.29s/it]avg_loss = 1.6741071428571428:   4%|▎         | 6/166 [00:09<03:26,  1.29s/it]avg_loss = 1.6741071428571428:   4%|▍         | 7/166 [00:09<03:25,  1.29s/it]avg_loss = 1.6123046875:   4%|▍         | 7/166 [00:10<03:25,  1.29s/it]      avg_loss = 1.6123046875:   5%|▍         | 8/166 [00:10<03:18,  1.25s/it]avg_loss = 1.609375:   5%|▍         | 8/166 [00:11<03:18,  1.25s/it]    avg_loss = 1.609375:   5%|▌         | 9/166 [00:11<03:16,  1.25s/it]avg_loss = 1.61796875:   5%|▌         | 9/166 [00:12<03:16,  1.25s/it]avg_loss = 1.61796875:   6%|▌         | 10/166 [00:12<03:10,  1.22s/it]avg_loss = 1.6335227272727273:   6%|▌         | 10/166 [00:13<03:10,  1.22s/it]avg_loss = 1.6335227272727273:   7%|▋         | 11/166 [00:13<03:08,  1.22s/it]avg_loss = 1.6412760416666667:   7%|▋         | 11/166 [00:15<03:08,  1.22s/it]avg_loss = 1.6412760416666667:   7%|▋         | 12/166 [00:15<03:04,  1.20s/it]avg_loss = 1.6358173076923077:   7%|▋         | 12/166 [00:16<03:04,  1.20s/it]avg_loss = 1.6358173076923077:   8%|▊         | 13/166 [00:16<02:58,  1.17s/it]avg_loss = 1.6467633928571428:   8%|▊         | 13/166 [00:17<02:58,  1.17s/it]avg_loss = 1.6467633928571428:   8%|▊         | 14/166 [00:17<02:56,  1.16s/it]avg_loss = 1.6640625:   8%|▊         | 14/166 [00:18<02:56,  1.16s/it]         avg_loss = 1.6640625:   9%|▉         | 15/166 [00:18<02:55,  1.16s/it]avg_loss = 1.68115234375:   9%|▉         | 15/166 [00:19<02:55,  1.16s/it]avg_loss = 1.68115234375:  10%|▉         | 16/166 [00:19<02:55,  1.17s/it]avg_loss = 1.6907169117647058:  10%|▉         | 16/166 [00:20<02:55,  1.17s/it]avg_loss = 1.6907169117647058:  10%|█         | 17/166 [00:20<02:54,  1.17s/it]avg_loss = 1.7052951388888888:  10%|█         | 17/166 [00:21<02:54,  1.17s/it]avg_loss = 1.7052951388888888:  11%|█         | 18/166 [00:21<02:52,  1.16s/it]avg_loss = 1.724095394736842:  11%|█         | 18/166 [00:23<02:52,  1.16s/it] avg_loss = 1.724095394736842:  11%|█▏        | 19/166 [00:23<02:51,  1.17s/it]avg_loss = 1.730078125:  11%|█▏        | 19/166 [00:24<02:51,  1.17s/it]      avg_loss = 1.730078125:  12%|█▏        | 20/166 [00:24<02:48,  1.15s/it]avg_loss = 1.7313988095238095:  12%|█▏        | 20/166 [00:25<02:48,  1.15s/it]avg_loss = 1.7313988095238095:  13%|█▎        | 21/166 [00:25<02:51,  1.18s/it]avg_loss = 1.7208806818181819:  13%|█▎        | 21/166 [00:26<02:51,  1.18s/it]avg_loss = 1.7208806818181819:  13%|█▎        | 22/166 [00:26<02:52,  1.20s/it]avg_loss = 1.7075407608695652:  13%|█▎        | 22/166 [00:27<02:52,  1.20s/it]avg_loss = 1.7075407608695652:  14%|█▍        | 23/166 [00:27<02:50,  1.19s/it]avg_loss = 1.7145182291666667:  14%|█▍        | 23/166 [00:29<02:50,  1.19s/it]avg_loss = 1.7145182291666667:  14%|█▍        | 24/166 [00:29<02:49,  1.19s/it]avg_loss = 1.72125:  14%|█▍        | 24/166 [00:30<02:49,  1.19s/it]           avg_loss = 1.72125:  15%|█▌        | 25/166 [00:30<02:46,  1.18s/it]avg_loss = 1.7256610576923077:  15%|█▌        | 25/166 [00:31<02:46,  1.18s/it]avg_loss = 1.7256610576923077:  16%|█▌        | 26/166 [00:31<02:44,  1.18s/it]avg_loss = 1.7317708333333333:  16%|█▌        | 26/166 [00:32<02:44,  1.18s/it]avg_loss = 1.7317708333333333:  16%|█▋        | 27/166 [00:32<02:43,  1.18s/it]avg_loss = 1.7332589285714286:  16%|█▋        | 27/166 [00:33<02:43,  1.18s/it]avg_loss = 1.7332589285714286:  17%|█▋        | 28/166 [00:33<02:41,  1.17s/it]avg_loss = 1.7424568965517242:  17%|█▋        | 28/166 [00:34<02:41,  1.17s/it]avg_loss = 1.7424568965517242:  17%|█▋        | 29/166 [00:34<02:42,  1.19s/it]avg_loss = 1.74296875:  17%|█▋        | 29/166 [00:36<02:42,  1.19s/it]        avg_loss = 1.74296875:  18%|█▊        | 30/166 [00:36<02:38,  1.17s/it]avg_loss = 1.7573084677419355:  18%|█▊        | 30/166 [00:37<02:38,  1.17s/it]avg_loss = 1.7573084677419355:  19%|█▊        | 31/166 [00:37<02:35,  1.15s/it]avg_loss = 1.763671875:  19%|█▊        | 31/166 [00:38<02:35,  1.15s/it]       avg_loss = 1.763671875:  19%|█▉        | 32/166 [00:38<02:32,  1.13s/it]avg_loss = 1.7682291666666667:  19%|█▉        | 32/166 [00:39<02:32,  1.13s/it]avg_loss = 1.7682291666666667:  20%|█▉        | 33/166 [00:39<02:30,  1.13s/it]avg_loss = 1.7663143382352942:  20%|█▉        | 33/166 [00:40<02:30,  1.13s/it]avg_loss = 1.7663143382352942:  20%|██        | 34/166 [00:40<02:29,  1.13s/it]avg_loss = 1.7598214285714286:  20%|██        | 34/166 [00:41<02:29,  1.13s/it]avg_loss = 1.7598214285714286:  21%|██        | 35/166 [00:41<02:29,  1.14s/it]avg_loss = 1.7513020833333333:  21%|██        | 35/166 [00:42<02:29,  1.14s/it]avg_loss = 1.7513020833333333:  22%|██▏       | 36/166 [00:42<02:28,  1.14s/it]avg_loss = 1.7419763513513513:  22%|██▏       | 36/166 [00:44<02:28,  1.14s/it]avg_loss = 1.7419763513513513:  22%|██▏       | 37/166 [00:44<02:29,  1.16s/it]avg_loss = 1.7388980263157894:  22%|██▏       | 37/166 [00:45<02:29,  1.16s/it]avg_loss = 1.7388980263157894:  23%|██▎       | 38/166 [00:45<02:28,  1.16s/it]avg_loss = 1.736378205128205:  23%|██▎       | 38/166 [00:46<02:28,  1.16s/it] avg_loss = 1.736378205128205:  23%|██▎       | 39/166 [00:46<02:28,  1.17s/it]avg_loss = 1.7404296875:  23%|██▎       | 39/166 [00:47<02:28,  1.17s/it]     avg_loss = 1.7404296875:  24%|██▍       | 40/166 [00:47<02:25,  1.16s/it]avg_loss = 1.741044207317073:  24%|██▍       | 40/166 [00:48<02:25,  1.16s/it]avg_loss = 1.741044207317073:  25%|██▍       | 41/166 [00:48<02:25,  1.17s/it]avg_loss = 1.7293526785714286:  25%|██▍       | 41/166 [00:49<02:25,  1.17s/it]avg_loss = 1.7293526785714286:  25%|██▌       | 42/166 [00:49<02:24,  1.16s/it]avg_loss = 1.713844476744186:  25%|██▌       | 42/166 [00:51<02:24,  1.16s/it] avg_loss = 1.713844476744186:  26%|██▌       | 43/166 [00:51<02:24,  1.17s/it]avg_loss = 1.7043678977272727:  26%|██▌       | 43/166 [00:52<02:24,  1.17s/it]avg_loss = 1.7043678977272727:  27%|██▋       | 44/166 [00:52<02:23,  1.17s/it]avg_loss = 1.690625:  27%|██▋       | 44/166 [00:53<02:23,  1.17s/it]          avg_loss = 1.690625:  27%|██▋       | 45/166 [00:53<02:23,  1.19s/it]avg_loss = 1.680876358695652:  27%|██▋       | 45/166 [00:54<02:23,  1.19s/it]avg_loss = 1.680876358695652:  28%|██▊       | 46/166 [00:54<02:22,  1.19s/it]avg_loss = 1.674534574468085:  28%|██▊       | 46/166 [00:55<02:22,  1.19s/it]avg_loss = 1.674534574468085:  28%|██▊       | 47/166 [00:55<02:22,  1.20s/it]avg_loss = 1.6756184895833333:  28%|██▊       | 47/166 [00:56<02:22,  1.20s/it]avg_loss = 1.6756184895833333:  29%|██▉       | 48/166 [00:56<02:16,  1.16s/it]avg_loss = 1.6860650510204083:  29%|██▉       | 48/166 [00:58<02:16,  1.16s/it]avg_loss = 1.6860650510204083:  30%|██▉       | 49/166 [00:58<02:18,  1.18s/it]avg_loss = 1.69671875:  30%|██▉       | 49/166 [00:59<02:18,  1.18s/it]        avg_loss = 1.69671875:  30%|███       | 50/166 [00:59<02:18,  1.19s/it]avg_loss = 1.703890931372549:  30%|███       | 50/166 [01:00<02:18,  1.19s/it]avg_loss = 1.703890931372549:  31%|███       | 51/166 [01:00<02:19,  1.21s/it]avg_loss = 1.7085336538461537:  31%|███       | 51/166 [01:01<02:19,  1.21s/it]avg_loss = 1.7085336538461537:  31%|███▏      | 52/166 [01:01<02:19,  1.23s/it]avg_loss = 1.7118219339622642:  31%|███▏      | 52/166 [01:03<02:19,  1.23s/it]avg_loss = 1.7118219339622642:  32%|███▏      | 53/166 [01:03<02:18,  1.22s/it]avg_loss = 1.712818287037037:  32%|███▏      | 53/166 [01:04<02:18,  1.22s/it] avg_loss = 1.712818287037037:  33%|███▎      | 54/166 [01:04<02:18,  1.24s/it]avg_loss = 1.7160511363636364:  33%|███▎      | 54/166 [01:05<02:18,  1.24s/it]avg_loss = 1.7160511363636364:  33%|███▎      | 55/166 [01:05<02:20,  1.26s/it]avg_loss = 1.7198660714285714:  33%|███▎      | 55/166 [01:07<02:20,  1.26s/it]avg_loss = 1.7198660714285714:  34%|███▎      | 56/166 [01:07<02:20,  1.28s/it]avg_loss = 1.715049342105263:  34%|███▎      | 56/166 [01:08<02:20,  1.28s/it] avg_loss = 1.715049342105263:  34%|███▍      | 57/166 [01:08<02:19,  1.28s/it]avg_loss = 1.715049342105263:  34%|███▍      | 57/166 [01:09<02:12,  1.22s/it]
Traceback (most recent call last):
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 115, in <module>
    main(args)
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 91, in main
    output = model(input,
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1163, in forward
    outputs = self.model(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 913, in forward
    layer_outputs = decoder_layer(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 656, in forward
    hidden_states = self.mlp(hidden_states)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 242, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 160, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 293, in pre_forward
    set_module_tensor_to_device(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 347, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 68.19 MiB is free. Process 3149714 has 2.27 GiB memory in use. Including non-PyTorch memory, this process has 21.22 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 226.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running with lmbda=100
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  8.64it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00,  9.85it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00, 10.27it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00,  9.90it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00,  9.99it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.97it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.94it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:02<00:46,  1.24s/it]calculating model weight mean & std:   8%|▊         | 3/40 [00:02<00:35,  1.06it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:03<00:30,  1.19it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:04<00:26,  1.34it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:04<00:23,  1.45it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:05<00:21,  1.53it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:05<00:20,  1.59it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:06<00:19,  1.63it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:07<00:18,  1.62it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:07<00:17,  1.61it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:08<00:17,  1.64it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:08<00:16,  1.66it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:09<00:15,  1.68it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:10<00:14,  1.67it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:10<00:15,  1.57it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:11<00:14,  1.63it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:12<00:16,  1.35it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:13<00:17,  1.21it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:14<00:16,  1.19it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:15<00:15,  1.25it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:15<00:13,  1.34it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:16<00:12,  1.34it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:17<00:11,  1.40it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:17<00:10,  1.45it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:18<00:09,  1.54it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:19<00:08,  1.47it/s]calculating model weight mean & std:  70%|███████   | 28/40 [00:19<00:08,  1.41it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:20<00:07,  1.43it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:21<00:06,  1.46it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:22<00:06,  1.31it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:23<00:07,  1.14it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:24<00:06,  1.03it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:25<00:06,  1.02s/it]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:26<00:05,  1.04s/it]calculating model weight mean & std:  90%|█████████ | 36/40 [00:27<00:03,  1.00it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:28<00:02,  1.07it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:29<00:01,  1.15it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:29<00:00,  1.14it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:30<00:00,  1.18it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:30<00:00,  1.30it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 10:13:14 - INFO - layer0_self_attn.q_proj | mse: 0.05209300826601882, bpp_loss: 2.6433912901580334, bpp: 0
2025-03-03 10:13:31 - INFO - layer0_self_attn.k_proj | mse: 0.050131522254564485, bpp_loss: 2.716718745417893, bpp: 0
2025-03-03 10:13:45 - INFO - layer0_self_attn.v_proj | mse: 0.047769100384345724, bpp_loss: 2.6052864541485907, bpp: 0
2025-03-03 10:14:02 - INFO - layer0_self_attn.o_proj | mse: 0.048288424698885744, bpp_loss: 2.5211579071730377, bpp: 0
2025-03-03 10:14:21 - INFO - layer0_mlp.gate_proj | mse: 0.05981304373441816, bpp_loss: 2.9369457470046147, bpp: 0
2025-03-03 10:14:38 - INFO - layer0_mlp.up_proj | mse: 0.05951627120862572, bpp_loss: 2.9121898510665805, bpp: 0
2025-03-03 10:15:22 - INFO - layer0_mlp.down_proj | mse: 0.06972504612698582, bpp_loss: 3.0201297693092513, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [02:24<1:33:38, 144.06s/it]2025-03-03 10:15:38 - INFO - layer1_self_attn.q_proj | mse: 0.06116323786644968, bpp_loss: 3.1172659398987888, bpp: 0
2025-03-03 10:15:55 - INFO - layer1_self_attn.k_proj | mse: 0.06167414453409969, bpp_loss: 3.149842834994197, bpp: 0
2025-03-03 10:16:09 - INFO - layer1_self_attn.v_proj | mse: 0.056673665502480826, bpp_loss: 2.6824921284615995, bpp: 0
2025-03-03 10:16:26 - INFO - layer1_self_attn.o_proj | mse: 0.07094943097934289, bpp_loss: 2.6482719257846474, bpp: 0
2025-03-03 10:16:44 - INFO - layer1_mlp.gate_proj | mse: 0.06860124837807931, bpp_loss: 3.109077418843905, bpp: 0
2025-03-03 10:17:01 - INFO - layer1_mlp.up_proj | mse: 0.06778735298108182, bpp_loss: 3.046160765212995, bpp: 0
2025-03-03 10:17:45 - INFO - layer1_mlp.down_proj | mse: 0.05362912087320243, bpp_loss: 3.0717229895431686, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [04:47<1:31:10, 143.95s/it]2025-03-03 10:18:02 - INFO - layer2_self_attn.q_proj | mse: 0.062236447054567136, bpp_loss: 3.44019552577287, bpp: 0
2025-03-03 10:18:19 - INFO - layer2_self_attn.k_proj | mse: 0.06253630811100508, bpp_loss: 3.4743234578147533, bpp: 0
2025-03-03 10:18:33 - INFO - layer2_self_attn.v_proj | mse: 0.05521037069119374, bpp_loss: 2.818293660692871, bpp: 0
2025-03-03 10:18:50 - INFO - layer2_self_attn.o_proj | mse: 0.05456692131306365, bpp_loss: 2.810177403762937, bpp: 0
2025-03-03 10:19:08 - INFO - layer2_mlp.gate_proj | mse: 0.05990561724901671, bpp_loss: 3.163119587743724, bpp: 0
2025-03-03 10:19:25 - INFO - layer2_mlp.up_proj | mse: 0.05886422426653227, bpp_loss: 3.070804641423402, bpp: 0
2025-03-03 10:20:09 - INFO - layer2_mlp.down_proj | mse: 0.04873571708431835, bpp_loss: 3.0824936120322457, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [07:11<1:28:41, 143.82s/it]2025-03-03 10:20:26 - INFO - layer3_self_attn.q_proj | mse: 0.05771548836316344, bpp_loss: 3.497028389163315, bpp: 0
2025-03-03 10:20:42 - INFO - layer3_self_attn.k_proj | mse: 0.05819265769539258, bpp_loss: 3.557772351242602, bpp: 0
2025-03-03 10:20:56 - INFO - layer3_self_attn.v_proj | mse: 0.051178340080163774, bpp_loss: 2.8553989601880314, bpp: 0
2025-03-03 10:21:13 - INFO - layer3_self_attn.o_proj | mse: 0.05024168218238901, bpp_loss: 2.82760645609349, bpp: 0
2025-03-03 10:21:32 - INFO - layer3_mlp.gate_proj | mse: 0.05461007270634184, bpp_loss: 3.1739488935029065, bpp: 0
2025-03-03 10:21:49 - INFO - layer3_mlp.up_proj | mse: 0.05363694932601253, bpp_loss: 3.077913394239214, bpp: 0
2025-03-03 10:22:33 - INFO - layer3_mlp.down_proj | mse: 0.053538711857135234, bpp_loss: 3.0803604933950637, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [09:35<1:26:18, 143.83s/it]2025-03-03 10:22:50 - INFO - layer4_self_attn.q_proj | mse: 0.055261770252225666, bpp_loss: 3.4478687556833028, bpp: 0
2025-03-03 10:23:06 - INFO - layer4_self_attn.k_proj | mse: 0.0553257035782304, bpp_loss: 3.461431824564934, bpp: 0
2025-03-03 10:23:20 - INFO - layer4_self_attn.v_proj | mse: 0.049312014268925994, bpp_loss: 2.8436218098551036, bpp: 0
2025-03-03 10:23:37 - INFO - layer4_self_attn.o_proj | mse: 0.04732425184960265, bpp_loss: 2.839853913523257, bpp: 0
2025-03-03 10:23:56 - INFO - layer4_mlp.gate_proj | mse: 0.052981781990097225, bpp_loss: 3.1808141172484117, bpp: 0
2025-03-03 10:24:12 - INFO - layer4_mlp.up_proj | mse: 0.051991122875473306, bpp_loss: 3.0799214453057004, bpp: 0
2025-03-03 10:24:56 - INFO - layer4_mlp.down_proj | mse: 0.04706901475961887, bpp_loss: 3.0835025601916843, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [11:58<1:23:48, 143.67s/it]2025-03-03 10:25:13 - INFO - layer5_self_attn.q_proj | mse: 0.05350970565403722, bpp_loss: 3.4116900342702867, bpp: 0
2025-03-03 10:25:29 - INFO - layer5_self_attn.k_proj | mse: 0.0533710777635807, bpp_loss: 3.403411577306688, bpp: 0
2025-03-03 10:25:44 - INFO - layer5_self_attn.v_proj | mse: 0.04838080003002106, bpp_loss: 2.8639207552745938, bpp: 0
2025-03-03 10:26:01 - INFO - layer5_self_attn.o_proj | mse: 0.049136293108936066, bpp_loss: 2.8560611003264786, bpp: 0
2025-03-03 10:26:19 - INFO - layer5_mlp.gate_proj | mse: 0.05194996444147102, bpp_loss: 3.1942810703206947, bpp: 0
2025-03-03 10:26:36 - INFO - layer5_mlp.up_proj | mse: 0.05081075700124358, bpp_loss: 3.077506008854619, bpp: 0
2025-03-03 10:27:20 - INFO - layer5_mlp.down_proj | mse: 0.04696721740483213, bpp_loss: 3.081221284855295, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [14:22<1:21:27, 143.75s/it]2025-03-03 10:27:37 - INFO - layer6_self_attn.q_proj | mse: 0.05296562900778317, bpp_loss: 3.4321351811289786, bpp: 0
2025-03-03 10:27:53 - INFO - layer6_self_attn.k_proj | mse: 0.053078184442167574, bpp_loss: 3.452957586124539, bpp: 0
2025-03-03 10:28:08 - INFO - layer6_self_attn.v_proj | mse: 0.047830330421987984, bpp_loss: 2.8863533538207413, bpp: 0
2025-03-03 10:28:25 - INFO - layer6_self_attn.o_proj | mse: 0.04842191671227501, bpp_loss: 2.881866835206747, bpp: 0
2025-03-03 10:28:43 - INFO - layer6_mlp.gate_proj | mse: 0.05115698337419145, bpp_loss: 3.206038142133642, bpp: 0
2025-03-03 10:29:00 - INFO - layer6_mlp.up_proj | mse: 0.04991216049166638, bpp_loss: 3.0741142579250864, bpp: 0
2025-03-03 10:29:44 - INFO - layer6_mlp.down_proj | mse: 0.04684641201725738, bpp_loss: 3.0767514630600257, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [16:46<1:19:04, 143.79s/it]2025-03-03 10:30:01 - INFO - layer7_self_attn.q_proj | mse: 0.052644430885175564, bpp_loss: 3.457569506764412, bpp: 0
2025-03-03 10:30:17 - INFO - layer7_self_attn.k_proj | mse: 0.05273936488430828, bpp_loss: 3.477884992174804, bpp: 0
2025-03-03 10:30:32 - INFO - layer7_self_attn.v_proj | mse: 0.047499075621686225, bpp_loss: 2.902982431277633, bpp: 0
2025-03-03 10:30:49 - INFO - layer7_self_attn.o_proj | mse: 0.04866456743557677, bpp_loss: 2.894901886731386, bpp: 0
2025-03-03 10:31:07 - INFO - layer7_mlp.gate_proj | mse: 0.05063835524258642, bpp_loss: 3.210044461654292, bpp: 0
2025-03-03 10:31:24 - INFO - layer7_mlp.up_proj | mse: 0.04938086949428783, bpp_loss: 3.0750824953670857, bpp: 0
2025-03-03 10:32:08 - INFO - layer7_mlp.down_proj | mse: 0.0470397940294456, bpp_loss: 3.0751546286736375, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [19:10<1:16:40, 143.77s/it]2025-03-03 10:32:25 - INFO - layer8_self_attn.q_proj | mse: 0.05211914005352276, bpp_loss: 3.4253580590337513, bpp: 0
2025-03-03 10:32:41 - INFO - layer8_self_attn.k_proj | mse: 0.05222532848362956, bpp_loss: 3.4458067008852957, bpp: 0
2025-03-03 10:32:55 - INFO - layer8_self_attn.v_proj | mse: 0.04734977919814488, bpp_loss: 2.910201343484223, bpp: 0
2025-03-03 10:33:13 - INFO - layer8_self_attn.o_proj | mse: 0.049000553917566476, bpp_loss: 2.9037689762562513, bpp: 0
2025-03-03 10:33:30 - INFO - layer8_mlp.gate_proj | mse: 0.0503714901533541, bpp_loss: 3.2055678854937906, bpp: 0
2025-03-03 10:33:47 - INFO - layer8_mlp.up_proj | mse: 0.04925791059548391, bpp_loss: 3.0850693545407717, bpp: 0
2025-03-03 10:34:32 - INFO - layer8_mlp.down_proj | mse: 0.04693696936190414, bpp_loss: 3.083734469143329, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [21:34<1:14:18, 143.83s/it]2025-03-03 10:34:49 - INFO - layer9_self_attn.q_proj | mse: 0.05186950305412374, bpp_loss: 3.414575282931328, bpp: 0
2025-03-03 10:35:04 - INFO - layer9_self_attn.k_proj | mse: 0.051922497147385935, bpp_loss: 3.422556669265032, bpp: 0
2025-03-03 10:35:19 - INFO - layer9_self_attn.v_proj | mse: 0.04713601175749789, bpp_loss: 2.9059801173955204, bpp: 0
2025-03-03 10:35:37 - INFO - layer9_self_attn.o_proj | mse: 0.04875780678068801, bpp_loss: 2.9044014263153075, bpp: 0
2025-03-03 10:35:54 - INFO - layer9_mlp.gate_proj | mse: 0.04987571011665235, bpp_loss: 3.1934542171933034, bpp: 0
2025-03-03 10:36:11 - INFO - layer9_mlp.up_proj | mse: 0.04902129354917958, bpp_loss: 3.0966305508657737, bpp: 0
2025-03-03 10:36:55 - INFO - layer9_mlp.down_proj | mse: 0.04683408426420064, bpp_loss: 3.092905219340766, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [23:57<1:11:51, 143.72s/it]2025-03-03 10:37:12 - INFO - layer10_self_attn.q_proj | mse: 0.05166768718877478, bpp_loss: 3.409867589920759, bpp: 0
2025-03-03 10:37:27 - INFO - layer10_self_attn.k_proj | mse: 0.051781959526467594, bpp_loss: 3.429566440060735, bpp: 0
2025-03-03 10:37:42 - INFO - layer10_self_attn.v_proj | mse: 0.04693132202591996, bpp_loss: 2.8994451823458074, bpp: 0
2025-03-03 10:38:00 - INFO - layer10_self_attn.o_proj | mse: 0.04797437230559844, bpp_loss: 2.9022875075787304, bpp: 0
2025-03-03 10:38:17 - INFO - layer10_mlp.gate_proj | mse: 0.04964743243270994, bpp_loss: 3.18079255681347, bpp: 0
2025-03-03 10:38:34 - INFO - layer10_mlp.up_proj | mse: 0.0490355440801195, bpp_loss: 3.1059653762314055, bpp: 0
2025-03-03 10:39:19 - INFO - layer10_mlp.down_proj | mse: 0.047104185113927804, bpp_loss: 3.1012120655841295, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [26:21<1:09:29, 143.77s/it]2025-03-03 10:39:36 - INFO - layer11_self_attn.q_proj | mse: 0.05198239964424114, bpp_loss: 3.457668795287609, bpp: 0
2025-03-03 10:39:50 - INFO - layer11_self_attn.k_proj | mse: 0.05219153181677688, bpp_loss: 3.484321375787258, bpp: 0
2025-03-03 10:40:05 - INFO - layer11_self_attn.v_proj | mse: 0.046896661345091344, bpp_loss: 2.909573728516698, bpp: 0
2025-03-03 10:40:23 - INFO - layer11_self_attn.o_proj | mse: 0.04961464165337271, bpp_loss: 2.8998647663742303, bpp: 0
2025-03-03 10:40:40 - INFO - layer11_mlp.gate_proj | mse: 0.04927031525965598, bpp_loss: 3.1667039854658974, bpp: 0
2025-03-03 10:40:57 - INFO - layer11_mlp.up_proj | mse: 0.04885564348771794, bpp_loss: 3.1145363953378467, bpp: 0
2025-03-03 10:41:43 - INFO - layer11_mlp.down_proj | mse: 0.047260660778061125, bpp_loss: 3.107752461262323, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [28:45<1:07:05, 143.76s/it]2025-03-03 10:42:00 - INFO - layer12_self_attn.q_proj | mse: 0.051374156054469544, bpp_loss: 3.4051448138058187, bpp: 0
2025-03-03 10:42:13 - INFO - layer12_self_attn.k_proj | mse: 0.05149115022159728, bpp_loss: 3.4245731577277185, bpp: 0
2025-03-03 10:42:29 - INFO - layer12_self_attn.v_proj | mse: 0.04703064655100764, bpp_loss: 2.9316242261603476, bpp: 0
2025-03-03 10:42:46 - INFO - layer12_self_attn.o_proj | mse: 0.051032547919314525, bpp_loss: 2.9263022971525787, bpp: 0
2025-03-03 10:43:03 - INFO - layer12_mlp.gate_proj | mse: 0.04918132360557124, bpp_loss: 3.1610717888783526, bpp: 0
2025-03-03 10:43:20 - INFO - layer12_mlp.up_proj | mse: 0.048897131540785906, bpp_loss: 3.122624734485591, bpp: 0
2025-03-03 10:44:07 - INFO - layer12_mlp.down_proj | mse: 0.04718283222300103, bpp_loss: 3.115051946968392, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [31:08<1:04:40, 143.71s/it]2025-03-03 10:44:24 - INFO - layer13_self_attn.q_proj | mse: 0.0508975614954862, bpp_loss: 3.3564956295117736, bpp: 0
2025-03-03 10:44:37 - INFO - layer13_self_attn.k_proj | mse: 0.050776325130983055, bpp_loss: 3.353732511475682, bpp: 0
2025-03-03 10:44:53 - INFO - layer13_self_attn.v_proj | mse: 0.04720736151248061, bpp_loss: 2.9479929919913412, bpp: 0
2025-03-03 10:45:10 - INFO - layer13_self_attn.o_proj | mse: 0.04886582706875237, bpp_loss: 2.948861922211945, bpp: 0
2025-03-03 10:45:27 - INFO - layer13_mlp.gate_proj | mse: 0.04916260673629125, bpp_loss: 3.158224852879842, bpp: 0
2025-03-03 10:45:44 - INFO - layer13_mlp.up_proj | mse: 0.04900009904325583, bpp_loss: 3.13036745019533, bpp: 0
2025-03-03 10:46:31 - INFO - layer13_mlp.down_proj | mse: 0.04720663071954372, bpp_loss: 3.121975440780322, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [33:32<1:02:18, 143.80s/it]2025-03-03 10:46:47 - INFO - layer14_self_attn.q_proj | mse: 0.05129742938847779, bpp_loss: 3.393011376298964, bpp: 0
2025-03-03 10:47:01 - INFO - layer14_self_attn.k_proj | mse: 0.051376863051046516, bpp_loss: 3.4158850314468143, bpp: 0
2025-03-03 10:47:18 - INFO - layer14_self_attn.v_proj | mse: 0.04711596885818488, bpp_loss: 2.9384476181492207, bpp: 0
2025-03-03 10:47:34 - INFO - layer14_self_attn.o_proj | mse: 0.04848190449806346, bpp_loss: 2.9366824055835603, bpp: 0
2025-03-03 10:47:51 - INFO - layer14_mlp.gate_proj | mse: 0.04908677237657857, bpp_loss: 3.1546983864572313, bpp: 0
2025-03-03 10:48:08 - INFO - layer14_mlp.up_proj | mse: 0.04900195040367478, bpp_loss: 3.1357074241947243, bpp: 0
2025-03-03 10:48:55 - INFO - layer14_mlp.down_proj | mse: 0.0471279836104705, bpp_loss: 3.1261082454136124, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [35:57<59:56, 143.87s/it]  2025-03-03 10:49:11 - INFO - layer15_self_attn.q_proj | mse: 0.05098520143671906, bpp_loss: 3.375181103274226, bpp: 0
2025-03-03 10:49:26 - INFO - layer15_self_attn.k_proj | mse: 0.051217035298356424, bpp_loss: 3.4106194015592335, bpp: 0
2025-03-03 10:49:43 - INFO - layer15_self_attn.v_proj | mse: 0.04731828533248986, bpp_loss: 2.970796878449619, bpp: 0
2025-03-03 10:49:58 - INFO - layer15_self_attn.o_proj | mse: 0.05188784017477181, bpp_loss: 2.9687409737333654, bpp: 0
2025-03-03 10:50:15 - INFO - layer15_mlp.gate_proj | mse: 0.04908349266687496, bpp_loss: 3.1557435678663075, bpp: 0
2025-03-03 10:50:32 - INFO - layer15_mlp.up_proj | mse: 0.04906673703103581, bpp_loss: 3.142808555232154, bpp: 0
2025-03-03 10:51:19 - INFO - layer15_mlp.down_proj | mse: 0.04713988835239294, bpp_loss: 3.1326173913837585, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [38:21<57:36, 144.03s/it]2025-03-03 10:51:36 - INFO - layer16_self_attn.q_proj | mse: 0.05086393911471449, bpp_loss: 3.3634429816156626, bpp: 0
2025-03-03 10:51:50 - INFO - layer16_self_attn.k_proj | mse: 0.050974080501466575, bpp_loss: 3.3891024708747866, bpp: 0
2025-03-03 10:52:07 - INFO - layer16_self_attn.v_proj | mse: 0.047395082454556904, bpp_loss: 2.9753203190490605, bpp: 0
2025-03-03 10:52:22 - INFO - layer16_self_attn.o_proj | mse: 0.048834062503439656, bpp_loss: 2.972856582291424, bpp: 0
2025-03-03 10:52:39 - INFO - layer16_mlp.gate_proj | mse: 0.04916385379508976, bpp_loss: 3.1596342011182394, bpp: 0
2025-03-03 10:52:57 - INFO - layer16_mlp.up_proj | mse: 0.049109208447649745, bpp_loss: 3.1426093885192166, bpp: 0
2025-03-03 10:53:44 - INFO - layer16_mlp.down_proj | mse: 0.04727924030606376, bpp_loss: 3.13255391402377, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [40:46<55:18, 144.30s/it]2025-03-03 10:54:01 - INFO - layer17_self_attn.q_proj | mse: 0.05079080570856257, bpp_loss: 3.354221472106874, bpp: 0
2025-03-03 10:54:15 - INFO - layer17_self_attn.k_proj | mse: 0.05091176024876456, bpp_loss: 3.3811832601577043, bpp: 0
2025-03-03 10:54:33 - INFO - layer17_self_attn.v_proj | mse: 0.04749382108175532, bpp_loss: 2.9852797450497746, bpp: 0
2025-03-03 10:54:48 - INFO - layer17_self_attn.o_proj | mse: 0.04844940570628192, bpp_loss: 2.9870747837051748, bpp: 0
2025-03-03 10:55:05 - INFO - layer17_mlp.gate_proj | mse: 0.04910414879499143, bpp_loss: 3.1703971144225864, bpp: 0
2025-03-03 10:55:22 - INFO - layer17_mlp.up_proj | mse: 0.0489011473997362, bpp_loss: 3.1380186395512686, bpp: 0
2025-03-03 10:56:09 - INFO - layer17_mlp.down_proj | mse: 0.046897327175604034, bpp_loss: 3.129815574335279, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [43:11<53:02, 144.64s/it]2025-03-03 10:56:26 - INFO - layer18_self_attn.q_proj | mse: 0.05067690419231867, bpp_loss: 3.3664048409834506, bpp: 0
2025-03-03 10:56:40 - INFO - layer18_self_attn.k_proj | mse: 0.0508350335827728, bpp_loss: 3.3937910135835407, bpp: 0
2025-03-03 10:56:58 - INFO - layer18_self_attn.v_proj | mse: 0.04756253800445086, bpp_loss: 3.018086880221963, bpp: 0
2025-03-03 10:57:13 - INFO - layer18_self_attn.o_proj | mse: 0.04852537589651792, bpp_loss: 3.011535652987659, bpp: 0
2025-03-03 10:57:30 - INFO - layer18_mlp.gate_proj | mse: 0.04913355630930192, bpp_loss: 3.177041883049188, bpp: 0
2025-03-03 10:57:47 - INFO - layer18_mlp.up_proj | mse: 0.048791301846095585, bpp_loss: 3.1324300806279535, bpp: 0
2025-03-03 10:58:34 - INFO - layer18_mlp.down_proj | mse: 0.04653162031587398, bpp_loss: 3.126708839668168, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [45:36<50:38, 144.69s/it]2025-03-03 10:58:50 - INFO - layer19_self_attn.q_proj | mse: 0.05024951763960425, bpp_loss: 3.3235817494243385, bpp: 0
2025-03-03 10:59:05 - INFO - layer19_self_attn.k_proj | mse: 0.050329689236856275, bpp_loss: 3.344417589008808, bpp: 0
2025-03-03 10:59:24 - INFO - layer19_self_attn.v_proj | mse: 0.04759858555749836, bpp_loss: 3.0158416622132065, bpp: 0
2025-03-03 10:59:37 - INFO - layer19_self_attn.o_proj | mse: 0.047476032776851626, bpp_loss: 3.012743878774345, bpp: 0
2025-03-03 10:59:54 - INFO - layer19_mlp.gate_proj | mse: 0.049207017411741646, bpp_loss: 3.183738247498318, bpp: 0
2025-03-03 11:00:11 - INFO - layer19_mlp.up_proj | mse: 0.048764174196989446, bpp_loss: 3.1314627838355524, bpp: 0
2025-03-03 11:01:05 - INFO - layer19_mlp.down_proj | mse: 0.046452248044856245, bpp_loss: 3.1255942445386338, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [48:07<48:49, 146.47s/it]2025-03-03 11:01:20 - INFO - layer20_self_attn.q_proj | mse: 0.0506176988397874, bpp_loss: 3.345816651061177, bpp: 0
2025-03-03 11:01:35 - INFO - layer20_self_attn.k_proj | mse: 0.05072495523566704, bpp_loss: 3.3704078292846678, bpp: 0
2025-03-03 11:01:54 - INFO - layer20_self_attn.v_proj | mse: 0.04765456847163869, bpp_loss: 3.014986163601279, bpp: 0
2025-03-03 11:02:07 - INFO - layer20_self_attn.o_proj | mse: 0.04849880653970429, bpp_loss: 3.0160170497372745, bpp: 0
2025-03-03 11:02:25 - INFO - layer20_mlp.gate_proj | mse: 0.04933541502512942, bpp_loss: 3.18668286965953, bpp: 0
2025-03-03 11:02:42 - INFO - layer20_mlp.up_proj | mse: 0.04884969386358227, bpp_loss: 3.1309973260870687, bpp: 0
2025-03-03 11:03:31 - INFO - layer20_mlp.down_proj | mse: 0.04636080622238322, bpp_loss: 3.1244460173503117, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [50:33<46:21, 146.39s/it]2025-03-03 11:03:45 - INFO - layer21_self_attn.q_proj | mse: 0.050411792813857076, bpp_loss: 3.3147170061618088, bpp: 0
2025-03-03 11:04:01 - INFO - layer21_self_attn.k_proj | mse: 0.050445411486414286, bpp_loss: 3.3315671110153198, bpp: 0
2025-03-03 11:04:18 - INFO - layer21_self_attn.v_proj | mse: 0.04809023917552151, bpp_loss: 3.0418038968741894, bpp: 0
2025-03-03 11:04:32 - INFO - layer21_self_attn.o_proj | mse: 0.0478158720936954, bpp_loss: 3.0422676436230542, bpp: 0
2025-03-03 11:04:49 - INFO - layer21_mlp.gate_proj | mse: 0.04993352530077408, bpp_loss: 3.1951497528288098, bpp: 0
2025-03-03 11:05:06 - INFO - layer21_mlp.up_proj | mse: 0.0493173409130275, bpp_loss: 3.125572993744303, bpp: 0
2025-03-03 11:05:56 - INFO - layer21_mlp.down_proj | mse: 0.04654093205447968, bpp_loss: 3.123600775969249, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [52:58<43:48, 146.04s/it]2025-03-03 11:06:11 - INFO - layer22_self_attn.q_proj | mse: 0.05065449916037616, bpp_loss: 3.3130225144699215, bpp: 0
2025-03-03 11:06:27 - INFO - layer22_self_attn.k_proj | mse: 0.05081836515864477, bpp_loss: 3.3371283004060386, bpp: 0
2025-03-03 11:06:44 - INFO - layer22_self_attn.v_proj | mse: 0.048863987794365835, bpp_loss: 3.097067749686539, bpp: 0
2025-03-03 11:06:59 - INFO - layer22_self_attn.o_proj | mse: 0.04728554179855205, bpp_loss: 3.0885208558291195, bpp: 0
2025-03-03 11:07:16 - INFO - layer22_mlp.gate_proj | mse: 0.04981351649260807, bpp_loss: 3.203483641092424, bpp: 0
2025-03-03 11:07:33 - INFO - layer22_mlp.up_proj | mse: 0.04907717496811594, bpp_loss: 3.1217866550993034, bpp: 0
2025-03-03 11:08:23 - INFO - layer22_mlp.down_proj | mse: 0.046121760982294986, bpp_loss: 3.1214789410984074, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [55:25<41:25, 146.18s/it]2025-03-03 11:08:37 - INFO - layer23_self_attn.q_proj | mse: 0.05021376674371587, bpp_loss: 3.287254955135286, bpp: 0
2025-03-03 11:08:55 - INFO - layer23_self_attn.k_proj | mse: 0.050275122860650744, bpp_loss: 3.3015479777008294, bpp: 0
2025-03-03 11:09:11 - INFO - layer23_self_attn.v_proj | mse: 0.048610709328338636, bpp_loss: 3.0906243166700005, bpp: 0
2025-03-03 11:09:25 - INFO - layer23_self_attn.o_proj | mse: 0.046023369416504485, bpp_loss: 3.0884732876718046, bpp: 0
2025-03-03 11:09:42 - INFO - layer23_mlp.gate_proj | mse: 0.04976662268686282, bpp_loss: 3.210791470386364, bpp: 0
2025-03-03 11:09:59 - INFO - layer23_mlp.up_proj | mse: 0.04890516875233761, bpp_loss: 3.1185057126813467, bpp: 0
2025-03-03 11:10:49 - INFO - layer23_mlp.down_proj | mse: 0.04583759638576512, bpp_loss: 3.1196392575761784, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [57:51<39:01, 146.32s/it]2025-03-03 11:11:05 - INFO - layer24_self_attn.q_proj | mse: 0.05013995102609797, bpp_loss: 3.3003092815354464, bpp: 0
2025-03-03 11:11:23 - INFO - layer24_self_attn.k_proj | mse: 0.050197954917134795, bpp_loss: 3.3156275185197592, bpp: 0
2025-03-03 11:11:37 - INFO - layer24_self_attn.v_proj | mse: 0.048523021180317406, bpp_loss: 3.1001972350478173, bpp: 0
2025-03-03 11:11:51 - INFO - layer24_self_attn.o_proj | mse: 0.04596754224737269, bpp_loss: 3.096785484366119, bpp: 0
2025-03-03 11:12:09 - INFO - layer24_mlp.gate_proj | mse: 0.04967405466591536, bpp_loss: 3.2167217067546314, bpp: 0
2025-03-03 11:12:26 - INFO - layer24_mlp.up_proj | mse: 0.04873874408607159, bpp_loss: 3.1178433890695927, bpp: 0
2025-03-03 11:13:16 - INFO - layer24_mlp.down_proj | mse: 0.04560678063501691, bpp_loss: 3.120496160219665, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [1:00:18<36:37, 146.52s/it]2025-03-03 11:13:32 - INFO - layer25_self_attn.q_proj | mse: 0.04981898281278868, bpp_loss: 3.290532193519175, bpp: 0
2025-03-03 11:13:50 - INFO - layer25_self_attn.k_proj | mse: 0.04985724046167162, bpp_loss: 3.3024314837157727, bpp: 0
2025-03-03 11:14:04 - INFO - layer25_self_attn.v_proj | mse: 0.04856105633633101, bpp_loss: 3.124299558997154, bpp: 0
2025-03-03 11:14:18 - INFO - layer25_self_attn.o_proj | mse: 0.04580617558566966, bpp_loss: 3.1243128660321235, bpp: 0
2025-03-03 11:14:35 - INFO - layer25_mlp.gate_proj | mse: 0.049545371382670664, bpp_loss: 3.2206737144125834, bpp: 0
2025-03-03 11:14:53 - INFO - layer25_mlp.up_proj | mse: 0.04857289625317053, bpp_loss: 3.116890905852671, bpp: 0
2025-03-03 11:15:43 - INFO - layer25_mlp.down_proj | mse: 0.045420999089118355, bpp_loss: 3.120123472602831, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [1:02:45<34:11, 146.55s/it]2025-03-03 11:15:59 - INFO - layer26_self_attn.q_proj | mse: 0.04974148112996873, bpp_loss: 3.3008191055059433, bpp: 0
2025-03-03 11:16:17 - INFO - layer26_self_attn.k_proj | mse: 0.0497974492112511, bpp_loss: 3.3130246403440835, bpp: 0
2025-03-03 11:16:31 - INFO - layer26_self_attn.v_proj | mse: 0.04854986494500323, bpp_loss: 3.141969653852284, bpp: 0
2025-03-03 11:16:45 - INFO - layer26_self_attn.o_proj | mse: 0.04626224146924195, bpp_loss: 3.1174534038454293, bpp: 0
2025-03-03 11:17:02 - INFO - layer26_mlp.gate_proj | mse: 0.049476200821735976, bpp_loss: 3.2240729446212453, bpp: 0
2025-03-03 11:17:19 - INFO - layer26_mlp.up_proj | mse: 0.048479114135331125, bpp_loss: 3.1179610101713076, bpp: 0
2025-03-03 11:18:09 - INFO - layer26_mlp.down_proj | mse: 0.04531717732390319, bpp_loss: 3.121059996041435, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [1:05:11<31:43, 146.44s/it]2025-03-03 11:18:25 - INFO - layer27_self_attn.q_proj | mse: 0.049587512356171246, bpp_loss: 3.3018717267364264, bpp: 0
2025-03-03 11:18:43 - INFO - layer27_self_attn.k_proj | mse: 0.049651445682175964, bpp_loss: 3.311542696468532, bpp: 0
2025-03-03 11:18:57 - INFO - layer27_self_attn.v_proj | mse: 0.048336408994373324, bpp_loss: 3.1373228092864154, bpp: 0
2025-03-03 11:19:12 - INFO - layer27_self_attn.o_proj | mse: 0.045904217068544154, bpp_loss: 3.130477307699621, bpp: 0
2025-03-03 11:19:29 - INFO - layer27_mlp.gate_proj | mse: 0.049268062862707115, bpp_loss: 3.2275810290265965, bpp: 0
2025-03-03 11:19:46 - INFO - layer27_mlp.up_proj | mse: 0.04825615979929957, bpp_loss: 3.118640469621729, bpp: 0
2025-03-03 11:20:36 - INFO - layer27_mlp.down_proj | mse: 0.0451393038887556, bpp_loss: 3.122008401265851, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [1:07:38<29:17, 146.46s/it]2025-03-03 11:20:52 - INFO - layer28_self_attn.q_proj | mse: 0.04927258853247901, bpp_loss: 3.295353997461498, bpp: 0
2025-03-03 11:21:10 - INFO - layer28_self_attn.k_proj | mse: 0.04928876376408, bpp_loss: 3.304265806637704, bpp: 0
2025-03-03 11:21:24 - INFO - layer28_self_attn.v_proj | mse: 0.048143522509513856, bpp_loss: 3.144562836959958, bpp: 0
2025-03-03 11:21:38 - INFO - layer28_self_attn.o_proj | mse: 0.04604750247639885, bpp_loss: 3.1380204167962074, bpp: 0
2025-03-03 11:21:56 - INFO - layer28_mlp.gate_proj | mse: 0.04899475921439167, bpp_loss: 3.228748312758075, bpp: 0
2025-03-03 11:22:13 - INFO - layer28_mlp.up_proj | mse: 0.04798976167041031, bpp_loss: 3.121386563501976, bpp: 0
2025-03-03 11:23:03 - INFO - layer28_mlp.down_proj | mse: 0.044910240612706626, bpp_loss: 3.1238335059334834, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [1:10:05<26:54, 146.75s/it]2025-03-03 11:23:21 - INFO - layer29_self_attn.q_proj | mse: 0.049196707339390744, bpp_loss: 3.317069919258356, bpp: 0
2025-03-03 11:23:37 - INFO - layer29_self_attn.k_proj | mse: 0.04930539510606313, bpp_loss: 3.3330928603187204, bpp: 0
2025-03-03 11:23:51 - INFO - layer29_self_attn.v_proj | mse: 0.0479259022340128, bpp_loss: 3.1483732166513803, bpp: 0
2025-03-03 11:24:06 - INFO - layer29_self_attn.o_proj | mse: 0.04590490308822462, bpp_loss: 3.143479398973286, bpp: 0
2025-03-03 11:24:23 - INFO - layer29_mlp.gate_proj | mse: 0.04881832511583094, bpp_loss: 3.2273824346838174, bpp: 0
2025-03-03 11:24:41 - INFO - layer29_mlp.up_proj | mse: 0.04786162225862399, bpp_loss: 3.1250026875072057, bpp: 0
2025-03-03 11:25:30 - INFO - layer29_mlp.down_proj | mse: 0.044801079018627316, bpp_loss: 3.127699041104427, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [1:12:32<24:28, 146.89s/it]2025-03-03 11:25:48 - INFO - layer30_self_attn.q_proj | mse: 0.04889390566886303, bpp_loss: 3.297605510018766, bpp: 0
2025-03-03 11:26:04 - INFO - layer30_self_attn.k_proj | mse: 0.04895717893268872, bpp_loss: 3.3050403647124766, bpp: 0
2025-03-03 11:26:18 - INFO - layer30_self_attn.v_proj | mse: 0.0482151652134412, bpp_loss: 3.1934108962491154, bpp: 0
2025-03-03 11:26:32 - INFO - layer30_self_attn.o_proj | mse: 0.045759670867763204, bpp_loss: 3.191042154505849, bpp: 0
2025-03-03 11:26:50 - INFO - layer30_mlp.gate_proj | mse: 0.048588179590516284, bpp_loss: 3.2287507400468543, bpp: 0
2025-03-03 11:27:08 - INFO - layer30_mlp.up_proj | mse: 0.04764215089738654, bpp_loss: 3.1263067857534796, bpp: 0
2025-03-03 11:27:57 - INFO - layer30_mlp.down_proj | mse: 0.04470075670915954, bpp_loss: 3.128394796975233, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [1:14:59<22:02, 146.91s/it]2025-03-03 11:28:15 - INFO - layer31_self_attn.q_proj | mse: 0.04884463462294778, bpp_loss: 3.311491140164435, bpp: 0
2025-03-03 11:28:31 - INFO - layer31_self_attn.k_proj | mse: 0.04899175803279859, bpp_loss: 3.3331414204463363, bpp: 0
2025-03-03 11:28:45 - INFO - layer31_self_attn.v_proj | mse: 0.0477616987882257, bpp_loss: 3.1612175020948055, bpp: 0
2025-03-03 11:29:00 - INFO - layer31_self_attn.o_proj | mse: 0.04624368185572454, bpp_loss: 3.1513605577126147, bpp: 0
2025-03-03 11:29:17 - INFO - layer31_mlp.gate_proj | mse: 0.04845337088630087, bpp_loss: 3.2290752868961405, bpp: 0
2025-03-03 11:29:35 - INFO - layer31_mlp.up_proj | mse: 0.047523323224205924, bpp_loss: 3.129261819024881, bpp: 0
2025-03-03 11:30:24 - INFO - layer31_mlp.down_proj | mse: 0.044588820821277346, bpp_loss: 3.1309481485160413, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:17:26<19:34, 146.85s/it]2025-03-03 11:30:41 - INFO - layer32_self_attn.q_proj | mse: 0.0483847937770257, bpp_loss: 3.2780431823059915, bpp: 0
2025-03-03 11:30:57 - INFO - layer32_self_attn.k_proj | mse: 0.0484030196512391, bpp_loss: 3.285941450893879, bpp: 0
2025-03-03 11:31:12 - INFO - layer32_self_attn.v_proj | mse: 0.047992453559446764, bpp_loss: 3.19624887637794, bpp: 0
2025-03-03 11:31:26 - INFO - layer32_self_attn.o_proj | mse: 0.046564894811190104, bpp_loss: 3.194543825387955, bpp: 0
2025-03-03 11:31:43 - INFO - layer32_mlp.gate_proj | mse: 0.048255868635791545, bpp_loss: 3.226053609505848, bpp: 0
2025-03-03 11:32:01 - INFO - layer32_mlp.up_proj | mse: 0.0473834548673322, bpp_loss: 3.133750396580608, bpp: 0
2025-03-03 11:32:50 - INFO - layer32_mlp.down_proj | mse: 0.044618255803843314, bpp_loss: 3.1353353679042173, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:19:52<17:05, 146.54s/it]2025-03-03 11:33:07 - INFO - layer33_self_attn.q_proj | mse: 0.048318019958722404, bpp_loss: 3.2819386119022966, bpp: 0
2025-03-03 11:33:23 - INFO - layer33_self_attn.k_proj | mse: 0.0484179452145573, bpp_loss: 3.296803253777325, bpp: 0
2025-03-03 11:33:37 - INFO - layer33_self_attn.v_proj | mse: 0.04766562265903038, bpp_loss: 3.1773882642388345, bpp: 0
2025-03-03 11:33:51 - INFO - layer33_self_attn.o_proj | mse: 0.046292989983784685, bpp_loss: 3.174197775386274, bpp: 0
2025-03-03 11:34:08 - INFO - layer33_mlp.gate_proj | mse: 0.04813779359281092, bpp_loss: 3.224079809917344, bpp: 0
2025-03-03 11:34:27 - INFO - layer33_mlp.up_proj | mse: 0.04733210021689796, bpp_loss: 3.1384516527255375, bpp: 0
2025-03-03 11:35:15 - INFO - layer33_mlp.down_proj | mse: 0.04462389778351768, bpp_loss: 3.1395133496020677, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:22:17<14:36, 146.10s/it]2025-03-03 11:35:33 - INFO - layer34_self_attn.q_proj | mse: 0.047895650620211595, bpp_loss: 3.244484128989279, bpp: 0
2025-03-03 11:35:48 - INFO - layer34_self_attn.k_proj | mse: 0.0479644454154114, bpp_loss: 3.2571815290302037, bpp: 0
2025-03-03 11:36:02 - INFO - layer34_self_attn.v_proj | mse: 0.0478829833595172, bpp_loss: 3.201453877314925, bpp: 0
2025-03-03 11:36:15 - INFO - layer34_self_attn.o_proj | mse: 0.04657103190616939, bpp_loss: 3.211033005565405, bpp: 0
2025-03-03 11:36:32 - INFO - layer34_mlp.gate_proj | mse: 0.04804068232240805, bpp_loss: 3.2186022507371725, bpp: 0
2025-03-03 11:36:51 - INFO - layer34_mlp.up_proj | mse: 0.047380922294177494, bpp_loss: 3.1463192787987215, bpp: 0
2025-03-03 11:37:39 - INFO - layer34_mlp.down_proj | mse: 0.044772358210703675, bpp_loss: 3.147614663163269, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:24:41<12:07, 145.48s/it]2025-03-03 11:37:57 - INFO - layer35_self_attn.q_proj | mse: 0.047833233953932866, bpp_loss: 3.2370262802764773, bpp: 0
2025-03-03 11:38:11 - INFO - layer35_self_attn.k_proj | mse: 0.04791193339003277, bpp_loss: 3.251045404151082, bpp: 0
2025-03-03 11:38:25 - INFO - layer35_self_attn.v_proj | mse: 0.04790803605660484, bpp_loss: 3.202038801573217, bpp: 0
2025-03-03 11:38:39 - INFO - layer35_self_attn.o_proj | mse: 0.047237765163075866, bpp_loss: 3.205845262296498, bpp: 0
2025-03-03 11:38:56 - INFO - layer35_mlp.gate_proj | mse: 0.04793879157555271, bpp_loss: 3.2126003790784767, bpp: 0
2025-03-03 11:39:15 - INFO - layer35_mlp.up_proj | mse: 0.04742358049492865, bpp_loss: 3.1550594642206473, bpp: 0
2025-03-03 11:40:03 - INFO - layer35_mlp.down_proj | mse: 0.04498876686145577, bpp_loss: 3.15559150148873, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:27:05<09:40, 145.09s/it]2025-03-03 11:40:22 - INFO - layer36_self_attn.q_proj | mse: 0.047888338021239304, bpp_loss: 3.239103409945965, bpp: 0
2025-03-03 11:40:35 - INFO - layer36_self_attn.k_proj | mse: 0.04802122930388135, bpp_loss: 3.258386971950531, bpp: 0
2025-03-03 11:40:49 - INFO - layer36_self_attn.v_proj | mse: 0.04816474832924885, bpp_loss: 3.222530697286129, bpp: 0
2025-03-03 11:41:03 - INFO - layer36_self_attn.o_proj | mse: 0.04789322915615028, bpp_loss: 3.2268657667189835, bpp: 0
2025-03-03 11:41:20 - INFO - layer36_mlp.gate_proj | mse: 0.04798087843659001, bpp_loss: 3.208075758483675, bpp: 0
2025-03-03 11:41:40 - INFO - layer36_mlp.up_proj | mse: 0.04754593509211214, bpp_loss: 3.1602864098769645, bpp: 0
2025-03-03 11:42:27 - INFO - layer36_mlp.down_proj | mse: 0.045298084139523194, bpp_loss: 3.1558984061496127, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:29:29<07:14, 144.84s/it]2025-03-03 11:42:46 - INFO - layer37_self_attn.q_proj | mse: 0.047459457058085824, bpp_loss: 3.1776914263144134, bpp: 0
2025-03-03 11:42:59 - INFO - layer37_self_attn.k_proj | mse: 0.04743013249790687, bpp_loss: 3.176215841807425, bpp: 0
2025-03-03 11:43:10 - INFO - layer37_self_attn.v_proj | mse: 0.04855347303770102, bpp_loss: 3.2456871155649423, bpp: 0
2025-03-03 11:43:22 - INFO - layer37_self_attn.o_proj | mse: 0.04937227275437213, bpp_loss: 3.247680400758982, bpp: 0
2025-03-03 11:43:37 - INFO - layer37_mlp.gate_proj | mse: 0.04812303764597027, bpp_loss: 3.211440030954502, bpp: 0
2025-03-03 11:43:52 - INFO - layer37_mlp.up_proj | mse: 0.04772094084138823, bpp_loss: 3.1679705765512254, bpp: 0
2025-03-03 11:44:43 - INFO - layer37_mlp.down_proj | mse: 0.045769722326488814, bpp_loss: 3.1553224386440384, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:31:45<04:44, 142.16s/it]2025-03-03 11:45:02 - INFO - layer38_self_attn.q_proj | mse: 0.047420709924890336, bpp_loss: 3.1542860076949, bpp: 0
2025-03-03 11:45:20 - INFO - layer38_self_attn.k_proj | mse: 0.04741937867588879, bpp_loss: 3.1607552268728614, bpp: 0
2025-03-03 11:45:39 - INFO - layer38_self_attn.v_proj | mse: 0.04922246830544578, bpp_loss: 3.2949449425935744, bpp: 0
2025-03-03 11:45:57 - INFO - layer38_self_attn.o_proj | mse: 0.050545206954742065, bpp_loss: 3.3064011785760523, bpp: 0
2025-03-03 11:46:20 - INFO - layer38_mlp.gate_proj | mse: 0.048783116305964325, bpp_loss: 3.2416414368483757, bpp: 0
2025-03-03 11:46:43 - INFO - layer38_mlp.up_proj | mse: 0.04809528921429041, bpp_loss: 3.1713735065526434, bpp: 0
2025-03-03 11:47:43 - INFO - layer38_mlp.down_proj | mse: 0.04673066628234094, bpp_loss: 3.1376785152350313, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:34:45<02:33, 153.39s/it]2025-03-03 11:48:02 - INFO - layer39_self_attn.q_proj | mse: 0.04800093424598309, bpp_loss: 3.152437195293605, bpp: 0
2025-03-03 11:48:18 - INFO - layer39_self_attn.k_proj | mse: 0.048065902163830256, bpp_loss: 3.163028220012784, bpp: 0
2025-03-03 11:48:29 - INFO - layer39_self_attn.v_proj | mse: 0.04884063345951416, bpp_loss: 3.1872395078092812, bpp: 0
2025-03-03 11:48:41 - INFO - layer39_self_attn.o_proj | mse: 0.05747828871516051, bpp_loss: 3.189158391728997, bpp: 0
2025-03-03 11:48:56 - INFO - layer39_mlp.gate_proj | mse: 0.05017862454436879, bpp_loss: 3.312375796889817, bpp: 0
2025-03-03 11:49:11 - INFO - layer39_mlp.up_proj | mse: 0.049186240423301095, bpp_loss: 3.2144262545638616, bpp: 0
2025-03-03 11:49:51 - INFO - layer39_mlp.down_proj | mse: 0.05011784828230697, bpp_loss: 3.1234779294856168, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:36:53<00:00, 145.89s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:36:53<00:00, 145.34s/it]
2025-03-03 11:49:51 - INFO - #### Total | mse: 0.04942213794972004, bpp_loss: 3.1514794174813443, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda100_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_4.39201_bpp_5.10767_MSE_0.0081_total_iter_190000.pth.tar/COL_MSE0.04942_bpploss3.1515_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda100_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_4.39201_bpp_5.10767_MSE_0.0081_total_iter_190000.pth.tar/COL_MSE0.04942_bpploss3.1515_bpp0
I0303 11:50:43.080517 3192449 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.19it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.14it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.17it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.18it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.52it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.57it/s]
W0303 11:50:47.093055 3192449 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 11:50:47.108209 3192449 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.3046875:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.3046875:   1%|          | 1/166 [00:01<04:10,  1.52s/it]avg_loss = 1.5859375:   1%|          | 1/166 [00:02<04:10,  1.52s/it]avg_loss = 1.5859375:   1%|          | 2/166 [00:02<03:38,  1.33s/it]avg_loss = 1.75:   1%|          | 2/166 [00:04<03:38,  1.33s/it]     avg_loss = 1.75:   2%|▏         | 3/166 [00:04<03:35,  1.32s/it]avg_loss = 1.779296875:   2%|▏         | 3/166 [00:05<03:35,  1.32s/it]avg_loss = 1.779296875:   2%|▏         | 4/166 [00:05<03:33,  1.32s/it]avg_loss = 1.709375:   2%|▏         | 4/166 [00:06<03:33,  1.32s/it]   avg_loss = 1.709375:   3%|▎         | 5/166 [00:06<03:30,  1.31s/it]avg_loss = 1.6796875:   3%|▎         | 5/166 [00:07<03:30,  1.31s/it]avg_loss = 1.6796875:   4%|▎         | 6/166 [00:07<03:31,  1.32s/it]avg_loss = 1.6171875:   4%|▎         | 6/166 [00:09<03:31,  1.32s/it]avg_loss = 1.6171875:   4%|▍         | 7/166 [00:09<03:25,  1.29s/it]avg_loss = 1.5546875:   4%|▍         | 7/166 [00:10<03:25,  1.29s/it]avg_loss = 1.5546875:   5%|▍         | 8/166 [00:10<03:18,  1.26s/it]avg_loss = 1.5546875:   5%|▍         | 8/166 [00:11<03:44,  1.42s/it]
Traceback (most recent call last):
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 115, in <module>
    main(args)
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 91, in main
    output = model(input,
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1163, in forward
    outputs = self.model(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 913, in forward
    layer_outputs = decoder_layer(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 656, in forward
    hidden_states = self.mlp(hidden_states)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 242, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 160, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 293, in pre_forward
    set_module_tensor_to_device(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 347, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 120.19 MiB is free. Process 3192335 has 2.22 GiB memory in use. Including non-PyTorch memory, this process has 21.22 GiB memory in use. Of the allocated memory 20.76 GiB is allocated by PyTorch, and 226.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running with lmbda=200
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  9.08it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00,  9.95it/s]Loading checkpoint shards:  36%|███▋      | 4/11 [00:00<00:00,  9.60it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00,  9.59it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00,  9.95it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00,  9.81it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.13it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.93it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:01<00:49,  1.28s/it]calculating model weight mean & std:   5%|▌         | 2/40 [00:02<00:50,  1.33s/it]calculating model weight mean & std:   8%|▊         | 3/40 [00:03<00:37,  1.02s/it]calculating model weight mean & std:  10%|█         | 4/40 [00:03<00:32,  1.12it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:04<00:27,  1.28it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:05<00:31,  1.07it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:06<00:32,  1.03it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:08<00:33,  1.06s/it]calculating model weight mean & std:  22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]calculating model weight mean & std:  25%|██▌       | 10/40 [00:10<00:30,  1.02s/it]calculating model weight mean & std:  28%|██▊       | 11/40 [00:11<00:29,  1.00s/it]calculating model weight mean & std:  30%|███       | 12/40 [00:11<00:24,  1.13it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:12<00:21,  1.26it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:12<00:18,  1.38it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:13<00:16,  1.48it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:13<00:15,  1.58it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:15<00:18,  1.25it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:16<00:19,  1.10it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:17<00:19,  1.07it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:18<00:18,  1.11it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:18<00:15,  1.19it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:19<00:13,  1.31it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:20<00:12,  1.33it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:20<00:12,  1.32it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:21<00:10,  1.40it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:22<00:09,  1.42it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:22<00:09,  1.38it/s]calculating model weight mean & std:  70%|███████   | 28/40 [00:23<00:08,  1.48it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:24<00:07,  1.49it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:24<00:06,  1.53it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:25<00:06,  1.47it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:26<00:05,  1.58it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:26<00:04,  1.66it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:27<00:03,  1.74it/s]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:27<00:02,  1.79it/s]calculating model weight mean & std:  90%|█████████ | 36/40 [00:28<00:02,  1.83it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:28<00:01,  1.73it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:29<00:01,  1.53it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:30<00:00,  1.35it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:31<00:00,  1.32it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:31<00:00,  1.27it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 11:53:06 - INFO - layer0_self_attn.q_proj | mse: 0.19865695608865197, bpp_loss: 3.182453899048269, bpp: 0
2025-03-03 11:53:20 - INFO - layer0_self_attn.k_proj | mse: 0.12759310444303673, bpp_loss: 3.2382317396998404, bpp: 0
2025-03-03 11:53:38 - INFO - layer0_self_attn.v_proj | mse: 0.050817931297549565, bpp_loss: 3.0994365099817514, bpp: 0
2025-03-03 11:53:52 - INFO - layer0_self_attn.o_proj | mse: 0.05587607306447227, bpp_loss: 3.0195041493326427, bpp: 0
2025-03-03 11:54:09 - INFO - layer0_mlp.gate_proj | mse: 0.03281536891952492, bpp_loss: 3.4208691749307842, bpp: 0
2025-03-03 11:54:26 - INFO - layer0_mlp.up_proj | mse: 0.03275986656251411, bpp_loss: 3.3945601730434984, bpp: 0
2025-03-03 11:55:12 - INFO - layer0_mlp.down_proj | mse: 0.05641270993373118, bpp_loss: 3.512268405186909, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [02:22<1:32:19, 142.04s/it]2025-03-03 11:55:28 - INFO - layer1_self_attn.q_proj | mse: 0.049321544380162695, bpp_loss: 3.6373312410712244, bpp: 0
2025-03-03 11:55:43 - INFO - layer1_self_attn.k_proj | mse: 0.0495853022603358, bpp_loss: 3.671955466233194, bpp: 0
2025-03-03 11:56:01 - INFO - layer1_self_attn.v_proj | mse: 0.04702783572442498, bpp_loss: 3.1694824687764047, bpp: 0
2025-03-03 11:56:14 - INFO - layer1_self_attn.o_proj | mse: 0.12853371529745677, bpp_loss: 3.1608880999311806, bpp: 0
2025-03-03 11:56:31 - INFO - layer1_mlp.gate_proj | mse: 0.03777081251022263, bpp_loss: 3.598952614046909, bpp: 0
2025-03-03 11:56:48 - INFO - layer1_mlp.up_proj | mse: 0.03757062661115349, bpp_loss: 3.5336166283046757, bpp: 0
2025-03-03 11:57:34 - INFO - layer1_mlp.down_proj | mse: 0.02768752357017005, bpp_loss: 3.563676953660669, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [04:44<1:29:56, 142.02s/it]2025-03-03 11:57:50 - INFO - layer2_self_attn.q_proj | mse: 0.03269236428607564, bpp_loss: 3.9741000212728976, bpp: 0
2025-03-03 11:58:05 - INFO - layer2_self_attn.k_proj | mse: 0.032804841847955776, bpp_loss: 4.015166814252734, bpp: 0
2025-03-03 11:58:23 - INFO - layer2_self_attn.v_proj | mse: 0.030973647660786703, bpp_loss: 3.2993804119899868, bpp: 0
2025-03-03 11:58:36 - INFO - layer2_self_attn.o_proj | mse: 0.0383544481139627, bpp_loss: 3.294468090496957, bpp: 0
2025-03-03 11:58:53 - INFO - layer2_mlp.gate_proj | mse: 0.03160844124225182, bpp_loss: 3.658983346875067, bpp: 0
2025-03-03 11:59:10 - INFO - layer2_mlp.up_proj | mse: 0.0313847644911013, bpp_loss: 3.5618443894165535, bpp: 0
2025-03-03 11:59:56 - INFO - layer2_mlp.down_proj | mse: 0.024773081234214157, bpp_loss: 3.576409726396755, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [07:05<1:27:32, 141.95s/it]2025-03-03 12:00:12 - INFO - layer3_self_attn.q_proj | mse: 0.029024992071464285, bpp_loss: 4.034554836265743, bpp: 0
2025-03-03 12:00:27 - INFO - layer3_self_attn.k_proj | mse: 0.02918457322789086, bpp_loss: 4.1066268419474365, bpp: 0
2025-03-03 12:00:44 - INFO - layer3_self_attn.v_proj | mse: 0.027442867526877416, bpp_loss: 3.338777171857655, bpp: 0
2025-03-03 12:00:58 - INFO - layer3_self_attn.o_proj | mse: 0.027937200329868867, bpp_loss: 3.3122526772692797, bpp: 0
2025-03-03 12:01:15 - INFO - layer3_mlp.gate_proj | mse: 0.028326166003592185, bpp_loss: 3.673637652507535, bpp: 0
2025-03-03 12:01:31 - INFO - layer3_mlp.up_proj | mse: 0.028130872200822974, bpp_loss: 3.572062303567374, bpp: 0
2025-03-03 12:02:18 - INFO - layer3_mlp.down_proj | mse: 0.034792737213635606, bpp_loss: 3.5759703834575634, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [09:27<1:25:06, 141.86s/it]2025-03-03 12:02:34 - INFO - layer4_self_attn.q_proj | mse: 0.027456168892249434, bpp_loss: 3.9802615124732257, bpp: 0
2025-03-03 12:02:48 - INFO - layer4_self_attn.k_proj | mse: 0.027494344960413617, bpp_loss: 3.9960665832832456, bpp: 0
2025-03-03 12:03:06 - INFO - layer4_self_attn.v_proj | mse: 0.026160893279458627, bpp_loss: 3.327535727098584, bpp: 0
2025-03-03 12:03:20 - INFO - layer4_self_attn.o_proj | mse: 0.025374221533120158, bpp_loss: 3.3233929400891067, bpp: 0
2025-03-03 12:03:37 - INFO - layer4_mlp.gate_proj | mse: 0.02715647154661412, bpp_loss: 3.6811649438407685, bpp: 0
2025-03-03 12:03:53 - INFO - layer4_mlp.up_proj | mse: 0.026938884507702196, bpp_loss: 3.5743144400141857, bpp: 0
2025-03-03 12:04:40 - INFO - layer4_mlp.down_proj | mse: 0.023860640723878057, bpp_loss: 3.578354838821623, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [11:49<1:22:43, 141.81s/it]2025-03-03 12:04:55 - INFO - layer5_self_attn.q_proj | mse: 0.026607729417167807, bpp_loss: 3.941456242464483, bpp: 0
2025-03-03 12:05:10 - INFO - layer5_self_attn.k_proj | mse: 0.026585385570764383, bpp_loss: 3.9323987739533184, bpp: 0
2025-03-03 12:05:28 - INFO - layer5_self_attn.v_proj | mse: 0.025465098745601916, bpp_loss: 3.3484701073169707, bpp: 0
2025-03-03 12:05:42 - INFO - layer5_self_attn.o_proj | mse: 0.027823842067047595, bpp_loss: 3.3401505207270383, bpp: 0
2025-03-03 12:05:59 - INFO - layer5_mlp.gate_proj | mse: 0.0267144908350838, bpp_loss: 3.6961197904966494, bpp: 0
2025-03-03 12:06:15 - INFO - layer5_mlp.up_proj | mse: 0.026463093120508898, bpp_loss: 3.5722279290358228, bpp: 0
2025-03-03 12:07:02 - INFO - layer5_mlp.down_proj | mse: 0.023809865653634323, bpp_loss: 3.575927476005422, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [14:11<1:20:24, 141.89s/it]2025-03-03 12:07:18 - INFO - layer6_self_attn.q_proj | mse: 0.02615810284805566, bpp_loss: 3.9623292384669186, bpp: 0
2025-03-03 12:07:32 - INFO - layer6_self_attn.k_proj | mse: 0.026209507971409324, bpp_loss: 3.9860406613722446, bpp: 0
2025-03-03 12:07:50 - INFO - layer6_self_attn.v_proj | mse: 0.02504891656296599, bpp_loss: 3.371519926711917, bpp: 0
2025-03-03 12:08:04 - INFO - layer6_self_attn.o_proj | mse: 0.025679874820589907, bpp_loss: 3.3665340599790214, bpp: 0
2025-03-03 12:08:21 - INFO - layer6_mlp.gate_proj | mse: 0.02571406675563886, bpp_loss: 3.7091023807172423, bpp: 0
2025-03-03 12:08:37 - INFO - layer6_mlp.up_proj | mse: 0.0254544313112473, bpp_loss: 3.5689550818116578, bpp: 0
2025-03-03 12:09:24 - INFO - layer6_mlp.down_proj | mse: 0.023763938730481757, bpp_loss: 3.571118043501068, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [16:33<1:18:05, 141.97s/it]2025-03-03 12:09:40 - INFO - layer7_self_attn.q_proj | mse: 0.025907705664686396, bpp_loss: 3.9897653958946466, bpp: 0
2025-03-03 12:09:54 - INFO - layer7_self_attn.k_proj | mse: 0.025961658331394008, bpp_loss: 4.012993641197681, bpp: 0
2025-03-03 12:10:12 - INFO - layer7_self_attn.v_proj | mse: 0.02479167401565005, bpp_loss: 3.3888577542454006, bpp: 0
2025-03-03 12:10:26 - INFO - layer7_self_attn.o_proj | mse: 0.02557101462194378, bpp_loss: 3.3799415710940957, bpp: 0
2025-03-03 12:10:43 - INFO - layer7_mlp.gate_proj | mse: 0.0253685188486012, bpp_loss: 3.713884084864899, bpp: 0
2025-03-03 12:10:59 - INFO - layer7_mlp.up_proj | mse: 0.025114294650538018, bpp_loss: 3.570175231165356, bpp: 0
2025-03-03 12:11:46 - INFO - layer7_mlp.down_proj | mse: 0.023856929762563515, bpp_loss: 3.5696342004670036, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [18:55<1:15:43, 141.99s/it]2025-03-03 12:12:02 - INFO - layer8_self_attn.q_proj | mse: 0.02569716993296657, bpp_loss: 3.954339075833559, bpp: 0
2025-03-03 12:12:16 - INFO - layer8_self_attn.k_proj | mse: 0.025761381375057974, bpp_loss: 3.9776851215958597, bpp: 0
2025-03-03 12:12:34 - INFO - layer8_self_attn.v_proj | mse: 0.024664940223166978, bpp_loss: 3.396583320386708, bpp: 0
2025-03-03 12:12:48 - INFO - layer8_self_attn.o_proj | mse: 0.025778815545477975, bpp_loss: 3.3893710066378118, bpp: 0
2025-03-03 12:13:05 - INFO - layer8_mlp.gate_proj | mse: 0.025213394622637195, bpp_loss: 3.7093129665211393, bpp: 0
2025-03-03 12:13:21 - INFO - layer8_mlp.up_proj | mse: 0.024992500405766203, bpp_loss: 3.5810283876679563, bpp: 0
2025-03-03 12:14:08 - INFO - layer8_mlp.down_proj | mse: 0.02377290436906848, bpp_loss: 3.5788083024322987, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [21:17<1:13:19, 141.92s/it]2025-03-03 12:14:24 - INFO - layer9_self_attn.q_proj | mse: 0.025571405838572366, bpp_loss: 3.943692895695567, bpp: 0
2025-03-03 12:14:38 - INFO - layer9_self_attn.k_proj | mse: 0.025598531427559357, bpp_loss: 3.952538725361228, bpp: 0
2025-03-03 12:14:56 - INFO - layer9_self_attn.v_proj | mse: 0.02454931809540017, bpp_loss: 3.3925490760430694, bpp: 0
2025-03-03 12:15:10 - INFO - layer9_self_attn.o_proj | mse: 0.025678376701936352, bpp_loss: 3.39050114993006, bpp: 0
2025-03-03 12:15:27 - INFO - layer9_mlp.gate_proj | mse: 0.02499481597970266, bpp_loss: 3.69629623796101, bpp: 0
2025-03-03 12:15:44 - INFO - layer9_mlp.up_proj | mse: 0.02482474078228415, bpp_loss: 3.59344469755888, bpp: 0
2025-03-03 12:16:30 - INFO - layer9_mlp.down_proj | mse: 0.023682064101390336, bpp_loss: 3.588781860001661, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [23:39<1:11:01, 142.06s/it]2025-03-03 12:16:46 - INFO - layer10_self_attn.q_proj | mse: 0.025485022982051273, bpp_loss: 3.938357549831271, bpp: 0
2025-03-03 12:17:01 - INFO - layer10_self_attn.k_proj | mse: 0.02554241130948293, bpp_loss: 3.960764779448509, bpp: 0
2025-03-03 12:17:18 - INFO - layer10_self_attn.v_proj | mse: 0.024477054265545917, bpp_loss: 3.3856569096446036, bpp: 0
2025-03-03 12:17:32 - INFO - layer10_self_attn.o_proj | mse: 0.02509150540637208, bpp_loss: 3.3885175097733735, bpp: 0
2025-03-03 12:17:49 - INFO - layer10_mlp.gate_proj | mse: 0.024931534612741606, bpp_loss: 3.682449395402714, bpp: 0
2025-03-03 12:18:06 - INFO - layer10_mlp.up_proj | mse: 0.024804117616074255, bpp_loss: 3.602979192799992, bpp: 0
2025-03-03 12:18:52 - INFO - layer10_mlp.down_proj | mse: 0.02380480600097601, bpp_loss: 3.597440670789392, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [26:01<1:08:40, 142.08s/it]2025-03-03 12:19:08 - INFO - layer11_self_attn.q_proj | mse: 0.02549127132346523, bpp_loss: 3.9896397706866265, bpp: 0
2025-03-03 12:19:23 - INFO - layer11_self_attn.k_proj | mse: 0.02560230638990915, bpp_loss: 4.02023935765028, bpp: 0
2025-03-03 12:19:40 - INFO - layer11_self_attn.v_proj | mse: 0.024415132645901467, bpp_loss: 3.396006980314851, bpp: 0
2025-03-03 12:19:54 - INFO - layer11_self_attn.o_proj | mse: 0.02593070586505438, bpp_loss: 3.38627927724272, bpp: 0
2025-03-03 12:20:11 - INFO - layer11_mlp.gate_proj | mse: 0.024771191418237543, bpp_loss: 3.6678648109237355, bpp: 0
2025-03-03 12:20:28 - INFO - layer11_mlp.up_proj | mse: 0.02468460048968123, bpp_loss: 3.612264237028581, bpp: 0
2025-03-03 12:21:14 - INFO - layer11_mlp.down_proj | mse: 0.023861225797719654, bpp_loss: 3.6045506282675044, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [28:23<1:06:17, 142.06s/it]2025-03-03 12:21:30 - INFO - layer12_self_attn.q_proj | mse: 0.025324425774854713, bpp_loss: 3.9325185527652504, bpp: 0
2025-03-03 12:21:45 - INFO - layer12_self_attn.k_proj | mse: 0.02541030616831255, bpp_loss: 3.9548055116087197, bpp: 0
2025-03-03 12:22:02 - INFO - layer12_self_attn.v_proj | mse: 0.024381061571176595, bpp_loss: 3.4191273595392704, bpp: 0
2025-03-03 12:22:17 - INFO - layer12_self_attn.o_proj | mse: 0.026836424275240238, bpp_loss: 3.4133883674442766, bpp: 0
2025-03-03 12:22:33 - INFO - layer12_mlp.gate_proj | mse: 0.024747502794716745, bpp_loss: 3.662065421651911, bpp: 0
2025-03-03 12:22:50 - INFO - layer12_mlp.up_proj | mse: 0.024675637597920057, bpp_loss: 3.6211949378803925, bpp: 0
2025-03-03 12:23:36 - INFO - layer12_mlp.down_proj | mse: 0.02379087684862513, bpp_loss: 3.612496559790991, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [30:45<1:03:56, 142.08s/it]2025-03-03 12:23:52 - INFO - layer13_self_attn.q_proj | mse: 0.025231579500479308, bpp_loss: 3.8813071548193694, bpp: 0
2025-03-03 12:24:07 - INFO - layer13_self_attn.k_proj | mse: 0.025250111302388047, bpp_loss: 3.8777793569862844, bpp: 0
2025-03-03 12:24:24 - INFO - layer13_self_attn.v_proj | mse: 0.02442238962165643, bpp_loss: 3.4366541995480655, bpp: 0
2025-03-03 12:24:39 - INFO - layer13_self_attn.o_proj | mse: 0.025475190651333707, bpp_loss: 3.437751211374998, bpp: 0
2025-03-03 12:24:56 - INFO - layer13_mlp.gate_proj | mse: 0.024743783592925565, bpp_loss: 3.658648375835684, bpp: 0
2025-03-03 12:25:12 - INFO - layer13_mlp.up_proj | mse: 0.02470063645722697, bpp_loss: 3.6291163458316413, bpp: 0
2025-03-03 12:25:59 - INFO - layer13_mlp.down_proj | mse: 0.023791063632762354, bpp_loss: 3.619724095309222, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [33:08<1:01:36, 142.18s/it]2025-03-03 12:26:15 - INFO - layer14_self_attn.q_proj | mse: 0.02528223185629171, bpp_loss: 3.919642186835408, bpp: 0
2025-03-03 12:26:29 - INFO - layer14_self_attn.k_proj | mse: 0.02536128357276806, bpp_loss: 3.9447053945064545, bpp: 0
2025-03-03 12:26:47 - INFO - layer14_self_attn.v_proj | mse: 0.024384239510993666, bpp_loss: 3.4263962718099354, bpp: 0
2025-03-03 12:27:02 - INFO - layer14_self_attn.o_proj | mse: 0.025146663242788605, bpp_loss: 3.4240100602060557, bpp: 0
2025-03-03 12:27:18 - INFO - layer14_mlp.gate_proj | mse: 0.02470729750917942, bpp_loss: 3.6549237509016637, bpp: 0
2025-03-03 12:27:35 - INFO - layer14_mlp.up_proj | mse: 0.024687229201730092, bpp_loss: 3.6348911867649467, bpp: 0
2025-03-03 12:28:22 - INFO - layer14_mlp.down_proj | mse: 0.023733962623282954, bpp_loss: 3.6241873573097916, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [35:31<59:20, 142.41s/it]  2025-03-03 12:28:38 - INFO - layer15_self_attn.q_proj | mse: 0.025169780251912993, bpp_loss: 3.899453463181853, bpp: 0
2025-03-03 12:28:52 - INFO - layer15_self_attn.k_proj | mse: 0.025263268047395, bpp_loss: 3.9388089344650505, bpp: 0
2025-03-03 12:29:10 - INFO - layer15_self_attn.v_proj | mse: 0.024384977445676977, bpp_loss: 3.4606197825446725, bpp: 0
2025-03-03 12:29:25 - INFO - layer15_self_attn.o_proj | mse: 0.027092800954473, bpp_loss: 3.4583462496846913, bpp: 0
2025-03-03 12:29:42 - INFO - layer15_mlp.gate_proj | mse: 0.0247056741352809, bpp_loss: 3.656160288331685, bpp: 0
2025-03-03 12:29:58 - INFO - layer15_mlp.up_proj | mse: 0.02469205537421688, bpp_loss: 3.6424469257394474, bpp: 0
2025-03-03 12:30:45 - INFO - layer15_mlp.down_proj | mse: 0.02371952256138026, bpp_loss: 3.6312875733331396, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [37:54<57:04, 142.68s/it]2025-03-03 12:31:01 - INFO - layer16_self_attn.q_proj | mse: 0.02513953605454076, bpp_loss: 3.8867050129920244, bpp: 0
2025-03-03 12:31:16 - INFO - layer16_self_attn.k_proj | mse: 0.025213895025581298, bpp_loss: 3.9148255033791064, bpp: 0
2025-03-03 12:31:33 - INFO - layer16_self_attn.v_proj | mse: 0.024398091546217297, bpp_loss: 3.4657218112051487, bpp: 0
2025-03-03 12:31:48 - INFO - layer16_self_attn.o_proj | mse: 0.02518873849848797, bpp_loss: 3.4627193717658518, bpp: 0
2025-03-03 12:32:05 - INFO - layer16_mlp.gate_proj | mse: 0.024729631947705347, bpp_loss: 3.660179455743896, bpp: 0
2025-03-03 12:32:22 - INFO - layer16_mlp.up_proj | mse: 0.024725462266524393, bpp_loss: 3.642069706431142, bpp: 0
2025-03-03 12:33:09 - INFO - layer16_mlp.down_proj | mse: 0.023798600922064428, bpp_loss: 3.631010653933993, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [40:18<54:48, 142.96s/it]2025-03-03 12:33:25 - INFO - layer17_self_attn.q_proj | mse: 0.025125370675192805, bpp_loss: 3.876026056110859, bpp: 0
2025-03-03 12:33:39 - INFO - layer17_self_attn.k_proj | mse: 0.025185771926896774, bpp_loss: 3.9057810781896114, bpp: 0
2025-03-03 12:33:57 - INFO - layer17_self_attn.v_proj | mse: 0.024405687823598, bpp_loss: 3.4761378333345054, bpp: 0
2025-03-03 12:34:12 - INFO - layer17_self_attn.o_proj | mse: 0.02495319456825437, bpp_loss: 3.4774015915393828, bpp: 0
2025-03-03 12:34:28 - INFO - layer17_mlp.gate_proj | mse: 0.024664941459238473, bpp_loss: 3.6713282421783164, bpp: 0
2025-03-03 12:34:45 - INFO - layer17_mlp.up_proj | mse: 0.0246249421856172, bpp_loss: 3.6370495676994326, bpp: 0
2025-03-03 12:35:32 - INFO - layer17_mlp.down_proj | mse: 0.02360711971315501, bpp_loss: 3.628169122476269, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [42:41<52:27, 143.07s/it]2025-03-03 12:35:48 - INFO - layer18_self_attn.q_proj | mse: 0.025010757181767006, bpp_loss: 3.888238188996911, bpp: 0
2025-03-03 12:36:03 - INFO - layer18_self_attn.k_proj | mse: 0.02507257126319128, bpp_loss: 3.918473905995488, bpp: 0
2025-03-03 12:36:20 - INFO - layer18_self_attn.v_proj | mse: 0.024348540530108126, bpp_loss: 3.5103861038014292, bpp: 0
2025-03-03 12:36:35 - INFO - layer18_self_attn.o_proj | mse: 0.024878481462730136, bpp_loss: 3.503243428990245, bpp: 0
2025-03-03 12:36:52 - INFO - layer18_mlp.gate_proj | mse: 0.024647227181283277, bpp_loss: 3.6788286576116525, bpp: 0
2025-03-03 12:37:09 - INFO - layer18_mlp.up_proj | mse: 0.024585940009669634, bpp_loss: 3.631045821916174, bpp: 0
2025-03-03 12:37:55 - INFO - layer18_mlp.down_proj | mse: 0.023424848610306036, bpp_loss: 3.6248884467063127, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [45:04<50:06, 143.17s/it]2025-03-03 12:38:12 - INFO - layer19_self_attn.q_proj | mse: 0.024918164920084095, bpp_loss: 3.8425084603577853, bpp: 0
2025-03-03 12:38:26 - INFO - layer19_self_attn.k_proj | mse: 0.024968665239102447, bpp_loss: 3.8651265470683573, bpp: 0
2025-03-03 12:38:44 - INFO - layer19_self_attn.v_proj | mse: 0.024351419958658832, bpp_loss: 3.5082628866657615, bpp: 0
2025-03-03 12:38:59 - INFO - layer19_self_attn.o_proj | mse: 0.02431102823233747, bpp_loss: 3.5042815177887676, bpp: 0
2025-03-03 12:39:15 - INFO - layer19_mlp.gate_proj | mse: 0.024663807020287396, bpp_loss: 3.6860079551184617, bpp: 0
2025-03-03 12:39:32 - INFO - layer19_mlp.up_proj | mse: 0.02457423303918661, bpp_loss: 3.629898870046492, bpp: 0
2025-03-03 12:40:19 - INFO - layer19_mlp.down_proj | mse: 0.023389620572660603, bpp_loss: 3.6236829204967727, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [47:28<47:47, 143.38s/it]2025-03-03 12:40:36 - INFO - layer20_self_attn.q_proj | mse: 0.025035092339351025, bpp_loss: 3.8659938003122805, bpp: 0
2025-03-03 12:40:50 - INFO - layer20_self_attn.k_proj | mse: 0.025099211076080204, bpp_loss: 3.8930629980564118, bpp: 0
2025-03-03 12:41:08 - INFO - layer20_self_attn.v_proj | mse: 0.02441074582816099, bpp_loss: 3.5068358652293683, bpp: 0
2025-03-03 12:41:23 - INFO - layer20_self_attn.o_proj | mse: 0.024913852266633396, bpp_loss: 3.507602153047919, bpp: 0
2025-03-03 12:41:40 - INFO - layer20_mlp.gate_proj | mse: 0.02471428268654646, bpp_loss: 3.6891420274421023, bpp: 0
2025-03-03 12:41:57 - INFO - layer20_mlp.up_proj | mse: 0.024621011478258868, bpp_loss: 3.629377343367647, bpp: 0
2025-03-03 12:42:43 - INFO - layer20_mlp.down_proj | mse: 0.023334598910120588, bpp_loss: 3.6226900146239336, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [49:52<45:28, 143.60s/it]2025-03-03 12:43:00 - INFO - layer21_self_attn.q_proj | mse: 0.02504902966350791, bpp_loss: 3.83305461935699, bpp: 0
2025-03-03 12:43:14 - INFO - layer21_self_attn.k_proj | mse: 0.025095764290712686, bpp_loss: 3.8518434178084133, bpp: 0
2025-03-03 12:43:31 - INFO - layer21_self_attn.v_proj | mse: 0.0245325310084085, bpp_loss: 3.5354355047643184, bpp: 0
2025-03-03 12:43:47 - INFO - layer21_self_attn.o_proj | mse: 0.02437626684984233, bpp_loss: 3.535269120708108, bpp: 0
2025-03-03 12:44:03 - INFO - layer21_mlp.gate_proj | mse: 0.025018402970678207, bpp_loss: 3.6977807543343966, bpp: 0
2025-03-03 12:44:20 - INFO - layer21_mlp.up_proj | mse: 0.024888423185775128, bpp_loss: 3.6232263451373137, bpp: 0
2025-03-03 12:45:07 - INFO - layer21_mlp.down_proj | mse: 0.02344085436277075, bpp_loss: 3.62125500768975, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [52:16<43:05, 143.62s/it]2025-03-03 12:45:24 - INFO - layer22_self_attn.q_proj | mse: 0.025096439185749688, bpp_loss: 3.828823374249041, bpp: 0
2025-03-03 12:45:38 - INFO - layer22_self_attn.k_proj | mse: 0.025146972878698437, bpp_loss: 3.855318398922682, bpp: 0
2025-03-03 12:45:55 - INFO - layer22_self_attn.v_proj | mse: 0.02470114537533026, bpp_loss: 3.594299887008965, bpp: 0
2025-03-03 12:46:10 - INFO - layer22_self_attn.o_proj | mse: 0.023973658586343368, bpp_loss: 3.584896874576807, bpp: 0
2025-03-03 12:46:27 - INFO - layer22_mlp.gate_proj | mse: 0.024929257494362807, bpp_loss: 3.706760066361339, bpp: 0
2025-03-03 12:46:44 - INFO - layer22_mlp.up_proj | mse: 0.024787828940578162, bpp_loss: 3.6191654307422816, bpp: 0
2025-03-03 12:47:31 - INFO - layer22_mlp.down_proj | mse: 0.023232252190224376, bpp_loss: 3.61904812813909, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [54:40<40:43, 143.72s/it]2025-03-03 12:47:48 - INFO - layer23_self_attn.q_proj | mse: 0.024958688288019813, bpp_loss: 3.8021384447440507, bpp: 0
2025-03-03 12:48:02 - INFO - layer23_self_attn.k_proj | mse: 0.024990367564399277, bpp_loss: 3.8179085459932685, bpp: 0
2025-03-03 12:48:19 - INFO - layer23_self_attn.v_proj | mse: 0.02460822308255783, bpp_loss: 3.587839234359562, bpp: 0
2025-03-03 12:48:35 - INFO - layer23_self_attn.o_proj | mse: 0.02327862052824241, bpp_loss: 3.5853055045753717, bpp: 0
2025-03-03 12:48:51 - INFO - layer23_mlp.gate_proj | mse: 0.02488945599218095, bpp_loss: 3.7145582734434694, bpp: 0
2025-03-03 12:49:08 - INFO - layer23_mlp.up_proj | mse: 0.024711132077643593, bpp_loss: 3.6155403112371762, bpp: 0
2025-03-03 12:49:55 - INFO - layer23_mlp.down_proj | mse: 0.02309424343424624, bpp_loss: 3.6170508681348075, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [57:04<38:21, 143.85s/it]2025-03-03 12:50:12 - INFO - layer24_self_attn.q_proj | mse: 0.024880068578531426, bpp_loss: 3.8154318971931933, bpp: 0
2025-03-03 12:50:26 - INFO - layer24_self_attn.k_proj | mse: 0.024909851103199775, bpp_loss: 3.8324883946403863, bpp: 0
2025-03-03 12:50:43 - INFO - layer24_self_attn.v_proj | mse: 0.024530554530085864, bpp_loss: 3.5977367835491894, bpp: 0
2025-03-03 12:50:58 - INFO - layer24_self_attn.o_proj | mse: 0.02327242224772406, bpp_loss: 3.593678880929947, bpp: 0
2025-03-03 12:51:15 - INFO - layer24_mlp.gate_proj | mse: 0.02484443002780793, bpp_loss: 3.720639442845627, bpp: 0
2025-03-03 12:51:32 - INFO - layer24_mlp.up_proj | mse: 0.02465194897439926, bpp_loss: 3.614728405078252, bpp: 0
2025-03-03 12:52:19 - INFO - layer24_mlp.down_proj | mse: 0.02296955678217301, bpp_loss: 3.617850145366457, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [59:28<35:58, 143.89s/it]2025-03-03 12:52:36 - INFO - layer25_self_attn.q_proj | mse: 0.024745986959038412, bpp_loss: 3.805613412335515, bpp: 0
2025-03-03 12:52:50 - INFO - layer25_self_attn.k_proj | mse: 0.024774362216308188, bpp_loss: 3.8187780123576522, bpp: 0
2025-03-03 12:53:07 - INFO - layer25_self_attn.v_proj | mse: 0.024459325292074043, bpp_loss: 3.6235744947195054, bpp: 0
2025-03-03 12:53:23 - INFO - layer25_self_attn.o_proj | mse: 0.023045946756023294, bpp_loss: 3.623354026079178, bpp: 0
2025-03-03 12:53:40 - INFO - layer25_mlp.gate_proj | mse: 0.024779398932973182, bpp_loss: 3.7249060225155617, bpp: 0
2025-03-03 12:53:57 - INFO - layer25_mlp.up_proj | mse: 0.02458864563283383, bpp_loss: 3.613774108334824, bpp: 0
2025-03-03 12:54:43 - INFO - layer25_mlp.down_proj | mse: 0.022880011642740467, bpp_loss: 3.617413151871275, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [1:01:53<33:36, 144.03s/it]2025-03-03 12:55:00 - INFO - layer26_self_attn.q_proj | mse: 0.02481182445318324, bpp_loss: 3.8162965743243693, bpp: 0
2025-03-03 12:55:14 - INFO - layer26_self_attn.k_proj | mse: 0.024847082156544586, bpp_loss: 3.830022560060024, bpp: 0
2025-03-03 12:55:31 - INFO - layer26_self_attn.v_proj | mse: 0.024541727380341202, bpp_loss: 3.643232483789325, bpp: 0
2025-03-03 12:55:47 - INFO - layer26_self_attn.o_proj | mse: 0.023283839840135667, bpp_loss: 3.617351381406188, bpp: 0
2025-03-03 12:56:04 - INFO - layer26_mlp.gate_proj | mse: 0.02475696011507645, bpp_loss: 3.728598372472657, bpp: 0
2025-03-03 12:56:21 - INFO - layer26_mlp.up_proj | mse: 0.024561339440067102, bpp_loss: 3.614877877080882, bpp: 0
2025-03-03 12:57:07 - INFO - layer26_mlp.down_proj | mse: 0.02282221705981035, bpp_loss: 3.6184822805501797, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [1:04:17<31:12, 144.00s/it]2025-03-03 12:57:24 - INFO - layer27_self_attn.q_proj | mse: 0.02458000357029659, bpp_loss: 3.817693923562765, bpp: 0
2025-03-03 12:57:38 - INFO - layer27_self_attn.k_proj | mse: 0.024602126777937924, bpp_loss: 3.828571719862521, bpp: 0
2025-03-03 12:57:55 - INFO - layer27_self_attn.v_proj | mse: 0.024292559470075043, bpp_loss: 3.637693564295769, bpp: 0
2025-03-03 12:58:11 - INFO - layer27_self_attn.o_proj | mse: 0.02308026071879719, bpp_loss: 3.629629514887929, bpp: 0
2025-03-03 12:58:27 - INFO - layer27_mlp.gate_proj | mse: 0.024665669368008535, bpp_loss: 3.732538887527254, bpp: 0
2025-03-03 12:58:44 - INFO - layer27_mlp.up_proj | mse: 0.024466090517385377, bpp_loss: 3.6157661207848126, bpp: 0
2025-03-03 12:59:31 - INFO - layer27_mlp.down_proj | mse: 0.022728529707452327, bpp_loss: 3.619521724984602, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [1:06:40<28:47, 143.97s/it]2025-03-03 12:59:48 - INFO - layer28_self_attn.q_proj | mse: 0.024425686224337145, bpp_loss: 3.8108828295767307, bpp: 0
2025-03-03 13:00:02 - INFO - layer28_self_attn.k_proj | mse: 0.024448538096125565, bpp_loss: 3.8209760247915985, bpp: 0
2025-03-03 13:00:18 - INFO - layer28_self_attn.v_proj | mse: 0.02417299551030644, bpp_loss: 3.645360216125846, bpp: 0
2025-03-03 13:00:35 - INFO - layer28_self_attn.o_proj | mse: 0.0233240053653732, bpp_loss: 3.6376172365248203, bpp: 0
2025-03-03 13:00:51 - INFO - layer28_mlp.gate_proj | mse: 0.024506630915639486, bpp_loss: 3.734046450091733, bpp: 0
2025-03-03 13:01:08 - INFO - layer28_mlp.up_proj | mse: 0.0243079365428426, bpp_loss: 3.6187837485361984, bpp: 0
2025-03-03 13:01:55 - INFO - layer28_mlp.down_proj | mse: 0.02259649529703979, bpp_loss: 3.6216179417515244, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [1:09:04<26:23, 143.94s/it]2025-03-03 13:02:12 - INFO - layer29_self_attn.q_proj | mse: 0.02431704295623862, bpp_loss: 3.83379444360733, bpp: 0
2025-03-03 13:02:26 - INFO - layer29_self_attn.k_proj | mse: 0.024347743263992996, bpp_loss: 3.851435092687607, bpp: 0
2025-03-03 13:02:42 - INFO - layer29_self_attn.v_proj | mse: 0.02403402831822418, bpp_loss: 3.6493826024606824, bpp: 0
2025-03-03 13:02:59 - INFO - layer29_self_attn.o_proj | mse: 0.023038988291534696, bpp_loss: 3.6438358077406883, bpp: 0
2025-03-03 13:03:16 - INFO - layer29_mlp.gate_proj | mse: 0.024502120628090655, bpp_loss: 3.7326227706339625, bpp: 0
2025-03-03 13:03:32 - INFO - layer29_mlp.up_proj | mse: 0.024300517367039063, bpp_loss: 3.622756210907742, bpp: 0
2025-03-03 13:04:19 - INFO - layer29_mlp.down_proj | mse: 0.022525726083636517, bpp_loss: 3.6257768448580197, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [1:11:28<24:00, 144.01s/it]2025-03-03 13:04:36 - INFO - layer30_self_attn.q_proj | mse: 0.024215348882092477, bpp_loss: 3.8122230560705064, bpp: 0
2025-03-03 13:04:50 - INFO - layer30_self_attn.k_proj | mse: 0.024236179776984394, bpp_loss: 3.8207660398259757, bpp: 0
2025-03-03 13:05:07 - INFO - layer30_self_attn.v_proj | mse: 0.02405857669814131, bpp_loss: 3.698370138220489, bpp: 0
2025-03-03 13:05:23 - INFO - layer30_self_attn.o_proj | mse: 0.022798267693874465, bpp_loss: 3.695712886378169, bpp: 0
2025-03-03 13:05:40 - INFO - layer30_mlp.gate_proj | mse: 0.024261191065676903, bpp_loss: 3.734619894016672, bpp: 0
2025-03-03 13:05:56 - INFO - layer30_mlp.up_proj | mse: 0.024075066166584922, bpp_loss: 3.6243717606972763, bpp: 0
2025-03-03 13:06:43 - INFO - layer30_mlp.down_proj | mse: 0.02246701131414802, bpp_loss: 3.6266173279671756, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [1:13:52<21:35, 143.90s/it]2025-03-03 13:07:00 - INFO - layer31_self_attn.q_proj | mse: 0.02414177790663085, bpp_loss: 3.8276354429125785, bpp: 0
2025-03-03 13:07:14 - INFO - layer31_self_attn.k_proj | mse: 0.024183799393220122, bpp_loss: 3.8518280452489853, bpp: 0
2025-03-03 13:07:30 - INFO - layer31_self_attn.v_proj | mse: 0.023913294416784296, bpp_loss: 3.663626612983644, bpp: 0
2025-03-03 13:07:46 - INFO - layer31_self_attn.o_proj | mse: 0.023160862468929944, bpp_loss: 3.6532509575784204, bpp: 0
2025-03-03 13:08:03 - INFO - layer31_mlp.gate_proj | mse: 0.02416547792947767, bpp_loss: 3.735130783087677, bpp: 0
2025-03-03 13:08:20 - INFO - layer31_mlp.up_proj | mse: 0.02399092815324244, bpp_loss: 3.6275319968660673, bpp: 0
2025-03-03 13:09:06 - INFO - layer31_mlp.down_proj | mse: 0.022397982214729027, bpp_loss: 3.6294359770913918, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:16:16<19:10, 143.78s/it]2025-03-03 13:09:23 - INFO - layer32_self_attn.q_proj | mse: 0.024020274550684503, bpp_loss: 3.791944576986134, bpp: 0
2025-03-03 13:09:37 - INFO - layer32_self_attn.k_proj | mse: 0.02403611233476699, bpp_loss: 3.8007886152341963, bpp: 0
2025-03-03 13:09:54 - INFO - layer32_self_attn.v_proj | mse: 0.023931130928476353, bpp_loss: 3.701637845374644, bpp: 0
2025-03-03 13:10:10 - INFO - layer32_self_attn.o_proj | mse: 0.02336498113547657, bpp_loss: 3.6992361845076083, bpp: 0
2025-03-03 13:10:27 - INFO - layer32_mlp.gate_proj | mse: 0.02404131592108399, bpp_loss: 3.7321668834597976, bpp: 0
2025-03-03 13:10:44 - INFO - layer32_mlp.up_proj | mse: 0.02387107316730709, bpp_loss: 3.6324875147806273, bpp: 0
2025-03-03 13:11:30 - INFO - layer32_mlp.down_proj | mse: 0.022396566226159337, bpp_loss: 3.6341873540094607, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:18:39<16:45, 143.71s/it]2025-03-03 13:11:47 - INFO - layer33_self_attn.q_proj | mse: 0.023970588184746483, bpp_loss: 3.7952924412488938, bpp: 0
2025-03-03 13:12:00 - INFO - layer33_self_attn.k_proj | mse: 0.023985630556821083, bpp_loss: 3.8118021791800856, bpp: 0
2025-03-03 13:12:17 - INFO - layer33_self_attn.v_proj | mse: 0.02381215842891874, bpp_loss: 3.6809306071326136, bpp: 0
2025-03-03 13:12:33 - INFO - layer33_self_attn.o_proj | mse: 0.02312214129323588, bpp_loss: 3.6771461915224792, bpp: 0
2025-03-03 13:12:50 - INFO - layer33_mlp.gate_proj | mse: 0.024010328982083745, bpp_loss: 3.7302191733210175, bpp: 0
2025-03-03 13:13:07 - INFO - layer33_mlp.up_proj | mse: 0.023856435333964983, bpp_loss: 3.6377742853981476, bpp: 0
2025-03-03 13:13:53 - INFO - layer33_mlp.down_proj | mse: 0.02239101489172804, bpp_loss: 3.6388280559193205, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:21:03<14:21, 143.61s/it]2025-03-03 13:14:10 - INFO - layer34_self_attn.q_proj | mse: 0.023884550192172862, bpp_loss: 3.7555913826450706, bpp: 0
2025-03-03 13:14:24 - INFO - layer34_self_attn.k_proj | mse: 0.023901374361309426, bpp_loss: 3.769847580678761, bpp: 0
2025-03-03 13:14:41 - INFO - layer34_self_attn.v_proj | mse: 0.02385283939597024, bpp_loss: 3.7070346377044916, bpp: 0
2025-03-03 13:14:57 - INFO - layer34_self_attn.o_proj | mse: 0.023225789596417724, bpp_loss: 3.7155477818846703, bpp: 0
2025-03-03 13:15:13 - INFO - layer34_mlp.gate_proj | mse: 0.02396161952465166, bpp_loss: 3.7243341071186244, bpp: 0
2025-03-03 13:15:30 - INFO - layer34_mlp.up_proj | mse: 0.023835177651053634, bpp_loss: 3.646299273713871, bpp: 0
2025-03-03 13:16:17 - INFO - layer34_mlp.down_proj | mse: 0.022443512221589995, bpp_loss: 3.647518309895639, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:23:26<11:57, 143.59s/it]2025-03-03 13:16:34 - INFO - layer35_self_attn.q_proj | mse: 0.023857487642832194, bpp_loss: 3.7473823242634534, bpp: 0
2025-03-03 13:16:47 - INFO - layer35_self_attn.k_proj | mse: 0.023872769194741333, bpp_loss: 3.763068088181317, bpp: 0
2025-03-03 13:17:04 - INFO - layer35_self_attn.v_proj | mse: 0.023850078630283184, bpp_loss: 3.7079492982104423, bpp: 0
2025-03-03 13:17:20 - INFO - layer35_self_attn.o_proj | mse: 0.023539604663977746, bpp_loss: 3.7111025415360928, bpp: 0
2025-03-03 13:17:37 - INFO - layer35_mlp.gate_proj | mse: 0.023922284982812857, bpp_loss: 3.718015926303687, bpp: 0
2025-03-03 13:17:54 - INFO - layer35_mlp.up_proj | mse: 0.023814977495978037, bpp_loss: 3.6557444617152215, bpp: 0
2025-03-03 13:18:40 - INFO - layer35_mlp.down_proj | mse: 0.02253298182331998, bpp_loss: 3.656195378496691, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:25:49<09:33, 143.47s/it]2025-03-03 13:18:57 - INFO - layer36_self_attn.q_proj | mse: 0.02388721269017596, bpp_loss: 3.748619559146464, bpp: 0
2025-03-03 13:19:11 - INFO - layer36_self_attn.k_proj | mse: 0.023926783046988007, bpp_loss: 3.7700288423150776, bpp: 0
2025-03-03 13:19:27 - INFO - layer36_self_attn.v_proj | mse: 0.023928279311534316, bpp_loss: 3.7306681463122366, bpp: 0
2025-03-03 13:19:43 - INFO - layer36_self_attn.o_proj | mse: 0.02385866500093245, bpp_loss: 3.733977232053876, bpp: 0
2025-03-03 13:20:00 - INFO - layer36_mlp.gate_proj | mse: 0.023933129450074003, bpp_loss: 3.713319959408707, bpp: 0
2025-03-03 13:20:17 - INFO - layer36_mlp.up_proj | mse: 0.023845994650059307, bpp_loss: 3.661331274388013, bpp: 0
2025-03-03 13:21:03 - INFO - layer36_mlp.down_proj | mse: 0.02267955243452937, bpp_loss: 3.6568586438894273, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:28:12<07:10, 143.37s/it]2025-03-03 13:21:20 - INFO - layer37_self_attn.q_proj | mse: 0.023911419914360108, bpp_loss: 3.6836288741976024, bpp: 0
2025-03-03 13:21:34 - INFO - layer37_self_attn.k_proj | mse: 0.02392594313640625, bpp_loss: 3.6823682211339475, bpp: 0
2025-03-03 13:21:51 - INFO - layer37_self_attn.v_proj | mse: 0.02409296482520499, bpp_loss: 3.7552428184449673, bpp: 0
2025-03-03 13:22:06 - INFO - layer37_self_attn.o_proj | mse: 0.024696960655279432, bpp_loss: 3.756651887111366, bpp: 0
2025-03-03 13:22:23 - INFO - layer37_mlp.gate_proj | mse: 0.023993015740658468, bpp_loss: 3.717127959926923, bpp: 0
2025-03-03 13:22:40 - INFO - layer37_mlp.up_proj | mse: 0.023913805532348027, bpp_loss: 3.669597841578501, bpp: 0
2025-03-03 13:23:27 - INFO - layer37_mlp.down_proj | mse: 0.02291231431117792, bpp_loss: 3.6567114334001585, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:30:36<04:46, 143.44s/it]2025-03-03 13:23:44 - INFO - layer38_self_attn.q_proj | mse: 0.02395063428258121, bpp_loss: 3.658236341997981, bpp: 0
2025-03-03 13:23:58 - INFO - layer38_self_attn.k_proj | mse: 0.023957047639539927, bpp_loss: 3.6657100307196377, bpp: 0
2025-03-03 13:24:14 - INFO - layer38_self_attn.v_proj | mse: 0.024275950377378844, bpp_loss: 3.8093991618975998, bpp: 0
2025-03-03 13:24:31 - INFO - layer38_self_attn.o_proj | mse: 0.0251361875368572, bpp_loss: 3.820079029649496, bpp: 0
2025-03-03 13:24:47 - INFO - layer38_mlp.gate_proj | mse: 0.0242337530252839, bpp_loss: 3.750291915403472, bpp: 0
2025-03-03 13:25:04 - INFO - layer38_mlp.up_proj | mse: 0.024094582362099215, bpp_loss: 3.673451830005204, bpp: 0
2025-03-03 13:25:51 - INFO - layer38_mlp.down_proj | mse: 0.02347329711931112, bpp_loss: 3.6390105438315206, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:33:00<02:23, 143.59s/it]2025-03-03 13:26:08 - INFO - layer39_self_attn.q_proj | mse: 0.024281243853561882, bpp_loss: 3.654738847985864, bpp: 0
2025-03-03 13:26:21 - INFO - layer39_self_attn.k_proj | mse: 0.024312848965651567, bpp_loss: 3.666763873398304, bpp: 0
2025-03-03 13:26:38 - INFO - layer39_self_attn.v_proj | mse: 0.024434356029812407, bpp_loss: 3.69375606328249, bpp: 0
2025-03-03 13:26:54 - INFO - layer39_self_attn.o_proj | mse: 0.03715391367315118, bpp_loss: 3.7011003011092543, bpp: 0
2025-03-03 13:27:09 - INFO - layer39_mlp.gate_proj | mse: 0.024754721452255317, bpp_loss: 3.827053916343936, bpp: 0
2025-03-03 13:27:23 - INFO - layer39_mlp.up_proj | mse: 0.024549495128306703, bpp_loss: 3.7195108009709252, bpp: 0
2025-03-03 13:28:02 - INFO - layer39_mlp.down_proj | mse: 0.02584863923285719, bpp_loss: 3.625863606593123, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:35:11<00:00, 139.95s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:35:11<00:00, 142.80s/it]
2025-03-03 13:28:02 - INFO - #### Total | mse: 0.026205369255436803, bpp_loss: 3.6536591723022505, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda200_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_4.97679_bpp_5.524_MSE_0.00426_total_iter_95000.pth.tar/COL_MSE0.02621_bpploss3.6537_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda200_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_4.97679_bpp_5.524_MSE_0.00426_total_iter_95000.pth.tar/COL_MSE0.02495_bpploss3.6532_bpp0
I0303 13:28:42.182340 3224411 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:08,  1.74s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.29it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  2.14it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:00,  3.06it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:02<00:00,  4.98it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]
W0303 13:28:44.617764 3224411 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 13:28:44.631372 3224411 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.265625:   0%|          | 0/166 [00:11<?, ?it/s]avg_loss = 1.265625:   1%|          | 1/166 [00:11<31:16, 11.37s/it]avg_loss = 1.5546875:   1%|          | 1/166 [00:14<31:16, 11.37s/it]avg_loss = 1.5546875:   1%|          | 2/166 [00:14<18:18,  6.70s/it]avg_loss = 1.7239583333333333:   1%|          | 2/166 [00:18<18:18,  6.70s/it]avg_loss = 1.7239583333333333:   2%|▏         | 3/166 [00:18<14:23,  5.30s/it]avg_loss = 1.751953125:   2%|▏         | 3/166 [00:21<14:23,  5.30s/it]       avg_loss = 1.751953125:   2%|▏         | 4/166 [00:21<12:03,  4.47s/it]avg_loss = 1.684375:   2%|▏         | 4/166 [00:24<12:03,  4.47s/it]   avg_loss = 1.684375:   3%|▎         | 5/166 [00:24<10:45,  4.01s/it]avg_loss = 1.6549479166666667:   3%|▎         | 5/166 [00:28<10:45,  4.01s/it]avg_loss = 1.6549479166666667:   4%|▎         | 6/166 [00:28<10:02,  3.77s/it]avg_loss = 1.5915178571428572:   4%|▎         | 6/166 [00:31<10:02,  3.77s/it]avg_loss = 1.5915178571428572:   4%|▍         | 7/166 [00:31<09:39,  3.64s/it]avg_loss = 1.525390625:   4%|▍         | 7/166 [00:34<09:39,  3.64s/it]       avg_loss = 1.525390625:   5%|▍         | 8/166 [00:34<09:17,  3.53s/it]avg_loss = 1.5225694444444444:   5%|▍         | 8/166 [00:38<09:17,  3.53s/it]avg_loss = 1.5225694444444444:   5%|▌         | 9/166 [00:38<09:11,  3.51s/it]avg_loss = 1.53359375:   5%|▌         | 9/166 [00:41<09:11,  3.51s/it]        avg_loss = 1.53359375:   6%|▌         | 10/166 [00:41<09:09,  3.52s/it]avg_loss = 1.5504261363636365:   6%|▌         | 10/166 [00:45<09:09,  3.52s/it]avg_loss = 1.5504261363636365:   7%|▋         | 11/166 [00:45<09:14,  3.58s/it]avg_loss = 1.5598958333333333:   7%|▋         | 11/166 [00:49<09:14,  3.58s/it]avg_loss = 1.5598958333333333:   7%|▋         | 12/166 [00:49<09:14,  3.60s/it]avg_loss = 1.5552884615384615:   7%|▋         | 12/166 [00:52<09:14,  3.60s/it]avg_loss = 1.5552884615384615:   8%|▊         | 13/166 [00:52<09:13,  3.62s/it]avg_loss = 1.5680803571428572:   8%|▊         | 13/166 [00:56<09:13,  3.62s/it]avg_loss = 1.5680803571428572:   8%|▊         | 14/166 [00:56<09:03,  3.58s/it]avg_loss = 1.5848958333333334:   8%|▊         | 14/166 [01:00<09:03,  3.58s/it]avg_loss = 1.5848958333333334:   9%|▉         | 15/166 [01:00<09:06,  3.62s/it]avg_loss = 1.6025390625:   9%|▉         | 15/166 [01:03<09:06,  3.62s/it]      avg_loss = 1.6025390625:  10%|▉         | 16/166 [01:03<09:06,  3.64s/it]avg_loss = 1.6121323529411764:  10%|▉         | 16/166 [01:07<09:06,  3.64s/it]avg_loss = 1.6121323529411764:  10%|█         | 17/166 [01:07<09:10,  3.69s/it]avg_loss = 1.6258680555555556:  10%|█         | 17/166 [01:11<09:10,  3.69s/it]avg_loss = 1.6258680555555556:  11%|█         | 18/166 [01:11<08:58,  3.64s/it]avg_loss = 1.6455592105263157:  11%|█         | 18/166 [01:14<08:58,  3.64s/it]avg_loss = 1.6455592105263157:  11%|█▏        | 19/166 [01:14<08:55,  3.64s/it]avg_loss = 1.65234375:  11%|█▏        | 19/166 [01:18<08:55,  3.64s/it]        avg_loss = 1.65234375:  12%|█▏        | 20/166 [01:18<08:46,  3.61s/it]avg_loss = 1.6529017857142858:  12%|█▏        | 20/166 [01:21<08:46,  3.61s/it]avg_loss = 1.6529017857142858:  13%|█▎        | 21/166 [01:21<08:41,  3.60s/it]avg_loss = 1.6427556818181819:  13%|█▎        | 21/166 [01:25<08:41,  3.60s/it]avg_loss = 1.6427556818181819:  13%|█▎        | 22/166 [01:25<08:31,  3.55s/it]avg_loss = 1.6266983695652173:  13%|█▎        | 22/166 [01:28<08:31,  3.55s/it]avg_loss = 1.6266983695652173:  14%|█▍        | 23/166 [01:28<08:30,  3.57s/it]avg_loss = 1.6344401041666667:  14%|█▍        | 23/166 [01:32<08:30,  3.57s/it]avg_loss = 1.6344401041666667:  14%|█▍        | 24/166 [01:32<08:28,  3.58s/it]avg_loss = 1.641875:  14%|█▍        | 24/166 [01:36<08:28,  3.58s/it]          avg_loss = 1.641875:  15%|█▌        | 25/166 [01:36<08:25,  3.58s/it]avg_loss = 1.6463341346153846:  15%|█▌        | 25/166 [01:39<08:25,  3.58s/it]avg_loss = 1.6463341346153846:  16%|█▌        | 26/166 [01:39<08:08,  3.49s/it]avg_loss = 1.6527777777777777:  16%|█▌        | 26/166 [01:42<08:08,  3.49s/it]avg_loss = 1.6527777777777777:  16%|█▋        | 27/166 [01:42<08:13,  3.55s/it]avg_loss = 1.6548549107142858:  16%|█▋        | 27/166 [01:46<08:13,  3.55s/it]avg_loss = 1.6548549107142858:  17%|█▋        | 28/166 [01:46<08:14,  3.58s/it]avg_loss = 1.6643318965517242:  17%|█▋        | 28/166 [01:50<08:14,  3.58s/it]avg_loss = 1.6643318965517242:  17%|█▋        | 29/166 [01:50<08:20,  3.65s/it]avg_loss = 1.6651041666666666:  17%|█▋        | 29/166 [01:54<08:20,  3.65s/it]avg_loss = 1.6651041666666666:  18%|█▊        | 30/166 [01:54<08:21,  3.68s/it]avg_loss = 1.6794354838709677:  18%|█▊        | 30/166 [01:57<08:21,  3.68s/it]avg_loss = 1.6794354838709677:  19%|█▊        | 31/166 [01:57<08:19,  3.70s/it]avg_loss = 1.6865234375:  19%|█▊        | 31/166 [02:01<08:19,  3.70s/it]      avg_loss = 1.6865234375:  19%|█▉        | 32/166 [02:01<08:17,  3.71s/it]avg_loss = 1.6917613636363635:  19%|█▉        | 32/166 [02:05<08:17,  3.71s/it]avg_loss = 1.6917613636363635:  20%|█▉        | 33/166 [02:05<08:17,  3.74s/it]avg_loss = 1.689797794117647:  20%|█▉        | 33/166 [02:09<08:17,  3.74s/it] avg_loss = 1.689797794117647:  20%|██        | 34/166 [02:09<08:06,  3.68s/it]avg_loss = 1.6832589285714286:  20%|██        | 34/166 [02:12<08:06,  3.68s/it]avg_loss = 1.6832589285714286:  21%|██        | 35/166 [02:12<07:57,  3.65s/it]avg_loss = 1.6733940972222223:  21%|██        | 35/166 [02:16<07:57,  3.65s/it]avg_loss = 1.6733940972222223:  22%|██▏       | 36/166 [02:16<07:50,  3.62s/it]avg_loss = 1.6627956081081081:  22%|██▏       | 36/166 [02:19<07:50,  3.62s/it]avg_loss = 1.6627956081081081:  22%|██▏       | 37/166 [02:19<07:47,  3.62s/it]avg_loss = 1.6595394736842106:  22%|██▏       | 37/166 [02:23<07:47,  3.62s/it]avg_loss = 1.6595394736842106:  23%|██▎       | 38/166 [02:23<07:39,  3.59s/it]avg_loss = 1.6570512820512822:  23%|██▎       | 38/166 [02:26<07:39,  3.59s/it]avg_loss = 1.6570512820512822:  23%|██▎       | 39/166 [02:26<07:31,  3.55s/it]avg_loss = 1.66171875:  23%|██▎       | 39/166 [02:30<07:31,  3.55s/it]        avg_loss = 1.66171875:  24%|██▍       | 40/166 [02:30<07:23,  3.52s/it]avg_loss = 1.6625381097560976:  24%|██▍       | 40/166 [02:33<07:23,  3.52s/it]avg_loss = 1.6625381097560976:  25%|██▍       | 41/166 [02:33<07:22,  3.54s/it]avg_loss = 1.6514136904761905:  25%|██▍       | 41/166 [02:37<07:22,  3.54s/it]avg_loss = 1.6514136904761905:  25%|██▌       | 42/166 [02:37<07:28,  3.62s/it]avg_loss = 1.6364462209302326:  25%|██▌       | 42/166 [02:40<07:28,  3.62s/it]avg_loss = 1.6364462209302326:  26%|██▌       | 43/166 [02:40<07:15,  3.54s/it]avg_loss = 1.6271306818181819:  26%|██▌       | 43/166 [02:44<07:15,  3.54s/it]avg_loss = 1.6271306818181819:  27%|██▋       | 44/166 [02:44<07:04,  3.48s/it]avg_loss = 1.613888888888889:  27%|██▋       | 44/166 [02:48<07:04,  3.48s/it] avg_loss = 1.613888888888889:  27%|██▋       | 45/166 [02:48<07:08,  3.54s/it]avg_loss = 1.6041100543478262:  27%|██▋       | 45/166 [02:51<07:08,  3.54s/it]avg_loss = 1.6041100543478262:  28%|██▊       | 46/166 [02:51<07:07,  3.56s/it]avg_loss = 1.5977393617021276:  28%|██▊       | 46/166 [02:55<07:07,  3.56s/it]avg_loss = 1.5977393617021276:  28%|██▊       | 47/166 [02:55<07:09,  3.61s/it]avg_loss = 1.5986328125:  28%|██▊       | 47/166 [02:58<07:09,  3.61s/it]      avg_loss = 1.5986328125:  29%|██▉       | 48/166 [02:58<07:04,  3.59s/it]avg_loss = 1.6096938775510203:  29%|██▉       | 48/166 [03:02<07:04,  3.59s/it]avg_loss = 1.6096938775510203:  30%|██▉       | 49/166 [03:02<07:03,  3.62s/it]avg_loss = 1.6209375:  30%|██▉       | 49/166 [03:06<07:03,  3.62s/it]         avg_loss = 1.6209375:  30%|███       | 50/166 [03:06<07:00,  3.62s/it]avg_loss = 1.6277573529411764:  30%|███       | 50/166 [03:09<07:00,  3.62s/it]avg_loss = 1.6277573529411764:  31%|███       | 51/166 [03:09<07:00,  3.65s/it]avg_loss = 1.6320612980769231:  31%|███       | 51/166 [03:13<07:00,  3.65s/it]avg_loss = 1.6320612980769231:  31%|███▏      | 52/166 [03:13<06:56,  3.66s/it]avg_loss = 1.635318396226415:  31%|███▏      | 52/166 [03:16<06:56,  3.66s/it] avg_loss = 1.635318396226415:  32%|███▏      | 53/166 [03:16<06:43,  3.57s/it]avg_loss = 1.6368634259259258:  32%|███▏      | 53/166 [03:20<06:43,  3.57s/it]avg_loss = 1.6368634259259258:  33%|███▎      | 54/166 [03:20<06:34,  3.52s/it]avg_loss = 1.6400568181818183:  33%|███▎      | 54/166 [03:24<06:34,  3.52s/it]avg_loss = 1.6400568181818183:  33%|███▎      | 55/166 [03:24<06:35,  3.57s/it]avg_loss = 1.6441127232142858:  33%|███▎      | 55/166 [03:27<06:35,  3.57s/it]avg_loss = 1.6441127232142858:  34%|███▎      | 56/166 [03:27<06:31,  3.56s/it]avg_loss = 1.6396655701754386:  34%|███▎      | 56/166 [03:31<06:31,  3.56s/it]avg_loss = 1.6396655701754386:  34%|███▍      | 57/166 [03:31<06:24,  3.53s/it]avg_loss = 1.6437230603448276:  34%|███▍      | 57/166 [03:34<06:24,  3.53s/it]avg_loss = 1.6437230603448276:  35%|███▍      | 58/166 [03:34<06:16,  3.49s/it]avg_loss = 1.6422139830508475:  35%|███▍      | 58/166 [03:38<06:16,  3.49s/it]avg_loss = 1.6422139830508475:  36%|███▌      | 59/166 [03:38<06:17,  3.53s/it]avg_loss = 1.6377604166666666:  36%|███▌      | 59/166 [03:41<06:17,  3.53s/it]avg_loss = 1.6377604166666666:  36%|███▌      | 60/166 [03:41<06:15,  3.54s/it]avg_loss = 1.634093237704918:  36%|███▌      | 60/166 [03:45<06:15,  3.54s/it] avg_loss = 1.634093237704918:  37%|███▋      | 61/166 [03:45<06:07,  3.50s/it]avg_loss = 1.6305443548387097:  37%|███▋      | 61/166 [03:48<06:07,  3.50s/it]avg_loss = 1.6305443548387097:  37%|███▋      | 62/166 [03:48<06:01,  3.47s/it]avg_loss = 1.624875992063492:  37%|███▋      | 62/166 [03:52<06:01,  3.47s/it] avg_loss = 1.624875992063492:  38%|███▊      | 63/166 [03:52<06:05,  3.55s/it]avg_loss = 1.6207275390625:  38%|███▊      | 63/166 [03:55<06:05,  3.55s/it]  avg_loss = 1.6207275390625:  39%|███▊      | 64/166 [03:55<05:54,  3.47s/it]avg_loss = 1.6137019230769232:  39%|███▊      | 64/166 [03:59<05:54,  3.47s/it]avg_loss = 1.6137019230769232:  39%|███▉      | 65/166 [03:59<06:00,  3.57s/it]avg_loss = 1.6067708333333333:  39%|███▉      | 65/166 [04:01<06:00,  3.57s/it]avg_loss = 1.6067708333333333:  40%|███▉      | 66/166 [04:01<05:27,  3.28s/it]avg_loss = 1.6010960820895523:  40%|███▉      | 66/166 [04:04<05:27,  3.28s/it]avg_loss = 1.6010960820895523:  40%|████      | 67/166 [04:04<05:08,  3.11s/it]avg_loss = 1.6000689338235294:  40%|████      | 67/166 [04:07<05:08,  3.11s/it]avg_loss = 1.6000689338235294:  41%|████      | 68/166 [04:07<04:53,  2.99s/it]avg_loss = 1.6019021739130435:  41%|████      | 68/166 [04:10<04:53,  2.99s/it]avg_loss = 1.6019021739130435:  42%|████▏     | 69/166 [04:10<04:44,  2.93s/it]avg_loss = 1.6050223214285715:  42%|████▏     | 69/166 [04:12<04:44,  2.93s/it]avg_loss = 1.6050223214285715:  42%|████▏     | 70/166 [04:12<04:37,  2.89s/it]avg_loss = 1.6092649647887325:  42%|████▏     | 70/166 [04:15<04:37,  2.89s/it]avg_loss = 1.6092649647887325:  43%|████▎     | 71/166 [04:15<04:31,  2.86s/it]avg_loss = 1.6146918402777777:  43%|████▎     | 71/166 [04:18<04:31,  2.86s/it]avg_loss = 1.6146918402777777:  43%|████▎     | 72/166 [04:18<04:18,  2.75s/it]avg_loss = 1.6210402397260273:  43%|████▎     | 72/166 [04:20<04:18,  2.75s/it]avg_loss = 1.6210402397260273:  44%|████▍     | 73/166 [04:20<04:12,  2.72s/it]avg_loss = 1.615181587837838:  44%|████▍     | 73/166 [04:23<04:12,  2.72s/it] avg_loss = 1.615181587837838:  45%|████▍     | 74/166 [04:23<04:04,  2.66s/it]avg_loss = 1.6107291666666668:  45%|████▍     | 74/166 [04:26<04:04,  2.66s/it]avg_loss = 1.6107291666666668:  45%|████▌     | 75/166 [04:26<04:04,  2.69s/it]avg_loss = 1.609888980263158:  45%|████▌     | 75/166 [04:28<04:04,  2.69s/it] avg_loss = 1.609888980263158:  46%|████▌     | 76/166 [04:28<04:00,  2.67s/it]avg_loss = 1.6065340909090908:  46%|████▌     | 76/166 [04:31<04:00,  2.67s/it]avg_loss = 1.6065340909090908:  46%|████▋     | 77/166 [04:31<03:55,  2.65s/it]avg_loss = 1.603165064102564:  46%|████▋     | 77/166 [04:33<03:55,  2.65s/it] avg_loss = 1.603165064102564:  47%|████▋     | 78/166 [04:33<03:49,  2.60s/it]avg_loss = 1.6005735759493671:  47%|████▋     | 78/166 [04:36<03:49,  2.60s/it]avg_loss = 1.6005735759493671:  48%|████▊     | 79/166 [04:36<03:47,  2.61s/it]avg_loss = 1.59716796875:  48%|████▊     | 79/166 [04:38<03:47,  2.61s/it]     avg_loss = 1.59716796875:  48%|████▊     | 80/166 [04:38<03:41,  2.57s/it]avg_loss = 1.5875771604938271:  48%|████▊     | 80/166 [04:42<03:41,  2.57s/it]avg_loss = 1.5875771604938271:  49%|████▉     | 81/166 [04:42<04:12,  2.97s/it]avg_loss = 1.5891768292682926:  49%|████▉     | 81/166 [04:46<04:12,  2.97s/it]avg_loss = 1.5891768292682926:  49%|████▉     | 82/166 [04:46<04:24,  3.15s/it]avg_loss = 1.5903614457831325:  49%|████▉     | 82/166 [04:48<04:24,  3.15s/it]avg_loss = 1.5903614457831325:  50%|█████     | 83/166 [04:48<04:05,  2.96s/it]avg_loss = 1.5929129464285714:  50%|█████     | 83/166 [04:51<04:05,  2.96s/it]avg_loss = 1.5929129464285714:  51%|█████     | 84/166 [04:51<03:49,  2.80s/it]avg_loss = 1.594485294117647:  51%|█████     | 84/166 [04:54<03:49,  2.80s/it] avg_loss = 1.594485294117647:  51%|█████     | 85/166 [04:54<03:51,  2.86s/it]avg_loss = 1.5933866279069768:  51%|█████     | 85/166 [04:57<03:51,  2.86s/it]avg_loss = 1.5933866279069768:  52%|█████▏    | 86/166 [04:57<03:56,  2.95s/it]avg_loss = 1.59375:  52%|█████▏    | 86/166 [05:00<03:56,  2.95s/it]           avg_loss = 1.59375:  52%|█████▏    | 87/166 [05:00<03:49,  2.90s/it]avg_loss = 1.5943714488636365:  52%|█████▏    | 87/166 [05:03<03:49,  2.90s/it]avg_loss = 1.5943714488636365:  53%|█████▎    | 88/166 [05:03<03:44,  2.88s/it]avg_loss = 1.5955933988764044:  53%|█████▎    | 88/166 [05:05<03:44,  2.88s/it]avg_loss = 1.5955933988764044:  54%|█████▎    | 89/166 [05:05<03:41,  2.88s/it]avg_loss = 1.5954861111111112:  54%|█████▎    | 89/166 [05:09<03:41,  2.88s/it]avg_loss = 1.5954861111111112:  54%|█████▍    | 90/166 [05:09<03:51,  3.04s/it]avg_loss = 1.5963255494505495:  54%|█████▍    | 90/166 [05:12<03:51,  3.04s/it]avg_loss = 1.5963255494505495:  55%|█████▍    | 91/166 [05:12<03:50,  3.08s/it]avg_loss = 1.5967221467391304:  55%|█████▍    | 91/166 [05:15<03:50,  3.08s/it]avg_loss = 1.5967221467391304:  55%|█████▌    | 92/166 [05:15<03:53,  3.15s/it]avg_loss = 1.6000504032258065:  55%|█████▌    | 92/166 [05:19<03:53,  3.15s/it]avg_loss = 1.6000504032258065:  56%|█████▌    | 93/166 [05:19<03:51,  3.17s/it]avg_loss = 1.5994015957446808:  56%|█████▌    | 93/166 [05:21<03:51,  3.17s/it]avg_loss = 1.5994015957446808:  57%|█████▋    | 94/166 [05:21<03:30,  2.93s/it]avg_loss = 1.5986842105263157:  57%|█████▋    | 94/166 [05:23<03:30,  2.93s/it]avg_loss = 1.5986842105263157:  57%|█████▋    | 95/166 [05:23<03:18,  2.80s/it]avg_loss = 1.5982259114583333:  57%|█████▋    | 95/166 [05:26<03:18,  2.80s/it]avg_loss = 1.5982259114583333:  58%|█████▊    | 96/166 [05:26<03:12,  2.75s/it]avg_loss = 1.5974548969072164:  58%|█████▊    | 96/166 [05:29<03:12,  2.75s/it]avg_loss = 1.5974548969072164:  58%|█████▊    | 97/166 [05:29<03:16,  2.85s/it]avg_loss = 1.5958227040816326:  58%|█████▊    | 97/166 [05:32<03:16,  2.85s/it]avg_loss = 1.5958227040816326:  59%|█████▉    | 98/166 [05:32<03:17,  2.91s/it]avg_loss = 1.5936710858585859:  59%|█████▉    | 98/166 [05:35<03:17,  2.91s/it]avg_loss = 1.5936710858585859:  60%|█████▉    | 99/166 [05:35<03:05,  2.76s/it]avg_loss = 1.591015625:  60%|█████▉    | 99/166 [05:37<03:05,  2.76s/it]       avg_loss = 1.591015625:  60%|██████    | 100/166 [05:37<02:53,  2.63s/it]avg_loss = 1.5917388613861385:  60%|██████    | 100/166 [05:39<02:53,  2.63s/it]avg_loss = 1.5917388613861385:  61%|██████    | 101/166 [05:39<02:47,  2.58s/it]avg_loss = 1.5929074754901962:  61%|██████    | 101/166 [05:42<02:47,  2.58s/it]avg_loss = 1.5929074754901962:  61%|██████▏   | 102/166 [05:42<02:40,  2.51s/it]avg_loss = 1.5935224514563107:  61%|██████▏   | 102/166 [05:45<02:40,  2.51s/it]avg_loss = 1.5935224514563107:  62%|██████▏   | 103/166 [05:45<02:45,  2.63s/it]avg_loss = 1.5953275240384615:  62%|██████▏   | 103/166 [05:47<02:45,  2.63s/it]avg_loss = 1.5953275240384615:  63%|██████▎   | 104/166 [05:47<02:41,  2.61s/it]avg_loss = 1.6018601190476192:  63%|██████▎   | 104/166 [05:49<02:41,  2.61s/it]avg_loss = 1.6018601190476192:  63%|██████▎   | 105/166 [05:49<02:32,  2.50s/it]avg_loss = 1.6072376179245282:  63%|██████▎   | 105/166 [05:52<02:32,  2.50s/it]avg_loss = 1.6072376179245282:  64%|██████▍   | 106/166 [05:52<02:25,  2.43s/it]avg_loss = 1.6104702102803738:  64%|██████▍   | 106/166 [05:54<02:25,  2.43s/it]avg_loss = 1.6104702102803738:  64%|██████▍   | 107/166 [05:54<02:21,  2.39s/it]avg_loss = 1.6134259259259258:  64%|██████▍   | 107/166 [05:56<02:21,  2.39s/it]avg_loss = 1.6134259259259258:  65%|██████▌   | 108/166 [05:56<02:17,  2.37s/it]avg_loss = 1.6181192660550459:  65%|██████▌   | 108/166 [05:59<02:17,  2.37s/it]avg_loss = 1.6181192660550459:  66%|██████▌   | 109/166 [05:59<02:16,  2.39s/it]avg_loss = 1.6215198863636364:  66%|██████▌   | 109/166 [06:01<02:16,  2.39s/it]avg_loss = 1.6215198863636364:  66%|██████▋   | 110/166 [06:01<02:14,  2.39s/it]avg_loss = 1.6229588963963963:  66%|██████▋   | 110/166 [06:04<02:14,  2.39s/it]avg_loss = 1.6229588963963963:  67%|██████▋   | 111/166 [06:04<02:13,  2.43s/it]avg_loss = 1.6242327008928572:  67%|██████▋   | 111/166 [06:06<02:13,  2.43s/it]avg_loss = 1.6242327008928572:  67%|██████▋   | 112/166 [06:06<02:09,  2.40s/it]avg_loss = 1.6243086283185841:  67%|██████▋   | 112/166 [06:09<02:09,  2.40s/it]avg_loss = 1.6243086283185841:  68%|██████▊   | 113/166 [06:09<02:08,  2.42s/it]avg_loss = 1.6251370614035088:  68%|██████▊   | 113/166 [06:11<02:08,  2.42s/it]avg_loss = 1.6251370614035088:  69%|██████▊   | 114/166 [06:11<02:05,  2.41s/it]avg_loss = 1.622078804347826:  69%|██████▊   | 114/166 [06:13<02:05,  2.41s/it] avg_loss = 1.622078804347826:  69%|██████▉   | 115/166 [06:13<02:04,  2.45s/it]avg_loss = 1.6213631465517242:  69%|██████▉   | 115/166 [06:16<02:04,  2.45s/it]avg_loss = 1.6213631465517242:  70%|██████▉   | 116/166 [06:16<02:03,  2.47s/it]avg_loss = 1.6225293803418803:  70%|██████▉   | 116/166 [06:18<02:03,  2.47s/it]avg_loss = 1.6225293803418803:  70%|███████   | 117/166 [06:18<02:01,  2.49s/it]avg_loss = 1.6225293803418803:  70%|███████   | 117/166 [06:20<02:39,  3.25s/it]
Traceback (most recent call last):
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 115, in <module>
    main(args)
  File "/home/jgryu/Weight_compression/comp_llm/eval_ppl.py", line 91, in main
    output = model(input,
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 1163, in forward
    outputs = self.model(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 913, in forward
    layer_outputs = decoder_layer(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 656, in forward
    hidden_states = self.mlp(hidden_states)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 242, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 160, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/hooks.py", line 293, in pre_forward
    set_module_tensor_to_device(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 347, in set_module_tensor_to_device
    new_value = value.to(device)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 102.19 MiB is free. Including non-PyTorch memory, this process has 4.46 GiB memory in use. Process 3226676 has 19.00 GiB memory in use. Of the allocated memory 4.08 GiB is allocated by PyTorch, and 145.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda200_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_4.97679_bpp_5.524_MSE_0.00426_total_iter_95000.pth.tar/COL_MSE0.02621_bpploss3.6537_bpp0
I0303 13:35:49.210179 3227633 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:07,  1.43s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.53it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  2.49it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:01<00:00,  3.50it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:01<00:00,  4.50it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  3.07it/s]
W0303 13:35:51.383150 3227633 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 13:35:51.397752 3227633 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.2734375:   0%|          | 0/166 [00:10<?, ?it/s]avg_loss = 1.2734375:   1%|          | 1/166 [00:10<27:59, 10.18s/it]avg_loss = 1.5625:   1%|          | 1/166 [00:12<27:59, 10.18s/it]   avg_loss = 1.5625:   1%|          | 2/166 [00:12<15:15,  5.58s/it]avg_loss = 1.7291666666666667:   1%|          | 2/166 [00:14<15:15,  5.58s/it]avg_loss = 1.7291666666666667:   2%|▏         | 3/166 [00:14<11:01,  4.06s/it]avg_loss = 1.7578125:   2%|▏         | 3/166 [00:17<11:01,  4.06s/it]         avg_loss = 1.7578125:   2%|▏         | 4/166 [00:17<09:04,  3.36s/it]avg_loss = 1.6875:   2%|▏         | 4/166 [00:19<09:04,  3.36s/it]   avg_loss = 1.6875:   3%|▎         | 5/166 [00:19<07:51,  2.93s/it]avg_loss = 1.6575520833333333:   3%|▎         | 5/166 [00:21<07:51,  2.93s/it]avg_loss = 1.6575520833333333:   4%|▎         | 6/166 [00:21<07:18,  2.74s/it]avg_loss = 1.59375:   4%|▎         | 6/166 [00:24<07:18,  2.74s/it]           avg_loss = 1.59375:   4%|▍         | 7/166 [00:24<06:59,  2.64s/it]avg_loss = 1.529296875:   4%|▍         | 7/166 [00:26<06:59,  2.64s/it]avg_loss = 1.529296875:   5%|▍         | 8/166 [00:26<06:33,  2.49s/it]avg_loss = 1.5251736111111112:   5%|▍         | 8/166 [00:28<06:33,  2.49s/it]avg_loss = 1.5251736111111112:   5%|▌         | 9/166 [00:28<06:33,  2.51s/it]avg_loss = 1.53515625:   5%|▌         | 9/166 [00:31<06:33,  2.51s/it]        avg_loss = 1.53515625:   6%|▌         | 10/166 [00:31<06:39,  2.56s/it]avg_loss = 1.5525568181818181:   6%|▌         | 10/166 [00:34<06:39,  2.56s/it]avg_loss = 1.5525568181818181:   7%|▋         | 11/166 [00:34<06:37,  2.57s/it]avg_loss = 1.5631510416666667:   7%|▋         | 11/166 [00:36<06:37,  2.57s/it]avg_loss = 1.5631510416666667:   7%|▋         | 12/166 [00:36<06:27,  2.51s/it]avg_loss = 1.5588942307692308:   7%|▋         | 12/166 [00:38<06:27,  2.51s/it]avg_loss = 1.5588942307692308:   8%|▊         | 13/166 [00:38<06:24,  2.51s/it]avg_loss = 1.5719866071428572:   8%|▊         | 13/166 [00:41<06:24,  2.51s/it]avg_loss = 1.5719866071428572:   8%|▊         | 14/166 [00:41<06:18,  2.49s/it]avg_loss = 1.5880208333333334:   8%|▊         | 14/166 [00:43<06:18,  2.49s/it]avg_loss = 1.5880208333333334:   9%|▉         | 15/166 [00:43<06:15,  2.48s/it]avg_loss = 1.60546875:   9%|▉         | 15/166 [00:46<06:15,  2.48s/it]        avg_loss = 1.60546875:  10%|▉         | 16/166 [00:46<06:12,  2.48s/it]avg_loss = 1.6153492647058822:  10%|▉         | 16/166 [00:48<06:12,  2.48s/it]avg_loss = 1.6153492647058822:  10%|█         | 17/166 [00:48<06:15,  2.52s/it]avg_loss = 1.6293402777777777:  10%|█         | 17/166 [00:51<06:15,  2.52s/it]avg_loss = 1.6293402777777777:  11%|█         | 18/166 [00:51<06:12,  2.51s/it]avg_loss = 1.6484375:  11%|█         | 18/166 [00:53<06:12,  2.51s/it]         avg_loss = 1.6484375:  11%|█▏        | 19/166 [00:53<06:09,  2.51s/it]avg_loss = 1.655078125:  11%|█▏        | 19/166 [00:56<06:09,  2.51s/it]avg_loss = 1.655078125:  12%|█▏        | 20/166 [00:56<06:07,  2.52s/it]avg_loss = 1.6558779761904763:  12%|█▏        | 20/166 [00:59<06:07,  2.52s/it]avg_loss = 1.6558779761904763:  13%|█▎        | 21/166 [00:59<06:12,  2.57s/it]avg_loss = 1.6452414772727273:  13%|█▎        | 21/166 [01:01<06:12,  2.57s/it]avg_loss = 1.6452414772727273:  13%|█▎        | 22/166 [01:01<06:16,  2.62s/it]avg_loss = 1.6294157608695652:  13%|█▎        | 22/166 [01:04<06:16,  2.62s/it]avg_loss = 1.6294157608695652:  14%|█▍        | 23/166 [01:04<06:14,  2.62s/it]avg_loss = 1.63671875:  14%|█▍        | 23/166 [01:07<06:14,  2.62s/it]        avg_loss = 1.63671875:  14%|█▍        | 24/166 [01:07<06:10,  2.61s/it]avg_loss = 1.6440625:  14%|█▍        | 24/166 [01:09<06:10,  2.61s/it] avg_loss = 1.6440625:  15%|█▌        | 25/166 [01:09<06:15,  2.66s/it]avg_loss = 1.6487379807692308:  15%|█▌        | 25/166 [01:12<06:15,  2.66s/it]avg_loss = 1.6487379807692308:  16%|█▌        | 26/166 [01:12<06:13,  2.67s/it]avg_loss = 1.6550925925925926:  16%|█▌        | 26/166 [01:15<06:13,  2.67s/it]avg_loss = 1.6550925925925926:  16%|█▋        | 27/166 [01:15<06:18,  2.72s/it]avg_loss = 1.6573660714285714:  16%|█▋        | 27/166 [01:18<06:18,  2.72s/it]avg_loss = 1.6573660714285714:  17%|█▋        | 28/166 [01:18<06:18,  2.74s/it]avg_loss = 1.6670258620689655:  17%|█▋        | 28/166 [01:20<06:18,  2.74s/it]avg_loss = 1.6670258620689655:  17%|█▋        | 29/166 [01:20<06:13,  2.73s/it]avg_loss = 1.6677083333333333:  17%|█▋        | 29/166 [01:23<06:13,  2.73s/it]avg_loss = 1.6677083333333333:  18%|█▊        | 30/166 [01:23<06:07,  2.70s/it]avg_loss = 1.6824596774193548:  18%|█▊        | 30/166 [01:26<06:07,  2.70s/it]avg_loss = 1.6824596774193548:  19%|█▊        | 31/166 [01:26<06:07,  2.72s/it]avg_loss = 1.689453125:  19%|█▊        | 31/166 [01:28<06:07,  2.72s/it]       avg_loss = 1.689453125:  19%|█▉        | 32/166 [01:28<06:02,  2.71s/it]avg_loss = 1.6943655303030303:  19%|█▉        | 32/166 [01:31<06:02,  2.71s/it]avg_loss = 1.6943655303030303:  20%|█▉        | 33/166 [01:31<06:00,  2.71s/it]avg_loss = 1.6923253676470589:  20%|█▉        | 33/166 [01:34<06:00,  2.71s/it]avg_loss = 1.6923253676470589:  20%|██        | 34/166 [01:34<06:03,  2.75s/it]avg_loss = 1.6854910714285714:  20%|██        | 34/166 [01:37<06:03,  2.75s/it]avg_loss = 1.6854910714285714:  21%|██        | 35/166 [01:37<05:56,  2.72s/it]avg_loss = 1.67578125:  21%|██        | 35/166 [01:39<05:56,  2.72s/it]        avg_loss = 1.67578125:  22%|██▏       | 36/166 [01:39<05:48,  2.68s/it]avg_loss = 1.6649070945945945:  22%|██▏       | 36/166 [01:42<05:48,  2.68s/it]avg_loss = 1.6649070945945945:  22%|██▏       | 37/166 [01:42<05:45,  2.68s/it]avg_loss = 1.661595394736842:  22%|██▏       | 37/166 [01:45<05:45,  2.68s/it] avg_loss = 1.661595394736842:  23%|██▎       | 38/166 [01:45<05:43,  2.68s/it]avg_loss = 1.6592548076923077:  23%|██▎       | 38/166 [01:47<05:43,  2.68s/it]avg_loss = 1.6592548076923077:  23%|██▎       | 39/166 [01:47<05:31,  2.61s/it]avg_loss = 1.663671875:  23%|██▎       | 39/166 [01:50<05:31,  2.61s/it]       avg_loss = 1.663671875:  24%|██▍       | 40/166 [01:50<05:24,  2.58s/it]avg_loss = 1.6644435975609757:  24%|██▍       | 40/166 [01:52<05:24,  2.58s/it]avg_loss = 1.6644435975609757:  25%|██▍       | 41/166 [01:52<05:21,  2.57s/it]avg_loss = 1.6532738095238095:  25%|██▍       | 41/166 [01:55<05:21,  2.57s/it]avg_loss = 1.6532738095238095:  25%|██▌       | 42/166 [01:55<05:19,  2.57s/it]avg_loss = 1.638263081395349:  25%|██▌       | 42/166 [01:57<05:19,  2.57s/it] avg_loss = 1.638263081395349:  26%|██▌       | 43/166 [01:57<05:20,  2.60s/it]avg_loss = 1.62890625:  26%|██▌       | 43/166 [02:00<05:20,  2.60s/it]       avg_loss = 1.62890625:  27%|██▋       | 44/166 [02:00<05:20,  2.63s/it]avg_loss = 1.615625:  27%|██▋       | 44/166 [02:03<05:20,  2.63s/it]  avg_loss = 1.615625:  27%|██▋       | 45/166 [02:03<05:20,  2.65s/it]avg_loss = 1.6056385869565217:  27%|██▋       | 45/166 [02:05<05:20,  2.65s/it]avg_loss = 1.6056385869565217:  28%|██▊       | 46/166 [02:05<05:17,  2.64s/it]avg_loss = 1.5994015957446808:  28%|██▊       | 46/166 [02:08<05:17,  2.64s/it]avg_loss = 1.5994015957446808:  28%|██▊       | 47/166 [02:08<05:14,  2.64s/it]avg_loss = 1.6002604166666667:  28%|██▊       | 47/166 [02:11<05:14,  2.64s/it]avg_loss = 1.6002604166666667:  29%|██▉       | 48/166 [02:11<05:15,  2.68s/it]avg_loss = 1.6112882653061225:  29%|██▉       | 48/166 [02:14<05:15,  2.68s/it]avg_loss = 1.6112882653061225:  30%|██▉       | 49/166 [02:14<05:16,  2.70s/it]avg_loss = 1.6221875:  30%|██▉       | 49/166 [02:16<05:16,  2.70s/it]         avg_loss = 1.6221875:  30%|███       | 50/166 [02:16<05:15,  2.72s/it]avg_loss = 1.6291360294117647:  30%|███       | 50/166 [02:19<05:15,  2.72s/it]avg_loss = 1.6291360294117647:  31%|███       | 51/166 [02:19<05:12,  2.72s/it]avg_loss = 1.6332632211538463:  31%|███       | 51/166 [02:22<05:12,  2.72s/it]avg_loss = 1.6332632211538463:  31%|███▏      | 52/166 [02:22<05:10,  2.73s/it]avg_loss = 1.6364976415094339:  31%|███▏      | 52/166 [02:25<05:10,  2.73s/it]avg_loss = 1.6364976415094339:  32%|███▏      | 53/166 [02:25<05:09,  2.74s/it]avg_loss = 1.6381655092592593:  32%|███▏      | 53/166 [02:27<05:09,  2.74s/it]avg_loss = 1.6381655092592593:  33%|███▎      | 54/166 [02:27<05:04,  2.72s/it]avg_loss = 1.6416193181818182:  33%|███▎      | 54/166 [02:30<05:04,  2.72s/it]avg_loss = 1.6416193181818182:  33%|███▎      | 55/166 [02:30<04:58,  2.69s/it]avg_loss = 1.6457868303571428:  33%|███▎      | 55/166 [02:32<04:58,  2.69s/it]avg_loss = 1.6457868303571428:  34%|███▎      | 56/166 [02:32<04:52,  2.65s/it]avg_loss = 1.6413103070175439:  34%|███▎      | 56/166 [02:35<04:52,  2.65s/it]avg_loss = 1.6413103070175439:  34%|███▍      | 57/166 [02:35<04:48,  2.65s/it]avg_loss = 1.6449353448275863:  34%|███▍      | 57/166 [02:38<04:48,  2.65s/it]avg_loss = 1.6449353448275863:  35%|███▍      | 58/166 [02:38<04:46,  2.66s/it]avg_loss = 1.6434057203389831:  35%|███▍      | 58/166 [02:40<04:46,  2.66s/it]avg_loss = 1.6434057203389831:  36%|███▌      | 59/166 [02:40<04:44,  2.66s/it]avg_loss = 1.6390625:  36%|███▌      | 59/166 [02:43<04:44,  2.66s/it]         avg_loss = 1.6390625:  36%|███▌      | 60/166 [02:43<04:43,  2.67s/it]avg_loss = 1.6352459016393444:  36%|███▌      | 60/166 [02:46<04:43,  2.67s/it]avg_loss = 1.6352459016393444:  37%|███▋      | 61/166 [02:46<04:35,  2.62s/it]avg_loss = 1.6316784274193548:  37%|███▋      | 61/166 [02:48<04:35,  2.62s/it]avg_loss = 1.6316784274193548:  37%|███▋      | 62/166 [02:48<04:30,  2.60s/it]avg_loss = 1.6259920634920635:  37%|███▋      | 62/166 [02:51<04:30,  2.60s/it]avg_loss = 1.6259920634920635:  38%|███▊      | 63/166 [02:51<04:28,  2.60s/it]avg_loss = 1.6217041015625:  38%|███▊      | 63/166 [02:53<04:28,  2.60s/it]   avg_loss = 1.6217041015625:  39%|███▊      | 64/166 [02:53<04:24,  2.60s/it]avg_loss = 1.6147836538461537:  39%|███▊      | 64/166 [02:56<04:24,  2.60s/it]avg_loss = 1.6147836538461537:  39%|███▉      | 65/166 [02:56<04:23,  2.61s/it]avg_loss = 1.6078361742424243:  39%|███▉      | 65/166 [02:59<04:23,  2.61s/it]avg_loss = 1.6078361742424243:  40%|███▉      | 66/166 [02:59<04:19,  2.59s/it]avg_loss = 1.6020289179104477:  40%|███▉      | 66/166 [03:01<04:19,  2.59s/it]avg_loss = 1.6020289179104477:  40%|████      | 67/166 [03:01<04:18,  2.61s/it]avg_loss = 1.6007582720588236:  40%|████      | 67/166 [03:04<04:18,  2.61s/it]avg_loss = 1.6007582720588236:  41%|████      | 68/166 [03:04<04:16,  2.62s/it]avg_loss = 1.6024682971014492:  41%|████      | 68/166 [03:06<04:16,  2.62s/it]avg_loss = 1.6024682971014492:  42%|████▏     | 69/166 [03:06<04:14,  2.63s/it]avg_loss = 1.6058035714285714:  42%|████▏     | 69/166 [03:09<04:14,  2.63s/it]avg_loss = 1.6058035714285714:  42%|████▏     | 70/166 [03:09<04:12,  2.64s/it]avg_loss = 1.6100352112676057:  42%|████▏     | 70/166 [03:12<04:12,  2.64s/it]avg_loss = 1.6100352112676057:  43%|████▎     | 71/166 [03:12<04:09,  2.63s/it]avg_loss = 1.6154513888888888:  43%|████▎     | 71/166 [03:14<04:09,  2.63s/it]avg_loss = 1.6154513888888888:  43%|████▎     | 72/166 [03:14<04:06,  2.62s/it]avg_loss = 1.6220034246575343:  43%|████▎     | 72/166 [03:17<04:06,  2.62s/it]avg_loss = 1.6220034246575343:  44%|████▍     | 73/166 [03:17<04:03,  2.62s/it]avg_loss = 1.6161317567567568:  44%|████▍     | 73/166 [03:20<04:03,  2.62s/it]avg_loss = 1.6161317567567568:  45%|████▍     | 74/166 [03:20<03:59,  2.61s/it]avg_loss = 1.6115625:  45%|████▍     | 74/166 [03:22<03:59,  2.61s/it]         avg_loss = 1.6115625:  45%|████▌     | 75/166 [03:22<04:00,  2.64s/it]avg_loss = 1.610608552631579:  45%|████▌     | 75/166 [03:25<04:00,  2.64s/it]avg_loss = 1.610608552631579:  46%|████▌     | 76/166 [03:25<04:00,  2.67s/it]avg_loss = 1.6072443181818181:  46%|████▌     | 76/166 [03:28<04:00,  2.67s/it]avg_loss = 1.6072443181818181:  46%|████▋     | 77/166 [03:28<03:57,  2.67s/it]avg_loss = 1.6039663461538463:  46%|████▋     | 77/166 [03:30<03:57,  2.67s/it]avg_loss = 1.6039663461538463:  47%|████▋     | 78/166 [03:30<03:54,  2.67s/it]avg_loss = 1.6013647151898733:  47%|████▋     | 78/166 [03:33<03:54,  2.67s/it]avg_loss = 1.6013647151898733:  48%|████▊     | 79/166 [03:33<03:52,  2.68s/it]avg_loss = 1.59794921875:  48%|████▊     | 79/166 [03:36<03:52,  2.68s/it]     avg_loss = 1.59794921875:  48%|████▊     | 80/166 [03:36<03:55,  2.74s/it]avg_loss = 1.5882523148148149:  48%|████▊     | 80/166 [03:39<03:55,  2.74s/it]avg_loss = 1.5882523148148149:  49%|████▉     | 81/166 [03:39<03:54,  2.75s/it]avg_loss = 1.5899390243902438:  49%|████▉     | 81/166 [03:42<03:54,  2.75s/it]avg_loss = 1.5899390243902438:  49%|████▉     | 82/166 [03:42<03:55,  2.80s/it]avg_loss = 1.5910203313253013:  49%|████▉     | 82/166 [03:44<03:55,  2.80s/it]avg_loss = 1.5910203313253013:  50%|█████     | 83/166 [03:44<03:48,  2.75s/it]avg_loss = 1.593656994047619:  50%|█████     | 83/166 [03:47<03:48,  2.75s/it] avg_loss = 1.593656994047619:  51%|█████     | 84/166 [03:47<03:39,  2.68s/it]avg_loss = 1.5951286764705883:  51%|█████     | 84/166 [03:50<03:39,  2.68s/it]avg_loss = 1.5951286764705883:  51%|█████     | 85/166 [03:50<03:38,  2.70s/it]avg_loss = 1.5940225290697674:  51%|█████     | 85/166 [03:52<03:38,  2.70s/it]avg_loss = 1.5940225290697674:  52%|█████▏    | 86/166 [03:52<03:33,  2.67s/it]avg_loss = 1.594378591954023:  52%|█████▏    | 86/166 [03:55<03:33,  2.67s/it] avg_loss = 1.594378591954023:  52%|█████▏    | 87/166 [03:55<03:35,  2.72s/it]avg_loss = 1.5949041193181819:  52%|█████▏    | 87/166 [03:58<03:35,  2.72s/it]avg_loss = 1.5949041193181819:  53%|█████▎    | 88/166 [03:58<03:35,  2.76s/it]avg_loss = 1.5960323033707866:  53%|█████▎    | 88/166 [04:01<03:35,  2.76s/it]avg_loss = 1.5960323033707866:  54%|█████▎    | 89/166 [04:01<03:34,  2.79s/it]avg_loss = 1.5959201388888888:  54%|█████▎    | 89/166 [04:03<03:34,  2.79s/it]avg_loss = 1.5959201388888888:  54%|█████▍    | 90/166 [04:03<03:28,  2.74s/it]avg_loss = 1.5967548076923077:  54%|█████▍    | 90/166 [04:06<03:28,  2.74s/it]avg_loss = 1.5967548076923077:  55%|█████▍    | 91/166 [04:06<03:22,  2.71s/it]avg_loss = 1.5971467391304348:  55%|█████▍    | 91/166 [04:09<03:22,  2.71s/it]avg_loss = 1.5971467391304348:  55%|█████▌    | 92/166 [04:09<03:19,  2.70s/it]avg_loss = 1.600554435483871:  55%|█████▌    | 92/166 [04:11<03:19,  2.70s/it] avg_loss = 1.600554435483871:  56%|█████▌    | 93/166 [04:11<03:16,  2.69s/it]avg_loss = 1.5999002659574468:  56%|█████▌    | 93/166 [04:14<03:16,  2.69s/it]avg_loss = 1.5999002659574468:  57%|█████▋    | 94/166 [04:14<03:11,  2.66s/it]avg_loss = 1.5993421052631578:  57%|█████▋    | 94/166 [04:17<03:11,  2.66s/it]avg_loss = 1.5993421052631578:  57%|█████▋    | 95/166 [04:17<03:09,  2.67s/it]avg_loss = 1.5987955729166667:  57%|█████▋    | 95/166 [04:19<03:09,  2.67s/it]avg_loss = 1.5987955729166667:  58%|█████▊    | 96/166 [04:19<03:07,  2.68s/it]avg_loss = 1.5980186855670102:  58%|█████▊    | 96/166 [04:22<03:07,  2.68s/it]avg_loss = 1.5980186855670102:  58%|█████▊    | 97/166 [04:22<03:04,  2.68s/it]avg_loss = 1.5964604591836735:  58%|█████▊    | 97/166 [04:25<03:04,  2.68s/it]avg_loss = 1.5964604591836735:  59%|█████▉    | 98/166 [04:25<03:03,  2.70s/it]avg_loss = 1.5941445707070707:  59%|█████▉    | 98/166 [04:27<03:03,  2.70s/it]avg_loss = 1.5941445707070707:  60%|█████▉    | 99/166 [04:27<03:01,  2.71s/it]avg_loss = 1.591484375:  60%|█████▉    | 99/166 [04:30<03:01,  2.71s/it]       avg_loss = 1.591484375:  60%|██████    | 100/166 [04:30<02:56,  2.68s/it]avg_loss = 1.592125618811881:  60%|██████    | 100/166 [04:33<02:56,  2.68s/it]avg_loss = 1.592125618811881:  61%|██████    | 101/166 [04:33<02:56,  2.72s/it]avg_loss = 1.5932904411764706:  61%|██████    | 101/166 [04:36<02:56,  2.72s/it]avg_loss = 1.5932904411764706:  61%|██████▏   | 102/166 [04:36<02:55,  2.74s/it]avg_loss = 1.5939016990291262:  61%|██████▏   | 102/166 [04:38<02:55,  2.74s/it]avg_loss = 1.5939016990291262:  62%|██████▏   | 103/166 [04:38<02:51,  2.72s/it]avg_loss = 1.595703125:  62%|██████▏   | 103/166 [04:41<02:51,  2.72s/it]       avg_loss = 1.595703125:  63%|██████▎   | 104/166 [04:41<02:53,  2.80s/it]avg_loss = 1.6022321428571429:  63%|██████▎   | 104/166 [04:44<02:53,  2.80s/it]avg_loss = 1.6022321428571429:  63%|██████▎   | 105/166 [04:44<02:48,  2.76s/it]avg_loss = 1.6076061320754718:  63%|██████▎   | 105/166 [04:47<02:48,  2.76s/it]avg_loss = 1.6076061320754718:  64%|██████▍   | 106/166 [04:47<02:43,  2.73s/it]avg_loss = 1.6107622663551402:  64%|██████▍   | 106/166 [04:49<02:43,  2.73s/it]avg_loss = 1.6107622663551402:  64%|██████▍   | 107/166 [04:49<02:37,  2.67s/it]avg_loss = 1.6137152777777777:  64%|██████▍   | 107/166 [04:52<02:37,  2.67s/it]avg_loss = 1.6137152777777777:  65%|██████▌   | 108/166 [04:52<02:32,  2.62s/it]avg_loss = 1.6184059633027523:  65%|██████▌   | 108/166 [04:54<02:32,  2.62s/it]avg_loss = 1.6184059633027523:  66%|██████▌   | 109/166 [04:54<02:29,  2.62s/it]avg_loss = 1.621875:  66%|██████▌   | 109/166 [04:57<02:29,  2.62s/it]          avg_loss = 1.621875:  66%|██████▋   | 110/166 [04:57<02:27,  2.63s/it]avg_loss = 1.623240427927928:  66%|██████▋   | 110/166 [05:00<02:27,  2.63s/it]avg_loss = 1.623240427927928:  67%|██████▋   | 111/166 [05:00<02:25,  2.64s/it]avg_loss = 1.62451171875:  67%|██████▋   | 111/166 [05:02<02:25,  2.64s/it]    avg_loss = 1.62451171875:  67%|██████▋   | 112/166 [05:02<02:22,  2.63s/it]avg_loss = 1.624654314159292:  67%|██████▋   | 112/166 [05:05<02:22,  2.63s/it]avg_loss = 1.624654314159292:  68%|██████▊   | 113/166 [05:05<02:18,  2.62s/it]avg_loss = 1.6254797149122806:  68%|██████▊   | 113/166 [05:07<02:18,  2.62s/it]avg_loss = 1.6254797149122806:  69%|██████▊   | 114/166 [05:07<02:16,  2.62s/it]avg_loss = 1.6224184782608695:  69%|██████▊   | 114/166 [05:10<02:16,  2.62s/it]avg_loss = 1.6224184782608695:  69%|██████▉   | 115/166 [05:10<02:15,  2.65s/it]avg_loss = 1.6218345905172413:  69%|██████▉   | 115/166 [05:13<02:15,  2.65s/it]avg_loss = 1.6218345905172413:  70%|██████▉   | 116/166 [05:13<02:11,  2.64s/it]avg_loss = 1.622996794871795:  70%|██████▉   | 116/166 [05:15<02:11,  2.64s/it] avg_loss = 1.622996794871795:  70%|███████   | 117/166 [05:15<02:08,  2.63s/it]avg_loss = 1.62255031779661:  70%|███████   | 117/166 [05:18<02:08,  2.63s/it] avg_loss = 1.62255031779661:  71%|███████   | 118/166 [05:18<02:06,  2.64s/it]avg_loss = 1.6215204831932772:  71%|███████   | 118/166 [05:21<02:06,  2.64s/it]avg_loss = 1.6215204831932772:  72%|███████▏  | 119/166 [05:21<02:04,  2.64s/it]avg_loss = 1.6216145833333333:  72%|███████▏  | 119/166 [05:23<02:04,  2.64s/it]avg_loss = 1.6216145833333333:  72%|███████▏  | 120/166 [05:23<02:01,  2.63s/it]avg_loss = 1.6202221074380165:  72%|███████▏  | 120/166 [05:26<02:01,  2.63s/it]avg_loss = 1.6202221074380165:  73%|███████▎  | 121/166 [05:26<01:58,  2.63s/it]avg_loss = 1.619748975409836:  73%|███████▎  | 121/166 [05:28<01:58,  2.63s/it] avg_loss = 1.619748975409836:  73%|███████▎  | 122/166 [05:28<01:55,  2.62s/it]avg_loss = 1.619728150406504:  73%|███████▎  | 122/166 [05:31<01:55,  2.62s/it]avg_loss = 1.619728150406504:  74%|███████▍  | 123/166 [05:31<01:52,  2.63s/it]avg_loss = 1.6175655241935485:  74%|███████▍  | 123/166 [05:34<01:52,  2.63s/it]avg_loss = 1.6175655241935485:  75%|███████▍  | 124/166 [05:34<01:50,  2.64s/it]avg_loss = 1.6154375:  75%|███████▍  | 124/166 [05:36<01:50,  2.64s/it]         avg_loss = 1.6154375:  75%|███████▌  | 125/166 [05:36<01:47,  2.62s/it]avg_loss = 1.6127852182539681:  75%|███████▌  | 125/166 [05:39<01:47,  2.62s/it]avg_loss = 1.6127852182539681:  76%|███████▌  | 126/166 [05:39<01:46,  2.67s/it]avg_loss = 1.6101747047244095:  76%|███████▌  | 126/166 [05:42<01:46,  2.67s/it]avg_loss = 1.6101747047244095:  77%|███████▋  | 127/166 [05:42<01:42,  2.63s/it]avg_loss = 1.60833740234375:  77%|███████▋  | 127/166 [05:44<01:42,  2.63s/it]  avg_loss = 1.60833740234375:  77%|███████▋  | 128/166 [05:44<01:38,  2.59s/it]avg_loss = 1.606952519379845:  77%|███████▋  | 128/166 [05:47<01:38,  2.59s/it]avg_loss = 1.606952519379845:  78%|███████▊  | 129/166 [05:47<01:37,  2.63s/it]avg_loss = 1.6069110576923078:  78%|███████▊  | 129/166 [05:49<01:37,  2.63s/it]avg_loss = 1.6069110576923078:  78%|███████▊  | 130/166 [05:49<01:33,  2.59s/it]avg_loss = 1.6080033396946565:  78%|███████▊  | 130/166 [05:52<01:33,  2.59s/it]avg_loss = 1.6080033396946565:  79%|███████▉  | 131/166 [05:52<01:31,  2.62s/it]avg_loss = 1.6084280303030303:  79%|███████▉  | 131/166 [05:55<01:31,  2.62s/it]avg_loss = 1.6084280303030303:  80%|███████▉  | 132/166 [05:55<01:30,  2.66s/it]avg_loss = 1.6093162593984962:  80%|███████▉  | 132/166 [05:58<01:30,  2.66s/it]avg_loss = 1.6093162593984962:  80%|████████  | 133/166 [05:58<01:28,  2.70s/it]avg_loss = 1.6106576492537314:  80%|████████  | 133/166 [06:00<01:28,  2.70s/it]avg_loss = 1.6106576492537314:  81%|████████  | 134/166 [06:00<01:26,  2.70s/it]avg_loss = 1.6088541666666667:  81%|████████  | 134/166 [06:03<01:26,  2.70s/it]avg_loss = 1.6088541666666667:  81%|████████▏ | 135/166 [06:03<01:24,  2.73s/it]avg_loss = 1.6092601102941178:  81%|████████▏ | 135/166 [06:06<01:24,  2.73s/it]avg_loss = 1.6092601102941178:  82%|████████▏ | 136/166 [06:06<01:21,  2.71s/it]avg_loss = 1.6097171532846715:  82%|████████▏ | 136/166 [06:08<01:21,  2.71s/it]avg_loss = 1.6097171532846715:  83%|████████▎ | 137/166 [06:08<01:18,  2.69s/it]avg_loss = 1.6105072463768115:  83%|████████▎ | 137/166 [06:11<01:18,  2.69s/it]avg_loss = 1.6105072463768115:  83%|████████▎ | 138/166 [06:11<01:15,  2.71s/it]avg_loss = 1.6099932553956835:  83%|████████▎ | 138/166 [06:14<01:15,  2.71s/it]avg_loss = 1.6099932553956835:  84%|████████▎ | 139/166 [06:14<01:12,  2.70s/it]avg_loss = 1.6089285714285715:  84%|████████▎ | 139/166 [06:17<01:12,  2.70s/it]avg_loss = 1.6089285714285715:  84%|████████▍ | 140/166 [06:17<01:10,  2.73s/it]avg_loss = 1.6077681737588652:  84%|████████▍ | 140/166 [06:19<01:10,  2.73s/it]avg_loss = 1.6077681737588652:  85%|████████▍ | 141/166 [06:19<01:08,  2.74s/it]avg_loss = 1.607449383802817:  85%|████████▍ | 141/166 [06:22<01:08,  2.74s/it] avg_loss = 1.607449383802817:  86%|████████▌ | 142/166 [06:22<01:05,  2.75s/it]avg_loss = 1.6057692307692308:  86%|████████▌ | 142/166 [06:25<01:05,  2.75s/it]avg_loss = 1.6057692307692308:  86%|████████▌ | 143/166 [06:25<01:02,  2.71s/it]avg_loss = 1.6070421006944444:  86%|████████▌ | 143/166 [06:27<01:02,  2.71s/it]avg_loss = 1.6070421006944444:  87%|████████▋ | 144/166 [06:27<00:58,  2.67s/it]avg_loss = 1.6066271551724138:  87%|████████▋ | 144/166 [06:30<00:58,  2.67s/it]avg_loss = 1.6066271551724138:  87%|████████▋ | 145/166 [06:30<00:55,  2.66s/it]avg_loss = 1.6067529965753424:  87%|████████▋ | 145/166 [06:33<00:55,  2.66s/it]avg_loss = 1.6067529965753424:  88%|████████▊ | 146/166 [06:33<00:52,  2.64s/it]avg_loss = 1.6056547619047619:  88%|████████▊ | 146/166 [06:35<00:52,  2.64s/it]avg_loss = 1.6056547619047619:  89%|████████▊ | 147/166 [06:35<00:50,  2.63s/it]avg_loss = 1.6047825168918919:  89%|████████▊ | 147/166 [06:38<00:50,  2.63s/it]avg_loss = 1.6047825168918919:  89%|████████▉ | 148/166 [06:38<00:48,  2.67s/it]avg_loss = 1.6032927852348993:  89%|████████▉ | 148/166 [06:41<00:48,  2.67s/it]avg_loss = 1.6032927852348993:  90%|████████▉ | 149/166 [06:41<00:44,  2.63s/it]avg_loss = 1.6043229166666666:  90%|████████▉ | 149/166 [06:43<00:44,  2.63s/it]avg_loss = 1.6043229166666666:  90%|█████████ | 150/166 [06:43<00:41,  2.60s/it]avg_loss = 1.603425082781457:  90%|█████████ | 150/166 [06:46<00:41,  2.60s/it] avg_loss = 1.603425082781457:  91%|█████████ | 151/166 [06:46<00:39,  2.61s/it]avg_loss = 1.603258634868421:  91%|█████████ | 151/166 [06:48<00:39,  2.61s/it]avg_loss = 1.603258634868421:  92%|█████████▏| 152/166 [06:48<00:36,  2.61s/it]avg_loss = 1.6032986111111112:  92%|█████████▏| 152/166 [06:51<00:36,  2.61s/it]avg_loss = 1.6032986111111112:  92%|█████████▏| 153/166 [06:51<00:34,  2.63s/it]avg_loss = 1.6050121753246753:  92%|█████████▏| 153/166 [06:54<00:34,  2.63s/it]avg_loss = 1.6050121753246753:  93%|█████████▎| 154/166 [06:54<00:31,  2.66s/it]avg_loss = 1.6046875:  93%|█████████▎| 154/166 [06:56<00:31,  2.66s/it]         avg_loss = 1.6046875:  93%|█████████▎| 155/166 [06:56<00:29,  2.67s/it]avg_loss = 1.6046674679487178:  93%|█████████▎| 155/166 [06:59<00:29,  2.67s/it]avg_loss = 1.6046674679487178:  94%|█████████▍| 156/166 [06:59<00:26,  2.68s/it]avg_loss = 1.602906050955414:  94%|█████████▍| 156/166 [07:02<00:26,  2.68s/it] avg_loss = 1.602906050955414:  95%|█████████▍| 157/166 [07:02<00:24,  2.70s/it]avg_loss = 1.5988429588607596:  95%|█████████▍| 157/166 [07:05<00:24,  2.70s/it]avg_loss = 1.5988429588607596:  95%|█████████▌| 158/166 [07:05<00:22,  2.75s/it]avg_loss = 1.599498820754717:  95%|█████████▌| 158/166 [07:07<00:22,  2.75s/it] avg_loss = 1.599498820754717:  96%|█████████▌| 159/166 [07:07<00:19,  2.73s/it]avg_loss = 1.601025390625:  96%|█████████▌| 159/166 [07:10<00:19,  2.73s/it]   avg_loss = 1.601025390625:  96%|█████████▋| 160/166 [07:10<00:16,  2.71s/it]avg_loss = 1.60350349378882:  96%|█████████▋| 160/166 [07:13<00:16,  2.71s/it]avg_loss = 1.60350349378882:  97%|█████████▋| 161/166 [07:13<00:13,  2.66s/it]avg_loss = 1.6033468364197532:  97%|█████████▋| 161/166 [07:15<00:13,  2.66s/it]avg_loss = 1.6033468364197532:  98%|█████████▊| 162/166 [07:15<00:10,  2.66s/it]avg_loss = 1.6028086656441718:  98%|█████████▊| 162/166 [07:18<00:10,  2.66s/it]avg_loss = 1.6028086656441718:  98%|█████████▊| 163/166 [07:18<00:08,  2.67s/it]avg_loss = 1.603563262195122:  98%|█████████▊| 163/166 [07:21<00:08,  2.67s/it] avg_loss = 1.603563262195122:  99%|█████████▉| 164/166 [07:21<00:05,  2.67s/it]avg_loss = 1.6033617424242423:  99%|█████████▉| 164/166 [07:23<00:05,  2.67s/it]avg_loss = 1.6033617424242423:  99%|█████████▉| 165/166 [07:23<00:02,  2.68s/it]avg_loss = 1.6052804969879517:  99%|█████████▉| 165/166 [07:26<00:02,  2.68s/it]avg_loss = 1.6052804969879517: 100%|██████████| 166/166 [07:26<00:00,  2.64s/it]avg_loss = 1.6052804969879517: 100%|██████████| 166/166 [07:26<00:00,  2.69s/it]
I0303 13:44:02.501162 3227633 eval_ppl.py:105] wikitext2 perplexity: 4.9792561531066895
wikitext2 perplexity: 4.979
Running with lmbda=300
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  9.22it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00, 10.05it/s]Loading checkpoint shards:  36%|███▋      | 4/11 [00:00<00:00,  9.50it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00,  9.65it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00,  9.91it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00,  9.90it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.12it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.94it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:22,  1.70it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:01<00:22,  1.70it/s]calculating model weight mean & std:   8%|▊         | 3/40 [00:01<00:21,  1.72it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:02<00:20,  1.72it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:03<00:27,  1.28it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:04<00:24,  1.40it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:04<00:24,  1.37it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:05<00:21,  1.47it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:06<00:21,  1.48it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:06<00:22,  1.33it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:07<00:22,  1.26it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:08<00:22,  1.27it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:09<00:19,  1.37it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:09<00:17,  1.48it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:10<00:15,  1.58it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:10<00:14,  1.63it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:11<00:14,  1.62it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:12<00:13,  1.62it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:12<00:12,  1.62it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:13<00:13,  1.51it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:14<00:14,  1.36it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:15<00:13,  1.31it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:16<00:13,  1.24it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:17<00:13,  1.18it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:17<00:12,  1.21it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:18<00:11,  1.18it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:19<00:11,  1.09it/s]calculating model weight mean & std:  70%|███████   | 28/40 [00:20<00:09,  1.21it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:21<00:08,  1.30it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:21<00:06,  1.43it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:22<00:05,  1.54it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:22<00:04,  1.63it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:23<00:04,  1.71it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:23<00:03,  1.77it/s]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:24<00:02,  1.82it/s]calculating model weight mean & std:  90%|█████████ | 36/40 [00:24<00:02,  1.83it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:25<00:01,  1.86it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:25<00:01,  1.88it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:26<00:00,  1.84it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:26<00:00,  1.82it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:26<00:00,  1.48it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 13:45:16 - INFO - layer0_self_attn.q_proj | mse: 0.23115439808011373, bpp_loss: 3.479998795427382, bpp: 0
2025-03-03 13:45:31 - INFO - layer0_self_attn.k_proj | mse: 0.1350839498693881, bpp_loss: 3.5293679714575408, bpp: 0
2025-03-03 13:45:49 - INFO - layer0_self_attn.v_proj | mse: 0.03582289458090097, bpp_loss: 3.3869281841441987, bpp: 0
2025-03-03 13:46:02 - INFO - layer0_self_attn.o_proj | mse: 0.03967212505048152, bpp_loss: 3.3061484168842434, bpp: 0
2025-03-03 13:46:18 - INFO - layer0_mlp.gate_proj | mse: 0.022321047751384607, bpp_loss: 3.7069849591012356, bpp: 0
2025-03-03 13:46:35 - INFO - layer0_mlp.up_proj | mse: 0.022283188254864764, bpp_loss: 3.6800380659324152, bpp: 0
2025-03-03 13:47:22 - INFO - layer0_mlp.down_proj | mse: 0.04278239022780705, bpp_loss: 3.7970743137929173, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [02:20<1:31:33, 140.87s/it]2025-03-03 13:47:37 - INFO - layer1_self_attn.q_proj | mse: 0.03469880498178003, bpp_loss: 3.9345455045253037, bpp: 0
2025-03-03 13:47:52 - INFO - layer1_self_attn.k_proj | mse: 0.03499390098259962, bpp_loss: 3.9710615599900483, bpp: 0
2025-03-03 13:48:10 - INFO - layer1_self_attn.v_proj | mse: 0.0323292336740265, bpp_loss: 3.455948858894408, bpp: 0
2025-03-03 13:48:23 - INFO - layer1_self_attn.o_proj | mse: 0.088863021617768, bpp_loss: 3.437189824543893, bpp: 0
2025-03-03 13:48:40 - INFO - layer1_mlp.gate_proj | mse: 0.02557832413073733, bpp_loss: 3.8842284636916937, bpp: 0
2025-03-03 13:48:56 - INFO - layer1_mlp.up_proj | mse: 0.025469206485866775, bpp_loss: 3.8185200450596986, bpp: 0
2025-03-03 13:49:43 - INFO - layer1_mlp.down_proj | mse: 0.018834444400730357, bpp_loss: 3.850981622741178, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [04:42<1:29:23, 141.14s/it]2025-03-03 13:49:59 - INFO - layer2_self_attn.q_proj | mse: 0.022199893516965333, bpp_loss: 4.277031178511679, bpp: 0
2025-03-03 13:50:14 - INFO - layer2_self_attn.k_proj | mse: 0.022338834751546174, bpp_loss: 4.322955808341503, bpp: 0
2025-03-03 13:50:31 - INFO - layer2_self_attn.v_proj | mse: 0.021102130386609012, bpp_loss: 3.585783266201615, bpp: 0
2025-03-03 13:50:45 - INFO - layer2_self_attn.o_proj | mse: 0.026293695564952934, bpp_loss: 3.580556314736605, bpp: 0
2025-03-03 13:51:02 - INFO - layer2_mlp.gate_proj | mse: 0.021336060831516068, bpp_loss: 3.9457747421330875, bpp: 0
2025-03-03 13:51:18 - INFO - layer2_mlp.up_proj | mse: 0.021218047592110247, bpp_loss: 3.848029548978364, bpp: 0
2025-03-03 13:52:04 - INFO - layer2_mlp.down_proj | mse: 0.016746943509709344, bpp_loss: 3.86410999322931, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [07:03<1:27:08, 141.32s/it]2025-03-03 13:52:21 - INFO - layer3_self_attn.q_proj | mse: 0.01967687629365726, bpp_loss: 4.337135780155659, bpp: 0
2025-03-03 13:52:35 - INFO - layer3_self_attn.k_proj | mse: 0.019876248445657975, bpp_loss: 4.4161443991214036, bpp: 0
2025-03-03 13:52:53 - INFO - layer3_self_attn.v_proj | mse: 0.018674927863374786, bpp_loss: 3.62585661418736, bpp: 0
2025-03-03 13:53:07 - INFO - layer3_self_attn.o_proj | mse: 0.01915132588699022, bpp_loss: 3.600086725279689, bpp: 0
2025-03-03 13:53:24 - INFO - layer3_mlp.gate_proj | mse: 0.019113085131084395, bpp_loss: 3.961867528105224, bpp: 0
2025-03-03 13:53:40 - INFO - layer3_mlp.up_proj | mse: 0.01900827176184662, bpp_loss: 3.859342512709123, bpp: 0
2025-03-03 13:54:26 - INFO - layer3_mlp.down_proj | mse: 0.024831692997744625, bpp_loss: 3.8639796237702724, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [09:25<1:24:54, 141.50s/it]2025-03-03 13:54:42 - INFO - layer4_self_attn.q_proj | mse: 0.018593504743732718, bpp_loss: 4.279462812654674, bpp: 0
2025-03-03 13:54:57 - INFO - layer4_self_attn.k_proj | mse: 0.018621954165292276, bpp_loss: 4.296552958525718, bpp: 0
2025-03-03 13:55:14 - INFO - layer4_self_attn.v_proj | mse: 0.01778548109836663, bpp_loss: 3.614838889427483, bpp: 0
2025-03-03 13:55:29 - INFO - layer4_self_attn.o_proj | mse: 0.017274211025696703, bpp_loss: 3.6107744336128236, bpp: 0
2025-03-03 13:55:45 - INFO - layer4_mlp.gate_proj | mse: 0.018334171930845845, bpp_loss: 3.969590261247423, bpp: 0
2025-03-03 13:56:02 - INFO - layer4_mlp.up_proj | mse: 0.01821446939372837, bpp_loss: 3.8617329562151874, bpp: 0
2025-03-03 13:56:48 - INFO - layer4_mlp.down_proj | mse: 0.01611126078081454, bpp_loss: 3.8663924982150397, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [11:47<1:22:38, 141.68s/it]2025-03-03 13:57:05 - INFO - layer5_self_attn.q_proj | mse: 0.018023986037869692, bpp_loss: 4.239229910261929, bpp: 0
2025-03-03 13:57:19 - INFO - layer5_self_attn.k_proj | mse: 0.01802766273253553, bpp_loss: 4.23053686350584, bpp: 0
2025-03-03 13:57:36 - INFO - layer5_self_attn.v_proj | mse: 0.017294189031256155, bpp_loss: 3.6358339676260947, bpp: 0
2025-03-03 13:57:51 - INFO - layer5_self_attn.o_proj | mse: 0.018929587639299143, bpp_loss: 3.6270850136876107, bpp: 0
2025-03-03 13:58:08 - INFO - layer5_mlp.gate_proj | mse: 0.01806157284328332, bpp_loss: 3.9851804532386637, bpp: 0
2025-03-03 13:58:24 - INFO - layer5_mlp.up_proj | mse: 0.01788596553921234, bpp_loss: 3.8598323133808594, bpp: 0
2025-03-03 13:59:10 - INFO - layer5_mlp.down_proj | mse: 0.016077362206734048, bpp_loss: 3.863976329703022, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [14:09<1:20:21, 141.80s/it]2025-03-03 13:59:27 - INFO - layer6_self_attn.q_proj | mse: 0.017679047926103548, bpp_loss: 4.25972059648484, bpp: 0
2025-03-03 13:59:41 - INFO - layer6_self_attn.k_proj | mse: 0.01772414908482593, bpp_loss: 4.285093956515193, bpp: 0
2025-03-03 13:59:58 - INFO - layer6_self_attn.v_proj | mse: 0.016992218000773978, bpp_loss: 3.658824255950749, bpp: 0
2025-03-03 14:00:13 - INFO - layer6_self_attn.o_proj | mse: 0.01745179927168183, bpp_loss: 3.6537605445086956, bpp: 0
2025-03-03 14:00:30 - INFO - layer6_mlp.gate_proj | mse: 0.017342740958243095, bpp_loss: 3.998629664215777, bpp: 0
2025-03-03 14:00:47 - INFO - layer6_mlp.up_proj | mse: 0.017201690092971213, bpp_loss: 3.8566288970686773, bpp: 0
2025-03-03 14:01:33 - INFO - layer6_mlp.down_proj | mse: 0.016049076770659674, bpp_loss: 3.85911784183096, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [16:31<1:18:06, 142.01s/it]2025-03-03 14:01:49 - INFO - layer7_self_attn.q_proj | mse: 0.017500482565600575, bpp_loss: 4.287696583345532, bpp: 0
2025-03-03 14:02:03 - INFO - layer7_self_attn.k_proj | mse: 0.01756321443011087, bpp_loss: 4.312258780114353, bpp: 0
2025-03-03 14:02:20 - INFO - layer7_self_attn.v_proj | mse: 0.01681730893975715, bpp_loss: 3.676238604299724, bpp: 0
2025-03-03 14:02:36 - INFO - layer7_self_attn.o_proj | mse: 0.017362535132502785, bpp_loss: 3.667218689098954, bpp: 0
2025-03-03 14:02:53 - INFO - layer7_mlp.gate_proj | mse: 0.01710590691272052, bpp_loss: 4.003936790481761, bpp: 0
2025-03-03 14:03:09 - INFO - layer7_mlp.up_proj | mse: 0.01696121650359833, bpp_loss: 3.8580381723465744, bpp: 0
2025-03-03 14:03:55 - INFO - layer7_mlp.down_proj | mse: 0.01611629296521738, bpp_loss: 3.8577022693223424, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [18:54<1:15:49, 142.18s/it]2025-03-03 14:04:12 - INFO - layer8_self_attn.q_proj | mse: 0.017362451697676785, bpp_loss: 4.25066976800561, bpp: 0
2025-03-03 14:04:26 - INFO - layer8_self_attn.k_proj | mse: 0.017439895903172162, bpp_loss: 4.275365924537182, bpp: 0
2025-03-03 14:04:42 - INFO - layer8_self_attn.v_proj | mse: 0.016737452540736684, bpp_loss: 3.683981003463268, bpp: 0
2025-03-03 14:04:58 - INFO - layer8_self_attn.o_proj | mse: 0.01749876380818493, bpp_loss: 3.6767664501070976, bpp: 0
2025-03-03 14:05:15 - INFO - layer8_mlp.gate_proj | mse: 0.017006385302899815, bpp_loss: 3.999573186757388, bpp: 0
2025-03-03 14:05:32 - INFO - layer8_mlp.up_proj | mse: 0.016880792198395937, bpp_loss: 3.8690762969078842, bpp: 0
2025-03-03 14:06:18 - INFO - layer8_mlp.down_proj | mse: 0.016053790323299014, bpp_loss: 3.866972863563785, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [21:16<1:13:29, 142.24s/it]2025-03-03 14:06:34 - INFO - layer9_self_attn.q_proj | mse: 0.01727261834757368, bpp_loss: 4.240013265833259, bpp: 0
2025-03-03 14:06:48 - INFO - layer9_self_attn.k_proj | mse: 0.017300776674295852, bpp_loss: 4.249518755599857, bpp: 0
2025-03-03 14:07:05 - INFO - layer9_self_attn.v_proj | mse: 0.016660078791316597, bpp_loss: 3.680068868994713, bpp: 0
2025-03-03 14:07:21 - INFO - layer9_self_attn.o_proj | mse: 0.01742743815659639, bpp_loss: 3.6781542778015135, bpp: 0
2025-03-03 14:07:37 - INFO - layer9_mlp.gate_proj | mse: 0.0168596855908897, bpp_loss: 3.9862434238747313, bpp: 0
2025-03-03 14:07:54 - INFO - layer9_mlp.up_proj | mse: 0.01676327201417588, bpp_loss: 3.8816731555042443, bpp: 0
2025-03-03 14:08:40 - INFO - layer9_mlp.down_proj | mse: 0.015988404887968648, bpp_loss: 3.8772074554805402, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [23:39<1:11:09, 142.32s/it]2025-03-03 14:08:57 - INFO - layer10_self_attn.q_proj | mse: 0.01720663067074205, bpp_loss: 4.2343943477421995, bpp: 0
2025-03-03 14:09:10 - INFO - layer10_self_attn.k_proj | mse: 0.01727434637552555, bpp_loss: 4.258010738715529, bpp: 0
2025-03-03 14:09:27 - INFO - layer10_self_attn.v_proj | mse: 0.016599801764798014, bpp_loss: 3.673150600716472, bpp: 0
2025-03-03 14:09:43 - INFO - layer10_self_attn.o_proj | mse: 0.017023112989789025, bpp_loss: 3.676085715889931, bpp: 0
2025-03-03 14:10:00 - INFO - layer10_mlp.gate_proj | mse: 0.0168257925104603, bpp_loss: 3.9721884232980234, bpp: 0
2025-03-03 14:10:17 - INFO - layer10_mlp.up_proj | mse: 0.016741300156622205, bpp_loss: 3.8911162003322883, bpp: 0
2025-03-03 14:11:03 - INFO - layer10_mlp.down_proj | mse: 0.016069802942827595, bpp_loss: 3.885804697981587, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [26:01<1:08:48, 142.35s/it]2025-03-03 14:11:19 - INFO - layer11_self_attn.q_proj | mse: 0.017207396417034025, bpp_loss: 4.286300240084529, bpp: 0
2025-03-03 14:11:33 - INFO - layer11_self_attn.k_proj | mse: 0.017290647686419164, bpp_loss: 4.318597786277532, bpp: 0
2025-03-03 14:11:49 - INFO - layer11_self_attn.v_proj | mse: 0.016561464389303556, bpp_loss: 3.6834389939159156, bpp: 0
2025-03-03 14:12:06 - INFO - layer11_self_attn.o_proj | mse: 0.017602940531931455, bpp_loss: 3.673891605734825, bpp: 0
2025-03-03 14:12:22 - INFO - layer11_mlp.gate_proj | mse: 0.016716941307667845, bpp_loss: 3.957874780120673, bpp: 0
2025-03-03 14:12:39 - INFO - layer11_mlp.up_proj | mse: 0.016660149316062526, bpp_loss: 3.900580033991072, bpp: 0
2025-03-03 14:13:25 - INFO - layer11_mlp.down_proj | mse: 0.016105610560663532, bpp_loss: 3.8930292478038204, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [28:24<1:06:26, 142.38s/it]2025-03-03 14:13:42 - INFO - layer12_self_attn.q_proj | mse: 0.017095549251617013, bpp_loss: 4.228314670249819, bpp: 0
2025-03-03 14:13:55 - INFO - layer12_self_attn.k_proj | mse: 0.01717622887425404, bpp_loss: 4.2517883895337585, bpp: 0
2025-03-03 14:14:12 - INFO - layer12_self_attn.v_proj | mse: 0.01653415153548488, bpp_loss: 3.706569751277566, bpp: 0
2025-03-03 14:14:28 - INFO - layer12_self_attn.o_proj | mse: 0.018215791578205614, bpp_loss: 3.7008317106962205, bpp: 0
2025-03-03 14:14:45 - INFO - layer12_mlp.gate_proj | mse: 0.016694911766777676, bpp_loss: 3.9523444082449983, bpp: 0
2025-03-03 14:15:01 - INFO - layer12_mlp.up_proj | mse: 0.01665337427084986, bpp_loss: 3.909735730069655, bpp: 0
2025-03-03 14:15:47 - INFO - layer12_mlp.down_proj | mse: 0.016062525228539754, bpp_loss: 3.901064348027662, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [30:46<1:04:02, 142.33s/it]2025-03-03 14:16:04 - INFO - layer13_self_attn.q_proj | mse: 0.01704194330296413, bpp_loss: 4.1763999190181496, bpp: 0
2025-03-03 14:16:17 - INFO - layer13_self_attn.k_proj | mse: 0.01708807534531445, bpp_loss: 4.173431876748801, bpp: 0
2025-03-03 14:16:34 - INFO - layer13_self_attn.v_proj | mse: 0.01654705426779933, bpp_loss: 3.724346645958722, bpp: 0
2025-03-03 14:16:50 - INFO - layer13_self_attn.o_proj | mse: 0.017278451368964866, bpp_loss: 3.725551590025425, bpp: 0
2025-03-03 14:17:07 - INFO - layer13_mlp.gate_proj | mse: 0.01669789207249661, bpp_loss: 3.9485325570459717, bpp: 0
2025-03-03 14:17:24 - INFO - layer13_mlp.up_proj | mse: 0.01666972062968245, bpp_loss: 3.9176243364810945, bpp: 0
2025-03-03 14:18:10 - INFO - layer13_mlp.down_proj | mse: 0.016056906596882543, bpp_loss: 3.9082986830009356, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [33:08<1:01:40, 142.31s/it]2025-03-03 14:18:26 - INFO - layer14_self_attn.q_proj | mse: 0.01705581017104572, bpp_loss: 4.214747538939118, bpp: 0
2025-03-03 14:18:40 - INFO - layer14_self_attn.k_proj | mse: 0.01714612558903239, bpp_loss: 4.241109648868441, bpp: 0
2025-03-03 14:18:56 - INFO - layer14_self_attn.v_proj | mse: 0.016530715874760828, bpp_loss: 3.714035443626344, bpp: 0
2025-03-03 14:19:13 - INFO - layer14_self_attn.o_proj | mse: 0.01703960156551433, bpp_loss: 3.711561173275113, bpp: 0
2025-03-03 14:19:29 - INFO - layer14_mlp.gate_proj | mse: 0.01667703542611518, bpp_loss: 3.944745790572078, bpp: 0
2025-03-03 14:19:46 - INFO - layer14_mlp.up_proj | mse: 0.016656515265863314, bpp_loss: 3.9235267467520853, bpp: 0
2025-03-03 14:20:32 - INFO - layer14_mlp.down_proj | mse: 0.016012671718267174, bpp_loss: 3.912815026221452, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [35:30<59:17, 142.28s/it]  2025-03-03 14:20:49 - INFO - layer15_self_attn.q_proj | mse: 0.01698830583448809, bpp_loss: 4.19411106184125, bpp: 0
2025-03-03 14:21:02 - INFO - layer15_self_attn.k_proj | mse: 0.017083312143803337, bpp_loss: 4.235145836994052, bpp: 0
2025-03-03 14:21:18 - INFO - layer15_self_attn.v_proj | mse: 0.016513376263810296, bpp_loss: 3.748472217768431, bpp: 0
2025-03-03 14:21:35 - INFO - layer15_self_attn.o_proj | mse: 0.0183687646964128, bpp_loss: 3.7460464300215244, bpp: 0
2025-03-03 14:21:51 - INFO - layer15_mlp.gate_proj | mse: 0.01666926328322881, bpp_loss: 3.94626615030898, bpp: 0
2025-03-03 14:22:08 - INFO - layer15_mlp.up_proj | mse: 0.01665103809572179, bpp_loss: 3.931195660928885, bpp: 0
2025-03-03 14:22:55 - INFO - layer15_mlp.down_proj | mse: 0.016000411262436346, bpp_loss: 3.9199793280550725, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [37:53<56:59, 142.49s/it]2025-03-03 14:23:12 - INFO - layer16_self_attn.q_proj | mse: 0.016954635246928033, bpp_loss: 4.181208830699324, bpp: 0
2025-03-03 14:23:25 - INFO - layer16_self_attn.k_proj | mse: 0.01703898229369467, bpp_loss: 4.210537102296948, bpp: 0
2025-03-03 14:23:42 - INFO - layer16_self_attn.v_proj | mse: 0.01651713453919489, bpp_loss: 3.7536517610028386, bpp: 0
2025-03-03 14:23:58 - INFO - layer16_self_attn.o_proj | mse: 0.01706115370812436, bpp_loss: 3.7506175906956196, bpp: 0
2025-03-03 14:24:15 - INFO - layer16_mlp.gate_proj | mse: 0.01668729481953473, bpp_loss: 3.9501559554978654, bpp: 0
2025-03-03 14:24:32 - INFO - layer16_mlp.up_proj | mse: 0.01667524998950937, bpp_loss: 3.9307426969210306, bpp: 0
2025-03-03 14:25:18 - INFO - layer16_mlp.down_proj | mse: 0.016055708980943873, bpp_loss: 3.9196347253190145, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [40:17<54:45, 142.84s/it]2025-03-03 14:25:35 - INFO - layer17_self_attn.q_proj | mse: 0.016944042732240223, bpp_loss: 4.1702016652375455, bpp: 0
2025-03-03 14:25:49 - INFO - layer17_self_attn.k_proj | mse: 0.017023615452852282, bpp_loss: 4.20126175865531, bpp: 0
2025-03-03 14:26:05 - INFO - layer17_self_attn.v_proj | mse: 0.016522520720740154, bpp_loss: 3.764153844676912, bpp: 0
2025-03-03 14:26:22 - INFO - layer17_self_attn.o_proj | mse: 0.016902319756917316, bpp_loss: 3.765296047106385, bpp: 0
2025-03-03 14:26:39 - INFO - layer17_mlp.gate_proj | mse: 0.01664281410003287, bpp_loss: 3.9611732560175437, bpp: 0
2025-03-03 14:26:56 - INFO - layer17_mlp.up_proj | mse: 0.016609736826791052, bpp_loss: 3.9255887478590012, bpp: 0
2025-03-03 14:27:42 - INFO - layer17_mlp.down_proj | mse: 0.015927889574333828, bpp_loss: 3.9168212620748415, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [42:41<52:30, 143.21s/it]2025-03-03 14:27:59 - INFO - layer18_self_attn.q_proj | mse: 0.016859195076517574, bpp_loss: 4.182177581414581, bpp: 0
2025-03-03 14:28:13 - INFO - layer18_self_attn.k_proj | mse: 0.01693273453215604, bpp_loss: 4.213659266605974, bpp: 0
2025-03-03 14:28:30 - INFO - layer18_self_attn.v_proj | mse: 0.01646643212248689, bpp_loss: 3.79839789558202, bpp: 0
2025-03-03 14:28:46 - INFO - layer18_self_attn.o_proj | mse: 0.016827447198170056, bpp_loss: 3.7912792138010265, bpp: 0
2025-03-03 14:29:03 - INFO - layer18_mlp.gate_proj | mse: 0.016621837966740133, bpp_loss: 3.968814744717545, bpp: 0
2025-03-03 14:29:20 - INFO - layer18_mlp.up_proj | mse: 0.01658641765130638, bpp_loss: 3.919564791354868, bpp: 0
2025-03-03 14:30:07 - INFO - layer18_mlp.down_proj | mse: 0.015807130882793383, bpp_loss: 3.913436981290579, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [45:05<50:13, 143.48s/it]2025-03-03 14:30:23 - INFO - layer19_self_attn.q_proj | mse: 0.01682372415082311, bpp_loss: 4.1358944237232205, bpp: 0
2025-03-03 14:30:37 - INFO - layer19_self_attn.k_proj | mse: 0.01688112731111272, bpp_loss: 4.15944171436131, bpp: 0
2025-03-03 14:30:54 - INFO - layer19_self_attn.v_proj | mse: 0.016469997570718056, bpp_loss: 3.7962925365567206, bpp: 0
2025-03-03 14:31:10 - INFO - layer19_self_attn.o_proj | mse: 0.016450651815728978, bpp_loss: 3.7922616472840307, bpp: 0
2025-03-03 14:31:27 - INFO - layer19_mlp.gate_proj | mse: 0.016626193058645537, bpp_loss: 3.976286536399965, bpp: 0
2025-03-03 14:31:44 - INFO - layer19_mlp.up_proj | mse: 0.016581568130802443, bpp_loss: 3.9183357074304865, bpp: 0
2025-03-03 14:32:30 - INFO - layer19_mlp.down_proj | mse: 0.015781497506785022, bpp_loss: 3.912168732257905, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [47:29<47:51, 143.59s/it]2025-03-03 14:32:47 - INFO - layer20_self_attn.q_proj | mse: 0.016899985435896495, bpp_loss: 4.159581040665508, bpp: 0
2025-03-03 14:33:01 - INFO - layer20_self_attn.k_proj | mse: 0.01696508684946526, bpp_loss: 4.187731356620788, bpp: 0
2025-03-03 14:33:18 - INFO - layer20_self_attn.v_proj | mse: 0.016511477657991932, bpp_loss: 3.794771216288209, bpp: 0
2025-03-03 14:33:34 - INFO - layer20_self_attn.o_proj | mse: 0.016865157885415875, bpp_loss: 3.7956826547533273, bpp: 0
2025-03-03 14:33:51 - INFO - layer20_mlp.gate_proj | mse: 0.01666497823537486, bpp_loss: 3.9792814582586287, bpp: 0
2025-03-03 14:34:08 - INFO - layer20_mlp.up_proj | mse: 0.01661065014628556, bpp_loss: 3.917725637389554, bpp: 0
2025-03-03 14:34:55 - INFO - layer20_mlp.down_proj | mse: 0.015747708805726426, bpp_loss: 3.911270131750239, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [49:54<45:32, 143.83s/it]2025-03-03 14:35:11 - INFO - layer21_self_attn.q_proj | mse: 0.016914373308113788, bpp_loss: 4.126424944326281, bpp: 0
2025-03-03 14:35:26 - INFO - layer21_self_attn.k_proj | mse: 0.016975356749492524, bpp_loss: 4.146223221793771, bpp: 0
2025-03-03 14:35:43 - INFO - layer21_self_attn.v_proj | mse: 0.016583643220162227, bpp_loss: 3.823596467785537, bpp: 0
2025-03-03 14:35:58 - INFO - layer21_self_attn.o_proj | mse: 0.016484882343676874, bpp_loss: 3.8235259713977574, bpp: 0
2025-03-03 14:36:15 - INFO - layer21_mlp.gate_proj | mse: 0.016866234022994708, bpp_loss: 3.9879331815573904, bpp: 0
2025-03-03 14:36:32 - INFO - layer21_mlp.up_proj | mse: 0.01679741917596841, bpp_loss: 3.9114394008561417, bpp: 0
2025-03-03 14:37:18 - INFO - layer21_mlp.down_proj | mse: 0.015817475427804897, bpp_loss: 3.9096494039727583, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [52:17<43:07, 143.77s/it]2025-03-03 14:37:35 - INFO - layer22_self_attn.q_proj | mse: 0.016916490698587004, bpp_loss: 4.1212017613649365, bpp: 0
2025-03-03 14:37:50 - INFO - layer22_self_attn.k_proj | mse: 0.016962070216978462, bpp_loss: 4.148688234463334, bpp: 0
2025-03-03 14:38:07 - INFO - layer22_self_attn.v_proj | mse: 0.01667825089641991, bpp_loss: 3.8828971648961303, bpp: 0
2025-03-03 14:38:21 - INFO - layer22_self_attn.o_proj | mse: 0.01618125559542536, bpp_loss: 3.8735806680470706, bpp: 0
2025-03-03 14:38:38 - INFO - layer22_mlp.gate_proj | mse: 0.016801131510695726, bpp_loss: 3.9966437782954287, bpp: 0
2025-03-03 14:38:55 - INFO - layer22_mlp.up_proj | mse: 0.016723533688981607, bpp_loss: 3.907281825608677, bpp: 0
2025-03-03 14:39:42 - INFO - layer22_mlp.down_proj | mse: 0.015683055399404445, bpp_loss: 3.9074970149883517, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [54:41<40:43, 143.71s/it]2025-03-03 14:39:58 - INFO - layer23_self_attn.q_proj | mse: 0.016838232540011294, bpp_loss: 4.094444880783558, bpp: 0
2025-03-03 14:40:13 - INFO - layer23_self_attn.k_proj | mse: 0.016884498078083218, bpp_loss: 4.110936933532357, bpp: 0
2025-03-03 14:40:31 - INFO - layer23_self_attn.v_proj | mse: 0.016621185183648794, bpp_loss: 3.8764375135675073, bpp: 0
2025-03-03 14:40:44 - INFO - layer23_self_attn.o_proj | mse: 0.015716558842629944, bpp_loss: 3.874116626828909, bpp: 0
2025-03-03 14:41:01 - INFO - layer23_mlp.gate_proj | mse: 0.016771608629712245, bpp_loss: 4.004577598582816, bpp: 0
2025-03-03 14:41:18 - INFO - layer23_mlp.up_proj | mse: 0.016678627211519904, bpp_loss: 3.903599970815358, bpp: 0
2025-03-03 14:42:05 - INFO - layer23_mlp.down_proj | mse: 0.015586172115522018, bpp_loss: 3.9054386359122066, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [57:04<38:18, 143.63s/it]2025-03-03 14:42:21 - INFO - layer24_self_attn.q_proj | mse: 0.016784125982402396, bpp_loss: 4.107768181860447, bpp: 0
2025-03-03 14:42:36 - INFO - layer24_self_attn.k_proj | mse: 0.016808103297288227, bpp_loss: 4.125390878990292, bpp: 0
2025-03-03 14:42:54 - INFO - layer24_self_attn.v_proj | mse: 0.016553584433514446, bpp_loss: 3.8864283373951913, bpp: 0
2025-03-03 14:43:07 - INFO - layer24_self_attn.o_proj | mse: 0.015705895871866844, bpp_loss: 3.882441738322377, bpp: 0
2025-03-03 14:43:24 - INFO - layer24_mlp.gate_proj | mse: 0.016744248873847345, bpp_loss: 4.010390748083592, bpp: 0
2025-03-03 14:43:41 - INFO - layer24_mlp.up_proj | mse: 0.01664565294423611, bpp_loss: 3.9028104310786285, bpp: 0
2025-03-03 14:44:29 - INFO - layer24_mlp.down_proj | mse: 0.015501826716850709, bpp_loss: 3.906169442887659, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [59:28<35:54, 143.64s/it]2025-03-03 14:44:43 - INFO - layer25_self_attn.q_proj | mse: 0.016694874821974064, bpp_loss: 4.098095258697867, bpp: 0
2025-03-03 14:44:59 - INFO - layer25_self_attn.k_proj | mse: 0.01671830702933001, bpp_loss: 4.11192812718451, bpp: 0
2025-03-03 14:45:17 - INFO - layer25_self_attn.v_proj | mse: 0.016507074153286252, bpp_loss: 3.9125622087717056, bpp: 0
2025-03-03 14:45:30 - INFO - layer25_self_attn.o_proj | mse: 0.015542800255158324, bpp_loss: 3.9123155277967454, bpp: 0
2025-03-03 14:45:47 - INFO - layer25_mlp.gate_proj | mse: 0.016697800053840767, bpp_loss: 4.014648243067441, bpp: 0
2025-03-03 14:46:04 - INFO - layer25_mlp.up_proj | mse: 0.016589362248293195, bpp_loss: 3.9018166095018385, bpp: 0
2025-03-03 14:46:53 - INFO - layer25_mlp.down_proj | mse: 0.0154423551969239, bpp_loss: 3.905743077756078, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [1:01:52<33:31, 143.68s/it]2025-03-03 14:47:07 - INFO - layer26_self_attn.q_proj | mse: 0.016739829506224126, bpp_loss: 4.108880695700646, bpp: 0
2025-03-03 14:47:23 - INFO - layer26_self_attn.k_proj | mse: 0.016773581674502942, bpp_loss: 4.123190567493439, bpp: 0
2025-03-03 14:47:40 - INFO - layer26_self_attn.v_proj | mse: 0.016556621461180934, bpp_loss: 3.932540682181716, bpp: 0
2025-03-03 14:47:54 - INFO - layer26_self_attn.o_proj | mse: 0.01571239266365156, bpp_loss: 3.9069938807934523, bpp: 0
2025-03-03 14:48:11 - INFO - layer26_mlp.gate_proj | mse: 0.016683575617743546, bpp_loss: 4.018294138875272, bpp: 0
2025-03-03 14:48:28 - INFO - layer26_mlp.up_proj | mse: 0.01657327821130038, bpp_loss: 3.9029569712501986, bpp: 0
2025-03-03 14:49:17 - INFO - layer26_mlp.down_proj | mse: 0.01540102096608659, bpp_loss: 3.906823962016238, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [1:04:15<31:08, 143.73s/it]2025-03-03 14:49:31 - INFO - layer27_self_attn.q_proj | mse: 0.016572483348657602, bpp_loss: 4.110042866021395, bpp: 0
2025-03-03 14:49:47 - INFO - layer27_self_attn.k_proj | mse: 0.016583264982284348, bpp_loss: 4.12151046782732, bpp: 0
2025-03-03 14:50:04 - INFO - layer27_self_attn.v_proj | mse: 0.01639274804648335, bpp_loss: 3.926757381334901, bpp: 0
2025-03-03 14:50:18 - INFO - layer27_self_attn.o_proj | mse: 0.01556757576321291, bpp_loss: 3.9184728672355416, bpp: 0
2025-03-03 14:50:34 - INFO - layer27_mlp.gate_proj | mse: 0.016620221459905486, bpp_loss: 4.02230771570294, bpp: 0
2025-03-03 14:50:51 - INFO - layer27_mlp.up_proj | mse: 0.016507424442214185, bpp_loss: 3.9038582401695074, bpp: 0
2025-03-03 14:51:40 - INFO - layer27_mlp.down_proj | mse: 0.015336460951833221, bpp_loss: 3.9078748979502254, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [1:06:39<28:44, 143.73s/it]2025-03-03 14:51:54 - INFO - layer28_self_attn.q_proj | mse: 0.01647256550925168, bpp_loss: 4.1034679785743355, bpp: 0
2025-03-03 14:52:11 - INFO - layer28_self_attn.k_proj | mse: 0.016493926678815527, bpp_loss: 4.114002971164882, bpp: 0
2025-03-03 14:52:27 - INFO - layer28_self_attn.v_proj | mse: 0.01630998069908902, bpp_loss: 3.9345226481556894, bpp: 0
2025-03-03 14:52:41 - INFO - layer28_self_attn.o_proj | mse: 0.01571108551804419, bpp_loss: 3.9266650764644146, bpp: 0
2025-03-03 14:52:58 - INFO - layer28_mlp.gate_proj | mse: 0.01650983340821926, bpp_loss: 4.02381769462868, bpp: 0
2025-03-03 14:53:15 - INFO - layer28_mlp.up_proj | mse: 0.016405481505673444, bpp_loss: 3.9068984648143803, bpp: 0
2025-03-03 14:54:04 - INFO - layer28_mlp.down_proj | mse: 0.015246352713163462, bpp_loss: 3.910046223302682, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [1:09:02<26:19, 143.59s/it]2025-03-03 14:54:18 - INFO - layer29_self_attn.q_proj | mse: 0.01638990755418478, bpp_loss: 4.126379617415369, bpp: 0
2025-03-03 14:54:34 - INFO - layer29_self_attn.k_proj | mse: 0.016413740248705542, bpp_loss: 4.144597463496029, bpp: 0
2025-03-03 14:54:51 - INFO - layer29_self_attn.v_proj | mse: 0.016204732301355176, bpp_loss: 3.9386281864717603, bpp: 0
2025-03-03 14:55:05 - INFO - layer29_self_attn.o_proj | mse: 0.015529523920234108, bpp_loss: 3.9328900500386954, bpp: 0
2025-03-03 14:55:22 - INFO - layer29_mlp.gate_proj | mse: 0.016508363856551397, bpp_loss: 4.022555043686319, bpp: 0
2025-03-03 14:55:39 - INFO - layer29_mlp.up_proj | mse: 0.016395606667830534, bpp_loss: 3.9109385301117543, bpp: 0
2025-03-03 14:56:28 - INFO - layer29_mlp.down_proj | mse: 0.015195903141747097, bpp_loss: 3.914220345489405, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [1:11:27<23:57, 143.74s/it]2025-03-03 14:56:42 - INFO - layer30_self_attn.q_proj | mse: 0.016320287681261182, bpp_loss: 4.104411290995777, bpp: 0
2025-03-03 14:56:59 - INFO - layer30_self_attn.k_proj | mse: 0.01633713595379192, bpp_loss: 4.11328025136143, bpp: 0
2025-03-03 14:57:15 - INFO - layer30_self_attn.v_proj | mse: 0.01620887066872489, bpp_loss: 3.9882880184426903, bpp: 0
2025-03-03 14:57:29 - INFO - layer30_self_attn.o_proj | mse: 0.015357655595098257, bpp_loss: 3.9856096528470517, bpp: 0
2025-03-03 14:57:46 - INFO - layer30_mlp.gate_proj | mse: 0.01634694802667107, bpp_loss: 4.024738682585734, bpp: 0
2025-03-03 14:58:03 - INFO - layer30_mlp.up_proj | mse: 0.016241177388730026, bpp_loss: 3.912623486143571, bpp: 0
2025-03-03 14:58:52 - INFO - layer30_mlp.down_proj | mse: 0.01515415414025213, bpp_loss: 3.9151437945663927, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [1:13:50<21:33, 143.77s/it]2025-03-03 14:59:07 - INFO - layer31_self_attn.q_proj | mse: 0.01627079228836934, bpp_loss: 4.120315604545176, bpp: 0
2025-03-03 14:59:24 - INFO - layer31_self_attn.k_proj | mse: 0.016299367789221527, bpp_loss: 4.145191823467612, bpp: 0
2025-03-03 14:59:39 - INFO - layer31_self_attn.v_proj | mse: 0.016117876647486734, bpp_loss: 3.9530938040465116, bpp: 0
2025-03-03 14:59:52 - INFO - layer31_self_attn.o_proj | mse: 0.015615092823674867, bpp_loss: 3.9426587411016225, bpp: 0
2025-03-03 15:00:09 - INFO - layer31_mlp.gate_proj | mse: 0.016277494542705006, bpp_loss: 4.025482147821673, bpp: 0
2025-03-03 15:00:26 - INFO - layer31_mlp.up_proj | mse: 0.016179295529385372, bpp_loss: 3.9158314329606516, bpp: 0
2025-03-03 15:01:15 - INFO - layer31_mlp.down_proj | mse: 0.015109010062380572, bpp_loss: 3.917946258297673, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:16:14<19:09, 143.70s/it]2025-03-03 15:01:30 - INFO - layer32_self_attn.q_proj | mse: 0.016203953576312487, bpp_loss: 4.0841012730449435, bpp: 0
2025-03-03 15:01:48 - INFO - layer32_self_attn.k_proj | mse: 0.01621500961781142, bpp_loss: 4.093363460153341, bpp: 0
2025-03-03 15:02:02 - INFO - layer32_self_attn.v_proj | mse: 0.016111852653049364, bpp_loss: 3.9915322393924, bpp: 0
2025-03-03 15:02:15 - INFO - layer32_self_attn.o_proj | mse: 0.015758383793851295, bpp_loss: 3.9890457363426686, bpp: 0
2025-03-03 15:02:32 - INFO - layer32_mlp.gate_proj | mse: 0.01619675023232634, bpp_loss: 4.022598463407269, bpp: 0
2025-03-03 15:02:49 - INFO - layer32_mlp.up_proj | mse: 0.016094322481076482, bpp_loss: 3.9209361731454178, bpp: 0
2025-03-03 15:03:38 - INFO - layer32_mlp.down_proj | mse: 0.015107530896823295, bpp_loss: 3.9227996339676556, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:18:37<16:44, 143.48s/it]2025-03-03 15:03:54 - INFO - layer33_self_attn.q_proj | mse: 0.016162134187412868, bpp_loss: 4.087383303716779, bpp: 0
2025-03-03 15:04:12 - INFO - layer33_self_attn.k_proj | mse: 0.016180387873234937, bpp_loss: 4.104464882872999, bpp: 0
2025-03-03 15:04:25 - INFO - layer33_self_attn.v_proj | mse: 0.01605063003183609, bpp_loss: 3.9705025659501554, bpp: 0
2025-03-03 15:04:39 - INFO - layer33_self_attn.o_proj | mse: 0.015579757247809254, bpp_loss: 3.9668407678604125, bpp: 0
2025-03-03 15:04:55 - INFO - layer33_mlp.gate_proj | mse: 0.01617193953056943, bpp_loss: 4.020821817936721, bpp: 0
2025-03-03 15:05:12 - INFO - layer33_mlp.up_proj | mse: 0.016084508073395613, bpp_loss: 3.9262254010196087, bpp: 0
2025-03-03 15:06:01 - INFO - layer33_mlp.down_proj | mse: 0.015107664117862345, bpp_loss: 3.9275281897297614, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:21:00<14:19, 143.33s/it]2025-03-03 15:06:17 - INFO - layer34_self_attn.q_proj | mse: 0.016113068947401755, bpp_loss: 4.047471711784601, bpp: 0
2025-03-03 15:06:35 - INFO - layer34_self_attn.k_proj | mse: 0.01613947328867063, bpp_loss: 4.062016322985292, bpp: 0
2025-03-03 15:06:49 - INFO - layer34_self_attn.v_proj | mse: 0.016068564811212105, bpp_loss: 3.996992141455412, bpp: 0
2025-03-03 15:07:02 - INFO - layer34_self_attn.o_proj | mse: 0.01565099204814281, bpp_loss: 4.005121221467853, bpp: 0
2025-03-03 15:07:19 - INFO - layer34_mlp.gate_proj | mse: 0.01614621413590523, bpp_loss: 4.0148627844121725, bpp: 0
2025-03-03 15:07:36 - INFO - layer34_mlp.up_proj | mse: 0.016067671406202813, bpp_loss: 3.9349368054005835, bpp: 0
2025-03-03 15:08:25 - INFO - layer34_mlp.down_proj | mse: 0.015137044163917363, bpp_loss: 3.93633186786815, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:23:24<11:57, 143.58s/it]2025-03-03 15:08:42 - INFO - layer35_self_attn.q_proj | mse: 0.016095015505162093, bpp_loss: 4.039177871346474, bpp: 0
2025-03-03 15:08:59 - INFO - layer35_self_attn.k_proj | mse: 0.01611905771380148, bpp_loss: 4.05527983084321, bpp: 0
2025-03-03 15:09:11 - INFO - layer35_self_attn.v_proj | mse: 0.016061035281692202, bpp_loss: 3.997870935164392, bpp: 0
2025-03-03 15:09:22 - INFO - layer35_self_attn.o_proj | mse: 0.015880028061948225, bpp_loss: 4.000820455923677, bpp: 0
2025-03-03 15:09:37 - INFO - layer35_mlp.gate_proj | mse: 0.01611822673040275, bpp_loss: 4.008538554995148, bpp: 0
2025-03-03 15:09:51 - INFO - layer35_mlp.up_proj | mse: 0.016063867052819657, bpp_loss: 3.944490212202072, bpp: 0
2025-03-03 15:10:34 - INFO - layer35_mlp.down_proj | mse: 0.015193282670174876, bpp_loss: 3.9451595307224325, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:25:33<09:16, 139.12s/it]2025-03-03 15:10:52 - INFO - layer36_self_attn.q_proj | mse: 0.016124106447828242, bpp_loss: 4.040098856836558, bpp: 0
2025-03-03 15:11:09 - INFO - layer36_self_attn.k_proj | mse: 0.0161517975395248, bpp_loss: 4.0622218095511196, bpp: 0
2025-03-03 15:11:27 - INFO - layer36_self_attn.v_proj | mse: 0.016104929416598416, bpp_loss: 4.021081793643535, bpp: 0
2025-03-03 15:11:45 - INFO - layer36_self_attn.o_proj | mse: 0.01609070655992588, bpp_loss: 4.024306162744761, bpp: 0
2025-03-03 15:12:07 - INFO - layer36_mlp.gate_proj | mse: 0.01612895171075258, bpp_loss: 4.004182844746996, bpp: 0
2025-03-03 15:12:29 - INFO - layer36_mlp.up_proj | mse: 0.01607869991077563, bpp_loss: 3.9502115188925355, bpp: 0
2025-03-03 15:13:27 - INFO - layer36_mlp.down_proj | mse: 0.015295617029356123, bpp_loss: 3.945952704852378, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:28:25<07:27, 149.15s/it]2025-03-03 15:13:46 - INFO - layer37_self_attn.q_proj | mse: 0.016164164434845592, bpp_loss: 3.974496427103877, bpp: 0
2025-03-03 15:14:04 - INFO - layer37_self_attn.k_proj | mse: 0.01616974715175877, bpp_loss: 3.973543137460947, bpp: 0
2025-03-03 15:14:22 - INFO - layer37_self_attn.v_proj | mse: 0.016226712742738684, bpp_loss: 4.045851591303944, bpp: 0
2025-03-03 15:14:40 - INFO - layer37_self_attn.o_proj | mse: 0.016637399351501915, bpp_loss: 4.047764833793044, bpp: 0
2025-03-03 15:14:55 - INFO - layer37_mlp.gate_proj | mse: 0.016167651735889934, bpp_loss: 4.008110296615848, bpp: 0
2025-03-03 15:15:09 - INFO - layer37_mlp.up_proj | mse: 0.01611959876976368, bpp_loss: 3.9585919594323196, bpp: 0
2025-03-03 15:15:48 - INFO - layer37_mlp.down_proj | mse: 0.015453718814213506, bpp_loss: 3.9460539727023356, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:30:47<04:53, 146.88s/it]2025-03-03 15:16:00 - INFO - layer38_self_attn.q_proj | mse: 0.016187748678995587, bpp_loss: 3.948647188618779, bpp: 0
2025-03-03 15:16:12 - INFO - layer38_self_attn.k_proj | mse: 0.016212074566043382, bpp_loss: 3.9566719864308832, bpp: 0
2025-03-03 15:16:23 - INFO - layer38_self_attn.v_proj | mse: 0.016339255198372378, bpp_loss: 4.1009814048558475, bpp: 0
2025-03-03 15:16:35 - INFO - layer38_self_attn.o_proj | mse: 0.016953567281155203, bpp_loss: 4.11178853213787, bpp: 0
2025-03-03 15:16:50 - INFO - layer38_mlp.gate_proj | mse: 0.01631938775254121, bpp_loss: 4.042873236647359, bpp: 0
2025-03-03 15:17:04 - INFO - layer38_mlp.up_proj | mse: 0.01624137653358221, bpp_loss: 3.963099261511255, bpp: 0
2025-03-03 15:17:43 - INFO - layer38_mlp.down_proj | mse: 0.015836972395540362, bpp_loss: 3.9286576114318987, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:32:42<02:17, 137.33s/it]2025-03-03 15:17:55 - INFO - layer39_self_attn.q_proj | mse: 0.016420092420125185, bpp_loss: 3.944788636416197, bpp: 0
2025-03-03 15:18:07 - INFO - layer39_self_attn.k_proj | mse: 0.01644717165643106, bpp_loss: 3.957662441059947, bpp: 0
2025-03-03 15:18:19 - INFO - layer39_self_attn.v_proj | mse: 0.016480792183095515, bpp_loss: 3.9842544581741093, bpp: 0
2025-03-03 15:18:30 - INFO - layer39_self_attn.o_proj | mse: 0.025348807285119842, bpp_loss: 3.9916606444120406, bpp: 0
2025-03-03 15:18:45 - INFO - layer39_mlp.gate_proj | mse: 0.01665747528139213, bpp_loss: 4.120604786663144, bpp: 0
2025-03-03 15:18:59 - INFO - layer39_mlp.up_proj | mse: 0.016543050769563993, bpp_loss: 4.009480209869367, bpp: 0
2025-03-03 15:19:38 - INFO - layer39_mlp.down_proj | mse: 0.017507304650200742, bpp_loss: 3.916520862226133, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:34:37<00:00, 130.70s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:34:37<00:00, 141.94s/it]
2025-03-03 15:19:38 - INFO - #### Total | mse: 0.018051072596749936, bpp_loss: 3.9433882213422398, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda300_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_5.34295_bpp_5.7068_MSE_0.00302_total_iter_95000.pth.tar/COL_MSE0.01805_bpploss3.9434_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda300_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_5.34295_bpp_5.7068_MSE_0.00302_total_iter_95000.pth.tar/COL_MSE0.01692_bpploss3.943_bpp0
I0303 15:20:22.012974 3265228 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.10s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.14s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.15s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.30s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:01,  1.89s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.70s/it]
W0303 15:20:32.429158 3265228 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 15:20:32.444240 3265228 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.2578125:   0%|          | 0/166 [00:02<?, ?it/s]avg_loss = 1.2578125:   1%|          | 1/166 [00:02<07:21,  2.68s/it]avg_loss = 1.55078125:   1%|          | 1/166 [00:03<07:21,  2.68s/it]avg_loss = 1.55078125:   1%|          | 2/166 [00:03<04:41,  1.72s/it]avg_loss = 1.7161458333333333:   1%|          | 2/166 [00:04<04:41,  1.72s/it]avg_loss = 1.7161458333333333:   2%|▏         | 3/166 [00:04<03:54,  1.44s/it]avg_loss = 1.74609375:   2%|▏         | 3/166 [00:05<03:54,  1.44s/it]        avg_loss = 1.74609375:   2%|▏         | 4/166 [00:05<03:25,  1.27s/it]avg_loss = 1.6796875:   2%|▏         | 4/166 [00:06<03:25,  1.27s/it] avg_loss = 1.6796875:   3%|▎         | 5/166 [00:06<03:12,  1.20s/it]avg_loss = 1.6497395833333333:   3%|▎         | 5/166 [00:07<03:12,  1.20s/it]avg_loss = 1.6497395833333333:   4%|▎         | 6/166 [00:07<03:04,  1.16s/it]avg_loss = 1.5859375:   4%|▎         | 6/166 [00:09<03:04,  1.16s/it]         avg_loss = 1.5859375:   4%|▍         | 7/166 [00:09<03:01,  1.14s/it]avg_loss = 1.5185546875:   4%|▍         | 7/166 [00:10<03:01,  1.14s/it]avg_loss = 1.5185546875:   5%|▍         | 8/166 [00:10<02:56,  1.12s/it]avg_loss = 1.515625:   5%|▍         | 8/166 [00:11<02:56,  1.12s/it]    avg_loss = 1.515625:   5%|▌         | 9/166 [00:11<02:55,  1.12s/it]avg_loss = 1.5265625:   5%|▌         | 9/166 [00:12<02:55,  1.12s/it]avg_loss = 1.5265625:   6%|▌         | 10/166 [00:12<02:50,  1.09s/it]avg_loss = 1.5440340909090908:   6%|▌         | 10/166 [00:13<02:50,  1.09s/it]avg_loss = 1.5440340909090908:   7%|▋         | 11/166 [00:13<02:50,  1.10s/it]avg_loss = 1.5540364583333333:   7%|▋         | 11/166 [00:14<02:50,  1.10s/it]avg_loss = 1.5540364583333333:   7%|▋         | 12/166 [00:14<02:47,  1.09s/it]avg_loss = 1.5504807692307692:   7%|▋         | 12/166 [00:15<02:47,  1.09s/it]avg_loss = 1.5504807692307692:   8%|▊         | 13/166 [00:15<02:49,  1.10s/it]avg_loss = 1.5641741071428572:   8%|▊         | 13/166 [00:16<02:49,  1.10s/it]avg_loss = 1.5641741071428572:   8%|▊         | 14/166 [00:16<02:45,  1.09s/it]avg_loss = 1.5807291666666667:   8%|▊         | 14/166 [00:17<02:45,  1.09s/it]avg_loss = 1.5807291666666667:   9%|▉         | 15/166 [00:17<02:44,  1.09s/it]avg_loss = 1.5986328125:   9%|▉         | 15/166 [00:18<02:44,  1.09s/it]      avg_loss = 1.5986328125:  10%|▉         | 16/166 [00:18<02:44,  1.10s/it]avg_loss = 1.6084558823529411:  10%|▉         | 16/166 [00:19<02:44,  1.10s/it]avg_loss = 1.6084558823529411:  10%|█         | 17/166 [00:19<02:42,  1.09s/it]avg_loss = 1.6219618055555556:  10%|█         | 17/166 [00:21<02:42,  1.09s/it]avg_loss = 1.6219618055555556:  11%|█         | 18/166 [00:21<02:40,  1.09s/it]avg_loss = 1.6410361842105263:  11%|█         | 18/166 [00:22<02:40,  1.09s/it]avg_loss = 1.6410361842105263:  11%|█▏        | 19/166 [00:22<02:39,  1.08s/it]avg_loss = 1.64765625:  11%|█▏        | 19/166 [00:23<02:39,  1.08s/it]        avg_loss = 1.64765625:  12%|█▏        | 20/166 [00:23<02:37,  1.08s/it]avg_loss = 1.6484375:  12%|█▏        | 20/166 [00:24<02:37,  1.08s/it] avg_loss = 1.6484375:  13%|█▎        | 21/166 [00:24<02:35,  1.08s/it]avg_loss = 1.6381392045454546:  13%|█▎        | 21/166 [00:25<02:35,  1.08s/it]avg_loss = 1.6381392045454546:  13%|█▎        | 22/166 [00:25<02:34,  1.07s/it]avg_loss = 1.622282608695652:  13%|█▎        | 22/166 [00:26<02:34,  1.07s/it] avg_loss = 1.622282608695652:  14%|█▍        | 23/166 [00:26<02:33,  1.07s/it]avg_loss = 1.6298828125:  14%|█▍        | 23/166 [00:27<02:33,  1.07s/it]     avg_loss = 1.6298828125:  14%|█▍        | 24/166 [00:27<02:31,  1.07s/it]avg_loss = 1.6375:  14%|█▍        | 24/166 [00:28<02:31,  1.07s/it]      avg_loss = 1.6375:  15%|█▌        | 25/166 [00:28<02:30,  1.07s/it]avg_loss = 1.6421274038461537:  15%|█▌        | 25/166 [00:29<02:30,  1.07s/it]avg_loss = 1.6421274038461537:  16%|█▌        | 26/166 [00:29<02:28,  1.06s/it]avg_loss = 1.6487268518518519:  16%|█▌        | 26/166 [00:30<02:28,  1.06s/it]avg_loss = 1.6487268518518519:  16%|█▋        | 27/166 [00:30<02:27,  1.06s/it]avg_loss = 1.6509486607142858:  16%|█▋        | 27/166 [00:31<02:27,  1.06s/it]avg_loss = 1.6509486607142858:  17%|█▋        | 28/166 [00:31<02:25,  1.05s/it]avg_loss = 1.6605603448275863:  17%|█▋        | 28/166 [00:32<02:25,  1.05s/it]avg_loss = 1.6605603448275863:  17%|█▋        | 29/166 [00:32<02:25,  1.07s/it]avg_loss = 1.6611979166666666:  17%|█▋        | 29/166 [00:33<02:25,  1.07s/it]avg_loss = 1.6611979166666666:  18%|█▊        | 30/166 [00:33<02:24,  1.07s/it]avg_loss = 1.6756552419354838:  18%|█▊        | 30/166 [00:34<02:24,  1.07s/it]avg_loss = 1.6756552419354838:  19%|█▊        | 31/166 [00:34<02:26,  1.08s/it]avg_loss = 1.68310546875:  19%|█▊        | 31/166 [00:35<02:26,  1.08s/it]     avg_loss = 1.68310546875:  19%|█▉        | 32/166 [00:35<02:23,  1.07s/it]avg_loss = 1.6882102272727273:  19%|█▉        | 32/166 [00:37<02:23,  1.07s/it]avg_loss = 1.6882102272727273:  20%|█▉        | 33/166 [00:37<02:25,  1.10s/it]avg_loss = 1.6863511029411764:  20%|█▉        | 33/166 [00:38<02:25,  1.10s/it]avg_loss = 1.6863511029411764:  20%|██        | 34/166 [00:38<02:23,  1.09s/it]avg_loss = 1.6796875:  20%|██        | 34/166 [00:39<02:23,  1.09s/it]         avg_loss = 1.6796875:  21%|██        | 35/166 [00:39<02:24,  1.10s/it]avg_loss = 1.6697048611111112:  21%|██        | 35/166 [00:40<02:24,  1.10s/it]avg_loss = 1.6697048611111112:  22%|██▏       | 36/166 [00:40<02:22,  1.09s/it]avg_loss = 1.6589949324324325:  22%|██▏       | 36/166 [00:41<02:22,  1.09s/it]avg_loss = 1.6589949324324325:  22%|██▏       | 37/166 [00:41<02:23,  1.11s/it]avg_loss = 1.6554276315789473:  22%|██▏       | 37/166 [00:42<02:23,  1.11s/it]avg_loss = 1.6554276315789473:  23%|██▎       | 38/166 [00:42<02:20,  1.10s/it]avg_loss = 1.6528445512820513:  23%|██▎       | 38/166 [00:43<02:20,  1.10s/it]avg_loss = 1.6528445512820513:  23%|██▎       | 39/166 [00:43<02:20,  1.11s/it]avg_loss = 1.657421875:  23%|██▎       | 39/166 [00:44<02:20,  1.11s/it]       avg_loss = 1.657421875:  24%|██▍       | 40/166 [00:44<02:18,  1.10s/it]avg_loss = 1.658346036585366:  24%|██▍       | 40/166 [00:45<02:18,  1.10s/it]avg_loss = 1.658346036585366:  25%|██▍       | 41/166 [00:45<02:16,  1.09s/it]avg_loss = 1.6471354166666667:  25%|██▍       | 41/166 [00:46<02:16,  1.09s/it]avg_loss = 1.6471354166666667:  25%|██▌       | 42/166 [00:46<02:14,  1.08s/it]avg_loss = 1.632267441860465:  25%|██▌       | 42/166 [00:48<02:14,  1.08s/it] avg_loss = 1.632267441860465:  26%|██▌       | 43/166 [00:48<02:14,  1.10s/it]avg_loss = 1.623046875:  26%|██▌       | 43/166 [00:49<02:14,  1.10s/it]      avg_loss = 1.623046875:  27%|██▋       | 44/166 [00:49<02:12,  1.08s/it]avg_loss = 1.6100694444444446:  27%|██▋       | 44/166 [00:50<02:12,  1.08s/it]avg_loss = 1.6100694444444446:  27%|██▋       | 45/166 [00:50<02:13,  1.10s/it]avg_loss = 1.6002038043478262:  27%|██▋       | 45/166 [00:51<02:13,  1.10s/it]avg_loss = 1.6002038043478262:  28%|██▊       | 46/166 [00:51<02:10,  1.09s/it]avg_loss = 1.5939162234042554:  28%|██▊       | 46/166 [00:52<02:10,  1.09s/it]avg_loss = 1.5939162234042554:  28%|██▊       | 47/166 [00:52<02:14,  1.13s/it]avg_loss = 1.5948893229166667:  28%|██▊       | 47/166 [00:53<02:14,  1.13s/it]avg_loss = 1.5948893229166667:  29%|██▉       | 48/166 [00:53<02:11,  1.11s/it]avg_loss = 1.6060267857142858:  29%|██▉       | 48/166 [00:54<02:11,  1.11s/it]avg_loss = 1.6060267857142858:  30%|██▉       | 49/166 [00:54<02:12,  1.13s/it]avg_loss = 1.61703125:  30%|██▉       | 49/166 [00:55<02:12,  1.13s/it]        avg_loss = 1.61703125:  30%|███       | 50/166 [00:55<02:10,  1.12s/it]avg_loss = 1.6237745098039216:  30%|███       | 50/166 [00:57<02:10,  1.12s/it]avg_loss = 1.6237745098039216:  31%|███       | 51/166 [00:57<02:09,  1.13s/it]avg_loss = 1.6278545673076923:  31%|███       | 51/166 [00:58<02:09,  1.13s/it]avg_loss = 1.6278545673076923:  31%|███▏      | 52/166 [00:58<02:06,  1.11s/it]avg_loss = 1.6310436320754718:  31%|███▏      | 52/166 [00:59<02:06,  1.11s/it]avg_loss = 1.6310436320754718:  32%|███▏      | 53/166 [00:59<02:05,  1.11s/it]avg_loss = 1.6326678240740742:  32%|███▏      | 53/166 [01:00<02:05,  1.11s/it]avg_loss = 1.6326678240740742:  33%|███▎      | 54/166 [01:00<02:04,  1.11s/it]avg_loss = 1.6357954545454545:  33%|███▎      | 54/166 [01:01<02:04,  1.11s/it]avg_loss = 1.6357954545454545:  33%|███▎      | 55/166 [01:01<02:03,  1.11s/it]avg_loss = 1.6399274553571428:  33%|███▎      | 55/166 [01:02<02:03,  1.11s/it]avg_loss = 1.6399274553571428:  34%|███▎      | 56/166 [01:02<02:01,  1.10s/it]avg_loss = 1.6354166666666667:  34%|███▎      | 56/166 [01:03<02:01,  1.10s/it]avg_loss = 1.6354166666666667:  34%|███▍      | 57/166 [01:03<02:00,  1.11s/it]avg_loss = 1.6392780172413792:  34%|███▍      | 57/166 [01:04<02:00,  1.11s/it]avg_loss = 1.6392780172413792:  35%|███▍      | 58/166 [01:04<01:58,  1.10s/it]avg_loss = 1.6377118644067796:  35%|███▍      | 58/166 [01:05<01:58,  1.10s/it]avg_loss = 1.6377118644067796:  36%|███▌      | 59/166 [01:05<01:58,  1.11s/it]avg_loss = 1.6333333333333333:  36%|███▌      | 59/166 [01:06<01:58,  1.11s/it]avg_loss = 1.6333333333333333:  36%|███▌      | 60/166 [01:06<01:56,  1.10s/it]avg_loss = 1.629610655737705:  36%|███▌      | 60/166 [01:08<01:56,  1.10s/it] avg_loss = 1.629610655737705:  37%|███▋      | 61/166 [01:08<01:57,  1.11s/it]avg_loss = 1.6261340725806452:  37%|███▋      | 61/166 [01:09<01:57,  1.11s/it]avg_loss = 1.6261340725806452:  37%|███▋      | 62/166 [01:09<01:54,  1.10s/it]avg_loss = 1.6205357142857142:  37%|███▋      | 62/166 [01:10<01:54,  1.10s/it]avg_loss = 1.6205357142857142:  38%|███▊      | 63/166 [01:10<01:52,  1.09s/it]avg_loss = 1.6163330078125:  38%|███▊      | 63/166 [01:11<01:52,  1.09s/it]   avg_loss = 1.6163330078125:  39%|███▊      | 64/166 [01:11<01:50,  1.09s/it]avg_loss = 1.609375:  39%|███▊      | 64/166 [01:12<01:50,  1.09s/it]       avg_loss = 1.609375:  39%|███▉      | 65/166 [01:12<01:49,  1.09s/it]avg_loss = 1.6023910984848484:  39%|███▉      | 65/166 [01:13<01:49,  1.09s/it]avg_loss = 1.6023910984848484:  40%|███▉      | 66/166 [01:13<01:47,  1.08s/it]avg_loss = 1.5965485074626866:  40%|███▉      | 66/166 [01:14<01:47,  1.08s/it]avg_loss = 1.5965485074626866:  40%|████      | 67/166 [01:14<01:46,  1.08s/it]avg_loss = 1.5952435661764706:  40%|████      | 67/166 [01:15<01:46,  1.08s/it]avg_loss = 1.5952435661764706:  41%|████      | 68/166 [01:15<01:45,  1.07s/it]avg_loss = 1.5969202898550725:  41%|████      | 68/166 [01:16<01:45,  1.07s/it]avg_loss = 1.5969202898550725:  42%|████▏     | 69/166 [01:16<01:44,  1.08s/it]avg_loss = 1.6002232142857142:  42%|████▏     | 69/166 [01:17<01:44,  1.08s/it]avg_loss = 1.6002232142857142:  42%|████▏     | 70/166 [01:17<01:42,  1.07s/it]avg_loss = 1.6045334507042253:  42%|████▏     | 70/166 [01:18<01:42,  1.07s/it]avg_loss = 1.6045334507042253:  43%|████▎     | 71/166 [01:18<01:42,  1.08s/it]avg_loss = 1.6099175347222223:  43%|████▎     | 71/166 [01:19<01:42,  1.08s/it]avg_loss = 1.6099175347222223:  43%|████▎     | 72/166 [01:19<01:40,  1.07s/it]avg_loss = 1.6163313356164384:  43%|████▎     | 72/166 [01:21<01:40,  1.07s/it]avg_loss = 1.6163313356164384:  44%|████▍     | 73/166 [01:21<01:39,  1.07s/it]avg_loss = 1.6104307432432432:  44%|████▍     | 73/166 [01:22<01:39,  1.07s/it]avg_loss = 1.6104307432432432:  45%|████▍     | 74/166 [01:22<01:38,  1.07s/it]avg_loss = 1.6058333333333332:  45%|████▍     | 74/166 [01:23<01:38,  1.07s/it]avg_loss = 1.6058333333333332:  45%|████▌     | 75/166 [01:23<01:39,  1.09s/it]avg_loss = 1.6048519736842106:  45%|████▌     | 75/166 [01:24<01:39,  1.09s/it]avg_loss = 1.6048519736842106:  46%|████▌     | 76/166 [01:24<01:37,  1.08s/it]avg_loss = 1.6014610389610389:  46%|████▌     | 76/166 [01:25<01:37,  1.08s/it]avg_loss = 1.6014610389610389:  46%|████▋     | 77/166 [01:25<01:37,  1.10s/it]avg_loss = 1.5981570512820513:  46%|████▋     | 77/166 [01:26<01:37,  1.10s/it]avg_loss = 1.5981570512820513:  47%|████▋     | 78/166 [01:26<01:35,  1.08s/it]avg_loss = 1.5956289556962024:  47%|████▋     | 78/166 [01:27<01:35,  1.08s/it]avg_loss = 1.5956289556962024:  48%|████▊     | 79/166 [01:27<01:36,  1.11s/it]avg_loss = 1.59228515625:  48%|████▊     | 79/166 [01:28<01:36,  1.11s/it]     avg_loss = 1.59228515625:  48%|████▊     | 80/166 [01:28<01:34,  1.10s/it]avg_loss = 1.5825135030864197:  48%|████▊     | 80/166 [01:29<01:34,  1.10s/it]avg_loss = 1.5825135030864197:  49%|████▉     | 81/166 [01:29<01:34,  1.11s/it]avg_loss = 1.5841749237804879:  49%|████▉     | 81/166 [01:30<01:34,  1.11s/it]avg_loss = 1.5841749237804879:  49%|████▉     | 82/166 [01:30<01:32,  1.11s/it]avg_loss = 1.5854198042168675:  49%|████▉     | 82/166 [01:32<01:32,  1.11s/it]avg_loss = 1.5854198042168675:  50%|█████     | 83/166 [01:32<01:32,  1.11s/it]avg_loss = 1.5881231398809523:  50%|█████     | 83/166 [01:33<01:32,  1.11s/it]avg_loss = 1.5881231398809523:  51%|█████     | 84/166 [01:33<01:30,  1.11s/it]avg_loss = 1.5897518382352942:  51%|█████     | 84/166 [01:34<01:30,  1.11s/it]avg_loss = 1.5897518382352942:  51%|█████     | 85/166 [01:34<01:29,  1.11s/it]avg_loss = 1.5886173691860466:  51%|█████     | 85/166 [01:35<01:29,  1.11s/it]avg_loss = 1.5886173691860466:  52%|█████▏    | 86/166 [01:35<01:28,  1.11s/it]avg_loss = 1.5890355603448276:  52%|█████▏    | 86/166 [01:36<01:28,  1.11s/it]avg_loss = 1.5890355603448276:  52%|█████▏    | 87/166 [01:36<01:26,  1.09s/it]avg_loss = 1.5896218039772727:  52%|█████▏    | 87/166 [01:37<01:26,  1.09s/it]avg_loss = 1.5896218039772727:  53%|█████▎    | 88/166 [01:37<01:24,  1.08s/it]avg_loss = 1.590721558988764:  53%|█████▎    | 88/166 [01:38<01:24,  1.08s/it] avg_loss = 1.590721558988764:  54%|█████▎    | 89/166 [01:38<01:24,  1.09s/it]avg_loss = 1.5905815972222221:  54%|█████▎    | 89/166 [01:39<01:24,  1.09s/it]avg_loss = 1.5905815972222221:  54%|█████▍    | 90/166 [01:39<01:22,  1.08s/it]avg_loss = 1.5914749313186813:  54%|█████▍    | 90/166 [01:40<01:22,  1.08s/it]avg_loss = 1.5914749313186813:  55%|█████▍    | 91/166 [01:40<01:21,  1.09s/it]avg_loss = 1.5917544157608696:  55%|█████▍    | 91/166 [01:41<01:21,  1.09s/it]avg_loss = 1.5917544157608696:  55%|█████▌    | 92/166 [01:41<01:19,  1.08s/it]avg_loss = 1.5950520833333333:  55%|█████▌    | 92/166 [01:42<01:19,  1.08s/it]avg_loss = 1.5950520833333333:  56%|█████▌    | 93/166 [01:42<01:20,  1.11s/it]avg_loss = 1.5943733377659575:  56%|█████▌    | 93/166 [01:44<01:20,  1.11s/it]avg_loss = 1.5943733377659575:  57%|█████▋    | 94/166 [01:44<01:18,  1.09s/it]avg_loss = 1.5937911184210527:  57%|█████▋    | 94/166 [01:45<01:18,  1.09s/it]avg_loss = 1.5937911184210527:  57%|█████▋    | 95/166 [01:45<01:19,  1.11s/it]avg_loss = 1.5932210286458333:  57%|█████▋    | 95/166 [01:46<01:19,  1.11s/it]avg_loss = 1.5932210286458333:  58%|█████▊    | 96/166 [01:46<01:16,  1.09s/it]avg_loss = 1.5924210695876289:  58%|█████▊    | 96/166 [01:47<01:16,  1.09s/it]avg_loss = 1.5924210695876289:  58%|█████▊    | 97/166 [01:47<01:16,  1.11s/it]avg_loss = 1.5908402423469388:  58%|█████▊    | 97/166 [01:48<01:16,  1.11s/it]avg_loss = 1.5908402423469388:  59%|█████▉    | 98/166 [01:48<01:14,  1.09s/it]avg_loss = 1.5886600378787878:  59%|█████▉    | 98/166 [01:49<01:14,  1.09s/it]avg_loss = 1.5886600378787878:  60%|█████▉    | 99/166 [01:49<01:14,  1.11s/it]avg_loss = 1.5859765625:  60%|█████▉    | 99/166 [01:50<01:14,  1.11s/it]      avg_loss = 1.5859765625:  60%|██████    | 100/166 [01:50<01:12,  1.10s/it]avg_loss = 1.5866723391089108:  60%|██████    | 100/166 [01:51<01:12,  1.10s/it]avg_loss = 1.5866723391089108:  61%|██████    | 101/166 [01:51<01:12,  1.12s/it]avg_loss = 1.587890625:  61%|██████    | 101/166 [01:52<01:12,  1.12s/it]       avg_loss = 1.587890625:  61%|██████▏   | 102/166 [01:52<01:10,  1.09s/it]avg_loss = 1.588402609223301:  61%|██████▏   | 102/166 [01:53<01:10,  1.09s/it]avg_loss = 1.588402609223301:  62%|██████▏   | 103/166 [01:53<01:09,  1.10s/it]avg_loss = 1.5902569110576923:  62%|██████▏   | 103/166 [01:55<01:09,  1.10s/it]avg_loss = 1.5902569110576923:  63%|██████▎   | 104/166 [01:55<01:07,  1.09s/it]avg_loss = 1.5966889880952382:  63%|██████▎   | 104/166 [01:56<01:07,  1.09s/it]avg_loss = 1.5966889880952382:  63%|██████▎   | 105/166 [01:56<01:07,  1.11s/it]avg_loss = 1.602115271226415:  63%|██████▎   | 105/166 [01:57<01:07,  1.11s/it] avg_loss = 1.602115271226415:  64%|██████▍   | 106/166 [01:57<01:05,  1.09s/it]avg_loss = 1.6053227219626167:  64%|██████▍   | 106/166 [01:58<01:05,  1.09s/it]avg_loss = 1.6053227219626167:  64%|██████▍   | 107/166 [01:58<01:05,  1.11s/it]avg_loss = 1.6082537615740742:  64%|██████▍   | 107/166 [01:59<01:05,  1.11s/it]avg_loss = 1.6082537615740742:  65%|██████▌   | 108/166 [01:59<01:04,  1.10s/it]avg_loss = 1.6129945527522935:  65%|██████▌   | 108/166 [02:00<01:04,  1.10s/it]avg_loss = 1.6129945527522935:  66%|██████▌   | 109/166 [02:00<01:02,  1.10s/it]avg_loss = 1.6164417613636364:  66%|██████▌   | 109/166 [02:01<01:02,  1.10s/it]avg_loss = 1.6164417613636364:  66%|██████▋   | 110/166 [02:01<01:01,  1.09s/it]avg_loss = 1.6178561373873874:  66%|██████▋   | 110/166 [02:02<01:01,  1.09s/it]avg_loss = 1.6178561373873874:  67%|██████▋   | 111/166 [02:02<00:59,  1.09s/it]avg_loss = 1.6191057477678572:  67%|██████▋   | 111/166 [02:03<00:59,  1.09s/it]avg_loss = 1.6191057477678572:  67%|██████▋   | 112/166 [02:03<00:58,  1.09s/it]avg_loss = 1.6191579092920354:  67%|██████▋   | 112/166 [02:04<00:58,  1.09s/it]avg_loss = 1.6191579092920354:  68%|██████▊   | 113/166 [02:04<00:57,  1.08s/it]avg_loss = 1.620031524122807:  68%|██████▊   | 113/166 [02:05<00:57,  1.08s/it] avg_loss = 1.620031524122807:  69%|██████▊   | 114/166 [02:05<00:56,  1.08s/it]avg_loss = 1.6168138586956522:  69%|██████▊   | 114/166 [02:07<00:56,  1.08s/it]avg_loss = 1.6168138586956522:  69%|██████▉   | 115/166 [02:07<00:54,  1.08s/it]avg_loss = 1.616143588362069:  69%|██████▉   | 115/166 [02:08<00:54,  1.08s/it] avg_loss = 1.616143588362069:  70%|██████▉   | 116/166 [02:08<00:53,  1.07s/it]avg_loss = 1.6172876602564104:  70%|██████▉   | 116/166 [02:09<00:53,  1.07s/it]avg_loss = 1.6172876602564104:  70%|███████   | 117/166 [02:09<00:52,  1.07s/it]avg_loss = 1.6167571504237288:  70%|███████   | 117/166 [02:10<00:52,  1.07s/it]avg_loss = 1.6167571504237288:  71%|███████   | 118/166 [02:10<00:51,  1.07s/it]avg_loss = 1.6156446953781514:  71%|███████   | 118/166 [02:11<00:51,  1.07s/it]avg_loss = 1.6156446953781514:  72%|███████▏  | 119/166 [02:11<00:50,  1.07s/it]avg_loss = 1.61572265625:  72%|███████▏  | 119/166 [02:12<00:50,  1.07s/it]     avg_loss = 1.61572265625:  72%|███████▏  | 120/166 [02:12<00:49,  1.07s/it]avg_loss = 1.6142497417355373:  72%|███████▏  | 120/166 [02:13<00:49,  1.07s/it]avg_loss = 1.6142497417355373:  73%|███████▎  | 121/166 [02:13<00:48,  1.08s/it]avg_loss = 1.6136974897540983:  73%|███████▎  | 121/166 [02:14<00:48,  1.08s/it]avg_loss = 1.6136974897540983:  73%|███████▎  | 122/166 [02:14<00:47,  1.08s/it]avg_loss = 1.6136623475609757:  73%|███████▎  | 122/166 [02:15<00:47,  1.08s/it]avg_loss = 1.6136623475609757:  74%|███████▍  | 123/166 [02:15<00:46,  1.09s/it]avg_loss = 1.611422631048387:  74%|███████▍  | 123/166 [02:16<00:46,  1.09s/it] avg_loss = 1.611422631048387:  75%|███████▍  | 124/166 [02:16<00:45,  1.08s/it]avg_loss = 1.60921875:  75%|███████▍  | 124/166 [02:17<00:45,  1.08s/it]       avg_loss = 1.60921875:  75%|███████▌  | 125/166 [02:17<00:45,  1.10s/it]avg_loss = 1.6065538194444444:  75%|███████▌  | 125/166 [02:18<00:45,  1.10s/it]avg_loss = 1.6065538194444444:  76%|███████▌  | 126/166 [02:18<00:43,  1.09s/it]avg_loss = 1.603869340551181:  76%|███████▌  | 126/166 [02:20<00:43,  1.09s/it] avg_loss = 1.603869340551181:  77%|███████▋  | 127/166 [02:20<00:43,  1.12s/it]avg_loss = 1.602081298828125:  77%|███████▋  | 127/166 [02:21<00:43,  1.12s/it]avg_loss = 1.602081298828125:  77%|███████▋  | 128/166 [02:21<00:41,  1.10s/it]avg_loss = 1.6006843507751938:  77%|███████▋  | 128/166 [02:22<00:41,  1.10s/it]avg_loss = 1.6006843507751938:  78%|███████▊  | 129/166 [02:22<00:41,  1.13s/it]avg_loss = 1.6006310096153846:  78%|███████▊  | 129/166 [02:23<00:41,  1.13s/it]avg_loss = 1.6006310096153846:  78%|███████▊  | 130/166 [02:23<00:39,  1.11s/it]avg_loss = 1.6017115935114503:  78%|███████▊  | 130/166 [02:24<00:39,  1.11s/it]avg_loss = 1.6017115935114503:  79%|███████▉  | 131/166 [02:24<00:39,  1.12s/it]avg_loss = 1.6020655776515151:  79%|███████▉  | 131/166 [02:25<00:39,  1.12s/it]avg_loss = 1.6020655776515151:  80%|███████▉  | 132/166 [02:25<00:37,  1.11s/it]avg_loss = 1.603001644736842:  80%|███████▉  | 132/166 [02:26<00:37,  1.11s/it] avg_loss = 1.603001644736842:  80%|████████  | 133/166 [02:26<00:36,  1.10s/it]avg_loss = 1.6043318563432836:  80%|████████  | 133/166 [02:27<00:36,  1.10s/it]avg_loss = 1.6043318563432836:  81%|████████  | 134/166 [02:27<00:35,  1.10s/it]avg_loss = 1.6025752314814814:  81%|████████  | 134/166 [02:28<00:35,  1.10s/it]avg_loss = 1.6025752314814814:  81%|████████▏ | 135/166 [02:28<00:33,  1.09s/it]avg_loss = 1.6030847886029411:  81%|████████▏ | 135/166 [02:29<00:33,  1.09s/it]avg_loss = 1.6030847886029411:  82%|████████▏ | 136/166 [02:29<00:32,  1.09s/it]avg_loss = 1.6035298813868613:  82%|████████▏ | 136/166 [02:31<00:32,  1.09s/it]avg_loss = 1.6035298813868613:  83%|████████▎ | 137/166 [02:31<00:31,  1.09s/it]avg_loss = 1.6043648097826086:  83%|████████▎ | 137/166 [02:32<00:31,  1.09s/it]avg_loss = 1.6043648097826086:  83%|████████▎ | 138/166 [02:32<00:30,  1.08s/it]avg_loss = 1.6038388039568345:  83%|████████▎ | 138/166 [02:33<00:30,  1.08s/it]avg_loss = 1.6038388039568345:  84%|████████▎ | 139/166 [02:33<00:29,  1.09s/it]avg_loss = 1.6027622767857144:  84%|████████▎ | 139/166 [02:34<00:29,  1.09s/it]avg_loss = 1.6027622767857144:  84%|████████▍ | 140/166 [02:34<00:28,  1.09s/it]avg_loss = 1.6016456117021276:  84%|████████▍ | 140/166 [02:35<00:28,  1.09s/it]avg_loss = 1.6016456117021276:  85%|████████▍ | 141/166 [02:35<00:27,  1.10s/it]avg_loss = 1.6013699383802817:  85%|████████▍ | 141/166 [02:36<00:27,  1.10s/it]avg_loss = 1.6013699383802817:  86%|████████▌ | 142/166 [02:36<00:26,  1.12s/it]avg_loss = 1.599732298951049:  86%|████████▌ | 142/166 [02:37<00:26,  1.12s/it] avg_loss = 1.599732298951049:  86%|████████▌ | 143/166 [02:37<00:25,  1.12s/it]avg_loss = 1.6011555989583333:  86%|████████▌ | 143/166 [02:38<00:25,  1.12s/it]avg_loss = 1.6011555989583333:  87%|████████▋ | 144/166 [02:38<00:24,  1.11s/it]avg_loss = 1.6007273706896552:  87%|████████▋ | 144/166 [02:39<00:24,  1.11s/it]avg_loss = 1.6007273706896552:  87%|████████▋ | 145/166 [02:39<00:23,  1.12s/it]avg_loss = 1.6008936215753424:  87%|████████▋ | 145/166 [02:41<00:23,  1.12s/it]avg_loss = 1.6008936215753424:  88%|████████▊ | 146/166 [02:41<00:22,  1.12s/it]avg_loss = 1.599782100340136:  88%|████████▊ | 146/166 [02:42<00:22,  1.12s/it] avg_loss = 1.599782100340136:  89%|████████▊ | 147/166 [02:42<00:21,  1.11s/it]avg_loss = 1.598949535472973:  89%|████████▊ | 147/166 [02:43<00:21,  1.11s/it]avg_loss = 1.598949535472973:  89%|████████▉ | 148/166 [02:43<00:19,  1.10s/it]avg_loss = 1.597498951342282:  89%|████████▉ | 148/166 [02:44<00:19,  1.10s/it]avg_loss = 1.597498951342282:  90%|████████▉ | 149/166 [02:44<00:18,  1.11s/it]avg_loss = 1.5985677083333334:  90%|████████▉ | 149/166 [02:45<00:18,  1.11s/it]avg_loss = 1.5985677083333334:  90%|█████████ | 150/166 [02:45<00:17,  1.10s/it]avg_loss = 1.597604511589404:  90%|█████████ | 150/166 [02:46<00:17,  1.10s/it] avg_loss = 1.597604511589404:  91%|█████████ | 151/166 [02:46<00:16,  1.11s/it]avg_loss = 1.597424958881579:  91%|█████████ | 151/166 [02:47<00:16,  1.11s/it]avg_loss = 1.597424958881579:  92%|█████████▏| 152/166 [02:47<00:15,  1.10s/it]avg_loss = 1.5974009395424837:  92%|█████████▏| 152/166 [02:48<00:15,  1.10s/it]avg_loss = 1.5974009395424837:  92%|█████████▏| 153/166 [02:48<00:14,  1.11s/it]avg_loss = 1.5990006087662338:  92%|█████████▏| 153/166 [02:49<00:14,  1.11s/it]avg_loss = 1.5990006087662338:  93%|█████████▎| 154/166 [02:49<00:13,  1.10s/it]avg_loss = 1.598664314516129:  93%|█████████▎| 154/166 [02:51<00:13,  1.10s/it] avg_loss = 1.598664314516129:  93%|█████████▎| 155/166 [02:51<00:12,  1.10s/it]avg_loss = 1.5986328125:  93%|█████████▎| 155/166 [02:52<00:12,  1.10s/it]     avg_loss = 1.5986328125:  94%|█████████▍| 156/166 [02:52<00:10,  1.09s/it]avg_loss = 1.5969098328025477:  94%|█████████▍| 156/166 [02:53<00:10,  1.09s/it]avg_loss = 1.5969098328025477:  95%|█████████▍| 157/166 [02:53<00:09,  1.10s/it]avg_loss = 1.5928599683544304:  95%|█████████▍| 157/166 [02:54<00:09,  1.10s/it]avg_loss = 1.5928599683544304:  95%|█████████▌| 158/166 [02:54<00:08,  1.09s/it]avg_loss = 1.5935534591194969:  95%|█████████▌| 158/166 [02:55<00:08,  1.09s/it]avg_loss = 1.5935534591194969:  96%|█████████▌| 159/166 [02:55<00:07,  1.09s/it]avg_loss = 1.595166015625:  96%|█████████▌| 159/166 [02:56<00:07,  1.09s/it]    avg_loss = 1.595166015625:  96%|█████████▋| 160/166 [02:56<00:06,  1.08s/it]avg_loss = 1.5977775621118013:  96%|█████████▋| 160/166 [02:57<00:06,  1.08s/it]avg_loss = 1.5977775621118013:  97%|█████████▋| 161/166 [02:57<00:05,  1.09s/it]avg_loss = 1.597608024691358:  97%|█████████▋| 161/166 [02:58<00:05,  1.09s/it] avg_loss = 1.597608024691358:  98%|█████████▊| 162/166 [02:58<00:04,  1.08s/it]avg_loss = 1.5970092024539877:  98%|█████████▊| 162/166 [02:59<00:04,  1.08s/it]avg_loss = 1.5970092024539877:  98%|█████████▊| 163/166 [02:59<00:03,  1.08s/it]avg_loss = 1.597799161585366:  98%|█████████▊| 163/166 [03:00<00:03,  1.08s/it] avg_loss = 1.597799161585366:  99%|█████████▉| 164/166 [03:00<00:02,  1.08s/it]avg_loss = 1.597537878787879:  99%|█████████▉| 164/166 [03:01<00:02,  1.08s/it]avg_loss = 1.597537878787879:  99%|█████████▉| 165/166 [03:01<00:01,  1.08s/it]avg_loss = 1.5994446536144578:  99%|█████████▉| 165/166 [03:02<00:01,  1.08s/it]avg_loss = 1.5994446536144578: 100%|██████████| 166/166 [03:02<00:00,  1.09s/it]avg_loss = 1.5994446536144578: 100%|██████████| 166/166 [03:02<00:00,  1.10s/it]
I0303 15:24:28.477184 3265228 eval_ppl.py:105] wikitext2 perplexity: 4.950282573699951
wikitext2 perplexity: 4.950
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda300_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_5.34295_bpp_5.7068_MSE_0.00302_total_iter_95000.pth.tar/COL_MSE0.01805_bpploss3.9434_bpp0
I0303 15:24:32.997528 3268048 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.23it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.20it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.23it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.28it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.62it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.67it/s]
W0303 15:24:36.800346 3268048 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 15:24:36.815223 3268048 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.2578125:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.2578125:   1%|          | 1/166 [00:01<03:56,  1.43s/it]avg_loss = 1.5546875:   1%|          | 1/166 [00:02<03:56,  1.43s/it]avg_loss = 1.5546875:   1%|          | 2/166 [00:02<03:07,  1.14s/it]avg_loss = 1.7239583333333333:   1%|          | 2/166 [00:03<03:07,  1.14s/it]avg_loss = 1.7239583333333333:   2%|▏         | 3/166 [00:03<02:53,  1.06s/it]avg_loss = 1.75:   2%|▏         | 3/166 [00:04<02:53,  1.06s/it]              avg_loss = 1.75:   2%|▏         | 4/166 [00:04<02:46,  1.03s/it]avg_loss = 1.6828125:   2%|▏         | 4/166 [00:05<02:46,  1.03s/it]avg_loss = 1.6828125:   3%|▎         | 5/166 [00:05<02:42,  1.01s/it]avg_loss = 1.65234375:   3%|▎         | 5/166 [00:06<02:42,  1.01s/it]avg_loss = 1.65234375:   4%|▎         | 6/166 [00:06<02:40,  1.01s/it]avg_loss = 1.5881696428571428:   4%|▎         | 6/166 [00:07<02:40,  1.01s/it]avg_loss = 1.5881696428571428:   4%|▍         | 7/166 [00:07<02:41,  1.02s/it]avg_loss = 1.521484375:   4%|▍         | 7/166 [00:08<02:41,  1.02s/it]       avg_loss = 1.521484375:   5%|▍         | 8/166 [00:08<02:38,  1.01s/it]avg_loss = 1.5182291666666667:   5%|▍         | 8/166 [00:09<02:38,  1.01s/it]avg_loss = 1.5182291666666667:   5%|▌         | 9/166 [00:09<02:37,  1.01s/it]avg_loss = 1.52890625:   5%|▌         | 9/166 [00:10<02:37,  1.01s/it]        avg_loss = 1.52890625:   6%|▌         | 10/166 [00:10<02:35,  1.00it/s]avg_loss = 1.5454545454545454:   6%|▌         | 10/166 [00:11<02:35,  1.00it/s]avg_loss = 1.5454545454545454:   7%|▋         | 11/166 [00:11<02:35,  1.00s/it]avg_loss = 1.5553385416666667:   7%|▋         | 11/166 [00:12<02:35,  1.00s/it]avg_loss = 1.5553385416666667:   7%|▋         | 12/166 [00:12<02:34,  1.00s/it]avg_loss = 1.5516826923076923:   7%|▋         | 12/166 [00:13<02:34,  1.00s/it]avg_loss = 1.5516826923076923:   8%|▊         | 13/166 [00:13<02:36,  1.02s/it]avg_loss = 1.5652901785714286:   8%|▊         | 13/166 [00:14<02:36,  1.02s/it]avg_loss = 1.5652901785714286:   8%|▊         | 14/166 [00:14<02:33,  1.01s/it]avg_loss = 1.58125:   8%|▊         | 14/166 [00:15<02:33,  1.01s/it]           avg_loss = 1.58125:   9%|▉         | 15/166 [00:15<02:36,  1.03s/it]avg_loss = 1.5986328125:   9%|▉         | 15/166 [00:16<02:36,  1.03s/it]avg_loss = 1.5986328125:  10%|▉         | 16/166 [00:16<02:33,  1.03s/it]avg_loss = 1.6079963235294117:  10%|▉         | 16/166 [00:17<02:33,  1.03s/it]avg_loss = 1.6079963235294117:  10%|█         | 17/166 [00:17<02:32,  1.02s/it]avg_loss = 1.6215277777777777:  10%|█         | 17/166 [00:18<02:32,  1.02s/it]avg_loss = 1.6215277777777777:  11%|█         | 18/166 [00:18<02:32,  1.03s/it]avg_loss = 1.640625:  11%|█         | 18/166 [00:19<02:32,  1.03s/it]          avg_loss = 1.640625:  11%|█▏        | 19/166 [00:19<02:31,  1.03s/it]avg_loss = 1.647265625:  11%|█▏        | 19/166 [00:20<02:31,  1.03s/it]avg_loss = 1.647265625:  12%|█▏        | 20/166 [00:20<02:28,  1.02s/it]avg_loss = 1.6476934523809523:  12%|█▏        | 20/166 [00:21<02:28,  1.02s/it]avg_loss = 1.6476934523809523:  13%|█▎        | 21/166 [00:21<02:29,  1.03s/it]avg_loss = 1.6374289772727273:  13%|█▎        | 21/166 [00:22<02:29,  1.03s/it]avg_loss = 1.6374289772727273:  13%|█▎        | 22/166 [00:22<02:27,  1.03s/it]avg_loss = 1.6209239130434783:  13%|█▎        | 22/166 [00:23<02:27,  1.03s/it]avg_loss = 1.6209239130434783:  14%|█▍        | 23/166 [00:23<02:29,  1.05s/it]avg_loss = 1.6285807291666667:  14%|█▍        | 23/166 [00:24<02:29,  1.05s/it]avg_loss = 1.6285807291666667:  14%|█▍        | 24/166 [00:24<02:27,  1.04s/it]avg_loss = 1.6359375:  14%|█▍        | 24/166 [00:25<02:27,  1.04s/it]         avg_loss = 1.6359375:  15%|█▌        | 25/166 [00:25<02:25,  1.03s/it]avg_loss = 1.6403245192307692:  15%|█▌        | 25/166 [00:26<02:25,  1.03s/it]avg_loss = 1.6403245192307692:  16%|█▌        | 26/166 [00:26<02:25,  1.04s/it]avg_loss = 1.6469907407407407:  16%|█▌        | 26/166 [00:27<02:25,  1.04s/it]avg_loss = 1.6469907407407407:  16%|█▋        | 27/166 [00:27<02:24,  1.04s/it]avg_loss = 1.6489955357142858:  16%|█▋        | 27/166 [00:28<02:24,  1.04s/it]avg_loss = 1.6489955357142858:  17%|█▋        | 28/166 [00:28<02:22,  1.03s/it]avg_loss = 1.6589439655172413:  17%|█▋        | 28/166 [00:29<02:22,  1.03s/it]avg_loss = 1.6589439655172413:  17%|█▋        | 29/166 [00:29<02:22,  1.04s/it]avg_loss = 1.6598958333333333:  17%|█▋        | 29/166 [00:30<02:22,  1.04s/it]avg_loss = 1.6598958333333333:  18%|█▊        | 30/166 [00:30<02:20,  1.03s/it]avg_loss = 1.6743951612903225:  18%|█▊        | 30/166 [00:31<02:20,  1.03s/it]avg_loss = 1.6743951612903225:  19%|█▊        | 31/166 [00:31<02:19,  1.03s/it]avg_loss = 1.681884765625:  19%|█▊        | 31/166 [00:33<02:19,  1.03s/it]    avg_loss = 1.681884765625:  19%|█▉        | 32/166 [00:33<02:18,  1.04s/it]avg_loss = 1.6870265151515151:  19%|█▉        | 32/166 [00:34<02:18,  1.04s/it]avg_loss = 1.6870265151515151:  20%|█▉        | 33/166 [00:34<02:16,  1.03s/it]avg_loss = 1.685202205882353:  20%|█▉        | 33/166 [00:35<02:16,  1.03s/it] avg_loss = 1.685202205882353:  20%|██        | 34/166 [00:35<02:16,  1.03s/it]avg_loss = 1.6785714285714286:  20%|██        | 34/166 [00:36<02:16,  1.03s/it]avg_loss = 1.6785714285714286:  21%|██        | 35/166 [00:36<02:14,  1.02s/it]avg_loss = 1.6692708333333333:  21%|██        | 35/166 [00:37<02:14,  1.02s/it]avg_loss = 1.6692708333333333:  22%|██▏       | 36/166 [00:37<02:13,  1.03s/it]avg_loss = 1.6587837837837838:  22%|██▏       | 36/166 [00:38<02:13,  1.03s/it]avg_loss = 1.6587837837837838:  22%|██▏       | 37/166 [00:38<02:12,  1.02s/it]avg_loss = 1.6554276315789473:  22%|██▏       | 37/166 [00:39<02:12,  1.02s/it]avg_loss = 1.6554276315789473:  23%|██▎       | 38/166 [00:39<02:09,  1.01s/it]avg_loss = 1.6530448717948718:  23%|██▎       | 38/166 [00:40<02:09,  1.01s/it]avg_loss = 1.6530448717948718:  23%|██▎       | 39/166 [00:40<02:11,  1.03s/it]avg_loss = 1.657421875:  23%|██▎       | 39/166 [00:41<02:11,  1.03s/it]       avg_loss = 1.657421875:  24%|██▍       | 40/166 [00:41<02:08,  1.02s/it]avg_loss = 1.6585365853658536:  24%|██▍       | 40/166 [00:42<02:08,  1.02s/it]avg_loss = 1.6585365853658536:  25%|██▍       | 41/166 [00:42<02:08,  1.03s/it]avg_loss = 1.6471354166666667:  25%|██▍       | 41/166 [00:43<02:08,  1.03s/it]avg_loss = 1.6471354166666667:  25%|██▌       | 42/166 [00:43<02:06,  1.02s/it]avg_loss = 1.632267441860465:  25%|██▌       | 42/166 [00:44<02:06,  1.02s/it] avg_loss = 1.632267441860465:  26%|██▌       | 43/166 [00:44<02:04,  1.02s/it]avg_loss = 1.6228693181818181:  26%|██▌       | 43/166 [00:45<02:04,  1.02s/it]avg_loss = 1.6228693181818181:  27%|██▋       | 44/166 [00:45<02:04,  1.02s/it]avg_loss = 1.6097222222222223:  27%|██▋       | 44/166 [00:46<02:04,  1.02s/it]avg_loss = 1.6097222222222223:  27%|██▋       | 45/166 [00:46<02:03,  1.02s/it]avg_loss = 1.599694293478261:  27%|██▋       | 45/166 [00:47<02:03,  1.02s/it] avg_loss = 1.599694293478261:  28%|██▊       | 46/166 [00:47<02:03,  1.03s/it]avg_loss = 1.593251329787234:  28%|██▊       | 46/166 [00:48<02:03,  1.03s/it]avg_loss = 1.593251329787234:  28%|██▊       | 47/166 [00:48<02:02,  1.03s/it]avg_loss = 1.5940755208333333:  28%|██▊       | 47/166 [00:49<02:02,  1.03s/it]avg_loss = 1.5940755208333333:  29%|██▉       | 48/166 [00:49<02:00,  1.02s/it]avg_loss = 1.6052295918367347:  29%|██▉       | 48/166 [00:50<02:00,  1.02s/it]avg_loss = 1.6052295918367347:  30%|██▉       | 49/166 [00:50<02:00,  1.03s/it]avg_loss = 1.61625:  30%|██▉       | 49/166 [00:51<02:00,  1.03s/it]           avg_loss = 1.61625:  30%|███       | 50/166 [00:51<01:58,  1.02s/it]avg_loss = 1.6231617647058822:  30%|███       | 50/166 [00:52<01:58,  1.02s/it]avg_loss = 1.6231617647058822:  31%|███       | 51/166 [00:52<01:58,  1.03s/it]avg_loss = 1.6272536057692308:  31%|███       | 51/166 [00:53<01:58,  1.03s/it]avg_loss = 1.6272536057692308:  31%|███▏      | 52/166 [00:53<01:56,  1.02s/it]avg_loss = 1.6304540094339623:  31%|███▏      | 52/166 [00:54<01:56,  1.02s/it]avg_loss = 1.6304540094339623:  32%|███▏      | 53/166 [00:54<01:55,  1.02s/it]avg_loss = 1.6320891203703705:  32%|███▏      | 53/166 [00:55<01:55,  1.02s/it]avg_loss = 1.6320891203703705:  33%|███▎      | 54/166 [00:55<01:53,  1.01s/it]avg_loss = 1.6355113636363636:  33%|███▎      | 54/166 [00:56<01:53,  1.01s/it]avg_loss = 1.6355113636363636:  33%|███▎      | 55/166 [00:56<01:52,  1.02s/it]avg_loss = 1.6396484375:  33%|███▎      | 55/166 [00:57<01:52,  1.02s/it]      avg_loss = 1.6396484375:  34%|███▎      | 56/166 [00:57<01:51,  1.01s/it]avg_loss = 1.6351425438596492:  34%|███▎      | 56/166 [00:58<01:51,  1.01s/it]avg_loss = 1.6351425438596492:  34%|███▍      | 57/166 [00:58<01:51,  1.02s/it]avg_loss = 1.6388739224137931:  34%|███▍      | 57/166 [00:59<01:51,  1.02s/it]avg_loss = 1.6388739224137931:  35%|███▍      | 58/166 [00:59<01:49,  1.01s/it]avg_loss = 1.6371822033898304:  35%|███▍      | 58/166 [01:00<01:49,  1.01s/it]avg_loss = 1.6371822033898304:  36%|███▌      | 59/166 [01:00<01:48,  1.01s/it]avg_loss = 1.6328125:  36%|███▌      | 59/166 [01:01<01:48,  1.01s/it]         avg_loss = 1.6328125:  36%|███▌      | 60/166 [01:01<01:46,  1.00s/it]avg_loss = 1.6289702868852458:  36%|███▌      | 60/166 [01:02<01:46,  1.00s/it]avg_loss = 1.6289702868852458:  37%|███▋      | 61/166 [01:02<01:45,  1.01s/it]avg_loss = 1.6255040322580645:  37%|███▋      | 61/166 [01:03<01:45,  1.01s/it]avg_loss = 1.6255040322580645:  37%|███▋      | 62/166 [01:03<01:44,  1.01s/it]avg_loss = 1.6197916666666667:  37%|███▋      | 62/166 [01:04<01:44,  1.01s/it]avg_loss = 1.6197916666666667:  38%|███▊      | 63/166 [01:04<01:44,  1.01s/it]avg_loss = 1.6156005859375:  38%|███▊      | 63/166 [01:05<01:44,  1.01s/it]   avg_loss = 1.6156005859375:  39%|███▊      | 64/166 [01:05<01:42,  1.01s/it]avg_loss = 1.6086538461538462:  39%|███▊      | 64/166 [01:06<01:42,  1.01s/it]avg_loss = 1.6086538461538462:  39%|███▉      | 65/166 [01:06<01:41,  1.01s/it]avg_loss = 1.601680871212121:  39%|███▉      | 65/166 [01:07<01:41,  1.01s/it] avg_loss = 1.601680871212121:  40%|███▉      | 66/166 [01:07<01:40,  1.01s/it]avg_loss = 1.595732276119403:  40%|███▉      | 66/166 [01:08<01:40,  1.01s/it]avg_loss = 1.595732276119403:  40%|████      | 67/166 [01:08<01:40,  1.02s/it]avg_loss = 1.5945542279411764:  40%|████      | 67/166 [01:09<01:40,  1.02s/it]avg_loss = 1.5945542279411764:  41%|████      | 68/166 [01:09<01:39,  1.01s/it]avg_loss = 1.5962409420289856:  41%|████      | 68/166 [01:10<01:39,  1.01s/it]avg_loss = 1.5962409420289856:  42%|████▏     | 69/166 [01:10<01:39,  1.02s/it]avg_loss = 1.5995535714285714:  42%|████▏     | 69/166 [01:11<01:39,  1.02s/it]avg_loss = 1.5995535714285714:  42%|████▏     | 70/166 [01:11<01:39,  1.03s/it]avg_loss = 1.603763204225352:  42%|████▏     | 70/166 [01:12<01:39,  1.03s/it] avg_loss = 1.603763204225352:  43%|████▎     | 71/166 [01:12<01:37,  1.03s/it]avg_loss = 1.6091579861111112:  43%|████▎     | 71/166 [01:13<01:37,  1.03s/it]avg_loss = 1.6091579861111112:  43%|████▎     | 72/166 [01:13<01:35,  1.02s/it]avg_loss = 1.615582191780822:  43%|████▎     | 72/166 [01:14<01:35,  1.02s/it] avg_loss = 1.615582191780822:  44%|████▍     | 73/166 [01:14<01:35,  1.03s/it]avg_loss = 1.6097972972972974:  44%|████▍     | 73/166 [01:15<01:35,  1.03s/it]avg_loss = 1.6097972972972974:  45%|████▍     | 74/166 [01:15<01:33,  1.01s/it]avg_loss = 1.6052083333333333:  45%|████▍     | 74/166 [01:16<01:33,  1.01s/it]avg_loss = 1.6052083333333333:  45%|████▌     | 75/166 [01:16<01:34,  1.04s/it]avg_loss = 1.6041324013157894:  45%|████▌     | 75/166 [01:17<01:34,  1.04s/it]avg_loss = 1.6041324013157894:  46%|████▌     | 76/166 [01:17<01:32,  1.02s/it]avg_loss = 1.6008522727272727:  46%|████▌     | 76/166 [01:18<01:32,  1.02s/it]avg_loss = 1.6008522727272727:  46%|████▋     | 77/166 [01:18<01:33,  1.05s/it]avg_loss = 1.5975560897435896:  46%|████▋     | 77/166 [01:19<01:33,  1.05s/it]avg_loss = 1.5975560897435896:  47%|████▋     | 78/166 [01:19<01:30,  1.03s/it]avg_loss = 1.5949367088607596:  47%|████▋     | 78/166 [01:20<01:30,  1.03s/it]avg_loss = 1.5949367088607596:  48%|████▊     | 79/166 [01:20<01:29,  1.03s/it]avg_loss = 1.59150390625:  48%|████▊     | 79/166 [01:22<01:29,  1.03s/it]     avg_loss = 1.59150390625:  48%|████▊     | 80/166 [01:22<01:28,  1.03s/it]avg_loss = 1.5818865740740742:  48%|████▊     | 80/166 [01:23<01:28,  1.03s/it]avg_loss = 1.5818865740740742:  49%|████▉     | 81/166 [01:23<01:26,  1.02s/it]avg_loss = 1.5836509146341464:  49%|████▉     | 81/166 [01:24<01:26,  1.02s/it]avg_loss = 1.5836509146341464:  49%|████▉     | 82/166 [01:24<01:26,  1.03s/it]avg_loss = 1.5847138554216869:  49%|████▉     | 82/166 [01:25<01:26,  1.03s/it]avg_loss = 1.5847138554216869:  50%|█████     | 83/166 [01:25<01:25,  1.02s/it]avg_loss = 1.5874255952380953:  50%|█████     | 83/166 [01:26<01:25,  1.02s/it]avg_loss = 1.5874255952380953:  51%|█████     | 84/166 [01:26<01:23,  1.02s/it]avg_loss = 1.5890625:  51%|█████     | 84/166 [01:27<01:23,  1.02s/it]         avg_loss = 1.5890625:  51%|█████     | 85/166 [01:27<01:24,  1.04s/it]avg_loss = 1.5880268895348837:  51%|█████     | 85/166 [01:28<01:24,  1.04s/it]avg_loss = 1.5880268895348837:  52%|█████▏    | 86/166 [01:28<01:21,  1.02s/it]avg_loss = 1.588451867816092:  52%|█████▏    | 86/166 [01:29<01:21,  1.02s/it] avg_loss = 1.588451867816092:  52%|█████▏    | 87/166 [01:29<01:21,  1.04s/it]avg_loss = 1.5890447443181819:  52%|█████▏    | 87/166 [01:30<01:21,  1.04s/it]avg_loss = 1.5890447443181819:  53%|█████▎    | 88/166 [01:30<01:20,  1.03s/it]avg_loss = 1.5902387640449438:  53%|█████▎    | 88/166 [01:31<01:20,  1.03s/it]avg_loss = 1.5902387640449438:  54%|█████▎    | 89/166 [01:31<01:20,  1.04s/it]avg_loss = 1.590017361111111:  54%|█████▎    | 89/166 [01:32<01:20,  1.04s/it] avg_loss = 1.590017361111111:  54%|█████▍    | 90/166 [01:32<01:17,  1.02s/it]avg_loss = 1.590831043956044:  54%|█████▍    | 90/166 [01:33<01:17,  1.02s/it]avg_loss = 1.590831043956044:  55%|█████▍    | 91/166 [01:33<01:17,  1.03s/it]avg_loss = 1.591117527173913:  55%|█████▍    | 91/166 [01:34<01:17,  1.03s/it]avg_loss = 1.591117527173913:  55%|█████▌    | 92/166 [01:34<01:15,  1.02s/it]avg_loss = 1.5945060483870968:  55%|█████▌    | 92/166 [01:35<01:15,  1.02s/it]avg_loss = 1.5945060483870968:  56%|█████▌    | 93/166 [01:35<01:15,  1.03s/it]avg_loss = 1.5939162234042554:  56%|█████▌    | 93/166 [01:36<01:15,  1.03s/it]avg_loss = 1.5939162234042554:  57%|█████▋    | 94/166 [01:36<01:13,  1.02s/it]avg_loss = 1.5933388157894737:  57%|█████▋    | 94/166 [01:37<01:13,  1.02s/it]avg_loss = 1.5933388157894737:  57%|█████▋    | 95/166 [01:37<01:13,  1.03s/it]avg_loss = 1.5928548177083333:  57%|█████▋    | 95/166 [01:38<01:13,  1.03s/it]avg_loss = 1.5928548177083333:  58%|█████▊    | 96/166 [01:38<01:11,  1.02s/it]avg_loss = 1.5920586340206186:  58%|█████▊    | 96/166 [01:39<01:11,  1.02s/it]avg_loss = 1.5920586340206186:  58%|█████▊    | 97/166 [01:39<01:11,  1.03s/it]avg_loss = 1.590481505102041:  58%|█████▊    | 97/166 [01:40<01:11,  1.03s/it] avg_loss = 1.590481505102041:  59%|█████▉    | 98/166 [01:40<01:09,  1.02s/it]avg_loss = 1.5882260101010102:  59%|█████▉    | 98/166 [01:41<01:09,  1.02s/it]avg_loss = 1.5882260101010102:  60%|█████▉    | 99/166 [01:41<01:09,  1.03s/it]avg_loss = 1.585546875:  60%|█████▉    | 99/166 [01:42<01:09,  1.03s/it]       avg_loss = 1.585546875:  60%|██████    | 100/166 [01:42<01:07,  1.03s/it]avg_loss = 1.5861695544554455:  60%|██████    | 100/166 [01:43<01:07,  1.03s/it]avg_loss = 1.5861695544554455:  61%|██████    | 101/166 [01:43<01:07,  1.03s/it]avg_loss = 1.5873161764705883:  61%|██████    | 101/166 [01:44<01:07,  1.03s/it]avg_loss = 1.5873161764705883:  61%|██████▏   | 102/166 [01:44<01:05,  1.02s/it]avg_loss = 1.5879095873786409:  61%|██████▏   | 102/166 [01:45<01:05,  1.02s/it]avg_loss = 1.5879095873786409:  62%|██████▏   | 103/166 [01:45<01:04,  1.03s/it]avg_loss = 1.5897686298076923:  62%|██████▏   | 103/166 [01:46<01:04,  1.03s/it]avg_loss = 1.5897686298076923:  63%|██████▎   | 104/166 [01:46<01:03,  1.02s/it]avg_loss = 1.5962053571428572:  63%|██████▎   | 104/166 [01:47<01:03,  1.02s/it]avg_loss = 1.5962053571428572:  63%|██████▎   | 105/166 [01:47<01:01,  1.02s/it]avg_loss = 1.6014887971698113:  63%|██████▎   | 105/166 [01:48<01:01,  1.02s/it]avg_loss = 1.6014887971698113:  64%|██████▍   | 106/166 [01:48<01:00,  1.02s/it]avg_loss = 1.6047021028037383:  64%|██████▍   | 106/166 [01:49<01:00,  1.02s/it]avg_loss = 1.6047021028037383:  64%|██████▍   | 107/166 [01:49<00:59,  1.02s/it]avg_loss = 1.6077112268518519:  64%|██████▍   | 107/166 [01:50<00:59,  1.02s/it]avg_loss = 1.6077112268518519:  65%|██████▌   | 108/166 [01:50<00:58,  1.01s/it]avg_loss = 1.612456995412844:  65%|██████▌   | 108/166 [01:51<00:58,  1.01s/it] avg_loss = 1.612456995412844:  66%|██████▌   | 109/166 [01:51<00:57,  1.01s/it]avg_loss = 1.6159801136363636:  66%|██████▌   | 109/166 [01:52<00:57,  1.01s/it]avg_loss = 1.6159801136363636:  66%|██████▋   | 110/166 [01:52<00:56,  1.01s/it]avg_loss = 1.6174690315315314:  66%|██████▋   | 110/166 [01:53<00:56,  1.01s/it]avg_loss = 1.6174690315315314:  67%|██████▋   | 111/166 [01:53<00:55,  1.01s/it]avg_loss = 1.6187918526785714:  67%|██████▋   | 111/166 [01:54<00:55,  1.01s/it]avg_loss = 1.6187918526785714:  67%|██████▋   | 112/166 [01:54<00:54,  1.01s/it]avg_loss = 1.6187776548672566:  67%|██████▋   | 112/166 [01:55<00:54,  1.01s/it]avg_loss = 1.6187776548672566:  68%|██████▊   | 113/166 [01:55<00:53,  1.00s/it]avg_loss = 1.619654605263158:  68%|██████▊   | 113/166 [01:56<00:53,  1.00s/it] avg_loss = 1.619654605263158:  69%|██████▊   | 114/166 [01:56<00:51,  1.00it/s]avg_loss = 1.6164402173913044:  69%|██████▊   | 114/166 [01:57<00:51,  1.00it/s]avg_loss = 1.6164402173913044:  69%|██████▉   | 115/166 [01:57<00:51,  1.00s/it]avg_loss = 1.6157731681034482:  69%|██████▉   | 115/166 [01:58<00:51,  1.00s/it]avg_loss = 1.6157731681034482:  70%|██████▉   | 116/166 [01:58<00:49,  1.00it/s]avg_loss = 1.6168536324786325:  70%|██████▉   | 116/166 [01:59<00:49,  1.00it/s]avg_loss = 1.6168536324786325:  70%|███████   | 117/166 [01:59<00:49,  1.01s/it]avg_loss = 1.6163268008474576:  70%|███████   | 117/166 [02:00<00:49,  1.01s/it]avg_loss = 1.6163268008474576:  71%|███████   | 118/166 [02:00<00:48,  1.01s/it]avg_loss = 1.6151523109243697:  71%|███████   | 118/166 [02:01<00:48,  1.01s/it]avg_loss = 1.6151523109243697:  72%|███████▏  | 119/166 [02:01<00:47,  1.01s/it]avg_loss = 1.615234375:  72%|███████▏  | 119/166 [02:02<00:47,  1.01s/it]       avg_loss = 1.615234375:  72%|███████▏  | 120/166 [02:02<00:47,  1.02s/it]avg_loss = 1.6137009297520661:  72%|███████▏  | 120/166 [02:03<00:47,  1.02s/it]avg_loss = 1.6137009297520661:  73%|███████▎  | 121/166 [02:03<00:45,  1.02s/it]avg_loss = 1.6130891393442623:  73%|███████▎  | 121/166 [02:04<00:45,  1.02s/it]avg_loss = 1.6130891393442623:  73%|███████▎  | 122/166 [02:04<00:44,  1.01s/it]avg_loss = 1.6129954268292683:  73%|███████▎  | 122/166 [02:05<00:44,  1.01s/it]avg_loss = 1.6129954268292683:  74%|███████▍  | 123/166 [02:05<00:44,  1.03s/it]avg_loss = 1.6108240927419355:  74%|███████▍  | 123/166 [02:06<00:44,  1.03s/it]avg_loss = 1.6108240927419355:  75%|███████▍  | 124/166 [02:06<00:42,  1.02s/it]avg_loss = 1.608625:  75%|███████▍  | 124/166 [02:07<00:42,  1.02s/it]          avg_loss = 1.608625:  75%|███████▌  | 125/166 [02:07<00:42,  1.04s/it]avg_loss = 1.6059647817460319:  75%|███████▌  | 125/166 [02:08<00:42,  1.04s/it]avg_loss = 1.6059647817460319:  76%|███████▌  | 126/166 [02:08<00:41,  1.03s/it]avg_loss = 1.6033464566929134:  76%|███████▌  | 126/166 [02:10<00:41,  1.03s/it]avg_loss = 1.6033464566929134:  77%|███████▋  | 127/166 [02:10<00:40,  1.05s/it]avg_loss = 1.60150146484375:  77%|███████▋  | 127/166 [02:11<00:40,  1.05s/it]  avg_loss = 1.60150146484375:  77%|███████▋  | 128/166 [02:11<00:39,  1.03s/it]avg_loss = 1.600109011627907:  77%|███████▋  | 128/166 [02:12<00:39,  1.03s/it]avg_loss = 1.600109011627907:  78%|███████▊  | 129/166 [02:12<00:38,  1.04s/it]avg_loss = 1.6000600961538463:  78%|███████▊  | 129/166 [02:13<00:38,  1.04s/it]avg_loss = 1.6000600961538463:  78%|███████▊  | 130/166 [02:13<00:36,  1.03s/it]avg_loss = 1.6011450381679388:  78%|███████▊  | 130/166 [02:14<00:36,  1.03s/it]avg_loss = 1.6011450381679388:  79%|███████▉  | 131/166 [02:14<00:35,  1.02s/it]avg_loss = 1.6015625:  79%|███████▉  | 131/166 [02:15<00:35,  1.02s/it]         avg_loss = 1.6015625:  80%|███████▉  | 132/166 [02:15<00:34,  1.03s/it]avg_loss = 1.6025023496240602:  80%|███████▉  | 132/166 [02:16<00:34,  1.03s/it]avg_loss = 1.6025023496240602:  80%|████████  | 133/166 [02:16<00:33,  1.02s/it]avg_loss = 1.6038362873134329:  80%|████████  | 133/166 [02:17<00:33,  1.02s/it]avg_loss = 1.6038362873134329:  81%|████████  | 134/166 [02:17<00:32,  1.01s/it]avg_loss = 1.6020833333333333:  81%|████████  | 134/166 [02:18<00:32,  1.01s/it]avg_loss = 1.6020833333333333:  81%|████████▏ | 135/166 [02:18<00:31,  1.02s/it]avg_loss = 1.6025390625:  81%|████████▏ | 135/166 [02:19<00:31,  1.02s/it]      avg_loss = 1.6025390625:  82%|████████▏ | 136/166 [02:19<00:30,  1.01s/it]avg_loss = 1.6029881386861313:  82%|████████▏ | 136/166 [02:20<00:30,  1.01s/it]avg_loss = 1.6029881386861313:  83%|████████▎ | 137/166 [02:20<00:29,  1.02s/it]avg_loss = 1.6038269927536233:  83%|████████▎ | 137/166 [02:21<00:29,  1.02s/it]avg_loss = 1.6038269927536233:  83%|████████▎ | 138/166 [02:21<00:28,  1.01s/it]avg_loss = 1.603304856115108:  83%|████████▎ | 138/166 [02:22<00:28,  1.01s/it] avg_loss = 1.603304856115108:  84%|████████▎ | 139/166 [02:22<00:27,  1.02s/it]avg_loss = 1.6022321428571429:  84%|████████▎ | 139/166 [02:23<00:27,  1.02s/it]avg_loss = 1.6022321428571429:  84%|████████▍ | 140/166 [02:23<00:26,  1.01s/it]avg_loss = 1.6011192375886525:  84%|████████▍ | 140/166 [02:24<00:26,  1.01s/it]avg_loss = 1.6011192375886525:  85%|████████▍ | 141/166 [02:24<00:25,  1.02s/it]avg_loss = 1.6007922535211268:  85%|████████▍ | 141/166 [02:25<00:25,  1.02s/it]avg_loss = 1.6007922535211268:  86%|████████▌ | 142/166 [02:25<00:24,  1.01s/it]avg_loss = 1.5991586538461537:  86%|████████▌ | 142/166 [02:26<00:24,  1.01s/it]avg_loss = 1.5991586538461537:  86%|████████▌ | 143/166 [02:26<00:23,  1.02s/it]avg_loss = 1.6005316840277777:  86%|████████▌ | 143/166 [02:27<00:23,  1.02s/it]avg_loss = 1.6005316840277777:  87%|████████▋ | 144/166 [02:27<00:22,  1.00s/it]avg_loss = 1.6001077586206895:  87%|████████▋ | 144/166 [02:28<00:22,  1.00s/it]avg_loss = 1.6001077586206895:  87%|████████▋ | 145/166 [02:28<00:21,  1.02s/it]avg_loss = 1.60033176369863:  87%|████████▋ | 145/166 [02:29<00:21,  1.02s/it]  avg_loss = 1.60033176369863:  88%|████████▊ | 146/166 [02:29<00:20,  1.00s/it]avg_loss = 1.5992240646258504:  88%|████████▊ | 146/166 [02:30<00:20,  1.00s/it]avg_loss = 1.5992240646258504:  89%|████████▊ | 147/166 [02:30<00:19,  1.02s/it]avg_loss = 1.5984480574324325:  89%|████████▊ | 147/166 [02:31<00:19,  1.02s/it]avg_loss = 1.5984480574324325:  89%|████████▉ | 148/166 [02:31<00:18,  1.00s/it]avg_loss = 1.5970008389261745:  89%|████████▉ | 148/166 [02:32<00:18,  1.00s/it]avg_loss = 1.5970008389261745:  90%|████████▉ | 149/166 [02:32<00:17,  1.02s/it]avg_loss = 1.5980729166666667:  90%|████████▉ | 149/166 [02:33<00:17,  1.02s/it]avg_loss = 1.5980729166666667:  90%|█████████ | 150/166 [02:33<00:16,  1.00s/it]avg_loss = 1.5971129966887416:  90%|█████████ | 150/166 [02:34<00:16,  1.00s/it]avg_loss = 1.5971129966887416:  91%|█████████ | 151/166 [02:34<00:15,  1.02s/it]avg_loss = 1.596936677631579:  91%|█████████ | 151/166 [02:35<00:15,  1.02s/it] avg_loss = 1.596936677631579:  92%|█████████▏| 152/166 [02:35<00:14,  1.01s/it]avg_loss = 1.5969158496732025:  92%|█████████▏| 152/166 [02:36<00:14,  1.01s/it]avg_loss = 1.5969158496732025:  92%|█████████▏| 153/166 [02:36<00:13,  1.02s/it]avg_loss = 1.5985693993506493:  92%|█████████▏| 153/166 [02:37<00:13,  1.02s/it]avg_loss = 1.5985693993506493:  93%|█████████▎| 154/166 [02:37<00:12,  1.01s/it]avg_loss = 1.5981854838709677:  93%|█████████▎| 154/166 [02:38<00:12,  1.01s/it]avg_loss = 1.5981854838709677:  93%|█████████▎| 155/166 [02:38<00:11,  1.01s/it]avg_loss = 1.5981069711538463:  93%|█████████▎| 155/166 [02:39<00:11,  1.01s/it]avg_loss = 1.5981069711538463:  94%|█████████▍| 156/166 [02:39<00:09,  1.00it/s]avg_loss = 1.5963873407643312:  94%|█████████▍| 156/166 [02:40<00:09,  1.00it/s]avg_loss = 1.5963873407643312:  95%|█████████▍| 157/166 [02:40<00:08,  1.00it/s]avg_loss = 1.5923160601265822:  95%|█████████▍| 157/166 [02:41<00:08,  1.00it/s]avg_loss = 1.5923160601265822:  95%|█████████▌| 158/166 [02:41<00:07,  1.01it/s]avg_loss = 1.5930129716981132:  95%|█████████▌| 158/166 [02:42<00:07,  1.01it/s]avg_loss = 1.5930129716981132:  96%|█████████▌| 159/166 [02:42<00:06,  1.00it/s]avg_loss = 1.594580078125:  96%|█████████▌| 159/166 [02:43<00:06,  1.00it/s]    avg_loss = 1.594580078125:  96%|█████████▋| 160/166 [02:43<00:05,  1.00it/s]avg_loss = 1.5970982142857142:  96%|█████████▋| 160/166 [02:44<00:05,  1.00it/s]avg_loss = 1.5970982142857142:  97%|█████████▋| 161/166 [02:44<00:05,  1.00s/it]avg_loss = 1.5969328703703705:  97%|█████████▋| 161/166 [02:45<00:05,  1.00s/it]avg_loss = 1.5969328703703705:  98%|█████████▊| 162/166 [02:45<00:04,  1.00s/it]avg_loss = 1.596338190184049:  98%|█████████▊| 162/166 [02:46<00:04,  1.00s/it] avg_loss = 1.596338190184049:  98%|█████████▊| 163/166 [02:46<00:03,  1.00s/it]avg_loss = 1.5970846036585367:  98%|█████████▊| 163/166 [02:47<00:03,  1.00s/it]avg_loss = 1.5970846036585367:  99%|█████████▉| 164/166 [02:47<00:01,  1.00it/s]avg_loss = 1.596780303030303:  99%|█████████▉| 164/166 [02:48<00:01,  1.00it/s] avg_loss = 1.596780303030303:  99%|█████████▉| 165/166 [02:48<00:01,  1.00s/it]avg_loss = 1.598691641566265:  99%|█████████▉| 165/166 [02:49<00:01,  1.00s/it]avg_loss = 1.598691641566265: 100%|██████████| 166/166 [02:49<00:00,  1.02s/it]avg_loss = 1.598691641566265: 100%|██████████| 166/166 [02:49<00:00,  1.02s/it]
I0303 15:28:10.835106 3268048 eval_ppl.py:105] wikitext2 perplexity: 4.946556091308594
wikitext2 perplexity: 4.947
Running with lmbda=1000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  9.09it/s]Loading checkpoint shards:  18%|█▊        | 2/11 [00:00<00:00,  9.59it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00,  9.30it/s]Loading checkpoint shards:  36%|███▋      | 4/11 [00:00<00:00,  9.48it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00,  9.50it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00, 10.11it/s]Loading checkpoint shards:  73%|███████▎  | 8/11 [00:00<00:00,  9.82it/s]Loading checkpoint shards:  91%|█████████ | 10/11 [00:01<00:00, 10.05it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00,  9.92it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:23,  1.63it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:01<00:22,  1.67it/s]calculating model weight mean & std:   8%|▊         | 3/40 [00:01<00:21,  1.69it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:02<00:21,  1.69it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:02<00:20,  1.73it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:03<00:19,  1.76it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:04<00:18,  1.79it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:04<00:21,  1.47it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:06<00:24,  1.24it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:06<00:24,  1.24it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:07<00:24,  1.19it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:08<00:21,  1.30it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:08<00:18,  1.43it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:09<00:16,  1.53it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:10<00:16,  1.54it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:10<00:14,  1.61it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:11<00:17,  1.33it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:12<00:17,  1.23it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:13<00:18,  1.16it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:14<00:17,  1.14it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:15<00:17,  1.11it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:16<00:15,  1.13it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:17<00:16,  1.06it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:18<00:15,  1.05it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:19<00:13,  1.10it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:20<00:13,  1.06it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:21<00:13,  1.03s/it]calculating model weight mean & std:  70%|███████   | 28/40 [00:22<00:11,  1.07it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:22<00:09,  1.14it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:23<00:07,  1.25it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:24<00:07,  1.16it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:25<00:07,  1.01it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:27<00:07,  1.11s/it]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:28<00:06,  1.16s/it]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:29<00:05,  1.16s/it]calculating model weight mean & std:  90%|█████████ | 36/40 [00:30<00:03,  1.00it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:30<00:02,  1.10it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:31<00:01,  1.22it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:32<00:00,  1.30it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:32<00:00,  1.34it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:32<00:00,  1.21it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 15:29:24 - INFO - layer0_self_attn.q_proj | mse: 0.1097777221571381, bpp_loss: 4.285247448608279, bpp: 0
2025-03-03 15:29:35 - INFO - layer0_self_attn.k_proj | mse: 0.06215161793991693, bpp_loss: 4.343135120645165, bpp: 0
2025-03-03 15:29:47 - INFO - layer0_self_attn.v_proj | mse: 0.013541261819008377, bpp_loss: 4.224522980749607, bpp: 0
2025-03-03 15:29:58 - INFO - layer0_self_attn.o_proj | mse: 0.013223577229629092, bpp_loss: 4.137232810109854, bpp: 0
2025-03-03 15:30:13 - INFO - layer0_mlp.gate_proj | mse: 0.0070050781181350075, bpp_loss: 4.539853735544064, bpp: 0
2025-03-03 15:30:28 - INFO - layer0_mlp.up_proj | mse: 0.006989722676618642, bpp_loss: 4.512349666489495, bpp: 0
2025-03-03 15:31:07 - INFO - layer0_mlp.down_proj | mse: 0.01464092901449884, bpp_loss: 4.62441618701926, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [01:54<1:14:39, 114.85s/it]2025-03-03 15:31:19 - INFO - layer1_self_attn.q_proj | mse: 0.011099248687105115, bpp_loss: 4.784101946055889, bpp: 0
2025-03-03 15:31:30 - INFO - layer1_self_attn.k_proj | mse: 0.01120082687954848, bpp_loss: 4.823775172457099, bpp: 0
2025-03-03 15:31:42 - INFO - layer1_self_attn.v_proj | mse: 0.010233292533831106, bpp_loss: 4.292109276354313, bpp: 0
2025-03-03 15:31:54 - INFO - layer1_self_attn.o_proj | mse: 0.028254052425095374, bpp_loss: 4.254866445884108, bpp: 0
2025-03-03 15:32:08 - INFO - layer1_mlp.gate_proj | mse: 0.00802241852271363, bpp_loss: 4.713003389923661, bpp: 0
2025-03-03 15:32:23 - INFO - layer1_mlp.up_proj | mse: 0.007986558028485904, bpp_loss: 4.647755250886634, bpp: 0
2025-03-03 15:33:02 - INFO - layer1_mlp.down_proj | mse: 0.005929979526064772, bpp_loss: 4.682188441135265, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [03:50<1:12:52, 115.06s/it]2025-03-03 15:33:14 - INFO - layer2_self_attn.q_proj | mse: 0.0069643661119548235, bpp_loss: 5.133868737667799, bpp: 0
2025-03-03 15:33:26 - INFO - layer2_self_attn.k_proj | mse: 0.00701834427263704, bpp_loss: 5.188234791830182, bpp: 0
2025-03-03 15:33:37 - INFO - layer2_self_attn.v_proj | mse: 0.006633488158950511, bpp_loss: 4.420991065874696, bpp: 0
2025-03-03 15:33:49 - INFO - layer2_self_attn.o_proj | mse: 0.008285651141171428, bpp_loss: 4.412743522822857, bpp: 0
2025-03-03 15:34:03 - INFO - layer2_mlp.gate_proj | mse: 0.006674275857342186, bpp_loss: 4.775285823256882, bpp: 0
2025-03-03 15:34:18 - INFO - layer2_mlp.up_proj | mse: 0.006634970157171634, bpp_loss: 4.67821829451455, bpp: 0
2025-03-03 15:34:56 - INFO - layer2_mlp.down_proj | mse: 0.005231247536967666, bpp_loss: 4.695658195846611, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [05:44<1:10:47, 114.80s/it]2025-03-03 15:35:08 - INFO - layer3_self_attn.q_proj | mse: 0.0061788151734456535, bpp_loss: 5.193070806711912, bpp: 0
2025-03-03 15:35:20 - INFO - layer3_self_attn.k_proj | mse: 0.006251129064195509, bpp_loss: 5.284859126657247, bpp: 0
2025-03-03 15:35:31 - INFO - layer3_self_attn.v_proj | mse: 0.005860514556934385, bpp_loss: 4.4617888958007095, bpp: 0
2025-03-03 15:35:43 - INFO - layer3_self_attn.o_proj | mse: 0.006000341591251282, bpp_loss: 4.435737521052361, bpp: 0
2025-03-03 15:35:57 - INFO - layer3_mlp.gate_proj | mse: 0.005978695163854339, bpp_loss: 4.7936100495634255, bpp: 0
2025-03-03 15:36:12 - INFO - layer3_mlp.up_proj | mse: 0.005941783322148346, bpp_loss: 4.69133901954801, bpp: 0
2025-03-03 15:36:50 - INFO - layer3_mlp.down_proj | mse: 0.012551855565851939, bpp_loss: 4.696151022585454, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [07:38<1:08:39, 114.43s/it]2025-03-03 15:37:02 - INFO - layer4_self_attn.q_proj | mse: 0.005821099481604065, bpp_loss: 5.129046364799142, bpp: 0
2025-03-03 15:37:14 - INFO - layer4_self_attn.k_proj | mse: 0.005840966240728846, bpp_loss: 5.148079242557287, bpp: 0
2025-03-03 15:37:25 - INFO - layer4_self_attn.v_proj | mse: 0.005578719921486819, bpp_loss: 4.451283920258284, bpp: 0
2025-03-03 15:37:36 - INFO - layer4_self_attn.o_proj | mse: 0.005408411364070399, bpp_loss: 4.44444426573813, bpp: 0
2025-03-03 15:37:51 - INFO - layer4_mlp.gate_proj | mse: 0.005730378357484043, bpp_loss: 4.801329347104938, bpp: 0
2025-03-03 15:38:06 - INFO - layer4_mlp.up_proj | mse: 0.005695346717865247, bpp_loss: 4.693698144290182, bpp: 0
2025-03-03 15:38:44 - INFO - layer4_mlp.down_proj | mse: 0.005029707452903665, bpp_loss: 4.698220422725987, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [09:32<1:06:37, 114.22s/it]2025-03-03 15:38:56 - INFO - layer5_self_attn.q_proj | mse: 0.005653901189090288, bpp_loss: 5.087149981707334, bpp: 0
2025-03-03 15:39:07 - INFO - layer5_self_attn.k_proj | mse: 0.005654014753159014, bpp_loss: 5.078901729732752, bpp: 0
2025-03-03 15:39:19 - INFO - layer5_self_attn.v_proj | mse: 0.005424146245200818, bpp_loss: 4.472161938473582, bpp: 0
2025-03-03 15:39:30 - INFO - layer5_self_attn.o_proj | mse: 0.005931711811596241, bpp_loss: 4.460146293342113, bpp: 0
2025-03-03 15:39:45 - INFO - layer5_mlp.gate_proj | mse: 0.00564622214642231, bpp_loss: 4.817321695497743, bpp: 0
2025-03-03 15:39:59 - INFO - layer5_mlp.up_proj | mse: 0.0055960221927775665, bpp_loss: 4.692022248661076, bpp: 0
2025-03-03 15:40:38 - INFO - layer5_mlp.down_proj | mse: 0.005019394153032749, bpp_loss: 4.695847050707649, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [11:26<1:04:41, 114.15s/it]2025-03-03 15:40:50 - INFO - layer6_self_attn.q_proj | mse: 0.005536337347511683, bpp_loss: 5.105579705536366, bpp: 0
2025-03-03 15:41:01 - INFO - layer6_self_attn.k_proj | mse: 0.005553814162398308, bpp_loss: 5.13331460416317, bpp: 0
2025-03-03 15:41:13 - INFO - layer6_self_attn.v_proj | mse: 0.00532396512256618, bpp_loss: 4.494533620029688, bpp: 0
2025-03-03 15:41:24 - INFO - layer6_self_attn.o_proj | mse: 0.005457613808017604, bpp_loss: 4.486925648152829, bpp: 0
2025-03-03 15:41:39 - INFO - layer6_mlp.gate_proj | mse: 0.005417084019377171, bpp_loss: 4.831573176163214, bpp: 0
2025-03-03 15:41:53 - INFO - layer6_mlp.up_proj | mse: 0.0053740501902324045, bpp_loss: 4.689061386331364, bpp: 0
2025-03-03 15:42:32 - INFO - layer6_mlp.down_proj | mse: 0.0050089757870846454, bpp_loss: 4.691054805588943, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [13:20<1:02:42, 114.03s/it]2025-03-03 15:42:44 - INFO - layer7_self_attn.q_proj | mse: 0.005480565338070416, bpp_loss: 5.134741315767169, bpp: 0
2025-03-03 15:42:55 - INFO - layer7_self_attn.k_proj | mse: 0.005505852116197672, bpp_loss: 5.161807158067822, bpp: 0
2025-03-03 15:43:07 - INFO - layer7_self_attn.v_proj | mse: 0.005272442263402488, bpp_loss: 4.511811671108007, bpp: 0
2025-03-03 15:43:18 - INFO - layer7_self_attn.o_proj | mse: 0.005431596975162828, bpp_loss: 4.500233484581113, bpp: 0
2025-03-03 15:43:33 - INFO - layer7_mlp.gate_proj | mse: 0.0053445925463556756, bpp_loss: 4.837695162329409, bpp: 0
2025-03-03 15:43:47 - INFO - layer7_mlp.up_proj | mse: 0.0053014728789125545, bpp_loss: 4.690659303080152, bpp: 0
2025-03-03 15:44:26 - INFO - layer7_mlp.down_proj | mse: 0.005031111080758387, bpp_loss: 4.689959817931608, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [15:14<1:00:49, 114.04s/it]2025-03-03 15:44:38 - INFO - layer8_self_attn.q_proj | mse: 0.005438710257606339, bpp_loss: 5.095027528256178, bpp: 0
2025-03-03 15:44:49 - INFO - layer8_self_attn.k_proj | mse: 0.005464732189256038, bpp_loss: 5.122313469946384, bpp: 0
2025-03-03 15:45:01 - INFO - layer8_self_attn.v_proj | mse: 0.005240340250571275, bpp_loss: 4.519483075216413, bpp: 0
2025-03-03 15:45:13 - INFO - layer8_self_attn.o_proj | mse: 0.005474692916900285, bpp_loss: 4.509879759401083, bpp: 0
2025-03-03 15:45:27 - INFO - layer8_mlp.gate_proj | mse: 0.005313073409905621, bpp_loss: 4.833511437475681, bpp: 0
2025-03-03 15:45:42 - INFO - layer8_mlp.up_proj | mse: 0.005273888913412347, bpp_loss: 4.701660333960144, bpp: 0
2025-03-03 15:46:21 - INFO - layer8_mlp.down_proj | mse: 0.005012265797384046, bpp_loss: 4.699117805008535, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [17:08<59:01, 114.25s/it]  2025-03-03 15:46:33 - INFO - layer9_self_attn.q_proj | mse: 0.005408025709763543, bpp_loss: 5.084325000569224, bpp: 0
2025-03-03 15:46:44 - INFO - layer9_self_attn.k_proj | mse: 0.005416867947212548, bpp_loss: 5.09452482804656, bpp: 0
2025-03-03 15:46:56 - INFO - layer9_self_attn.v_proj | mse: 0.005219340168393295, bpp_loss: 4.515641651526093, bpp: 0
2025-03-03 15:47:08 - INFO - layer9_self_attn.o_proj | mse: 0.005451602792330946, bpp_loss: 4.511350154802203, bpp: 0
2025-03-03 15:47:22 - INFO - layer9_mlp.gate_proj | mse: 0.005267611386976952, bpp_loss: 4.820022856471716, bpp: 0
2025-03-03 15:47:37 - INFO - layer9_mlp.up_proj | mse: 0.005236963680931811, bpp_loss: 4.714403210028454, bpp: 0
2025-03-03 15:48:16 - INFO - layer9_mlp.down_proj | mse: 0.004991482628586014, bpp_loss: 4.7095460052015605, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [19:04<57:20, 114.69s/it]2025-03-03 15:48:28 - INFO - layer10_self_attn.q_proj | mse: 0.00538611665150895, bpp_loss: 5.078441891893744, bpp: 0
2025-03-03 15:48:40 - INFO - layer10_self_attn.k_proj | mse: 0.005413880053388042, bpp_loss: 5.104195208027959, bpp: 0
2025-03-03 15:48:52 - INFO - layer10_self_attn.v_proj | mse: 0.005203790234460514, bpp_loss: 4.508871253579855, bpp: 0
2025-03-03 15:49:03 - INFO - layer10_self_attn.o_proj | mse: 0.00532172582454164, bpp_loss: 4.5093116377294065, bpp: 0
2025-03-03 15:49:18 - INFO - layer10_mlp.gate_proj | mse: 0.005255573080662268, bpp_loss: 4.8056124385860235, bpp: 0
2025-03-03 15:49:33 - INFO - layer10_mlp.up_proj | mse: 0.005231885143847858, bpp_loss: 4.723659149308999, bpp: 0
2025-03-03 15:50:12 - INFO - layer10_mlp.down_proj | mse: 0.005016239767244751, bpp_loss: 4.717950479713855, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [21:00<55:35, 115.03s/it]2025-03-03 15:50:24 - INFO - layer11_self_attn.q_proj | mse: 0.005389651506970582, bpp_loss: 5.13060583807528, bpp: 0
2025-03-03 15:50:36 - INFO - layer11_self_attn.k_proj | mse: 0.005424441048252694, bpp_loss: 5.165679853633046, bpp: 0
2025-03-03 15:50:47 - INFO - layer11_self_attn.v_proj | mse: 0.005191295405739852, bpp_loss: 4.519008598849178, bpp: 0
2025-03-03 15:50:59 - INFO - layer11_self_attn.o_proj | mse: 0.0055095779447054865, bpp_loss: 4.5077341807633635, bpp: 0
2025-03-03 15:51:14 - INFO - layer11_mlp.gate_proj | mse: 0.005224503050189214, bpp_loss: 4.792089866984774, bpp: 0
2025-03-03 15:51:28 - INFO - layer11_mlp.up_proj | mse: 0.005206967659247791, bpp_loss: 4.733323439845332, bpp: 0
2025-03-03 15:52:07 - INFO - layer11_mlp.down_proj | mse: 0.005025962156269782, bpp_loss: 4.72535615152231, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [22:55<53:38, 114.96s/it]2025-03-03 15:52:19 - INFO - layer12_self_attn.q_proj | mse: 0.005351778585340874, bpp_loss: 5.070826392397285, bpp: 0
2025-03-03 15:52:30 - INFO - layer12_self_attn.k_proj | mse: 0.005385532607726933, bpp_loss: 5.096605132222176, bpp: 0
2025-03-03 15:52:42 - INFO - layer12_self_attn.v_proj | mse: 0.005183332015124739, bpp_loss: 4.541946902498603, bpp: 0
2025-03-03 15:52:53 - INFO - layer12_self_attn.o_proj | mse: 0.005693073376371578, bpp_loss: 4.533717485070229, bpp: 0
2025-03-03 15:53:08 - INFO - layer12_mlp.gate_proj | mse: 0.005217324908327465, bpp_loss: 4.786825475096703, bpp: 0
2025-03-03 15:53:22 - INFO - layer12_mlp.up_proj | mse: 0.005205028743764518, bpp_loss: 4.742566596137153, bpp: 0
2025-03-03 15:54:01 - INFO - layer12_mlp.down_proj | mse: 0.005011779265908963, bpp_loss: 4.7334558083503335, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [24:48<51:34, 114.63s/it]2025-03-03 15:54:13 - INFO - layer13_self_attn.q_proj | mse: 0.005334242439022425, bpp_loss: 5.019135474935174, bpp: 0
2025-03-03 15:54:24 - INFO - layer13_self_attn.k_proj | mse: 0.005363985100385017, bpp_loss: 5.016516304761171, bpp: 0
2025-03-03 15:54:35 - INFO - layer13_self_attn.v_proj | mse: 0.005186240645864543, bpp_loss: 4.559789819270373, bpp: 0
2025-03-03 15:54:47 - INFO - layer13_self_attn.o_proj | mse: 0.005399945510392028, bpp_loss: 4.558805291131139, bpp: 0
2025-03-03 15:55:01 - INFO - layer13_mlp.gate_proj | mse: 0.00521887308787662, bpp_loss: 4.782693105770482, bpp: 0
2025-03-03 15:55:16 - INFO - layer13_mlp.up_proj | mse: 0.005209445295891547, bpp_loss: 4.750314080273664, bpp: 0
2025-03-03 15:55:54 - INFO - layer13_mlp.down_proj | mse: 0.005009449957844765, bpp_loss: 4.740571221985199, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [26:42<49:33, 114.38s/it]2025-03-03 15:56:06 - INFO - layer14_self_attn.q_proj | mse: 0.005341981482660954, bpp_loss: 5.056594785451889, bpp: 0
2025-03-03 15:56:18 - INFO - layer14_self_attn.k_proj | mse: 0.005377793564088405, bpp_loss: 5.085037549212575, bpp: 0
2025-03-03 15:56:29 - INFO - layer14_self_attn.v_proj | mse: 0.005177197701306323, bpp_loss: 4.549425220638514, bpp: 0
2025-03-03 15:56:41 - INFO - layer14_self_attn.o_proj | mse: 0.0053276186408914615, bpp_loss: 4.544403674826026, bpp: 0
2025-03-03 15:56:55 - INFO - layer14_mlp.gate_proj | mse: 0.005210023846022469, bpp_loss: 4.778675956527392, bpp: 0
2025-03-03 15:57:10 - INFO - layer14_mlp.up_proj | mse: 0.005203147854970934, bpp_loss: 4.756350014551922, bpp: 0
2025-03-03 15:57:48 - INFO - layer14_mlp.down_proj | mse: 0.004997893376060458, bpp_loss: 4.745139709170218, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [28:36<47:32, 114.11s/it]2025-03-03 15:58:00 - INFO - layer15_self_attn.q_proj | mse: 0.005319389649413575, bpp_loss: 5.035059620887041, bpp: 0
2025-03-03 15:58:11 - INFO - layer15_self_attn.k_proj | mse: 0.005357217145415793, bpp_loss: 5.0789008975028995, bpp: 0
2025-03-03 15:58:23 - INFO - layer15_self_attn.v_proj | mse: 0.005173999829836376, bpp_loss: 4.583750865459442, bpp: 0
2025-03-03 15:58:34 - INFO - layer15_self_attn.o_proj | mse: 0.005746353002149432, bpp_loss: 4.578946997374296, bpp: 0
2025-03-03 15:58:49 - INFO - layer15_mlp.gate_proj | mse: 0.005208538156754519, bpp_loss: 4.78079418959441, bpp: 0
2025-03-03 15:59:03 - INFO - layer15_mlp.up_proj | mse: 0.005203957481801032, bpp_loss: 4.763820722643976, bpp: 0
2025-03-03 15:59:42 - INFO - layer15_mlp.down_proj | mse: 0.0049954109324719925, bpp_loss: 4.752323436185166, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [30:29<45:34, 113.95s/it]2025-03-03 15:59:54 - INFO - layer16_self_attn.q_proj | mse: 0.0053084402190812004, bpp_loss: 5.021810480654239, bpp: 0
2025-03-03 16:00:05 - INFO - layer16_self_attn.k_proj | mse: 0.005343652960341868, bpp_loss: 5.053106632605195, bpp: 0
2025-03-03 16:00:17 - INFO - layer16_self_attn.v_proj | mse: 0.0051720154715579544, bpp_loss: 4.588882506489754, bpp: 0
2025-03-03 16:00:28 - INFO - layer16_self_attn.o_proj | mse: 0.005331999896310207, bpp_loss: 4.583648272231221, bpp: 0
2025-03-03 16:00:43 - INFO - layer16_mlp.gate_proj | mse: 0.005213240378738477, bpp_loss: 4.784425854738112, bpp: 0
2025-03-03 16:00:57 - INFO - layer16_mlp.up_proj | mse: 0.0052091561925026834, bpp_loss: 4.763331880834367, bpp: 0
2025-03-03 16:01:35 - INFO - layer16_mlp.down_proj | mse: 0.005011921070777848, bpp_loss: 4.751770255604276, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [32:23<43:39, 113.88s/it]2025-03-03 16:01:47 - INFO - layer17_self_attn.q_proj | mse: 0.005301507712094027, bpp_loss: 5.010292873382569, bpp: 0
2025-03-03 16:01:59 - INFO - layer17_self_attn.k_proj | mse: 0.005337029625737714, bpp_loss: 5.043470914065838, bpp: 0
2025-03-03 16:02:10 - INFO - layer17_self_attn.v_proj | mse: 0.005174440643833756, bpp_loss: 4.599198644682765, bpp: 0
2025-03-03 16:02:22 - INFO - layer17_self_attn.o_proj | mse: 0.0052832252876096695, bpp_loss: 4.597997196689248, bpp: 0
2025-03-03 16:02:36 - INFO - layer17_mlp.gate_proj | mse: 0.005197304670325223, bpp_loss: 4.794865668427061, bpp: 0
2025-03-03 16:02:51 - INFO - layer17_mlp.up_proj | mse: 0.005187948639157577, bpp_loss: 4.758061355242023, bpp: 0
2025-03-03 16:03:30 - INFO - layer17_mlp.down_proj | mse: 0.004972492450164048, bpp_loss: 4.74898210523857, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [34:18<41:51, 114.16s/it]2025-03-03 16:03:42 - INFO - layer18_self_attn.q_proj | mse: 0.005274640307540839, bpp_loss: 5.021009898334742, bpp: 0
2025-03-03 16:03:54 - INFO - layer18_self_attn.k_proj | mse: 0.005301659285361264, bpp_loss: 5.05464148171246, bpp: 0
2025-03-03 16:04:06 - INFO - layer18_self_attn.v_proj | mse: 0.005154602623371265, bpp_loss: 4.633057022467256, bpp: 0
2025-03-03 16:04:17 - INFO - layer18_self_attn.o_proj | mse: 0.00526411778540151, bpp_loss: 4.6240328085422515, bpp: 0
2025-03-03 16:04:32 - INFO - layer18_mlp.gate_proj | mse: 0.0051935531933338585, bpp_loss: 4.802909577334368, bpp: 0
2025-03-03 16:04:47 - INFO - layer18_mlp.up_proj | mse: 0.005179672110430061, bpp_loss: 4.752101052800814, bpp: 0
2025-03-03 16:05:26 - INFO - layer18_mlp.down_proj | mse: 0.004934178010662914, bpp_loss: 4.745519308414724, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [36:14<40:09, 114.72s/it]2025-03-03 16:05:38 - INFO - layer19_self_attn.q_proj | mse: 0.005261973046846439, bpp_loss: 4.974977269247174, bpp: 0
2025-03-03 16:05:50 - INFO - layer19_self_attn.k_proj | mse: 0.005288475192272461, bpp_loss: 5.000172069817782, bpp: 0
2025-03-03 16:06:02 - INFO - layer19_self_attn.v_proj | mse: 0.005154139560086952, bpp_loss: 4.630985682979226, bpp: 0
2025-03-03 16:06:13 - INFO - layer19_self_attn.o_proj | mse: 0.005140327851695886, bpp_loss: 4.6250094509869815, bpp: 0
2025-03-03 16:06:28 - INFO - layer19_mlp.gate_proj | mse: 0.0051938900228166085, bpp_loss: 4.810443290626561, bpp: 0
2025-03-03 16:06:43 - INFO - layer19_mlp.up_proj | mse: 0.0051783896862526175, bpp_loss: 4.750664587098139, bpp: 0
2025-03-03 16:07:22 - INFO - layer19_mlp.down_proj | mse: 0.00492758185246402, bpp_loss: 4.744293163330466, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [38:10<38:20, 115.02s/it]2025-03-03 16:07:34 - INFO - layer20_self_attn.q_proj | mse: 0.00528491206167535, bpp_loss: 4.998533368855715, bpp: 0
2025-03-03 16:07:46 - INFO - layer20_self_attn.k_proj | mse: 0.005311920841905931, bpp_loss: 5.028644029125571, bpp: 0
2025-03-03 16:07:57 - INFO - layer20_self_attn.v_proj | mse: 0.005169911523362262, bpp_loss: 4.629065200611949, bpp: 0
2025-03-03 16:08:09 - INFO - layer20_self_attn.o_proj | mse: 0.005270768468087519, bpp_loss: 4.6282818838208915, bpp: 0
2025-03-03 16:08:24 - INFO - layer20_mlp.gate_proj | mse: 0.0052053058297916125, bpp_loss: 4.813519694021455, bpp: 0
2025-03-03 16:08:39 - INFO - layer20_mlp.up_proj | mse: 0.005188006665847266, bpp_loss: 4.75005780061086, bpp: 0
2025-03-03 16:09:17 - INFO - layer20_mlp.down_proj | mse: 0.004917644524339905, bpp_loss: 4.743517402255977, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [40:05<36:28, 115.19s/it]2025-03-03 16:09:30 - INFO - layer21_self_attn.q_proj | mse: 0.005288737084920746, bpp_loss: 4.965415936633945, bpp: 0
2025-03-03 16:09:41 - INFO - layer21_self_attn.k_proj | mse: 0.0053145286437453155, bpp_loss: 4.986840619295836, bpp: 0
2025-03-03 16:09:53 - INFO - layer21_self_attn.v_proj | mse: 0.005191002920322032, bpp_loss: 4.6580081705003975, bpp: 0
2025-03-03 16:10:05 - INFO - layer21_self_attn.o_proj | mse: 0.005154061224055872, bpp_loss: 4.655940788686276, bpp: 0
2025-03-03 16:10:19 - INFO - layer21_mlp.gate_proj | mse: 0.005268365047236521, bpp_loss: 4.821722449748604, bpp: 0
2025-03-03 16:10:34 - INFO - layer21_mlp.up_proj | mse: 0.005248048838781547, bpp_loss: 4.74354113108582, bpp: 0
2025-03-03 16:11:12 - INFO - layer21_mlp.down_proj | mse: 0.004938594562789943, bpp_loss: 4.741495387697661, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [42:00<34:32, 115.16s/it]2025-03-03 16:11:25 - INFO - layer22_self_attn.q_proj | mse: 0.00528645004363466, bpp_loss: 4.957816289067268, bpp: 0
2025-03-03 16:11:36 - INFO - layer22_self_attn.k_proj | mse: 0.005302196976462169, bpp_loss: 4.98643937766552, bpp: 0
2025-03-03 16:11:48 - INFO - layer22_self_attn.v_proj | mse: 0.005215281991161904, bpp_loss: 4.7171439391374586, bpp: 0
2025-03-03 16:11:59 - INFO - layer22_self_attn.o_proj | mse: 0.005054384882118548, bpp_loss: 4.7064984914660455, bpp: 0
2025-03-03 16:12:14 - INFO - layer22_mlp.gate_proj | mse: 0.005248847478309454, bpp_loss: 4.830231805311309, bpp: 0
2025-03-03 16:12:28 - INFO - layer22_mlp.up_proj | mse: 0.005222870062401283, bpp_loss: 4.739276095948838, bpp: 0
2025-03-03 16:13:07 - INFO - layer22_mlp.down_proj | mse: 0.0048936300586385475, bpp_loss: 4.739429963600856, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [43:55<32:34, 114.99s/it]2025-03-03 16:13:19 - INFO - layer23_self_attn.q_proj | mse: 0.005265602925304352, bpp_loss: 4.931371165290475, bpp: 0
2025-03-03 16:13:31 - INFO - layer23_self_attn.k_proj | mse: 0.005278666037895452, bpp_loss: 4.948979362696409, bpp: 0
2025-03-03 16:13:42 - INFO - layer23_self_attn.v_proj | mse: 0.005197572949342906, bpp_loss: 4.710766831487417, bpp: 0
2025-03-03 16:13:54 - INFO - layer23_self_attn.o_proj | mse: 0.004907453372367552, bpp_loss: 4.7069765736162665, bpp: 0
2025-03-03 16:14:09 - INFO - layer23_mlp.gate_proj | mse: 0.005238559929928045, bpp_loss: 4.838052622477213, bpp: 0
2025-03-03 16:14:24 - INFO - layer23_mlp.up_proj | mse: 0.005208353089383263, bpp_loss: 4.735520194636451, bpp: 0
2025-03-03 16:15:03 - INFO - layer23_mlp.down_proj | mse: 0.00486543664122001, bpp_loss: 4.7373042843684, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [45:51<30:43, 115.19s/it]2025-03-03 16:15:15 - INFO - layer24_self_attn.q_proj | mse: 0.005245902108777953, bpp_loss: 4.944510379955172, bpp: 0
2025-03-03 16:15:26 - INFO - layer24_self_attn.k_proj | mse: 0.005254637271533588, bpp_loss: 4.962975331395865, bpp: 0
2025-03-03 16:15:38 - INFO - layer24_self_attn.v_proj | mse: 0.0051734542587796835, bpp_loss: 4.720539842024445, bpp: 0
2025-03-03 16:15:50 - INFO - layer24_self_attn.o_proj | mse: 0.004902545550491369, bpp_loss: 4.71489851243794, bpp: 0
2025-03-03 16:16:04 - INFO - layer24_mlp.gate_proj | mse: 0.005227706878837065, bpp_loss: 4.843167092789103, bpp: 0
2025-03-03 16:16:19 - INFO - layer24_mlp.up_proj | mse: 0.005197152564860536, bpp_loss: 4.734640100212009, bpp: 0
2025-03-03 16:16:58 - INFO - layer24_mlp.down_proj | mse: 0.004838552429528004, bpp_loss: 4.737938958654801, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [47:46<28:47, 115.15s/it]2025-03-03 16:17:10 - INFO - layer25_self_attn.q_proj | mse: 0.005217650613166748, bpp_loss: 4.934995090067386, bpp: 0
2025-03-03 16:17:22 - INFO - layer25_self_attn.k_proj | mse: 0.005227122320025259, bpp_loss: 4.949791473224759, bpp: 0
2025-03-03 16:17:33 - INFO - layer25_self_attn.v_proj | mse: 0.005158551871802042, bpp_loss: 4.746897225081921, bpp: 0
2025-03-03 16:17:45 - INFO - layer25_self_attn.o_proj | mse: 0.004850924887170529, bpp_loss: 4.7448997809737925, bpp: 0
2025-03-03 16:18:00 - INFO - layer25_mlp.gate_proj | mse: 0.005214745295785261, bpp_loss: 4.847427877176691, bpp: 0
2025-03-03 16:18:14 - INFO - layer25_mlp.up_proj | mse: 0.005181115223902027, bpp_loss: 4.733584263534458, bpp: 0
2025-03-03 16:18:53 - INFO - layer25_mlp.down_proj | mse: 0.004818877261485154, bpp_loss: 4.7375226428387345, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [49:41<26:54, 115.30s/it]2025-03-03 16:19:06 - INFO - layer26_self_attn.q_proj | mse: 0.0052325284332234, bpp_loss: 4.9455866273492575, bpp: 0
2025-03-03 16:19:17 - INFO - layer26_self_attn.k_proj | mse: 0.005244511991871392, bpp_loss: 4.960975848585367, bpp: 0
2025-03-03 16:19:29 - INFO - layer26_self_attn.v_proj | mse: 0.00517492502935138, bpp_loss: 4.767255710288882, bpp: 0
2025-03-03 16:19:41 - INFO - layer26_self_attn.o_proj | mse: 0.004905591385167266, bpp_loss: 4.74031037606299, bpp: 0
2025-03-03 16:19:55 - INFO - layer26_mlp.gate_proj | mse: 0.005210157410414713, bpp_loss: 4.850904754190533, bpp: 0
2025-03-03 16:20:10 - INFO - layer26_mlp.up_proj | mse: 0.005174080947028323, bpp_loss: 4.734785743057728, bpp: 0
2025-03-03 16:20:49 - INFO - layer26_mlp.down_proj | mse: 0.004807264369777124, bpp_loss: 4.738663337655641, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [51:37<25:01, 115.49s/it]2025-03-03 16:21:02 - INFO - layer27_self_attn.q_proj | mse: 0.005177180550814311, bpp_loss: 4.946725245341659, bpp: 0
2025-03-03 16:21:13 - INFO - layer27_self_attn.k_proj | mse: 0.00518383123350032, bpp_loss: 4.958777045682073, bpp: 0
2025-03-03 16:21:25 - INFO - layer27_self_attn.v_proj | mse: 0.005120379511852347, bpp_loss: 4.761093531623483, bpp: 0
2025-03-03 16:21:36 - INFO - layer27_self_attn.o_proj | mse: 0.004863018301672757, bpp_loss: 4.7509675185382365, bpp: 0
2025-03-03 16:21:51 - INFO - layer27_mlp.gate_proj | mse: 0.005190171507731813, bpp_loss: 4.854931382558964, bpp: 0
2025-03-03 16:22:06 - INFO - layer27_mlp.up_proj | mse: 0.005156305208851503, bpp_loss: 4.7356583231577165, bpp: 0
2025-03-03 16:22:44 - INFO - layer27_mlp.down_proj | mse: 0.0047849797174642425, bpp_loss: 4.7396879463008155, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [53:32<23:04, 115.37s/it]2025-03-03 16:22:57 - INFO - layer28_self_attn.q_proj | mse: 0.005144117646903637, bpp_loss: 4.9403670268505815, bpp: 0
2025-03-03 16:23:08 - INFO - layer28_self_attn.k_proj | mse: 0.005154886765306484, bpp_loss: 4.951444727405906, bpp: 0
2025-03-03 16:23:20 - INFO - layer28_self_attn.v_proj | mse: 0.005093216840720473, bpp_loss: 4.768806838393211, bpp: 0
2025-03-03 16:23:31 - INFO - layer28_self_attn.o_proj | mse: 0.004888841843847295, bpp_loss: 4.758932894542813, bpp: 0
2025-03-03 16:23:46 - INFO - layer28_mlp.gate_proj | mse: 0.005157134406813625, bpp_loss: 4.856521244623043, bpp: 0
2025-03-03 16:24:01 - INFO - layer28_mlp.up_proj | mse: 0.005121266702168839, bpp_loss: 4.738693881365988, bpp: 0
2025-03-03 16:24:39 - INFO - layer28_mlp.down_proj | mse: 0.0047568642412206125, bpp_loss: 4.741991982719412, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [55:27<21:07, 115.21s/it]2025-03-03 16:24:51 - INFO - layer29_self_attn.q_proj | mse: 0.005118241262672632, bpp_loss: 4.963011611029506, bpp: 0
2025-03-03 16:25:03 - INFO - layer29_self_attn.k_proj | mse: 0.00512653653848451, bpp_loss: 4.981882645711303, bpp: 0
2025-03-03 16:25:15 - INFO - layer29_self_attn.v_proj | mse: 0.005062465545016875, bpp_loss: 4.7730298161506655, bpp: 0
2025-03-03 16:25:26 - INFO - layer29_self_attn.o_proj | mse: 0.004846910744986194, bpp_loss: 4.765235419273377, bpp: 0
2025-03-03 16:25:41 - INFO - layer29_mlp.gate_proj | mse: 0.005154777630493954, bpp_loss: 4.855410561296675, bpp: 0
2025-03-03 16:25:55 - INFO - layer29_mlp.up_proj | mse: 0.005121469280552959, bpp_loss: 4.742777234978146, bpp: 0
2025-03-03 16:26:34 - INFO - layer29_mlp.down_proj | mse: 0.004742578001548573, bpp_loss: 4.746064792987373, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [57:22<19:10, 115.07s/it]2025-03-03 16:26:46 - INFO - layer30_self_attn.q_proj | mse: 0.005096059187126286, bpp_loss: 4.940593159720302, bpp: 0
2025-03-03 16:26:58 - INFO - layer30_self_attn.k_proj | mse: 0.005100847419085198, bpp_loss: 4.949701537117362, bpp: 0
2025-03-03 16:27:09 - INFO - layer30_self_attn.v_proj | mse: 0.005061917656326126, bpp_loss: 4.823086222931742, bpp: 0
2025-03-03 16:27:21 - INFO - layer30_self_attn.o_proj | mse: 0.0047902691592472575, bpp_loss: 4.818508236780763, bpp: 0
2025-03-03 16:27:36 - INFO - layer30_mlp.gate_proj | mse: 0.005104535101053224, bpp_loss: 4.858001625979388, bpp: 0
2025-03-03 16:27:50 - INFO - layer30_mlp.up_proj | mse: 0.005069960121181685, bpp_loss: 4.744643475280868, bpp: 0
2025-03-03 16:28:30 - INFO - layer30_mlp.down_proj | mse: 0.0047302832103984, bpp_loss: 4.7471342576874624, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [59:17<17:16, 115.18s/it]2025-03-03 16:28:42 - INFO - layer31_self_attn.q_proj | mse: 0.005079248923794058, bpp_loss: 4.957091019302607, bpp: 0
2025-03-03 16:28:54 - INFO - layer31_self_attn.k_proj | mse: 0.005089915602771646, bpp_loss: 4.982941452413797, bpp: 0
2025-03-03 16:29:06 - INFO - layer31_self_attn.v_proj | mse: 0.005032462381586432, bpp_loss: 4.787627986520529, bpp: 0
2025-03-03 16:29:17 - INFO - layer31_self_attn.o_proj | mse: 0.00487811907812556, bpp_loss: 4.776060466468334, bpp: 0
2025-03-03 16:29:32 - INFO - layer31_mlp.gate_proj | mse: 0.005083130806328285, bpp_loss: 4.859247505885583, bpp: 0
2025-03-03 16:29:47 - INFO - layer31_mlp.up_proj | mse: 0.005051730470083156, bpp_loss: 4.747870735658539, bpp: 0
2025-03-03 16:30:27 - INFO - layer31_mlp.down_proj | mse: 0.004716276460225809, bpp_loss: 4.749980717152357, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:01:15<15:26, 115.83s/it]2025-03-03 16:30:39 - INFO - layer32_self_attn.q_proj | mse: 0.005056143502839953, bpp_loss: 4.920683090612292, bpp: 0
2025-03-03 16:30:51 - INFO - layer32_self_attn.k_proj | mse: 0.005062101212943332, bpp_loss: 4.930345800966024, bpp: 0
2025-03-03 16:31:03 - INFO - layer32_self_attn.v_proj | mse: 0.005032600512576146, bpp_loss: 4.826438201367855, bpp: 0
2025-03-03 16:31:15 - INFO - layer32_self_attn.o_proj | mse: 0.0049201804280205865, bpp_loss: 4.822345220595598, bpp: 0
2025-03-03 16:31:30 - INFO - layer32_mlp.gate_proj | mse: 0.0050570222295002265, bpp_loss: 4.856488779794287, bpp: 0
2025-03-03 16:31:46 - INFO - layer32_mlp.up_proj | mse: 0.005025499659518238, bpp_loss: 4.753098401648027, bpp: 0
2025-03-03 16:32:25 - INFO - layer32_mlp.down_proj | mse: 0.004714921245171359, bpp_loss: 4.754890687846475, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:03:13<13:36, 116.66s/it]2025-03-03 16:32:38 - INFO - layer33_self_attn.q_proj | mse: 0.005044725446901532, bpp_loss: 4.923654045090079, bpp: 0
2025-03-03 16:32:50 - INFO - layer33_self_attn.k_proj | mse: 0.005052820942657815, bpp_loss: 4.941551390364766, bpp: 0
2025-03-03 16:33:02 - INFO - layer33_self_attn.v_proj | mse: 0.005013357660539139, bpp_loss: 4.8048691972345114, bpp: 0
2025-03-03 16:33:14 - INFO - layer33_self_attn.o_proj | mse: 0.004859844997123802, bpp_loss: 4.799559578299522, bpp: 0
2025-03-03 16:33:29 - INFO - layer33_mlp.gate_proj | mse: 0.005049084247021427, bpp_loss: 4.8549764222017044, bpp: 0
2025-03-03 16:33:44 - INFO - layer33_mlp.up_proj | mse: 0.005022510426616277, bpp_loss: 4.758412944718644, bpp: 0
2025-03-03 16:34:24 - INFO - layer33_mlp.down_proj | mse: 0.00471545550274033, bpp_loss: 4.759732936929773, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:05:12<11:43, 117.17s/it]2025-03-03 16:34:36 - INFO - layer34_self_attn.q_proj | mse: 0.005031237280224631, bpp_loss: 4.883803381696343, bpp: 0
2025-03-03 16:34:48 - INFO - layer34_self_attn.k_proj | mse: 0.005039126043023152, bpp_loss: 4.899064063131809, bpp: 0
2025-03-03 16:35:00 - INFO - layer34_self_attn.v_proj | mse: 0.0050166301598256755, bpp_loss: 4.831682547330856, bpp: 0
2025-03-03 16:35:11 - INFO - layer34_self_attn.o_proj | mse: 0.0048883454066325814, bpp_loss: 4.837825390249491, bpp: 0
2025-03-03 16:35:26 - INFO - layer34_mlp.gate_proj | mse: 0.005039684266645023, bpp_loss: 4.849104441316039, bpp: 0
2025-03-03 16:35:41 - INFO - layer34_mlp.up_proj | mse: 0.005016986903793644, bpp_loss: 4.76719214723066, bpp: 0
2025-03-03 16:36:21 - INFO - layer34_mlp.down_proj | mse: 0.004725013425585709, bpp_loss: 4.768530983119099, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:07:08<09:45, 117.06s/it]2025-03-03 16:36:33 - INFO - layer35_self_attn.q_proj | mse: 0.00502776129266801, bpp_loss: 4.8752576430141925, bpp: 0
2025-03-03 16:36:44 - INFO - layer35_self_attn.k_proj | mse: 0.005032743278833973, bpp_loss: 4.892267318591475, bpp: 0
2025-03-03 16:36:56 - INFO - layer35_self_attn.v_proj | mse: 0.005014884981381793, bpp_loss: 4.832739878073335, bpp: 0
2025-03-03 16:37:08 - INFO - layer35_self_attn.o_proj | mse: 0.004954016494652215, bpp_loss: 4.83361980304122, bpp: 0
2025-03-03 16:37:23 - INFO - layer35_mlp.gate_proj | mse: 0.005032200883794319, bpp_loss: 4.842865863718369, bpp: 0
2025-03-03 16:37:38 - INFO - layer35_mlp.up_proj | mse: 0.005014925411220319, bpp_loss: 4.776858672610036, bpp: 0
2025-03-03 16:38:18 - INFO - layer35_mlp.down_proj | mse: 0.004742544696288811, bpp_loss: 4.77741962765102, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:09:05<07:48, 117.03s/it]2025-03-03 16:38:30 - INFO - layer36_self_attn.q_proj | mse: 0.005035572182962264, bpp_loss: 4.875946886986494, bpp: 0
2025-03-03 16:38:41 - INFO - layer36_self_attn.k_proj | mse: 0.005044178485264406, bpp_loss: 4.898986700773239, bpp: 0
2025-03-03 16:38:53 - INFO - layer36_self_attn.v_proj | mse: 0.005028196080816845, bpp_loss: 4.8564795235544445, bpp: 0
2025-03-03 16:39:05 - INFO - layer36_self_attn.o_proj | mse: 0.005033108537961138, bpp_loss: 4.858071391284466, bpp: 0
2025-03-03 16:39:20 - INFO - layer36_mlp.gate_proj | mse: 0.005034297055040181, bpp_loss: 4.838980703773322, bpp: 0
2025-03-03 16:39:34 - INFO - layer36_mlp.up_proj | mse: 0.005019711411383474, bpp_loss: 4.782689068990725, bpp: 0
2025-03-03 16:40:14 - INFO - layer36_mlp.down_proj | mse: 0.004775051316523157, bpp_loss: 4.7784204513110495, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:11:01<05:50, 116.73s/it]2025-03-03 16:40:26 - INFO - layer37_self_attn.q_proj | mse: 0.005046045571259613, bpp_loss: 4.810231208205223, bpp: 0
2025-03-03 16:40:37 - INFO - layer37_self_attn.k_proj | mse: 0.005053425845146332, bpp_loss: 4.809560739919544, bpp: 0
2025-03-03 16:40:49 - INFO - layer37_self_attn.v_proj | mse: 0.005066858388605898, bpp_loss: 4.881161427870393, bpp: 0
2025-03-03 16:41:01 - INFO - layer37_self_attn.o_proj | mse: 0.005200755060901273, bpp_loss: 4.881987217962742, bpp: 0
2025-03-03 16:41:16 - INFO - layer37_mlp.gate_proj | mse: 0.005047189624100106, bpp_loss: 4.84330055989601, bpp: 0
2025-03-03 16:41:30 - INFO - layer37_mlp.up_proj | mse: 0.005032536683217489, bpp_loss: 4.790991250122035, bpp: 0
2025-03-03 16:42:09 - INFO - layer37_mlp.down_proj | mse: 0.004822565904842122, bpp_loss: 4.778857243833719, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:12:57<03:52, 116.32s/it]2025-03-03 16:42:21 - INFO - layer38_self_attn.q_proj | mse: 0.0050563775838795705, bpp_loss: 4.784109283387661, bpp: 0
2025-03-03 16:42:33 - INFO - layer38_self_attn.k_proj | mse: 0.005062899869638898, bpp_loss: 4.792719104140997, bpp: 0
2025-03-03 16:42:44 - INFO - layer38_self_attn.v_proj | mse: 0.005100144248912723, bpp_loss: 4.937401087731123, bpp: 0
2025-03-03 16:42:56 - INFO - layer38_self_attn.o_proj | mse: 0.005298992615616867, bpp_loss: 4.94662052065134, bpp: 0
2025-03-03 16:43:11 - INFO - layer38_mlp.gate_proj | mse: 0.005095013573646347, bpp_loss: 4.8797675884984155, bpp: 0
2025-03-03 16:43:26 - INFO - layer38_mlp.up_proj | mse: 0.005070764254360686, bpp_loss: 4.796006954764878, bpp: 0
2025-03-03 16:44:05 - INFO - layer38_mlp.down_proj | mse: 0.004955670547158563, bpp_loss: 4.76231130198748, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:14:53<01:56, 116.16s/it]2025-03-03 16:44:17 - INFO - layer39_self_attn.q_proj | mse: 0.00512943589868809, bpp_loss: 4.779304615631699, bpp: 0
2025-03-03 16:44:29 - INFO - layer39_self_attn.k_proj | mse: 0.005139910677565874, bpp_loss: 4.793114665746689, bpp: 0
2025-03-03 16:44:40 - INFO - layer39_self_attn.v_proj | mse: 0.005143778345277894, bpp_loss: 4.820481664910912, bpp: 0
2025-03-03 16:44:52 - INFO - layer39_self_attn.o_proj | mse: 0.00804038427254769, bpp_loss: 4.827616802677512, bpp: 0
2025-03-03 16:45:07 - INFO - layer39_mlp.gate_proj | mse: 0.005198145542295921, bpp_loss: 4.958581281591345, bpp: 0
2025-03-03 16:45:22 - INFO - layer39_mlp.up_proj | mse: 0.005166865379668492, bpp_loss: 4.842607697237421, bpp: 0
2025-03-03 16:46:01 - INFO - layer39_mlp.down_proj | mse: 0.0054981696228301, bpp_loss: 4.751680840800206, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:16:48<00:00, 116.06s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:16:48<00:00, 115.22s/it]
2025-03-03 16:46:01 - INFO - #### Total | mse: 0.005803598627489164, bpp_loss: 4.777577754999549, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda1000_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_6.59649_bpp_6.05166_MSE_0.00106_total_iter_140000.pth.tar/COL_MSE0.0058_bpploss4.7776_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda1000_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_6.59649_bpp_6.05166_MSE_0.00106_total_iter_140000.pth.tar/COL_MSE0.00533_bpploss4.7774_bpp0
I0303 16:46:37.107802 3313733 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.10s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.10s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.10s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.09s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:09<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]
W0303 16:46:46.681848 3313733 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 16:46:46.696122 3313733 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.2421875:   0%|          | 0/166 [00:02<?, ?it/s]avg_loss = 1.2421875:   1%|          | 1/166 [00:02<07:23,  2.69s/it]avg_loss = 1.5390625:   1%|          | 1/166 [00:03<07:23,  2.69s/it]avg_loss = 1.5390625:   1%|          | 2/166 [00:03<04:32,  1.66s/it]avg_loss = 1.7083333333333333:   1%|          | 2/166 [00:04<04:32,  1.66s/it]avg_loss = 1.7083333333333333:   2%|▏         | 3/166 [00:04<03:45,  1.39s/it]avg_loss = 1.73828125:   2%|▏         | 3/166 [00:05<03:45,  1.39s/it]        avg_loss = 1.73828125:   2%|▏         | 4/166 [00:05<03:21,  1.25s/it]avg_loss = 1.671875:   2%|▏         | 4/166 [00:06<03:21,  1.25s/it]  avg_loss = 1.671875:   3%|▎         | 5/166 [00:06<03:09,  1.18s/it]avg_loss = 1.6419270833333333:   3%|▎         | 5/166 [00:07<03:09,  1.18s/it]avg_loss = 1.6419270833333333:   4%|▎         | 6/166 [00:07<02:59,  1.12s/it]avg_loss = 1.578125:   4%|▎         | 6/166 [00:08<02:59,  1.12s/it]          avg_loss = 1.578125:   4%|▍         | 7/166 [00:08<02:52,  1.09s/it]avg_loss = 1.509765625:   4%|▍         | 7/166 [00:09<02:52,  1.09s/it]avg_loss = 1.509765625:   5%|▍         | 8/166 [00:09<02:48,  1.06s/it]avg_loss = 1.5069444444444444:   5%|▍         | 8/166 [00:10<02:48,  1.06s/it]avg_loss = 1.5069444444444444:   5%|▌         | 9/166 [00:10<02:48,  1.07s/it]avg_loss = 1.5171875:   5%|▌         | 9/166 [00:11<02:48,  1.07s/it]         avg_loss = 1.5171875:   6%|▌         | 10/166 [00:11<02:45,  1.06s/it]avg_loss = 1.5355113636363635:   6%|▌         | 10/166 [00:13<02:45,  1.06s/it]avg_loss = 1.5355113636363635:   7%|▋         | 11/166 [00:13<02:44,  1.06s/it]avg_loss = 1.5455729166666667:   7%|▋         | 11/166 [00:14<02:44,  1.06s/it]avg_loss = 1.5455729166666667:   7%|▋         | 12/166 [00:14<02:41,  1.05s/it]avg_loss = 1.5420673076923077:   7%|▋         | 12/166 [00:15<02:41,  1.05s/it]avg_loss = 1.5420673076923077:   8%|▊         | 13/166 [00:15<02:42,  1.06s/it]avg_loss = 1.5558035714285714:   8%|▊         | 13/166 [00:16<02:42,  1.06s/it]avg_loss = 1.5558035714285714:   8%|▊         | 14/166 [00:16<02:39,  1.05s/it]avg_loss = 1.571875:   8%|▊         | 14/166 [00:17<02:39,  1.05s/it]          avg_loss = 1.571875:   9%|▉         | 15/166 [00:17<02:40,  1.06s/it]avg_loss = 1.58984375:   9%|▉         | 15/166 [00:18<02:40,  1.06s/it]avg_loss = 1.58984375:  10%|▉         | 16/166 [00:18<02:36,  1.04s/it]avg_loss = 1.599264705882353:  10%|▉         | 16/166 [00:19<02:36,  1.04s/it]avg_loss = 1.599264705882353:  10%|█         | 17/166 [00:19<02:38,  1.07s/it]avg_loss = 1.6128472222222223:  10%|█         | 17/166 [00:20<02:38,  1.07s/it]avg_loss = 1.6128472222222223:  11%|█         | 18/166 [00:20<02:37,  1.06s/it]avg_loss = 1.6319901315789473:  11%|█         | 18/166 [00:21<02:37,  1.06s/it]avg_loss = 1.6319901315789473:  11%|█▏        | 19/166 [00:21<02:36,  1.07s/it]avg_loss = 1.638671875:  11%|█▏        | 19/166 [00:22<02:36,  1.07s/it]       avg_loss = 1.638671875:  12%|█▏        | 20/166 [00:22<02:33,  1.05s/it]avg_loss = 1.638764880952381:  12%|█▏        | 20/166 [00:23<02:33,  1.05s/it]avg_loss = 1.638764880952381:  13%|█▎        | 21/166 [00:23<02:31,  1.04s/it]avg_loss = 1.6281960227272727:  13%|█▎        | 21/166 [00:24<02:31,  1.04s/it]avg_loss = 1.6281960227272727:  13%|█▎        | 22/166 [00:24<02:28,  1.03s/it]avg_loss = 1.6117527173913044:  13%|█▎        | 22/166 [00:25<02:28,  1.03s/it]avg_loss = 1.6117527173913044:  14%|█▍        | 23/166 [00:25<02:27,  1.03s/it]avg_loss = 1.6197916666666667:  14%|█▍        | 23/166 [00:26<02:27,  1.03s/it]avg_loss = 1.6197916666666667:  14%|█▍        | 24/166 [00:26<02:26,  1.03s/it]avg_loss = 1.6271875:  14%|█▍        | 24/166 [00:27<02:26,  1.03s/it]         avg_loss = 1.6271875:  15%|█▌        | 25/166 [00:27<02:25,  1.03s/it]avg_loss = 1.6319110576923077:  15%|█▌        | 25/166 [00:28<02:25,  1.03s/it]avg_loss = 1.6319110576923077:  16%|█▌        | 26/166 [00:28<02:23,  1.02s/it]avg_loss = 1.638599537037037:  16%|█▌        | 26/166 [00:29<02:23,  1.02s/it] avg_loss = 1.638599537037037:  16%|█▋        | 27/166 [00:29<02:22,  1.03s/it]avg_loss = 1.6409040178571428:  16%|█▋        | 27/166 [00:30<02:22,  1.03s/it]avg_loss = 1.6409040178571428:  17%|█▋        | 28/166 [00:30<02:22,  1.03s/it]avg_loss = 1.6508620689655173:  17%|█▋        | 28/166 [00:31<02:22,  1.03s/it]avg_loss = 1.6508620689655173:  17%|█▋        | 29/166 [00:31<02:20,  1.03s/it]avg_loss = 1.6513020833333334:  17%|█▋        | 29/166 [00:32<02:20,  1.03s/it]avg_loss = 1.6513020833333334:  18%|█▊        | 30/166 [00:32<02:20,  1.04s/it]avg_loss = 1.666078629032258:  18%|█▊        | 30/166 [00:33<02:20,  1.04s/it] avg_loss = 1.666078629032258:  19%|█▊        | 31/166 [00:33<02:19,  1.03s/it]avg_loss = 1.673583984375:  19%|█▊        | 31/166 [00:34<02:19,  1.03s/it]   avg_loss = 1.673583984375:  19%|█▉        | 32/166 [00:34<02:17,  1.03s/it]avg_loss = 1.6787405303030303:  19%|█▉        | 32/166 [00:35<02:17,  1.03s/it]avg_loss = 1.6787405303030303:  20%|█▉        | 33/166 [00:35<02:18,  1.04s/it]avg_loss = 1.6767003676470589:  20%|█▉        | 33/166 [00:36<02:18,  1.04s/it]avg_loss = 1.6767003676470589:  20%|██        | 34/166 [00:36<02:15,  1.03s/it]avg_loss = 1.6700892857142857:  20%|██        | 34/166 [00:37<02:15,  1.03s/it]avg_loss = 1.6700892857142857:  21%|██        | 35/166 [00:37<02:16,  1.04s/it]avg_loss = 1.6603732638888888:  21%|██        | 35/166 [00:38<02:16,  1.04s/it]avg_loss = 1.6603732638888888:  22%|██▏       | 36/166 [00:38<02:13,  1.03s/it]avg_loss = 1.6497043918918919:  22%|██▏       | 36/166 [00:40<02:13,  1.03s/it]avg_loss = 1.6497043918918919:  22%|██▏       | 37/166 [00:40<02:14,  1.05s/it]avg_loss = 1.6463815789473684:  22%|██▏       | 37/166 [00:41<02:14,  1.05s/it]avg_loss = 1.6463815789473684:  23%|██▎       | 38/166 [00:41<02:12,  1.03s/it]avg_loss = 1.6440304487179487:  23%|██▎       | 38/166 [00:42<02:12,  1.03s/it]avg_loss = 1.6440304487179487:  23%|██▎       | 39/166 [00:42<02:10,  1.03s/it]avg_loss = 1.6486328125:  23%|██▎       | 39/166 [00:43<02:10,  1.03s/it]      avg_loss = 1.6486328125:  24%|██▍       | 40/166 [00:43<02:10,  1.04s/it]avg_loss = 1.649580792682927:  24%|██▍       | 40/166 [00:44<02:10,  1.04s/it]avg_loss = 1.649580792682927:  25%|██▍       | 41/166 [00:44<02:08,  1.02s/it]avg_loss = 1.6383928571428572:  25%|██▍       | 41/166 [00:45<02:08,  1.02s/it]avg_loss = 1.6383928571428572:  25%|██▌       | 42/166 [00:45<02:08,  1.03s/it]avg_loss = 1.623455668604651:  25%|██▌       | 42/166 [00:46<02:08,  1.03s/it] avg_loss = 1.623455668604651:  26%|██▌       | 43/166 [00:46<02:05,  1.02s/it]avg_loss = 1.6140802556818181:  26%|██▌       | 43/166 [00:47<02:05,  1.02s/it]avg_loss = 1.6140802556818181:  27%|██▋       | 44/166 [00:47<02:05,  1.03s/it]avg_loss = 1.600954861111111:  27%|██▋       | 44/166 [00:48<02:05,  1.03s/it] avg_loss = 1.600954861111111:  27%|██▋       | 45/166 [00:48<02:03,  1.02s/it]avg_loss = 1.591117527173913:  27%|██▋       | 45/166 [00:49<02:03,  1.02s/it]avg_loss = 1.591117527173913:  28%|██▊       | 46/166 [00:49<02:03,  1.03s/it]avg_loss = 1.5848570478723405:  28%|██▊       | 46/166 [00:50<02:03,  1.03s/it]avg_loss = 1.5848570478723405:  28%|██▊       | 47/166 [00:50<02:01,  1.02s/it]avg_loss = 1.5858561197916667:  28%|██▊       | 47/166 [00:51<02:01,  1.02s/it]avg_loss = 1.5858561197916667:  29%|██▉       | 48/166 [00:51<02:01,  1.03s/it]avg_loss = 1.596859056122449:  29%|██▉       | 48/166 [00:52<02:01,  1.03s/it] avg_loss = 1.596859056122449:  30%|██▉       | 49/166 [00:52<01:59,  1.02s/it]avg_loss = 1.608046875:  30%|██▉       | 49/166 [00:53<01:59,  1.02s/it]      avg_loss = 1.608046875:  30%|███       | 50/166 [00:53<01:58,  1.03s/it]avg_loss = 1.614813112745098:  30%|███       | 50/166 [00:54<01:58,  1.03s/it]avg_loss = 1.614813112745098:  31%|███       | 51/166 [00:54<01:56,  1.02s/it]avg_loss = 1.6189152644230769:  31%|███       | 51/166 [00:55<01:56,  1.02s/it]avg_loss = 1.6189152644230769:  31%|███▏      | 52/166 [00:55<01:56,  1.03s/it]avg_loss = 1.6221255896226414:  31%|███▏      | 52/166 [00:56<01:56,  1.03s/it]avg_loss = 1.6221255896226414:  32%|███▏      | 53/166 [00:56<01:54,  1.02s/it]avg_loss = 1.6237702546296295:  32%|███▏      | 53/166 [00:57<01:54,  1.02s/it]avg_loss = 1.6237702546296295:  33%|███▎      | 54/166 [00:57<01:54,  1.02s/it]avg_loss = 1.627059659090909:  33%|███▎      | 54/166 [00:58<01:54,  1.02s/it] avg_loss = 1.627059659090909:  33%|███▎      | 55/166 [00:58<01:52,  1.02s/it]avg_loss = 1.6312081473214286:  33%|███▎      | 55/166 [00:59<01:52,  1.02s/it]avg_loss = 1.6312081473214286:  34%|███▎      | 56/166 [00:59<01:53,  1.03s/it]avg_loss = 1.6267132675438596:  34%|███▎      | 56/166 [01:00<01:53,  1.03s/it]avg_loss = 1.6267132675438596:  34%|███▍      | 57/166 [01:00<01:51,  1.02s/it]avg_loss = 1.6304552801724137:  34%|███▍      | 57/166 [01:01<01:51,  1.02s/it]avg_loss = 1.6304552801724137:  35%|███▍      | 58/166 [01:01<01:51,  1.03s/it]avg_loss = 1.6287738347457628:  35%|███▍      | 58/166 [01:02<01:51,  1.03s/it]avg_loss = 1.6287738347457628:  36%|███▌      | 59/166 [01:02<01:49,  1.02s/it]avg_loss = 1.6242838541666667:  36%|███▌      | 59/166 [01:03<01:49,  1.02s/it]avg_loss = 1.6242838541666667:  36%|███▌      | 60/166 [01:03<01:48,  1.02s/it]avg_loss = 1.6205814549180328:  36%|███▌      | 60/166 [01:04<01:48,  1.02s/it]avg_loss = 1.6205814549180328:  37%|███▋      | 61/166 [01:04<01:49,  1.04s/it]avg_loss = 1.617124495967742:  37%|███▋      | 61/166 [01:05<01:49,  1.04s/it] avg_loss = 1.617124495967742:  37%|███▋      | 62/166 [01:05<01:47,  1.03s/it]avg_loss = 1.6115451388888888:  37%|███▋      | 62/166 [01:06<01:47,  1.03s/it]avg_loss = 1.6115451388888888:  38%|███▊      | 63/166 [01:06<01:45,  1.02s/it]avg_loss = 1.60736083984375:  38%|███▊      | 63/166 [01:07<01:45,  1.02s/it]  avg_loss = 1.60736083984375:  39%|███▊      | 64/166 [01:07<01:44,  1.02s/it]avg_loss = 1.600420673076923:  39%|███▊      | 64/166 [01:08<01:44,  1.02s/it]avg_loss = 1.600420673076923:  39%|███▉      | 65/166 [01:08<01:42,  1.02s/it]avg_loss = 1.593454071969697:  39%|███▉      | 65/166 [01:09<01:42,  1.02s/it]avg_loss = 1.593454071969697:  40%|███▉      | 66/166 [01:09<01:42,  1.02s/it]avg_loss = 1.5875116604477613:  40%|███▉      | 66/166 [01:10<01:42,  1.02s/it]avg_loss = 1.5875116604477613:  40%|████      | 67/166 [01:10<01:40,  1.02s/it]avg_loss = 1.5862247242647058:  40%|████      | 67/166 [01:11<01:40,  1.02s/it]avg_loss = 1.5862247242647058:  41%|████      | 68/166 [01:11<01:39,  1.01s/it]avg_loss = 1.5879189311594204:  41%|████      | 68/166 [01:12<01:39,  1.01s/it]avg_loss = 1.5879189311594204:  42%|████▏     | 69/166 [01:12<01:38,  1.01s/it]avg_loss = 1.5911272321428571:  42%|████▏     | 69/166 [01:13<01:38,  1.01s/it]avg_loss = 1.5911272321428571:  42%|████▏     | 70/166 [01:13<01:37,  1.01s/it]avg_loss = 1.595455545774648:  42%|████▏     | 70/166 [01:14<01:37,  1.01s/it] avg_loss = 1.595455545774648:  43%|████▎     | 71/166 [01:14<01:37,  1.03s/it]avg_loss = 1.6009657118055556:  43%|████▎     | 71/166 [01:15<01:37,  1.03s/it]avg_loss = 1.6009657118055556:  43%|████▎     | 72/166 [01:15<01:35,  1.02s/it]avg_loss = 1.6072880993150684:  43%|████▎     | 72/166 [01:16<01:35,  1.02s/it]avg_loss = 1.6072880993150684:  44%|████▍     | 73/166 [01:16<01:37,  1.05s/it]avg_loss = 1.601509712837838:  44%|████▍     | 73/166 [01:17<01:37,  1.05s/it] avg_loss = 1.601509712837838:  45%|████▍     | 74/166 [01:17<01:35,  1.04s/it]avg_loss = 1.5969270833333333:  45%|████▍     | 74/166 [01:19<01:35,  1.04s/it]avg_loss = 1.5969270833333333:  45%|████▌     | 75/166 [01:19<01:35,  1.05s/it]avg_loss = 1.595960115131579:  45%|████▌     | 75/166 [01:20<01:35,  1.05s/it] avg_loss = 1.595960115131579:  46%|████▌     | 76/166 [01:20<01:33,  1.04s/it]avg_loss = 1.5926846590909092:  46%|████▌     | 76/166 [01:21<01:33,  1.04s/it]avg_loss = 1.5926846590909092:  46%|████▋     | 77/166 [01:21<01:31,  1.03s/it]avg_loss = 1.5893930288461537:  46%|████▋     | 77/166 [01:22<01:31,  1.03s/it]avg_loss = 1.5893930288461537:  47%|████▋     | 78/166 [01:22<01:32,  1.05s/it]avg_loss = 1.586778085443038:  47%|████▋     | 78/166 [01:23<01:32,  1.05s/it] avg_loss = 1.586778085443038:  48%|████▊     | 79/166 [01:23<01:30,  1.03s/it]avg_loss = 1.583349609375:  48%|████▊     | 79/166 [01:24<01:30,  1.03s/it]   avg_loss = 1.583349609375:  48%|████▊     | 80/166 [01:24<01:29,  1.04s/it]avg_loss = 1.5736400462962963:  48%|████▊     | 80/166 [01:25<01:29,  1.04s/it]avg_loss = 1.5736400462962963:  49%|████▉     | 81/166 [01:25<01:28,  1.04s/it]avg_loss = 1.5753144054878048:  49%|████▉     | 81/166 [01:26<01:28,  1.04s/it]avg_loss = 1.5753144054878048:  49%|████▉     | 82/166 [01:26<01:27,  1.04s/it]avg_loss = 1.5763836596385543:  49%|████▉     | 82/166 [01:27<01:27,  1.04s/it]avg_loss = 1.5763836596385543:  50%|█████     | 83/166 [01:27<01:24,  1.02s/it]avg_loss = 1.579008556547619:  50%|█████     | 83/166 [01:28<01:24,  1.02s/it] avg_loss = 1.579008556547619:  51%|█████     | 84/166 [01:28<01:23,  1.02s/it]avg_loss = 1.5805606617647059:  51%|█████     | 84/166 [01:29<01:23,  1.02s/it]avg_loss = 1.5805606617647059:  51%|█████     | 85/166 [01:29<01:23,  1.03s/it]avg_loss = 1.5794422238372092:  51%|█████     | 85/166 [01:30<01:23,  1.03s/it]avg_loss = 1.5794422238372092:  52%|█████▏    | 86/166 [01:30<01:21,  1.02s/it]avg_loss = 1.5798760775862069:  52%|█████▏    | 86/166 [01:31<01:21,  1.02s/it]avg_loss = 1.5798760775862069:  52%|█████▏    | 87/166 [01:31<01:21,  1.03s/it]avg_loss = 1.5804776278409092:  52%|█████▏    | 87/166 [01:32<01:21,  1.03s/it]avg_loss = 1.5804776278409092:  53%|█████▎    | 88/166 [01:32<01:19,  1.02s/it]avg_loss = 1.5816801264044944:  53%|█████▎    | 88/166 [01:33<01:19,  1.02s/it]avg_loss = 1.5816801264044944:  54%|█████▎    | 89/166 [01:33<01:19,  1.03s/it]avg_loss = 1.5815538194444445:  54%|█████▎    | 89/166 [01:34<01:19,  1.03s/it]avg_loss = 1.5815538194444445:  54%|█████▍    | 90/166 [01:34<01:17,  1.02s/it]avg_loss = 1.5823746565934067:  54%|█████▍    | 90/166 [01:35<01:17,  1.02s/it]avg_loss = 1.5823746565934067:  55%|█████▍    | 91/166 [01:35<01:16,  1.03s/it]avg_loss = 1.5825832201086956:  55%|█████▍    | 91/166 [01:36<01:16,  1.03s/it]avg_loss = 1.5825832201086956:  55%|█████▌    | 92/166 [01:36<01:15,  1.02s/it]avg_loss = 1.585895497311828:  55%|█████▌    | 92/166 [01:37<01:15,  1.02s/it] avg_loss = 1.585895497311828:  56%|█████▌    | 93/166 [01:37<01:15,  1.03s/it]avg_loss = 1.5853141622340425:  56%|█████▌    | 93/166 [01:38<01:15,  1.03s/it]avg_loss = 1.5853141622340425:  57%|█████▋    | 94/166 [01:38<01:13,  1.02s/it]avg_loss = 1.5846628289473683:  57%|█████▋    | 94/166 [01:39<01:13,  1.02s/it]avg_loss = 1.5846628289473683:  57%|█████▋    | 95/166 [01:39<01:13,  1.03s/it]avg_loss = 1.5841064453125:  57%|█████▋    | 95/166 [01:40<01:13,  1.03s/it]   avg_loss = 1.5841064453125:  58%|█████▊    | 96/166 [01:40<01:11,  1.02s/it]avg_loss = 1.583239368556701:  58%|█████▊    | 96/166 [01:41<01:11,  1.02s/it]avg_loss = 1.583239368556701:  58%|█████▊    | 97/166 [01:41<01:10,  1.03s/it]avg_loss = 1.5816725127551021:  58%|█████▊    | 97/166 [01:42<01:10,  1.03s/it]avg_loss = 1.5816725127551021:  59%|█████▉    | 98/166 [01:42<01:09,  1.02s/it]avg_loss = 1.5795059974747474:  59%|█████▉    | 98/166 [01:43<01:09,  1.02s/it]avg_loss = 1.5795059974747474:  60%|█████▉    | 99/166 [01:43<01:08,  1.02s/it]avg_loss = 1.5768359375:  60%|█████▉    | 99/166 [01:44<01:08,  1.02s/it]      avg_loss = 1.5768359375:  60%|██████    | 100/166 [01:44<01:07,  1.02s/it]avg_loss = 1.577544863861386:  60%|██████    | 100/166 [01:45<01:07,  1.02s/it]avg_loss = 1.577544863861386:  61%|██████    | 101/166 [01:45<01:06,  1.03s/it]avg_loss = 1.5787760416666667:  61%|██████    | 101/166 [01:46<01:06,  1.03s/it]avg_loss = 1.5787760416666667:  61%|██████▏   | 102/166 [01:46<01:05,  1.02s/it]avg_loss = 1.5793006674757282:  61%|██████▏   | 102/166 [01:47<01:05,  1.02s/it]avg_loss = 1.5793006674757282:  62%|██████▏   | 103/166 [01:47<01:05,  1.05s/it]avg_loss = 1.5811673677884615:  62%|██████▏   | 103/166 [01:48<01:05,  1.05s/it]avg_loss = 1.5811673677884615:  63%|██████▎   | 104/166 [01:48<01:04,  1.04s/it]avg_loss = 1.587686011904762:  63%|██████▎   | 104/166 [01:49<01:04,  1.04s/it] avg_loss = 1.587686011904762:  63%|██████▎   | 105/166 [01:49<01:02,  1.03s/it]avg_loss = 1.5930498231132075:  63%|██████▎   | 105/166 [01:50<01:02,  1.03s/it]avg_loss = 1.5930498231132075:  64%|██████▍   | 106/166 [01:50<01:01,  1.02s/it]avg_loss = 1.5962689836448598:  64%|██████▍   | 106/166 [01:51<01:01,  1.02s/it]avg_loss = 1.5962689836448598:  64%|██████▍   | 107/166 [01:51<00:59,  1.01s/it]avg_loss = 1.5992838541666667:  64%|██████▍   | 107/166 [01:52<00:59,  1.01s/it]avg_loss = 1.5992838541666667:  65%|██████▌   | 108/166 [01:52<00:58,  1.01s/it]avg_loss = 1.6041069380733946:  65%|██████▌   | 108/166 [01:53<00:58,  1.01s/it]avg_loss = 1.6041069380733946:  66%|██████▌   | 109/166 [01:53<00:57,  1.01s/it]avg_loss = 1.6075639204545455:  66%|██████▌   | 109/166 [01:54<00:57,  1.01s/it]avg_loss = 1.6075639204545455:  66%|██████▋   | 110/166 [01:54<00:56,  1.01s/it]avg_loss = 1.609058277027027:  66%|██████▋   | 110/166 [01:55<00:56,  1.01s/it] avg_loss = 1.609058277027027:  67%|██████▋   | 111/166 [01:55<00:55,  1.01s/it]avg_loss = 1.6102469308035714:  67%|██████▋   | 111/166 [01:56<00:55,  1.01s/it]avg_loss = 1.6102469308035714:  67%|██████▋   | 112/166 [01:56<00:54,  1.01s/it]avg_loss = 1.610377488938053:  67%|██████▋   | 112/166 [01:57<00:54,  1.01s/it] avg_loss = 1.610377488938053:  68%|██████▊   | 113/166 [01:57<00:53,  1.01s/it]avg_loss = 1.6112595942982457:  68%|██████▊   | 113/166 [01:58<00:53,  1.01s/it]avg_loss = 1.6112595942982457:  69%|██████▊   | 114/166 [01:58<00:52,  1.02s/it]avg_loss = 1.6079823369565218:  69%|██████▊   | 114/166 [01:59<00:52,  1.02s/it]avg_loss = 1.6079823369565218:  69%|██████▉   | 115/166 [01:59<00:51,  1.01s/it]avg_loss = 1.6071861530172413:  69%|██████▉   | 115/166 [02:00<00:51,  1.01s/it]avg_loss = 1.6071861530172413:  70%|██████▉   | 116/166 [02:00<00:51,  1.03s/it]avg_loss = 1.6083400106837606:  70%|██████▉   | 116/166 [02:02<00:51,  1.03s/it]avg_loss = 1.6083400106837606:  70%|███████   | 117/166 [02:02<00:50,  1.03s/it]avg_loss = 1.6077529131355932:  70%|███████   | 117/166 [02:03<00:50,  1.03s/it]avg_loss = 1.6077529131355932:  71%|███████   | 118/166 [02:03<00:50,  1.05s/it]avg_loss = 1.6065191701680672:  71%|███████   | 118/166 [02:04<00:50,  1.05s/it]avg_loss = 1.6065191701680672:  72%|███████▏  | 119/166 [02:04<00:48,  1.03s/it]avg_loss = 1.60654296875:  72%|███████▏  | 119/166 [02:05<00:48,  1.03s/it]     avg_loss = 1.60654296875:  72%|███████▏  | 120/166 [02:05<00:48,  1.05s/it]avg_loss = 1.6050167871900827:  72%|███████▏  | 120/166 [02:06<00:48,  1.05s/it]avg_loss = 1.6050167871900827:  73%|███████▎  | 121/166 [02:06<00:46,  1.04s/it]avg_loss = 1.6043481045081966:  73%|███████▎  | 121/166 [02:07<00:46,  1.04s/it]avg_loss = 1.6043481045081966:  73%|███████▎  | 122/166 [02:07<00:45,  1.05s/it]avg_loss = 1.6042619410569106:  73%|███████▎  | 122/166 [02:08<00:45,  1.05s/it]avg_loss = 1.6042619410569106:  74%|███████▍  | 123/166 [02:08<00:44,  1.03s/it]avg_loss = 1.6019720262096775:  74%|███████▍  | 123/166 [02:09<00:44,  1.03s/it]avg_loss = 1.6019720262096775:  75%|███████▍  | 124/166 [02:09<00:43,  1.03s/it]avg_loss = 1.59978125:  75%|███████▍  | 124/166 [02:10<00:43,  1.03s/it]        avg_loss = 1.59978125:  75%|███████▌  | 125/166 [02:10<00:42,  1.03s/it]avg_loss = 1.5970672123015872:  75%|███████▌  | 125/166 [02:11<00:42,  1.03s/it]avg_loss = 1.5970672123015872:  76%|███████▌  | 126/166 [02:11<00:40,  1.02s/it]avg_loss = 1.5943959153543308:  76%|███████▌  | 126/166 [02:12<00:40,  1.02s/it]avg_loss = 1.5943959153543308:  77%|███████▋  | 127/166 [02:12<00:40,  1.03s/it]avg_loss = 1.592498779296875:  77%|███████▋  | 127/166 [02:13<00:40,  1.03s/it] avg_loss = 1.592498779296875:  77%|███████▋  | 128/166 [02:13<00:38,  1.02s/it]avg_loss = 1.5910549903100775:  77%|███████▋  | 128/166 [02:14<00:38,  1.02s/it]avg_loss = 1.5910549903100775:  78%|███████▊  | 129/166 [02:14<00:37,  1.03s/it]avg_loss = 1.591015625:  78%|███████▊  | 129/166 [02:15<00:37,  1.03s/it]       avg_loss = 1.591015625:  78%|███████▊  | 130/166 [02:15<00:36,  1.02s/it]avg_loss = 1.5921099713740459:  78%|███████▊  | 130/166 [02:16<00:36,  1.02s/it]avg_loss = 1.5921099713740459:  79%|███████▉  | 131/166 [02:16<00:35,  1.02s/it]avg_loss = 1.5925366950757576:  79%|███████▉  | 131/166 [02:17<00:35,  1.02s/it]avg_loss = 1.5925366950757576:  80%|███████▉  | 132/166 [02:17<00:34,  1.02s/it]avg_loss = 1.5934856672932332:  80%|███████▉  | 132/166 [02:18<00:34,  1.02s/it]avg_loss = 1.5934856672932332:  80%|████████  | 133/166 [02:18<00:33,  1.02s/it]avg_loss = 1.5948285914179106:  80%|████████  | 133/166 [02:19<00:33,  1.02s/it]avg_loss = 1.5948285914179106:  81%|████████  | 134/166 [02:19<00:32,  1.02s/it]avg_loss = 1.593142361111111:  81%|████████  | 134/166 [02:20<00:32,  1.02s/it] avg_loss = 1.593142361111111:  81%|████████▏ | 135/166 [02:20<00:31,  1.03s/it]avg_loss = 1.593606387867647:  81%|████████▏ | 135/166 [02:21<00:31,  1.03s/it]avg_loss = 1.593606387867647:  82%|████████▏ | 136/166 [02:21<00:30,  1.03s/it]avg_loss = 1.594063640510949:  82%|████████▏ | 136/166 [02:22<00:30,  1.03s/it]avg_loss = 1.594063640510949:  83%|████████▎ | 137/166 [02:22<00:29,  1.03s/it]avg_loss = 1.5948539402173914:  83%|████████▎ | 137/166 [02:23<00:29,  1.03s/it]avg_loss = 1.5948539402173914:  83%|████████▎ | 138/166 [02:23<00:28,  1.02s/it]avg_loss = 1.594396357913669:  83%|████████▎ | 138/166 [02:24<00:28,  1.02s/it] avg_loss = 1.594396357913669:  84%|████████▎ | 139/166 [02:24<00:27,  1.03s/it]avg_loss = 1.5933314732142858:  84%|████████▎ | 139/166 [02:25<00:27,  1.03s/it]avg_loss = 1.5933314732142858:  84%|████████▍ | 140/166 [02:25<00:26,  1.02s/it]avg_loss = 1.592226285460993:  84%|████████▍ | 140/166 [02:26<00:26,  1.02s/it] avg_loss = 1.592226285460993:  85%|████████▍ | 141/166 [02:26<00:25,  1.03s/it]avg_loss = 1.5919069102112675:  85%|████████▍ | 141/166 [02:27<00:25,  1.03s/it]avg_loss = 1.5919069102112675:  86%|████████▌ | 142/166 [02:27<00:24,  1.02s/it]avg_loss = 1.590280812937063:  86%|████████▌ | 142/166 [02:28<00:24,  1.02s/it] avg_loss = 1.590280812937063:  86%|████████▌ | 143/166 [02:28<00:23,  1.03s/it]avg_loss = 1.5917154947916667:  86%|████████▌ | 143/166 [02:29<00:23,  1.03s/it]avg_loss = 1.5917154947916667:  87%|████████▋ | 144/166 [02:29<00:22,  1.02s/it]avg_loss = 1.5912984913793105:  87%|████████▋ | 144/166 [02:30<00:22,  1.02s/it]avg_loss = 1.5912984913793105:  87%|████████▋ | 145/166 [02:30<00:21,  1.05s/it]avg_loss = 1.5915293236301369:  87%|████████▋ | 145/166 [02:31<00:21,  1.05s/it]avg_loss = 1.5915293236301369:  88%|████████▊ | 146/166 [02:31<00:20,  1.04s/it]avg_loss = 1.5904283588435375:  88%|████████▊ | 146/166 [02:32<00:20,  1.04s/it]avg_loss = 1.5904283588435375:  89%|████████▊ | 147/166 [02:32<00:19,  1.03s/it]avg_loss = 1.5896062077702702:  89%|████████▊ | 147/166 [02:33<00:19,  1.03s/it]avg_loss = 1.5896062077702702:  89%|████████▉ | 148/166 [02:33<00:18,  1.02s/it]avg_loss = 1.5881658976510067:  89%|████████▉ | 148/166 [02:34<00:18,  1.02s/it]avg_loss = 1.5881658976510067:  90%|████████▉ | 149/166 [02:34<00:17,  1.02s/it]avg_loss = 1.5892447916666668:  90%|████████▉ | 149/166 [02:35<00:17,  1.02s/it]avg_loss = 1.5892447916666668:  90%|█████████ | 150/166 [02:35<00:16,  1.01s/it]avg_loss = 1.5883433360927153:  90%|█████████ | 150/166 [02:36<00:16,  1.01s/it]avg_loss = 1.5883433360927153:  91%|█████████ | 151/166 [02:36<00:15,  1.01s/it]avg_loss = 1.588173314144737:  91%|█████████ | 151/166 [02:37<00:15,  1.01s/it] avg_loss = 1.588173314144737:  92%|█████████▏| 152/166 [02:37<00:14,  1.01s/it]avg_loss = 1.5881587009803921:  92%|█████████▏| 152/166 [02:38<00:14,  1.01s/it]avg_loss = 1.5881587009803921:  92%|█████████▏| 153/166 [02:38<00:13,  1.01s/it]avg_loss = 1.5897169237012987:  92%|█████████▏| 153/166 [02:39<00:13,  1.01s/it]avg_loss = 1.5897169237012987:  93%|█████████▎| 154/166 [02:39<00:12,  1.01s/it]avg_loss = 1.589390120967742:  93%|█████████▎| 154/166 [02:40<00:12,  1.01s/it] avg_loss = 1.589390120967742:  93%|█████████▎| 155/166 [02:40<00:11,  1.01s/it]avg_loss = 1.5893679887820513:  93%|█████████▎| 155/166 [02:41<00:11,  1.01s/it]avg_loss = 1.5893679887820513:  94%|█████████▍| 156/166 [02:41<00:10,  1.01s/it]avg_loss = 1.587704020700637:  94%|█████████▍| 156/166 [02:42<00:10,  1.01s/it] avg_loss = 1.587704020700637:  95%|█████████▍| 157/166 [02:42<00:09,  1.01s/it]avg_loss = 1.5836876977848102:  95%|█████████▍| 157/166 [02:44<00:09,  1.01s/it]avg_loss = 1.5836876977848102:  95%|█████████▌| 158/166 [02:44<00:08,  1.02s/it]avg_loss = 1.584340605345912:  95%|█████████▌| 158/166 [02:45<00:08,  1.02s/it] avg_loss = 1.584340605345912:  96%|█████████▌| 159/166 [02:45<00:07,  1.01s/it]avg_loss = 1.5859130859375:  96%|█████████▌| 159/166 [02:46<00:07,  1.01s/it]  avg_loss = 1.5859130859375:  96%|█████████▋| 160/166 [02:46<00:06,  1.04s/it]avg_loss = 1.5884365295031055:  96%|█████████▋| 160/166 [02:47<00:06,  1.04s/it]avg_loss = 1.5884365295031055:  97%|█████████▋| 161/166 [02:47<00:05,  1.03s/it]avg_loss = 1.5882282021604939:  97%|█████████▋| 161/166 [02:48<00:05,  1.03s/it]avg_loss = 1.5882282021604939:  98%|█████████▊| 162/166 [02:48<00:04,  1.02s/it]avg_loss = 1.587638995398773:  98%|█████████▊| 162/166 [02:49<00:04,  1.02s/it] avg_loss = 1.587638995398773:  98%|█████████▊| 163/166 [02:49<00:03,  1.04s/it]avg_loss = 1.5883431783536586:  98%|█████████▊| 163/166 [02:50<00:03,  1.04s/it]avg_loss = 1.5883431783536586:  99%|█████████▉| 164/166 [02:50<00:02,  1.03s/it]avg_loss = 1.588091856060606:  99%|█████████▉| 164/166 [02:51<00:02,  1.03s/it] avg_loss = 1.588091856060606:  99%|█████████▉| 165/166 [02:51<00:01,  1.04s/it]avg_loss = 1.5900084713855422:  99%|█████████▉| 165/166 [02:52<00:01,  1.04s/it]avg_loss = 1.5900084713855422: 100%|██████████| 166/166 [02:52<00:00,  1.03s/it]avg_loss = 1.5900084713855422: 100%|██████████| 166/166 [02:52<00:00,  1.04s/it]
I0303 16:50:32.855880 3313733 eval_ppl.py:105] wikitext2 perplexity: 4.903790473937988
wikitext2 perplexity: 4.904
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda1000_rdloss_ql_encdim512_M16_batch_size2048_total_iter1500000_lr0.0001_seed100/best_loss_model_loss_6.59649_bpp_6.05166_MSE_0.00106_total_iter_140000.pth.tar/COL_MSE0.0058_bpploss4.7776_bpp0
I0303 16:50:36.859545 3315859 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.21it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:03,  1.22it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.26it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:03<00:01,  1.30it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:03<00:00,  1.68it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.71it/s]
W0303 16:50:40.563617 3315859 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 16:50:40.577528 3315859 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.234375:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.234375:   1%|          | 1/166 [00:01<03:48,  1.38s/it]avg_loss = 1.53515625:   1%|          | 1/166 [00:02<03:48,  1.38s/it]avg_loss = 1.53515625:   1%|          | 2/166 [00:02<03:03,  1.12s/it]avg_loss = 1.7057291666666667:   1%|          | 2/166 [00:03<03:03,  1.12s/it]avg_loss = 1.7057291666666667:   2%|▏         | 3/166 [00:03<02:51,  1.05s/it]avg_loss = 1.734375:   2%|▏         | 3/166 [00:04<02:51,  1.05s/it]          avg_loss = 1.734375:   2%|▏         | 4/166 [00:04<02:44,  1.01s/it]avg_loss = 1.66875:   2%|▏         | 4/166 [00:05<02:44,  1.01s/it] avg_loss = 1.66875:   3%|▎         | 5/166 [00:05<02:40,  1.00it/s]avg_loss = 1.6393229166666667:   3%|▎         | 5/166 [00:06<02:40,  1.00it/s]avg_loss = 1.6393229166666667:   4%|▎         | 6/166 [00:06<02:37,  1.01it/s]avg_loss = 1.5758928571428572:   4%|▎         | 6/166 [00:07<02:37,  1.01it/s]avg_loss = 1.5758928571428572:   4%|▍         | 7/166 [00:07<02:37,  1.01it/s]avg_loss = 1.5087890625:   4%|▍         | 7/166 [00:08<02:37,  1.01it/s]      avg_loss = 1.5087890625:   5%|▍         | 8/166 [00:08<02:36,  1.01it/s]avg_loss = 1.5060763888888888:   5%|▍         | 8/166 [00:09<02:36,  1.01it/s]avg_loss = 1.5060763888888888:   5%|▌         | 9/166 [00:09<02:35,  1.01it/s]avg_loss = 1.51640625:   5%|▌         | 9/166 [00:10<02:35,  1.01it/s]        avg_loss = 1.51640625:   6%|▌         | 10/166 [00:10<02:34,  1.01it/s]avg_loss = 1.5348011363636365:   6%|▌         | 10/166 [00:11<02:34,  1.01it/s]avg_loss = 1.5348011363636365:   7%|▋         | 11/166 [00:11<02:34,  1.00it/s]avg_loss = 1.544921875:   7%|▋         | 11/166 [00:12<02:34,  1.00it/s]       avg_loss = 1.544921875:   7%|▋         | 12/166 [00:12<02:33,  1.00it/s]avg_loss = 1.5414663461538463:   7%|▋         | 12/166 [00:13<02:33,  1.00it/s]avg_loss = 1.5414663461538463:   8%|▊         | 13/166 [00:13<02:34,  1.01s/it]avg_loss = 1.5558035714285714:   8%|▊         | 13/166 [00:14<02:34,  1.01s/it]avg_loss = 1.5558035714285714:   8%|▊         | 14/166 [00:14<02:38,  1.04s/it]avg_loss = 1.571875:   8%|▊         | 14/166 [00:15<02:38,  1.04s/it]          avg_loss = 1.571875:   9%|▉         | 15/166 [00:15<02:36,  1.04s/it]avg_loss = 1.58984375:   9%|▉         | 15/166 [00:16<02:36,  1.04s/it]avg_loss = 1.58984375:  10%|▉         | 16/166 [00:16<02:35,  1.03s/it]avg_loss = 1.599264705882353:  10%|▉         | 16/166 [00:17<02:35,  1.03s/it]avg_loss = 1.599264705882353:  10%|█         | 17/166 [00:17<02:33,  1.03s/it]avg_loss = 1.6128472222222223:  10%|█         | 17/166 [00:18<02:33,  1.03s/it]avg_loss = 1.6128472222222223:  11%|█         | 18/166 [00:18<02:32,  1.03s/it]avg_loss = 1.6319901315789473:  11%|█         | 18/166 [00:19<02:32,  1.03s/it]avg_loss = 1.6319901315789473:  11%|█▏        | 19/166 [00:19<02:30,  1.02s/it]avg_loss = 1.638671875:  11%|█▏        | 19/166 [00:20<02:30,  1.02s/it]       avg_loss = 1.638671875:  12%|█▏        | 20/166 [00:20<02:29,  1.02s/it]avg_loss = 1.6391369047619047:  12%|█▏        | 20/166 [00:21<02:29,  1.02s/it]avg_loss = 1.6391369047619047:  13%|█▎        | 21/166 [00:21<02:27,  1.02s/it]avg_loss = 1.6281960227272727:  13%|█▎        | 21/166 [00:22<02:27,  1.02s/it]avg_loss = 1.6281960227272727:  13%|█▎        | 22/166 [00:22<02:26,  1.02s/it]avg_loss = 1.611413043478261:  13%|█▎        | 22/166 [00:23<02:26,  1.02s/it] avg_loss = 1.611413043478261:  14%|█▍        | 23/166 [00:23<02:24,  1.01s/it]avg_loss = 1.6194661458333333:  14%|█▍        | 23/166 [00:24<02:24,  1.01s/it]avg_loss = 1.6194661458333333:  14%|█▍        | 24/166 [00:24<02:23,  1.01s/it]avg_loss = 1.6271875:  14%|█▍        | 24/166 [00:25<02:23,  1.01s/it]         avg_loss = 1.6271875:  15%|█▌        | 25/166 [00:25<02:24,  1.02s/it]avg_loss = 1.6319110576923077:  15%|█▌        | 25/166 [00:26<02:24,  1.02s/it]avg_loss = 1.6319110576923077:  16%|█▌        | 26/166 [00:26<02:22,  1.02s/it]avg_loss = 1.638599537037037:  16%|█▌        | 26/166 [00:27<02:22,  1.02s/it] avg_loss = 1.638599537037037:  16%|█▋        | 27/166 [00:27<02:20,  1.01s/it]avg_loss = 1.6409040178571428:  16%|█▋        | 27/166 [00:28<02:20,  1.01s/it]avg_loss = 1.6409040178571428:  17%|█▋        | 28/166 [00:28<02:20,  1.02s/it]avg_loss = 1.6505926724137931:  17%|█▋        | 28/166 [00:29<02:20,  1.02s/it]avg_loss = 1.6505926724137931:  17%|█▋        | 29/166 [00:29<02:21,  1.03s/it]avg_loss = 1.6510416666666667:  17%|█▋        | 29/166 [00:30<02:21,  1.03s/it]avg_loss = 1.6510416666666667:  18%|█▊        | 30/166 [00:30<02:18,  1.01s/it]avg_loss = 1.6658266129032258:  18%|█▊        | 30/166 [00:31<02:18,  1.01s/it]avg_loss = 1.6658266129032258:  19%|█▊        | 31/166 [00:31<02:18,  1.03s/it]avg_loss = 1.67333984375:  19%|█▊        | 31/166 [00:32<02:18,  1.03s/it]     avg_loss = 1.67333984375:  19%|█▉        | 32/166 [00:32<02:15,  1.01s/it]avg_loss = 1.6785037878787878:  19%|█▉        | 32/166 [00:33<02:15,  1.01s/it]avg_loss = 1.6785037878787878:  20%|█▉        | 33/166 [00:33<02:15,  1.02s/it]avg_loss = 1.6764705882352942:  20%|█▉        | 33/166 [00:34<02:15,  1.02s/it]avg_loss = 1.6764705882352942:  20%|██        | 34/166 [00:34<02:13,  1.01s/it]avg_loss = 1.6698660714285714:  20%|██        | 34/166 [00:35<02:13,  1.01s/it]avg_loss = 1.6698660714285714:  21%|██        | 35/166 [00:35<02:13,  1.02s/it]avg_loss = 1.66015625:  21%|██        | 35/166 [00:36<02:13,  1.02s/it]        avg_loss = 1.66015625:  22%|██▏       | 36/166 [00:36<02:13,  1.03s/it]avg_loss = 1.6494932432432432:  22%|██▏       | 36/166 [00:37<02:13,  1.03s/it]avg_loss = 1.6494932432432432:  22%|██▏       | 37/166 [00:37<02:10,  1.02s/it]avg_loss = 1.645970394736842:  22%|██▏       | 37/166 [00:38<02:10,  1.02s/it] avg_loss = 1.645970394736842:  23%|██▎       | 38/166 [00:38<02:10,  1.02s/it]avg_loss = 1.6434294871794872:  23%|██▎       | 38/166 [00:39<02:10,  1.02s/it]avg_loss = 1.6434294871794872:  23%|██▎       | 39/166 [00:39<02:09,  1.02s/it]avg_loss = 1.6478515625:  23%|██▎       | 39/166 [00:40<02:09,  1.02s/it]      avg_loss = 1.6478515625:  24%|██▍       | 40/166 [00:40<02:07,  1.02s/it]avg_loss = 1.6488185975609757:  24%|██▍       | 40/166 [00:41<02:07,  1.02s/it]avg_loss = 1.6488185975609757:  25%|██▍       | 41/166 [00:41<02:06,  1.01s/it]avg_loss = 1.6376488095238095:  25%|██▍       | 41/166 [00:42<02:06,  1.01s/it]avg_loss = 1.6376488095238095:  25%|██▌       | 42/166 [00:42<02:05,  1.01s/it]avg_loss = 1.6228197674418605:  25%|██▌       | 42/166 [00:43<02:05,  1.01s/it]avg_loss = 1.6228197674418605:  26%|██▌       | 43/166 [00:43<02:04,  1.01s/it]avg_loss = 1.6134588068181819:  26%|██▌       | 43/166 [00:44<02:04,  1.01s/it]avg_loss = 1.6134588068181819:  27%|██▋       | 44/166 [00:44<02:02,  1.01s/it]avg_loss = 1.6003472222222221:  27%|██▋       | 44/166 [00:45<02:02,  1.01s/it]avg_loss = 1.6003472222222221:  27%|██▋       | 45/166 [00:45<02:01,  1.01s/it]avg_loss = 1.5903532608695652:  27%|██▋       | 45/166 [00:46<02:01,  1.01s/it]avg_loss = 1.5903532608695652:  28%|██▊       | 46/166 [00:46<02:00,  1.00s/it]avg_loss = 1.5841090425531914:  28%|██▊       | 46/166 [00:47<02:00,  1.00s/it]avg_loss = 1.5841090425531914:  28%|██▊       | 47/166 [00:47<01:59,  1.00s/it]avg_loss = 1.5851236979166667:  28%|██▊       | 47/166 [00:48<01:59,  1.00s/it]avg_loss = 1.5851236979166667:  29%|██▉       | 48/166 [00:48<02:01,  1.03s/it]avg_loss = 1.596141581632653:  29%|██▉       | 48/166 [00:49<02:01,  1.03s/it] avg_loss = 1.596141581632653:  30%|██▉       | 49/166 [00:49<01:58,  1.02s/it]avg_loss = 1.60734375:  30%|██▉       | 49/166 [00:50<01:58,  1.02s/it]       avg_loss = 1.60734375:  30%|███       | 50/166 [00:50<02:00,  1.04s/it]avg_loss = 1.6141237745098038:  30%|███       | 50/166 [00:51<02:00,  1.04s/it]avg_loss = 1.6141237745098038:  31%|███       | 51/166 [00:51<01:58,  1.03s/it]avg_loss = 1.6182391826923077:  31%|███       | 51/166 [00:52<01:58,  1.03s/it]avg_loss = 1.6182391826923077:  31%|███▏      | 52/166 [00:52<01:56,  1.02s/it]avg_loss = 1.6214622641509433:  31%|███▏      | 52/166 [00:54<01:56,  1.02s/it]avg_loss = 1.6214622641509433:  32%|███▏      | 53/166 [00:54<01:59,  1.06s/it]avg_loss = 1.623119212962963:  32%|███▏      | 53/166 [00:55<01:59,  1.06s/it] avg_loss = 1.623119212962963:  33%|███▎      | 54/166 [00:55<01:56,  1.04s/it]avg_loss = 1.6264204545454546:  33%|███▎      | 54/166 [00:56<01:56,  1.04s/it]avg_loss = 1.6264204545454546:  33%|███▎      | 55/166 [00:56<01:58,  1.07s/it]avg_loss = 1.6305803571428572:  33%|███▎      | 55/166 [00:57<01:58,  1.07s/it]avg_loss = 1.6305803571428572:  34%|███▎      | 56/166 [00:57<01:54,  1.04s/it]avg_loss = 1.6260964912280702:  34%|███▎      | 56/166 [00:58<01:54,  1.04s/it]avg_loss = 1.6260964912280702:  34%|███▍      | 57/166 [00:58<01:54,  1.05s/it]avg_loss = 1.6298491379310345:  34%|███▍      | 57/166 [00:59<01:54,  1.05s/it]avg_loss = 1.6298491379310345:  35%|███▍      | 58/166 [00:59<01:52,  1.04s/it]avg_loss = 1.6283103813559323:  35%|███▍      | 58/166 [01:00<01:52,  1.04s/it]avg_loss = 1.6283103813559323:  36%|███▌      | 59/166 [01:00<01:52,  1.05s/it]avg_loss = 1.623828125:  36%|███▌      | 59/166 [01:01<01:52,  1.05s/it]       avg_loss = 1.623828125:  36%|███▌      | 60/166 [01:01<01:50,  1.04s/it]avg_loss = 1.6201331967213115:  36%|███▌      | 60/166 [01:02<01:50,  1.04s/it]avg_loss = 1.6201331967213115:  37%|███▋      | 61/166 [01:02<01:48,  1.03s/it]avg_loss = 1.6166834677419355:  37%|███▋      | 61/166 [01:03<01:48,  1.03s/it]avg_loss = 1.6166834677419355:  37%|███▋      | 62/166 [01:03<01:47,  1.04s/it]avg_loss = 1.6109871031746033:  37%|███▋      | 62/166 [01:04<01:47,  1.04s/it]avg_loss = 1.6109871031746033:  38%|███▊      | 63/166 [01:04<01:46,  1.04s/it]avg_loss = 1.6068115234375:  38%|███▊      | 63/166 [01:05<01:46,  1.04s/it]   avg_loss = 1.6068115234375:  39%|███▊      | 64/166 [01:05<01:45,  1.03s/it]avg_loss = 1.5998798076923078:  39%|███▊      | 64/166 [01:06<01:45,  1.03s/it]avg_loss = 1.5998798076923078:  39%|███▉      | 65/166 [01:06<01:44,  1.03s/it]avg_loss = 1.5929214015151516:  39%|███▉      | 65/166 [01:07<01:44,  1.03s/it]avg_loss = 1.5929214015151516:  40%|███▉      | 66/166 [01:07<01:43,  1.04s/it]avg_loss = 1.5868703358208955:  40%|███▉      | 66/166 [01:08<01:43,  1.04s/it]avg_loss = 1.5868703358208955:  40%|████      | 67/166 [01:08<01:42,  1.03s/it]avg_loss = 1.585592830882353:  40%|████      | 67/166 [01:09<01:42,  1.03s/it] avg_loss = 1.585592830882353:  41%|████      | 68/166 [01:09<01:41,  1.03s/it]avg_loss = 1.5872961956521738:  41%|████      | 68/166 [01:10<01:41,  1.03s/it]avg_loss = 1.5872961956521738:  42%|████▏     | 69/166 [01:10<01:40,  1.03s/it]avg_loss = 1.5905133928571429:  42%|████▏     | 69/166 [01:11<01:40,  1.03s/it]avg_loss = 1.5905133928571429:  42%|████▏     | 70/166 [01:11<01:39,  1.04s/it]avg_loss = 1.594850352112676:  42%|████▏     | 70/166 [01:12<01:39,  1.04s/it] avg_loss = 1.594850352112676:  43%|████▎     | 71/166 [01:12<01:38,  1.04s/it]avg_loss = 1.6003689236111112:  43%|████▎     | 71/166 [01:13<01:38,  1.04s/it]avg_loss = 1.6003689236111112:  43%|████▎     | 72/166 [01:13<01:37,  1.03s/it]avg_loss = 1.60669948630137:  43%|████▎     | 72/166 [01:14<01:37,  1.03s/it]  avg_loss = 1.60669948630137:  44%|████▍     | 73/166 [01:14<01:35,  1.03s/it]avg_loss = 1.600929054054054:  44%|████▍     | 73/166 [01:15<01:35,  1.03s/it]avg_loss = 1.600929054054054:  45%|████▍     | 74/166 [01:15<01:34,  1.03s/it]avg_loss = 1.5963541666666667:  45%|████▍     | 74/166 [01:16<01:34,  1.03s/it]avg_loss = 1.5963541666666667:  45%|████▌     | 75/166 [01:16<01:33,  1.03s/it]avg_loss = 1.5952919407894737:  45%|████▌     | 75/166 [01:17<01:33,  1.03s/it]avg_loss = 1.5952919407894737:  46%|████▌     | 76/166 [01:17<01:32,  1.03s/it]avg_loss = 1.5919237012987013:  46%|████▌     | 76/166 [01:18<01:32,  1.03s/it]avg_loss = 1.5919237012987013:  46%|████▋     | 77/166 [01:18<01:31,  1.03s/it]avg_loss = 1.5886418269230769:  46%|████▋     | 77/166 [01:19<01:31,  1.03s/it]avg_loss = 1.5886418269230769:  47%|████▋     | 78/166 [01:19<01:30,  1.03s/it]avg_loss = 1.5860363924050633:  47%|████▋     | 78/166 [01:21<01:30,  1.03s/it]avg_loss = 1.5860363924050633:  48%|████▊     | 79/166 [01:21<01:29,  1.03s/it]avg_loss = 1.5826171875:  48%|████▊     | 79/166 [01:22<01:29,  1.03s/it]      avg_loss = 1.5826171875:  48%|████▊     | 80/166 [01:22<01:29,  1.04s/it]avg_loss = 1.5729648919753085:  48%|████▊     | 80/166 [01:23<01:29,  1.04s/it]avg_loss = 1.5729648919753085:  49%|████▉     | 81/166 [01:23<01:28,  1.04s/it]avg_loss = 1.5746474847560976:  49%|████▉     | 81/166 [01:24<01:28,  1.04s/it]avg_loss = 1.5746474847560976:  49%|████▉     | 82/166 [01:24<01:25,  1.02s/it]avg_loss = 1.5757247740963856:  49%|████▉     | 82/166 [01:25<01:25,  1.02s/it]avg_loss = 1.5757247740963856:  50%|█████     | 83/166 [01:25<01:24,  1.02s/it]avg_loss = 1.5783575148809523:  50%|█████     | 83/166 [01:26<01:24,  1.02s/it]avg_loss = 1.5783575148809523:  51%|█████     | 84/166 [01:26<01:23,  1.01s/it]avg_loss = 1.5799172794117646:  51%|█████     | 84/166 [01:27<01:23,  1.01s/it]avg_loss = 1.5799172794117646:  51%|█████     | 85/166 [01:27<01:22,  1.02s/it]avg_loss = 1.5788063226744187:  51%|█████     | 85/166 [01:28<01:22,  1.02s/it]avg_loss = 1.5788063226744187:  52%|█████▏    | 86/166 [01:28<01:21,  1.01s/it]avg_loss = 1.5792474856321839:  52%|█████▏    | 86/166 [01:29<01:21,  1.01s/it]avg_loss = 1.5792474856321839:  52%|█████▏    | 87/166 [01:29<01:20,  1.01s/it]avg_loss = 1.5799449573863635:  52%|█████▏    | 87/166 [01:30<01:20,  1.01s/it]avg_loss = 1.5799449573863635:  53%|█████▎    | 88/166 [01:30<01:18,  1.01s/it]avg_loss = 1.581153441011236:  53%|█████▎    | 88/166 [01:31<01:18,  1.01s/it] avg_loss = 1.581153441011236:  54%|█████▎    | 89/166 [01:31<01:18,  1.02s/it]avg_loss = 1.5809461805555556:  54%|█████▎    | 89/166 [01:32<01:18,  1.02s/it]avg_loss = 1.5809461805555556:  54%|█████▍    | 90/166 [01:32<01:17,  1.01s/it]avg_loss = 1.581773695054945:  54%|█████▍    | 90/166 [01:33<01:17,  1.01s/it] avg_loss = 1.581773695054945:  55%|█████▍    | 91/166 [01:33<01:17,  1.03s/it]avg_loss = 1.5820737092391304:  55%|█████▍    | 91/166 [01:34<01:17,  1.03s/it]avg_loss = 1.5820737092391304:  55%|█████▌    | 92/166 [01:34<01:15,  1.02s/it]avg_loss = 1.5853914650537635:  55%|█████▌    | 92/166 [01:35<01:15,  1.02s/it]avg_loss = 1.5853914650537635:  56%|█████▌    | 93/166 [01:35<01:15,  1.03s/it]avg_loss = 1.5848154920212767:  56%|█████▌    | 93/166 [01:36<01:15,  1.03s/it]avg_loss = 1.5848154920212767:  57%|█████▋    | 94/166 [01:36<01:13,  1.02s/it]avg_loss = 1.5842516447368422:  57%|█████▋    | 94/166 [01:37<01:13,  1.02s/it]avg_loss = 1.5842516447368422:  57%|█████▋    | 95/166 [01:37<01:13,  1.04s/it]avg_loss = 1.5837809244791667:  57%|█████▋    | 95/166 [01:38<01:13,  1.04s/it]avg_loss = 1.5837809244791667:  58%|█████▊    | 96/166 [01:38<01:11,  1.03s/it]avg_loss = 1.582997744845361:  58%|█████▊    | 96/166 [01:39<01:11,  1.03s/it] avg_loss = 1.582997744845361:  58%|█████▊    | 97/166 [01:39<01:12,  1.05s/it]avg_loss = 1.5813536352040816:  58%|█████▊    | 97/166 [01:40<01:12,  1.05s/it]avg_loss = 1.5813536352040816:  59%|█████▉    | 98/166 [01:40<01:10,  1.03s/it]avg_loss = 1.5791903409090908:  59%|█████▉    | 98/166 [01:41<01:10,  1.03s/it]avg_loss = 1.5791903409090908:  60%|█████▉    | 99/166 [01:41<01:10,  1.05s/it]avg_loss = 1.5765234375:  60%|█████▉    | 99/166 [01:42<01:10,  1.05s/it]      avg_loss = 1.5765234375:  60%|██████    | 100/166 [01:42<01:08,  1.04s/it]avg_loss = 1.5771581064356435:  60%|██████    | 100/166 [01:43<01:08,  1.04s/it]avg_loss = 1.5771581064356435:  61%|██████    | 101/166 [01:43<01:07,  1.03s/it]avg_loss = 1.5783930759803921:  61%|██████    | 101/166 [01:44<01:07,  1.03s/it]avg_loss = 1.5783930759803921:  61%|██████▏   | 102/166 [01:44<01:05,  1.03s/it]avg_loss = 1.5789214199029127:  61%|██████▏   | 102/166 [01:45<01:05,  1.03s/it]avg_loss = 1.5789214199029127:  62%|██████▏   | 103/166 [01:45<01:04,  1.02s/it]avg_loss = 1.5807917668269231:  62%|██████▏   | 103/166 [01:46<01:04,  1.02s/it]avg_loss = 1.5807917668269231:  63%|██████▎   | 104/166 [01:46<01:03,  1.02s/it]avg_loss = 1.587313988095238:  63%|██████▎   | 104/166 [01:47<01:03,  1.02s/it] avg_loss = 1.587313988095238:  63%|██████▎   | 105/166 [01:47<01:02,  1.02s/it]avg_loss = 1.5926813089622642:  63%|██████▎   | 105/166 [01:48<01:02,  1.02s/it]avg_loss = 1.5926813089622642:  64%|██████▍   | 106/166 [01:48<01:01,  1.02s/it]avg_loss = 1.595903913551402:  64%|██████▍   | 106/166 [01:49<01:01,  1.02s/it] avg_loss = 1.595903913551402:  64%|██████▍   | 107/166 [01:49<01:00,  1.02s/it]avg_loss = 1.5989221643518519:  64%|██████▍   | 107/166 [01:50<01:00,  1.02s/it]avg_loss = 1.5989221643518519:  65%|██████▌   | 108/166 [01:50<00:58,  1.01s/it]avg_loss = 1.6037485665137614:  65%|██████▌   | 108/166 [01:51<00:58,  1.01s/it]avg_loss = 1.6037485665137614:  66%|██████▌   | 109/166 [01:51<00:58,  1.02s/it]avg_loss = 1.6072088068181818:  66%|██████▌   | 109/166 [01:52<00:58,  1.02s/it]avg_loss = 1.6072088068181818:  66%|██████▋   | 110/166 [01:52<00:56,  1.01s/it]avg_loss = 1.6087063626126126:  66%|██████▋   | 110/166 [01:53<00:56,  1.01s/it]avg_loss = 1.6087063626126126:  67%|██████▋   | 111/166 [01:53<00:56,  1.03s/it]avg_loss = 1.6098981584821428:  67%|██████▋   | 111/166 [01:54<00:56,  1.03s/it]avg_loss = 1.6098981584821428:  67%|██████▋   | 112/166 [01:54<00:54,  1.02s/it]avg_loss = 1.610031803097345:  67%|██████▋   | 112/166 [01:55<00:54,  1.02s/it] avg_loss = 1.610031803097345:  68%|██████▊   | 113/166 [01:55<00:54,  1.02s/it]avg_loss = 1.6108484100877194:  68%|██████▊   | 113/166 [01:56<00:54,  1.02s/it]avg_loss = 1.6108484100877194:  69%|██████▊   | 114/166 [01:56<00:52,  1.02s/it]avg_loss = 1.6075747282608697:  69%|██████▊   | 114/166 [01:57<00:52,  1.02s/it]avg_loss = 1.6075747282608697:  69%|██████▉   | 115/166 [01:57<00:52,  1.03s/it]avg_loss = 1.6068494073275863:  69%|██████▉   | 115/166 [01:58<00:52,  1.03s/it]avg_loss = 1.6068494073275863:  70%|██████▉   | 116/166 [01:58<00:50,  1.01s/it]avg_loss = 1.608006143162393:  70%|██████▉   | 116/166 [01:59<00:50,  1.01s/it] avg_loss = 1.608006143162393:  70%|███████   | 117/166 [01:59<00:50,  1.03s/it]avg_loss = 1.607421875:  70%|███████   | 117/166 [02:00<00:50,  1.03s/it]      avg_loss = 1.607421875:  71%|███████   | 118/166 [02:00<00:48,  1.02s/it]avg_loss = 1.6061909138655461:  71%|███████   | 118/166 [02:01<00:48,  1.02s/it]avg_loss = 1.6061909138655461:  72%|███████▏  | 119/166 [02:01<00:48,  1.03s/it]avg_loss = 1.6062174479166667:  72%|███████▏  | 119/166 [02:02<00:48,  1.03s/it]avg_loss = 1.6062174479166667:  72%|███████▏  | 120/166 [02:02<00:46,  1.02s/it]avg_loss = 1.6046939566115703:  72%|███████▏  | 120/166 [02:04<00:46,  1.02s/it]avg_loss = 1.6046939566115703:  73%|███████▎  | 121/166 [02:04<00:46,  1.03s/it]avg_loss = 1.6040279200819672:  73%|███████▎  | 121/166 [02:04<00:46,  1.03s/it]avg_loss = 1.6040279200819672:  73%|███████▎  | 122/166 [02:04<00:44,  1.01s/it]avg_loss = 1.6039443597560976:  73%|███████▎  | 122/166 [02:06<00:44,  1.01s/it]avg_loss = 1.6039443597560976:  74%|███████▍  | 123/166 [02:06<00:43,  1.02s/it]avg_loss = 1.601657006048387:  74%|███████▍  | 123/166 [02:07<00:43,  1.02s/it] avg_loss = 1.601657006048387:  75%|███████▍  | 124/166 [02:07<00:42,  1.01s/it]avg_loss = 1.59940625:  75%|███████▍  | 124/166 [02:08<00:42,  1.01s/it]       avg_loss = 1.59940625:  75%|███████▌  | 125/166 [02:08<00:41,  1.01s/it]avg_loss = 1.5966951884920635:  75%|███████▌  | 125/166 [02:09<00:41,  1.01s/it]avg_loss = 1.5966951884920635:  76%|███████▌  | 126/166 [02:09<00:40,  1.00s/it]avg_loss = 1.5940268208661417:  76%|███████▌  | 126/166 [02:10<00:40,  1.00s/it]avg_loss = 1.5940268208661417:  77%|███████▋  | 127/166 [02:10<00:39,  1.01s/it]avg_loss = 1.592132568359375:  77%|███████▋  | 127/166 [02:11<00:39,  1.01s/it] avg_loss = 1.592132568359375:  77%|███████▋  | 128/166 [02:11<00:37,  1.00it/s]avg_loss = 1.5906916182170543:  77%|███████▋  | 128/166 [02:12<00:37,  1.00it/s]avg_loss = 1.5906916182170543:  78%|███████▊  | 129/166 [02:12<00:37,  1.01s/it]avg_loss = 1.590655048076923:  78%|███████▊  | 129/166 [02:13<00:37,  1.01s/it] avg_loss = 1.590655048076923:  78%|███████▊  | 130/166 [02:13<00:36,  1.00s/it]avg_loss = 1.591752146946565:  78%|███████▊  | 130/166 [02:14<00:36,  1.00s/it]avg_loss = 1.591752146946565:  79%|███████▉  | 131/166 [02:14<00:35,  1.00s/it]avg_loss = 1.5921223958333333:  79%|███████▉  | 131/166 [02:15<00:35,  1.00s/it]avg_loss = 1.5921223958333333:  80%|███████▉  | 132/166 [02:15<00:33,  1.00it/s]avg_loss = 1.5930744830827068:  80%|███████▉  | 132/166 [02:16<00:33,  1.00it/s]avg_loss = 1.5930744830827068:  80%|████████  | 133/166 [02:16<00:33,  1.01s/it]avg_loss = 1.5944204757462686:  80%|████████  | 133/166 [02:17<00:33,  1.01s/it]avg_loss = 1.5944204757462686:  81%|████████  | 134/166 [02:17<00:32,  1.01s/it]avg_loss = 1.5926793981481482:  81%|████████  | 134/166 [02:18<00:32,  1.01s/it]avg_loss = 1.5926793981481482:  81%|████████▏ | 135/166 [02:18<00:31,  1.02s/it]avg_loss = 1.5931468290441178:  81%|████████▏ | 135/166 [02:19<00:31,  1.02s/it]avg_loss = 1.5931468290441178:  82%|████████▏ | 136/166 [02:19<00:30,  1.01s/it]avg_loss = 1.5936074361313868:  82%|████████▏ | 136/166 [02:20<00:30,  1.01s/it]avg_loss = 1.5936074361313868:  83%|████████▎ | 137/166 [02:20<00:29,  1.01s/it]avg_loss = 1.5944576539855073:  83%|████████▎ | 137/166 [02:21<00:29,  1.01s/it]avg_loss = 1.5944576539855073:  83%|████████▎ | 138/166 [02:21<00:28,  1.03s/it]avg_loss = 1.5940029226618706:  83%|████████▎ | 138/166 [02:22<00:28,  1.03s/it]avg_loss = 1.5940029226618706:  84%|████████▎ | 139/166 [02:22<00:27,  1.03s/it]avg_loss = 1.5929408482142857:  84%|████████▎ | 139/166 [02:23<00:27,  1.03s/it]avg_loss = 1.5929408482142857:  84%|████████▍ | 140/166 [02:23<00:26,  1.04s/it]avg_loss = 1.5918384308510638:  84%|████████▍ | 140/166 [02:24<00:26,  1.04s/it]avg_loss = 1.5918384308510638:  85%|████████▍ | 141/166 [02:24<00:25,  1.03s/it]avg_loss = 1.5915768045774648:  85%|████████▍ | 141/166 [02:25<00:25,  1.03s/it]avg_loss = 1.5915768045774648:  86%|████████▌ | 142/166 [02:25<00:24,  1.03s/it]avg_loss = 1.5899530157342658:  86%|████████▌ | 142/166 [02:26<00:24,  1.03s/it]avg_loss = 1.5899530157342658:  86%|████████▌ | 143/166 [02:26<00:23,  1.03s/it]avg_loss = 1.5913357204861112:  86%|████████▌ | 143/166 [02:27<00:23,  1.03s/it]avg_loss = 1.5913357204861112:  87%|████████▋ | 144/166 [02:27<00:22,  1.03s/it]avg_loss = 1.5909213362068966:  87%|████████▋ | 144/166 [02:28<00:22,  1.03s/it]avg_loss = 1.5909213362068966:  87%|████████▋ | 145/166 [02:28<00:21,  1.03s/it]avg_loss = 1.5911547517123288:  87%|████████▋ | 145/166 [02:29<00:21,  1.03s/it]avg_loss = 1.5911547517123288:  88%|████████▊ | 146/166 [02:29<00:20,  1.01s/it]avg_loss = 1.590109481292517:  88%|████████▊ | 146/166 [02:30<00:20,  1.01s/it] avg_loss = 1.590109481292517:  89%|████████▊ | 147/166 [02:30<00:19,  1.03s/it]avg_loss = 1.5892894847972974:  89%|████████▊ | 147/166 [02:31<00:19,  1.03s/it]avg_loss = 1.5892894847972974:  89%|████████▉ | 148/166 [02:31<00:18,  1.02s/it]avg_loss = 1.5878513003355705:  89%|████████▉ | 148/166 [02:32<00:18,  1.02s/it]avg_loss = 1.5878513003355705:  90%|████████▉ | 149/166 [02:32<00:17,  1.03s/it]avg_loss = 1.5888802083333333:  90%|████████▉ | 149/166 [02:33<00:17,  1.03s/it]avg_loss = 1.5888802083333333:  90%|█████████ | 150/166 [02:33<00:16,  1.01s/it]avg_loss = 1.587929428807947:  90%|█████████ | 150/166 [02:34<00:16,  1.01s/it] avg_loss = 1.587929428807947:  91%|█████████ | 151/166 [02:34<00:15,  1.03s/it]avg_loss = 1.5878135279605263:  91%|█████████ | 151/166 [02:35<00:15,  1.03s/it]avg_loss = 1.5878135279605263:  92%|█████████▏| 152/166 [02:35<00:14,  1.02s/it]avg_loss = 1.587750204248366:  92%|█████████▏| 152/166 [02:36<00:14,  1.02s/it] avg_loss = 1.587750204248366:  92%|█████████▏| 153/166 [02:36<00:13,  1.03s/it]avg_loss = 1.5893618100649352:  92%|█████████▏| 153/166 [02:37<00:13,  1.03s/it]avg_loss = 1.5893618100649352:  93%|█████████▎| 154/166 [02:37<00:12,  1.02s/it]avg_loss = 1.5890372983870968:  93%|█████████▎| 154/166 [02:38<00:12,  1.02s/it]avg_loss = 1.5890372983870968:  93%|█████████▎| 155/166 [02:38<00:11,  1.03s/it]avg_loss = 1.5890174278846154:  93%|█████████▎| 155/166 [02:39<00:11,  1.03s/it]avg_loss = 1.5890174278846154:  94%|█████████▍| 156/166 [02:39<00:10,  1.01s/it]avg_loss = 1.5873556926751593:  94%|█████████▍| 156/166 [02:40<00:10,  1.01s/it]avg_loss = 1.5873556926751593:  95%|█████████▍| 157/166 [02:40<00:09,  1.02s/it]avg_loss = 1.5833415743670887:  95%|█████████▍| 157/166 [02:41<00:09,  1.02s/it]avg_loss = 1.5833415743670887:  95%|█████████▌| 158/166 [02:41<00:08,  1.01s/it]avg_loss = 1.5839966588050314:  95%|█████████▌| 158/166 [02:42<00:08,  1.01s/it]avg_loss = 1.5839966588050314:  96%|█████████▌| 159/166 [02:42<00:07,  1.02s/it]avg_loss = 1.5855712890625:  96%|█████████▌| 159/166 [02:43<00:07,  1.02s/it]   avg_loss = 1.5855712890625:  96%|█████████▋| 160/166 [02:43<00:06,  1.02s/it]avg_loss = 1.588096855590062:  96%|█████████▋| 160/166 [02:44<00:06,  1.02s/it]avg_loss = 1.588096855590062:  97%|█████████▋| 161/166 [02:44<00:05,  1.01s/it]avg_loss = 1.587890625:  97%|█████████▋| 161/166 [02:45<00:05,  1.01s/it]      avg_loss = 1.587890625:  98%|█████████▊| 162/166 [02:45<00:04,  1.01s/it]avg_loss = 1.587255559815951:  98%|█████████▊| 162/166 [02:46<00:04,  1.01s/it]avg_loss = 1.587255559815951:  98%|█████████▊| 163/166 [02:46<00:03,  1.02s/it]avg_loss = 1.5879620807926829:  98%|█████████▊| 163/166 [02:47<00:03,  1.02s/it]avg_loss = 1.5879620807926829:  99%|█████████▉| 164/166 [02:47<00:02,  1.02s/it]avg_loss = 1.5877604166666666:  99%|█████████▉| 164/166 [02:48<00:02,  1.02s/it]avg_loss = 1.5877604166666666:  99%|█████████▉| 165/166 [02:48<00:01,  1.02s/it]avg_loss = 1.5896319653614457:  99%|█████████▉| 165/166 [02:49<00:01,  1.02s/it]avg_loss = 1.5896319653614457: 100%|██████████| 166/166 [02:49<00:00,  1.02s/it]avg_loss = 1.5896319653614457: 100%|██████████| 166/166 [02:49<00:00,  1.02s/it]
I0303 16:54:08.488562 3315859 eval_ppl.py:105] wikitext2 perplexity: 4.901944160461426
wikitext2 perplexity: 4.902
Running with lmbda=10000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  9.01it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00, 10.13it/s]Loading checkpoint shards:  36%|███▋      | 4/11 [00:00<00:00,  9.86it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00,  9.57it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00, 10.12it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00, 10.13it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.29it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.10it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:26,  1.50it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:01<00:25,  1.50it/s]calculating model weight mean & std:   8%|▊         | 3/40 [00:01<00:23,  1.56it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:02<00:22,  1.61it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:03<00:21,  1.64it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:03<00:20,  1.67it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:04<00:19,  1.68it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:04<00:18,  1.69it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:05<00:18,  1.70it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:06<00:17,  1.73it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:06<00:16,  1.75it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:07<00:15,  1.78it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:07<00:15,  1.78it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:08<00:14,  1.80it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:08<00:13,  1.81it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:09<00:13,  1.82it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:09<00:12,  1.82it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:10<00:12,  1.83it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:10<00:11,  1.84it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:11<00:10,  1.87it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:11<00:10,  1.87it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:12<00:09,  1.88it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:13<00:09,  1.73it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:13<00:09,  1.73it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:14<00:08,  1.77it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:14<00:07,  1.78it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:15<00:07,  1.68it/s]calculating model weight mean & std:  70%|███████   | 28/40 [00:16<00:07,  1.60it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:16<00:07,  1.55it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:17<00:06,  1.63it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:17<00:05,  1.69it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:18<00:05,  1.50it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:20<00:06,  1.11it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:21<00:06,  1.06s/it]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:22<00:05,  1.12s/it]calculating model weight mean & std:  90%|█████████ | 36/40 [00:23<00:04,  1.06s/it]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:24<00:02,  1.05it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:25<00:01,  1.13it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:25<00:00,  1.28it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:26<00:00,  1.41it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:26<00:00,  1.51it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 16:55:15 - INFO - layer0_self_attn.q_proj | mse: 0.09311410387509177, bpp_loss: 5.445936350598931, bpp: 0
2025-03-03 16:55:26 - INFO - layer0_self_attn.k_proj | mse: 0.042197993890731623, bpp_loss: 5.502923525571823, bpp: 0
2025-03-03 16:55:37 - INFO - layer0_self_attn.v_proj | mse: 0.006388924460499248, bpp_loss: 5.425233820974827, bpp: 0
2025-03-03 16:55:49 - INFO - layer0_self_attn.o_proj | mse: 0.004241842313870809, bpp_loss: 5.319746895506978, bpp: 0
2025-03-03 16:56:03 - INFO - layer0_mlp.gate_proj | mse: 0.001583251876126844, bpp_loss: 5.732325649261474, bpp: 0
2025-03-03 16:56:17 - INFO - layer0_mlp.up_proj | mse: 0.0015632227109415732, bpp_loss: 5.70601707663801, bpp: 0
2025-03-03 16:56:56 - INFO - layer0_mlp.down_proj | mse: 0.010507584215295943, bpp_loss: 5.813979090860596, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [01:52<1:13:24, 112.93s/it]2025-03-03 16:57:08 - INFO - layer1_self_attn.q_proj | mse: 0.003415081292455242, bpp_loss: 5.98700500190258, bpp: 0
2025-03-03 16:57:19 - INFO - layer1_self_attn.k_proj | mse: 0.0035303995783973557, bpp_loss: 6.02638819411397, bpp: 0
2025-03-03 16:57:31 - INFO - layer1_self_attn.v_proj | mse: 0.0023570215511057573, bpp_loss: 5.494200250580906, bpp: 0
2025-03-03 16:57:42 - INFO - layer1_self_attn.o_proj | mse: 0.007156385801677487, bpp_loss: 5.434654050394893, bpp: 0
2025-03-03 16:57:57 - INFO - layer1_mlp.gate_proj | mse: 0.0018738900537655485, bpp_loss: 5.9042368676927355, bpp: 0
2025-03-03 16:58:11 - INFO - layer1_mlp.up_proj | mse: 0.001831085756230588, bpp_loss: 5.841544723069227, bpp: 0
2025-03-03 16:58:50 - INFO - layer1_mlp.down_proj | mse: 0.0015643063336200234, bpp_loss: 5.8737339357535046, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [03:46<1:11:50, 113.44s/it]2025-03-03 16:59:02 - INFO - layer2_self_attn.q_proj | mse: 0.0018856876737835563, bpp_loss: 6.349178622663021, bpp: 0
2025-03-03 16:59:13 - INFO - layer2_self_attn.k_proj | mse: 0.0019318877386934076, bpp_loss: 6.408767648488283, bpp: 0
2025-03-03 16:59:24 - INFO - layer2_self_attn.v_proj | mse: 0.0014673342156826276, bpp_loss: 5.618943718522787, bpp: 0
2025-03-03 16:59:36 - INFO - layer2_self_attn.o_proj | mse: 0.0019567682355707125, bpp_loss: 5.60009556017816, bpp: 0
2025-03-03 16:59:50 - INFO - layer2_mlp.gate_proj | mse: 0.001586553388758225, bpp_loss: 5.966687958439191, bpp: 0
2025-03-03 17:00:05 - INFO - layer2_mlp.up_proj | mse: 0.0015399692875934423, bpp_loss: 5.871312749275455, bpp: 0
2025-03-03 17:00:43 - INFO - layer2_mlp.down_proj | mse: 0.0012336618436195816, bpp_loss: 5.887371403337629, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [05:39<1:09:52, 113.30s/it]2025-03-03 17:00:55 - INFO - layer3_self_attn.q_proj | mse: 0.0017175040391510315, bpp_loss: 6.408227558583021, bpp: 0
2025-03-03 17:01:06 - INFO - layer3_self_attn.k_proj | mse: 0.0017841224600909015, bpp_loss: 6.511790088713169, bpp: 0
2025-03-03 17:01:18 - INFO - layer3_self_attn.v_proj | mse: 0.0013207729479720164, bpp_loss: 5.660957599133253, bpp: 0
2025-03-03 17:01:29 - INFO - layer3_self_attn.o_proj | mse: 0.0015571392906502518, bpp_loss: 5.631199945658445, bpp: 0
2025-03-03 17:01:43 - INFO - layer3_mlp.gate_proj | mse: 0.0014495503142836334, bpp_loss: 5.987320996103463, bpp: 0
2025-03-03 17:01:58 - INFO - layer3_mlp.up_proj | mse: 0.00140248526113316, bpp_loss: 5.8864239838388235, bpp: 0
2025-03-03 17:02:36 - INFO - layer3_mlp.down_proj | mse: 0.0073100224499309694, bpp_loss: 5.890150979685562, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [07:32<1:07:55, 113.20s/it]2025-03-03 17:02:48 - INFO - layer4_self_attn.q_proj | mse: 0.0015678717904350201, bpp_loss: 6.342871050611138, bpp: 0
2025-03-03 17:02:59 - INFO - layer4_self_attn.k_proj | mse: 0.0015784159824527694, bpp_loss: 6.3619539719074965, bpp: 0
2025-03-03 17:03:11 - INFO - layer4_self_attn.v_proj | mse: 0.0012566737952506063, bpp_loss: 5.651942736878991, bpp: 0
2025-03-03 17:03:22 - INFO - layer4_self_attn.o_proj | mse: 0.0012214357917787323, bpp_loss: 5.633534136638045, bpp: 0
2025-03-03 17:03:37 - INFO - layer4_mlp.gate_proj | mse: 0.0013967764134243763, bpp_loss: 5.994243483190183, bpp: 0
2025-03-03 17:03:51 - INFO - layer4_mlp.up_proj | mse: 0.0013512331874654623, bpp_loss: 5.887940981542623, bpp: 0
2025-03-03 17:04:29 - INFO - layer4_mlp.down_proj | mse: 0.0011940621472771576, bpp_loss: 5.890571812733456, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [09:26<1:06:06, 113.34s/it]2025-03-03 17:04:41 - INFO - layer5_self_attn.q_proj | mse: 0.0015186679559073817, bpp_loss: 6.301232487633825, bpp: 0
2025-03-03 17:04:53 - INFO - layer5_self_attn.k_proj | mse: 0.0015108241552095388, bpp_loss: 6.288665428981185, bpp: 0
2025-03-03 17:05:04 - INFO - layer5_self_attn.v_proj | mse: 0.0012287899922823252, bpp_loss: 5.672728046551347, bpp: 0
2025-03-03 17:05:15 - INFO - layer5_self_attn.o_proj | mse: 0.0013401897384448982, bpp_loss: 5.648016911745072, bpp: 0
2025-03-03 17:05:30 - INFO - layer5_mlp.gate_proj | mse: 0.0013955897847878983, bpp_loss: 6.010077263249292, bpp: 0
2025-03-03 17:05:44 - INFO - layer5_mlp.up_proj | mse: 0.0013372678113526787, bpp_loss: 5.886287674528581, bpp: 0
2025-03-03 17:06:22 - INFO - layer5_mlp.down_proj | mse: 0.0011899037967515842, bpp_loss: 5.888027598791652, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [11:19<1:04:09, 113.22s/it]2025-03-03 17:06:34 - INFO - layer6_self_attn.q_proj | mse: 0.0014794783863706746, bpp_loss: 6.317453802600503, bpp: 0
2025-03-03 17:06:46 - INFO - layer6_self_attn.k_proj | mse: 0.0014997857277294286, bpp_loss: 6.345205986425281, bpp: 0
2025-03-03 17:06:57 - INFO - layer6_self_attn.v_proj | mse: 0.001210257726846771, bpp_loss: 5.6932438293099406, bpp: 0
2025-03-03 17:07:08 - INFO - layer6_self_attn.o_proj | mse: 0.0012375776494493195, bpp_loss: 5.677694057002664, bpp: 0
2025-03-03 17:07:23 - INFO - layer6_mlp.gate_proj | mse: 0.0013292594414692272, bpp_loss: 6.024851661810168, bpp: 0
2025-03-03 17:07:37 - INFO - layer6_mlp.up_proj | mse: 0.0012753049206543775, bpp_loss: 5.883503542343775, bpp: 0
2025-03-03 17:08:15 - INFO - layer6_mlp.down_proj | mse: 0.001187631399479197, bpp_loss: 5.882814802588136, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [13:12<1:02:10, 113.06s/it]2025-03-03 17:08:27 - INFO - layer7_self_attn.q_proj | mse: 0.0014725275700744624, bpp_loss: 6.346996974349022, bpp: 0
2025-03-03 17:08:38 - INFO - layer7_self_attn.k_proj | mse: 0.0014974720336517024, bpp_loss: 6.374304161220789, bpp: 0
2025-03-03 17:08:50 - INFO - layer7_self_attn.v_proj | mse: 0.0012056739102115643, bpp_loss: 5.710504251718521, bpp: 0
2025-03-03 17:09:01 - INFO - layer7_self_attn.o_proj | mse: 0.0012386084171955567, bpp_loss: 5.68978798866272, bpp: 0
2025-03-03 17:09:16 - INFO - layer7_mlp.gate_proj | mse: 0.001313519873567717, bpp_loss: 6.030787733528349, bpp: 0
2025-03-03 17:09:30 - INFO - layer7_mlp.up_proj | mse: 0.001258269795315775, bpp_loss: 5.884921189480358, bpp: 0
2025-03-03 17:10:08 - INFO - layer7_mlp.down_proj | mse: 0.0011925658998985086, bpp_loss: 5.88224173400689, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [15:05<1:00:20, 113.13s/it]2025-03-03 17:10:20 - INFO - layer8_self_attn.q_proj | mse: 0.0014527208376717224, bpp_loss: 6.304654925912619, bpp: 0
2025-03-03 17:10:32 - INFO - layer8_self_attn.k_proj | mse: 0.0014745869038145843, bpp_loss: 6.332152770385147, bpp: 0
2025-03-03 17:10:43 - INFO - layer8_self_attn.v_proj | mse: 0.0012015524615704542, bpp_loss: 5.717740687355399, bpp: 0
2025-03-03 17:10:54 - INFO - layer8_self_attn.o_proj | mse: 0.0012537708427142386, bpp_loss: 5.700568841472268, bpp: 0
2025-03-03 17:11:09 - INFO - layer8_mlp.gate_proj | mse: 0.0013063435343102336, bpp_loss: 6.02656572593583, bpp: 0
2025-03-03 17:11:23 - INFO - layer8_mlp.up_proj | mse: 0.0012555180769853666, bpp_loss: 5.896057249550466, bpp: 0
2025-03-03 17:12:01 - INFO - layer8_mlp.down_proj | mse: 0.0011936191358193407, bpp_loss: 5.891642679191298, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [16:58<58:23, 113.02s/it]  2025-03-03 17:12:13 - INFO - layer9_self_attn.q_proj | mse: 0.0014484165277036238, bpp_loss: 6.2971695010364055, bpp: 0
2025-03-03 17:12:24 - INFO - layer9_self_attn.k_proj | mse: 0.0014522688990308763, bpp_loss: 6.30481439344585, bpp: 0
2025-03-03 17:12:36 - INFO - layer9_self_attn.v_proj | mse: 0.0011953062060271508, bpp_loss: 5.714006451144814, bpp: 0
2025-03-03 17:12:47 - INFO - layer9_self_attn.o_proj | mse: 0.0012567058944822765, bpp_loss: 5.702590708360076, bpp: 0
2025-03-03 17:13:01 - INFO - layer9_mlp.gate_proj | mse: 0.001292175579813329, bpp_loss: 6.012793678266031, bpp: 0
2025-03-03 17:13:16 - INFO - layer9_mlp.up_proj | mse: 0.001253201902180818, bpp_loss: 5.909324962783743, bpp: 0
2025-03-03 17:13:54 - INFO - layer9_mlp.down_proj | mse: 0.0011923322480503827, bpp_loss: 5.902767407535403, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [18:50<56:24, 112.81s/it]2025-03-03 17:14:05 - INFO - layer10_self_attn.q_proj | mse: 0.001425742186683864, bpp_loss: 6.28902676589787, bpp: 0
2025-03-03 17:14:16 - INFO - layer10_self_attn.k_proj | mse: 0.0014523890683566603, bpp_loss: 6.314793473407626, bpp: 0
2025-03-03 17:14:28 - INFO - layer10_self_attn.v_proj | mse: 0.001187163430536133, bpp_loss: 5.70712523072958, bpp: 0
2025-03-03 17:14:39 - INFO - layer10_self_attn.o_proj | mse: 0.0012165956448169741, bpp_loss: 5.701035030335188, bpp: 0
2025-03-03 17:14:53 - INFO - layer10_mlp.gate_proj | mse: 0.001282764783811332, bpp_loss: 5.997250703418696, bpp: 0
2025-03-03 17:15:08 - INFO - layer10_mlp.up_proj | mse: 0.0012527260146547306, bpp_loss: 5.918195115857654, bpp: 0
2025-03-03 17:15:45 - INFO - layer10_mlp.down_proj | mse: 0.0011993341638856063, bpp_loss: 5.910718320586064, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [20:42<54:23, 112.52s/it]2025-03-03 17:15:57 - INFO - layer11_self_attn.q_proj | mse: 0.0014492003515412346, bpp_loss: 6.342231247797608, bpp: 0
2025-03-03 17:16:08 - INFO - layer11_self_attn.k_proj | mse: 0.0014835546411477, bpp_loss: 6.37904814735055, bpp: 0
2025-03-03 17:16:20 - INFO - layer11_self_attn.v_proj | mse: 0.0011899160845039937, bpp_loss: 5.717084731832147, bpp: 0
2025-03-03 17:16:31 - INFO - layer11_self_attn.o_proj | mse: 0.0012760437695155647, bpp_loss: 5.702321367189288, bpp: 0
2025-03-03 17:16:46 - INFO - layer11_mlp.gate_proj | mse: 0.0012708057920843292, bpp_loss: 5.984028770415871, bpp: 0
2025-03-03 17:17:00 - INFO - layer11_mlp.up_proj | mse: 0.0012497969543999177, bpp_loss: 5.9284484851139565, bpp: 0
2025-03-03 17:17:38 - INFO - layer11_mlp.down_proj | mse: 0.0012048662705380745, bpp_loss: 5.9190331885108245, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [22:34<52:30, 112.51s/it]2025-03-03 17:17:49 - INFO - layer12_self_attn.q_proj | mse: 0.00142463238761633, bpp_loss: 6.279241301044822, bpp: 0
2025-03-03 17:18:01 - INFO - layer12_self_attn.k_proj | mse: 0.0014517134780294468, bpp_loss: 6.305667529180646, bpp: 0
2025-03-03 17:18:12 - INFO - layer12_self_attn.v_proj | mse: 0.0011962947928335758, bpp_loss: 5.739945505037904, bpp: 0
2025-03-03 17:18:24 - INFO - layer12_self_attn.o_proj | mse: 0.0013165213641786828, bpp_loss: 5.725043523907662, bpp: 0
2025-03-03 17:18:38 - INFO - layer12_mlp.gate_proj | mse: 0.00126973882203576, bpp_loss: 5.978832000935519, bpp: 0
2025-03-03 17:18:52 - INFO - layer12_mlp.up_proj | mse: 0.0012535055980804025, bpp_loss: 5.93776540502354, bpp: 0
2025-03-03 17:19:30 - INFO - layer12_mlp.down_proj | mse: 0.0012040828243889763, bpp_loss: 5.9275135424126075, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [24:27<50:34, 112.40s/it]2025-03-03 17:19:42 - INFO - layer13_self_attn.q_proj | mse: 0.001398508827713293, bpp_loss: 6.22929474927485, bpp: 0
2025-03-03 17:19:53 - INFO - layer13_self_attn.k_proj | mse: 0.0014139057977984035, bpp_loss: 6.222041864395141, bpp: 0
2025-03-03 17:20:04 - INFO - layer13_self_attn.v_proj | mse: 0.0012017543274966988, bpp_loss: 5.758630490973592, bpp: 0
2025-03-03 17:20:15 - INFO - layer13_self_attn.o_proj | mse: 0.0012597563644262846, bpp_loss: 5.751326165944338, bpp: 0
2025-03-03 17:20:30 - INFO - layer13_mlp.gate_proj | mse: 0.0012691373530791773, bpp_loss: 5.974000533752971, bpp: 0
2025-03-03 17:20:44 - INFO - layer13_mlp.up_proj | mse: 0.0012579739965396393, bpp_loss: 5.945118187202348, bpp: 0
2025-03-03 17:21:22 - INFO - layer13_mlp.down_proj | mse: 0.0012063535907336945, bpp_loss: 5.9339891375766864, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [26:18<48:35, 112.15s/it]2025-03-03 17:21:33 - INFO - layer14_self_attn.q_proj | mse: 0.0014108403791147368, bpp_loss: 6.265110463201999, bpp: 0
2025-03-03 17:21:44 - INFO - layer14_self_attn.k_proj | mse: 0.001438499139816217, bpp_loss: 6.2925505391508345, bpp: 0
2025-03-03 17:21:56 - INFO - layer14_self_attn.v_proj | mse: 0.0011996958049284964, bpp_loss: 5.747724296376109, bpp: 0
2025-03-03 17:22:07 - INFO - layer14_self_attn.o_proj | mse: 0.0012317863454711345, bpp_loss: 5.735402878969908, bpp: 0
2025-03-03 17:22:21 - INFO - layer14_mlp.gate_proj | mse: 0.0012648693012083045, bpp_loss: 5.970173485742675, bpp: 0
2025-03-03 17:22:36 - INFO - layer14_mlp.up_proj | mse: 0.0012584426736486649, bpp_loss: 5.951714913933365, bpp: 0
2025-03-03 17:23:14 - INFO - layer14_mlp.down_proj | mse: 0.001205777529913425, bpp_loss: 5.938874557669516, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [28:10<46:43, 112.14s/it]2025-03-03 17:23:25 - INFO - layer15_self_attn.q_proj | mse: 0.001396795748501081, bpp_loss: 6.24111690968275, bpp: 0
2025-03-03 17:23:37 - INFO - layer15_self_attn.k_proj | mse: 0.001429691319232939, bpp_loss: 6.285754779949785, bpp: 0
2025-03-03 17:23:48 - INFO - layer15_self_attn.v_proj | mse: 0.0012089099067617247, bpp_loss: 5.782615736946464, bpp: 0
2025-03-03 17:23:59 - INFO - layer15_self_attn.o_proj | mse: 0.0013585604647867757, bpp_loss: 5.77279485233128, bpp: 0
2025-03-03 17:24:14 - INFO - layer15_mlp.gate_proj | mse: 0.0012653903396793273, bpp_loss: 5.972270084531219, bpp: 0
2025-03-03 17:24:28 - INFO - layer15_mlp.up_proj | mse: 0.001262117411201299, bpp_loss: 5.958847203188473, bpp: 0
2025-03-03 17:25:06 - INFO - layer15_mlp.down_proj | mse: 0.0012093657424613162, bpp_loss: 5.946342781296483, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [30:02<44:51, 112.14s/it]2025-03-03 17:25:18 - INFO - layer16_self_attn.q_proj | mse: 0.0013933763112154182, bpp_loss: 6.228096620291471, bpp: 0
2025-03-03 17:25:29 - INFO - layer16_self_attn.k_proj | mse: 0.0014216928164618836, bpp_loss: 6.258431903645397, bpp: 0
2025-03-03 17:25:40 - INFO - layer16_self_attn.v_proj | mse: 0.0012139318721151465, bpp_loss: 5.787775885388255, bpp: 0
2025-03-03 17:25:52 - INFO - layer16_self_attn.o_proj | mse: 0.0012551303668512656, bpp_loss: 5.7768138568848375, bpp: 0
2025-03-03 17:26:06 - INFO - layer16_mlp.gate_proj | mse: 0.0012662948178291079, bpp_loss: 5.975972000868232, bpp: 0
2025-03-03 17:26:20 - INFO - layer16_mlp.up_proj | mse: 0.0012615269295469058, bpp_loss: 5.958321914076805, bpp: 0
2025-03-03 17:26:58 - INFO - layer16_mlp.down_proj | mse: 0.0012130437418692878, bpp_loss: 5.945102189398474, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [31:55<42:59, 112.17s/it]2025-03-03 17:27:10 - INFO - layer17_self_attn.q_proj | mse: 0.0013870768659705384, bpp_loss: 6.215048759132624, bpp: 0
2025-03-03 17:27:21 - INFO - layer17_self_attn.k_proj | mse: 0.0014146578700494523, bpp_loss: 6.248148798719049, bpp: 0
2025-03-03 17:27:32 - INFO - layer17_self_attn.v_proj | mse: 0.001217511805559161, bpp_loss: 5.797959450781345, bpp: 0
2025-03-03 17:27:44 - INFO - layer17_self_attn.o_proj | mse: 0.0012413425300909725, bpp_loss: 5.790120149254799, bpp: 0
2025-03-03 17:27:58 - INFO - layer17_mlp.gate_proj | mse: 0.00126668272109938, bpp_loss: 5.986437568951536, bpp: 0
2025-03-03 17:28:12 - INFO - layer17_mlp.up_proj | mse: 0.001255807008697634, bpp_loss: 5.952759777726951, bpp: 0
2025-03-03 17:28:50 - INFO - layer17_mlp.down_proj | mse: 0.0012036931185144388, bpp_loss: 5.942193400639074, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [33:47<41:07, 112.17s/it]2025-03-03 17:29:02 - INFO - layer18_self_attn.q_proj | mse: 0.001382505564559232, bpp_loss: 6.2239706175029275, bpp: 0
2025-03-03 17:29:13 - INFO - layer18_self_attn.k_proj | mse: 0.001406347181971105, bpp_loss: 6.257601167336106, bpp: 0
2025-03-03 17:29:25 - INFO - layer18_self_attn.v_proj | mse: 0.001218952446888135, bpp_loss: 5.831738602891565, bpp: 0
2025-03-03 17:29:36 - INFO - layer18_self_attn.o_proj | mse: 0.0012528320850400095, bpp_loss: 5.817170227840543, bpp: 0
2025-03-03 17:29:50 - INFO - layer18_mlp.gate_proj | mse: 0.0012697220835675806, bpp_loss: 5.995224799160604, bpp: 0
2025-03-03 17:30:04 - INFO - layer18_mlp.up_proj | mse: 0.0012515805884014638, bpp_loss: 5.946936328653936, bpp: 0
2025-03-03 17:30:42 - INFO - layer18_mlp.down_proj | mse: 0.0011947828456301574, bpp_loss: 5.938356285514655, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [35:39<39:15, 112.16s/it]2025-03-03 17:30:54 - INFO - layer19_self_attn.q_proj | mse: 0.001361679073172019, bpp_loss: 6.177431559041143, bpp: 0
2025-03-03 17:31:05 - INFO - layer19_self_attn.k_proj | mse: 0.0013818682151939363, bpp_loss: 6.201787494942546, bpp: 0
2025-03-03 17:31:17 - INFO - layer19_self_attn.v_proj | mse: 0.0012210137506172038, bpp_loss: 5.829722515046597, bpp: 0
2025-03-03 17:31:28 - INFO - layer19_self_attn.o_proj | mse: 0.0012136479619433331, bpp_loss: 5.817555298730731, bpp: 0
2025-03-03 17:31:42 - INFO - layer19_mlp.gate_proj | mse: 0.0012733230860219266, bpp_loss: 6.003043951259719, bpp: 0
2025-03-03 17:31:56 - INFO - layer19_mlp.up_proj | mse: 0.0012506544790004974, bpp_loss: 5.945070309771432, bpp: 0
2025-03-03 17:32:34 - INFO - layer19_mlp.down_proj | mse: 0.0011946070487951236, bpp_loss: 5.937202348394527, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [37:31<37:22, 112.14s/it]2025-03-03 17:32:46 - INFO - layer20_self_attn.q_proj | mse: 0.0013740712307040172, bpp_loss: 6.20087729357183, bpp: 0
2025-03-03 17:32:57 - INFO - layer20_self_attn.k_proj | mse: 0.0013982947942082565, bpp_loss: 6.2305300528556105, bpp: 0
2025-03-03 17:33:09 - INFO - layer20_self_attn.v_proj | mse: 0.0012201114956793507, bpp_loss: 5.826942602172494, bpp: 0
2025-03-03 17:33:20 - INFO - layer20_self_attn.o_proj | mse: 0.0012509589731962568, bpp_loss: 5.82060253277421, bpp: 0
2025-03-03 17:33:34 - INFO - layer20_mlp.gate_proj | mse: 0.001276063387858654, bpp_loss: 6.00634574106446, bpp: 0
2025-03-03 17:33:49 - INFO - layer20_mlp.up_proj | mse: 0.001253215207117063, bpp_loss: 5.9442024521253725, bpp: 0
2025-03-03 17:34:26 - INFO - layer20_mlp.down_proj | mse: 0.0011916104337995044, bpp_loss: 5.936861181424724, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [39:23<35:29, 112.08s/it]2025-03-03 17:34:38 - INFO - layer21_self_attn.q_proj | mse: 0.0013671430113398474, bpp_loss: 6.166839893013239, bpp: 0
2025-03-03 17:34:50 - INFO - layer21_self_attn.k_proj | mse: 0.001383345475140989, bpp_loss: 6.187251435592771, bpp: 0
2025-03-03 17:35:01 - INFO - layer21_self_attn.v_proj | mse: 0.001234872506979599, bpp_loss: 5.856877727657556, bpp: 0
2025-03-03 17:35:12 - INFO - layer21_self_attn.o_proj | mse: 0.0012285861563671335, bpp_loss: 5.849581059515476, bpp: 0
2025-03-03 17:35:27 - INFO - layer21_mlp.gate_proj | mse: 0.0012930110439712311, bpp_loss: 6.014462302349232, bpp: 0
2025-03-03 17:35:41 - INFO - layer21_mlp.up_proj | mse: 0.001263484300264325, bpp_loss: 5.93742503049197, bpp: 0
2025-03-03 17:36:19 - INFO - layer21_mlp.down_proj | mse: 0.0011932782719365678, bpp_loss: 5.933549019777113, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [41:15<33:37, 112.10s/it]2025-03-03 17:36:30 - INFO - layer22_self_attn.q_proj | mse: 0.0013570352298147717, bpp_loss: 6.155667700469494, bpp: 0
2025-03-03 17:36:42 - INFO - layer22_self_attn.k_proj | mse: 0.0013707083436893116, bpp_loss: 6.184530880302191, bpp: 0
2025-03-03 17:36:53 - INFO - layer22_self_attn.v_proj | mse: 0.0012592069692733997, bpp_loss: 5.916513997837901, bpp: 0
2025-03-03 17:37:04 - INFO - layer22_self_attn.o_proj | mse: 0.0012216691775281336, bpp_loss: 5.901755707636475, bpp: 0
2025-03-03 17:37:19 - INFO - layer22_mlp.gate_proj | mse: 0.0012907163287412715, bpp_loss: 6.023329742639153, bpp: 0
2025-03-03 17:37:33 - INFO - layer22_mlp.up_proj | mse: 0.0012551663974770006, bpp_loss: 5.932843054886217, bpp: 0
2025-03-03 17:38:11 - INFO - layer22_mlp.down_proj | mse: 0.0011820159438390248, bpp_loss: 5.93144033352534, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [43:07<31:46, 112.15s/it]2025-03-03 17:38:23 - INFO - layer23_self_attn.q_proj | mse: 0.0013405026190424069, bpp_loss: 6.129236689209938, bpp: 0
2025-03-03 17:38:34 - INFO - layer23_self_attn.k_proj | mse: 0.001355470131537011, bpp_loss: 6.146330410987138, bpp: 0
2025-03-03 17:38:46 - INFO - layer23_self_attn.v_proj | mse: 0.0012544945239481061, bpp_loss: 5.90988138705492, bpp: 0
2025-03-03 17:38:57 - INFO - layer23_self_attn.o_proj | mse: 0.001183979117225413, bpp_loss: 5.9012980007380245, bpp: 0
2025-03-03 17:39:11 - INFO - layer23_mlp.gate_proj | mse: 0.0012939429045381874, bpp_loss: 6.031328198424092, bpp: 0
2025-03-03 17:39:26 - INFO - layer23_mlp.up_proj | mse: 0.0012510860739646328, bpp_loss: 5.92879671951135, bpp: 0
2025-03-03 17:40:03 - INFO - layer23_mlp.down_proj | mse: 0.0011750580630508582, bpp_loss: 5.92890923599954, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [45:00<29:56, 112.28s/it]2025-03-03 17:40:15 - INFO - layer24_self_attn.q_proj | mse: 0.0013405482764333027, bpp_loss: 6.142125666439533, bpp: 0
2025-03-03 17:40:27 - INFO - layer24_self_attn.k_proj | mse: 0.001351088180828049, bpp_loss: 6.160540570616722, bpp: 0
2025-03-03 17:40:38 - INFO - layer24_self_attn.v_proj | mse: 0.0012517307453367784, bpp_loss: 5.919409389942884, bpp: 0
2025-03-03 17:40:49 - INFO - layer24_self_attn.o_proj | mse: 0.001186524227063593, bpp_loss: 5.907666776329279, bpp: 0
2025-03-03 17:41:04 - INFO - layer24_mlp.gate_proj | mse: 0.001292640995067017, bpp_loss: 6.036134005917443, bpp: 0
2025-03-03 17:41:18 - INFO - layer24_mlp.up_proj | mse: 0.0012480388143729835, bpp_loss: 5.9275915271706054, bpp: 0
2025-03-03 17:41:56 - INFO - layer24_mlp.down_proj | mse: 0.0011677205194690612, bpp_loss: 5.929118856318571, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [46:53<28:06, 112.43s/it]2025-03-03 17:42:08 - INFO - layer25_self_attn.q_proj | mse: 0.0013352443708970147, bpp_loss: 6.132419995069504, bpp: 0
2025-03-03 17:42:19 - INFO - layer25_self_attn.k_proj | mse: 0.001342775638642457, bpp_loss: 6.146632345616817, bpp: 0
2025-03-03 17:42:31 - INFO - layer25_self_attn.v_proj | mse: 0.00125740106881726, bpp_loss: 5.946567569449544, bpp: 0
2025-03-03 17:42:42 - INFO - layer25_self_attn.o_proj | mse: 0.001181198419885479, bpp_loss: 5.939193811044097, bpp: 0
2025-03-03 17:42:57 - INFO - layer25_mlp.gate_proj | mse: 0.0012931123331632916, bpp_loss: 6.04069725451646, bpp: 0
2025-03-03 17:43:11 - INFO - layer25_mlp.up_proj | mse: 0.0012444333483271229, bpp_loss: 5.926548500083111, bpp: 0
2025-03-03 17:43:50 - INFO - layer25_mlp.down_proj | mse: 0.0011628451616373173, bpp_loss: 5.928526218677009, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [48:46<26:18, 112.76s/it]2025-03-03 17:44:02 - INFO - layer26_self_attn.q_proj | mse: 0.001346568099129372, bpp_loss: 6.142687963619828, bpp: 0
2025-03-03 17:44:13 - INFO - layer26_self_attn.k_proj | mse: 0.001358948204964281, bpp_loss: 6.158144983500242, bpp: 0
2025-03-03 17:44:24 - INFO - layer26_self_attn.v_proj | mse: 0.0012729462516002277, bpp_loss: 5.9678205322474245, bpp: 0
2025-03-03 17:44:36 - INFO - layer26_self_attn.o_proj | mse: 0.0012073546584287006, bpp_loss: 5.938246996998787, bpp: 0
2025-03-03 17:44:50 - INFO - layer26_mlp.gate_proj | mse: 0.0012966342785448515, bpp_loss: 6.043982027967771, bpp: 0
2025-03-03 17:45:05 - INFO - layer26_mlp.up_proj | mse: 0.00124427368909218, bpp_loss: 5.927738616974265, bpp: 0
2025-03-03 17:45:43 - INFO - layer26_mlp.down_proj | mse: 0.0011615540677917399, bpp_loss: 5.929797571428396, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [50:39<24:27, 112.86s/it]2025-03-03 17:45:55 - INFO - layer27_self_attn.q_proj | mse: 0.0013267138552284915, bpp_loss: 6.144485115334391, bpp: 0
2025-03-03 17:46:06 - INFO - layer27_self_attn.k_proj | mse: 0.001335120956883553, bpp_loss: 6.156295782253146, bpp: 0
2025-03-03 17:46:17 - INFO - layer27_self_attn.v_proj | mse: 0.0012557674844531558, bpp_loss: 5.960747542828321, bpp: 0
2025-03-03 17:46:29 - INFO - layer27_self_attn.o_proj | mse: 0.0011936719263728299, bpp_loss: 5.944963322430849, bpp: 0
2025-03-03 17:46:43 - INFO - layer27_mlp.gate_proj | mse: 0.0012922783282564615, bpp_loss: 6.04829293831631, bpp: 0
2025-03-03 17:46:57 - INFO - layer27_mlp.up_proj | mse: 0.0012410815344529053, bpp_loss: 5.928577949713778, bpp: 0
2025-03-03 17:47:35 - INFO - layer27_mlp.down_proj | mse: 0.0011572727109846216, bpp_loss: 5.930766207255699, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [52:32<22:33, 112.78s/it]2025-03-03 17:47:47 - INFO - layer28_self_attn.q_proj | mse: 0.0013197301285286897, bpp_loss: 6.1382019273191695, bpp: 0
2025-03-03 17:47:59 - INFO - layer28_self_attn.k_proj | mse: 0.0013273586210227654, bpp_loss: 6.148826206251979, bpp: 0
2025-03-03 17:48:10 - INFO - layer28_self_attn.v_proj | mse: 0.0012494432405238808, bpp_loss: 5.968383022919297, bpp: 0
2025-03-03 17:48:21 - INFO - layer28_self_attn.o_proj | mse: 0.0012190977625434222, bpp_loss: 5.950785765349865, bpp: 0
2025-03-03 17:48:36 - INFO - layer28_mlp.gate_proj | mse: 0.0012858834608672138, bpp_loss: 6.050168000547974, bpp: 0
2025-03-03 17:48:50 - INFO - layer28_mlp.up_proj | mse: 0.0012343163606445484, bpp_loss: 5.931615344021055, bpp: 0
2025-03-03 17:49:28 - INFO - layer28_mlp.down_proj | mse: 0.0011522619861563696, bpp_loss: 5.93335666352952, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [54:25<20:40, 112.80s/it]2025-03-03 17:49:40 - INFO - layer29_self_attn.q_proj | mse: 0.0013191866433426467, bpp_loss: 6.160592336505651, bpp: 0
2025-03-03 17:49:51 - INFO - layer29_self_attn.k_proj | mse: 0.0013280211167175644, bpp_loss: 6.179377419352531, bpp: 0
2025-03-03 17:50:03 - INFO - layer29_self_attn.v_proj | mse: 0.0012437461483700567, bpp_loss: 5.97276571393013, bpp: 0
2025-03-03 17:50:14 - INFO - layer29_self_attn.o_proj | mse: 0.0011920064745404608, bpp_loss: 5.959720577150583, bpp: 0
2025-03-03 17:50:29 - INFO - layer29_mlp.gate_proj | mse: 0.001288602732320844, bpp_loss: 6.0489094686728935, bpp: 0
2025-03-03 17:50:43 - INFO - layer29_mlp.up_proj | mse: 0.0012367709067860474, bpp_loss: 5.935622576430992, bpp: 0
2025-03-03 17:51:21 - INFO - layer29_mlp.down_proj | mse: 0.0011504866784697641, bpp_loss: 5.9372106953627535, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [56:17<18:47, 112.75s/it]2025-03-03 17:51:33 - INFO - layer30_self_attn.q_proj | mse: 0.0013050796683728946, bpp_loss: 6.1374822127074005, bpp: 0
2025-03-03 17:51:44 - INFO - layer30_self_attn.k_proj | mse: 0.0013108712041144852, bpp_loss: 6.145967592000961, bpp: 0
2025-03-03 17:51:55 - INFO - layer30_self_attn.v_proj | mse: 0.0012629864510096032, bpp_loss: 6.02438632696867, bpp: 0
2025-03-03 17:52:06 - INFO - layer30_self_attn.o_proj | mse: 0.0011961288502351935, bpp_loss: 6.015360124632716, bpp: 0
2025-03-03 17:52:21 - INFO - layer30_mlp.gate_proj | mse: 0.0012755337655577955, bpp_loss: 6.051979659552927, bpp: 0
2025-03-03 17:52:35 - INFO - layer30_mlp.up_proj | mse: 0.001226570570115769, bpp_loss: 5.938102796894532, bpp: 0
2025-03-03 17:53:13 - INFO - layer30_mlp.down_proj | mse: 0.001149278504420399, bpp_loss: 5.938891986481569, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [58:10<16:52, 112.53s/it]2025-03-03 17:53:25 - INFO - layer31_self_attn.q_proj | mse: 0.0013103997973475722, bpp_loss: 6.1539171151816845, bpp: 0
2025-03-03 17:53:36 - INFO - layer31_self_attn.k_proj | mse: 0.0013206379457882764, bpp_loss: 6.18018438577652, bpp: 0
2025-03-03 17:53:47 - INFO - layer31_self_attn.v_proj | mse: 0.0012437584318305515, bpp_loss: 5.987788992226124, bpp: 0
2025-03-03 17:53:59 - INFO - layer31_self_attn.o_proj | mse: 0.001207812738799794, bpp_loss: 5.973988357186317, bpp: 0
2025-03-03 17:54:13 - INFO - layer31_mlp.gate_proj | mse: 0.001272953380470906, bpp_loss: 6.0533075704618735, bpp: 0
2025-03-03 17:54:27 - INFO - layer31_mlp.up_proj | mse: 0.0012233609044636294, bpp_loss: 5.941182549021862, bpp: 0
2025-03-03 17:55:05 - INFO - layer31_mlp.down_proj | mse: 0.0011477045733817373, bpp_loss: 5.941844373085985, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [1:00:02<14:59, 112.47s/it]2025-03-03 17:55:17 - INFO - layer32_self_attn.q_proj | mse: 0.001290721693634919, bpp_loss: 6.11716910071671, bpp: 0
2025-03-03 17:55:28 - INFO - layer32_self_attn.k_proj | mse: 0.0012968890337386283, bpp_loss: 6.1261514758318665, bpp: 0
2025-03-03 17:55:39 - INFO - layer32_self_attn.v_proj | mse: 0.0012596596032044623, bpp_loss: 6.02800326064229, bpp: 0
2025-03-03 17:55:51 - INFO - layer32_self_attn.o_proj | mse: 0.001237098942135131, bpp_loss: 6.019758985862136, bpp: 0
2025-03-03 17:56:05 - INFO - layer32_mlp.gate_proj | mse: 0.0012643662887799362, bpp_loss: 6.0506091391598735, bpp: 0
2025-03-03 17:56:19 - INFO - layer32_mlp.up_proj | mse: 0.001219726339234626, bpp_loss: 5.9468072839357236, bpp: 0
2025-03-03 17:56:58 - INFO - layer32_mlp.down_proj | mse: 0.0011491493177813727, bpp_loss: 5.946839318065732, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:01:54<13:06, 112.42s/it]2025-03-03 17:57:09 - INFO - layer33_self_attn.q_proj | mse: 0.0012882317434872628, bpp_loss: 6.118849775120616, bpp: 0
2025-03-03 17:57:21 - INFO - layer33_self_attn.k_proj | mse: 0.0012961040510839896, bpp_loss: 6.137171291857958, bpp: 0
2025-03-03 17:57:32 - INFO - layer33_self_attn.v_proj | mse: 0.0012451420593617571, bpp_loss: 6.005272709876299, bpp: 0
2025-03-03 17:57:44 - INFO - layer33_self_attn.o_proj | mse: 0.0012068153449839576, bpp_loss: 5.996105095744133, bpp: 0
2025-03-03 17:57:58 - INFO - layer33_mlp.gate_proj | mse: 0.001262255696699951, bpp_loss: 6.0493585490518145, bpp: 0
2025-03-03 17:58:13 - INFO - layer33_mlp.up_proj | mse: 0.0012223089561172727, bpp_loss: 5.952260992924372, bpp: 0
2025-03-03 17:58:51 - INFO - layer33_mlp.down_proj | mse: 0.0011534854394228422, bpp_loss: 5.952301225148969, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:03:48<11:16, 112.71s/it]2025-03-03 17:59:03 - INFO - layer34_self_attn.q_proj | mse: 0.0012712834650470224, bpp_loss: 6.079463613778353, bpp: 0
2025-03-03 17:59:14 - INFO - layer34_self_attn.k_proj | mse: 0.0012785622265621048, bpp_loss: 6.094350031837821, bpp: 0
2025-03-03 17:59:26 - INFO - layer34_self_attn.v_proj | mse: 0.0012575987630022046, bpp_loss: 6.033378802463412, bpp: 0
2025-03-03 17:59:37 - INFO - layer34_self_attn.o_proj | mse: 0.0012248538384839619, bpp_loss: 6.030938213691115, bpp: 0
2025-03-03 17:59:52 - INFO - layer34_mlp.gate_proj | mse: 0.0012579111629052425, bpp_loss: 6.043486557845716, bpp: 0
2025-03-03 18:00:06 - INFO - layer34_mlp.up_proj | mse: 0.0012243806634481024, bpp_loss: 5.9612531825348185, bpp: 0
2025-03-03 18:00:44 - INFO - layer34_mlp.down_proj | mse: 0.0011593494827750544, bpp_loss: 5.961339803095217, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:05:41<09:24, 112.96s/it]2025-03-03 18:00:56 - INFO - layer35_self_attn.q_proj | mse: 0.0012654365378515025, bpp_loss: 6.069714858457446, bpp: 0
2025-03-03 18:01:08 - INFO - layer35_self_attn.k_proj | mse: 0.0012729392986980607, bpp_loss: 6.086811359003186, bpp: 0
2025-03-03 18:01:19 - INFO - layer35_self_attn.v_proj | mse: 0.001255957878090825, bpp_loss: 6.034769656285643, bpp: 0
2025-03-03 18:01:31 - INFO - layer35_self_attn.o_proj | mse: 0.001243487268646044, bpp_loss: 6.029422827139497, bpp: 0
2025-03-03 18:01:45 - INFO - layer35_mlp.gate_proj | mse: 0.0012557145608503041, bpp_loss: 6.037153224812614, bpp: 0
2025-03-03 18:01:59 - INFO - layer35_mlp.up_proj | mse: 0.0012272334134556765, bpp_loss: 5.971206007953043, bpp: 0
2025-03-03 18:02:38 - INFO - layer35_mlp.down_proj | mse: 0.0011664667652832687, bpp_loss: 5.970922147924149, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:07:34<07:31, 113.00s/it]2025-03-03 18:02:49 - INFO - layer36_self_attn.q_proj | mse: 0.0012634234409107904, bpp_loss: 6.069777964577079, bpp: 0
2025-03-03 18:03:01 - INFO - layer36_self_attn.k_proj | mse: 0.0012750940030795712, bpp_loss: 6.092935310080647, bpp: 0
2025-03-03 18:03:12 - INFO - layer36_self_attn.v_proj | mse: 0.001268669405595688, bpp_loss: 6.060694296956062, bpp: 0
2025-03-03 18:03:23 - INFO - layer36_self_attn.o_proj | mse: 0.0012851312126476535, bpp_loss: 6.056349696442485, bpp: 0
2025-03-03 18:03:38 - INFO - layer36_mlp.gate_proj | mse: 0.001252809964510523, bpp_loss: 6.03339587924657, bpp: 0
2025-03-03 18:03:52 - INFO - layer36_mlp.up_proj | mse: 0.001230275608587723, bpp_loss: 5.977176196817998, bpp: 0
2025-03-03 18:04:30 - INFO - layer36_mlp.down_proj | mse: 0.0011762916452365368, bpp_loss: 5.973169077877645, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:09:26<05:38, 112.78s/it]2025-03-03 18:04:42 - INFO - layer37_self_attn.q_proj | mse: 0.0012454391800476878, bpp_loss: 6.003541036620736, bpp: 0
2025-03-03 18:04:53 - INFO - layer37_self_attn.k_proj | mse: 0.001247799342688229, bpp_loss: 6.002201995998621, bpp: 0
2025-03-03 18:05:04 - INFO - layer37_self_attn.v_proj | mse: 0.001284598388578266, bpp_loss: 6.08502302274108, bpp: 0
2025-03-03 18:05:15 - INFO - layer37_self_attn.o_proj | mse: 0.0013411754282087538, bpp_loss: 6.079118885025382, bpp: 0
2025-03-03 18:05:30 - INFO - layer37_mlp.gate_proj | mse: 0.00125714883297754, bpp_loss: 6.037968237753268, bpp: 0
2025-03-03 18:05:44 - INFO - layer37_mlp.up_proj | mse: 0.0012350942273042533, bpp_loss: 5.9853641342233725, bpp: 0
2025-03-03 18:06:22 - INFO - layer37_mlp.down_proj | mse: 0.0011892671340926753, bpp_loss: 5.975064436898188, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:11:18<03:45, 112.53s/it]2025-03-03 18:06:34 - INFO - layer38_self_attn.q_proj | mse: 0.001236171193222666, bpp_loss: 5.9759611994773145, bpp: 0
2025-03-03 18:06:45 - INFO - layer38_self_attn.k_proj | mse: 0.001241546134242759, bpp_loss: 5.98389631934464, bpp: 0
2025-03-03 18:06:56 - INFO - layer38_self_attn.v_proj | mse: 0.0013152785329163562, bpp_loss: 6.144570587053895, bpp: 0
2025-03-03 18:07:07 - INFO - layer38_self_attn.o_proj | mse: 0.0013843135508860218, bpp_loss: 6.146183557510376, bpp: 0
2025-03-03 18:07:21 - INFO - layer38_mlp.gate_proj | mse: 0.001281631374919835, bpp_loss: 6.076165220582927, bpp: 0
2025-03-03 18:07:36 - INFO - layer38_mlp.up_proj | mse: 0.0012449093216915087, bpp_loss: 5.99047912646223, bpp: 0
2025-03-03 18:08:13 - INFO - layer38_mlp.down_proj | mse: 0.001228122698226648, bpp_loss: 5.961262462702062, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:13:10<01:52, 112.24s/it]2025-03-03 18:08:25 - INFO - layer39_self_attn.q_proj | mse: 0.0012513857655075994, bpp_loss: 5.969524540230632, bpp: 0
2025-03-03 18:08:36 - INFO - layer39_self_attn.k_proj | mse: 0.0012609081126702254, bpp_loss: 5.9829968009889125, bpp: 0
2025-03-03 18:08:48 - INFO - layer39_self_attn.v_proj | mse: 0.001286297214341036, bpp_loss: 6.024988574832678, bpp: 0
2025-03-03 18:08:59 - INFO - layer39_self_attn.o_proj | mse: 0.0022810877477244286, bpp_loss: 6.029583100527525, bpp: 0
2025-03-03 18:09:13 - INFO - layer39_mlp.gate_proj | mse: 0.0013343572063320127, bpp_loss: 6.1565232737196816, bpp: 0
2025-03-03 18:09:27 - INFO - layer39_mlp.up_proj | mse: 0.001282335506481252, bpp_loss: 6.036092210257495, bpp: 0
2025-03-03 18:10:05 - INFO - layer39_mlp.down_proj | mse: 0.0013976586594548826, bpp_loss: 5.953697345792143, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:15:01<00:00, 112.01s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:15:01<00:00, 112.55s/it]
2025-03-03 18:10:05 - INFO - #### Total | mse: 0.001689947680285084, bpp_loss: 5.972869042287127, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda10000_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_10.96029_bpp_6.2788_MSE_0.0004_total_iter_140000.pth.tar/COL_MSE0.00169_bpploss5.9729_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda10000_rdloss_ql_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100/best_loss_model_loss_10.96029_bpp_6.2788_MSE_0.0004_total_iter_140000.pth.tar/COL_MSE0.00169_bpploss5.9729_bpp0
I0303 18:10:44.673865 3355323 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:08,  1.63s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.45s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.36s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.24s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.01s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]
W0303 18:10:50.821748 3355323 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 18:10:50.840173 3355323 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.234375:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.234375:   1%|          | 1/166 [00:01<04:38,  1.69s/it]avg_loss = 1.53515625:   1%|          | 1/166 [00:02<04:38,  1.69s/it]avg_loss = 1.53515625:   1%|          | 2/166 [00:02<03:28,  1.27s/it]avg_loss = 1.7057291666666667:   1%|          | 2/166 [00:03<03:28,  1.27s/it]avg_loss = 1.7057291666666667:   2%|▏         | 3/166 [00:03<03:09,  1.16s/it]avg_loss = 1.734375:   2%|▏         | 3/166 [00:04<03:09,  1.16s/it]          avg_loss = 1.734375:   2%|▏         | 4/166 [00:04<02:59,  1.11s/it]avg_loss = 1.66875:   2%|▏         | 4/166 [00:05<02:59,  1.11s/it] avg_loss = 1.66875:   3%|▎         | 5/166 [00:05<02:54,  1.08s/it]avg_loss = 1.6393229166666667:   3%|▎         | 5/166 [00:06<02:54,  1.08s/it]avg_loss = 1.6393229166666667:   4%|▎         | 6/166 [00:06<02:53,  1.09s/it]avg_loss = 1.5758928571428572:   4%|▎         | 6/166 [00:07<02:53,  1.09s/it]avg_loss = 1.5758928571428572:   4%|▍         | 7/166 [00:07<02:53,  1.09s/it]avg_loss = 1.5078125:   4%|▍         | 7/166 [00:09<02:53,  1.09s/it]         avg_loss = 1.5078125:   5%|▍         | 8/166 [00:09<02:52,  1.09s/it]avg_loss = 1.5052083333333333:   5%|▍         | 8/166 [00:10<02:52,  1.09s/it]avg_loss = 1.5052083333333333:   5%|▌         | 9/166 [00:10<02:52,  1.10s/it]avg_loss = 1.51640625:   5%|▌         | 9/166 [00:11<02:52,  1.10s/it]        avg_loss = 1.51640625:   6%|▌         | 10/166 [00:11<02:50,  1.09s/it]avg_loss = 1.5340909090909092:   6%|▌         | 10/166 [00:12<02:50,  1.09s/it]avg_loss = 1.5340909090909092:   7%|▋         | 11/166 [00:12<02:49,  1.09s/it]avg_loss = 1.5442708333333333:   7%|▋         | 11/166 [00:13<02:49,  1.09s/it]avg_loss = 1.5442708333333333:   7%|▋         | 12/166 [00:13<02:47,  1.09s/it]avg_loss = 1.5408653846153846:   7%|▋         | 12/166 [00:14<02:47,  1.09s/it]avg_loss = 1.5408653846153846:   8%|▊         | 13/166 [00:14<02:46,  1.09s/it]avg_loss = 1.5546875:   8%|▊         | 13/166 [00:15<02:46,  1.09s/it]         avg_loss = 1.5546875:   8%|▊         | 14/166 [00:15<02:47,  1.10s/it]avg_loss = 1.5708333333333333:   8%|▊         | 14/166 [00:16<02:47,  1.10s/it]avg_loss = 1.5708333333333333:   9%|▉         | 15/166 [00:16<02:46,  1.10s/it]avg_loss = 1.5888671875:   9%|▉         | 15/166 [00:17<02:46,  1.10s/it]      avg_loss = 1.5888671875:  10%|▉         | 16/166 [00:17<02:44,  1.10s/it]avg_loss = 1.5983455882352942:  10%|▉         | 16/166 [00:18<02:44,  1.10s/it]avg_loss = 1.5983455882352942:  10%|█         | 17/166 [00:18<02:43,  1.10s/it]avg_loss = 1.6119791666666667:  10%|█         | 17/166 [00:20<02:43,  1.10s/it]avg_loss = 1.6119791666666667:  11%|█         | 18/166 [00:20<02:43,  1.11s/it]avg_loss = 1.6311677631578947:  11%|█         | 18/166 [00:21<02:43,  1.11s/it]avg_loss = 1.6311677631578947:  11%|█▏        | 19/166 [00:21<02:41,  1.10s/it]avg_loss = 1.6375:  11%|█▏        | 19/166 [00:22<02:41,  1.10s/it]            avg_loss = 1.6375:  12%|█▏        | 20/166 [00:22<02:37,  1.08s/it]avg_loss = 1.6380208333333333:  12%|█▏        | 20/166 [00:23<02:37,  1.08s/it]avg_loss = 1.6380208333333333:  13%|█▎        | 21/166 [00:23<02:35,  1.08s/it]avg_loss = 1.6274857954545454:  13%|█▎        | 21/166 [00:24<02:35,  1.08s/it]avg_loss = 1.6274857954545454:  13%|█▎        | 22/166 [00:24<02:33,  1.07s/it]avg_loss = 1.6107336956521738:  13%|█▎        | 22/166 [00:25<02:33,  1.07s/it]avg_loss = 1.6107336956521738:  14%|█▍        | 23/166 [00:25<02:33,  1.07s/it]avg_loss = 1.6184895833333333:  14%|█▍        | 23/166 [00:26<02:33,  1.07s/it]avg_loss = 1.6184895833333333:  14%|█▍        | 24/166 [00:26<02:33,  1.08s/it]avg_loss = 1.6259375:  14%|█▍        | 24/166 [00:27<02:33,  1.08s/it]         avg_loss = 1.6259375:  15%|█▌        | 25/166 [00:27<02:34,  1.09s/it]avg_loss = 1.6307091346153846:  15%|█▌        | 25/166 [00:28<02:34,  1.09s/it]avg_loss = 1.6307091346153846:  16%|█▌        | 26/166 [00:28<02:33,  1.10s/it]avg_loss = 1.6374421296296295:  16%|█▌        | 26/166 [00:29<02:33,  1.10s/it]avg_loss = 1.6374421296296295:  16%|█▋        | 27/166 [00:29<02:33,  1.10s/it]avg_loss = 1.6397879464285714:  16%|█▋        | 27/166 [00:30<02:33,  1.10s/it]avg_loss = 1.6397879464285714:  17%|█▋        | 28/166 [00:30<02:31,  1.10s/it]avg_loss = 1.6495150862068966:  17%|█▋        | 28/166 [00:32<02:31,  1.10s/it]avg_loss = 1.6495150862068966:  17%|█▋        | 29/166 [00:32<02:31,  1.10s/it]avg_loss = 1.6502604166666666:  17%|█▋        | 29/166 [00:33<02:31,  1.10s/it]avg_loss = 1.6502604166666666:  18%|█▊        | 30/166 [00:33<02:30,  1.11s/it]avg_loss = 1.665070564516129:  18%|█▊        | 30/166 [00:34<02:30,  1.11s/it] avg_loss = 1.665070564516129:  19%|█▊        | 31/166 [00:34<02:28,  1.10s/it]avg_loss = 1.672607421875:  19%|█▊        | 31/166 [00:35<02:28,  1.10s/it]   avg_loss = 1.672607421875:  19%|█▉        | 32/166 [00:35<02:27,  1.10s/it]avg_loss = 1.6775568181818181:  19%|█▉        | 32/166 [00:36<02:27,  1.10s/it]avg_loss = 1.6775568181818181:  20%|█▉        | 33/166 [00:36<02:26,  1.10s/it]avg_loss = 1.6755514705882353:  20%|█▉        | 33/166 [00:37<02:26,  1.10s/it]avg_loss = 1.6755514705882353:  20%|██        | 34/166 [00:37<02:25,  1.10s/it]avg_loss = 1.6689732142857143:  20%|██        | 34/166 [00:38<02:25,  1.10s/it]avg_loss = 1.6689732142857143:  21%|██        | 35/166 [00:38<02:24,  1.11s/it]avg_loss = 1.6590711805555556:  21%|██        | 35/166 [00:39<02:24,  1.11s/it]avg_loss = 1.6590711805555556:  22%|██▏       | 36/166 [00:39<02:23,  1.11s/it]avg_loss = 1.6482263513513513:  22%|██▏       | 36/166 [00:40<02:23,  1.11s/it]avg_loss = 1.6482263513513513:  22%|██▏       | 37/166 [00:40<02:22,  1.11s/it]avg_loss = 1.644736842105263:  22%|██▏       | 37/166 [00:41<02:22,  1.11s/it] avg_loss = 1.644736842105263:  23%|██▎       | 38/166 [00:41<02:21,  1.11s/it]avg_loss = 1.642227564102564:  23%|██▎       | 38/166 [00:43<02:21,  1.11s/it]avg_loss = 1.642227564102564:  23%|██▎       | 39/166 [00:43<02:20,  1.10s/it]avg_loss = 1.6466796875:  23%|██▎       | 39/166 [00:44<02:20,  1.10s/it]     avg_loss = 1.6466796875:  24%|██▍       | 40/166 [00:44<02:17,  1.09s/it]avg_loss = 1.6476753048780488:  24%|██▍       | 40/166 [00:45<02:17,  1.09s/it]avg_loss = 1.6476753048780488:  25%|██▍       | 41/166 [00:45<02:15,  1.08s/it]avg_loss = 1.6365327380952381:  25%|██▍       | 41/166 [00:46<02:15,  1.08s/it]avg_loss = 1.6365327380952381:  25%|██▌       | 42/166 [00:46<02:13,  1.08s/it]avg_loss = 1.621638808139535:  25%|██▌       | 42/166 [00:47<02:13,  1.08s/it] avg_loss = 1.621638808139535:  26%|██▌       | 43/166 [00:47<02:12,  1.07s/it]avg_loss = 1.6123046875:  26%|██▌       | 43/166 [00:48<02:12,  1.07s/it]     avg_loss = 1.6123046875:  27%|██▋       | 44/166 [00:48<02:10,  1.07s/it]avg_loss = 1.59921875:  27%|██▋       | 44/166 [00:49<02:10,  1.07s/it]  avg_loss = 1.59921875:  27%|██▋       | 45/166 [00:49<02:09,  1.07s/it]avg_loss = 1.5892493206521738:  27%|██▋       | 45/166 [00:50<02:09,  1.07s/it]avg_loss = 1.5892493206521738:  28%|██▊       | 46/166 [00:50<02:09,  1.08s/it]avg_loss = 1.583028590425532:  28%|██▊       | 46/166 [00:51<02:09,  1.08s/it] avg_loss = 1.583028590425532:  28%|██▊       | 47/166 [00:51<02:09,  1.09s/it]avg_loss = 1.5839029947916667:  28%|██▊       | 47/166 [00:52<02:09,  1.09s/it]avg_loss = 1.5839029947916667:  29%|██▉       | 48/166 [00:52<02:06,  1.08s/it]avg_loss = 1.5949457908163265:  29%|██▉       | 48/166 [00:53<02:06,  1.08s/it]avg_loss = 1.5949457908163265:  30%|██▉       | 49/166 [00:53<02:07,  1.09s/it]avg_loss = 1.606171875:  30%|██▉       | 49/166 [00:54<02:07,  1.09s/it]       avg_loss = 1.606171875:  30%|███       | 50/166 [00:54<02:05,  1.09s/it]avg_loss = 1.6128216911764706:  30%|███       | 50/166 [00:55<02:05,  1.09s/it]avg_loss = 1.6128216911764706:  31%|███       | 51/166 [00:55<02:04,  1.08s/it]avg_loss = 1.6168118990384615:  31%|███       | 51/166 [00:57<02:04,  1.08s/it]avg_loss = 1.6168118990384615:  31%|███▏      | 52/166 [00:57<02:03,  1.08s/it]avg_loss = 1.6200619103773586:  31%|███▏      | 52/166 [00:58<02:03,  1.08s/it]avg_loss = 1.6200619103773586:  32%|███▏      | 53/166 [00:58<02:03,  1.09s/it]avg_loss = 1.6217447916666667:  32%|███▏      | 53/166 [00:59<02:03,  1.09s/it]avg_loss = 1.6217447916666667:  33%|███▎      | 54/166 [00:59<02:02,  1.09s/it]avg_loss = 1.6250710227272727:  33%|███▎      | 54/166 [01:00<02:02,  1.09s/it]avg_loss = 1.6250710227272727:  33%|███▎      | 55/166 [01:00<02:00,  1.09s/it]avg_loss = 1.6292550223214286:  33%|███▎      | 55/166 [01:01<02:00,  1.09s/it]avg_loss = 1.6292550223214286:  34%|███▎      | 56/166 [01:01<02:00,  1.10s/it]avg_loss = 1.624794407894737:  34%|███▎      | 56/166 [01:02<02:00,  1.10s/it] avg_loss = 1.624794407894737:  34%|███▍      | 57/166 [01:02<01:59,  1.10s/it]avg_loss = 1.6285695043103448:  34%|███▍      | 57/166 [01:03<01:59,  1.10s/it]avg_loss = 1.6285695043103448:  35%|███▍      | 58/166 [01:03<01:58,  1.10s/it]avg_loss = 1.6269200211864407:  35%|███▍      | 58/166 [01:04<01:58,  1.10s/it]avg_loss = 1.6269200211864407:  36%|███▌      | 59/166 [01:04<01:57,  1.10s/it]avg_loss = 1.6224609375:  36%|███▌      | 59/166 [01:05<01:57,  1.10s/it]      avg_loss = 1.6224609375:  36%|███▌      | 60/166 [01:05<01:56,  1.10s/it]avg_loss = 1.6187884221311475:  36%|███▌      | 60/166 [01:06<01:56,  1.10s/it]avg_loss = 1.6187884221311475:  37%|███▋      | 61/166 [01:06<01:54,  1.09s/it]avg_loss = 1.6153603830645162:  37%|███▋      | 61/166 [01:08<01:54,  1.09s/it]avg_loss = 1.6153603830645162:  37%|███▋      | 62/166 [01:08<01:53,  1.09s/it]avg_loss = 1.6096850198412698:  37%|███▋      | 62/166 [01:09<01:53,  1.09s/it]avg_loss = 1.6096850198412698:  38%|███▊      | 63/166 [01:09<01:53,  1.11s/it]avg_loss = 1.60552978515625:  38%|███▊      | 63/166 [01:10<01:53,  1.11s/it]  avg_loss = 1.60552978515625:  39%|███▊      | 64/166 [01:10<01:52,  1.10s/it]avg_loss = 1.5986177884615385:  39%|███▊      | 64/166 [01:11<01:52,  1.10s/it]avg_loss = 1.5986177884615385:  39%|███▉      | 65/166 [01:11<01:50,  1.10s/it]avg_loss = 1.591678503787879:  39%|███▉      | 65/166 [01:12<01:50,  1.10s/it] avg_loss = 1.591678503787879:  40%|███▉      | 66/166 [01:12<01:48,  1.08s/it]avg_loss = 1.5856459888059702:  40%|███▉      | 66/166 [01:13<01:48,  1.08s/it]avg_loss = 1.5856459888059702:  40%|████      | 67/166 [01:13<01:46,  1.08s/it]avg_loss = 1.5843864889705883:  40%|████      | 67/166 [01:14<01:46,  1.08s/it]avg_loss = 1.5843864889705883:  41%|████      | 68/166 [01:14<01:45,  1.07s/it]avg_loss = 1.5861073369565217:  41%|████      | 68/166 [01:15<01:45,  1.07s/it]avg_loss = 1.5861073369565217:  42%|████▏     | 69/166 [01:15<01:43,  1.07s/it]avg_loss = 1.5893415178571428:  42%|████▏     | 69/166 [01:16<01:43,  1.07s/it]avg_loss = 1.5893415178571428:  42%|████▏     | 70/166 [01:16<01:42,  1.06s/it]avg_loss = 1.5936949823943662:  42%|████▏     | 70/166 [01:17<01:42,  1.06s/it]avg_loss = 1.5936949823943662:  43%|████▎     | 71/166 [01:17<01:41,  1.07s/it]avg_loss = 1.5992296006944444:  43%|████▎     | 71/166 [01:18<01:41,  1.07s/it]avg_loss = 1.5992296006944444:  43%|████▎     | 72/166 [01:18<01:39,  1.06s/it]avg_loss = 1.6055757705479452:  43%|████▎     | 72/166 [01:19<01:39,  1.06s/it]avg_loss = 1.6055757705479452:  44%|████▍     | 73/166 [01:19<01:39,  1.07s/it]avg_loss = 1.5997149493243243:  44%|████▍     | 73/166 [01:20<01:39,  1.07s/it]avg_loss = 1.5997149493243243:  45%|████▍     | 74/166 [01:20<01:39,  1.08s/it]avg_loss = 1.59515625:  45%|████▍     | 74/166 [01:22<01:39,  1.08s/it]        avg_loss = 1.59515625:  45%|████▌     | 75/166 [01:22<01:37,  1.07s/it]avg_loss = 1.5941097861842106:  45%|████▌     | 75/166 [01:23<01:37,  1.07s/it]avg_loss = 1.5941097861842106:  46%|████▌     | 76/166 [01:23<01:37,  1.08s/it]avg_loss = 1.5907568993506493:  46%|████▌     | 76/166 [01:24<01:37,  1.08s/it]avg_loss = 1.5907568993506493:  46%|████▋     | 77/166 [01:24<01:37,  1.10s/it]avg_loss = 1.5873898237179487:  46%|████▋     | 77/166 [01:25<01:37,  1.10s/it]avg_loss = 1.5873898237179487:  47%|████▋     | 78/166 [01:25<01:35,  1.09s/it]avg_loss = 1.5848002373417722:  47%|████▋     | 78/166 [01:26<01:35,  1.09s/it]avg_loss = 1.5848002373417722:  48%|████▊     | 79/166 [01:26<01:35,  1.09s/it]avg_loss = 1.581396484375:  48%|████▊     | 79/166 [01:27<01:35,  1.09s/it]    avg_loss = 1.581396484375:  48%|████▊     | 80/166 [01:27<01:32,  1.08s/it]avg_loss = 1.5717110339506173:  48%|████▊     | 80/166 [01:28<01:32,  1.08s/it]avg_loss = 1.5717110339506173:  49%|████▉     | 81/166 [01:28<01:32,  1.09s/it]avg_loss = 1.573408917682927:  49%|████▉     | 81/166 [01:29<01:32,  1.09s/it] avg_loss = 1.573408917682927:  49%|████▉     | 82/166 [01:29<01:31,  1.09s/it]avg_loss = 1.5745011295180722:  49%|████▉     | 82/166 [01:30<01:31,  1.09s/it]avg_loss = 1.5745011295180722:  50%|█████     | 83/166 [01:30<01:29,  1.08s/it]avg_loss = 1.5771484375:  50%|█████     | 83/166 [01:31<01:29,  1.08s/it]      avg_loss = 1.5771484375:  51%|█████     | 84/166 [01:31<01:29,  1.09s/it]avg_loss = 1.5787224264705881:  51%|█████     | 84/166 [01:32<01:29,  1.09s/it]avg_loss = 1.5787224264705881:  51%|█████     | 85/166 [01:32<01:28,  1.10s/it]avg_loss = 1.577625363372093:  51%|█████     | 85/166 [01:33<01:28,  1.10s/it] avg_loss = 1.577625363372093:  52%|█████▏    | 86/166 [01:33<01:26,  1.08s/it]avg_loss = 1.5780801005747127:  52%|█████▏    | 86/166 [01:35<01:26,  1.08s/it]avg_loss = 1.5780801005747127:  52%|█████▏    | 87/166 [01:35<01:25,  1.09s/it]avg_loss = 1.5787020596590908:  52%|█████▏    | 87/166 [01:36<01:25,  1.09s/it]avg_loss = 1.5787020596590908:  53%|█████▎    | 88/166 [01:36<01:24,  1.09s/it]avg_loss = 1.5799245084269662:  53%|█████▎    | 88/166 [01:37<01:24,  1.09s/it]avg_loss = 1.5799245084269662:  54%|█████▎    | 89/166 [01:37<01:24,  1.10s/it]avg_loss = 1.5798177083333333:  54%|█████▎    | 89/166 [01:38<01:24,  1.10s/it]avg_loss = 1.5798177083333333:  54%|█████▍    | 90/166 [01:38<01:22,  1.09s/it]avg_loss = 1.5806576236263736:  54%|█████▍    | 90/166 [01:39<01:22,  1.09s/it]avg_loss = 1.5806576236263736:  55%|█████▍    | 91/166 [01:39<01:22,  1.10s/it]avg_loss = 1.5808848505434783:  55%|█████▍    | 91/166 [01:40<01:22,  1.10s/it]avg_loss = 1.5808848505434783:  55%|█████▌    | 92/166 [01:40<01:20,  1.09s/it]avg_loss = 1.5842153897849462:  55%|█████▌    | 92/166 [01:41<01:20,  1.09s/it]avg_loss = 1.5842153897849462:  56%|█████▌    | 93/166 [01:41<01:19,  1.09s/it]avg_loss = 1.5836519281914894:  56%|█████▌    | 93/166 [01:42<01:19,  1.09s/it]avg_loss = 1.5836519281914894:  57%|█████▋    | 94/166 [01:42<01:18,  1.09s/it]avg_loss = 1.5831003289473684:  57%|█████▋    | 94/166 [01:43<01:18,  1.09s/it]avg_loss = 1.5831003289473684:  57%|█████▋    | 95/166 [01:43<01:17,  1.09s/it]avg_loss = 1.5825602213541667:  57%|█████▋    | 95/166 [01:44<01:17,  1.09s/it]avg_loss = 1.5825602213541667:  58%|█████▊    | 96/166 [01:44<01:15,  1.08s/it]avg_loss = 1.5817896262886597:  58%|█████▊    | 96/166 [01:45<01:15,  1.08s/it]avg_loss = 1.5817896262886597:  58%|█████▊    | 97/166 [01:45<01:14,  1.08s/it]avg_loss = 1.5802375637755102:  58%|█████▊    | 97/166 [01:47<01:14,  1.08s/it]avg_loss = 1.5802375637755102:  59%|█████▉    | 98/166 [01:47<01:12,  1.07s/it]avg_loss = 1.578006628787879:  59%|█████▉    | 98/166 [01:48<01:12,  1.07s/it] avg_loss = 1.578006628787879:  60%|█████▉    | 99/166 [01:48<01:11,  1.07s/it]avg_loss = 1.5753515625:  60%|█████▉    | 99/166 [01:49<01:11,  1.07s/it]     avg_loss = 1.5753515625:  60%|██████    | 100/166 [01:49<01:10,  1.06s/it]avg_loss = 1.5759978341584158:  60%|██████    | 100/166 [01:50<01:10,  1.06s/it]avg_loss = 1.5759978341584158:  61%|██████    | 101/166 [01:50<01:09,  1.07s/it]avg_loss = 1.5772441789215685:  61%|██████    | 101/166 [01:51<01:09,  1.07s/it]avg_loss = 1.5772441789215685:  61%|██████▏   | 102/166 [01:51<01:08,  1.07s/it]avg_loss = 1.577783677184466:  61%|██████▏   | 102/166 [01:52<01:08,  1.07s/it] avg_loss = 1.577783677184466:  62%|██████▏   | 103/166 [01:52<01:07,  1.07s/it]avg_loss = 1.57958984375:  62%|██████▏   | 103/166 [01:53<01:07,  1.07s/it]    avg_loss = 1.57958984375:  63%|██████▎   | 104/166 [01:53<01:07,  1.08s/it]avg_loss = 1.5861235119047619:  63%|██████▎   | 104/166 [01:54<01:07,  1.08s/it]avg_loss = 1.5861235119047619:  63%|██████▎   | 105/166 [01:54<01:05,  1.08s/it]avg_loss = 1.5915020636792452:  63%|██████▎   | 105/166 [01:55<01:05,  1.08s/it]avg_loss = 1.5915020636792452:  64%|██████▍   | 106/166 [01:55<01:05,  1.08s/it]avg_loss = 1.5947356892523366:  64%|██████▍   | 106/166 [01:56<01:05,  1.08s/it]avg_loss = 1.5947356892523366:  64%|██████▍   | 107/166 [01:56<01:03,  1.08s/it]avg_loss = 1.5977647569444444:  64%|██████▍   | 107/166 [01:57<01:03,  1.08s/it]avg_loss = 1.5977647569444444:  65%|██████▌   | 108/166 [01:57<01:02,  1.08s/it]avg_loss = 1.6024584288990826:  65%|██████▌   | 108/166 [01:58<01:02,  1.08s/it]avg_loss = 1.6024584288990826:  66%|██████▌   | 109/166 [01:58<01:01,  1.08s/it]avg_loss = 1.6059303977272728:  66%|██████▌   | 109/166 [01:59<01:01,  1.08s/it]avg_loss = 1.6059303977272728:  66%|██████▋   | 110/166 [01:59<01:01,  1.09s/it]avg_loss = 1.6074394707207207:  66%|██████▋   | 110/166 [02:01<01:01,  1.09s/it]avg_loss = 1.6074394707207207:  67%|██████▋   | 111/166 [02:01<00:59,  1.09s/it]avg_loss = 1.6087123325892858:  67%|██████▋   | 111/166 [02:02<00:59,  1.09s/it]avg_loss = 1.6087123325892858:  67%|██████▋   | 112/166 [02:02<00:58,  1.09s/it]avg_loss = 1.6087873340707965:  67%|██████▋   | 112/166 [02:03<00:58,  1.09s/it]avg_loss = 1.6087873340707965:  68%|██████▊   | 113/166 [02:03<00:57,  1.08s/it]avg_loss = 1.6096148574561404:  68%|██████▊   | 113/166 [02:04<00:57,  1.08s/it]avg_loss = 1.6096148574561404:  69%|██████▊   | 114/166 [02:04<00:56,  1.09s/it]avg_loss = 1.6062839673913043:  69%|██████▊   | 114/166 [02:05<00:56,  1.09s/it]avg_loss = 1.6062839673913043:  69%|██████▉   | 115/166 [02:05<00:55,  1.09s/it]avg_loss = 1.6055024245689655:  69%|██████▉   | 115/166 [02:06<00:55,  1.09s/it]avg_loss = 1.6055024245689655:  70%|██████▉   | 116/166 [02:06<00:54,  1.08s/it]avg_loss = 1.6066706730769231:  70%|██████▉   | 116/166 [02:07<00:54,  1.08s/it]avg_loss = 1.6066706730769231:  70%|███████   | 117/166 [02:07<00:53,  1.08s/it]avg_loss = 1.6060977224576272:  70%|███████   | 117/166 [02:08<00:53,  1.08s/it]avg_loss = 1.6060977224576272:  71%|███████   | 118/166 [02:08<00:52,  1.09s/it]avg_loss = 1.6048778886554622:  71%|███████   | 118/166 [02:09<00:52,  1.09s/it]avg_loss = 1.6048778886554622:  72%|███████▏  | 119/166 [02:09<00:51,  1.10s/it]avg_loss = 1.6049153645833334:  72%|███████▏  | 119/166 [02:10<00:51,  1.10s/it]avg_loss = 1.6049153645833334:  72%|███████▏  | 120/166 [02:10<00:50,  1.09s/it]avg_loss = 1.6033380681818181:  72%|███████▏  | 120/166 [02:11<00:50,  1.09s/it]avg_loss = 1.6033380681818181:  73%|███████▎  | 121/166 [02:11<00:49,  1.10s/it]avg_loss = 1.6026191086065573:  73%|███████▎  | 121/166 [02:13<00:49,  1.10s/it]avg_loss = 1.6026191086065573:  73%|███████▎  | 122/166 [02:13<00:47,  1.09s/it]avg_loss = 1.6024834857723578:  73%|███████▎  | 122/166 [02:14<00:47,  1.09s/it]avg_loss = 1.6024834857723578:  74%|███████▍  | 123/166 [02:14<00:46,  1.09s/it]avg_loss = 1.6002079133064515:  74%|███████▍  | 123/166 [02:15<00:46,  1.09s/it]avg_loss = 1.6002079133064515:  75%|███████▍  | 124/166 [02:15<00:45,  1.09s/it]avg_loss = 1.59796875:  75%|███████▍  | 124/166 [02:16<00:45,  1.09s/it]        avg_loss = 1.59796875:  75%|███████▌  | 125/166 [02:16<00:44,  1.09s/it]avg_loss = 1.5952690972222223:  75%|███████▌  | 125/166 [02:17<00:44,  1.09s/it]avg_loss = 1.5952690972222223:  76%|███████▌  | 126/166 [02:17<00:43,  1.09s/it]avg_loss = 1.5925504429133859:  76%|███████▌  | 126/166 [02:18<00:43,  1.09s/it]avg_loss = 1.5925504429133859:  77%|███████▋  | 127/166 [02:18<00:42,  1.09s/it]avg_loss = 1.590667724609375:  77%|███████▋  | 127/166 [02:19<00:42,  1.09s/it] avg_loss = 1.590667724609375:  77%|███████▋  | 128/166 [02:19<00:41,  1.09s/it]avg_loss = 1.5892381298449612:  77%|███████▋  | 128/166 [02:20<00:41,  1.09s/it]avg_loss = 1.5892381298449612:  78%|███████▊  | 129/166 [02:20<00:40,  1.09s/it]avg_loss = 1.5892127403846155:  78%|███████▊  | 129/166 [02:21<00:40,  1.09s/it]avg_loss = 1.5892127403846155:  78%|███████▊  | 130/166 [02:21<00:39,  1.10s/it]avg_loss = 1.5902612118320612:  78%|███████▊  | 130/166 [02:22<00:39,  1.10s/it]avg_loss = 1.5902612118320612:  79%|███████▉  | 131/166 [02:22<00:38,  1.09s/it]avg_loss = 1.5906427556818181:  79%|███████▉  | 131/166 [02:23<00:38,  1.09s/it]avg_loss = 1.5906427556818181:  80%|███████▉  | 132/166 [02:23<00:36,  1.09s/it]avg_loss = 1.5916059680451127:  80%|███████▉  | 132/166 [02:25<00:36,  1.09s/it]avg_loss = 1.5916059680451127:  80%|████████  | 133/166 [02:25<00:35,  1.08s/it]avg_loss = 1.5929629197761195:  80%|████████  | 133/166 [02:26<00:35,  1.08s/it]avg_loss = 1.5929629197761195:  81%|████████  | 134/166 [02:26<00:34,  1.08s/it]avg_loss = 1.5912326388888889:  81%|████████  | 134/166 [02:27<00:34,  1.08s/it]avg_loss = 1.5912326388888889:  81%|████████▏ | 135/166 [02:27<00:33,  1.07s/it]avg_loss = 1.5917107077205883:  81%|████████▏ | 135/166 [02:28<00:33,  1.07s/it]avg_loss = 1.5917107077205883:  82%|████████▏ | 136/166 [02:28<00:32,  1.07s/it]avg_loss = 1.5921817974452555:  82%|████████▏ | 136/166 [02:29<00:32,  1.07s/it]avg_loss = 1.5921817974452555:  83%|████████▎ | 137/166 [02:29<00:31,  1.07s/it]avg_loss = 1.592985733695652:  83%|████████▎ | 137/166 [02:30<00:31,  1.07s/it] avg_loss = 1.592985733695652:  83%|████████▎ | 138/166 [02:30<00:29,  1.06s/it]avg_loss = 1.5925415917266188:  83%|████████▎ | 138/166 [02:31<00:29,  1.06s/it]avg_loss = 1.5925415917266188:  84%|████████▎ | 139/166 [02:31<00:28,  1.07s/it]avg_loss = 1.5914899553571429:  84%|████████▎ | 139/166 [02:32<00:28,  1.07s/it]avg_loss = 1.5914899553571429:  84%|████████▍ | 140/166 [02:32<00:27,  1.07s/it]avg_loss = 1.5903978280141844:  84%|████████▍ | 140/166 [02:33<00:27,  1.07s/it]avg_loss = 1.5903978280141844:  85%|████████▍ | 141/166 [02:33<00:27,  1.09s/it]avg_loss = 1.590091329225352:  85%|████████▍ | 141/166 [02:34<00:27,  1.09s/it] avg_loss = 1.590091329225352:  86%|████████▌ | 142/166 [02:34<00:25,  1.07s/it]avg_loss = 1.5884779283216783:  86%|████████▌ | 142/166 [02:35<00:25,  1.07s/it]avg_loss = 1.5884779283216783:  86%|████████▌ | 143/166 [02:35<00:25,  1.09s/it]avg_loss = 1.5898708767361112:  86%|████████▌ | 143/166 [02:36<00:25,  1.09s/it]avg_loss = 1.5898708767361112:  87%|████████▋ | 144/166 [02:36<00:23,  1.08s/it]avg_loss = 1.5894665948275861:  87%|████████▋ | 144/166 [02:37<00:23,  1.08s/it]avg_loss = 1.5894665948275861:  87%|████████▋ | 145/166 [02:37<00:22,  1.09s/it]avg_loss = 1.5897099743150684:  87%|████████▋ | 145/166 [02:38<00:22,  1.09s/it]avg_loss = 1.5897099743150684:  88%|████████▊ | 146/166 [02:38<00:21,  1.08s/it]avg_loss = 1.5886213860544218:  88%|████████▊ | 146/166 [02:40<00:21,  1.08s/it]avg_loss = 1.5886213860544218:  89%|████████▊ | 147/166 [02:40<00:20,  1.10s/it]avg_loss = 1.5878114442567568:  89%|████████▊ | 147/166 [02:41<00:20,  1.10s/it]avg_loss = 1.5878114442567568:  89%|████████▉ | 148/166 [02:41<00:19,  1.09s/it]avg_loss = 1.5863831795302012:  89%|████████▉ | 148/166 [02:42<00:19,  1.09s/it]avg_loss = 1.5863831795302012:  90%|████████▉ | 149/166 [02:42<00:18,  1.09s/it]avg_loss = 1.5874739583333333:  90%|████████▉ | 149/166 [02:43<00:18,  1.09s/it]avg_loss = 1.5874739583333333:  90%|█████████ | 150/166 [02:43<00:17,  1.08s/it]avg_loss = 1.5864807533112584:  90%|█████████ | 150/166 [02:44<00:17,  1.08s/it]avg_loss = 1.5864807533112584:  91%|█████████ | 151/166 [02:44<00:16,  1.08s/it]avg_loss = 1.5863229851973684:  91%|█████████ | 151/166 [02:45<00:16,  1.08s/it]avg_loss = 1.5863229851973684:  92%|█████████▏| 152/166 [02:45<00:15,  1.09s/it]avg_loss = 1.5863204656862746:  92%|█████████▏| 152/166 [02:46<00:15,  1.09s/it]avg_loss = 1.5863204656862746:  92%|█████████▏| 153/166 [02:46<00:14,  1.08s/it]avg_loss = 1.587890625:  92%|█████████▏| 153/166 [02:47<00:14,  1.08s/it]       avg_loss = 1.587890625:  93%|█████████▎| 154/166 [02:47<00:13,  1.09s/it]avg_loss = 1.5875756048387097:  93%|█████████▎| 154/166 [02:48<00:13,  1.09s/it]avg_loss = 1.5875756048387097:  93%|█████████▎| 155/166 [02:48<00:11,  1.08s/it]avg_loss = 1.5875150240384615:  93%|█████████▎| 155/166 [02:49<00:11,  1.08s/it]avg_loss = 1.5875150240384615:  94%|█████████▍| 156/166 [02:49<00:10,  1.09s/it]avg_loss = 1.585813097133758:  94%|█████████▍| 156/166 [02:51<00:10,  1.09s/it] avg_loss = 1.585813097133758:  95%|█████████▍| 157/166 [02:51<00:09,  1.11s/it]avg_loss = 1.5817840189873418:  95%|█████████▍| 157/166 [02:52<00:09,  1.11s/it]avg_loss = 1.5817840189873418:  95%|█████████▌| 158/166 [02:52<00:08,  1.10s/it]avg_loss = 1.5824488993710693:  95%|█████████▌| 158/166 [02:53<00:08,  1.10s/it]avg_loss = 1.5824488993710693:  96%|█████████▌| 159/166 [02:53<00:07,  1.11s/it]avg_loss = 1.583984375:  96%|█████████▌| 159/166 [02:54<00:07,  1.11s/it]       avg_loss = 1.583984375:  96%|█████████▋| 160/166 [02:54<00:06,  1.09s/it]avg_loss = 1.5865683229813665:  96%|█████████▋| 160/166 [02:55<00:06,  1.09s/it]avg_loss = 1.5865683229813665:  97%|█████████▋| 161/166 [02:55<00:05,  1.10s/it]avg_loss = 1.5863233024691359:  97%|█████████▋| 161/166 [02:56<00:05,  1.10s/it]avg_loss = 1.5863233024691359:  98%|█████████▊| 162/166 [02:56<00:04,  1.09s/it]avg_loss = 1.5856978527607362:  98%|█████████▊| 162/166 [02:57<00:04,  1.09s/it]avg_loss = 1.5856978527607362:  98%|█████████▊| 163/166 [02:57<00:03,  1.09s/it]avg_loss = 1.5864138719512195:  98%|█████████▊| 163/166 [02:58<00:03,  1.09s/it]avg_loss = 1.5864138719512195:  99%|█████████▉| 164/166 [02:58<00:02,  1.08s/it]avg_loss = 1.5861742424242424:  99%|█████████▉| 164/166 [02:59<00:02,  1.08s/it]avg_loss = 1.5861742424242424:  99%|█████████▉| 165/166 [02:59<00:01,  1.09s/it]avg_loss = 1.5880553463855422:  99%|█████████▉| 165/166 [03:00<00:01,  1.09s/it]avg_loss = 1.5880553463855422: 100%|██████████| 166/166 [03:00<00:00,  1.09s/it]avg_loss = 1.5880553463855422: 100%|██████████| 166/166 [03:00<00:00,  1.09s/it]
I0303 18:15:10.354953 3355323 eval_ppl.py:105] wikitext2 perplexity: 4.894222259521484
wikitext2 perplexity: 4.894
Running with lmbda=100000
/home/jgryu/Weight_compression/comp_llm/matmul_had.py:96: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("quip_lib::hadamard")
/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|▉         | 1/11 [00:00<00:01,  8.88it/s]Loading checkpoint shards:  27%|██▋       | 3/11 [00:00<00:00, 10.17it/s]Loading checkpoint shards:  45%|████▌     | 5/11 [00:00<00:00, 10.17it/s]Loading checkpoint shards:  64%|██████▎   | 7/11 [00:00<00:00, 10.51it/s]Loading checkpoint shards:  82%|████████▏ | 9/11 [00:00<00:00, 10.74it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.75it/s]Loading checkpoint shards: 100%|██████████| 11/11 [00:01<00:00, 10.55it/s]
calculating model weight mean & std:   0%|          | 0/40 [00:00<?, ?it/s]calculating model weight mean & std:   2%|▎         | 1/40 [00:00<00:26,  1.49it/s]calculating model weight mean & std:   5%|▌         | 2/40 [00:01<00:25,  1.51it/s]calculating model weight mean & std:   8%|▊         | 3/40 [00:01<00:24,  1.51it/s]calculating model weight mean & std:  10%|█         | 4/40 [00:02<00:23,  1.51it/s]calculating model weight mean & std:  12%|█▎        | 5/40 [00:03<00:22,  1.55it/s]calculating model weight mean & std:  15%|█▌        | 6/40 [00:03<00:21,  1.61it/s]calculating model weight mean & std:  18%|█▊        | 7/40 [00:04<00:20,  1.64it/s]calculating model weight mean & std:  20%|██        | 8/40 [00:05<00:19,  1.67it/s]calculating model weight mean & std:  22%|██▎       | 9/40 [00:05<00:18,  1.68it/s]calculating model weight mean & std:  25%|██▌       | 10/40 [00:06<00:17,  1.69it/s]calculating model weight mean & std:  28%|██▊       | 11/40 [00:06<00:17,  1.69it/s]calculating model weight mean & std:  30%|███       | 12/40 [00:07<00:16,  1.70it/s]calculating model weight mean & std:  32%|███▎      | 13/40 [00:07<00:15,  1.71it/s]calculating model weight mean & std:  35%|███▌      | 14/40 [00:08<00:15,  1.72it/s]calculating model weight mean & std:  38%|███▊      | 15/40 [00:09<00:14,  1.72it/s]calculating model weight mean & std:  40%|████      | 16/40 [00:09<00:13,  1.72it/s]calculating model weight mean & std:  42%|████▎     | 17/40 [00:10<00:13,  1.72it/s]calculating model weight mean & std:  45%|████▌     | 18/40 [00:10<00:12,  1.74it/s]calculating model weight mean & std:  48%|████▊     | 19/40 [00:11<00:11,  1.78it/s]calculating model weight mean & std:  50%|█████     | 20/40 [00:11<00:11,  1.80it/s]calculating model weight mean & std:  52%|█████▎    | 21/40 [00:12<00:10,  1.82it/s]calculating model weight mean & std:  55%|█████▌    | 22/40 [00:12<00:09,  1.84it/s]calculating model weight mean & std:  57%|█████▊    | 23/40 [00:13<00:09,  1.84it/s]calculating model weight mean & std:  60%|██████    | 24/40 [00:14<00:08,  1.84it/s]calculating model weight mean & std:  62%|██████▎   | 25/40 [00:14<00:08,  1.84it/s]calculating model weight mean & std:  65%|██████▌   | 26/40 [00:15<00:07,  1.85it/s]calculating model weight mean & std:  68%|██████▊   | 27/40 [00:15<00:07,  1.84it/s]calculating model weight mean & std:  70%|███████   | 28/40 [00:16<00:06,  1.84it/s]calculating model weight mean & std:  72%|███████▎  | 29/40 [00:16<00:05,  1.84it/s]calculating model weight mean & std:  75%|███████▌  | 30/40 [00:17<00:05,  1.84it/s]calculating model weight mean & std:  78%|███████▊  | 31/40 [00:17<00:04,  1.83it/s]calculating model weight mean & std:  80%|████████  | 32/40 [00:18<00:04,  1.83it/s]calculating model weight mean & std:  82%|████████▎ | 33/40 [00:18<00:03,  1.84it/s]calculating model weight mean & std:  85%|████████▌ | 34/40 [00:19<00:03,  1.85it/s]calculating model weight mean & std:  88%|████████▊ | 35/40 [00:19<00:02,  1.86it/s]calculating model weight mean & std:  90%|█████████ | 36/40 [00:20<00:02,  1.87it/s]calculating model weight mean & std:  92%|█████████▎| 37/40 [00:21<00:01,  1.88it/s]calculating model weight mean & std:  95%|█████████▌| 38/40 [00:21<00:01,  1.88it/s]calculating model weight mean & std:  98%|█████████▊| 39/40 [00:22<00:00,  1.87it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:22<00:00,  1.87it/s]calculating model weight mean & std: 100%|██████████| 40/40 [00:22<00:00,  1.77it/s]
pseudo compress quantization...:   0%|          | 0/40 [00:00<?, ?it/s]2025-03-03 18:16:04 - INFO - layer0_self_attn.q_proj | mse: 0.11650325886082208, bpp_loss: 5.679889028146863, bpp: 0
2025-03-03 18:16:16 - INFO - layer0_self_attn.k_proj | mse: 0.0540423869571666, bpp_loss: 5.7292808884382245, bpp: 0
2025-03-03 18:16:27 - INFO - layer0_self_attn.v_proj | mse: 0.007043908703324159, bpp_loss: 5.666833525151015, bpp: 0
2025-03-03 18:16:38 - INFO - layer0_self_attn.o_proj | mse: 0.004418383916316416, bpp_loss: 5.551871134489775, bpp: 0
2025-03-03 18:16:52 - INFO - layer0_mlp.gate_proj | mse: 0.0013611164374616124, bpp_loss: 5.9701958902456145, bpp: 0
2025-03-03 18:17:07 - INFO - layer0_mlp.up_proj | mse: 0.0013392277572190489, bpp_loss: 5.944542675768887, bpp: 0
2025-03-03 18:17:45 - INFO - layer0_mlp.down_proj | mse: 0.011388182150473781, bpp_loss: 6.051484165037119, bpp: 0
pseudo compress quantization...:   2%|▎         | 1/40 [01:52<1:13:21, 112.87s/it]2025-03-03 18:17:57 - INFO - layer1_self_attn.q_proj | mse: 0.00346749481838651, bpp_loss: 6.221344905495644, bpp: 0
2025-03-03 18:18:09 - INFO - layer1_self_attn.k_proj | mse: 0.0036349378530565603, bpp_loss: 6.259313969686628, bpp: 0
2025-03-03 18:18:20 - INFO - layer1_self_attn.v_proj | mse: 0.0020810675852417615, bpp_loss: 5.738099354878068, bpp: 0
2025-03-03 18:18:31 - INFO - layer1_self_attn.o_proj | mse: 0.006649269856288854, bpp_loss: 5.6691065514832735, bpp: 0
2025-03-03 18:18:46 - INFO - layer1_mlp.gate_proj | mse: 0.0016415328188554494, bpp_loss: 6.141275885149285, bpp: 0
2025-03-03 18:19:00 - INFO - layer1_mlp.up_proj | mse: 0.0015780737666167973, bpp_loss: 6.080071186467453, bpp: 0
2025-03-03 18:19:39 - INFO - layer1_mlp.down_proj | mse: 0.0014160524333798686, bpp_loss: 6.111447960552242, bpp: 0
pseudo compress quantization...:   5%|▌         | 2/40 [03:46<1:11:37, 113.09s/it]2025-03-03 18:19:51 - INFO - layer2_self_attn.q_proj | mse: 0.0017494840285492165, bpp_loss: 6.589010354280472, bpp: 0
2025-03-03 18:20:02 - INFO - layer2_self_attn.k_proj | mse: 0.0018063160079258222, bpp_loss: 6.648360063806177, bpp: 0
2025-03-03 18:20:13 - INFO - layer2_self_attn.v_proj | mse: 0.0012525573295227156, bpp_loss: 5.859871231168508, bpp: 0
2025-03-03 18:20:25 - INFO - layer2_self_attn.o_proj | mse: 0.0017389387935961423, bpp_loss: 5.836802504807711, bpp: 0
2025-03-03 18:20:39 - INFO - layer2_mlp.gate_proj | mse: 0.0013868017456404765, bpp_loss: 6.203862076997757, bpp: 0
2025-03-03 18:20:53 - INFO - layer2_mlp.up_proj | mse: 0.0013306914818007058, bpp_loss: 6.109483029555391, bpp: 0
2025-03-03 18:21:31 - INFO - layer2_mlp.down_proj | mse: 0.0010763240196175704, bpp_loss: 6.125244402195569, bpp: 0
pseudo compress quantization...:   8%|▊         | 3/40 [05:38<1:09:40, 112.98s/it]2025-03-03 18:21:43 - INFO - layer3_self_attn.q_proj | mse: 0.0016115303378394779, bpp_loss: 6.647471344470977, bpp: 0
2025-03-03 18:21:55 - INFO - layer3_self_attn.k_proj | mse: 0.0016949819666887262, bpp_loss: 6.7528268050402405, bpp: 0
2025-03-03 18:22:06 - INFO - layer3_self_attn.v_proj | mse: 0.0011354520318420157, bpp_loss: 5.901902551874518, bpp: 0
2025-03-03 18:22:17 - INFO - layer3_self_attn.o_proj | mse: 0.00140848415645209, bpp_loss: 5.871211251467466, bpp: 0
2025-03-03 18:22:32 - INFO - layer3_mlp.gate_proj | mse: 0.0012737302170710307, bpp_loss: 6.224932553481173, bpp: 0
2025-03-03 18:22:46 - INFO - layer3_mlp.up_proj | mse: 0.001220366435425469, bpp_loss: 6.124988450717043, bpp: 0
2025-03-03 18:23:24 - INFO - layer3_mlp.down_proj | mse: 0.0067694595429171585, bpp_loss: 6.1288870041569075, bpp: 0
pseudo compress quantization...:  10%|█         | 4/40 [07:31<1:07:39, 112.75s/it]2025-03-03 18:23:36 - INFO - layer4_self_attn.q_proj | mse: 0.0014504550027372447, bpp_loss: 6.584203807488084, bpp: 0
2025-03-03 18:23:47 - INFO - layer4_self_attn.k_proj | mse: 0.0014655100059174483, bpp_loss: 6.60268208898604, bpp: 0
2025-03-03 18:23:58 - INFO - layer4_self_attn.v_proj | mse: 0.0010796563825333806, bpp_loss: 5.893744144812226, bpp: 0
2025-03-03 18:24:10 - INFO - layer4_self_attn.o_proj | mse: 0.0010508164396354535, bpp_loss: 5.871258642077446, bpp: 0
2025-03-03 18:24:24 - INFO - layer4_mlp.gate_proj | mse: 0.0012428180432286536, bpp_loss: 6.231720063090324, bpp: 0
2025-03-03 18:24:38 - INFO - layer4_mlp.up_proj | mse: 0.0011803187490039236, bpp_loss: 6.1262491086015, bpp: 0
2025-03-03 18:25:16 - INFO - layer4_mlp.down_proj | mse: 0.0010423027826087273, bpp_loss: 6.128850837438195, bpp: 0
pseudo compress quantization...:  12%|█▎        | 5/40 [09:23<1:05:41, 112.60s/it]2025-03-03 18:25:28 - INFO - layer5_self_attn.q_proj | mse: 0.0013997003233812877, bpp_loss: 6.54282251060009, bpp: 0
2025-03-03 18:25:39 - INFO - layer5_self_attn.k_proj | mse: 0.0013944800844344076, bpp_loss: 6.5284560782462355, bpp: 0
2025-03-03 18:25:51 - INFO - layer5_self_attn.v_proj | mse: 0.0010589490175366262, bpp_loss: 5.914387231394649, bpp: 0
2025-03-03 18:26:02 - INFO - layer5_self_attn.o_proj | mse: 0.0011518695720835188, bpp_loss: 5.885025152936578, bpp: 0
2025-03-03 18:26:16 - INFO - layer5_mlp.gate_proj | mse: 0.0012563113945387758, bpp_loss: 6.247263433425514, bpp: 0
2025-03-03 18:26:30 - INFO - layer5_mlp.up_proj | mse: 0.0011743788245959644, bpp_loss: 6.1245362643842345, bpp: 0
2025-03-03 18:27:09 - INFO - layer5_mlp.down_proj | mse: 0.0010385889027920427, bpp_loss: 6.12617236883552, bpp: 0
pseudo compress quantization...:  15%|█▌        | 6/40 [11:16<1:03:45, 112.50s/it]2025-03-03 18:27:20 - INFO - layer6_self_attn.q_proj | mse: 0.0013597322605652976, bpp_loss: 6.5585612594336276, bpp: 0
2025-03-03 18:27:32 - INFO - layer6_self_attn.k_proj | mse: 0.0013854088647407082, bpp_loss: 6.585821616575122, bpp: 0
2025-03-03 18:27:43 - INFO - layer6_self_attn.v_proj | mse: 0.0010425714564825828, bpp_loss: 5.933900115862489, bpp: 0
2025-03-03 18:27:54 - INFO - layer6_self_attn.o_proj | mse: 0.0010641383160688639, bpp_loss: 5.916728487387299, bpp: 0
2025-03-03 18:28:09 - INFO - layer6_mlp.gate_proj | mse: 0.0011791700608953192, bpp_loss: 6.2619930087416265, bpp: 0
2025-03-03 18:28:23 - INFO - layer6_mlp.up_proj | mse: 0.0011128832375939149, bpp_loss: 6.121845176264092, bpp: 0
2025-03-03 18:29:01 - INFO - layer6_mlp.down_proj | mse: 0.0010369201204336975, bpp_loss: 6.120748621390925, bpp: 0
pseudo compress quantization...:  18%|█▊        | 7/40 [13:08<1:01:51, 112.46s/it]2025-03-03 18:29:13 - INFO - layer7_self_attn.q_proj | mse: 0.001351118310070772, bpp_loss: 6.58766381457448, bpp: 0
2025-03-03 18:29:24 - INFO - layer7_self_attn.k_proj | mse: 0.0013848024557900549, bpp_loss: 6.61455695591867, bpp: 0
2025-03-03 18:29:35 - INFO - layer7_self_attn.v_proj | mse: 0.0010407887323669992, bpp_loss: 5.9510226187855, bpp: 0
2025-03-03 18:29:47 - INFO - layer7_self_attn.o_proj | mse: 0.0010678727198226855, bpp_loss: 5.927897539883852, bpp: 0
2025-03-03 18:30:01 - INFO - layer7_mlp.gate_proj | mse: 0.001164171535023519, bpp_loss: 6.267823039271214, bpp: 0
2025-03-03 18:30:15 - INFO - layer7_mlp.up_proj | mse: 0.0010977692592108255, bpp_loss: 6.1232511198079145, bpp: 0
2025-03-03 18:30:53 - INFO - layer7_mlp.down_proj | mse: 0.0010408118572045764, bpp_loss: 6.1201783648243655, bpp: 0
pseudo compress quantization...:  20%|██        | 8/40 [15:00<59:58, 112.44s/it]  2025-03-03 18:31:05 - INFO - layer8_self_attn.q_proj | mse: 0.00132906973024603, bpp_loss: 6.54472348511219, bpp: 0
2025-03-03 18:31:16 - INFO - layer8_self_attn.k_proj | mse: 0.0013633303874366488, bpp_loss: 6.572048092782498, bpp: 0
2025-03-03 18:31:28 - INFO - layer8_self_attn.v_proj | mse: 0.0010380920492615818, bpp_loss: 5.958025876581669, bpp: 0
2025-03-03 18:31:39 - INFO - layer8_self_attn.o_proj | mse: 0.0010834132673375417, bpp_loss: 5.939395126104355, bpp: 0
2025-03-03 18:31:53 - INFO - layer8_mlp.gate_proj | mse: 0.0011562274580255367, bpp_loss: 6.263533010968455, bpp: 0
2025-03-03 18:32:08 - INFO - layer8_mlp.up_proj | mse: 0.001097896814922183, bpp_loss: 6.1343637322938, bpp: 0
2025-03-03 18:32:46 - INFO - layer8_mlp.down_proj | mse: 0.0010427330899983878, bpp_loss: 6.129717199256023, bpp: 0
pseudo compress quantization...:  22%|██▎       | 9/40 [16:53<58:05, 112.42s/it]2025-03-03 18:32:57 - INFO - layer9_self_attn.q_proj | mse: 0.0013276607246219155, bpp_loss: 6.538656711429358, bpp: 0
2025-03-03 18:33:09 - INFO - layer9_self_attn.k_proj | mse: 0.0013374363891868208, bpp_loss: 6.545555195882916, bpp: 0
2025-03-03 18:33:20 - INFO - layer9_self_attn.v_proj | mse: 0.0010333565434774347, bpp_loss: 5.9543901581317185, bpp: 0
2025-03-03 18:33:31 - INFO - layer9_self_attn.o_proj | mse: 0.0010902243303001998, bpp_loss: 5.941863683015108, bpp: 0
2025-03-03 18:33:46 - INFO - layer9_mlp.gate_proj | mse: 0.0011425609708676297, bpp_loss: 6.249675657241433, bpp: 0
2025-03-03 18:34:00 - INFO - layer9_mlp.up_proj | mse: 0.001097354059361676, bpp_loss: 6.147643183999591, bpp: 0
2025-03-03 18:34:38 - INFO - layer9_mlp.down_proj | mse: 0.0010434603120620623, bpp_loss: 6.141028659790754, bpp: 0
pseudo compress quantization...:  25%|██▌       | 10/40 [18:45<56:16, 112.54s/it]2025-03-03 18:34:50 - INFO - layer10_self_attn.q_proj | mse: 0.0013031024947600448, bpp_loss: 6.529966211915016, bpp: 0
2025-03-03 18:35:01 - INFO - layer10_self_attn.k_proj | mse: 0.0013372099563395865, bpp_loss: 6.555228880792856, bpp: 0
2025-03-03 18:35:13 - INFO - layer10_self_attn.v_proj | mse: 0.001024894629776958, bpp_loss: 5.947365959361195, bpp: 0
2025-03-03 18:35:24 - INFO - layer10_self_attn.o_proj | mse: 0.0010486985856354271, bpp_loss: 5.940577769055962, bpp: 0
2025-03-03 18:35:38 - INFO - layer10_mlp.gate_proj | mse: 0.0011326754890757223, bpp_loss: 6.23401240364269, bpp: 0
2025-03-03 18:35:53 - INFO - layer10_mlp.up_proj | mse: 0.0010970279596662204, bpp_loss: 6.156419993329931, bpp: 0
2025-03-03 18:36:30 - INFO - layer10_mlp.down_proj | mse: 0.0010502599928663584, bpp_loss: 6.148771911169644, bpp: 0
pseudo compress quantization...:  28%|██▊       | 11/40 [20:37<54:18, 112.37s/it]2025-03-03 18:36:42 - INFO - layer11_self_attn.q_proj | mse: 0.0013302316760798157, bpp_loss: 6.583276838734746, bpp: 0
2025-03-03 18:36:53 - INFO - layer11_self_attn.k_proj | mse: 0.001372318635831157, bpp_loss: 6.620336570590735, bpp: 0
2025-03-03 18:37:05 - INFO - layer11_self_attn.v_proj | mse: 0.0010278989788032591, bpp_loss: 5.957114588096738, bpp: 0
2025-03-03 18:37:16 - INFO - layer11_self_attn.o_proj | mse: 0.0011059250263282996, bpp_loss: 5.943122627288103, bpp: 0
2025-03-03 18:37:30 - INFO - layer11_mlp.gate_proj | mse: 0.0011215571976428214, bpp_loss: 6.220859743378781, bpp: 0
2025-03-03 18:37:44 - INFO - layer11_mlp.up_proj | mse: 0.0010960792747927862, bpp_loss: 6.16676812922513, bpp: 0
2025-03-03 18:38:22 - INFO - layer11_mlp.down_proj | mse: 0.0010563364001687041, bpp_loss: 6.157394551651345, bpp: 0
pseudo compress quantization...:  30%|███       | 12/40 [22:29<52:21, 112.20s/it]2025-03-03 18:38:34 - INFO - layer12_self_attn.q_proj | mse: 0.0012991917190545903, bpp_loss: 6.519504542872309, bpp: 0
2025-03-03 18:38:45 - INFO - layer12_self_attn.k_proj | mse: 0.0013341027043612158, bpp_loss: 6.545807264074683, bpp: 0
2025-03-03 18:38:56 - INFO - layer12_self_attn.v_proj | mse: 0.001037096973079801, bpp_loss: 5.979818673878908, bpp: 0
2025-03-03 18:39:08 - INFO - layer12_self_attn.o_proj | mse: 0.0011409899025362185, bpp_loss: 5.964134719073773, bpp: 0
2025-03-03 18:39:22 - INFO - layer12_mlp.gate_proj | mse: 0.0011197688425348656, bpp_loss: 6.215664941624359, bpp: 0
2025-03-03 18:39:36 - INFO - layer12_mlp.up_proj | mse: 0.0011011348930510785, bpp_loss: 6.176046933620064, bpp: 0
2025-03-03 18:40:14 - INFO - layer12_mlp.down_proj | mse: 0.00105601545077115, bpp_loss: 6.166010202743389, bpp: 0
pseudo compress quantization...:  32%|███▎      | 13/40 [24:21<50:25, 112.04s/it]2025-03-03 18:40:26 - INFO - layer13_self_attn.q_proj | mse: 0.001273068275033256, bpp_loss: 6.470720543712377, bpp: 0
2025-03-03 18:40:37 - INFO - layer13_self_attn.k_proj | mse: 0.0012963062646553425, bpp_loss: 6.461260843276977, bpp: 0
2025-03-03 18:40:48 - INFO - layer13_self_attn.v_proj | mse: 0.001043085739479525, bpp_loss: 5.998827230110765, bpp: 0
2025-03-03 18:40:59 - INFO - layer13_self_attn.o_proj | mse: 0.0010935645045011605, bpp_loss: 5.990807205289602, bpp: 0
2025-03-03 18:41:14 - INFO - layer13_mlp.gate_proj | mse: 0.0011178172229834363, bpp_loss: 6.2105995416641235, bpp: 0
2025-03-03 18:41:28 - INFO - layer13_mlp.up_proj | mse: 0.0011059190047716697, bpp_loss: 6.183319963018099, bpp: 0
2025-03-03 18:42:06 - INFO - layer13_mlp.down_proj | mse: 0.0010590302634860206, bpp_loss: 6.172120259840179, bpp: 0
pseudo compress quantization...:  35%|███▌      | 14/40 [26:13<48:32, 112.02s/it]2025-03-03 18:42:18 - INFO - layer14_self_attn.q_proj | mse: 0.0012849181061962392, bpp_loss: 6.50572605855763, bpp: 0
2025-03-03 18:42:29 - INFO - layer14_self_attn.k_proj | mse: 0.0013241790588618592, bpp_loss: 6.532279428765178, bpp: 0
2025-03-03 18:42:40 - INFO - layer14_self_attn.v_proj | mse: 0.001041036950974356, bpp_loss: 5.987808868065477, bpp: 0
2025-03-03 18:42:51 - INFO - layer14_self_attn.o_proj | mse: 0.0010653788296971349, bpp_loss: 5.97423174969852, bpp: 0
2025-03-03 18:43:06 - INFO - layer14_mlp.gate_proj | mse: 0.0011121074310533705, bpp_loss: 6.20684317306236, bpp: 0
2025-03-03 18:43:20 - INFO - layer14_mlp.up_proj | mse: 0.0011058901631034223, bpp_loss: 6.190076101267779, bpp: 0
2025-03-03 18:43:58 - INFO - layer14_mlp.down_proj | mse: 0.0010587511173397659, bpp_loss: 6.177101331894044, bpp: 0
pseudo compress quantization...:  38%|███▊      | 15/40 [28:05<46:40, 112.01s/it]2025-03-03 18:44:09 - INFO - layer15_self_attn.q_proj | mse: 0.0012696929886763528, bpp_loss: 6.481181310340762, bpp: 0
2025-03-03 18:44:21 - INFO - layer15_self_attn.k_proj | mse: 0.0013125170719390843, bpp_loss: 6.525326877310872, bpp: 0
2025-03-03 18:44:32 - INFO - layer15_self_attn.v_proj | mse: 0.001051586705313839, bpp_loss: 6.022694972828031, bpp: 0
2025-03-03 18:44:43 - INFO - layer15_self_attn.o_proj | mse: 0.0011853731741098689, bpp_loss: 6.013039569854737, bpp: 0
2025-03-03 18:44:58 - INFO - layer15_mlp.gate_proj | mse: 0.001112608898392368, bpp_loss: 6.20908758772744, bpp: 0
2025-03-03 18:45:12 - INFO - layer15_mlp.up_proj | mse: 0.0011095764888263344, bpp_loss: 6.197059118195816, bpp: 0
2025-03-03 18:45:50 - INFO - layer15_mlp.down_proj | mse: 0.0010632487008204437, bpp_loss: 6.184675286047988, bpp: 0
pseudo compress quantization...:  40%|████      | 16/40 [29:57<44:46, 111.96s/it]2025-03-03 18:46:01 - INFO - layer16_self_attn.q_proj | mse: 0.001264569974478106, bpp_loss: 6.468283696621657, bpp: 0
2025-03-03 18:46:13 - INFO - layer16_self_attn.k_proj | mse: 0.0013015964961507023, bpp_loss: 6.497595061436296, bpp: 0
2025-03-03 18:46:24 - INFO - layer16_self_attn.v_proj | mse: 0.001058224641012542, bpp_loss: 6.027951916381717, bpp: 0
2025-03-03 18:46:35 - INFO - layer16_self_attn.o_proj | mse: 0.0010932095588455423, bpp_loss: 6.016576320007443, bpp: 0
2025-03-03 18:46:50 - INFO - layer16_mlp.gate_proj | mse: 0.0011140770766474547, bpp_loss: 6.212844586703512, bpp: 0
2025-03-03 18:47:04 - INFO - layer16_mlp.up_proj | mse: 0.0011098364071937573, bpp_loss: 6.196576043632295, bpp: 0
2025-03-03 18:47:42 - INFO - layer16_mlp.down_proj | mse: 0.001067052109982314, bpp_loss: 6.18319445958844, bpp: 0
pseudo compress quantization...:  42%|████▎     | 17/40 [31:49<42:56, 112.00s/it]2025-03-03 18:47:53 - INFO - layer17_self_attn.q_proj | mse: 0.0012571961899667432, bpp_loss: 6.454829698577523, bpp: 0
2025-03-03 18:48:05 - INFO - layer17_self_attn.k_proj | mse: 0.001295677258772647, bpp_loss: 6.487135095968842, bpp: 0
2025-03-03 18:48:16 - INFO - layer17_self_attn.v_proj | mse: 0.0010614387359208768, bpp_loss: 6.0381186749041085, bpp: 0
2025-03-03 18:48:27 - INFO - layer17_self_attn.o_proj | mse: 0.0010799783019037063, bpp_loss: 6.029193652421236, bpp: 0
2025-03-03 18:48:42 - INFO - layer17_mlp.gate_proj | mse: 0.00111382299528432, bpp_loss: 6.223142213070834, bpp: 0
2025-03-03 18:48:56 - INFO - layer17_mlp.up_proj | mse: 0.0011035087511921226, bpp_loss: 6.190906997080202, bpp: 0
2025-03-03 18:49:34 - INFO - layer17_mlp.down_proj | mse: 0.0010585220149214529, bpp_loss: 6.18028814693292, bpp: 0
pseudo compress quantization...:  45%|████▌     | 18/40 [33:41<41:03, 111.98s/it]2025-03-03 18:49:45 - INFO - layer18_self_attn.q_proj | mse: 0.001253376844924783, bpp_loss: 6.463294989466667, bpp: 0
2025-03-03 18:49:57 - INFO - layer18_self_attn.k_proj | mse: 0.0012870706088253967, bpp_loss: 6.4961085003614425, bpp: 0
2025-03-03 18:50:08 - INFO - layer18_self_attn.v_proj | mse: 0.0010646179504366746, bpp_loss: 6.071688514947891, bpp: 0
2025-03-03 18:50:19 - INFO - layer18_self_attn.o_proj | mse: 0.0010960645363569585, bpp_loss: 6.056391741707921, bpp: 0
2025-03-03 18:50:34 - INFO - layer18_mlp.gate_proj | mse: 0.0011166266457852342, bpp_loss: 6.2320500569211115, bpp: 0
2025-03-03 18:50:48 - INFO - layer18_mlp.up_proj | mse: 0.001099278124819333, bpp_loss: 6.1851990203062694, bpp: 0
2025-03-03 18:51:25 - INFO - layer18_mlp.down_proj | mse: 0.0010513361476128516, bpp_loss: 6.176249252259732, bpp: 0
pseudo compress quantization...:  48%|████▊     | 19/40 [35:32<39:09, 111.90s/it]2025-03-03 18:51:37 - INFO - layer19_self_attn.q_proj | mse: 0.0012320498604632586, bpp_loss: 6.416759331077337, bpp: 0
2025-03-03 18:51:48 - INFO - layer19_self_attn.k_proj | mse: 0.0012603751727191352, bpp_loss: 6.440175747722387, bpp: 0
2025-03-03 18:52:00 - INFO - layer19_self_attn.v_proj | mse: 0.0010665862011584105, bpp_loss: 6.069822251945734, bpp: 0
2025-03-03 18:52:11 - INFO - layer19_self_attn.o_proj | mse: 0.0010573964344827661, bpp_loss: 6.056524664461612, bpp: 0
2025-03-03 18:52:25 - INFO - layer19_mlp.gate_proj | mse: 0.0011212952191562379, bpp_loss: 6.240130726606758, bpp: 0
2025-03-03 18:52:39 - INFO - layer19_mlp.up_proj | mse: 0.0010987133946544466, bpp_loss: 6.1832506670996, bpp: 0
2025-03-03 18:53:17 - INFO - layer19_mlp.down_proj | mse: 0.0010522813131160532, bpp_loss: 6.17509980113418, bpp: 0
pseudo compress quantization...:  50%|█████     | 20/40 [37:24<37:14, 111.72s/it]2025-03-03 18:53:28 - INFO - layer20_self_attn.q_proj | mse: 0.0012473674515819642, bpp_loss: 6.440122300088405, bpp: 0
2025-03-03 18:53:40 - INFO - layer20_self_attn.k_proj | mse: 0.0012743297632497304, bpp_loss: 6.468692555874586, bpp: 0
2025-03-03 18:53:51 - INFO - layer20_self_attn.v_proj | mse: 0.00106482943454425, bpp_loss: 6.06676591180265, bpp: 0
2025-03-03 18:54:02 - INFO - layer20_self_attn.o_proj | mse: 0.0010922027786117805, bpp_loss: 6.059424918144941, bpp: 0
2025-03-03 18:54:16 - INFO - layer20_mlp.gate_proj | mse: 0.001123066578281119, bpp_loss: 6.243368712177983, bpp: 0
2025-03-03 18:54:31 - INFO - layer20_mlp.up_proj | mse: 0.001099529631033517, bpp_loss: 6.182173390189806, bpp: 0
2025-03-03 18:55:08 - INFO - layer20_mlp.down_proj | mse: 0.0010487423717514186, bpp_loss: 6.1749434676435255, bpp: 0
pseudo compress quantization...:  52%|█████▎    | 21/40 [39:15<35:22, 111.72s/it]2025-03-03 18:55:20 - INFO - layer21_self_attn.q_proj | mse: 0.0012348649746689183, bpp_loss: 6.405746959075332, bpp: 0
2025-03-03 18:55:32 - INFO - layer21_self_attn.k_proj | mse: 0.0012615578613777185, bpp_loss: 6.425033440291881, bpp: 0
2025-03-03 18:55:43 - INFO - layer21_self_attn.v_proj | mse: 0.00108129726744476, bpp_loss: 6.096816473528743, bpp: 0
2025-03-03 18:55:54 - INFO - layer21_self_attn.o_proj | mse: 0.0010744308130281725, bpp_loss: 6.088844357579947, bpp: 0
2025-03-03 18:56:08 - INFO - layer21_mlp.gate_proj | mse: 0.0011393707905092171, bpp_loss: 6.251471718483501, bpp: 0
2025-03-03 18:56:23 - INFO - layer21_mlp.up_proj | mse: 0.00110756297986179, bpp_loss: 6.1753731145902915, bpp: 0
2025-03-03 18:57:00 - INFO - layer21_mlp.down_proj | mse: 0.0010485147285841775, bpp_loss: 6.171233121857599, bpp: 0
pseudo compress quantization...:  55%|█████▌    | 22/40 [41:07<33:32, 111.78s/it]2025-03-03 18:57:12 - INFO - layer22_self_attn.q_proj | mse: 0.0012207577679357606, bpp_loss: 6.393684476166964, bpp: 0
2025-03-03 18:57:24 - INFO - layer22_self_attn.k_proj | mse: 0.00123854062639943, bpp_loss: 6.4221382912248375, bpp: 0
2025-03-03 18:57:35 - INFO - layer22_self_attn.v_proj | mse: 0.0011062394133879445, bpp_loss: 6.15629740178585, bpp: 0
2025-03-03 18:57:46 - INFO - layer22_self_attn.o_proj | mse: 0.0010731685136397787, bpp_loss: 6.1411944390088316, bpp: 0
2025-03-03 18:58:00 - INFO - layer22_mlp.gate_proj | mse: 0.0011378796934284694, bpp_loss: 6.260535570096087, bpp: 0
2025-03-03 18:58:14 - INFO - layer22_mlp.up_proj | mse: 0.0010999941020659232, bpp_loss: 6.170780076583227, bpp: 0
2025-03-03 18:58:52 - INFO - layer22_mlp.down_proj | mse: 0.0010394809343885617, bpp_loss: 6.168941807388156, bpp: 0
pseudo compress quantization...:  57%|█████▊    | 23/40 [42:59<31:41, 111.84s/it]2025-03-03 18:59:04 - INFO - layer23_self_attn.q_proj | mse: 0.0012030690054147496, bpp_loss: 6.367369341775775, bpp: 0
2025-03-03 18:59:16 - INFO - layer23_self_attn.k_proj | mse: 0.0012234684727272145, bpp_loss: 6.383711266070605, bpp: 0
2025-03-03 18:59:27 - INFO - layer23_self_attn.v_proj | mse: 0.0011029618153064857, bpp_loss: 6.149607288762927, bpp: 0
2025-03-03 18:59:38 - INFO - layer23_self_attn.o_proj | mse: 0.0010398164848806663, bpp_loss: 6.140271403640509, bpp: 0
2025-03-03 18:59:52 - INFO - layer23_mlp.gate_proj | mse: 0.0011398642748864675, bpp_loss: 6.26845121273288, bpp: 0
2025-03-03 19:00:07 - INFO - layer23_mlp.up_proj | mse: 0.001095123551178887, bpp_loss: 6.166636154165975, bpp: 0
2025-03-03 19:00:44 - INFO - layer23_mlp.down_proj | mse: 0.0010328977377727202, bpp_loss: 6.166253356552787, bpp: 0
pseudo compress quantization...:  60%|██████    | 24/40 [44:51<29:49, 111.87s/it]2025-03-03 19:00:56 - INFO - layer24_self_attn.q_proj | mse: 0.0012076002117568936, bpp_loss: 6.379907158538699, bpp: 0
2025-03-03 19:01:07 - INFO - layer24_self_attn.k_proj | mse: 0.0012208427092238992, bpp_loss: 6.3980490987747904, bpp: 0
2025-03-03 19:01:19 - INFO - layer24_self_attn.v_proj | mse: 0.0010998962807411163, bpp_loss: 6.158875779807568, bpp: 0
2025-03-03 19:01:30 - INFO - layer24_self_attn.o_proj | mse: 0.0010432347633493012, bpp_loss: 6.146122428178788, bpp: 0
2025-03-03 19:01:44 - INFO - layer24_mlp.gate_proj | mse: 0.0011407654053426123, bpp_loss: 6.2732377458501745, bpp: 0
2025-03-03 19:01:58 - INFO - layer24_mlp.up_proj | mse: 0.0010928509822299033, bpp_loss: 6.165319693419669, bpp: 0
2025-03-03 19:02:36 - INFO - layer24_mlp.down_proj | mse: 0.0010263712802720923, bpp_loss: 6.166231105062697, bpp: 0
pseudo compress quantization...:  62%|██████▎   | 25/40 [46:43<27:58, 111.90s/it]2025-03-03 19:02:48 - INFO - layer25_self_attn.q_proj | mse: 0.0011961220132147292, bpp_loss: 6.370085249096155, bpp: 0
2025-03-03 19:03:00 - INFO - layer25_self_attn.k_proj | mse: 0.0012103324705450649, bpp_loss: 6.383767752572894, bpp: 0
2025-03-03 19:03:11 - INFO - layer25_self_attn.v_proj | mse: 0.0011088531251941707, bpp_loss: 6.186189609616995, bpp: 0
2025-03-03 19:03:22 - INFO - layer25_self_attn.o_proj | mse: 0.0010392340634424889, bpp_loss: 6.1778892596811055, bpp: 0
2025-03-03 19:03:36 - INFO - layer25_mlp.gate_proj | mse: 0.0011409672970203464, bpp_loss: 6.277942299070181, bpp: 0
2025-03-03 19:03:51 - INFO - layer25_mlp.up_proj | mse: 0.0010901245003592114, bpp_loss: 6.164331152814406, bpp: 0
2025-03-03 19:04:28 - INFO - layer25_mlp.down_proj | mse: 0.0010221169625289563, bpp_loss: 6.165540357679129, bpp: 0
pseudo compress quantization...:  65%|██████▌   | 26/40 [48:35<26:07, 111.95s/it]2025-03-03 19:04:40 - INFO - layer26_self_attn.q_proj | mse: 0.0012119495997073742, bpp_loss: 6.380260240137577, bpp: 0
2025-03-03 19:04:51 - INFO - layer26_self_attn.k_proj | mse: 0.0012274364939938427, bpp_loss: 6.395423379614949, bpp: 0
2025-03-03 19:05:03 - INFO - layer26_self_attn.v_proj | mse: 0.0011266378377650845, bpp_loss: 6.207678318247199, bpp: 0
2025-03-03 19:05:14 - INFO - layer26_self_attn.o_proj | mse: 0.0010669661772618295, bpp_loss: 6.179322137236595, bpp: 0
2025-03-03 19:05:28 - INFO - layer26_mlp.gate_proj | mse: 0.0011435962665841055, bpp_loss: 6.28109579163569, bpp: 0
2025-03-03 19:05:42 - INFO - layer26_mlp.up_proj | mse: 0.0010905760956468641, bpp_loss: 6.1655213988489574, bpp: 0
2025-03-03 19:06:20 - INFO - layer26_mlp.down_proj | mse: 0.0010209224367690296, bpp_loss: 6.166855014584683, bpp: 0
pseudo compress quantization...:  68%|██████▊   | 27/40 [50:27<24:14, 111.89s/it]2025-03-03 19:06:32 - INFO - layer27_self_attn.q_proj | mse: 0.0011894373771898052, bpp_loss: 6.382465164288878, bpp: 0
2025-03-03 19:06:43 - INFO - layer27_self_attn.k_proj | mse: 0.001201901265495825, bpp_loss: 6.39414909824729, bpp: 0
2025-03-03 19:06:54 - INFO - layer27_self_attn.v_proj | mse: 0.0011079006934790134, bpp_loss: 6.200220829173922, bpp: 0
2025-03-03 19:07:06 - INFO - layer27_self_attn.o_proj | mse: 0.001055872821854601, bpp_loss: 6.183355548679828, bpp: 0
2025-03-03 19:07:20 - INFO - layer27_mlp.gate_proj | mse: 0.0011427127329791237, bpp_loss: 6.285532574852308, bpp: 0
2025-03-03 19:07:34 - INFO - layer27_mlp.up_proj | mse: 0.0010879040352573303, bpp_loss: 6.166347313148004, bpp: 0
2025-03-03 19:08:12 - INFO - layer27_mlp.down_proj | mse: 0.001016964261155223, bpp_loss: 6.167815522408044, bpp: 0
pseudo compress quantization...:  70%|███████   | 28/40 [52:19<22:23, 111.96s/it]2025-03-03 19:08:24 - INFO - layer28_self_attn.q_proj | mse: 0.0011854563771724654, bpp_loss: 6.376189508587122, bpp: 0
2025-03-03 19:08:35 - INFO - layer28_self_attn.k_proj | mse: 0.0011951407269555794, bpp_loss: 6.386379412412643, bpp: 0
2025-03-03 19:08:47 - INFO - layer28_self_attn.v_proj | mse: 0.0011047047919980153, bpp_loss: 6.207855116575956, bpp: 0
2025-03-03 19:08:58 - INFO - layer28_self_attn.o_proj | mse: 0.001097169816038084, bpp_loss: 6.1884252618998286, bpp: 0
2025-03-03 19:09:12 - INFO - layer28_mlp.gate_proj | mse: 0.001136457782016197, bpp_loss: 6.287463956409031, bpp: 0
2025-03-03 19:09:27 - INFO - layer28_mlp.up_proj | mse: 0.001082378709830432, bpp_loss: 6.169351502701089, bpp: 0
2025-03-03 19:10:05 - INFO - layer28_mlp.down_proj | mse: 0.0010133275499687607, bpp_loss: 6.1705016840663225, bpp: 0
pseudo compress quantization...:  72%|███████▎  | 29/40 [54:12<20:32, 112.06s/it]2025-03-03 19:10:16 - INFO - layer29_self_attn.q_proj | mse: 0.00118630451535512, bpp_loss: 6.398496092632413, bpp: 0
2025-03-03 19:10:28 - INFO - layer29_self_attn.k_proj | mse: 0.00119616871354095, bpp_loss: 6.416870988234877, bpp: 0
2025-03-03 19:10:39 - INFO - layer29_self_attn.v_proj | mse: 0.001099806935948272, bpp_loss: 6.212220309972763, bpp: 0
2025-03-03 19:10:50 - INFO - layer29_self_attn.o_proj | mse: 0.0010538598407955917, bpp_loss: 6.198675211295486, bpp: 0
2025-03-03 19:11:04 - INFO - layer29_mlp.gate_proj | mse: 0.0011404439409152677, bpp_loss: 6.286123610094742, bpp: 0
2025-03-03 19:11:19 - INFO - layer29_mlp.up_proj | mse: 0.001086425813921336, bpp_loss: 6.1733057365373325, bpp: 0
2025-03-03 19:11:56 - INFO - layer29_mlp.down_proj | mse: 0.0010128908047067236, bpp_loss: 6.174323153661357, bpp: 0
pseudo compress quantization...:  75%|███████▌  | 30/40 [56:03<18:39, 111.96s/it]2025-03-03 19:12:08 - INFO - layer30_self_attn.q_proj | mse: 0.0011720912768639177, bpp_loss: 6.375462978631258, bpp: 0
2025-03-03 19:12:19 - INFO - layer30_self_attn.k_proj | mse: 0.001179610840557379, bpp_loss: 6.383618030697107, bpp: 0
2025-03-03 19:12:31 - INFO - layer30_self_attn.v_proj | mse: 0.0011219366329649606, bpp_loss: 6.263977089375257, bpp: 0
2025-03-03 19:12:42 - INFO - layer30_self_attn.o_proj | mse: 0.0010613301547653712, bpp_loss: 6.255264810249209, bpp: 0
2025-03-03 19:12:56 - INFO - layer30_mlp.gate_proj | mse: 0.0011291798960517577, bpp_loss: 6.289265596204334, bpp: 0
2025-03-03 19:13:10 - INFO - layer30_mlp.up_proj | mse: 0.0010769310680635465, bpp_loss: 6.175932266866719, bpp: 0
2025-03-03 19:13:48 - INFO - layer30_mlp.down_proj | mse: 0.0010121212643619593, bpp_loss: 6.176142649490524, bpp: 0
pseudo compress quantization...:  78%|███████▊  | 31/40 [57:55<16:46, 111.87s/it]2025-03-03 19:14:00 - INFO - layer31_self_attn.q_proj | mse: 0.0011765903839743913, bpp_loss: 6.391356021091342, bpp: 0
2025-03-03 19:14:11 - INFO - layer31_self_attn.k_proj | mse: 0.001190148195554664, bpp_loss: 6.417560977116227, bpp: 0
2025-03-03 19:14:22 - INFO - layer31_self_attn.v_proj | mse: 0.001101023693827473, bpp_loss: 6.227257356420159, bpp: 0
2025-03-03 19:14:34 - INFO - layer31_self_attn.o_proj | mse: 0.001071568534969481, bpp_loss: 6.213645082786679, bpp: 0
2025-03-03 19:14:48 - INFO - layer31_mlp.gate_proj | mse: 0.0011259263670291581, bpp_loss: 6.290523529825387, bpp: 0
2025-03-03 19:15:02 - INFO - layer31_mlp.up_proj | mse: 0.0010746071678121457, bpp_loss: 6.1789734447443925, bpp: 0
2025-03-03 19:15:40 - INFO - layer31_mlp.down_proj | mse: 0.0010111637381437944, bpp_loss: 6.179230447886167, bpp: 0
pseudo compress quantization...:  80%|████████  | 32/40 [59:47<14:55, 111.93s/it]2025-03-03 19:15:52 - INFO - layer32_self_attn.q_proj | mse: 0.0011567349812564834, bpp_loss: 6.354821555390954, bpp: 0
2025-03-03 19:16:03 - INFO - layer32_self_attn.k_proj | mse: 0.0011635167261483377, bpp_loss: 6.363317115828395, bpp: 0
2025-03-03 19:16:14 - INFO - layer32_self_attn.v_proj | mse: 0.0011200050008613037, bpp_loss: 6.267855602651834, bpp: 0
2025-03-03 19:16:26 - INFO - layer32_self_attn.o_proj | mse: 0.001102705484979934, bpp_loss: 6.258970605134964, bpp: 0
2025-03-03 19:16:40 - INFO - layer32_mlp.gate_proj | mse: 0.0011198542516417302, bpp_loss: 6.287746595674091, bpp: 0
2025-03-03 19:16:54 - INFO - layer32_mlp.up_proj | mse: 0.001072792288669998, bpp_loss: 6.184652559735157, bpp: 0
2025-03-03 19:17:32 - INFO - layer32_mlp.down_proj | mse: 0.001013358709271064, bpp_loss: 6.184206470681561, bpp: 0
pseudo compress quantization...:  82%|████████▎ | 33/40 [1:01:39<13:03, 111.98s/it]2025-03-03 19:17:44 - INFO - layer33_self_attn.q_proj | mse: 0.0011539585715395525, bpp_loss: 6.356063736900687, bpp: 0
2025-03-03 19:17:55 - INFO - layer33_self_attn.k_proj | mse: 0.0011630866891493173, bpp_loss: 6.374310647472739, bpp: 0
2025-03-03 19:18:06 - INFO - layer33_self_attn.v_proj | mse: 0.0011049938009647512, bpp_loss: 6.244874989241362, bpp: 0
2025-03-03 19:18:18 - INFO - layer33_self_attn.o_proj | mse: 0.0010698853532365865, bpp_loss: 6.235842308923602, bpp: 0
2025-03-03 19:18:32 - INFO - layer33_mlp.gate_proj | mse: 0.001120473317449476, bpp_loss: 6.286664733842567, bpp: 0
2025-03-03 19:18:46 - INFO - layer33_mlp.up_proj | mse: 0.0010758315652999004, bpp_loss: 6.1901685645182924, bpp: 0
2025-03-03 19:19:24 - INFO - layer33_mlp.down_proj | mse: 0.0010185919269686556, bpp_loss: 6.189892989314265, bpp: 0
pseudo compress quantization...:  85%|████████▌ | 34/40 [1:03:31<11:11, 111.90s/it]2025-03-03 19:19:36 - INFO - layer34_self_attn.q_proj | mse: 0.0011369956920047617, bpp_loss: 6.317160847112536, bpp: 0
2025-03-03 19:19:47 - INFO - layer34_self_attn.k_proj | mse: 0.0011466214056462685, bpp_loss: 6.331552472412586, bpp: 0
2025-03-03 19:19:58 - INFO - layer34_self_attn.v_proj | mse: 0.0011191099305890228, bpp_loss: 6.2731971855461595, bpp: 0
2025-03-03 19:20:10 - INFO - layer34_self_attn.o_proj | mse: 0.0010906197186700889, bpp_loss: 6.267494428530336, bpp: 0
2025-03-03 19:20:24 - INFO - layer34_mlp.gate_proj | mse: 0.00111667385684933, bpp_loss: 6.280989989748708, bpp: 0
2025-03-03 19:20:38 - INFO - layer34_mlp.up_proj | mse: 0.0010789546201089982, bpp_loss: 6.199192708620319, bpp: 0
2025-03-03 19:21:16 - INFO - layer34_mlp.down_proj | mse: 0.001024959755293921, bpp_loss: 6.19897223851747, bpp: 0
pseudo compress quantization...:  88%|████████▊ | 35/40 [1:05:23<09:20, 112.05s/it]2025-03-03 19:21:28 - INFO - layer35_self_attn.q_proj | mse: 0.0011283796556395863, bpp_loss: 6.306753340363502, bpp: 0
2025-03-03 19:21:39 - INFO - layer35_self_attn.k_proj | mse: 0.0011377731423487197, bpp_loss: 6.323840539827943, bpp: 0
2025-03-03 19:21:50 - INFO - layer35_self_attn.v_proj | mse: 0.0011182289978844816, bpp_loss: 6.274834593832493, bpp: 0
2025-03-03 19:22:02 - INFO - layer35_self_attn.o_proj | mse: 0.0011075682288737346, bpp_loss: 6.268118339180947, bpp: 0
2025-03-03 19:22:16 - INFO - layer35_mlp.gate_proj | mse: 0.0011122235702710466, bpp_loss: 6.2744980765713585, bpp: 0
2025-03-03 19:22:30 - INFO - layer35_mlp.up_proj | mse: 0.0010826165677551773, bpp_loss: 6.209099525213242, bpp: 0
2025-03-03 19:23:08 - INFO - layer35_mlp.down_proj | mse: 0.001032669064545899, bpp_loss: 6.208860714595627, bpp: 0
pseudo compress quantization...:  90%|█████████ | 36/40 [1:07:15<07:27, 111.99s/it]2025-03-03 19:23:20 - INFO - layer36_self_attn.q_proj | mse: 0.0011273384585400986, bpp_loss: 6.306647394001484, bpp: 0
2025-03-03 19:23:31 - INFO - layer36_self_attn.k_proj | mse: 0.0011410559551068037, bpp_loss: 6.329537675380707, bpp: 0
2025-03-03 19:23:42 - INFO - layer36_self_attn.v_proj | mse: 0.0011313796011611817, bpp_loss: 6.3014246840029955, bpp: 0
2025-03-03 19:23:54 - INFO - layer36_self_attn.o_proj | mse: 0.001155548584383411, bpp_loss: 6.295313469916582, bpp: 0
2025-03-03 19:24:08 - INFO - layer36_mlp.gate_proj | mse: 0.0011103066293921533, bpp_loss: 6.2709994249873695, bpp: 0
2025-03-03 19:24:22 - INFO - layer36_mlp.up_proj | mse: 0.0010856836559937472, bpp_loss: 6.215092840349233, bpp: 0
2025-03-03 19:25:00 - INFO - layer36_mlp.down_proj | mse: 0.0010420642379775952, bpp_loss: 6.211846437636349, bpp: 0
pseudo compress quantization...:  92%|█████████▎| 37/40 [1:09:07<05:35, 111.94s/it]2025-03-03 19:25:12 - INFO - layer37_self_attn.q_proj | mse: 0.0011033546542789133, bpp_loss: 6.240594627559185, bpp: 0
2025-03-03 19:25:23 - INFO - layer37_self_attn.k_proj | mse: 0.001110604677131706, bpp_loss: 6.238903647959233, bpp: 0
2025-03-03 19:25:34 - INFO - layer37_self_attn.v_proj | mse: 0.0011470639578691892, bpp_loss: 6.325383072122931, bpp: 0
2025-03-03 19:25:46 - INFO - layer37_self_attn.o_proj | mse: 0.0012105315553104425, bpp_loss: 6.317246018350124, bpp: 0
2025-03-03 19:26:00 - INFO - layer37_mlp.gate_proj | mse: 0.0011138616225185804, bpp_loss: 6.275524584783448, bpp: 0
2025-03-03 19:26:15 - INFO - layer37_mlp.up_proj | mse: 0.0010912047753440257, bpp_loss: 6.2232909458654895, bpp: 0
2025-03-03 19:26:53 - INFO - layer37_mlp.down_proj | mse: 0.0010530229560138519, bpp_loss: 6.21453384100287, bpp: 0
pseudo compress quantization...:  95%|█████████▌| 38/40 [1:11:00<03:44, 112.20s/it]2025-03-03 19:27:05 - INFO - layer38_self_attn.q_proj | mse: 0.0010927635301715378, bpp_loss: 6.212476458027959, bpp: 0
2025-03-03 19:27:16 - INFO - layer38_self_attn.k_proj | mse: 0.0011018122688148978, bpp_loss: 6.220099667459726, bpp: 0
2025-03-03 19:27:27 - INFO - layer38_self_attn.v_proj | mse: 0.001182361756299698, bpp_loss: 6.38581793859601, bpp: 0
2025-03-03 19:27:39 - INFO - layer38_self_attn.o_proj | mse: 0.001253403845361531, bpp_loss: 6.384773493781686, bpp: 0
2025-03-03 19:27:53 - INFO - layer38_mlp.gate_proj | mse: 0.0011402681440802341, bpp_loss: 6.313996580022352, bpp: 0
2025-03-03 19:28:08 - INFO - layer38_mlp.up_proj | mse: 0.0011016376479645515, bpp_loss: 6.228598592016432, bpp: 0
2025-03-03 19:28:46 - INFO - layer38_mlp.down_proj | mse: 0.0010898105897021223, bpp_loss: 6.202396563826888, bpp: 0
pseudo compress quantization...:  98%|█████████▊| 39/40 [1:12:53<01:52, 112.44s/it]2025-03-03 19:28:58 - INFO - layer39_self_attn.q_proj | mse: 0.001105051625934439, bpp_loss: 6.205521697178483, bpp: 0
2025-03-03 19:29:09 - INFO - layer39_self_attn.k_proj | mse: 0.0011186744471499716, bpp_loss: 6.21834880925715, bpp: 0
2025-03-03 19:29:20 - INFO - layer39_self_attn.v_proj | mse: 0.0011431163317822506, bpp_loss: 6.265996859669685, bpp: 0
2025-03-03 19:29:32 - INFO - layer39_self_attn.o_proj | mse: 0.0021724048480835567, bpp_loss: 6.269686199426651, bpp: 0
2025-03-03 19:29:46 - INFO - layer39_mlp.gate_proj | mse: 0.0011930730325651977, bpp_loss: 6.394454715649287, bpp: 0
2025-03-03 19:30:00 - INFO - layer39_mlp.up_proj | mse: 0.0011365050789185914, bpp_loss: 6.273229471732069, bpp: 0
2025-03-03 19:30:39 - INFO - layer39_mlp.down_proj | mse: 0.0012680579364773466, bpp_loss: 6.196012506496023, bpp: 0
pseudo compress quantization...: 100%|██████████| 40/40 [1:14:46<00:00, 112.57s/it]pseudo compress quantization...: 100%|██████████| 40/40 [1:14:46<00:00, 112.15s/it]
2025-03-03 19:30:39 - INFO - #### Total | mse: 0.0016206134622233131, bpp_loss: 6.211018531189016, bpp: 0 ####
## Strart saving /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/best_loss_model_loss_49.72731_bpp_6.30559_MSE_0.00042_total_iter_140000.pth.tar/COL_MSE0.00162_bpploss6.211_bpp0
## End saving
Running evaluation for directory: /home/jgryu/Weight_compression/comp_llm/model_lm_reconstructed/ldlq/meta-llama--Llama-2-13b-hf/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/best_loss_model_loss_49.72731_bpp_6.30559_MSE_0.00042_total_iter_140000.pth.tar/COL_MSE0.00162_bpploss6.211_bpp0
I0303 19:31:17.596311 3393930 modeling.py:879] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.59it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:01<00:02,  1.59it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:01<00:01,  1.57it/s]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:02<00:01,  1.60it/s]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:02<00:00,  2.01it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]
W0303 19:31:20.666675 3393930 big_modeling.py:414] Some parameters are on the meta device device because they were offloaded to the cpu.
I0303 19:31:20.681360 3393930 config.py:54] PyTorch version 2.4.1 available.
  0%|          | 0/166 [00:00<?, ?it/s]avg_loss = 1.2421875:   0%|          | 0/166 [00:01<?, ?it/s]avg_loss = 1.2421875:   1%|          | 1/166 [00:01<03:27,  1.26s/it]avg_loss = 1.5390625:   1%|          | 1/166 [00:02<03:27,  1.26s/it]avg_loss = 1.5390625:   1%|          | 2/166 [00:02<02:57,  1.08s/it]avg_loss = 1.7083333333333333:   1%|          | 2/166 [00:03<02:57,  1.08s/it]avg_loss = 1.7083333333333333:   2%|▏         | 3/166 [00:03<02:50,  1.05s/it]avg_loss = 1.736328125:   2%|▏         | 3/166 [00:04<02:50,  1.05s/it]       avg_loss = 1.736328125:   2%|▏         | 4/166 [00:04<02:46,  1.03s/it]avg_loss = 1.6703125:   2%|▏         | 4/166 [00:05<02:46,  1.03s/it]  avg_loss = 1.6703125:   3%|▎         | 5/166 [00:05<02:43,  1.02s/it]avg_loss = 1.640625:   3%|▎         | 5/166 [00:06<02:43,  1.02s/it] avg_loss = 1.640625:   4%|▎         | 6/166 [00:06<02:41,  1.01s/it]avg_loss = 1.5770089285714286:   4%|▎         | 6/166 [00:07<02:41,  1.01s/it]avg_loss = 1.5770089285714286:   4%|▍         | 7/166 [00:07<02:41,  1.02s/it]avg_loss = 1.509765625:   4%|▍         | 7/166 [00:08<02:41,  1.02s/it]       avg_loss = 1.509765625:   5%|▍         | 8/166 [00:08<02:41,  1.02s/it]avg_loss = 1.5069444444444444:   5%|▍         | 8/166 [00:09<02:41,  1.02s/it]avg_loss = 1.5069444444444444:   5%|▌         | 9/166 [00:09<02:41,  1.03s/it]avg_loss = 1.5171875:   5%|▌         | 9/166 [00:10<02:41,  1.03s/it]         avg_loss = 1.5171875:   6%|▌         | 10/166 [00:10<02:41,  1.03s/it]avg_loss = 1.5348011363636365:   6%|▌         | 10/166 [00:11<02:41,  1.03s/it]avg_loss = 1.5348011363636365:   7%|▋         | 11/166 [00:11<02:40,  1.03s/it]avg_loss = 1.544921875:   7%|▋         | 11/166 [00:12<02:40,  1.03s/it]       avg_loss = 1.544921875:   7%|▋         | 12/166 [00:12<02:39,  1.03s/it]avg_loss = 1.5414663461538463:   7%|▋         | 12/166 [00:13<02:39,  1.03s/it]avg_loss = 1.5414663461538463:   8%|▊         | 13/166 [00:13<02:37,  1.03s/it]avg_loss = 1.5552455357142858:   8%|▊         | 13/166 [00:14<02:37,  1.03s/it]avg_loss = 1.5552455357142858:   8%|▊         | 14/166 [00:14<02:37,  1.04s/it]avg_loss = 1.5713541666666666:   8%|▊         | 14/166 [00:15<02:37,  1.04s/it]avg_loss = 1.5713541666666666:   9%|▉         | 15/166 [00:15<02:36,  1.04s/it]avg_loss = 1.5888671875:   9%|▉         | 15/166 [00:16<02:36,  1.04s/it]      avg_loss = 1.5888671875:  10%|▉         | 16/166 [00:16<02:36,  1.04s/it]avg_loss = 1.5978860294117647:  10%|▉         | 16/166 [00:17<02:36,  1.04s/it]avg_loss = 1.5978860294117647:  10%|█         | 17/166 [00:17<02:37,  1.05s/it]avg_loss = 1.6115451388888888:  10%|█         | 17/166 [00:18<02:37,  1.05s/it]avg_loss = 1.6115451388888888:  11%|█         | 18/166 [00:18<02:35,  1.05s/it]avg_loss = 1.6307565789473684:  11%|█         | 18/166 [00:19<02:35,  1.05s/it]avg_loss = 1.6307565789473684:  11%|█▏        | 19/166 [00:19<02:34,  1.05s/it]avg_loss = 1.6375:  11%|█▏        | 19/166 [00:20<02:34,  1.05s/it]            avg_loss = 1.6375:  12%|█▏        | 20/166 [00:20<02:31,  1.04s/it]avg_loss = 1.6376488095238095:  12%|█▏        | 20/166 [00:21<02:31,  1.04s/it]avg_loss = 1.6376488095238095:  13%|█▎        | 21/166 [00:21<02:32,  1.05s/it]avg_loss = 1.6271306818181819:  13%|█▎        | 21/166 [00:22<02:32,  1.05s/it]avg_loss = 1.6271306818181819:  13%|█▎        | 22/166 [00:22<02:29,  1.04s/it]avg_loss = 1.6103940217391304:  13%|█▎        | 22/166 [00:23<02:29,  1.04s/it]avg_loss = 1.6103940217391304:  14%|█▍        | 23/166 [00:23<02:29,  1.05s/it]avg_loss = 1.6184895833333333:  14%|█▍        | 23/166 [00:24<02:29,  1.05s/it]avg_loss = 1.6184895833333333:  14%|█▍        | 24/166 [00:24<02:27,  1.04s/it]avg_loss = 1.6259375:  14%|█▍        | 24/166 [00:26<02:27,  1.04s/it]         avg_loss = 1.6259375:  15%|█▌        | 25/166 [00:26<02:27,  1.05s/it]avg_loss = 1.6304086538461537:  15%|█▌        | 25/166 [00:27<02:27,  1.05s/it]avg_loss = 1.6304086538461537:  16%|█▌        | 26/166 [00:27<02:25,  1.04s/it]avg_loss = 1.6371527777777777:  16%|█▌        | 26/166 [00:28<02:25,  1.04s/it]avg_loss = 1.6371527777777777:  16%|█▋        | 27/166 [00:28<02:25,  1.05s/it]avg_loss = 1.6395089285714286:  16%|█▋        | 27/166 [00:29<02:25,  1.05s/it]avg_loss = 1.6395089285714286:  17%|█▋        | 28/166 [00:29<02:23,  1.04s/it]avg_loss = 1.6495150862068966:  17%|█▋        | 28/166 [00:30<02:23,  1.04s/it]avg_loss = 1.6495150862068966:  17%|█▋        | 29/166 [00:30<02:22,  1.04s/it]avg_loss = 1.6502604166666666:  17%|█▋        | 29/166 [00:31<02:22,  1.04s/it]avg_loss = 1.6502604166666666:  18%|█▊        | 30/166 [00:31<02:20,  1.03s/it]avg_loss = 1.665070564516129:  18%|█▊        | 30/166 [00:32<02:20,  1.03s/it] avg_loss = 1.665070564516129:  19%|█▊        | 31/166 [00:32<02:19,  1.03s/it]avg_loss = 1.67236328125:  19%|█▊        | 31/166 [00:33<02:19,  1.03s/it]    avg_loss = 1.67236328125:  19%|█▉        | 32/166 [00:33<02:17,  1.03s/it]avg_loss = 1.6773200757575757:  19%|█▉        | 32/166 [00:34<02:17,  1.03s/it]avg_loss = 1.6773200757575757:  20%|█▉        | 33/166 [00:34<02:16,  1.03s/it]avg_loss = 1.6753216911764706:  20%|█▉        | 33/166 [00:35<02:16,  1.03s/it]avg_loss = 1.6753216911764706:  20%|██        | 34/166 [00:35<02:14,  1.02s/it]avg_loss = 1.6685267857142858:  20%|██        | 34/166 [00:36<02:14,  1.02s/it]avg_loss = 1.6685267857142858:  21%|██        | 35/166 [00:36<02:14,  1.03s/it]avg_loss = 1.6586371527777777:  21%|██        | 35/166 [00:37<02:14,  1.03s/it]avg_loss = 1.6586371527777777:  22%|██▏       | 36/166 [00:37<02:12,  1.02s/it]avg_loss = 1.6480152027027026:  22%|██▏       | 36/166 [00:38<02:12,  1.02s/it]avg_loss = 1.6480152027027026:  22%|██▏       | 37/166 [00:38<02:11,  1.02s/it]avg_loss = 1.64453125:  22%|██▏       | 37/166 [00:39<02:11,  1.02s/it]        avg_loss = 1.64453125:  23%|██▎       | 38/166 [00:39<02:10,  1.02s/it]avg_loss = 1.6420272435897436:  23%|██▎       | 38/166 [00:40<02:10,  1.02s/it]avg_loss = 1.6420272435897436:  23%|██▎       | 39/166 [00:40<02:10,  1.03s/it]avg_loss = 1.6466796875:  23%|██▎       | 39/166 [00:41<02:10,  1.03s/it]      avg_loss = 1.6466796875:  24%|██▍       | 40/166 [00:41<02:09,  1.02s/it]avg_loss = 1.6476753048780488:  24%|██▍       | 40/166 [00:42<02:09,  1.02s/it]avg_loss = 1.6476753048780488:  25%|██▍       | 41/166 [00:42<02:09,  1.04s/it]avg_loss = 1.6365327380952381:  25%|██▍       | 41/166 [00:43<02:09,  1.04s/it]avg_loss = 1.6365327380952381:  25%|██▌       | 42/166 [00:43<02:07,  1.03s/it]avg_loss = 1.621547965116279:  25%|██▌       | 42/166 [00:44<02:07,  1.03s/it] avg_loss = 1.621547965116279:  26%|██▌       | 43/166 [00:44<02:08,  1.04s/it]avg_loss = 1.6122159090909092:  26%|██▌       | 43/166 [00:45<02:08,  1.04s/it]avg_loss = 1.6122159090909092:  27%|██▋       | 44/166 [00:45<02:06,  1.04s/it]avg_loss = 1.5991319444444445:  27%|██▋       | 44/166 [00:46<02:06,  1.04s/it]avg_loss = 1.5991319444444445:  27%|██▋       | 45/166 [00:46<02:06,  1.05s/it]avg_loss = 1.589164402173913:  27%|██▋       | 45/166 [00:47<02:06,  1.05s/it] avg_loss = 1.589164402173913:  28%|██▊       | 46/166 [00:47<02:04,  1.04s/it]avg_loss = 1.5829454787234043:  28%|██▊       | 46/166 [00:48<02:04,  1.04s/it]avg_loss = 1.5829454787234043:  28%|██▊       | 47/166 [00:48<02:04,  1.05s/it]avg_loss = 1.5838216145833333:  28%|██▊       | 47/166 [00:49<02:04,  1.05s/it]avg_loss = 1.5838216145833333:  29%|██▉       | 48/166 [00:49<02:02,  1.04s/it]avg_loss = 1.5948660714285714:  29%|██▉       | 48/166 [00:50<02:02,  1.04s/it]avg_loss = 1.5948660714285714:  30%|██▉       | 49/166 [00:50<02:01,  1.04s/it]avg_loss = 1.60609375:  30%|██▉       | 49/166 [00:51<02:01,  1.04s/it]        avg_loss = 1.60609375:  30%|███       | 50/166 [00:51<02:01,  1.04s/it]avg_loss = 1.6127450980392157:  30%|███       | 50/166 [00:52<02:01,  1.04s/it]avg_loss = 1.6127450980392157:  31%|███       | 51/166 [00:52<01:59,  1.04s/it]avg_loss = 1.6167367788461537:  31%|███       | 51/166 [00:53<01:59,  1.04s/it]avg_loss = 1.6167367788461537:  31%|███▏      | 52/166 [00:53<01:59,  1.05s/it]avg_loss = 1.6199882075471699:  31%|███▏      | 52/166 [00:55<01:59,  1.05s/it]avg_loss = 1.6199882075471699:  32%|███▏      | 53/166 [00:55<01:58,  1.05s/it]avg_loss = 1.6216724537037037:  32%|███▏      | 53/166 [00:56<01:58,  1.05s/it]avg_loss = 1.6216724537037037:  33%|███▎      | 54/166 [00:56<01:57,  1.05s/it]avg_loss = 1.625:  33%|███▎      | 54/166 [00:57<01:57,  1.05s/it]             avg_loss = 1.625:  33%|███▎      | 55/166 [00:57<01:56,  1.05s/it]avg_loss = 1.6290457589285714:  33%|███▎      | 55/166 [00:58<01:56,  1.05s/it]avg_loss = 1.6290457589285714:  34%|███▎      | 56/166 [00:58<01:55,  1.05s/it]avg_loss = 1.6245888157894737:  34%|███▎      | 56/166 [00:59<01:55,  1.05s/it]avg_loss = 1.6245888157894737:  34%|███▍      | 57/166 [00:59<01:54,  1.05s/it]avg_loss = 1.6283674568965518:  34%|███▍      | 57/166 [01:00<01:54,  1.05s/it]avg_loss = 1.6283674568965518:  35%|███▍      | 58/166 [01:00<01:53,  1.05s/it]avg_loss = 1.6267213983050848:  35%|███▍      | 58/166 [01:01<01:53,  1.05s/it]avg_loss = 1.6267213983050848:  36%|███▌      | 59/166 [01:01<01:52,  1.05s/it]avg_loss = 1.622265625:  36%|███▌      | 59/166 [01:02<01:52,  1.05s/it]       avg_loss = 1.622265625:  36%|███▌      | 60/166 [01:02<01:51,  1.05s/it]avg_loss = 1.618468237704918:  36%|███▌      | 60/166 [01:03<01:51,  1.05s/it]avg_loss = 1.618468237704918:  37%|███▋      | 61/166 [01:03<01:49,  1.05s/it]avg_loss = 1.6150453629032258:  37%|███▋      | 61/166 [01:04<01:49,  1.05s/it]avg_loss = 1.6150453629032258:  37%|███▋      | 62/166 [01:04<01:49,  1.05s/it]avg_loss = 1.609499007936508:  37%|███▋      | 62/166 [01:05<01:49,  1.05s/it] avg_loss = 1.609499007936508:  38%|███▊      | 63/166 [01:05<01:47,  1.05s/it]avg_loss = 1.6053466796875:  38%|███▊      | 63/166 [01:06<01:47,  1.05s/it]  avg_loss = 1.6053466796875:  39%|███▊      | 64/166 [01:06<01:47,  1.05s/it]avg_loss = 1.5984375:  39%|███▊      | 64/166 [01:07<01:47,  1.05s/it]      avg_loss = 1.5984375:  39%|███▉      | 65/166 [01:07<01:45,  1.05s/it]avg_loss = 1.591500946969697:  39%|███▉      | 65/166 [01:08<01:45,  1.05s/it]avg_loss = 1.591500946969697:  40%|███▉      | 66/166 [01:08<01:45,  1.05s/it]avg_loss = 1.5854710820895523:  40%|███▉      | 66/166 [01:09<01:45,  1.05s/it]avg_loss = 1.5854710820895523:  40%|████      | 67/166 [01:09<01:44,  1.05s/it]avg_loss = 1.5842141544117647:  40%|████      | 67/166 [01:10<01:44,  1.05s/it]avg_loss = 1.5842141544117647:  41%|████      | 68/166 [01:10<01:43,  1.05s/it]avg_loss = 1.5859375:  41%|████      | 68/166 [01:11<01:43,  1.05s/it]         avg_loss = 1.5859375:  42%|████▏     | 69/166 [01:11<01:42,  1.06s/it]avg_loss = 1.5891741071428571:  42%|████▏     | 69/166 [01:12<01:42,  1.06s/it]avg_loss = 1.5891741071428571:  42%|████▏     | 70/166 [01:12<01:40,  1.04s/it]avg_loss = 1.5934198943661972:  42%|████▏     | 70/166 [01:13<01:40,  1.04s/it]avg_loss = 1.5934198943661972:  43%|████▎     | 71/166 [01:13<01:38,  1.04s/it]avg_loss = 1.5989583333333333:  43%|████▎     | 71/166 [01:14<01:38,  1.04s/it]avg_loss = 1.5989583333333333:  43%|████▎     | 72/166 [01:14<01:37,  1.03s/it]avg_loss = 1.605308219178082:  43%|████▎     | 72/166 [01:15<01:37,  1.03s/it] avg_loss = 1.605308219178082:  44%|████▍     | 73/166 [01:15<01:36,  1.04s/it]avg_loss = 1.599556587837838:  44%|████▍     | 73/166 [01:16<01:36,  1.04s/it]avg_loss = 1.599556587837838:  45%|████▍     | 74/166 [01:16<01:35,  1.03s/it]avg_loss = 1.595:  45%|████▍     | 74/166 [01:18<01:35,  1.03s/it]            avg_loss = 1.595:  45%|████▌     | 75/166 [01:18<01:34,  1.04s/it]avg_loss = 1.593955592105263:  45%|████▌     | 75/166 [01:19<01:34,  1.04s/it]avg_loss = 1.593955592105263:  46%|████▌     | 76/166 [01:19<01:32,  1.03s/it]avg_loss = 1.5906047077922079:  46%|████▌     | 76/166 [01:20<01:32,  1.03s/it]avg_loss = 1.5906047077922079:  46%|████▋     | 77/166 [01:20<01:32,  1.03s/it]avg_loss = 1.5873397435897436:  46%|████▋     | 77/166 [01:21<01:32,  1.03s/it]avg_loss = 1.5873397435897436:  47%|████▋     | 78/166 [01:21<01:30,  1.03s/it]avg_loss = 1.5847507911392404:  47%|████▋     | 78/166 [01:22<01:30,  1.03s/it]avg_loss = 1.5847507911392404:  48%|████▊     | 79/166 [01:22<01:29,  1.03s/it]avg_loss = 1.58134765625:  48%|████▊     | 79/166 [01:23<01:29,  1.03s/it]     avg_loss = 1.58134765625:  48%|████▊     | 80/166 [01:23<01:28,  1.03s/it]avg_loss = 1.5716145833333333:  48%|████▊     | 80/166 [01:24<01:28,  1.03s/it]avg_loss = 1.5716145833333333:  49%|████▉     | 81/166 [01:24<01:28,  1.04s/it]avg_loss = 1.573408917682927:  49%|████▉     | 81/166 [01:25<01:28,  1.04s/it] avg_loss = 1.573408917682927:  49%|████▉     | 82/166 [01:25<01:27,  1.04s/it]avg_loss = 1.5745011295180722:  49%|████▉     | 82/166 [01:26<01:27,  1.04s/it]avg_loss = 1.5745011295180722:  50%|█████     | 83/166 [01:26<01:26,  1.04s/it]avg_loss = 1.5771484375:  50%|█████     | 83/166 [01:27<01:26,  1.04s/it]      avg_loss = 1.5771484375:  51%|█████     | 84/166 [01:27<01:25,  1.04s/it]avg_loss = 1.5788143382352942:  51%|█████     | 84/166 [01:28<01:25,  1.04s/it]avg_loss = 1.5788143382352942:  51%|█████     | 85/166 [01:28<01:25,  1.05s/it]avg_loss = 1.577716206395349:  51%|█████     | 85/166 [01:29<01:25,  1.05s/it] avg_loss = 1.577716206395349:  52%|█████▏    | 86/166 [01:29<01:23,  1.04s/it]avg_loss = 1.5781698994252873:  52%|█████▏    | 86/166 [01:30<01:23,  1.04s/it]avg_loss = 1.5781698994252873:  52%|█████▏    | 87/166 [01:30<01:23,  1.05s/it]avg_loss = 1.5787908380681819:  52%|█████▏    | 87/166 [01:31<01:23,  1.05s/it]avg_loss = 1.5787908380681819:  53%|█████▎    | 88/166 [01:31<01:21,  1.04s/it]avg_loss = 1.5800122893258426:  53%|█████▎    | 88/166 [01:32<01:21,  1.04s/it]avg_loss = 1.5800122893258426:  54%|█████▎    | 89/166 [01:32<01:20,  1.05s/it]avg_loss = 1.579904513888889:  54%|█████▎    | 89/166 [01:33<01:20,  1.05s/it] avg_loss = 1.579904513888889:  54%|█████▍    | 90/166 [01:33<01:19,  1.05s/it]avg_loss = 1.5807434752747254:  54%|█████▍    | 90/166 [01:34<01:19,  1.05s/it]avg_loss = 1.5807434752747254:  55%|█████▍    | 91/166 [01:34<01:18,  1.05s/it]avg_loss = 1.5810546875:  55%|█████▍    | 91/166 [01:35<01:18,  1.05s/it]      avg_loss = 1.5810546875:  55%|█████▌    | 92/166 [01:35<01:17,  1.05s/it]avg_loss = 1.5843834005376345:  55%|█████▌    | 92/166 [01:36<01:17,  1.05s/it]avg_loss = 1.5843834005376345:  56%|█████▌    | 93/166 [01:36<01:16,  1.05s/it]avg_loss = 1.5838181515957446:  56%|█████▌    | 93/166 [01:37<01:16,  1.05s/it]avg_loss = 1.5838181515957446:  57%|█████▋    | 94/166 [01:37<01:15,  1.05s/it]avg_loss = 1.583264802631579:  57%|█████▋    | 94/166 [01:38<01:15,  1.05s/it] avg_loss = 1.583264802631579:  57%|█████▋    | 95/166 [01:38<01:14,  1.05s/it]avg_loss = 1.5827229817708333:  57%|█████▋    | 95/166 [01:39<01:14,  1.05s/it]avg_loss = 1.5827229817708333:  58%|█████▊    | 96/166 [01:39<01:13,  1.05s/it]avg_loss = 1.5818701675257731:  58%|█████▊    | 96/166 [01:41<01:13,  1.05s/it]avg_loss = 1.5818701675257731:  58%|█████▊    | 97/166 [01:41<01:12,  1.05s/it]avg_loss = 1.5803172831632653:  58%|█████▊    | 97/166 [01:42<01:12,  1.05s/it]avg_loss = 1.5803172831632653:  59%|█████▉    | 98/166 [01:42<01:11,  1.06s/it]avg_loss = 1.578164457070707:  59%|█████▉    | 98/166 [01:43<01:11,  1.06s/it] avg_loss = 1.578164457070707:  60%|█████▉    | 99/166 [01:43<01:10,  1.05s/it]avg_loss = 1.5755078125:  60%|█████▉    | 99/166 [01:44<01:10,  1.05s/it]     avg_loss = 1.5755078125:  60%|██████    | 100/166 [01:44<01:09,  1.05s/it]avg_loss = 1.5761525371287128:  60%|██████    | 100/166 [01:45<01:09,  1.05s/it]avg_loss = 1.5761525371287128:  61%|██████    | 101/166 [01:45<01:08,  1.05s/it]avg_loss = 1.5773973651960784:  61%|██████    | 101/166 [01:46<01:08,  1.05s/it]avg_loss = 1.5773973651960784:  61%|██████▏   | 102/166 [01:46<01:07,  1.05s/it]avg_loss = 1.5779353762135921:  61%|██████▏   | 102/166 [01:47<01:07,  1.05s/it]avg_loss = 1.5779353762135921:  62%|██████▏   | 103/166 [01:47<01:05,  1.04s/it]avg_loss = 1.5797400841346154:  62%|██████▏   | 103/166 [01:48<01:05,  1.04s/it]avg_loss = 1.5797400841346154:  63%|██████▎   | 104/166 [01:48<01:05,  1.05s/it]avg_loss = 1.5862723214285714:  63%|██████▎   | 104/166 [01:49<01:05,  1.05s/it]avg_loss = 1.5862723214285714:  63%|██████▎   | 105/166 [01:49<01:03,  1.05s/it]avg_loss = 1.5916494693396226:  63%|██████▎   | 105/166 [01:50<01:03,  1.05s/it]avg_loss = 1.5916494693396226:  64%|██████▍   | 106/166 [01:50<01:02,  1.05s/it]avg_loss = 1.5948817172897196:  64%|██████▍   | 106/166 [01:51<01:02,  1.05s/it]avg_loss = 1.5948817172897196:  64%|██████▍   | 107/166 [01:51<01:01,  1.05s/it]avg_loss = 1.5979094328703705:  64%|██████▍   | 107/166 [01:52<01:01,  1.05s/it]avg_loss = 1.5979094328703705:  65%|██████▌   | 108/166 [01:52<01:00,  1.05s/it]avg_loss = 1.6026017775229358:  65%|██████▌   | 108/166 [01:53<01:00,  1.05s/it]avg_loss = 1.6026017775229358:  66%|██████▌   | 109/166 [01:53<00:59,  1.04s/it]avg_loss = 1.606072443181818:  66%|██████▌   | 109/166 [01:54<00:59,  1.04s/it] avg_loss = 1.606072443181818:  66%|██████▋   | 110/166 [01:54<00:58,  1.05s/it]avg_loss = 1.6075802364864864:  66%|██████▋   | 110/166 [01:55<00:58,  1.05s/it]avg_loss = 1.6075802364864864:  67%|██████▋   | 111/166 [01:55<00:57,  1.04s/it]avg_loss = 1.6088518415178572:  67%|██████▋   | 111/166 [01:56<00:57,  1.04s/it]avg_loss = 1.6088518415178572:  67%|██████▋   | 112/166 [01:56<00:56,  1.04s/it]avg_loss = 1.6089256084070795:  67%|██████▋   | 112/166 [01:57<00:56,  1.04s/it]avg_loss = 1.6089256084070795:  68%|██████▊   | 113/166 [01:57<00:54,  1.04s/it]avg_loss = 1.6097519188596492:  68%|██████▊   | 113/166 [01:58<00:54,  1.04s/it]avg_loss = 1.6097519188596492:  69%|██████▊   | 114/166 [01:58<00:53,  1.03s/it]avg_loss = 1.6064198369565217:  69%|██████▊   | 114/166 [01:59<00:53,  1.03s/it]avg_loss = 1.6064198369565217:  69%|██████▉   | 115/166 [01:59<00:52,  1.03s/it]avg_loss = 1.6056371228448276:  69%|██████▉   | 115/166 [02:00<00:52,  1.03s/it]avg_loss = 1.6056371228448276:  70%|██████▉   | 116/166 [02:00<00:51,  1.03s/it]avg_loss = 1.6068042200854702:  70%|██████▉   | 116/166 [02:01<00:51,  1.03s/it]avg_loss = 1.6068042200854702:  70%|███████   | 117/166 [02:01<00:50,  1.03s/it]avg_loss = 1.6062301377118644:  70%|███████   | 117/166 [02:02<00:50,  1.03s/it]avg_loss = 1.6062301377118644:  71%|███████   | 118/166 [02:02<00:49,  1.03s/it]avg_loss = 1.6050091911764706:  71%|███████   | 118/166 [02:03<00:49,  1.03s/it]avg_loss = 1.6050091911764706:  72%|███████▏  | 119/166 [02:03<00:48,  1.03s/it]avg_loss = 1.60498046875:  72%|███████▏  | 119/166 [02:04<00:48,  1.03s/it]     avg_loss = 1.60498046875:  72%|███████▏  | 120/166 [02:04<00:47,  1.03s/it]avg_loss = 1.6034026342975207:  72%|███████▏  | 120/166 [02:05<00:47,  1.03s/it]avg_loss = 1.6034026342975207:  73%|███████▎  | 121/166 [02:05<00:46,  1.03s/it]avg_loss = 1.6026831454918034:  73%|███████▎  | 121/166 [02:07<00:46,  1.03s/it]avg_loss = 1.6026831454918034:  73%|███████▎  | 122/166 [02:07<00:45,  1.04s/it]avg_loss = 1.6025470020325203:  73%|███████▎  | 122/166 [02:08<00:45,  1.04s/it]avg_loss = 1.6025470020325203:  74%|███████▍  | 123/166 [02:08<00:44,  1.04s/it]avg_loss = 1.6002079133064515:  74%|███████▍  | 123/166 [02:09<00:44,  1.04s/it]avg_loss = 1.6002079133064515:  75%|███████▍  | 124/166 [02:09<00:44,  1.05s/it]avg_loss = 1.59796875:  75%|███████▍  | 124/166 [02:10<00:44,  1.05s/it]        avg_loss = 1.59796875:  75%|███████▌  | 125/166 [02:10<00:42,  1.05s/it]avg_loss = 1.5952070932539681:  75%|███████▌  | 125/166 [02:11<00:42,  1.05s/it]avg_loss = 1.5952070932539681:  76%|███████▌  | 126/166 [02:11<00:41,  1.05s/it]avg_loss = 1.5924889271653544:  76%|███████▌  | 126/166 [02:12<00:41,  1.05s/it]avg_loss = 1.5924889271653544:  77%|███████▋  | 127/166 [02:12<00:40,  1.05s/it]avg_loss = 1.590606689453125:  77%|███████▋  | 127/166 [02:13<00:40,  1.05s/it] avg_loss = 1.590606689453125:  77%|███████▋  | 128/166 [02:13<00:39,  1.05s/it]avg_loss = 1.5891170058139534:  77%|███████▋  | 128/166 [02:14<00:39,  1.05s/it]avg_loss = 1.5891170058139534:  78%|███████▊  | 129/166 [02:14<00:38,  1.05s/it]avg_loss = 1.5890925480769231:  78%|███████▊  | 129/166 [02:15<00:38,  1.05s/it]avg_loss = 1.5890925480769231:  78%|███████▊  | 130/166 [02:15<00:37,  1.05s/it]avg_loss = 1.5901419370229009:  78%|███████▊  | 130/166 [02:16<00:37,  1.05s/it]avg_loss = 1.5901419370229009:  79%|███████▉  | 131/166 [02:16<00:36,  1.04s/it]avg_loss = 1.590524384469697:  79%|███████▉  | 131/166 [02:17<00:36,  1.04s/it] avg_loss = 1.590524384469697:  80%|███████▉  | 132/166 [02:17<00:35,  1.05s/it]avg_loss = 1.5914297462406015:  80%|███████▉  | 132/166 [02:18<00:35,  1.05s/it]avg_loss = 1.5914297462406015:  80%|████████  | 133/166 [02:18<00:34,  1.04s/it]avg_loss = 1.5927880130597014:  80%|████████  | 133/166 [02:19<00:34,  1.04s/it]avg_loss = 1.5927880130597014:  81%|████████  | 134/166 [02:19<00:33,  1.05s/it]avg_loss = 1.5910590277777779:  81%|████████  | 134/166 [02:20<00:33,  1.05s/it]avg_loss = 1.5910590277777779:  81%|████████▏ | 135/166 [02:20<00:32,  1.06s/it]avg_loss = 1.5915383731617647:  81%|████████▏ | 135/166 [02:21<00:32,  1.06s/it]avg_loss = 1.5915383731617647:  82%|████████▏ | 136/166 [02:21<00:32,  1.07s/it]avg_loss = 1.5920107208029197:  82%|████████▏ | 136/166 [02:22<00:32,  1.07s/it]avg_loss = 1.5920107208029197:  83%|████████▎ | 137/166 [02:22<00:31,  1.07s/it]avg_loss = 1.5928158967391304:  83%|████████▎ | 137/166 [02:23<00:31,  1.07s/it]avg_loss = 1.5928158967391304:  83%|████████▎ | 138/166 [02:23<00:30,  1.08s/it]avg_loss = 1.5923167715827338:  83%|████████▎ | 138/166 [02:25<00:30,  1.08s/it]avg_loss = 1.5923167715827338:  84%|████████▎ | 139/166 [02:25<00:29,  1.08s/it]avg_loss = 1.5912667410714285:  84%|████████▎ | 139/166 [02:26<00:29,  1.08s/it]avg_loss = 1.5912667410714285:  84%|████████▍ | 140/166 [02:26<00:28,  1.08s/it]avg_loss = 1.5901761968085106:  84%|████████▍ | 140/166 [02:27<00:28,  1.08s/it]avg_loss = 1.5901761968085106:  85%|████████▍ | 141/166 [02:27<00:26,  1.08s/it]avg_loss = 1.589871258802817:  85%|████████▍ | 141/166 [02:28<00:26,  1.08s/it] avg_loss = 1.589871258802817:  86%|████████▌ | 142/166 [02:28<00:25,  1.08s/it]avg_loss = 1.5882593968531469:  86%|████████▌ | 142/166 [02:29<00:25,  1.08s/it]avg_loss = 1.5882593968531469:  86%|████████▌ | 143/166 [02:29<00:24,  1.08s/it]avg_loss = 1.5896538628472223:  86%|████████▌ | 143/166 [02:30<00:24,  1.08s/it]avg_loss = 1.5896538628472223:  87%|████████▋ | 144/166 [02:30<00:23,  1.08s/it]avg_loss = 1.5893049568965518:  87%|████████▋ | 144/166 [02:31<00:23,  1.08s/it]avg_loss = 1.5893049568965518:  87%|████████▋ | 145/166 [02:31<00:22,  1.07s/it]avg_loss = 1.5895494434931507:  87%|████████▋ | 145/166 [02:32<00:22,  1.07s/it]avg_loss = 1.5895494434931507:  88%|████████▊ | 146/166 [02:32<00:21,  1.08s/it]avg_loss = 1.5884619472789117:  88%|████████▊ | 146/166 [02:33<00:21,  1.08s/it]avg_loss = 1.5884619472789117:  89%|████████▊ | 147/166 [02:33<00:20,  1.08s/it]avg_loss = 1.5876002956081081:  89%|████████▊ | 147/166 [02:34<00:20,  1.08s/it]avg_loss = 1.5876002956081081:  89%|████████▉ | 148/166 [02:34<00:19,  1.08s/it]avg_loss = 1.5861734479865772:  89%|████████▉ | 148/166 [02:35<00:19,  1.08s/it]avg_loss = 1.5861734479865772:  90%|████████▉ | 149/166 [02:35<00:18,  1.08s/it]avg_loss = 1.5872135416666666:  90%|████████▉ | 149/166 [02:36<00:18,  1.08s/it]avg_loss = 1.5872135416666666:  90%|█████████ | 150/166 [02:36<00:17,  1.09s/it]avg_loss = 1.5862220612582782:  90%|█████████ | 150/166 [02:38<00:17,  1.09s/it]avg_loss = 1.5862220612582782:  91%|█████████ | 151/166 [02:38<00:16,  1.08s/it]avg_loss = 1.5860659950657894:  91%|█████████ | 151/166 [02:39<00:16,  1.08s/it]avg_loss = 1.5860659950657894:  92%|█████████▏| 152/166 [02:39<00:15,  1.08s/it]avg_loss = 1.5860651552287581:  92%|█████████▏| 152/166 [02:40<00:15,  1.08s/it]avg_loss = 1.5860651552287581:  92%|█████████▏| 153/166 [02:40<00:13,  1.08s/it]avg_loss = 1.5876369724025974:  92%|█████████▏| 153/166 [02:41<00:13,  1.08s/it]avg_loss = 1.5876369724025974:  93%|█████████▎| 154/166 [02:41<00:12,  1.06s/it]avg_loss = 1.5872731854838709:  93%|█████████▎| 154/166 [02:42<00:12,  1.06s/it]avg_loss = 1.5872731854838709:  93%|█████████▎| 155/166 [02:42<00:11,  1.06s/it]avg_loss = 1.587264623397436:  93%|█████████▎| 155/166 [02:43<00:11,  1.06s/it] avg_loss = 1.587264623397436:  94%|█████████▍| 156/166 [02:43<00:10,  1.06s/it]avg_loss = 1.585564291401274:  94%|█████████▍| 156/166 [02:44<00:10,  1.06s/it]avg_loss = 1.585564291401274:  95%|█████████▍| 157/166 [02:44<00:09,  1.06s/it]avg_loss = 1.5815615110759493:  95%|█████████▍| 157/166 [02:45<00:09,  1.06s/it]avg_loss = 1.5815615110759493:  95%|█████████▌| 158/166 [02:45<00:08,  1.05s/it]avg_loss = 1.5822277908805031:  95%|█████████▌| 158/166 [02:46<00:08,  1.05s/it]avg_loss = 1.5822277908805031:  96%|█████████▌| 159/166 [02:46<00:07,  1.06s/it]avg_loss = 1.5838134765625:  96%|█████████▌| 159/166 [02:47<00:07,  1.06s/it]   avg_loss = 1.5838134765625:  96%|█████████▋| 160/166 [02:47<00:06,  1.05s/it]avg_loss = 1.5863984860248448:  96%|█████████▋| 160/166 [02:48<00:06,  1.05s/it]avg_loss = 1.5863984860248448:  97%|█████████▋| 161/166 [02:48<00:05,  1.06s/it]avg_loss = 1.5861062885802468:  97%|█████████▋| 161/166 [02:49<00:05,  1.06s/it]avg_loss = 1.5861062885802468:  98%|█████████▊| 162/166 [02:49<00:04,  1.05s/it]avg_loss = 1.5854821702453987:  98%|█████████▊| 162/166 [02:50<00:04,  1.05s/it]avg_loss = 1.5854821702453987:  98%|█████████▊| 163/166 [02:50<00:03,  1.07s/it]avg_loss = 1.5861995045731707:  98%|█████████▊| 163/166 [02:51<00:03,  1.07s/it]avg_loss = 1.5861995045731707:  99%|█████████▉| 164/166 [02:51<00:02,  1.06s/it]avg_loss = 1.5859611742424242:  99%|█████████▉| 164/166 [02:52<00:02,  1.06s/it]avg_loss = 1.5859611742424242:  99%|█████████▉| 165/166 [02:52<00:01,  1.07s/it]avg_loss = 1.587890625:  99%|█████████▉| 165/166 [02:53<00:01,  1.07s/it]       avg_loss = 1.587890625: 100%|██████████| 166/166 [02:53<00:00,  1.06s/it]avg_loss = 1.587890625: 100%|██████████| 166/166 [02:53<00:00,  1.05s/it]
I0303 19:35:00.607529 3393930 eval_ppl.py:105] wikitext2 perplexity: 4.893415927886963
wikitext2 perplexity: 4.893
