08:05:14 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:05:14 INFO - ddp_or_single_process: find checkpoint...
08:05:14 INFO - ddp_or_single_process: no checkpoint is here
08:05:14 INFO - ddp_or_single_process: seed : 100.0
08:05:14 INFO - ddp_or_single_process: exp name : exp_NIC_Fair_model_TCM_lmbda_13.0_seed_100.0_batch_size_8_radius_denominator_8_total_iter_1000000
08:05:14 INFO - ddp_or_single_process: opts: Namespace(dist_port=4587, iter=1000000, model_name='TCM', learning_rate=0.0001, num_workers=2, batch_size=8, aux_learning_rate=0.001, seed=100.0, clip_max_norm=1.0, slurm=False, radius_denominator=8, dataset_dir='./dataset_wp_one_row/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt', data_dim=512, length=8, lmbda=13.0, checkpoint='None', save_path='./checkpoint/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt/lmbda13.0_batch_size8_total_iter1000000_seed100.0', **{'dev.num_gpus': 4, 'ddp.world_size': 4})
08:05:18 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:05:18 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:05:18 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:05:18 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:05:18 INFO - main: Create experiment save folder
08:05:40 INFO - main: Training mode : scratch!
08:05:40 INFO - main: lmbda : 13.0
08:05:40 INFO - main: batch_size : 8
08:05:40 INFO - main: num of gpus: 4
distributed init (rank 0): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 1): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 3): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 2): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py:278: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py:278: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py:278: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py:278: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
torch.Size([8, 256, 8]) torch.Size([256, 1, 1]) torch.Size([8, 8, 1024]) torch.Size([8, 256, 8])
torch.Size([8, 256, 8]) torch.Size([256, 1, 1]) torch.Size([8, 8, 1024]) torch.Size([8, 256, 8])
torch.Size([8, 256, 8]) torch.Size([256, 1, 1]) torch.Size([8, 8, 1024]) torch.Size([8, 256, 8])
Traceback (most recent call last):
  File "/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py", line 619, in <module>
    ddp_or_single_process(sys.argv[1:])    
  File "/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py", line 608, in ddp_or_single_process
    torch.multiprocessing.spawn(
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 246, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 202, in start_processes
    while not context.join():
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 163, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 74, in _wrap
    fn(i, *args)
  File "/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py", line 563, in distributed_worker
    main(opts)
  File "/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/train.py", line 284, in main
    out_net = net(img)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/jgryu/Weight_compression/nic_weight_comp_transformer/models/tr_nwc.py", line 223, in forward
    z_tmp = z - z_offset
RuntimeError: The size of tensor a (8) must match the size of tensor b (256) at non-singleton dimension 0

