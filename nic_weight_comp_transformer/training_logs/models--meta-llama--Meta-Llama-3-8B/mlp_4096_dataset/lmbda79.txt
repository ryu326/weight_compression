08:07:41 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:07:41 INFO - ddp_or_single_process: Create new exp folder!
08:07:41 INFO - ddp_or_single_process: seed : 100.0
08:07:41 INFO - ddp_or_single_process: exp name : exp_NIC_Fair_model_TCM_lmbda_79.0_seed_100.0_batch_size_8_radius_denominator_8_total_iter_1000000
08:07:41 INFO - ddp_or_single_process: opts: Namespace(dist_port=4587, iter=1000000, model_name='TCM', learning_rate=0.0001, num_workers=2, batch_size=8, aux_learning_rate=0.001, seed=100.0, clip_max_norm=1.0, slurm=False, radius_denominator=8, dataset_dir='./dataset_wp_one_row/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt', data_dim=512, length=8, lmbda=79.0, checkpoint='None', save_path='./checkpoint/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt/lmbda79.0_batch_size8_total_iter1000000_seed100.0', **{'dev.num_gpus': 4, 'ddp.world_size': 4})
08:07:47 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:07:47 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:07:47 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:07:47 INFO - logger_setup: /workspace/jgryu/Weight_compression/nic_weight_comp_transformer/utils/util.py
08:07:47 INFO - main: Create experiment save folder
08:08:13 INFO - main: Training mode : scratch!
08:08:13 INFO - main: lmbda : 79.0
08:08:13 INFO - main: batch_size : 8
08:08:13 INFO - main: num of gpus: 4
distributed init (rank 0): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 2): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 1): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
distributed init (rank 3): tcp://d941ff0a1a1f:4587
{'module.entropy_bottleneck.quantiles'}
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
torch.Size([1, 256, 8]) torch.Size([256, 1, 1]) torch.Size([1, 8, 1024]) torch.Size([1, 256, 8])
