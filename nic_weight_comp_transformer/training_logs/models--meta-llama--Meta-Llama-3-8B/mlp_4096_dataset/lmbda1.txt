15:21:21 INFO - logger_setup: /workspace/jgryu/weight_compression/nic_weight_comp_transformer/utils/util.py
15:21:21 INFO - ddp_or_single_process: find checkpoint...
15:21:21 INFO - ddp_or_single_process: no checkpoint is here
15:21:21 INFO - ddp_or_single_process: seed : 100.0
15:21:21 INFO - ddp_or_single_process: exp name : exp_NIC_Fair_model_TCM_lmbda_1.0_seed_100.0_batch_size_16_radius_denominator_8_total_iter_1000000
15:21:21 INFO - ddp_or_single_process: opts: Namespace(dist_port=5786, iter=1000000, model_name='TCM', learning_rate=0.0001, num_workers=2, batch_size=16, aux_learning_rate=0.001, seed=100.0, clip_max_norm=1.0, slurm=False, radius_denominator=8, dataset_dir='./dataset_wp_one_row/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt', data_dim=512, length=8, lmbda=1.0, checkpoint='None', save_path='./checkpoint/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt/lmbda1.0_batch_size16_total_iter1000000_seed100.0', **{'dev.num_gpus': 4, 'ddp.world_size': 4})
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /workspace/jgryu/weight_compression/nic_weight_comp_transformer/wandb/run-20241128_152127-h9vn4x8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tr_nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2
wandb: üöÄ View run at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2/runs/h9vn4x8e
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /workspace/jgryu/weight_compression/nic_weight_comp_transformer/wandb/run-20241128_152127-3snhqycy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tr_nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2
wandb: üöÄ View run at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2/runs/3snhqycy
15:21:27 INFO - logger_setup: /workspace/jgryu/weight_compression/nic_weight_comp_transformer/utils/util.py
distributed init (rank 3): tcp://ec3b2e8218de:5786
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /workspace/jgryu/weight_compression/nic_weight_comp_transformer/wandb/run-20241128_152127-1trvvtbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tr_nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2
wandb: üöÄ View run at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2/runs/1trvvtbx
15:21:27 INFO - logger_setup: /workspace/jgryu/weight_compression/nic_weight_comp_transformer/utils/util.py
15:21:27 INFO - main: Create experiment save folder
distributed init (rank 0): tcp://ec3b2e8218de:5786
wandb: Tracking run with wandb version 0.18.6
wandb: Run data is saved locally in /workspace/jgryu/weight_compression/nic_weight_comp_transformer/wandb/run-20241128_152127-hj54xfvb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tr_nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2
wandb: üöÄ View run at https://wandb.ai/maskedkd/Neural%20Weight%20Compression_v2/runs/hj54xfvb
15:21:27 INFO - logger_setup: /workspace/jgryu/weight_compression/nic_weight_comp_transformer/utils/util.py
distributed init (rank 2): tcp://ec3b2e8218de:5786
15:21:27 INFO - logger_setup: /workspace/jgryu/weight_compression/nic_weight_comp_transformer/utils/util.py
distributed init (rank 1): tcp://ec3b2e8218de:5786
[1;34mwandb[0m: üöÄ View run [33mtr_nwc[0m at: [34mhttps://wandb.ai/maskedkd/Neural Weight Compression_v2/runs/h9vn4x8e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241128_152127-h9vn4x8e/logs[0m
[1;34mwandb[0m: üöÄ View run [33mtr_nwc[0m at: [34mhttps://wandb.ai/maskedkd/Neural Weight Compression_v2/runs/3snhqycy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241128_152127-3snhqycy/logs[0m
[1;34mwandb[0m: üöÄ View run [33mtr_nwc[0m at: [34mhttps://wandb.ai/maskedkd/Neural Weight Compression_v2/runs/hj54xfvb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241128_152127-hj54xfvb/logs[0m
[1;34mwandb[0m: üöÄ View run [33mtr_nwc[0m at: [34mhttps://wandb.ai/maskedkd/Neural Weight Compression_v2/runs/1trvvtbx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241128_152127-1trvvtbx/logs[0m
Traceback (most recent call last):
  File "/workspace/jgryu/weight_compression/nic_weight_comp_transformer/train.py", line 620, in <module>
    ddp_or_single_process(sys.argv[1:])    
  File "/workspace/jgryu/weight_compression/nic_weight_comp_transformer/train.py", line 609, in ddp_or_single_process
    torch.multiprocessing.spawn(
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 246, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 202, in start_processes
    while not context.join():
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 163, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 74, in _wrap
    fn(i, *args)
  File "/workspace/jgryu/weight_compression/nic_weight_comp_transformer/train.py", line 564, in distributed_worker
    main(opts)
  File "/workspace/jgryu/weight_compression/nic_weight_comp_transformer/train.py", line 119, in main
    train_dataset = WParam_dataset(dataset_folder= opts.dataset_dir, split='train', data_dim=opts.data_dim, length=opts.length, seed = 100)
  File "/workspace/jgryu/weight_compression/nic_weight_comp_transformer/datasets_WeightParam.py", line 14, in __init__
    self.dataset = torch.load(dataset_folder)[split]
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 986, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 435, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/opt/conda/lib/python3.10/site-packages/torch/serialization.py", line 416, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './dataset_wp_one_row/models--meta-llama--Meta-Llama-3-8B/mlp_4096_dataset.pt'

