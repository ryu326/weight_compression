{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgryu/miniconda3/envs/nicc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jgryu/miniconda3/envs/nicc/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "from compressai.entropy_models.entropy_models import *\n",
    "\n",
    "\n",
    "class EntropyBottleneck_for_weight(EntropyModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        *args: Any,\n",
    "        tail_mass: float = 1e-9,\n",
    "        init_scale: float = 10,\n",
    "        filters: Tuple[int, ...] = (3, 3, 3, 3),\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.channels = int(channels)\n",
    "        self.filters = tuple(int(f) for f in filters)\n",
    "        self.init_scale = float(init_scale)\n",
    "        self.tail_mass = float(tail_mass)\n",
    "\n",
    "        \n",
    "        ################################################################################################\n",
    "        # 여기 부분 2차원 텐서 처리하기 적합한 모양으로 수정하기\n",
    "        \n",
    "        # Create parameters\n",
    "        filters = (1,) + self.filters + (1,)\n",
    "        scale = self.init_scale ** (1 / (len(self.filters) + 1))\n",
    "        channels = self.channels\n",
    "\n",
    "        self.matrices = nn.ParameterList()\n",
    "        self.biases = nn.ParameterList()\n",
    "        self.factors = nn.ParameterList()\n",
    "\n",
    "        for i in range(len(self.filters) + 1):\n",
    "            init = np.log(np.expm1(1 / scale / filters[i + 1]))\n",
    "            matrix = torch.Tensor(channels, filters[i + 1], filters[i])\n",
    "            matrix.data.fill_(init)\n",
    "            self.matrices.append(nn.Parameter(matrix))\n",
    "\n",
    "            bias = torch.Tensor(channels, filters[i + 1], 1)\n",
    "            nn.init.uniform_(bias, -0.5, 0.5)\n",
    "            self.biases.append(nn.Parameter(bias))\n",
    "\n",
    "            if i < len(self.filters):\n",
    "                factor = torch.Tensor(channels, filters[i + 1], 1)\n",
    "                nn.init.zeros_(factor)\n",
    "                self.factors.append(nn.Parameter(factor))\n",
    "\n",
    "        self.quantiles = nn.Parameter(torch.Tensor(channels, 1, 3))\n",
    "        init = torch.Tensor([-self.init_scale, 0, self.init_scale])\n",
    "        self.quantiles.data = init.repeat(self.quantiles.size(0), 1, 1)\n",
    "\n",
    "        target = np.log(2 / self.tail_mass - 1)\n",
    "        self.register_buffer(\"target\", torch.Tensor([-target, 0, target]))\n",
    "        \n",
    "        ################################################################################################\n",
    "\n",
    "    def _get_medians(self) -> Tensor:\n",
    "        medians = self.quantiles[:, :, 1:2]\n",
    "        return medians\n",
    "\n",
    "    def update(self, force: bool = False, update_quantiles: bool = False) -> bool:\n",
    "        # Check if we need to update the bottleneck parameters, the offsets are\n",
    "        # only computed and stored when the conditonal model is update()'d.\n",
    "        if self._offset.numel() > 0 and not force:\n",
    "            return False\n",
    "\n",
    "        if update_quantiles:\n",
    "            self._update_quantiles()\n",
    "\n",
    "        \n",
    "        ################################################################################################\n",
    "        # 여기 부분 2차원 텐서 처리하기 적합한 모양으로 수정하기\n",
    "        \n",
    "        medians = self.quantiles[:, 0, 1]\n",
    "\n",
    "        minima = medians - self.quantiles[:, 0, 0]\n",
    "        minima = torch.ceil(minima).int()\n",
    "        minima = torch.clamp(minima, min=0)\n",
    "\n",
    "        maxima = self.quantiles[:, 0, 2] - medians\n",
    "        maxima = torch.ceil(maxima).int()\n",
    "        maxima = torch.clamp(maxima, min=0)\n",
    "\n",
    "        self._offset = -minima\n",
    "\n",
    "        pmf_start = medians - minima\n",
    "        pmf_length = maxima + minima + 1\n",
    "\n",
    "        max_length = pmf_length.max().item()\n",
    "        device = pmf_start.device\n",
    "        samples = torch.arange(max_length, device=device)\n",
    "        samples = samples[None, :] + pmf_start[:, None, None]\n",
    "\n",
    "        pmf, lower, upper = self._likelihood(samples, stop_gradient=True)\n",
    "        pmf = pmf[:, 0, :]\n",
    "        tail_mass = torch.sigmoid(lower[:, 0, :1]) + torch.sigmoid(-upper[:, 0, -1:])\n",
    "        \n",
    "        ################################################################################################\n",
    "\n",
    "        quantized_cdf = self._pmf_to_cdf(pmf, tail_mass, pmf_length, max_length)\n",
    "        self._quantized_cdf = quantized_cdf\n",
    "        self._cdf_length = pmf_length + 2\n",
    "        return True\n",
    "\n",
    "    def loss(self) -> Tensor:\n",
    "        logits = self._logits_cumulative(self.quantiles, stop_gradient=True)\n",
    "        loss = torch.abs(logits - self.target).sum()\n",
    "        return loss\n",
    "\n",
    "    def _logits_cumulative(self, inputs: Tensor, stop_gradient: bool) -> Tensor:\n",
    "        # TorchScript not yet working (nn.Mmodule indexing not supported)\n",
    "        logits = inputs\n",
    "        for i in range(len(self.filters) + 1):\n",
    "            matrix = self.matrices[i]\n",
    "            if stop_gradient:\n",
    "                matrix = matrix.detach()\n",
    "            logits = torch.matmul(F.softplus(matrix), logits)\n",
    "\n",
    "            bias = self.biases[i]\n",
    "            if stop_gradient:\n",
    "                bias = bias.detach()\n",
    "            logits = logits + bias\n",
    "\n",
    "            if i < len(self.filters):\n",
    "                factor = self.factors[i]\n",
    "                if stop_gradient:\n",
    "                    factor = factor.detach()\n",
    "                logits = logits + torch.tanh(factor) * torch.tanh(logits)\n",
    "        return logits\n",
    "\n",
    "    def _likelihood(\n",
    "        self, inputs: Tensor, stop_gradient: bool = False\n",
    "    ) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        half = float(0.5)\n",
    "        lower = self._logits_cumulative(inputs - half, stop_gradient=stop_gradient)\n",
    "        upper = self._logits_cumulative(inputs + half, stop_gradient=stop_gradient)\n",
    "        likelihood = torch.sigmoid(upper) - torch.sigmoid(lower)\n",
    "        return likelihood, lower, upper\n",
    "\n",
    "    def forward(\n",
    "        self, x: Tensor, training: Optional[bool] = None\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        if training is None:\n",
    "            training = self.training\n",
    "\n",
    "        ################################################################################################\n",
    "        # 2차원 텐서 처리하기 적합하게 수정하기\n",
    "        \n",
    "        if not torch.jit.is_scripting():\n",
    "            # x from B x C x ... to C x B x ...\n",
    "            perm = torch.cat(\n",
    "                (\n",
    "                    torch.tensor([1, 0], dtype=torch.long, device=x.device),\n",
    "                    torch.arange(2, x.ndim, dtype=torch.long, device=x.device),\n",
    "                )\n",
    "            )\n",
    "            inv_perm = perm\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            # TorchScript in 2D for static inference\n",
    "            # Convert to (channels, ... , batch) format\n",
    "            # perm = (1, 2, 3, 0)\n",
    "            # inv_perm = (3, 0, 1, 2)\n",
    "\n",
    "        x = x.permute(*perm).contiguous()\n",
    "        shape = x.size()\n",
    "        values = x.reshape(x.size(0), 1, -1)\n",
    "        \n",
    "        ################################################################################################\n",
    "\n",
    "        # Add noise or quantize\n",
    "\n",
    "        outputs = self.quantize(\n",
    "            values, \"noise\" if training else \"dequantize\", self._get_medians()\n",
    "        )\n",
    "\n",
    "        if not torch.jit.is_scripting():\n",
    "            likelihood, _, _ = self._likelihood(outputs)\n",
    "            if self.use_likelihood_bound:\n",
    "                likelihood = self.likelihood_lower_bound(likelihood)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            # TorchScript not yet supported\n",
    "            # likelihood = torch.zeros_like(outputs)\n",
    "\n",
    "        # Convert back to input tensor shape\n",
    "        outputs = outputs.reshape(shape)\n",
    "        outputs = outputs.permute(*inv_perm).contiguous()\n",
    "\n",
    "        likelihood = likelihood.reshape(shape)\n",
    "        likelihood = likelihood.permute(*inv_perm).contiguous()\n",
    "\n",
    "        return outputs, likelihood\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_indexes(size):\n",
    "        dims = len(size)\n",
    "        N = size[0]\n",
    "        C = size[1]\n",
    "\n",
    "        view_dims = np.ones((dims,), dtype=np.int64)\n",
    "        view_dims[1] = -1\n",
    "        indexes = torch.arange(C).view(*view_dims)\n",
    "        indexes = indexes.int()\n",
    "\n",
    "        return indexes.repeat(N, 1, *size[2:])\n",
    "\n",
    "    ################################################################################################\n",
    "    # 2차원 텐서 처리하기 적합하게 수정하기\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extend_ndims(tensor, n):\n",
    "        return tensor.reshape(-1, *([1] * n)) if n > 0 else tensor.reshape(-1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_quantiles(self, search_radius=1e5, rtol=1e-4, atol=1e-3):\n",
    "        \"\"\"Fast quantile update via bisection search.\n",
    "\n",
    "        Often faster and much more precise than minimizing aux loss.\n",
    "        \"\"\"\n",
    "        device = self.quantiles.device\n",
    "        shape = (self.channels, 1, 1)\n",
    "        low = torch.full(shape, -search_radius, device=device)\n",
    "        high = torch.full(shape, search_radius, device=device)\n",
    "\n",
    "        def f(y, self=self):\n",
    "            return self._logits_cumulative(y, stop_gradient=True)\n",
    "\n",
    "        for i in range(len(self.target)):\n",
    "            q_i = self._search_target(f, self.target[i], low, high, rtol, atol)\n",
    "            self.quantiles[:, :, i] = q_i[:, :, 0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _search_target(f, target, low, high, rtol=1e-4, atol=1e-3, strict=False):\n",
    "        assert (low <= high).all()\n",
    "        if strict:\n",
    "            assert ((f(low) <= target) & (target <= f(high))).all()\n",
    "        else:\n",
    "            low = torch.where(target <= f(high), low, high)\n",
    "            high = torch.where(f(low) <= target, high, low)\n",
    "        while not torch.isclose(low, high, rtol=rtol, atol=atol).all():\n",
    "            mid = (low + high) / 2\n",
    "            f_mid = f(mid)\n",
    "            low = torch.where(f_mid <= target, mid, low)\n",
    "            high = torch.where(f_mid >= target, mid, high)\n",
    "        return (low + high) / 2\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    def compress(self, x):\n",
    "        indexes = self._build_indexes(x.size())\n",
    "        medians = self._get_medians().detach()\n",
    "        spatial_dims = len(x.size()) - 2\n",
    "        medians = self._extend_ndims(medians, spatial_dims)\n",
    "        medians = medians.expand(x.size(0), *([-1] * (spatial_dims + 1)))\n",
    "        return super().compress(x, indexes, medians)\n",
    "\n",
    "    def decompress(self, strings, size):\n",
    "        output_size = (len(strings), self._quantized_cdf.size(0), *size)\n",
    "        indexes = self._build_indexes(output_size).to(self._quantized_cdf.device)\n",
    "        medians = self._extend_ndims(self._get_medians().detach(), len(size))\n",
    "        medians = medians.expand(len(strings), *([-1] * (len(size) + 1)))\n",
    "        return super().decompress(strings, indexes, medians.dtype, medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 512\n",
    "test_entropy_models = EntropyBottleneck_for_weight(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test_tensor = torch.randn(4,dim, 168) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 168])\n",
      "torch.Size([4, 512, 168])\n"
     ]
    }
   ],
   "source": [
    "# 돌아가니까...\n",
    "print(test_entropy_models(test_tensor)[0].shape)\n",
    "print(test_entropy_models(test_tensor)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nicc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
