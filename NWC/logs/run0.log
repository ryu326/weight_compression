/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
10:18:31 INFO - logger_setup: /workspace/Weight_compression/NWC/utils/util.py
10:18:31 INFO - before_main: Create new exp folder!
10:18:31 INFO - before_main: seed : 100
10:18:31 INFO - before_main: exp name : block_seq_scaler_meta-llama--Meta-Llama-3-8B__scaled3_RHT_sig1e-06_col_1024.pt/lmbda30_rdloss_size16_encdim512_M16_Q0_R0_m0_batch_size2048_total_iter200000_lr0.0001_seed100
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ryu326 (maskedkd) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /workspace/Weight_compression/NWC/wandb/run-20250401_101831-0lz6qm33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/NWC_VQVAE
wandb: üöÄ View run at https://wandb.ai/maskedkd/NWC_VQVAE/runs/0lz6qm33
10:18:33 INFO - main: Create experiment save folder
{'entropy_bottleneck.quantiles'}
10:18:47 INFO - main: Training mode : scratch!
10:18:47 INFO - main: batch_size : 2048
10:18:47 INFO - main: num of gpus: 1
10:18:47 INFO - main: Namespace(iter=200000, dataset='block_seq', dataset_path='../Wparam_dataset/block_pt/meta-llama--Meta-Llama-3-8B/scaled3_RHT_sig1e-06_col_1024.pt', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=2048, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, N=0, R=0, m=0, Q=0, C=0, clip_max_norm=1.0, save_dir='', architecture='nwc', loss='rdloss', checkpoint='None', lmbda=30, dataset_stat_type='scaler', save_path='./checkpoint/nwc/block_seq_scaler_meta-llama--Meta-Llama-3-8B__scaled3_RHT_sig1e-06_col_1024.pt/lmbda30_rdloss_size16_encdim512_M16_Q0_R0_m0_batch_size2048_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:18:49 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 95.67747497558594	recon_loss: 3.0098559856414795	bpp_loss: 5.3817973136901855	aux_loss: 658.1145629882812
10:18:58 INFO - main: {'TEST MSE': 2.0405557760364266, 'TEST BPP': 5.4375, 'TEST loss': 66.59776845169067, 'TEST recon_loss': 2.040555765032768, 'TEST bpp_loss': 5.381095526695251}
10:18:58 INFO - main: can not find prev_mse_best_model!
10:18:58 INFO - main: can not find prev_bpp_best_model!
10:18:58 INFO - main: can not find prev_bpp_best_model!
10:18:58 INFO - main: can not find recent_saved_model!
/workspace/Weight_compression/NWC/train_nwc.py:418: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  csv_file = pd.concat([csv_file, pd.DataFrame([new_row])], ignore_index=True)
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:19:16 INFO - main: Train iter. 100/200000 (0.05%): 	Loss: 6.527549743652344	recon_loss: 0.04114538058638573	bpp_loss: 5.293188571929932	aux_loss: 654.9008178710938
10:19:33 INFO - main: Train iter. 200/200000 (0.1%): 	Loss: 5.9034295082092285	recon_loss: 0.02392888069152832	bpp_loss: 5.185563087463379	aux_loss: 652.0836181640625
10:19:50 INFO - main: Train iter. 300/200000 (0.15%): 	Loss: 5.625112056732178	recon_loss: 0.018380865454673767	bpp_loss: 5.073686122894287	aux_loss: 649.0233154296875
10:20:08 INFO - main: Train iter. 400/200000 (0.2%): 	Loss: 5.436420440673828	recon_loss: 0.01578867807984352	bpp_loss: 4.962759971618652	aux_loss: 645.6798095703125
10:20:26 INFO - main: Train iter. 500/200000 (0.25%): 	Loss: 5.293881416320801	recon_loss: 0.014405064284801483	bpp_loss: 4.861729621887207	aux_loss: 642.244140625
10:20:43 INFO - main: Train iter. 600/200000 (0.3%): 	Loss: 5.12332820892334	recon_loss: 0.012227150611579418	bpp_loss: 4.756513595581055	aux_loss: 638.3975830078125
10:21:01 INFO - main: Train iter. 700/200000 (0.35%): 	Loss: 5.014856815338135	recon_loss: 0.011626309715211391	bpp_loss: 4.666067600250244	aux_loss: 634.47265625
10:21:19 INFO - main: Train iter. 800/200000 (0.4%): 	Loss: 4.891688346862793	recon_loss: 0.01105688326060772	bpp_loss: 4.559981822967529	aux_loss: 629.8598022460938
10:21:37 INFO - main: Train iter. 900/200000 (0.45%): 	Loss: 4.823732376098633	recon_loss: 0.011781864799559116	bpp_loss: 4.470276355743408	aux_loss: 625.2386474609375
10:21:54 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 4.685542106628418	recon_loss: 0.010306090116500854	bpp_loss: 4.376359462738037	aux_loss: 620.1783447265625
10:22:12 INFO - main: Train iter. 1100/200000 (0.55%): 	Loss: 4.585676193237305	recon_loss: 0.010086468420922756	bpp_loss: 4.283082008361816	aux_loss: 614.5445556640625
10:22:30 INFO - main: Train iter. 1200/200000 (0.6%): 	Loss: 4.5113911628723145	recon_loss: 0.010733156464993954	bpp_loss: 4.189396381378174	aux_loss: 608.2852783203125
10:22:48 INFO - main: Train iter. 1300/200000 (0.65%): 	Loss: 4.410984516143799	recon_loss: 0.010357861407101154	bpp_loss: 4.10024881362915	aux_loss: 602.15576171875
10:23:06 INFO - main: Train iter. 1400/200000 (0.7%): 	Loss: 4.33647346496582	recon_loss: 0.01082866732031107	bpp_loss: 4.011613368988037	aux_loss: 595.496337890625
10:23:24 INFO - main: Train iter. 1500/200000 (0.75%): 	Loss: 4.264092922210693	recon_loss: 0.011108136735856533	bpp_loss: 3.9308488368988037	aux_loss: 588.7581787109375
10:23:42 INFO - main: Train iter. 1600/200000 (0.8%): 	Loss: 4.209814548492432	recon_loss: 0.01159281563013792	bpp_loss: 3.862030029296875	aux_loss: 582.2037353515625
10:24:00 INFO - main: Train iter. 1700/200000 (0.85%): 	Loss: 4.140434741973877	recon_loss: 0.012011537328362465	bpp_loss: 3.780088424682617	aux_loss: 574.9556884765625
10:24:17 INFO - main: Train iter. 1800/200000 (0.9%): 	Loss: 4.079109191894531	recon_loss: 0.012537260539829731	bpp_loss: 3.702991485595703	aux_loss: 567.1984252929688
10:24:35 INFO - main: Train iter. 1900/200000 (0.95%): 	Loss: 4.044776439666748	recon_loss: 0.01314594503492117	bpp_loss: 3.650398015975952	aux_loss: 560.475341796875
10:24:53 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 4.000486850738525	recon_loss: 0.01369414757937193	bpp_loss: 3.5896623134613037	aux_loss: 553.2062377929688
10:25:11 INFO - main: Train iter. 2100/200000 (1.05%): 	Loss: 3.9635515213012695	recon_loss: 0.014546764083206654	bpp_loss: 3.527148723602295	aux_loss: 545.8323974609375
10:25:29 INFO - main: Train iter. 2200/200000 (1.1%): 	Loss: 3.9178268909454346	recon_loss: 0.014881717041134834	bpp_loss: 3.4713754653930664	aux_loss: 538.8778686523438
10:25:47 INFO - main: Train iter. 2300/200000 (1.15%): 	Loss: 3.903230905532837	recon_loss: 0.015806952491402626	bpp_loss: 3.4290223121643066	aux_loss: 532.1392822265625
10:26:05 INFO - main: Train iter. 2400/200000 (1.2%): 	Loss: 3.8965952396392822	recon_loss: 0.01750224456191063	bpp_loss: 3.371527910232544	aux_loss: 525.755615234375
10:26:22 INFO - main: Train iter. 2500/200000 (1.25%): 	Loss: 3.8332226276397705	recon_loss: 0.016546132043004036	bpp_loss: 3.336838722229004	aux_loss: 519.9609375
10:26:40 INFO - main: Train iter. 2600/200000 (1.3%): 	Loss: 3.809393882751465	recon_loss: 0.017062600702047348	bpp_loss: 3.297515869140625	aux_loss: 513.5657958984375
10:26:58 INFO - main: Train iter. 2700/200000 (1.35%): 	Loss: 3.7901558876037598	recon_loss: 0.017582857981324196	bpp_loss: 3.2626700401306152	aux_loss: 507.0486145019531
10:27:16 INFO - main: Train iter. 2800/200000 (1.4%): 	Loss: 3.760047197341919	recon_loss: 0.018264634534716606	bpp_loss: 3.2121081352233887	aux_loss: 500.0015869140625
10:27:34 INFO - main: Train iter. 2900/200000 (1.45%): 	Loss: 3.7582380771636963	recon_loss: 0.01875242404639721	bpp_loss: 3.1956653594970703	aux_loss: 493.946044921875
10:27:52 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 3.7422237396240234	recon_loss: 0.01928635500371456	bpp_loss: 3.163633108139038	aux_loss: 487.55743408203125
10:28:10 INFO - main: Train iter. 3100/200000 (1.55%): 	Loss: 3.723208427429199	recon_loss: 0.01975911483168602	bpp_loss: 3.130434989929199	aux_loss: 481.1808166503906
10:28:28 INFO - main: Train iter. 3200/200000 (1.6%): 	Loss: 3.7164053916931152	recon_loss: 0.020269112661480904	bpp_loss: 3.1083319187164307	aux_loss: 475.4664611816406
10:28:46 INFO - main: Train iter. 3300/200000 (1.65%): 	Loss: 3.6972455978393555	recon_loss: 0.020836953073740005	bpp_loss: 3.0721371173858643	aux_loss: 469.669921875
10:29:06 INFO - main: Train iter. 3400/200000 (1.7%): 	Loss: 3.6953580379486084	recon_loss: 0.021103572100400925	bpp_loss: 3.062250852584839	aux_loss: 464.74798583984375
10:29:24 INFO - main: Train iter. 3500/200000 (1.75%): 	Loss: 3.7139499187469482	recon_loss: 0.021526964381337166	bpp_loss: 3.068140983581543	aux_loss: 459.34619140625
10:29:42 INFO - main: Train iter. 3600/200000 (1.8%): 	Loss: 3.6950666904449463	recon_loss: 0.022084824740886688	bpp_loss: 3.032521963119507	aux_loss: 453.72491455078125
10:29:59 INFO - main: Train iter. 3700/200000 (1.85%): 	Loss: 3.6948859691619873	recon_loss: 0.022219302132725716	bpp_loss: 3.0283069610595703	aux_loss: 449.3380126953125
10:30:17 INFO - main: Train iter. 3800/200000 (1.9%): 	Loss: 3.67576265335083	recon_loss: 0.02254309132695198	bpp_loss: 2.9994699954986572	aux_loss: 444.6705322265625
10:30:35 INFO - main: Train iter. 3900/200000 (1.95%): 	Loss: 3.6834869384765625	recon_loss: 0.02282169833779335	bpp_loss: 2.998836040496826	aux_loss: 440.1417236328125
10:30:53 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 3.6627197265625	recon_loss: 0.02300519309937954	bpp_loss: 2.9725639820098877	aux_loss: 435.66900634765625
10:31:11 INFO - main: Train iter. 4100/200000 (2.05%): 	Loss: 3.682368755340576	recon_loss: 0.023339979350566864	bpp_loss: 2.9821693897247314	aux_loss: 432.2344665527344
10:31:29 INFO - main: Train iter. 4200/200000 (2.1%): 	Loss: 3.6737899780273438	recon_loss: 0.02347957342863083	bpp_loss: 2.96940279006958	aux_loss: 428.5552062988281
10:31:47 INFO - main: Train iter. 4300/200000 (2.15%): 	Loss: 3.673433303833008	recon_loss: 0.02367333136498928	bpp_loss: 2.963233470916748	aux_loss: 424.827392578125
10:32:05 INFO - main: Train iter. 4400/200000 (2.2%): 	Loss: 3.681610107421875	recon_loss: 0.023903528228402138	bpp_loss: 2.9645042419433594	aux_loss: 421.3343811035156
10:32:22 INFO - main: Train iter. 4500/200000 (2.25%): 	Loss: 3.6788854598999023	recon_loss: 0.023998979479074478	bpp_loss: 2.958915948867798	aux_loss: 418.3678283691406
10:32:40 INFO - main: Train iter. 4600/200000 (2.3%): 	Loss: 3.677692174911499	recon_loss: 0.02402181550860405	bpp_loss: 2.9570376873016357	aux_loss: 415.6817321777344
10:32:58 INFO - main: Train iter. 4700/200000 (2.35%): 	Loss: 3.6819307804107666	recon_loss: 0.02422156371176243	bpp_loss: 2.9552838802337646	aux_loss: 413.1001281738281
10:33:16 INFO - main: Train iter. 4800/200000 (2.4%): 	Loss: 3.6850523948669434	recon_loss: 0.024555733427405357	bpp_loss: 2.948380470275879	aux_loss: 410.5224609375
10:33:34 INFO - main: Train iter. 4900/200000 (2.45%): 	Loss: 3.696453332901001	recon_loss: 0.024480313062667847	bpp_loss: 2.9620440006256104	aux_loss: 408.0318603515625
10:33:52 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 3.6593456268310547	recon_loss: 0.024286748841404915	bpp_loss: 2.9307432174682617	aux_loss: 405.5741271972656
10:34:02 INFO - main: {'TEST MSE': 0.02439559359277627, 'TEST BPP': 2.9905625, 'TEST loss': 3.6754802129268644, 'TEST recon_loss': 0.024395593516528605, 'TEST bpp_loss': 2.9436124074459076}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:34:20 INFO - main: Train iter. 5100/200000 (2.55%): 	Loss: 3.6566474437713623	recon_loss: 0.02434893697500229	bpp_loss: 2.9261794090270996	aux_loss: 403.142578125
10:34:38 INFO - main: Train iter. 5200/200000 (2.6%): 	Loss: 3.675210952758789	recon_loss: 0.024370932951569557	bpp_loss: 2.9440829753875732	aux_loss: 400.6357421875
10:34:56 INFO - main: Train iter. 5300/200000 (2.65%): 	Loss: 3.6520309448242188	recon_loss: 0.024328693747520447	bpp_loss: 2.9221701622009277	aux_loss: 398.11669921875
10:35:14 INFO - main: Train iter. 5400/200000 (2.7%): 	Loss: 3.6908302307128906	recon_loss: 0.024543916806578636	bpp_loss: 2.954512596130371	aux_loss: 395.88861083984375
10:35:32 INFO - main: Train iter. 5500/200000 (2.75%): 	Loss: 3.680096387863159	recon_loss: 0.024750040844082832	bpp_loss: 2.9375951290130615	aux_loss: 393.754150390625
10:35:50 INFO - main: Train iter. 5600/200000 (2.8%): 	Loss: 3.670073986053467	recon_loss: 0.024467725306749344	bpp_loss: 2.936042308807373	aux_loss: 391.5592346191406
10:36:07 INFO - main: Train iter. 5700/200000 (2.85%): 	Loss: 3.6676406860351562	recon_loss: 0.024528753012418747	bpp_loss: 2.9317779541015625	aux_loss: 389.29559326171875
10:36:25 INFO - main: Train iter. 5800/200000 (2.9%): 	Loss: 3.680769205093384	recon_loss: 0.02446006052196026	bpp_loss: 2.946967363357544	aux_loss: 387.0440979003906
10:36:43 INFO - main: Train iter. 5900/200000 (2.95%): 	Loss: 3.6729321479797363	recon_loss: 0.024513665586709976	bpp_loss: 2.9375221729278564	aux_loss: 384.84716796875
10:37:01 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 3.6663472652435303	recon_loss: 0.024511100724339485	bpp_loss: 2.9310142993927	aux_loss: 382.3958740234375
10:37:19 INFO - main: Train iter. 6100/200000 (3.05%): 	Loss: 3.6659765243530273	recon_loss: 0.02449204958975315	bpp_loss: 2.9312150478363037	aux_loss: 380.1104431152344
10:37:37 INFO - main: Train iter. 6200/200000 (3.1%): 	Loss: 3.679335594177246	recon_loss: 0.02481662854552269	bpp_loss: 2.9348368644714355	aux_loss: 377.4913330078125
10:37:55 INFO - main: Train iter. 6300/200000 (3.15%): 	Loss: 3.661559581756592	recon_loss: 0.024552637711167336	bpp_loss: 2.924980401992798	aux_loss: 374.974853515625
10:38:13 INFO - main: Train iter. 6400/200000 (3.2%): 	Loss: 3.683889865875244	recon_loss: 0.024499179795384407	bpp_loss: 2.9489145278930664	aux_loss: 372.4195251464844
10:38:31 INFO - main: Train iter. 6500/200000 (3.25%): 	Loss: 3.658477306365967	recon_loss: 0.024494078010320663	bpp_loss: 2.9236550331115723	aux_loss: 369.830322265625
10:38:49 INFO - main: Train iter. 6600/200000 (3.3%): 	Loss: 3.6637916564941406	recon_loss: 0.024486718699336052	bpp_loss: 2.929190158843994	aux_loss: 367.0811767578125
10:39:09 INFO - main: Train iter. 6700/200000 (3.35%): 	Loss: 3.6737234592437744	recon_loss: 0.024730568751692772	bpp_loss: 2.9318063259124756	aux_loss: 364.3833312988281
10:39:27 INFO - main: Train iter. 6800/200000 (3.4%): 	Loss: 3.6552209854125977	recon_loss: 0.024394232779741287	bpp_loss: 2.923393964767456	aux_loss: 361.7513427734375
10:39:45 INFO - main: Train iter. 6900/200000 (3.45%): 	Loss: 3.6607894897460938	recon_loss: 0.02445674128830433	bpp_loss: 2.9270873069763184	aux_loss: 359.1173400878906
10:40:03 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 3.6639628410339355	recon_loss: 0.024442575871944427	bpp_loss: 2.930685520172119	aux_loss: 356.2607421875
10:40:20 INFO - main: Train iter. 7100/200000 (3.55%): 	Loss: 3.6559383869171143	recon_loss: 0.024444153532385826	bpp_loss: 2.9226138591766357	aux_loss: 353.203369140625
10:40:38 INFO - main: Train iter. 7200/200000 (3.6%): 	Loss: 3.6664154529571533	recon_loss: 0.0244403388351202	bpp_loss: 2.9332053661346436	aux_loss: 349.9794616699219
10:40:56 INFO - main: Train iter. 7300/200000 (3.65%): 	Loss: 3.6493067741394043	recon_loss: 0.024340294301509857	bpp_loss: 2.919097900390625	aux_loss: 346.7088623046875
10:41:14 INFO - main: Train iter. 7400/200000 (3.7%): 	Loss: 3.670868396759033	recon_loss: 0.024631774052977562	bpp_loss: 2.931915044784546	aux_loss: 343.3926696777344
10:41:32 INFO - main: Train iter. 7500/200000 (3.75%): 	Loss: 3.685016632080078	recon_loss: 0.024447720497846603	bpp_loss: 2.951585054397583	aux_loss: 340.12255859375
10:41:50 INFO - main: Train iter. 7600/200000 (3.8%): 	Loss: 3.659698963165283	recon_loss: 0.024376556277275085	bpp_loss: 2.9284021854400635	aux_loss: 336.86749267578125
10:42:08 INFO - main: Train iter. 7700/200000 (3.85%): 	Loss: 3.656559467315674	recon_loss: 0.024347204715013504	bpp_loss: 2.9261434078216553	aux_loss: 333.0784912109375
10:42:25 INFO - main: Train iter. 7800/200000 (3.9%): 	Loss: 3.654932975769043	recon_loss: 0.024333151057362556	bpp_loss: 2.924938440322876	aux_loss: 328.6707763671875
10:42:43 INFO - main: Train iter. 7900/200000 (3.95%): 	Loss: 3.679035186767578	recon_loss: 0.024498406797647476	bpp_loss: 2.9440829753875732	aux_loss: 324.8480224609375
10:43:01 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 3.661526918411255	recon_loss: 0.024344181641936302	bpp_loss: 2.931201457977295	aux_loss: 320.9147644042969
10:43:19 INFO - main: Train iter. 8100/200000 (4.05%): 	Loss: 3.655496835708618	recon_loss: 0.02431899681687355	bpp_loss: 2.925926923751831	aux_loss: 317.0985107421875
10:43:37 INFO - main: Train iter. 8200/200000 (4.1%): 	Loss: 3.658377170562744	recon_loss: 0.024359874427318573	bpp_loss: 2.9275808334350586	aux_loss: 312.9140319824219
10:43:55 INFO - main: Train iter. 8300/200000 (4.15%): 	Loss: 3.6618950366973877	recon_loss: 0.024299567565321922	bpp_loss: 2.932908058166504	aux_loss: 308.41326904296875
10:44:13 INFO - main: Train iter. 8400/200000 (4.2%): 	Loss: 3.675828456878662	recon_loss: 0.024269593879580498	bpp_loss: 2.9477405548095703	aux_loss: 303.733642578125
10:44:31 INFO - main: Train iter. 8500/200000 (4.25%): 	Loss: 3.6693472862243652	recon_loss: 0.02436600998044014	bpp_loss: 2.9383668899536133	aux_loss: 299.36822509765625
10:44:49 INFO - main: Train iter. 8600/200000 (4.3%): 	Loss: 3.6595230102539062	recon_loss: 0.024280734360218048	bpp_loss: 2.931101083755493	aux_loss: 294.5055236816406
10:45:07 INFO - main: Train iter. 8700/200000 (4.35%): 	Loss: 3.663900136947632	recon_loss: 0.024411780759692192	bpp_loss: 2.931546688079834	aux_loss: 289.403076171875
10:45:25 INFO - main: Train iter. 8800/200000 (4.4%): 	Loss: 3.661038637161255	recon_loss: 0.024245357140898705	bpp_loss: 2.933677911758423	aux_loss: 284.887451171875
10:45:43 INFO - main: Train iter. 8900/200000 (4.45%): 	Loss: 3.6527698040008545	recon_loss: 0.024306058883666992	bpp_loss: 2.9235880374908447	aux_loss: 279.835205078125
10:46:00 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 3.669034242630005	recon_loss: 0.024261794984340668	bpp_loss: 2.941180467605591	aux_loss: 274.35833740234375
10:46:18 INFO - main: Train iter. 9100/200000 (4.55%): 	Loss: 3.6595046520233154	recon_loss: 0.024543533101677895	bpp_loss: 2.923198699951172	aux_loss: 268.913330078125
10:46:36 INFO - main: Train iter. 9200/200000 (4.6%): 	Loss: 3.653677463531494	recon_loss: 0.02431078441441059	bpp_loss: 2.924354076385498	aux_loss: 263.50518798828125
10:46:54 INFO - main: Train iter. 9300/200000 (4.65%): 	Loss: 3.6558279991149902	recon_loss: 0.024238726124167442	bpp_loss: 2.928666353225708	aux_loss: 257.62701416015625
10:47:12 INFO - main: Train iter. 9400/200000 (4.7%): 	Loss: 3.64731764793396	recon_loss: 0.02421916276216507	bpp_loss: 2.9207427501678467	aux_loss: 252.4537353515625
10:47:30 INFO - main: Train iter. 9500/200000 (4.75%): 	Loss: 3.6580657958984375	recon_loss: 0.024198291823267937	bpp_loss: 2.932116985321045	aux_loss: 247.00779724121094
10:47:48 INFO - main: Train iter. 9600/200000 (4.8%): 	Loss: 3.642728090286255	recon_loss: 0.024180589243769646	bpp_loss: 2.9173104763031006	aux_loss: 240.766357421875
10:48:06 INFO - main: Train iter. 9700/200000 (4.85%): 	Loss: 3.6425349712371826	recon_loss: 0.024252766743302345	bpp_loss: 2.914952039718628	aux_loss: 235.50672912597656
10:48:24 INFO - main: Train iter. 9800/200000 (4.9%): 	Loss: 3.6476011276245117	recon_loss: 0.024234957993030548	bpp_loss: 2.9205522537231445	aux_loss: 229.27627563476562
10:48:42 INFO - main: Train iter. 9900/200000 (4.95%): 	Loss: 3.646820068359375	recon_loss: 0.02421959675848484	bpp_loss: 2.9202322959899902	aux_loss: 223.3760986328125
10:49:02 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 3.64992618560791	recon_loss: 0.024239547550678253	bpp_loss: 2.9227397441864014	aux_loss: 216.48435974121094
10:49:12 INFO - main: {'TEST MSE': 0.0242469630869235, 'TEST BPP': 2.9693125, 'TEST loss': 3.6496857402324676, 'TEST recon_loss': 0.024246963012963533, 'TEST bpp_loss': 2.9222768461704254}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:49:30 INFO - main: Train iter. 10100/200000 (5.05%): 	Loss: 3.6578409671783447	recon_loss: 0.024249522015452385	bpp_loss: 2.9303553104400635	aux_loss: 210.98146057128906
10:49:48 INFO - main: Train iter. 10200/200000 (5.1%): 	Loss: 3.6543259620666504	recon_loss: 0.02419814094901085	bpp_loss: 2.9283816814422607	aux_loss: 203.30088806152344
10:50:06 INFO - main: Train iter. 10300/200000 (5.15%): 	Loss: 3.6564533710479736	recon_loss: 0.02423299290239811	bpp_loss: 2.9294636249542236	aux_loss: 197.40289306640625
10:50:24 INFO - main: Train iter. 10400/200000 (5.2%): 	Loss: 3.6468825340270996	recon_loss: 0.024184830486774445	bpp_loss: 2.921337604522705	aux_loss: 190.40478515625
10:50:42 INFO - main: Train iter. 10500/200000 (5.25%): 	Loss: 3.643660068511963	recon_loss: 0.024252234026789665	bpp_loss: 2.916093111038208	aux_loss: 183.6002197265625
10:51:00 INFO - main: Train iter. 10600/200000 (5.3%): 	Loss: 3.6565639972686768	recon_loss: 0.024256911128759384	bpp_loss: 2.928856611251831	aux_loss: 176.26507568359375
10:51:18 INFO - main: Train iter. 10700/200000 (5.35%): 	Loss: 3.6374120712280273	recon_loss: 0.024146394804120064	bpp_loss: 2.913020133972168	aux_loss: 170.98617553710938
10:51:36 INFO - main: Train iter. 10800/200000 (5.4%): 	Loss: 3.673025608062744	recon_loss: 0.024985814467072487	bpp_loss: 2.9234511852264404	aux_loss: 163.2721405029297
10:51:53 INFO - main: Train iter. 10900/200000 (5.45%): 	Loss: 3.661025285720825	recon_loss: 0.024436861276626587	bpp_loss: 2.927919387817383	aux_loss: 157.44747924804688
10:52:11 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 3.6488876342773438	recon_loss: 0.024163050577044487	bpp_loss: 2.9239959716796875	aux_loss: 149.83761596679688
10:52:29 INFO - main: Train iter. 11100/200000 (5.55%): 	Loss: 3.640657901763916	recon_loss: 0.024167176336050034	bpp_loss: 2.915642738342285	aux_loss: 141.6927032470703
10:52:47 INFO - main: Train iter. 11200/200000 (5.6%): 	Loss: 3.624464988708496	recon_loss: 0.024125726893544197	bpp_loss: 2.90069317817688	aux_loss: 133.75204467773438
10:53:05 INFO - main: Train iter. 11300/200000 (5.65%): 	Loss: 3.638972282409668	recon_loss: 0.02418498508632183	bpp_loss: 2.9134228229522705	aux_loss: 127.11954498291016
10:53:23 INFO - main: Train iter. 11400/200000 (5.7%): 	Loss: 3.636958122253418	recon_loss: 0.02414541505277157	bpp_loss: 2.912595748901367	aux_loss: 120.00639343261719
10:53:41 INFO - main: Train iter. 11500/200000 (5.75%): 	Loss: 3.633430242538452	recon_loss: 0.024174261838197708	bpp_loss: 2.9082024097442627	aux_loss: 113.44920349121094
10:53:59 INFO - main: Train iter. 11600/200000 (5.8%): 	Loss: 3.6520915031433105	recon_loss: 0.024100270122289658	bpp_loss: 2.9290833473205566	aux_loss: 105.95704650878906
10:54:17 INFO - main: Train iter. 11700/200000 (5.85%): 	Loss: 3.6426801681518555	recon_loss: 0.02422497421503067	bpp_loss: 2.915930986404419	aux_loss: 100.11885833740234
10:54:35 INFO - main: Train iter. 11800/200000 (5.9%): 	Loss: 3.6280059814453125	recon_loss: 0.02413840778172016	bpp_loss: 2.90385365486145	aux_loss: 91.98487854003906
10:54:53 INFO - main: Train iter. 11900/200000 (5.95%): 	Loss: 3.643603801727295	recon_loss: 0.024113347753882408	bpp_loss: 2.920203447341919	aux_loss: 85.84942626953125
10:55:11 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 3.6298911571502686	recon_loss: 0.02403324283659458	bpp_loss: 2.9088938236236572	aux_loss: 80.666748046875
10:55:29 INFO - main: Train iter. 12100/200000 (6.05%): 	Loss: 3.6548895835876465	recon_loss: 0.02446078136563301	bpp_loss: 2.9210660457611084	aux_loss: 73.99519348144531
10:55:46 INFO - main: Train iter. 12200/200000 (6.1%): 	Loss: 3.651200294494629	recon_loss: 0.02419842965900898	bpp_loss: 2.9252474308013916	aux_loss: 68.8287353515625
10:56:04 INFO - main: Train iter. 12300/200000 (6.15%): 	Loss: 3.638223886489868	recon_loss: 0.024098768830299377	bpp_loss: 2.9152607917785645	aux_loss: 63.73065948486328
10:56:22 INFO - main: Train iter. 12400/200000 (6.2%): 	Loss: 3.6493587493896484	recon_loss: 0.024142248556017876	bpp_loss: 2.92509126663208	aux_loss: 59.278465270996094
10:56:40 INFO - main: Train iter. 12500/200000 (6.25%): 	Loss: 3.6456456184387207	recon_loss: 0.024290472269058228	bpp_loss: 2.916931390762329	aux_loss: 54.87812042236328
10:56:58 INFO - main: Train iter. 12600/200000 (6.3%): 	Loss: 3.660146474838257	recon_loss: 0.024210436269640923	bpp_loss: 2.933833360671997	aux_loss: 51.0364990234375
10:57:16 INFO - main: Train iter. 12700/200000 (6.35%): 	Loss: 3.640831708908081	recon_loss: 0.024171756580471992	bpp_loss: 2.9156789779663086	aux_loss: 47.834781646728516
10:57:34 INFO - main: Train iter. 12800/200000 (6.4%): 	Loss: 3.660294532775879	recon_loss: 0.02420825883746147	bpp_loss: 2.934046745300293	aux_loss: 44.480323791503906
10:57:52 INFO - main: Train iter. 12900/200000 (6.45%): 	Loss: 3.6339147090911865	recon_loss: 0.024180596694350243	bpp_loss: 2.908496856689453	aux_loss: 41.74894714355469
10:58:10 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 3.634477138519287	recon_loss: 0.02413870021700859	bpp_loss: 2.910316228866577	aux_loss: 38.2503662109375
10:58:28 INFO - main: Train iter. 13100/200000 (6.55%): 	Loss: 3.6446456909179688	recon_loss: 0.024184325709939003	bpp_loss: 2.9191157817840576	aux_loss: 35.502227783203125
10:58:46 INFO - main: Train iter. 13200/200000 (6.6%): 	Loss: 3.6548495292663574	recon_loss: 0.02425772324204445	bpp_loss: 2.9271178245544434	aux_loss: 33.08021545410156
10:59:04 INFO - main: Train iter. 13300/200000 (6.65%): 	Loss: 3.634516716003418	recon_loss: 0.02414894476532936	bpp_loss: 2.910048246383667	aux_loss: 30.743642807006836
10:59:24 INFO - main: Train iter. 13400/200000 (6.7%): 	Loss: 3.6476426124572754	recon_loss: 0.02419132925570011	bpp_loss: 2.921902656555176	aux_loss: 28.300703048706055
10:59:42 INFO - main: Train iter. 13500/200000 (6.75%): 	Loss: 3.6261866092681885	recon_loss: 0.024070436134934425	bpp_loss: 2.904073476791382	aux_loss: 25.991302490234375
11:00:00 INFO - main: Train iter. 13600/200000 (6.8%): 	Loss: 3.6438705921173096	recon_loss: 0.024183085188269615	bpp_loss: 2.9183781147003174	aux_loss: 23.70690155029297
11:00:18 INFO - main: Train iter. 13700/200000 (6.85%): 	Loss: 3.6511600017547607	recon_loss: 0.02423185296356678	bpp_loss: 2.9242043495178223	aux_loss: 21.294837951660156
11:00:36 INFO - main: Train iter. 13800/200000 (6.9%): 	Loss: 3.625131130218506	recon_loss: 0.024118196219205856	bpp_loss: 2.901585340499878	aux_loss: 19.25696563720703
11:00:54 INFO - main: Train iter. 13900/200000 (6.95%): 	Loss: 3.632744789123535	recon_loss: 0.02422024868428707	bpp_loss: 2.906137228012085	aux_loss: 17.447269439697266
11:01:12 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 3.618922472000122	recon_loss: 0.02405611053109169	bpp_loss: 2.8972392082214355	aux_loss: 15.831680297851562
11:01:30 INFO - main: Train iter. 14100/200000 (7.05%): 	Loss: 3.655679941177368	recon_loss: 0.0242831539362669	bpp_loss: 2.927185297012329	aux_loss: 14.226144790649414
11:01:47 INFO - main: Train iter. 14200/200000 (7.1%): 	Loss: 3.635237455368042	recon_loss: 0.024165306240320206	bpp_loss: 2.9102783203125	aux_loss: 12.80710220336914
11:02:05 INFO - main: Train iter. 14300/200000 (7.15%): 	Loss: 3.6366989612579346	recon_loss: 0.02410169318318367	bpp_loss: 2.9136481285095215	aux_loss: 11.784061431884766
11:02:23 INFO - main: Train iter. 14400/200000 (7.2%): 	Loss: 3.6438498497009277	recon_loss: 0.024296579882502556	bpp_loss: 2.914952516555786	aux_loss: 10.110945701599121
11:02:41 INFO - main: Train iter. 14500/200000 (7.25%): 	Loss: 3.626741409301758	recon_loss: 0.024151436984539032	bpp_loss: 2.902198314666748	aux_loss: 8.533548355102539
11:02:59 INFO - main: Train iter. 14600/200000 (7.3%): 	Loss: 3.632077693939209	recon_loss: 0.024273240938782692	bpp_loss: 2.9038803577423096	aux_loss: 7.649532318115234
11:03:17 INFO - main: Train iter. 14700/200000 (7.35%): 	Loss: 3.6411211490631104	recon_loss: 0.024175994098186493	bpp_loss: 2.9158413410186768	aux_loss: 6.880550861358643
11:03:35 INFO - main: Train iter. 14800/200000 (7.4%): 	Loss: 3.6570119857788086	recon_loss: 0.024188188835978508	bpp_loss: 2.931366443634033	aux_loss: 6.046274185180664
11:03:53 INFO - main: Train iter. 14900/200000 (7.45%): 	Loss: 3.6422674655914307	recon_loss: 0.024173155426979065	bpp_loss: 2.9170727729797363	aux_loss: 5.261556625366211
11:04:11 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 3.6457290649414062	recon_loss: 0.02429070509970188	bpp_loss: 2.9170079231262207	aux_loss: 4.842827796936035
11:04:20 INFO - main: {'TEST MSE': 0.024362571751106708, 'TEST BPP': 2.96615625, 'TEST loss': 3.648478101015091, 'TEST recon_loss': 0.02436257167905569, 'TEST bpp_loss': 2.9176009488105774}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:04:38 INFO - main: Train iter. 15100/200000 (7.55%): 	Loss: 3.638226270675659	recon_loss: 0.024363894015550613	bpp_loss: 2.9073095321655273	aux_loss: 3.612199306488037
11:04:56 INFO - main: Train iter. 15200/200000 (7.6%): 	Loss: 3.635129451751709	recon_loss: 0.02433355338871479	bpp_loss: 2.905122756958008	aux_loss: 3.058101177215576
11:05:14 INFO - main: Train iter. 15300/200000 (7.65%): 	Loss: 3.628016233444214	recon_loss: 0.024125050753355026	bpp_loss: 2.9042646884918213	aux_loss: 2.6422019004821777
11:05:32 INFO - main: Train iter. 15400/200000 (7.7%): 	Loss: 3.641998291015625	recon_loss: 0.024117497727274895	bpp_loss: 2.918473243713379	aux_loss: 2.2965593338012695
11:05:50 INFO - main: Train iter. 15500/200000 (7.75%): 	Loss: 3.630533218383789	recon_loss: 0.024176038801670074	bpp_loss: 2.905251979827881	aux_loss: 2.005826234817505
11:06:08 INFO - main: Train iter. 15600/200000 (7.8%): 	Loss: 3.647312879562378	recon_loss: 0.024182438850402832	bpp_loss: 2.921839714050293	aux_loss: 1.1789377927780151
11:06:26 INFO - main: Train iter. 15700/200000 (7.85%): 	Loss: 3.6569509506225586	recon_loss: 0.024234531447291374	bpp_loss: 2.929914951324463	aux_loss: 0.9396030902862549
11:06:43 INFO - main: Train iter. 15800/200000 (7.9%): 	Loss: 3.630920886993408	recon_loss: 0.02414037473499775	bpp_loss: 2.906709671020508	aux_loss: 0.6895848512649536
11:07:01 INFO - main: Train iter. 15900/200000 (7.95%): 	Loss: 3.64229154586792	recon_loss: 0.024128083139657974	bpp_loss: 2.9184491634368896	aux_loss: 0.4232209324836731
11:07:19 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 3.6519088745117188	recon_loss: 0.024213207885622978	bpp_loss: 2.9255125522613525	aux_loss: 0.7783825993537903
11:07:37 INFO - main: Train iter. 16100/200000 (8.05%): 	Loss: 3.6303911209106445	recon_loss: 0.024188293144106865	bpp_loss: 2.9047422409057617	aux_loss: 0.2626873552799225
11:07:55 INFO - main: Train iter. 16200/200000 (8.1%): 	Loss: 3.6349430084228516	recon_loss: 0.024234360083937645	bpp_loss: 2.907912254333496	aux_loss: 0.3959497809410095
11:08:13 INFO - main: Train iter. 16300/200000 (8.15%): 	Loss: 3.6421451568603516	recon_loss: 0.024152418598532677	bpp_loss: 2.917572498321533	aux_loss: 0.522114634513855
11:08:31 INFO - main: Train iter. 16400/200000 (8.2%): 	Loss: 3.646681547164917	recon_loss: 0.024211851879954338	bpp_loss: 2.920325994491577	aux_loss: 0.6508089303970337
11:08:48 INFO - main: Train iter. 16500/200000 (8.25%): 	Loss: 3.6253280639648438	recon_loss: 0.024103378877043724	bpp_loss: 2.902226686477661	aux_loss: 0.292491614818573
11:09:06 INFO - main: Train iter. 16600/200000 (8.3%): 	Loss: 3.6155829429626465	recon_loss: 0.024186082184314728	bpp_loss: 2.890000581741333	aux_loss: 0.262743204832077
11:09:27 INFO - main: Train iter. 16700/200000 (8.35%): 	Loss: 3.6513209342956543	recon_loss: 0.02500157058238983	bpp_loss: 2.901273727416992	aux_loss: 0.3780148923397064
11:09:44 INFO - main: Train iter. 16800/200000 (8.4%): 	Loss: 3.6383936405181885	recon_loss: 0.02424616925418377	bpp_loss: 2.911008596420288	aux_loss: 0.6727033853530884
11:10:02 INFO - main: Train iter. 16900/200000 (8.45%): 	Loss: 3.6720757484436035	recon_loss: 0.024672996252775192	bpp_loss: 2.9318859577178955	aux_loss: 0.7498177289962769
11:10:20 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 3.6349642276763916	recon_loss: 0.024199476465582848	bpp_loss: 2.908979892730713	aux_loss: 0.2501108646392822
11:10:38 INFO - main: Train iter. 17100/200000 (8.55%): 	Loss: 3.64449405670166	recon_loss: 0.024354511871933937	bpp_loss: 2.913858652114868	aux_loss: 0.2869762182235718
11:10:56 INFO - main: Train iter. 17200/200000 (8.6%): 	Loss: 3.6298627853393555	recon_loss: 0.02410249225795269	bpp_loss: 2.9067881107330322	aux_loss: 0.8972203135490417
11:11:14 INFO - main: Train iter. 17300/200000 (8.65%): 	Loss: 3.6418144702911377	recon_loss: 0.024171750992536545	bpp_loss: 2.9166619777679443	aux_loss: 1.2406322956085205
11:11:32 INFO - main: Train iter. 17400/200000 (8.7%): 	Loss: 3.6433258056640625	recon_loss: 0.024184830486774445	bpp_loss: 2.917780876159668	aux_loss: 0.6211403012275696
11:11:50 INFO - main: Train iter. 17500/200000 (8.75%): 	Loss: 3.635540008544922	recon_loss: 0.024295996874570847	bpp_loss: 2.9066600799560547	aux_loss: 0.3815031051635742
11:12:07 INFO - main: Train iter. 17600/200000 (8.8%): 	Loss: 3.637451171875	recon_loss: 0.024135228246450424	bpp_loss: 2.9133942127227783	aux_loss: 0.4750865697860718
11:12:25 INFO - main: Train iter. 17700/200000 (8.85%): 	Loss: 3.6401655673980713	recon_loss: 0.024180840700864792	bpp_loss: 2.9147403240203857	aux_loss: 0.7724988460540771
11:12:43 INFO - main: Train iter. 17800/200000 (8.9%): 	Loss: 3.6326019763946533	recon_loss: 0.024102814495563507	bpp_loss: 2.909517526626587	aux_loss: 0.19656234979629517
11:13:01 INFO - main: Train iter. 17900/200000 (8.95%): 	Loss: 3.630127429962158	recon_loss: 0.024123692885041237	bpp_loss: 2.906416654586792	aux_loss: 0.6846007108688354
11:13:19 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 3.6453089714050293	recon_loss: 0.02421235293149948	bpp_loss: 2.918938398361206	aux_loss: 0.24898171424865723
11:13:37 INFO - main: Train iter. 18100/200000 (9.05%): 	Loss: 3.6526310443878174	recon_loss: 0.024164455011487007	bpp_loss: 2.9276974201202393	aux_loss: 0.8377628326416016
11:13:54 INFO - main: Train iter. 18200/200000 (9.1%): 	Loss: 3.65264630317688	recon_loss: 0.02430034428834915	bpp_loss: 2.923635959625244	aux_loss: 0.23411035537719727
11:14:12 INFO - main: Train iter. 18300/200000 (9.15%): 	Loss: 3.637578010559082	recon_loss: 0.024123556911945343	bpp_loss: 2.9138712882995605	aux_loss: 0.31691786646842957
11:14:30 INFO - main: Train iter. 18400/200000 (9.2%): 	Loss: 3.640956163406372	recon_loss: 0.02422976680099964	bpp_loss: 2.9140632152557373	aux_loss: 0.343807190656662
11:14:48 INFO - main: Train iter. 18500/200000 (9.25%): 	Loss: 3.636983633041382	recon_loss: 0.02416626363992691	bpp_loss: 2.9119956493377686	aux_loss: 0.6117777824401855
11:15:06 INFO - main: Train iter. 18600/200000 (9.3%): 	Loss: 3.647040843963623	recon_loss: 0.02423664927482605	bpp_loss: 2.9199414253234863	aux_loss: 0.2542736828327179
11:15:24 INFO - main: Train iter. 18700/200000 (9.35%): 	Loss: 3.6420769691467285	recon_loss: 0.024191534146666527	bpp_loss: 2.9163308143615723	aux_loss: 0.41439661383628845
11:15:42 INFO - main: Train iter. 18800/200000 (9.4%): 	Loss: 3.650883913040161	recon_loss: 0.02420123480260372	bpp_loss: 2.924846887588501	aux_loss: 0.22801116108894348
11:15:59 INFO - main: Train iter. 18900/200000 (9.45%): 	Loss: 3.638686180114746	recon_loss: 0.024190524592995644	bpp_loss: 2.912970542907715	aux_loss: 0.2546466588973999
11:16:17 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 3.651693820953369	recon_loss: 0.02419270947575569	bpp_loss: 2.925912618637085	aux_loss: 0.9097659587860107
11:16:35 INFO - main: Train iter. 19100/200000 (9.55%): 	Loss: 3.636669397354126	recon_loss: 0.024293972179293633	bpp_loss: 2.9078502655029297	aux_loss: 0.22581903636455536
11:16:53 INFO - main: Train iter. 19200/200000 (9.6%): 	Loss: 3.645995616912842	recon_loss: 0.024212632328271866	bpp_loss: 2.91961669921875	aux_loss: 0.32507598400115967
11:17:11 INFO - main: Train iter. 19300/200000 (9.65%): 	Loss: 3.611765146255493	recon_loss: 0.0241258442401886	bpp_loss: 2.8879897594451904	aux_loss: 0.46339213848114014
11:17:29 INFO - main: Train iter. 19400/200000 (9.7%): 	Loss: 3.622588634490967	recon_loss: 0.024167103692889214	bpp_loss: 2.8975753784179688	aux_loss: 0.7001878023147583
11:17:47 INFO - main: Train iter. 19500/200000 (9.75%): 	Loss: 3.6466803550720215	recon_loss: 0.02430843748152256	bpp_loss: 2.9174273014068604	aux_loss: 0.5072301030158997
11:18:05 INFO - main: Train iter. 19600/200000 (9.8%): 	Loss: 3.65250301361084	recon_loss: 0.024299243465065956	bpp_loss: 2.92352557182312	aux_loss: 0.32553157210350037
11:18:23 INFO - main: Train iter. 19700/200000 (9.85%): 	Loss: 3.6397666931152344	recon_loss: 0.02436027303338051	bpp_loss: 2.9089584350585938	aux_loss: 1.0095707178115845
11:18:40 INFO - main: Train iter. 19800/200000 (9.9%): 	Loss: 3.6235618591308594	recon_loss: 0.02418273128569126	bpp_loss: 2.8980798721313477	aux_loss: 0.2855302095413208
11:18:58 INFO - main: Train iter. 19900/200000 (9.95%): 	Loss: 3.632448196411133	recon_loss: 0.024329515174031258	bpp_loss: 2.9025628566741943	aux_loss: 0.3303869962692261
11:19:19 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 3.6294808387756348	recon_loss: 0.024281758815050125	bpp_loss: 2.9010281562805176	aux_loss: 0.20955711603164673
11:19:29 INFO - main: {'TEST MSE': 0.024307331875138522, 'TEST BPP': 2.963, 'TEST loss': 3.6433379108905792, 'TEST recon_loss': 0.024307331789284944, 'TEST bpp_loss': 2.914117957353592}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:19:46 INFO - main: Train iter. 20100/200000 (10.05%): 	Loss: 3.642092227935791	recon_loss: 0.02433868870139122	bpp_loss: 2.9119315147399902	aux_loss: 0.7700740098953247
11:20:04 INFO - main: Train iter. 20200/200000 (10.1%): 	Loss: 3.6333584785461426	recon_loss: 0.02419172041118145	bpp_loss: 2.907606840133667	aux_loss: 0.42259225249290466
11:20:22 INFO - main: Train iter. 20300/200000 (10.15%): 	Loss: 3.6495957374572754	recon_loss: 0.024180008098483086	bpp_loss: 2.9241955280303955	aux_loss: 0.7858741283416748
11:20:40 INFO - main: Train iter. 20400/200000 (10.2%): 	Loss: 3.643143892288208	recon_loss: 0.02436707727611065	bpp_loss: 2.9121315479278564	aux_loss: 0.37118998169898987
11:20:58 INFO - main: Train iter. 20500/200000 (10.25%): 	Loss: 3.634166717529297	recon_loss: 0.024292543530464172	bpp_loss: 2.9053902626037598	aux_loss: 0.28839752078056335
11:21:16 INFO - main: Train iter. 20600/200000 (10.3%): 	Loss: 3.6405727863311768	recon_loss: 0.024192072451114655	bpp_loss: 2.9148106575012207	aux_loss: 0.6346327066421509
11:21:34 INFO - main: Train iter. 20700/200000 (10.35%): 	Loss: 3.6379456520080566	recon_loss: 0.024174362421035767	bpp_loss: 2.912714719772339	aux_loss: 0.46983325481414795
11:21:51 INFO - main: Train iter. 20800/200000 (10.4%): 	Loss: 3.649318218231201	recon_loss: 0.02427034266293049	bpp_loss: 2.921207904815674	aux_loss: 0.37039363384246826
11:22:09 INFO - main: Train iter. 20900/200000 (10.45%): 	Loss: 3.61600923538208	recon_loss: 0.0240810364484787	bpp_loss: 2.893578052520752	aux_loss: 0.3070366680622101
11:22:28 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 3.6586761474609375	recon_loss: 0.02425682172179222	bpp_loss: 2.930971384048462	aux_loss: 0.22568389773368835
11:22:45 INFO - main: Train iter. 21100/200000 (10.55%): 	Loss: 3.6428701877593994	recon_loss: 0.024184323847293854	bpp_loss: 2.9173405170440674	aux_loss: 0.21175771951675415
11:23:03 INFO - main: Train iter. 21200/200000 (10.6%): 	Loss: 3.632720708847046	recon_loss: 0.024169722571969032	bpp_loss: 2.9076290130615234	aux_loss: 0.5428021550178528
11:23:21 INFO - main: Train iter. 21300/200000 (10.65%): 	Loss: 3.648256301879883	recon_loss: 0.02440062165260315	bpp_loss: 2.9162375926971436	aux_loss: 0.44005876779556274
11:23:39 INFO - main: Train iter. 21400/200000 (10.7%): 	Loss: 3.6486854553222656	recon_loss: 0.0245133675634861	bpp_loss: 2.9132843017578125	aux_loss: 0.42086488008499146
11:23:57 INFO - main: Train iter. 21500/200000 (10.75%): 	Loss: 3.6379804611206055	recon_loss: 0.024116436019539833	bpp_loss: 2.914487361907959	aux_loss: 0.18516795337200165
11:24:15 INFO - main: Train iter. 21600/200000 (10.8%): 	Loss: 3.633513927459717	recon_loss: 0.024240510538220406	bpp_loss: 2.9062986373901367	aux_loss: 0.46226266026496887
11:24:33 INFO - main: Train iter. 21700/200000 (10.85%): 	Loss: 3.626406192779541	recon_loss: 0.024144405499100685	bpp_loss: 2.902074098587036	aux_loss: 0.47016990184783936
11:24:51 INFO - main: Train iter. 21800/200000 (10.9%): 	Loss: 3.648850202560425	recon_loss: 0.02422618865966797	bpp_loss: 2.9220645427703857	aux_loss: 0.33811306953430176
11:25:09 INFO - main: Train iter. 21900/200000 (10.95%): 	Loss: 3.6411244869232178	recon_loss: 0.024138500913977623	bpp_loss: 2.9169695377349854	aux_loss: 0.33823326230049133
11:25:26 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 3.641777276992798	recon_loss: 0.024201763793826103	bpp_loss: 2.915724277496338	aux_loss: 0.264434814453125
11:25:44 INFO - main: Train iter. 22100/200000 (11.05%): 	Loss: 3.6309127807617188	recon_loss: 0.02415466494858265	bpp_loss: 2.9062728881835938	aux_loss: 0.2805742025375366
11:26:02 INFO - main: Train iter. 22200/200000 (11.1%): 	Loss: 3.6389968395233154	recon_loss: 0.024210620671510696	bpp_loss: 2.9126782417297363	aux_loss: 0.24688540399074554
11:26:20 INFO - main: Train iter. 22300/200000 (11.15%): 	Loss: 3.6369400024414062	recon_loss: 0.024118272587656975	bpp_loss: 2.9133918285369873	aux_loss: 0.5085890293121338
11:26:38 INFO - main: Train iter. 22400/200000 (11.2%): 	Loss: 3.6347858905792236	recon_loss: 0.02419743500649929	bpp_loss: 2.908862829208374	aux_loss: 0.7632234692573547
11:26:56 INFO - main: Train iter. 22500/200000 (11.25%): 	Loss: 3.641587257385254	recon_loss: 0.024205250665545464	bpp_loss: 2.9154298305511475	aux_loss: 0.43940070271492004
11:27:14 INFO - main: Train iter. 22600/200000 (11.3%): 	Loss: 3.6296794414520264	recon_loss: 0.02411700040102005	bpp_loss: 2.9061694145202637	aux_loss: 0.3062150478363037
11:27:31 INFO - main: Train iter. 22700/200000 (11.35%): 	Loss: 3.6401076316833496	recon_loss: 0.024235494434833527	bpp_loss: 2.9130427837371826	aux_loss: 0.37561678886413574
11:27:49 INFO - main: Train iter. 22800/200000 (11.4%): 	Loss: 3.6440649032592773	recon_loss: 0.02429364062845707	bpp_loss: 2.9152557849884033	aux_loss: 1.0564779043197632
11:28:07 INFO - main: Train iter. 22900/200000 (11.45%): 	Loss: 3.6348142623901367	recon_loss: 0.02414339780807495	bpp_loss: 2.9105122089385986	aux_loss: 0.29932573437690735
11:28:25 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 3.6425304412841797	recon_loss: 0.024189744144678116	bpp_loss: 2.9168381690979004	aux_loss: 0.33716118335723877
11:28:43 INFO - main: Train iter. 23100/200000 (11.55%): 	Loss: 3.64479660987854	recon_loss: 0.024266613647341728	bpp_loss: 2.9167981147766113	aux_loss: 1.545081377029419
11:29:01 INFO - main: Train iter. 23200/200000 (11.6%): 	Loss: 3.6570470333099365	recon_loss: 0.024264587089419365	bpp_loss: 2.9291093349456787	aux_loss: 0.8996744155883789
11:29:21 INFO - main: Train iter. 23300/200000 (11.65%): 	Loss: 3.6317410469055176	recon_loss: 0.024281099438667297	bpp_loss: 2.903308153152466	aux_loss: 0.2925395667552948
11:29:39 INFO - main: Train iter. 23400/200000 (11.7%): 	Loss: 3.6323673725128174	recon_loss: 0.024182476103305817	bpp_loss: 2.906893014907837	aux_loss: 0.6988151669502258
11:29:57 INFO - main: Train iter. 23500/200000 (11.75%): 	Loss: 3.629499673843384	recon_loss: 0.024212518706917763	bpp_loss: 2.9031240940093994	aux_loss: 0.1879018247127533
11:30:15 INFO - main: Train iter. 23600/200000 (11.8%): 	Loss: 3.6475300788879395	recon_loss: 0.02421669103205204	bpp_loss: 2.9210293292999268	aux_loss: 0.3225027322769165
11:30:33 INFO - main: Train iter. 23700/200000 (11.85%): 	Loss: 3.6453630924224854	recon_loss: 0.024201704189181328	bpp_loss: 2.919312000274658	aux_loss: 0.6412258744239807
11:30:51 INFO - main: Train iter. 23800/200000 (11.9%): 	Loss: 3.628492593765259	recon_loss: 0.024165073409676552	bpp_loss: 2.9035403728485107	aux_loss: 1.1365865468978882
11:31:08 INFO - main: Train iter. 23900/200000 (11.95%): 	Loss: 3.63639497756958	recon_loss: 0.02417827397584915	bpp_loss: 2.9110467433929443	aux_loss: 0.28751081228256226
11:31:26 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 3.6497552394866943	recon_loss: 0.024301791563630104	bpp_loss: 2.920701503753662	aux_loss: 0.3579541742801666
11:31:44 INFO - main: Train iter. 24100/200000 (12.05%): 	Loss: 3.651151418685913	recon_loss: 0.024202466011047363	bpp_loss: 2.925077438354492	aux_loss: 0.576069176197052
11:32:02 INFO - main: Train iter. 24200/200000 (12.1%): 	Loss: 3.6520495414733887	recon_loss: 0.02437938190996647	bpp_loss: 2.920668125152588	aux_loss: 0.8290749192237854
11:32:20 INFO - main: Train iter. 24300/200000 (12.15%): 	Loss: 3.627455472946167	recon_loss: 0.024140341207385063	bpp_loss: 2.903245210647583	aux_loss: 0.22694532573223114
11:32:38 INFO - main: Train iter. 24400/200000 (12.2%): 	Loss: 3.6480891704559326	recon_loss: 0.024348242208361626	bpp_loss: 2.9176418781280518	aux_loss: 0.34491002559661865
11:32:56 INFO - main: Train iter. 24500/200000 (12.25%): 	Loss: 3.634941816329956	recon_loss: 0.024153850972652435	bpp_loss: 2.9103262424468994	aux_loss: 0.34125715494155884
11:33:13 INFO - main: Train iter. 24600/200000 (12.3%): 	Loss: 3.627645492553711	recon_loss: 0.024136187508702278	bpp_loss: 2.903559923171997	aux_loss: 0.21524029970169067
11:33:31 INFO - main: Train iter. 24700/200000 (12.35%): 	Loss: 3.6386237144470215	recon_loss: 0.02417953684926033	bpp_loss: 2.9132375717163086	aux_loss: 0.30460891127586365
11:33:49 INFO - main: Train iter. 24800/200000 (12.4%): 	Loss: 3.6595664024353027	recon_loss: 0.02446698397397995	bpp_loss: 2.9255568981170654	aux_loss: 0.34566959738731384
11:34:07 INFO - main: Train iter. 24900/200000 (12.45%): 	Loss: 3.6369757652282715	recon_loss: 0.02420905791223049	bpp_loss: 2.9107038974761963	aux_loss: 0.5771249532699585
11:34:25 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 3.635716438293457	recon_loss: 0.024115685373544693	bpp_loss: 2.912245750427246	aux_loss: 0.43103715777397156
11:34:35 INFO - main: {'TEST MSE': 0.024612887582427346, 'TEST BPP': 2.9606875, 'TEST loss': 3.6506511783599853, 'TEST recon_loss': 0.02461288748309016, 'TEST bpp_loss': 2.9122645537853242}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:34:52 INFO - main: Train iter. 25100/200000 (12.55%): 	Loss: 3.6450822353363037	recon_loss: 0.024249054491519928	bpp_loss: 2.9176106452941895	aux_loss: 0.3897443413734436
11:35:10 INFO - main: Train iter. 25200/200000 (12.6%): 	Loss: 3.6431117057800293	recon_loss: 0.024239622056484222	bpp_loss: 2.9159231185913086	aux_loss: 0.24696572124958038
11:35:28 INFO - main: Train iter. 25300/200000 (12.65%): 	Loss: 3.6301231384277344	recon_loss: 0.02415628917515278	bpp_loss: 2.9054346084594727	aux_loss: 0.3133111000061035
11:35:46 INFO - main: Train iter. 25400/200000 (12.7%): 	Loss: 3.6295762062072754	recon_loss: 0.024134578183293343	bpp_loss: 2.90553879737854	aux_loss: 0.2668575644493103
11:36:03 INFO - main: Train iter. 25500/200000 (12.75%): 	Loss: 3.641721248626709	recon_loss: 0.024233615025877953	bpp_loss: 2.91471266746521	aux_loss: 0.27213943004608154
11:36:21 INFO - main: Train iter. 25600/200000 (12.8%): 	Loss: 3.6313037872314453	recon_loss: 0.024215921759605408	bpp_loss: 2.9048261642456055	aux_loss: 0.2207975685596466
11:36:39 INFO - main: Train iter. 25700/200000 (12.85%): 	Loss: 3.6391139030456543	recon_loss: 0.02421778440475464	bpp_loss: 2.9125804901123047	aux_loss: 0.2383953332901001
11:36:57 INFO - main: Train iter. 25800/200000 (12.9%): 	Loss: 3.6460165977478027	recon_loss: 0.024202603846788406	bpp_loss: 2.919938564300537	aux_loss: 0.6230583786964417
11:37:15 INFO - main: Train iter. 25900/200000 (12.95%): 	Loss: 3.632344961166382	recon_loss: 0.02418859675526619	bpp_loss: 2.906687021255493	aux_loss: 0.30266451835632324
11:37:32 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 3.631977081298828	recon_loss: 0.02417462132871151	bpp_loss: 2.906738519668579	aux_loss: 0.32685065269470215
11:37:50 INFO - main: Train iter. 26100/200000 (13.05%): 	Loss: 3.6436879634857178	recon_loss: 0.024229269474744797	bpp_loss: 2.9168097972869873	aux_loss: 0.21684622764587402
11:38:08 INFO - main: Train iter. 26200/200000 (13.1%): 	Loss: 3.6547160148620605	recon_loss: 0.024277880787849426	bpp_loss: 2.926379680633545	aux_loss: 0.4475131928920746
11:38:26 INFO - main: Train iter. 26300/200000 (13.15%): 	Loss: 3.6478826999664307	recon_loss: 0.024225642904639244	bpp_loss: 2.9211134910583496	aux_loss: 0.30097660422325134
11:38:44 INFO - main: Train iter. 26400/200000 (13.2%): 	Loss: 3.6408748626708984	recon_loss: 0.02417154237627983	bpp_loss: 2.9157285690307617	aux_loss: 0.22882917523384094
11:39:02 INFO - main: Train iter. 26500/200000 (13.25%): 	Loss: 3.6323838233947754	recon_loss: 0.02425740845501423	bpp_loss: 2.9046616554260254	aux_loss: 0.3637206554412842
11:39:19 INFO - main: Train iter. 26600/200000 (13.3%): 	Loss: 3.6353347301483154	recon_loss: 0.02415754832327366	bpp_loss: 2.9106082916259766	aux_loss: 0.9212164878845215
11:39:40 INFO - main: Train iter. 26700/200000 (13.35%): 	Loss: 3.6506035327911377	recon_loss: 0.02441275864839554	bpp_loss: 2.9182207584381104	aux_loss: 0.5273531675338745
11:39:58 INFO - main: Train iter. 26800/200000 (13.4%): 	Loss: 3.658202886581421	recon_loss: 0.024520616978406906	bpp_loss: 2.922584295272827	aux_loss: 0.3170916438102722
11:40:15 INFO - main: Train iter. 26900/200000 (13.45%): 	Loss: 3.628565549850464	recon_loss: 0.024141225963830948	bpp_loss: 2.9043288230895996	aux_loss: 0.19294683635234833
11:40:33 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 3.6428890228271484	recon_loss: 0.024376515299081802	bpp_loss: 2.911593437194824	aux_loss: 0.5433220863342285
11:40:51 INFO - main: Train iter. 27100/200000 (13.55%): 	Loss: 3.6333301067352295	recon_loss: 0.024115394800901413	bpp_loss: 2.9098682403564453	aux_loss: 0.6509701609611511
11:41:09 INFO - main: Train iter. 27200/200000 (13.6%): 	Loss: 3.6440179347991943	recon_loss: 0.024205436930060387	bpp_loss: 2.9178547859191895	aux_loss: 0.6083916425704956
11:41:27 INFO - main: Train iter. 27300/200000 (13.65%): 	Loss: 3.6487765312194824	recon_loss: 0.024208612740039825	bpp_loss: 2.922518253326416	aux_loss: 0.3093401789665222
11:41:45 INFO - main: Train iter. 27400/200000 (13.7%): 	Loss: 3.634587287902832	recon_loss: 0.02419584058225155	bpp_loss: 2.908712148666382	aux_loss: 0.398362934589386
11:42:02 INFO - main: Train iter. 27500/200000 (13.75%): 	Loss: 3.632035732269287	recon_loss: 0.024234099313616753	bpp_loss: 2.905012845993042	aux_loss: 0.2243461310863495
11:42:20 INFO - main: Train iter. 27600/200000 (13.8%): 	Loss: 3.6393256187438965	recon_loss: 0.024211736395955086	bpp_loss: 2.912973403930664	aux_loss: 0.3188198506832123
11:42:38 INFO - main: Train iter. 27700/200000 (13.85%): 	Loss: 3.6391830444335938	recon_loss: 0.02425117790699005	bpp_loss: 2.9116475582122803	aux_loss: 1.7232987880706787
11:42:56 INFO - main: Train iter. 27800/200000 (13.9%): 	Loss: 3.642329454421997	recon_loss: 0.0241868756711483	bpp_loss: 2.9167232513427734	aux_loss: 0.33583104610443115
11:43:14 INFO - main: Train iter. 27900/200000 (13.95%): 	Loss: 3.645421028137207	recon_loss: 0.024273274466395378	bpp_loss: 2.917222738265991	aux_loss: 1.0410263538360596
11:43:31 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 3.6131277084350586	recon_loss: 0.024094339460134506	bpp_loss: 2.8902974128723145	aux_loss: 0.2505958676338196
11:43:49 INFO - main: Train iter. 28100/200000 (14.05%): 	Loss: 3.637450933456421	recon_loss: 0.02419177070260048	bpp_loss: 2.9116978645324707	aux_loss: 0.7353495359420776
11:44:07 INFO - main: Train iter. 28200/200000 (14.1%): 	Loss: 3.631864309310913	recon_loss: 0.024165306240320206	bpp_loss: 2.906905174255371	aux_loss: 0.9629701972007751
11:44:25 INFO - main: Train iter. 28300/200000 (14.15%): 	Loss: 3.6487042903900146	recon_loss: 0.024242104962468147	bpp_loss: 2.921441078186035	aux_loss: 0.3685353398323059
11:44:42 INFO - main: Train iter. 28400/200000 (14.2%): 	Loss: 3.6405222415924072	recon_loss: 0.024168197065591812	bpp_loss: 2.9154763221740723	aux_loss: 0.8318691253662109
11:45:00 INFO - main: Train iter. 28500/200000 (14.25%): 	Loss: 3.6220827102661133	recon_loss: 0.024122849106788635	bpp_loss: 2.898397207260132	aux_loss: 0.4721989631652832
11:45:18 INFO - main: Train iter. 28600/200000 (14.3%): 	Loss: 3.641018867492676	recon_loss: 0.024308498948812485	bpp_loss: 2.911763906478882	aux_loss: 0.4438226819038391
11:45:36 INFO - main: Train iter. 28700/200000 (14.35%): 	Loss: 3.638674736022949	recon_loss: 0.02418457344174385	bpp_loss: 2.913137674331665	aux_loss: 0.42030465602874756
11:45:53 INFO - main: Train iter. 28800/200000 (14.4%): 	Loss: 3.6298651695251465	recon_loss: 0.024123838171362877	bpp_loss: 2.9061501026153564	aux_loss: 0.6793100833892822
11:46:11 INFO - main: Train iter. 28900/200000 (14.45%): 	Loss: 3.635080099105835	recon_loss: 0.024122141301631927	bpp_loss: 2.9114158153533936	aux_loss: 0.8023614287376404
11:46:29 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 3.6326770782470703	recon_loss: 0.024208541959524155	bpp_loss: 2.9064207077026367	aux_loss: 1.0215373039245605
11:46:47 INFO - main: Train iter. 29100/200000 (14.55%): 	Loss: 3.6418697834014893	recon_loss: 0.024174531921744347	bpp_loss: 2.9166338443756104	aux_loss: 0.24563291668891907
11:47:05 INFO - main: Train iter. 29200/200000 (14.6%): 	Loss: 3.641904354095459	recon_loss: 0.024225564673542976	bpp_loss: 2.915137529373169	aux_loss: 1.0492597818374634
11:47:22 INFO - main: Train iter. 29300/200000 (14.65%): 	Loss: 3.6196885108947754	recon_loss: 0.02418045699596405	bpp_loss: 2.8942747116088867	aux_loss: 1.0969330072402954
11:47:40 INFO - main: Train iter. 29400/200000 (14.7%): 	Loss: 3.624711036682129	recon_loss: 0.024160750210285187	bpp_loss: 2.899888515472412	aux_loss: 0.39304119348526
11:47:58 INFO - main: Train iter. 29500/200000 (14.75%): 	Loss: 3.6402130126953125	recon_loss: 0.024318628013134003	bpp_loss: 2.910654306411743	aux_loss: 0.18801575899124146
11:48:16 INFO - main: Train iter. 29600/200000 (14.8%): 	Loss: 3.6320457458496094	recon_loss: 0.024208948016166687	bpp_loss: 2.9057774543762207	aux_loss: 0.3620316684246063
11:48:34 INFO - main: Train iter. 29700/200000 (14.85%): 	Loss: 3.623748540878296	recon_loss: 0.024295205250382423	bpp_loss: 2.894892454147339	aux_loss: 0.21005654335021973
11:48:52 INFO - main: Train iter. 29800/200000 (14.9%): 	Loss: 3.6302149295806885	recon_loss: 0.02415786311030388	bpp_loss: 2.9054789543151855	aux_loss: 0.6826050877571106
11:49:09 INFO - main: Train iter. 29900/200000 (14.95%): 	Loss: 3.636244058609009	recon_loss: 0.024202754721045494	bpp_loss: 2.9101614952087402	aux_loss: 0.19172239303588867
11:49:30 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 3.629429817199707	recon_loss: 0.02422967180609703	bpp_loss: 2.9025397300720215	aux_loss: 0.3121001720428467
11:49:39 INFO - main: {'TEST MSE': 0.024436421326750824, 'TEST BPP': 2.95971875, 'TEST loss': 3.6441774122714996, 'TEST recon_loss': 0.02443642128072679, 'TEST bpp_loss': 2.911084770441055}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:49:57 INFO - main: Train iter. 30100/200000 (15.05%): 	Loss: 3.632694721221924	recon_loss: 0.024153172969818115	bpp_loss: 2.90809965133667	aux_loss: 0.20221520960330963
11:50:15 INFO - main: Train iter. 30200/200000 (15.1%): 	Loss: 3.629455089569092	recon_loss: 0.024172784760594368	bpp_loss: 2.9042716026306152	aux_loss: 0.24777817726135254
11:50:32 INFO - main: Train iter. 30300/200000 (15.15%): 	Loss: 3.651744842529297	recon_loss: 0.024291129782795906	bpp_loss: 2.92301082611084	aux_loss: 0.2661864757537842
11:50:50 INFO - main: Train iter. 30400/200000 (15.2%): 	Loss: 3.6278505325317383	recon_loss: 0.02419288270175457	bpp_loss: 2.902064085006714	aux_loss: 0.9895921349525452
11:51:08 INFO - main: Train iter. 30500/200000 (15.25%): 	Loss: 3.6241650581359863	recon_loss: 0.02415614202618599	bpp_loss: 2.8994808197021484	aux_loss: 0.31887221336364746
11:51:25 INFO - main: Train iter. 30600/200000 (15.3%): 	Loss: 3.6561622619628906	recon_loss: 0.02430165931582451	bpp_loss: 2.927112579345703	aux_loss: 0.5486611127853394
11:51:43 INFO - main: Train iter. 30700/200000 (15.35%): 	Loss: 3.6623549461364746	recon_loss: 0.024545351043343544	bpp_loss: 2.925994396209717	aux_loss: 0.2678457200527191
11:52:01 INFO - main: Train iter. 30800/200000 (15.4%): 	Loss: 3.6144776344299316	recon_loss: 0.024131925776600838	bpp_loss: 2.890519857406616	aux_loss: 0.33834031224250793
11:52:18 INFO - main: Train iter. 30900/200000 (15.45%): 	Loss: 3.6362547874450684	recon_loss: 0.02417132258415222	bpp_loss: 2.9111151695251465	aux_loss: 0.2856452465057373
11:52:36 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 3.645578145980835	recon_loss: 0.024290259927511215	bpp_loss: 2.916870355606079	aux_loss: 0.591691255569458
11:52:54 INFO - main: Train iter. 31100/200000 (15.55%): 	Loss: 3.648378849029541	recon_loss: 0.02437642216682434	bpp_loss: 2.917086124420166	aux_loss: 0.20164501667022705
11:53:11 INFO - main: Train iter. 31200/200000 (15.6%): 	Loss: 3.628268241882324	recon_loss: 0.024191180244088173	bpp_loss: 2.9025328159332275	aux_loss: 0.22057922184467316
11:53:29 INFO - main: Train iter. 31300/200000 (15.65%): 	Loss: 3.637813091278076	recon_loss: 0.024133015424013138	bpp_loss: 2.913822650909424	aux_loss: 0.3963812589645386
11:53:47 INFO - main: Train iter. 31400/200000 (15.7%): 	Loss: 3.6450042724609375	recon_loss: 0.024437513202428818	bpp_loss: 2.911878824234009	aux_loss: 0.6855687499046326
11:54:05 INFO - main: Train iter. 31500/200000 (15.75%): 	Loss: 3.6242427825927734	recon_loss: 0.024256303906440735	bpp_loss: 2.8965537548065186	aux_loss: 0.7445869445800781
11:54:23 INFO - main: Train iter. 31600/200000 (15.8%): 	Loss: 3.631600856781006	recon_loss: 0.02418539486825466	bpp_loss: 2.906038999557495	aux_loss: 0.3336721360683441
11:54:40 INFO - main: Train iter. 31700/200000 (15.85%): 	Loss: 3.6350626945495605	recon_loss: 0.024210505187511444	bpp_loss: 2.908747434616089	aux_loss: 0.5483683943748474
11:54:58 INFO - main: Train iter. 31800/200000 (15.9%): 	Loss: 3.647416114807129	recon_loss: 0.02443793974816799	bpp_loss: 2.914278030395508	aux_loss: 0.29353171586990356
11:55:16 INFO - main: Train iter. 31900/200000 (15.95%): 	Loss: 3.629098415374756	recon_loss: 0.024173256009817123	bpp_loss: 2.9039008617401123	aux_loss: 0.18605850636959076
11:55:34 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 3.6495957374572754	recon_loss: 0.024222247302532196	bpp_loss: 2.9229283332824707	aux_loss: 0.24571624398231506
11:55:52 INFO - main: Train iter. 32100/200000 (16.05%): 	Loss: 3.6288726329803467	recon_loss: 0.024176064878702164	bpp_loss: 2.903590679168701	aux_loss: 0.7484652996063232
11:56:10 INFO - main: Train iter. 32200/200000 (16.1%): 	Loss: 3.6214566230773926	recon_loss: 0.02412751130759716	bpp_loss: 2.8976311683654785	aux_loss: 0.3169941306114197
11:56:28 INFO - main: Train iter. 32300/200000 (16.15%): 	Loss: 3.654317855834961	recon_loss: 0.024241968989372253	bpp_loss: 2.927058696746826	aux_loss: 0.26896393299102783
11:56:45 INFO - main: Train iter. 32400/200000 (16.2%): 	Loss: 3.6329898834228516	recon_loss: 0.02425803616642952	bpp_loss: 2.9052488803863525	aux_loss: 0.27672848105430603
11:57:03 INFO - main: Train iter. 32500/200000 (16.25%): 	Loss: 3.617549419403076	recon_loss: 0.024077896028757095	bpp_loss: 2.895212411880493	aux_loss: 0.5220984816551208
11:57:21 INFO - main: Train iter. 32600/200000 (16.3%): 	Loss: 3.63179874420166	recon_loss: 0.02416153997182846	bpp_loss: 2.9069526195526123	aux_loss: 0.29178720712661743
11:57:39 INFO - main: Train iter. 32700/200000 (16.35%): 	Loss: 3.6303048133850098	recon_loss: 0.024321051314473152	bpp_loss: 2.9006731510162354	aux_loss: 0.7305920720100403
11:57:57 INFO - main: Train iter. 32800/200000 (16.4%): 	Loss: 3.6300759315490723	recon_loss: 0.024136146530508995	bpp_loss: 2.905991554260254	aux_loss: 0.5002343058586121
11:58:14 INFO - main: Train iter. 32900/200000 (16.45%): 	Loss: 3.638274908065796	recon_loss: 0.024144984781742096	bpp_loss: 2.9139254093170166	aux_loss: 0.2331944853067398
11:58:32 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 3.6355347633361816	recon_loss: 0.024208128452301025	bpp_loss: 2.9092907905578613	aux_loss: 0.3522069454193115
11:58:50 INFO - main: Train iter. 33100/200000 (16.55%): 	Loss: 3.64522647857666	recon_loss: 0.024236690253019333	bpp_loss: 2.918125867843628	aux_loss: 0.21881678700447083
11:59:07 INFO - main: Train iter. 33200/200000 (16.6%): 	Loss: 3.6411125659942627	recon_loss: 0.02421487122774124	bpp_loss: 2.9146664142608643	aux_loss: 0.2279442995786667
11:59:27 INFO - main: Train iter. 33300/200000 (16.65%): 	Loss: 3.618623733520508	recon_loss: 0.02411164902150631	bpp_loss: 2.8952741622924805	aux_loss: 0.2566855549812317
11:59:45 INFO - main: Train iter. 33400/200000 (16.7%): 	Loss: 3.643920421600342	recon_loss: 0.024319183081388474	bpp_loss: 2.9143450260162354	aux_loss: 0.774378776550293
12:00:03 INFO - main: Train iter. 33500/200000 (16.75%): 	Loss: 3.622063398361206	recon_loss: 0.02424483373761177	bpp_loss: 2.8947184085845947	aux_loss: 0.4208683967590332
12:00:20 INFO - main: Train iter. 33600/200000 (16.8%): 	Loss: 3.6512200832366943	recon_loss: 0.024262849241495132	bpp_loss: 2.9233345985412598	aux_loss: 0.8915847539901733
12:00:38 INFO - main: Train iter. 33700/200000 (16.85%): 	Loss: 3.623988151550293	recon_loss: 0.02411048114299774	bpp_loss: 2.9006738662719727	aux_loss: 0.6836624145507812
12:00:56 INFO - main: Train iter. 33800/200000 (16.9%): 	Loss: 3.6346328258514404	recon_loss: 0.02424049563705921	bpp_loss: 2.9074180126190186	aux_loss: 0.16450044512748718
12:01:13 INFO - main: Train iter. 33900/200000 (16.95%): 	Loss: 3.617870330810547	recon_loss: 0.02416282333433628	bpp_loss: 2.8929855823516846	aux_loss: 0.2651013731956482
12:01:31 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 3.6255900859832764	recon_loss: 0.02414637990295887	bpp_loss: 2.901198625564575	aux_loss: 0.41585880517959595
12:01:49 INFO - main: Train iter. 34100/200000 (17.05%): 	Loss: 3.6222712993621826	recon_loss: 0.024124694988131523	bpp_loss: 2.8985304832458496	aux_loss: 0.23968718945980072
12:02:06 INFO - main: Train iter. 34200/200000 (17.1%): 	Loss: 3.630636215209961	recon_loss: 0.02411165088415146	bpp_loss: 2.9072866439819336	aux_loss: 0.3609809875488281
12:02:24 INFO - main: Train iter. 34300/200000 (17.15%): 	Loss: 3.644087314605713	recon_loss: 0.0243056807667017	bpp_loss: 2.9149169921875	aux_loss: 0.4137158989906311
12:02:42 INFO - main: Train iter. 34400/200000 (17.2%): 	Loss: 3.639753818511963	recon_loss: 0.02419930137693882	bpp_loss: 2.9137747287750244	aux_loss: 0.17556264996528625
12:02:59 INFO - main: Train iter. 34500/200000 (17.25%): 	Loss: 3.6596360206604004	recon_loss: 0.024312175810337067	bpp_loss: 2.9302706718444824	aux_loss: 0.24691492319107056
12:03:17 INFO - main: Train iter. 34600/200000 (17.3%): 	Loss: 3.637190818786621	recon_loss: 0.024185802787542343	bpp_loss: 2.911616802215576	aux_loss: 0.4773951768875122
12:03:35 INFO - main: Train iter. 34700/200000 (17.35%): 	Loss: 3.636956214904785	recon_loss: 0.024185819551348686	bpp_loss: 2.911381483078003	aux_loss: 0.29990825057029724
12:03:52 INFO - main: Train iter. 34800/200000 (17.4%): 	Loss: 3.627551794052124	recon_loss: 0.024183060973882675	bpp_loss: 2.902060031890869	aux_loss: 0.6017107367515564
12:04:10 INFO - main: Train iter. 34900/200000 (17.45%): 	Loss: 3.648618698120117	recon_loss: 0.024224700406193733	bpp_loss: 2.92187762260437	aux_loss: 0.6887586116790771
12:04:28 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 3.6268391609191895	recon_loss: 0.02415592595934868	bpp_loss: 2.9021613597869873	aux_loss: 0.22312533855438232
12:04:37 INFO - main: {'TEST MSE': 0.024151196008564014, 'TEST BPP': 2.9589375, 'TEST loss': 3.6348321163654327, 'TEST recon_loss': 0.02415119589306414, 'TEST bpp_loss': 2.910296240568161}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:04:55 INFO - main: Train iter. 35100/200000 (17.55%): 	Loss: 3.6416735649108887	recon_loss: 0.024193624034523964	bpp_loss: 2.915864944458008	aux_loss: 0.23263747990131378
12:05:12 INFO - main: Train iter. 35200/200000 (17.6%): 	Loss: 3.638986349105835	recon_loss: 0.024317456409335136	bpp_loss: 2.9094626903533936	aux_loss: 0.37251752614974976
12:05:30 INFO - main: Train iter. 35300/200000 (17.65%): 	Loss: 3.62977933883667	recon_loss: 0.02424199879169464	bpp_loss: 2.902519464492798	aux_loss: 0.22542452812194824
12:05:48 INFO - main: Train iter. 35400/200000 (17.7%): 	Loss: 3.6283257007598877	recon_loss: 0.02434871345758438	bpp_loss: 2.89786434173584	aux_loss: 0.9215449690818787
12:06:05 INFO - main: Train iter. 35500/200000 (17.75%): 	Loss: 3.630343437194824	recon_loss: 0.02416260913014412	bpp_loss: 2.9054651260375977	aux_loss: 0.39131221175193787
12:06:23 INFO - main: Train iter. 35600/200000 (17.8%): 	Loss: 3.636467933654785	recon_loss: 0.024252912029623985	bpp_loss: 2.9088807106018066	aux_loss: 1.4202733039855957
12:06:41 INFO - main: Train iter. 35700/200000 (17.85%): 	Loss: 3.642794609069824	recon_loss: 0.024281132966279984	bpp_loss: 2.914360523223877	aux_loss: 0.2305120825767517
12:06:58 INFO - main: Train iter. 35800/200000 (17.9%): 	Loss: 3.630920648574829	recon_loss: 0.024169810116291046	bpp_loss: 2.9058263301849365	aux_loss: 0.40408170223236084
12:07:16 INFO - main: Train iter. 35900/200000 (17.95%): 	Loss: 3.6433815956115723	recon_loss: 0.024160346016287804	bpp_loss: 2.9185712337493896	aux_loss: 0.7237123250961304
12:07:33 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 3.6397409439086914	recon_loss: 0.02419985644519329	bpp_loss: 2.913745164871216	aux_loss: 0.3517042398452759
12:07:51 INFO - main: Train iter. 36100/200000 (18.05%): 	Loss: 3.628870964050293	recon_loss: 0.024189770221710205	bpp_loss: 2.9031779766082764	aux_loss: 0.4583182632923126
12:08:09 INFO - main: Train iter. 36200/200000 (18.1%): 	Loss: 3.6474382877349854	recon_loss: 0.024245327338576317	bpp_loss: 2.9200785160064697	aux_loss: 0.6152491569519043
12:08:26 INFO - main: Train iter. 36300/200000 (18.15%): 	Loss: 3.63919734954834	recon_loss: 0.024198781698942184	bpp_loss: 2.913233995437622	aux_loss: 0.27214911580085754
12:08:44 INFO - main: Train iter. 36400/200000 (18.2%): 	Loss: 3.639390707015991	recon_loss: 0.024216486141085625	bpp_loss: 2.912896156311035	aux_loss: 0.6781935691833496
12:09:02 INFO - main: Train iter. 36500/200000 (18.25%): 	Loss: 3.6267282962799072	recon_loss: 0.024189967662096024	bpp_loss: 2.901029348373413	aux_loss: 0.32507240772247314
12:09:22 INFO - main: Train iter. 36600/200000 (18.3%): 	Loss: 3.6187665462493896	recon_loss: 0.024091895669698715	bpp_loss: 2.896009683609009	aux_loss: 0.31432223320007324
12:09:39 INFO - main: Train iter. 36700/200000 (18.35%): 	Loss: 3.6225039958953857	recon_loss: 0.024086620658636093	bpp_loss: 2.8999054431915283	aux_loss: 0.49525490403175354
12:09:57 INFO - main: Train iter. 36800/200000 (18.4%): 	Loss: 3.635568618774414	recon_loss: 0.02413446269929409	bpp_loss: 2.9115347862243652	aux_loss: 1.1212806701660156
12:10:15 INFO - main: Train iter. 36900/200000 (18.45%): 	Loss: 3.635308027267456	recon_loss: 0.024151958525180817	bpp_loss: 2.9107491970062256	aux_loss: 0.74396812915802
12:10:32 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 3.6307830810546875	recon_loss: 0.024202091619372368	bpp_loss: 2.9047203063964844	aux_loss: 0.3530682921409607
12:10:50 INFO - main: Train iter. 37100/200000 (18.55%): 	Loss: 3.631016254425049	recon_loss: 0.02421307936310768	bpp_loss: 2.9046239852905273	aux_loss: 0.2948755919933319
12:11:08 INFO - main: Train iter. 37200/200000 (18.6%): 	Loss: 3.6230180263519287	recon_loss: 0.02411619760096073	bpp_loss: 2.8995320796966553	aux_loss: 0.3494873642921448
12:11:25 INFO - main: Train iter. 37300/200000 (18.65%): 	Loss: 3.6287059783935547	recon_loss: 0.024132931604981422	bpp_loss: 2.9047181606292725	aux_loss: 0.4307376742362976
12:11:43 INFO - main: Train iter. 37400/200000 (18.7%): 	Loss: 3.64802622795105	recon_loss: 0.02431282214820385	bpp_loss: 2.9186415672302246	aux_loss: 0.3679957091808319
12:12:01 INFO - main: Train iter. 37500/200000 (18.75%): 	Loss: 3.6296091079711914	recon_loss: 0.02420133352279663	bpp_loss: 2.903569221496582	aux_loss: 0.27124589681625366
12:12:18 INFO - main: Train iter. 37600/200000 (18.8%): 	Loss: 3.631300210952759	recon_loss: 0.02418733946979046	bpp_loss: 2.905679941177368	aux_loss: 0.19618210196495056
12:12:36 INFO - main: Train iter. 37700/200000 (18.85%): 	Loss: 3.6382558345794678	recon_loss: 0.02426764741539955	bpp_loss: 2.910226345062256	aux_loss: 0.32674309611320496
12:12:54 INFO - main: Train iter. 37800/200000 (18.9%): 	Loss: 3.6435937881469727	recon_loss: 0.02418609894812107	bpp_loss: 2.918010950088501	aux_loss: 0.22533103823661804
12:13:11 INFO - main: Train iter. 37900/200000 (18.95%): 	Loss: 3.626472234725952	recon_loss: 0.024144552648067474	bpp_loss: 2.9021356105804443	aux_loss: 0.2861365079879761
12:13:29 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 3.66628360748291	recon_loss: 0.024286888539791107	bpp_loss: 2.9376769065856934	aux_loss: 0.3783199191093445
12:13:46 INFO - main: Train iter. 38100/200000 (19.05%): 	Loss: 3.6482319831848145	recon_loss: 0.02421143464744091	bpp_loss: 2.921888828277588	aux_loss: 0.2619931995868683
12:14:04 INFO - main: Train iter. 38200/200000 (19.1%): 	Loss: 3.6374356746673584	recon_loss: 0.024181349202990532	bpp_loss: 2.9119951725006104	aux_loss: 0.27015072107315063
12:14:22 INFO - main: Train iter. 38300/200000 (19.15%): 	Loss: 3.6214709281921387	recon_loss: 0.02414766699075699	bpp_loss: 2.897040843963623	aux_loss: 0.5511788725852966
12:14:39 INFO - main: Train iter. 38400/200000 (19.2%): 	Loss: 3.658379554748535	recon_loss: 0.024307481944561005	bpp_loss: 2.929155111312866	aux_loss: 0.43350595235824585
12:14:57 INFO - main: Train iter. 38500/200000 (19.25%): 	Loss: 3.654500961303711	recon_loss: 0.024299077689647675	bpp_loss: 2.9255287647247314	aux_loss: 0.544478178024292
12:15:14 INFO - main: Train iter. 38600/200000 (19.3%): 	Loss: 3.643726348876953	recon_loss: 0.024219417944550514	bpp_loss: 2.9171438217163086	aux_loss: 0.24435003101825714
12:15:32 INFO - main: Train iter. 38700/200000 (19.35%): 	Loss: 3.635078191757202	recon_loss: 0.02419430948793888	bpp_loss: 2.9092488288879395	aux_loss: 0.46036192774772644
12:15:50 INFO - main: Train iter. 38800/200000 (19.4%): 	Loss: 3.625028371810913	recon_loss: 0.024119583889842033	bpp_loss: 2.9014408588409424	aux_loss: 0.5091862678527832
12:16:07 INFO - main: Train iter. 38900/200000 (19.45%): 	Loss: 3.6499462127685547	recon_loss: 0.024236058816313744	bpp_loss: 2.9228644371032715	aux_loss: 0.6103177666664124
12:16:25 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 3.6460812091827393	recon_loss: 0.02428244613111019	bpp_loss: 2.9176077842712402	aux_loss: 0.2895982563495636
12:16:43 INFO - main: Train iter. 39100/200000 (19.55%): 	Loss: 3.630746841430664	recon_loss: 0.0241787601262331	bpp_loss: 2.905384063720703	aux_loss: 0.2998954653739929
12:17:00 INFO - main: Train iter. 39200/200000 (19.6%): 	Loss: 3.643577814102173	recon_loss: 0.024141520261764526	bpp_loss: 2.919332265853882	aux_loss: 0.7592607140541077
12:17:18 INFO - main: Train iter. 39300/200000 (19.65%): 	Loss: 3.64088773727417	recon_loss: 0.02434777095913887	bpp_loss: 2.910454750061035	aux_loss: 0.47085145115852356
12:17:35 INFO - main: Train iter. 39400/200000 (19.7%): 	Loss: 3.630007266998291	recon_loss: 0.024149185046553612	bpp_loss: 2.905531644821167	aux_loss: 0.5356975793838501
12:17:53 INFO - main: Train iter. 39500/200000 (19.75%): 	Loss: 3.6220860481262207	recon_loss: 0.024145016446709633	bpp_loss: 2.897735595703125	aux_loss: 0.3840370774269104
12:18:11 INFO - main: Train iter. 39600/200000 (19.8%): 	Loss: 3.651007890701294	recon_loss: 0.024232596158981323	bpp_loss: 2.924030065536499	aux_loss: 0.6184178590774536
12:18:29 INFO - main: Train iter. 39700/200000 (19.85%): 	Loss: 3.6274466514587402	recon_loss: 0.02413218282163143	bpp_loss: 2.9034812450408936	aux_loss: 0.7051977515220642
12:18:46 INFO - main: Train iter. 39800/200000 (19.9%): 	Loss: 3.6382219791412354	recon_loss: 0.024195590987801552	bpp_loss: 2.9123542308807373	aux_loss: 0.34691092371940613
12:19:04 INFO - main: Train iter. 39900/200000 (19.95%): 	Loss: 3.6225509643554688	recon_loss: 0.024153519421815872	bpp_loss: 2.8979454040527344	aux_loss: 0.27609580755233765
12:19:25 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 3.63614559173584	recon_loss: 0.024193113669753075	bpp_loss: 2.9103522300720215	aux_loss: 0.8426765203475952
12:19:34 INFO - main: {'TEST MSE': 0.02418738333313547, 'TEST BPP': 2.957, 'TEST loss': 3.6342681488990785, 'TEST recon_loss': 0.02418738325871527, 'TEST bpp_loss': 2.9086466534137725}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:19:52 INFO - main: Train iter. 40100/200000 (20.05%): 	Loss: 3.6377105712890625	recon_loss: 0.024195969104766846	bpp_loss: 2.9118313789367676	aux_loss: 0.18059784173965454
12:20:10 INFO - main: Train iter. 40200/200000 (20.1%): 	Loss: 3.6190381050109863	recon_loss: 0.02406909503042698	bpp_loss: 2.896965265274048	aux_loss: 0.3815186023712158
12:20:27 INFO - main: Train iter. 40300/200000 (20.15%): 	Loss: 3.6188979148864746	recon_loss: 0.02414683811366558	bpp_loss: 2.8944926261901855	aux_loss: 0.5168637633323669
12:20:45 INFO - main: Train iter. 40400/200000 (20.2%): 	Loss: 3.6241660118103027	recon_loss: 0.02416960522532463	bpp_loss: 2.899077892303467	aux_loss: 0.9347734451293945
12:21:03 INFO - main: Train iter. 40500/200000 (20.25%): 	Loss: 3.651653528213501	recon_loss: 0.024367839097976685	bpp_loss: 2.9206182956695557	aux_loss: 0.49582722783088684
12:21:20 INFO - main: Train iter. 40600/200000 (20.3%): 	Loss: 3.6340389251708984	recon_loss: 0.024186035618185997	bpp_loss: 2.9084577560424805	aux_loss: 0.8392496109008789
12:21:38 INFO - main: Train iter. 40700/200000 (20.35%): 	Loss: 3.6387765407562256	recon_loss: 0.024281037971377373	bpp_loss: 2.9103453159332275	aux_loss: 0.4512072801589966
12:21:55 INFO - main: Train iter. 40800/200000 (20.4%): 	Loss: 3.639305591583252	recon_loss: 0.024193650111556053	bpp_loss: 2.9134960174560547	aux_loss: 0.27066463232040405
12:22:13 INFO - main: Train iter. 40900/200000 (20.45%): 	Loss: 3.6309943199157715	recon_loss: 0.024154914543032646	bpp_loss: 2.9063467979431152	aux_loss: 0.26129814982414246
12:22:31 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 3.6501760482788086	recon_loss: 0.024267597123980522	bpp_loss: 2.9221482276916504	aux_loss: 0.2792492210865021
12:22:48 INFO - main: Train iter. 41100/200000 (20.55%): 	Loss: 3.6384594440460205	recon_loss: 0.024147972464561462	bpp_loss: 2.914020299911499	aux_loss: 0.39064958691596985
12:23:06 INFO - main: Train iter. 41200/200000 (20.6%): 	Loss: 3.6436562538146973	recon_loss: 0.024222247302532196	bpp_loss: 2.9169888496398926	aux_loss: 0.1828884780406952
12:23:24 INFO - main: Train iter. 41300/200000 (20.65%): 	Loss: 3.6372761726379395	recon_loss: 0.024184592068195343	bpp_loss: 2.911738395690918	aux_loss: 0.28015193343162537
12:23:41 INFO - main: Train iter. 41400/200000 (20.7%): 	Loss: 3.6312408447265625	recon_loss: 0.02418004348874092	bpp_loss: 2.905839443206787	aux_loss: 0.24316957592964172
12:23:59 INFO - main: Train iter. 41500/200000 (20.75%): 	Loss: 3.6313531398773193	recon_loss: 0.024189621210098267	bpp_loss: 2.9056644439697266	aux_loss: 0.4512937664985657
12:24:16 INFO - main: Train iter. 41600/200000 (20.8%): 	Loss: 3.629626750946045	recon_loss: 0.02413259632885456	bpp_loss: 2.905648946762085	aux_loss: 0.23560629785060883
12:24:34 INFO - main: Train iter. 41700/200000 (20.85%): 	Loss: 3.626497268676758	recon_loss: 0.024105535820126534	bpp_loss: 2.9033312797546387	aux_loss: 0.31210076808929443
12:24:52 INFO - main: Train iter. 41800/200000 (20.9%): 	Loss: 3.649122714996338	recon_loss: 0.02428332157433033	bpp_loss: 2.9206230640411377	aux_loss: 1.465714931488037
12:25:09 INFO - main: Train iter. 41900/200000 (20.95%): 	Loss: 3.633563995361328	recon_loss: 0.024185026064515114	bpp_loss: 2.908013343811035	aux_loss: 0.8799725770950317
12:25:27 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 3.6388537883758545	recon_loss: 0.02418375574052334	bpp_loss: 2.9133410453796387	aux_loss: 0.47226983308792114
12:25:45 INFO - main: Train iter. 42100/200000 (21.05%): 	Loss: 3.637772798538208	recon_loss: 0.024201394990086555	bpp_loss: 2.911731004714966	aux_loss: 0.6425185203552246
12:26:02 INFO - main: Train iter. 42200/200000 (21.1%): 	Loss: 3.6336934566497803	recon_loss: 0.024241866543889046	bpp_loss: 2.906437397003174	aux_loss: 0.47623831033706665
12:26:20 INFO - main: Train iter. 42300/200000 (21.15%): 	Loss: 3.6371824741363525	recon_loss: 0.024219807237386703	bpp_loss: 2.910588264465332	aux_loss: 0.5101377367973328
12:26:38 INFO - main: Train iter. 42400/200000 (21.2%): 	Loss: 3.6339616775512695	recon_loss: 0.024110790342092514	bpp_loss: 2.910637855529785	aux_loss: 0.387480229139328
12:26:55 INFO - main: Train iter. 42500/200000 (21.25%): 	Loss: 3.6427693367004395	recon_loss: 0.024232925847172737	bpp_loss: 2.9157814979553223	aux_loss: 0.5377246737480164
12:27:13 INFO - main: Train iter. 42600/200000 (21.3%): 	Loss: 3.636054515838623	recon_loss: 0.02424415946006775	bpp_loss: 2.9087297916412354	aux_loss: 0.4260992109775543
12:27:30 INFO - main: Train iter. 42700/200000 (21.35%): 	Loss: 3.646698474884033	recon_loss: 0.02425239235162735	bpp_loss: 2.9191267490386963	aux_loss: 0.8775063753128052
12:27:48 INFO - main: Train iter. 42800/200000 (21.4%): 	Loss: 3.6333136558532715	recon_loss: 0.024199174717068672	bpp_loss: 2.9073383808135986	aux_loss: 0.24857661128044128
12:28:06 INFO - main: Train iter. 42900/200000 (21.45%): 	Loss: 3.6320900917053223	recon_loss: 0.02409631572663784	bpp_loss: 2.909200668334961	aux_loss: 0.9302344918251038
12:28:23 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 3.620250701904297	recon_loss: 0.024234307929873466	bpp_loss: 2.893221378326416	aux_loss: 0.5044975280761719
12:28:41 INFO - main: Train iter. 43100/200000 (21.55%): 	Loss: 3.642632007598877	recon_loss: 0.024180950596928596	bpp_loss: 2.917203426361084	aux_loss: 0.4287380576133728
12:28:59 INFO - main: Train iter. 43200/200000 (21.6%): 	Loss: 3.630146026611328	recon_loss: 0.02416290156543255	bpp_loss: 2.905258893966675	aux_loss: 0.5693124532699585
12:29:19 INFO - main: Train iter. 43300/200000 (21.65%): 	Loss: 3.6180925369262695	recon_loss: 0.024100111797451973	bpp_loss: 2.8950891494750977	aux_loss: 0.30394238233566284
12:29:37 INFO - main: Train iter. 43400/200000 (21.7%): 	Loss: 3.627340793609619	recon_loss: 0.02409769967198372	bpp_loss: 2.904409885406494	aux_loss: 0.7780250310897827
12:29:54 INFO - main: Train iter. 43500/200000 (21.75%): 	Loss: 3.619495391845703	recon_loss: 0.02410191111266613	bpp_loss: 2.8964381217956543	aux_loss: 0.31402528285980225
12:30:12 INFO - main: Train iter. 43600/200000 (21.8%): 	Loss: 3.6332149505615234	recon_loss: 0.024188149720430374	bpp_loss: 2.9075703620910645	aux_loss: 0.3954122066497803
12:30:30 INFO - main: Train iter. 43700/200000 (21.85%): 	Loss: 3.6236958503723145	recon_loss: 0.024127764627337456	bpp_loss: 2.8998630046844482	aux_loss: 1.0885868072509766
12:30:47 INFO - main: Train iter. 43800/200000 (21.9%): 	Loss: 3.6416573524475098	recon_loss: 0.024249032139778137	bpp_loss: 2.914186477661133	aux_loss: 0.4265393614768982
12:31:05 INFO - main: Train iter. 43900/200000 (21.95%): 	Loss: 3.6389474868774414	recon_loss: 0.024194438010454178	bpp_loss: 2.913114309310913	aux_loss: 0.43403303623199463
12:31:23 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 3.625598669052124	recon_loss: 0.024132393300533295	bpp_loss: 2.9016268253326416	aux_loss: 0.7116279602050781
12:31:40 INFO - main: Train iter. 44100/200000 (22.05%): 	Loss: 3.632676601409912	recon_loss: 0.024223534390330315	bpp_loss: 2.905970573425293	aux_loss: 0.7380526065826416
12:31:58 INFO - main: Train iter. 44200/200000 (22.1%): 	Loss: 3.6414310932159424	recon_loss: 0.02419031411409378	bpp_loss: 2.9157216548919678	aux_loss: 0.24273529648780823
12:32:15 INFO - main: Train iter. 44300/200000 (22.15%): 	Loss: 3.648953676223755	recon_loss: 0.024207908660173416	bpp_loss: 2.9227163791656494	aux_loss: 0.20913521945476532
12:32:33 INFO - main: Train iter. 44400/200000 (22.2%): 	Loss: 3.6337172985076904	recon_loss: 0.02415892481803894	bpp_loss: 2.908949613571167	aux_loss: 0.2745218873023987
12:32:51 INFO - main: Train iter. 44500/200000 (22.25%): 	Loss: 3.6395788192749023	recon_loss: 0.024209292605519295	bpp_loss: 2.913300037384033	aux_loss: 0.8880101442337036
12:33:08 INFO - main: Train iter. 44600/200000 (22.3%): 	Loss: 3.6374504566192627	recon_loss: 0.02423410676419735	bpp_loss: 2.9104273319244385	aux_loss: 0.3138121962547302
12:33:26 INFO - main: Train iter. 44700/200000 (22.35%): 	Loss: 3.6434900760650635	recon_loss: 0.024205686524510384	bpp_loss: 2.9173195362091064	aux_loss: 0.254097580909729
12:33:44 INFO - main: Train iter. 44800/200000 (22.4%): 	Loss: 3.645822763442993	recon_loss: 0.024217436090111732	bpp_loss: 2.919299602508545	aux_loss: 0.26072070002555847
12:34:02 INFO - main: Train iter. 44900/200000 (22.45%): 	Loss: 3.6359901428222656	recon_loss: 0.02413509413599968	bpp_loss: 2.9119372367858887	aux_loss: 0.5600031018257141
12:34:19 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 3.6470589637756348	recon_loss: 0.02448958531022072	bpp_loss: 2.9123713970184326	aux_loss: 0.20311418175697327
12:34:29 INFO - main: {'TEST MSE': 0.024801487284814055, 'TEST BPP': 2.95684375, 'TEST loss': 3.6525605585575103, 'TEST recon_loss': 0.024801487209275365, 'TEST bpp_loss': 2.9085159418582918}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:34:47 INFO - main: Train iter. 45100/200000 (22.55%): 	Loss: 3.64162015914917	recon_loss: 0.02425401099026203	bpp_loss: 2.9139997959136963	aux_loss: 0.6231513023376465
12:35:04 INFO - main: Train iter. 45200/200000 (22.6%): 	Loss: 3.6341753005981445	recon_loss: 0.024151217192411423	bpp_loss: 2.9096386432647705	aux_loss: 0.3118736147880554
12:35:22 INFO - main: Train iter. 45300/200000 (22.65%): 	Loss: 3.632737636566162	recon_loss: 0.0243662279099226	bpp_loss: 2.9017508029937744	aux_loss: 0.6236472725868225
12:35:39 INFO - main: Train iter. 45400/200000 (22.7%): 	Loss: 3.6283435821533203	recon_loss: 0.02418472059071064	bpp_loss: 2.902801990509033	aux_loss: 0.529524564743042
12:35:57 INFO - main: Train iter. 45500/200000 (22.75%): 	Loss: 3.6475861072540283	recon_loss: 0.02419644221663475	bpp_loss: 2.9216928482055664	aux_loss: 0.3287833631038666
12:36:14 INFO - main: Train iter. 45600/200000 (22.8%): 	Loss: 3.6323001384735107	recon_loss: 0.024180656298995018	bpp_loss: 2.9068803787231445	aux_loss: 0.7263320088386536
12:36:32 INFO - main: Train iter. 45700/200000 (22.85%): 	Loss: 3.6364593505859375	recon_loss: 0.024204926565289497	bpp_loss: 2.910311698913574	aux_loss: 0.5727674961090088
12:36:49 INFO - main: Train iter. 45800/200000 (22.9%): 	Loss: 3.632532835006714	recon_loss: 0.024217862635850906	bpp_loss: 2.9059970378875732	aux_loss: 0.36328428983688354
12:37:07 INFO - main: Train iter. 45900/200000 (22.95%): 	Loss: 3.625025749206543	recon_loss: 0.02417602576315403	bpp_loss: 2.899744987487793	aux_loss: 0.27428939938545227
12:37:25 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 3.623910427093506	recon_loss: 0.024176519364118576	bpp_loss: 2.8986148834228516	aux_loss: 0.9399132132530212
12:37:42 INFO - main: Train iter. 46100/200000 (23.05%): 	Loss: 3.6309990882873535	recon_loss: 0.02420354261994362	bpp_loss: 2.904892921447754	aux_loss: 0.4422956705093384
12:38:00 INFO - main: Train iter. 46200/200000 (23.1%): 	Loss: 3.617544651031494	recon_loss: 0.024088334292173386	bpp_loss: 2.894894599914551	aux_loss: 0.5025767087936401
12:38:17 INFO - main: Train iter. 46300/200000 (23.15%): 	Loss: 3.635300874710083	recon_loss: 0.024193527176976204	bpp_loss: 2.9094951152801514	aux_loss: 0.3586045503616333
12:38:35 INFO - main: Train iter. 46400/200000 (23.2%): 	Loss: 3.6319820880889893	recon_loss: 0.024180978536605835	bpp_loss: 2.906552791595459	aux_loss: 0.3395094871520996
12:38:53 INFO - main: Train iter. 46500/200000 (23.25%): 	Loss: 3.6213393211364746	recon_loss: 0.0241414662450552	bpp_loss: 2.897095203399658	aux_loss: 0.27413973212242126
12:39:13 INFO - main: Train iter. 46600/200000 (23.3%): 	Loss: 3.6241705417633057	recon_loss: 0.024063190445303917	bpp_loss: 2.9022748470306396	aux_loss: 0.4267253875732422
12:39:31 INFO - main: Train iter. 46700/200000 (23.35%): 	Loss: 3.6348631381988525	recon_loss: 0.024159763008356094	bpp_loss: 2.9100701808929443	aux_loss: 1.1097667217254639
12:39:48 INFO - main: Train iter. 46800/200000 (23.4%): 	Loss: 3.6227846145629883	recon_loss: 0.024162864312529564	bpp_loss: 2.8978986740112305	aux_loss: 0.9316251277923584
12:40:06 INFO - main: Train iter. 46900/200000 (23.45%): 	Loss: 3.6332714557647705	recon_loss: 0.024187471717596054	bpp_loss: 2.9076473712921143	aux_loss: 0.4190249741077423
12:40:23 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 3.628134250640869	recon_loss: 0.024164028465747833	bpp_loss: 2.9032132625579834	aux_loss: 0.43379080295562744
12:40:41 INFO - main: Train iter. 47100/200000 (23.55%): 	Loss: 3.6331558227539062	recon_loss: 0.024129798635840416	bpp_loss: 2.90926194190979	aux_loss: 0.30741870403289795
12:40:59 INFO - main: Train iter. 47200/200000 (23.6%): 	Loss: 3.6367931365966797	recon_loss: 0.024207422509789467	bpp_loss: 2.9105703830718994	aux_loss: 0.37238121032714844
12:41:16 INFO - main: Train iter. 47300/200000 (23.65%): 	Loss: 3.6246423721313477	recon_loss: 0.024118291214108467	bpp_loss: 2.9010937213897705	aux_loss: 0.3841371536254883
12:41:34 INFO - main: Train iter. 47400/200000 (23.7%): 	Loss: 3.628737211227417	recon_loss: 0.024160590022802353	bpp_loss: 2.9039194583892822	aux_loss: 0.23761986196041107
12:41:52 INFO - main: Train iter. 47500/200000 (23.75%): 	Loss: 3.632974863052368	recon_loss: 0.024184495210647583	bpp_loss: 2.907439947128296	aux_loss: 0.269167959690094
12:42:09 INFO - main: Train iter. 47600/200000 (23.8%): 	Loss: 3.6402029991149902	recon_loss: 0.02424934133887291	bpp_loss: 2.9127228260040283	aux_loss: 0.18249905109405518
12:42:27 INFO - main: Train iter. 47700/200000 (23.85%): 	Loss: 3.639843463897705	recon_loss: 0.024534085765480995	bpp_loss: 2.9038209915161133	aux_loss: 0.35162729024887085
12:42:45 INFO - main: Train iter. 47800/200000 (23.9%): 	Loss: 3.6203603744506836	recon_loss: 0.02410108782351017	bpp_loss: 2.8973276615142822	aux_loss: 0.5402818918228149
12:43:03 INFO - main: Train iter. 47900/200000 (23.95%): 	Loss: 3.6394596099853516	recon_loss: 0.024185825139284134	bpp_loss: 2.9138848781585693	aux_loss: 0.15981364250183105
12:43:20 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 3.633570432662964	recon_loss: 0.02418285794556141	bpp_loss: 2.9080846309661865	aux_loss: 0.440181702375412
12:43:38 INFO - main: Train iter. 48100/200000 (24.05%): 	Loss: 3.616213798522949	recon_loss: 0.024089358747005463	bpp_loss: 2.8935329914093018	aux_loss: 0.31317752599716187
12:43:55 INFO - main: Train iter. 48200/200000 (24.1%): 	Loss: 3.62477445602417	recon_loss: 0.024122487753629684	bpp_loss: 2.901099681854248	aux_loss: 0.4813440144062042
12:44:13 INFO - main: Train iter. 48300/200000 (24.15%): 	Loss: 3.6304500102996826	recon_loss: 0.024155473336577415	bpp_loss: 2.9057857990264893	aux_loss: 0.5867661237716675
12:44:31 INFO - main: Train iter. 48400/200000 (24.2%): 	Loss: 3.638366222381592	recon_loss: 0.02420525997877121	bpp_loss: 2.912208318710327	aux_loss: 0.23504206538200378
12:44:48 INFO - main: Train iter. 48500/200000 (24.25%): 	Loss: 3.647925615310669	recon_loss: 0.024297470226883888	bpp_loss: 2.919001579284668	aux_loss: 0.20524685084819794
12:45:06 INFO - main: Train iter. 48600/200000 (24.3%): 	Loss: 3.647735357284546	recon_loss: 0.024230558425188065	bpp_loss: 2.920818567276001	aux_loss: 0.30000489950180054
12:45:24 INFO - main: Train iter. 48700/200000 (24.35%): 	Loss: 3.6356277465820312	recon_loss: 0.024161189794540405	bpp_loss: 2.910792112350464	aux_loss: 0.7344509363174438
12:45:41 INFO - main: Train iter. 48800/200000 (24.4%): 	Loss: 3.6441385746002197	recon_loss: 0.024238361045718193	bpp_loss: 2.916987657546997	aux_loss: 0.7690912485122681
12:45:59 INFO - main: Train iter. 48900/200000 (24.45%): 	Loss: 3.6297800540924072	recon_loss: 0.024126514792442322	bpp_loss: 2.90598464012146	aux_loss: 0.47250896692276
12:46:16 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 3.623990774154663	recon_loss: 0.024124525487422943	bpp_loss: 2.900254964828491	aux_loss: 0.2491866499185562
12:46:34 INFO - main: Train iter. 49100/200000 (24.55%): 	Loss: 3.6387977600097656	recon_loss: 0.024188434705138206	bpp_loss: 2.913144588470459	aux_loss: 0.7227436304092407
12:46:51 INFO - main: Train iter. 49200/200000 (24.6%): 	Loss: 3.6268060207366943	recon_loss: 0.024144910275936127	bpp_loss: 2.902458667755127	aux_loss: 0.25560060143470764
12:47:09 INFO - main: Train iter. 49300/200000 (24.65%): 	Loss: 3.627267837524414	recon_loss: 0.02413337118923664	bpp_loss: 2.903266668319702	aux_loss: 0.20278242230415344
12:47:27 INFO - main: Train iter. 49400/200000 (24.7%): 	Loss: 3.6330699920654297	recon_loss: 0.02415231429040432	bpp_loss: 2.9085006713867188	aux_loss: 0.4475700855255127
12:47:44 INFO - main: Train iter. 49500/200000 (24.75%): 	Loss: 3.636204719543457	recon_loss: 0.024164574220776558	bpp_loss: 2.9112675189971924	aux_loss: 0.16357091069221497
12:48:02 INFO - main: Train iter. 49600/200000 (24.8%): 	Loss: 3.621629238128662	recon_loss: 0.02408558316528797	bpp_loss: 2.899061679840088	aux_loss: 0.2451009452342987
12:48:19 INFO - main: Train iter. 49700/200000 (24.85%): 	Loss: 3.6390507221221924	recon_loss: 0.024200711399316788	bpp_loss: 2.913029432296753	aux_loss: 0.2106790989637375
12:48:37 INFO - main: Train iter. 49800/200000 (24.9%): 	Loss: 3.6246581077575684	recon_loss: 0.02412412129342556	bpp_loss: 2.9009344577789307	aux_loss: 0.33484384417533875
12:48:55 INFO - main: Train iter. 49900/200000 (24.95%): 	Loss: 3.6301283836364746	recon_loss: 0.024141469970345497	bpp_loss: 2.905884265899658	aux_loss: 0.21783024072647095
12:49:15 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 3.62534236907959	recon_loss: 0.024151436984539032	bpp_loss: 2.90079927444458	aux_loss: 0.5326457023620605
12:49:25 INFO - main: {'TEST MSE': 0.02412895327891872, 'TEST BPP': 2.95640625, 'TEST loss': 3.6318753054141997, 'TEST recon_loss': 0.02412895317748189, 'TEST bpp_loss': 2.908006712436676}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:49:42 INFO - main: Train iter. 50100/200000 (25.05%): 	Loss: 3.6289148330688477	recon_loss: 0.024155326187610626	bpp_loss: 2.9042551517486572	aux_loss: 0.4193764925003052
12:50:00 INFO - main: Train iter. 50200/200000 (25.1%): 	Loss: 3.6481504440307617	recon_loss: 0.024415239691734314	bpp_loss: 2.9156932830810547	aux_loss: 0.3684765696525574
12:50:18 INFO - main: Train iter. 50300/200000 (25.15%): 	Loss: 3.621103286743164	recon_loss: 0.024095842614769936	bpp_loss: 2.8982279300689697	aux_loss: 0.7032064199447632
12:50:35 INFO - main: Train iter. 50400/200000 (25.2%): 	Loss: 3.6417195796966553	recon_loss: 0.024224799126386642	bpp_loss: 2.914975643157959	aux_loss: 0.24585716426372528
12:50:53 INFO - main: Train iter. 50500/200000 (25.25%): 	Loss: 3.639082908630371	recon_loss: 0.02420882135629654	bpp_loss: 2.912818193435669	aux_loss: 0.28991347551345825
12:51:10 INFO - main: Train iter. 50600/200000 (25.3%): 	Loss: 3.636322259902954	recon_loss: 0.024136796593666077	bpp_loss: 2.9122183322906494	aux_loss: 0.29197031259536743
12:51:28 INFO - main: Train iter. 50700/200000 (25.35%): 	Loss: 3.620943546295166	recon_loss: 0.024128349497914314	bpp_loss: 2.8970930576324463	aux_loss: 0.44789373874664307
12:51:46 INFO - main: Train iter. 50800/200000 (25.4%): 	Loss: 3.6345298290252686	recon_loss: 0.024201100692152977	bpp_loss: 2.908496856689453	aux_loss: 0.5598855018615723
12:52:03 INFO - main: Train iter. 50900/200000 (25.45%): 	Loss: 3.635922908782959	recon_loss: 0.02415618859231472	bpp_loss: 2.9112372398376465	aux_loss: 0.42735010385513306
12:52:21 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 3.632216691970825	recon_loss: 0.02407120354473591	bpp_loss: 2.910080671310425	aux_loss: 0.3451705873012543
12:52:39 INFO - main: Train iter. 51100/200000 (25.55%): 	Loss: 3.6304550170898438	recon_loss: 0.024107670411467552	bpp_loss: 2.9072248935699463	aux_loss: 0.5101215839385986
12:52:56 INFO - main: Train iter. 51200/200000 (25.6%): 	Loss: 3.6405129432678223	recon_loss: 0.024367472156882286	bpp_loss: 2.9094889163970947	aux_loss: 0.7523196935653687
12:53:14 INFO - main: Train iter. 51300/200000 (25.65%): 	Loss: 3.636131763458252	recon_loss: 0.024175170809030533	bpp_loss: 2.910876750946045	aux_loss: 0.27122819423675537
12:53:31 INFO - main: Train iter. 51400/200000 (25.7%): 	Loss: 3.628035306930542	recon_loss: 0.024158041924238205	bpp_loss: 2.903294086456299	aux_loss: 0.8409310579299927
12:53:49 INFO - main: Train iter. 51500/200000 (25.75%): 	Loss: 3.626343011856079	recon_loss: 0.024106595665216446	bpp_loss: 2.9031450748443604	aux_loss: 0.5534623265266418
12:54:06 INFO - main: Train iter. 51600/200000 (25.8%): 	Loss: 3.6324362754821777	recon_loss: 0.02417474426329136	bpp_loss: 2.907193899154663	aux_loss: 0.4346078336238861
12:54:24 INFO - main: Train iter. 51700/200000 (25.85%): 	Loss: 3.638962507247925	recon_loss: 0.02421024814248085	bpp_loss: 2.9126551151275635	aux_loss: 0.6810141801834106
12:54:41 INFO - main: Train iter. 51800/200000 (25.9%): 	Loss: 3.617084503173828	recon_loss: 0.02411818690598011	bpp_loss: 2.8935389518737793	aux_loss: 0.27928733825683594
12:54:59 INFO - main: Train iter. 51900/200000 (25.95%): 	Loss: 3.628330707550049	recon_loss: 0.02413611114025116	bpp_loss: 2.904247522354126	aux_loss: 0.40976646542549133
12:55:17 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 3.6384949684143066	recon_loss: 0.024178115651011467	bpp_loss: 2.913151502609253	aux_loss: 0.3545847237110138
12:55:34 INFO - main: Train iter. 52100/200000 (26.05%): 	Loss: 3.641300916671753	recon_loss: 0.024193691089749336	bpp_loss: 2.91549015045166	aux_loss: 0.3675050139427185
12:55:52 INFO - main: Train iter. 52200/200000 (26.1%): 	Loss: 3.637406349182129	recon_loss: 0.024184640496969223	bpp_loss: 2.911867141723633	aux_loss: 0.516934871673584
12:56:09 INFO - main: Train iter. 52300/200000 (26.15%): 	Loss: 3.6437578201293945	recon_loss: 0.024303870275616646	bpp_loss: 2.914641857147217	aux_loss: 0.25421980023384094
12:56:27 INFO - main: Train iter. 52400/200000 (26.2%): 	Loss: 3.637983798980713	recon_loss: 0.024166585877537727	bpp_loss: 2.9129862785339355	aux_loss: 0.6064294576644897
12:56:44 INFO - main: Train iter. 52500/200000 (26.25%): 	Loss: 3.628042697906494	recon_loss: 0.0241696834564209	bpp_loss: 2.902952194213867	aux_loss: 0.31169283390045166
12:57:02 INFO - main: Train iter. 52600/200000 (26.3%): 	Loss: 3.6369123458862305	recon_loss: 0.02424377202987671	bpp_loss: 2.9095990657806396	aux_loss: 0.34459584951400757
12:57:19 INFO - main: Train iter. 52700/200000 (26.35%): 	Loss: 3.623988628387451	recon_loss: 0.024144411087036133	bpp_loss: 2.899656295776367	aux_loss: 0.31470170617103577
12:57:37 INFO - main: Train iter. 52800/200000 (26.4%): 	Loss: 3.62459659576416	recon_loss: 0.02408088929951191	bpp_loss: 2.902169942855835	aux_loss: 0.6731102466583252
12:57:55 INFO - main: Train iter. 52900/200000 (26.45%): 	Loss: 3.6326963901519775	recon_loss: 0.02413763850927353	bpp_loss: 2.908567190170288	aux_loss: 0.2028445303440094
12:58:12 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 3.628384828567505	recon_loss: 0.024199264124035835	bpp_loss: 2.902406930923462	aux_loss: 0.2951522171497345
12:58:30 INFO - main: Train iter. 53100/200000 (26.55%): 	Loss: 3.6501712799072266	recon_loss: 0.02431383915245533	bpp_loss: 2.9207561016082764	aux_loss: 0.2782517075538635
12:58:47 INFO - main: Train iter. 53200/200000 (26.6%): 	Loss: 3.617290735244751	recon_loss: 0.02412412315607071	bpp_loss: 2.8935670852661133	aux_loss: 0.4103604257106781
12:59:07 INFO - main: Train iter. 53300/200000 (26.65%): 	Loss: 3.628004550933838	recon_loss: 0.024129586294293404	bpp_loss: 2.9041168689727783	aux_loss: 0.30879494547843933
12:59:25 INFO - main: Train iter. 53400/200000 (26.7%): 	Loss: 3.638312578201294	recon_loss: 0.024162815883755684	bpp_loss: 2.9134280681610107	aux_loss: 0.9892563819885254
12:59:42 INFO - main: Train iter. 53500/200000 (26.75%): 	Loss: 3.6532909870147705	recon_loss: 0.024341700598597527	bpp_loss: 2.9230399131774902	aux_loss: 0.5345284342765808
13:00:00 INFO - main: Train iter. 53600/200000 (26.8%): 	Loss: 3.6380629539489746	recon_loss: 0.0242011658847332	bpp_loss: 2.9120280742645264	aux_loss: 0.4554387032985687
13:00:18 INFO - main: Train iter. 53700/200000 (26.85%): 	Loss: 3.640775680541992	recon_loss: 0.02422865480184555	bpp_loss: 2.9139161109924316	aux_loss: 0.24541516602039337
13:00:35 INFO - main: Train iter. 53800/200000 (26.9%): 	Loss: 3.6414828300476074	recon_loss: 0.024266567081212997	bpp_loss: 2.9134857654571533	aux_loss: 0.6443986296653748
13:00:53 INFO - main: Train iter. 53900/200000 (26.95%): 	Loss: 3.632962703704834	recon_loss: 0.024186966940760612	bpp_loss: 2.907353639602661	aux_loss: 0.31874001026153564
13:01:11 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 3.6394424438476562	recon_loss: 0.02421421930193901	bpp_loss: 2.913015842437744	aux_loss: 0.8366785049438477
13:01:28 INFO - main: Train iter. 54100/200000 (27.05%): 	Loss: 3.619476318359375	recon_loss: 0.024082370102405548	bpp_loss: 2.897005319595337	aux_loss: 0.2927185893058777
13:01:46 INFO - main: Train iter. 54200/200000 (27.1%): 	Loss: 3.615225076675415	recon_loss: 0.024034548550844193	bpp_loss: 2.894188642501831	aux_loss: 0.23679551482200623
13:02:04 INFO - main: Train iter. 54300/200000 (27.15%): 	Loss: 3.632237672805786	recon_loss: 0.024179140105843544	bpp_loss: 2.9068634510040283	aux_loss: 0.15419746935367584
13:02:21 INFO - main: Train iter. 54400/200000 (27.2%): 	Loss: 3.6228647232055664	recon_loss: 0.024141477420926094	bpp_loss: 2.898620367050171	aux_loss: 0.8503042459487915
13:02:39 INFO - main: Train iter. 54500/200000 (27.25%): 	Loss: 3.6242012977600098	recon_loss: 0.024112025275826454	bpp_loss: 2.9008405208587646	aux_loss: 0.17298953235149384
13:02:57 INFO - main: Train iter. 54600/200000 (27.3%): 	Loss: 3.618302345275879	recon_loss: 0.024105044081807137	bpp_loss: 2.895151138305664	aux_loss: 0.5802613496780396
13:03:14 INFO - main: Train iter. 54700/200000 (27.35%): 	Loss: 3.6250107288360596	recon_loss: 0.02413688600063324	bpp_loss: 2.9009041786193848	aux_loss: 0.34652453660964966
13:03:32 INFO - main: Train iter. 54800/200000 (27.4%): 	Loss: 3.6341402530670166	recon_loss: 0.024139223620295525	bpp_loss: 2.909963607788086	aux_loss: 0.25164175033569336
13:03:49 INFO - main: Train iter. 54900/200000 (27.45%): 	Loss: 3.6404106616973877	recon_loss: 0.024202359840273857	bpp_loss: 2.914339780807495	aux_loss: 0.6101652383804321
13:04:07 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 3.6354079246520996	recon_loss: 0.024229446426033974	bpp_loss: 2.908524513244629	aux_loss: 0.32857248187065125
13:04:17 INFO - main: {'TEST MSE': 0.024224533184688438, 'TEST BPP': 2.95528125, 'TEST loss': 3.633352438688278, 'TEST recon_loss': 0.02422453310713172, 'TEST bpp_loss': 2.9066164467334747}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:04:34 INFO - main: Train iter. 55100/200000 (27.55%): 	Loss: 3.621856212615967	recon_loss: 0.024116091430187225	bpp_loss: 2.8983733654022217	aux_loss: 0.46593230962753296
13:04:52 INFO - main: Train iter. 55200/200000 (27.6%): 	Loss: 3.625891923904419	recon_loss: 0.024136453866958618	bpp_loss: 2.9017982482910156	aux_loss: 0.7662168741226196
13:05:09 INFO - main: Train iter. 55300/200000 (27.65%): 	Loss: 3.641888380050659	recon_loss: 0.024220678955316544	bpp_loss: 2.9152679443359375	aux_loss: 0.23752236366271973
13:05:27 INFO - main: Train iter. 55400/200000 (27.7%): 	Loss: 3.6345314979553223	recon_loss: 0.02415788173675537	bpp_loss: 2.909795045852661	aux_loss: 0.289126455783844
13:05:44 INFO - main: Train iter. 55500/200000 (27.75%): 	Loss: 3.6312599182128906	recon_loss: 0.024165114387869835	bpp_loss: 2.906306505203247	aux_loss: 0.23477844893932343
13:06:02 INFO - main: Train iter. 55600/200000 (27.8%): 	Loss: 3.630026340484619	recon_loss: 0.024140413850545883	bpp_loss: 2.9058139324188232	aux_loss: 0.26789048314094543
13:06:19 INFO - main: Train iter. 55700/200000 (27.85%): 	Loss: 3.640570878982544	recon_loss: 0.024261970072984695	bpp_loss: 2.9127118587493896	aux_loss: 0.33653733134269714
13:06:37 INFO - main: Train iter. 55800/200000 (27.9%): 	Loss: 3.636712074279785	recon_loss: 0.02422991394996643	bpp_loss: 2.9098145961761475	aux_loss: 0.46795904636383057
13:06:54 INFO - main: Train iter. 55900/200000 (27.95%): 	Loss: 3.6341421604156494	recon_loss: 0.024184925481677055	bpp_loss: 2.9085943698883057	aux_loss: 0.3923230469226837
13:07:12 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 3.6345646381378174	recon_loss: 0.024140113964676857	bpp_loss: 2.9103612899780273	aux_loss: 0.5269862413406372
13:07:30 INFO - main: Train iter. 56100/200000 (28.05%): 	Loss: 3.6311869621276855	recon_loss: 0.02417060174047947	bpp_loss: 2.906068801879883	aux_loss: 0.2816140055656433
13:07:47 INFO - main: Train iter. 56200/200000 (28.1%): 	Loss: 3.6461358070373535	recon_loss: 0.024396859109401703	bpp_loss: 2.9142301082611084	aux_loss: 0.2711831331253052
13:08:05 INFO - main: Train iter. 56300/200000 (28.15%): 	Loss: 3.639875650405884	recon_loss: 0.02424677088856697	bpp_loss: 2.9124724864959717	aux_loss: 1.01917564868927
13:08:23 INFO - main: Train iter. 56400/200000 (28.2%): 	Loss: 3.632472515106201	recon_loss: 0.024167928844690323	bpp_loss: 2.9074347019195557	aux_loss: 0.992225170135498
13:08:40 INFO - main: Train iter. 56500/200000 (28.25%): 	Loss: 3.6450998783111572	recon_loss: 0.024152709171175957	bpp_loss: 2.920518636703491	aux_loss: 0.43168139457702637
13:09:00 INFO - main: Train iter. 56600/200000 (28.3%): 	Loss: 3.6208600997924805	recon_loss: 0.02410019189119339	bpp_loss: 2.8978543281555176	aux_loss: 0.2604125142097473
13:09:18 INFO - main: Train iter. 56700/200000 (28.35%): 	Loss: 3.618459701538086	recon_loss: 0.024082081392407417	bpp_loss: 2.8959972858428955	aux_loss: 0.278108149766922
13:09:35 INFO - main: Train iter. 56800/200000 (28.4%): 	Loss: 3.6224658489227295	recon_loss: 0.02408680133521557	bpp_loss: 2.8998618125915527	aux_loss: 0.3573620915412903
13:09:53 INFO - main: Train iter. 56900/200000 (28.45%): 	Loss: 3.6411831378936768	recon_loss: 0.02414068579673767	bpp_loss: 2.9169626235961914	aux_loss: 0.31296050548553467
13:10:11 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 3.6402602195739746	recon_loss: 0.02432175911962986	bpp_loss: 2.9106075763702393	aux_loss: 0.5832295417785645
13:10:28 INFO - main: Train iter. 57100/200000 (28.55%): 	Loss: 3.624650239944458	recon_loss: 0.02408693917095661	bpp_loss: 2.9020421504974365	aux_loss: 0.5054467916488647
13:10:46 INFO - main: Train iter. 57200/200000 (28.6%): 	Loss: 3.639575481414795	recon_loss: 0.024178393185138702	bpp_loss: 2.9142236709594727	aux_loss: 0.3170982003211975
13:11:04 INFO - main: Train iter. 57300/200000 (28.65%): 	Loss: 3.63228178024292	recon_loss: 0.02418656274676323	bpp_loss: 2.9066848754882812	aux_loss: 0.1928493082523346
13:11:21 INFO - main: Train iter. 57400/200000 (28.7%): 	Loss: 3.622389554977417	recon_loss: 0.02411607839167118	bpp_loss: 2.89890718460083	aux_loss: 0.2149699181318283
13:11:39 INFO - main: Train iter. 57500/200000 (28.75%): 	Loss: 3.628408193588257	recon_loss: 0.02413397654891014	bpp_loss: 2.904388904571533	aux_loss: 0.36214232444763184
13:11:56 INFO - main: Train iter. 57600/200000 (28.8%): 	Loss: 3.629707098007202	recon_loss: 0.02434208244085312	bpp_loss: 2.899444580078125	aux_loss: 0.27938899397850037
13:12:14 INFO - main: Train iter. 57700/200000 (28.85%): 	Loss: 3.63753080368042	recon_loss: 0.024183768779039383	bpp_loss: 2.912017822265625	aux_loss: 0.3087419867515564
13:12:31 INFO - main: Train iter. 57800/200000 (28.9%): 	Loss: 3.623229742050171	recon_loss: 0.024119796231389046	bpp_loss: 2.8996357917785645	aux_loss: 0.26290982961654663
13:12:49 INFO - main: Train iter. 57900/200000 (28.95%): 	Loss: 3.6474123001098633	recon_loss: 0.024252770468592644	bpp_loss: 2.9198291301727295	aux_loss: 0.33597588539123535
13:13:07 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 3.6306095123291016	recon_loss: 0.02412966638803482	bpp_loss: 2.906719446182251	aux_loss: 0.39631006121635437
13:13:24 INFO - main: Train iter. 58100/200000 (29.05%): 	Loss: 3.629751205444336	recon_loss: 0.024119019508361816	bpp_loss: 2.9061806201934814	aux_loss: 0.5048763751983643
13:13:42 INFO - main: Train iter. 58200/200000 (29.1%): 	Loss: 3.630512237548828	recon_loss: 0.0241373423486948	bpp_loss: 2.9063918590545654	aux_loss: 0.3422097861766815
13:13:59 INFO - main: Train iter. 58300/200000 (29.15%): 	Loss: 3.6377124786376953	recon_loss: 0.024188848212361336	bpp_loss: 2.9120469093322754	aux_loss: 0.8862790465354919
13:14:17 INFO - main: Train iter. 58400/200000 (29.2%): 	Loss: 3.6385297775268555	recon_loss: 0.02420233190059662	bpp_loss: 2.9124598503112793	aux_loss: 0.5126301050186157
13:14:35 INFO - main: Train iter. 58500/200000 (29.25%): 	Loss: 3.62746000289917	recon_loss: 0.024153336882591248	bpp_loss: 2.902859926223755	aux_loss: 0.2967672348022461
13:14:52 INFO - main: Train iter. 58600/200000 (29.3%): 	Loss: 3.6352474689483643	recon_loss: 0.024157967418432236	bpp_loss: 2.910508394241333	aux_loss: 0.4115474224090576
13:15:10 INFO - main: Train iter. 58700/200000 (29.35%): 	Loss: 3.632183790206909	recon_loss: 0.024376463145017624	bpp_loss: 2.9008898735046387	aux_loss: 0.7596629858016968
13:15:28 INFO - main: Train iter. 58800/200000 (29.4%): 	Loss: 3.63968825340271	recon_loss: 0.024164000526070595	bpp_loss: 2.9147682189941406	aux_loss: 0.3905988335609436
13:15:45 INFO - main: Train iter. 58900/200000 (29.45%): 	Loss: 3.6422417163848877	recon_loss: 0.02420039102435112	bpp_loss: 2.9162299633026123	aux_loss: 0.35959410667419434
13:16:03 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 3.6316144466400146	recon_loss: 0.024136822670698166	bpp_loss: 2.9075098037719727	aux_loss: 0.20988331735134125
13:16:20 INFO - main: Train iter. 59100/200000 (29.55%): 	Loss: 3.646162509918213	recon_loss: 0.024246975779533386	bpp_loss: 2.9187533855438232	aux_loss: 0.3314144015312195
13:16:38 INFO - main: Train iter. 59200/200000 (29.6%): 	Loss: 3.6377530097961426	recon_loss: 0.024206094443798065	bpp_loss: 2.9115703105926514	aux_loss: 0.3693641126155853
13:16:55 INFO - main: Train iter. 59300/200000 (29.65%): 	Loss: 3.647336959838867	recon_loss: 0.02421017363667488	bpp_loss: 2.9210317134857178	aux_loss: 0.1630265712738037
13:17:13 INFO - main: Train iter. 59400/200000 (29.7%): 	Loss: 3.628363609313965	recon_loss: 0.024170590564608574	bpp_loss: 2.9032459259033203	aux_loss: 0.2316063940525055
13:17:31 INFO - main: Train iter. 59500/200000 (29.75%): 	Loss: 3.644270658493042	recon_loss: 0.024174325168132782	bpp_loss: 2.9190409183502197	aux_loss: 0.28159743547439575
13:17:48 INFO - main: Train iter. 59600/200000 (29.8%): 	Loss: 3.644408941268921	recon_loss: 0.02431354485452175	bpp_loss: 2.9150025844573975	aux_loss: 0.2837706506252289
13:18:06 INFO - main: Train iter. 59700/200000 (29.85%): 	Loss: 3.631718635559082	recon_loss: 0.024143023416399956	bpp_loss: 2.9074277877807617	aux_loss: 0.17259842157363892
13:18:24 INFO - main: Train iter. 59800/200000 (29.9%): 	Loss: 3.6247880458831787	recon_loss: 0.024096712470054626	bpp_loss: 2.9018867015838623	aux_loss: 0.38486555218696594
13:18:44 INFO - main: Train iter. 59900/200000 (29.95%): 	Loss: 3.6308796405792236	recon_loss: 0.02421744540333748	bpp_loss: 2.9043562412261963	aux_loss: 0.4029751420021057
13:19:02 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 3.632617950439453	recon_loss: 0.024191321805119514	bpp_loss: 2.9068782329559326	aux_loss: 0.3952523171901703
13:19:11 INFO - main: {'TEST MSE': 0.02417825470215559, 'TEST BPP': 2.95446875, 'TEST loss': 3.6316761791706087, 'TEST recon_loss': 0.02417825462296605, 'TEST bpp_loss': 2.9063285398483276}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:19:29 INFO - main: Train iter. 60100/200000 (30.05%): 	Loss: 3.6431875228881836	recon_loss: 0.024223430082201958	bpp_loss: 2.9164845943450928	aux_loss: 0.483611524105072
13:19:47 INFO - main: Train iter. 60200/200000 (30.1%): 	Loss: 3.627436637878418	recon_loss: 0.02408781461417675	bpp_loss: 2.9048023223876953	aux_loss: 0.21119630336761475
13:20:04 INFO - main: Train iter. 60300/200000 (30.15%): 	Loss: 3.624901533126831	recon_loss: 0.02412310242652893	bpp_loss: 2.9012084007263184	aux_loss: 0.19813714921474457
13:20:22 INFO - main: Train iter. 60400/200000 (30.2%): 	Loss: 3.615553617477417	recon_loss: 0.024088995531201363	bpp_loss: 2.892883777618408	aux_loss: 0.7016427516937256
13:20:40 INFO - main: Train iter. 60500/200000 (30.25%): 	Loss: 3.6261520385742188	recon_loss: 0.024121269583702087	bpp_loss: 2.9025139808654785	aux_loss: 0.24866212904453278
13:20:57 INFO - main: Train iter. 60600/200000 (30.3%): 	Loss: 3.6292829513549805	recon_loss: 0.02413996495306492	bpp_loss: 2.9050838947296143	aux_loss: 0.36744773387908936
13:21:15 INFO - main: Train iter. 60700/200000 (30.35%): 	Loss: 3.6308486461639404	recon_loss: 0.02413244917988777	bpp_loss: 2.9068751335144043	aux_loss: 0.3011450469493866
13:21:33 INFO - main: Train iter. 60800/200000 (30.4%): 	Loss: 3.6049017906188965	recon_loss: 0.02400464192032814	bpp_loss: 2.8847625255584717	aux_loss: 0.36300191283226013
13:21:50 INFO - main: Train iter. 60900/200000 (30.45%): 	Loss: 3.6426849365234375	recon_loss: 0.024198489263653755	bpp_loss: 2.9167304039001465	aux_loss: 0.3604087233543396
13:22:08 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 3.6484971046447754	recon_loss: 0.024366971105337143	bpp_loss: 2.9174880981445312	aux_loss: 0.17844055593013763
13:22:26 INFO - main: Train iter. 61100/200000 (30.55%): 	Loss: 3.6297764778137207	recon_loss: 0.024118265137076378	bpp_loss: 2.906228542327881	aux_loss: 0.32756829261779785
13:22:43 INFO - main: Train iter. 61200/200000 (30.6%): 	Loss: 3.639481544494629	recon_loss: 0.024183321744203568	bpp_loss: 2.9139819145202637	aux_loss: 0.16776305437088013
13:23:01 INFO - main: Train iter. 61300/200000 (30.65%): 	Loss: 3.6360466480255127	recon_loss: 0.024189021438360214	bpp_loss: 2.9103760719299316	aux_loss: 0.3063601553440094
13:23:18 INFO - main: Train iter. 61400/200000 (30.7%): 	Loss: 3.6337971687316895	recon_loss: 0.024135712534189224	bpp_loss: 2.9097256660461426	aux_loss: 0.21507081389427185
13:23:36 INFO - main: Train iter. 61500/200000 (30.75%): 	Loss: 3.6196863651275635	recon_loss: 0.024102995172142982	bpp_loss: 2.8965964317321777	aux_loss: 0.3656347990036011
13:23:54 INFO - main: Train iter. 61600/200000 (30.8%): 	Loss: 3.6251983642578125	recon_loss: 0.024155132472515106	bpp_loss: 2.9005444049835205	aux_loss: 0.4369175434112549
13:24:11 INFO - main: Train iter. 61700/200000 (30.85%): 	Loss: 3.6421382427215576	recon_loss: 0.02418511174619198	bpp_loss: 2.9165849685668945	aux_loss: 0.234922856092453
13:24:29 INFO - main: Train iter. 61800/200000 (30.9%): 	Loss: 3.621014356613159	recon_loss: 0.02414451166987419	bpp_loss: 2.896678924560547	aux_loss: 0.37793076038360596
13:24:46 INFO - main: Train iter. 61900/200000 (30.95%): 	Loss: 3.6286401748657227	recon_loss: 0.024127453565597534	bpp_loss: 2.9048166275024414	aux_loss: 0.22961264848709106
13:25:04 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 3.6204965114593506	recon_loss: 0.02410663664340973	bpp_loss: 2.8972973823547363	aux_loss: 0.4771462082862854
13:25:22 INFO - main: Train iter. 62100/200000 (31.05%): 	Loss: 3.6271560192108154	recon_loss: 0.02414877526462078	bpp_loss: 2.9026927947998047	aux_loss: 0.25083354115486145
13:25:39 INFO - main: Train iter. 62200/200000 (31.1%): 	Loss: 3.6226518154144287	recon_loss: 0.024127459153532982	bpp_loss: 2.8988280296325684	aux_loss: 0.1958712935447693
13:25:57 INFO - main: Train iter. 62300/200000 (31.15%): 	Loss: 3.6407341957092285	recon_loss: 0.024213546887040138	bpp_loss: 2.91432785987854	aux_loss: 0.2675672769546509
13:26:14 INFO - main: Train iter. 62400/200000 (31.2%): 	Loss: 3.632366895675659	recon_loss: 0.02418580837547779	bpp_loss: 2.906792640686035	aux_loss: 0.4020928740501404
13:26:32 INFO - main: Train iter. 62500/200000 (31.25%): 	Loss: 3.6259398460388184	recon_loss: 0.024091610684990883	bpp_loss: 2.903191566467285	aux_loss: 0.3001001477241516
13:26:50 INFO - main: Train iter. 62600/200000 (31.3%): 	Loss: 3.6307318210601807	recon_loss: 0.02418178878724575	bpp_loss: 2.905278205871582	aux_loss: 0.2429044097661972
13:27:07 INFO - main: Train iter. 62700/200000 (31.35%): 	Loss: 3.643691301345825	recon_loss: 0.024243276566267014	bpp_loss: 2.9163930416107178	aux_loss: 0.2737482190132141
13:27:25 INFO - main: Train iter. 62800/200000 (31.4%): 	Loss: 3.6210215091705322	recon_loss: 0.02407909743487835	bpp_loss: 2.898648500442505	aux_loss: 0.27058014273643494
13:27:43 INFO - main: Train iter. 62900/200000 (31.45%): 	Loss: 3.6281683444976807	recon_loss: 0.024096813052892685	bpp_loss: 2.905263900756836	aux_loss: 0.3442462980747223
13:28:00 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 3.6353890895843506	recon_loss: 0.024215087294578552	bpp_loss: 2.9089365005493164	aux_loss: 0.4017936587333679
13:28:18 INFO - main: Train iter. 63100/200000 (31.55%): 	Loss: 3.6335017681121826	recon_loss: 0.024227172136306763	bpp_loss: 2.906686544418335	aux_loss: 0.5894030928611755
13:28:35 INFO - main: Train iter. 63200/200000 (31.6%): 	Loss: 3.6191961765289307	recon_loss: 0.024075517430901527	bpp_loss: 2.896930694580078	aux_loss: 0.4901871681213379
13:28:56 INFO - main: Train iter. 63300/200000 (31.65%): 	Loss: 3.6170907020568848	recon_loss: 0.024059589952230453	bpp_loss: 2.8953030109405518	aux_loss: 0.27095627784729004
13:29:13 INFO - main: Train iter. 63400/200000 (31.7%): 	Loss: 3.65035343170166	recon_loss: 0.02427244558930397	bpp_loss: 2.922179937362671	aux_loss: 0.5476590394973755
13:29:31 INFO - main: Train iter. 63500/200000 (31.75%): 	Loss: 3.6306910514831543	recon_loss: 0.024211084470152855	bpp_loss: 2.904358386993408	aux_loss: 0.2427733838558197
13:29:48 INFO - main: Train iter. 63600/200000 (31.8%): 	Loss: 3.62550687789917	recon_loss: 0.02406710758805275	bpp_loss: 2.903493642807007	aux_loss: 0.4728822112083435
13:30:06 INFO - main: Train iter. 63700/200000 (31.85%): 	Loss: 3.6192543506622314	recon_loss: 0.02407083474099636	bpp_loss: 2.8971292972564697	aux_loss: 0.3679419159889221
13:30:24 INFO - main: Train iter. 63800/200000 (31.9%): 	Loss: 3.626068115234375	recon_loss: 0.024074256420135498	bpp_loss: 2.9038403034210205	aux_loss: 0.6378493905067444
13:30:42 INFO - main: Train iter. 63900/200000 (31.95%): 	Loss: 3.616424322128296	recon_loss: 0.024058837443590164	bpp_loss: 2.8946592807769775	aux_loss: 0.6808999180793762
13:30:59 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 3.626523733139038	recon_loss: 0.0241064615547657	bpp_loss: 2.903329849243164	aux_loss: 0.3643186688423157
13:31:17 INFO - main: Train iter. 64100/200000 (32.05%): 	Loss: 3.632887125015259	recon_loss: 0.024128014221787453	bpp_loss: 2.9090466499328613	aux_loss: 0.33788001537323
13:31:35 INFO - main: Train iter. 64200/200000 (32.1%): 	Loss: 3.6252293586730957	recon_loss: 0.024141531437635422	bpp_loss: 2.9009833335876465	aux_loss: 0.2389766275882721
13:31:52 INFO - main: Train iter. 64300/200000 (32.15%): 	Loss: 3.628356456756592	recon_loss: 0.02412276715040207	bpp_loss: 2.9046733379364014	aux_loss: 0.8395467400550842
13:32:10 INFO - main: Train iter. 64400/200000 (32.2%): 	Loss: 3.6490249633789062	recon_loss: 0.024304941296577454	bpp_loss: 2.9198765754699707	aux_loss: 0.35050341486930847
13:32:27 INFO - main: Train iter. 64500/200000 (32.25%): 	Loss: 3.621654748916626	recon_loss: 0.024048930034041405	bpp_loss: 2.900186777114868	aux_loss: 0.2740035057067871
13:32:45 INFO - main: Train iter. 64600/200000 (32.3%): 	Loss: 3.63740873336792	recon_loss: 0.024184033274650574	bpp_loss: 2.9118876457214355	aux_loss: 0.23481988906860352
13:33:03 INFO - main: Train iter. 64700/200000 (32.35%): 	Loss: 3.6161141395568848	recon_loss: 0.02406900003552437	bpp_loss: 2.8940441608428955	aux_loss: 0.22051729261875153
13:33:20 INFO - main: Train iter. 64800/200000 (32.4%): 	Loss: 3.6376616954803467	recon_loss: 0.024163460358977318	bpp_loss: 2.9127578735351562	aux_loss: 0.3038027584552765
13:33:38 INFO - main: Train iter. 64900/200000 (32.45%): 	Loss: 3.6360456943511963	recon_loss: 0.02415687032043934	bpp_loss: 2.911339521408081	aux_loss: 0.563617467880249
13:33:56 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 3.639439821243286	recon_loss: 0.024213438853621483	bpp_loss: 2.913036584854126	aux_loss: 0.5699602365493774
13:34:05 INFO - main: {'TEST MSE': 0.024247935151302386, 'TEST BPP': 2.95428125, 'TEST loss': 3.6334287962913514, 'TEST recon_loss': 0.024247935062274337, 'TEST bpp_loss': 2.905990740776062}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:34:23 INFO - main: Train iter. 65100/200000 (32.55%): 	Loss: 3.6389873027801514	recon_loss: 0.02421688474714756	bpp_loss: 2.9124808311462402	aux_loss: 0.8969435691833496
13:34:41 INFO - main: Train iter. 65200/200000 (32.6%): 	Loss: 3.623859405517578	recon_loss: 0.024160049855709076	bpp_loss: 2.8990578651428223	aux_loss: 0.39241769909858704
13:34:58 INFO - main: Train iter. 65300/200000 (32.65%): 	Loss: 3.6383509635925293	recon_loss: 0.024202683940529823	bpp_loss: 2.9122705459594727	aux_loss: 0.1911793351173401
13:35:16 INFO - main: Train iter. 65400/200000 (32.7%): 	Loss: 3.619324207305908	recon_loss: 0.02408912591636181	bpp_loss: 2.896650552749634	aux_loss: 0.2754574120044708
13:35:34 INFO - main: Train iter. 65500/200000 (32.75%): 	Loss: 3.6262707710266113	recon_loss: 0.024093838408589363	bpp_loss: 2.9034557342529297	aux_loss: 0.7016425132751465
13:35:51 INFO - main: Train iter. 65600/200000 (32.8%): 	Loss: 3.640852451324463	recon_loss: 0.024208420887589455	bpp_loss: 2.914599895477295	aux_loss: 0.5687764883041382
13:36:09 INFO - main: Train iter. 65700/200000 (32.85%): 	Loss: 3.6395931243896484	recon_loss: 0.024200839921832085	bpp_loss: 2.9135680198669434	aux_loss: 0.2531765401363373
13:36:27 INFO - main: Train iter. 65800/200000 (32.9%): 	Loss: 3.6389100551605225	recon_loss: 0.02416563779115677	bpp_loss: 2.913940906524658	aux_loss: 0.22554969787597656
13:36:44 INFO - main: Train iter. 65900/200000 (32.95%): 	Loss: 3.6296465396881104	recon_loss: 0.02411424182355404	bpp_loss: 2.906219244003296	aux_loss: 0.3008497357368469
13:37:02 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 3.6218605041503906	recon_loss: 0.024109428748488426	bpp_loss: 2.8985776901245117	aux_loss: 0.5056034326553345
13:37:20 INFO - main: Train iter. 66100/200000 (33.05%): 	Loss: 3.6350626945495605	recon_loss: 0.02416553907096386	bpp_loss: 2.9100964069366455	aux_loss: 0.4377886652946472
13:37:37 INFO - main: Train iter. 66200/200000 (33.1%): 	Loss: 3.6142170429229736	recon_loss: 0.024049904197454453	bpp_loss: 2.8927199840545654	aux_loss: 0.47115641832351685
13:37:55 INFO - main: Train iter. 66300/200000 (33.15%): 	Loss: 3.6407718658447266	recon_loss: 0.02419913373887539	bpp_loss: 2.914797782897949	aux_loss: 0.393923282623291
13:38:13 INFO - main: Train iter. 66400/200000 (33.2%): 	Loss: 3.632873058319092	recon_loss: 0.024216428399086	bpp_loss: 2.9063801765441895	aux_loss: 0.44546371698379517
13:38:30 INFO - main: Train iter. 66500/200000 (33.25%): 	Loss: 3.6451473236083984	recon_loss: 0.024175364524126053	bpp_loss: 2.919886350631714	aux_loss: 0.2692464590072632
13:38:50 INFO - main: Train iter. 66600/200000 (33.3%): 	Loss: 3.6587769985198975	recon_loss: 0.02427598088979721	bpp_loss: 2.930497646331787	aux_loss: 0.4038698673248291
13:39:08 INFO - main: Train iter. 66700/200000 (33.35%): 	Loss: 3.6381170749664307	recon_loss: 0.024216260761022568	bpp_loss: 2.9116291999816895	aux_loss: 0.2531258463859558
13:39:26 INFO - main: Train iter. 66800/200000 (33.4%): 	Loss: 3.6429128646850586	recon_loss: 0.024229450151324272	bpp_loss: 2.916029214859009	aux_loss: 0.233584925532341
13:39:44 INFO - main: Train iter. 66900/200000 (33.45%): 	Loss: 3.6347365379333496	recon_loss: 0.024259053170681	bpp_loss: 2.9069650173187256	aux_loss: 0.2043900042772293
13:40:01 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 3.633626937866211	recon_loss: 0.024208351969718933	bpp_loss: 2.907376289367676	aux_loss: 1.2025864124298096
13:40:19 INFO - main: Train iter. 67100/200000 (33.55%): 	Loss: 3.645071029663086	recon_loss: 0.024215860292315483	bpp_loss: 2.9185950756073	aux_loss: 0.6159713268280029
13:40:37 INFO - main: Train iter. 67200/200000 (33.6%): 	Loss: 3.645676851272583	recon_loss: 0.024234358221292496	bpp_loss: 2.9186460971832275	aux_loss: 0.7623626589775085
13:40:55 INFO - main: Train iter. 67300/200000 (33.65%): 	Loss: 3.6294779777526855	recon_loss: 0.024148421362042427	bpp_loss: 2.9050252437591553	aux_loss: 0.5812733173370361
13:41:13 INFO - main: Train iter. 67400/200000 (33.7%): 	Loss: 3.637495994567871	recon_loss: 0.024202123284339905	bpp_loss: 2.9114322662353516	aux_loss: 0.9294020533561707
13:41:30 INFO - main: Train iter. 67500/200000 (33.75%): 	Loss: 3.632472276687622	recon_loss: 0.0242055244743824	bpp_loss: 2.906306505203247	aux_loss: 0.7203482389450073
13:41:48 INFO - main: Train iter. 67600/200000 (33.8%): 	Loss: 3.6283657550811768	recon_loss: 0.024087531492114067	bpp_loss: 2.9057397842407227	aux_loss: 0.4465271830558777
13:42:06 INFO - main: Train iter. 67700/200000 (33.85%): 	Loss: 3.644157648086548	recon_loss: 0.02418392337858677	bpp_loss: 2.918639898300171	aux_loss: 0.7301998138427734
13:42:24 INFO - main: Train iter. 67800/200000 (33.9%): 	Loss: 3.633582353591919	recon_loss: 0.02416752092540264	bpp_loss: 2.9085566997528076	aux_loss: 0.8714600801467896
13:42:41 INFO - main: Train iter. 67900/200000 (33.95%): 	Loss: 3.617976188659668	recon_loss: 0.02410823106765747	bpp_loss: 2.8947291374206543	aux_loss: 0.35830819606781006
13:42:59 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 3.6321609020233154	recon_loss: 0.024171318858861923	bpp_loss: 2.9070212841033936	aux_loss: 0.17687241733074188
13:43:17 INFO - main: Train iter. 68100/200000 (34.05%): 	Loss: 3.6266727447509766	recon_loss: 0.0240553580224514	bpp_loss: 2.9050118923187256	aux_loss: 0.45067936182022095
13:43:35 INFO - main: Train iter. 68200/200000 (34.1%): 	Loss: 3.638374090194702	recon_loss: 0.024129413068294525	bpp_loss: 2.914491653442383	aux_loss: 0.5732202529907227
13:43:53 INFO - main: Train iter. 68300/200000 (34.15%): 	Loss: 3.632068157196045	recon_loss: 0.024250570684671402	bpp_loss: 2.9045510292053223	aux_loss: 0.24441088736057281
13:44:10 INFO - main: Train iter. 68400/200000 (34.2%): 	Loss: 3.6424174308776855	recon_loss: 0.0243771281093359	bpp_loss: 2.9111034870147705	aux_loss: 0.2613036036491394
13:44:28 INFO - main: Train iter. 68500/200000 (34.25%): 	Loss: 3.6303412914276123	recon_loss: 0.024139411747455597	bpp_loss: 2.906158924102783	aux_loss: 0.11728793382644653
13:44:46 INFO - main: Train iter. 68600/200000 (34.3%): 	Loss: 3.626267910003662	recon_loss: 0.024150611832737923	bpp_loss: 2.901749610900879	aux_loss: 0.45090484619140625
13:45:04 INFO - main: Train iter. 68700/200000 (34.35%): 	Loss: 3.641047477722168	recon_loss: 0.024218682199716568	bpp_loss: 2.91448712348938	aux_loss: 0.2731982469558716
13:45:21 INFO - main: Train iter. 68800/200000 (34.4%): 	Loss: 3.6194987297058105	recon_loss: 0.024097206071019173	bpp_loss: 2.89658260345459	aux_loss: 1.3834301233291626
13:45:39 INFO - main: Train iter. 68900/200000 (34.45%): 	Loss: 3.629092216491699	recon_loss: 0.024126946926116943	bpp_loss: 2.9052836894989014	aux_loss: 0.20325908064842224
13:45:57 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 3.631135940551758	recon_loss: 0.024130862206220627	bpp_loss: 2.907210111618042	aux_loss: 0.5552281141281128
13:46:15 INFO - main: Train iter. 69100/200000 (34.55%): 	Loss: 3.615422487258911	recon_loss: 0.02407688833773136	bpp_loss: 2.893115758895874	aux_loss: 0.3668626844882965
13:46:33 INFO - main: Train iter. 69200/200000 (34.6%): 	Loss: 3.6250109672546387	recon_loss: 0.02418339252471924	bpp_loss: 2.8995091915130615	aux_loss: 0.316742479801178
13:46:50 INFO - main: Train iter. 69300/200000 (34.65%): 	Loss: 3.6274337768554688	recon_loss: 0.02412264794111252	bpp_loss: 2.903754234313965	aux_loss: 0.15251240134239197
13:47:08 INFO - main: Train iter. 69400/200000 (34.7%): 	Loss: 3.6495819091796875	recon_loss: 0.02423248626291752	bpp_loss: 2.922607183456421	aux_loss: 0.3188459575176239
13:47:26 INFO - main: Train iter. 69500/200000 (34.75%): 	Loss: 3.643129348754883	recon_loss: 0.024276359006762505	bpp_loss: 2.9148385524749756	aux_loss: 0.9804226160049438
13:47:43 INFO - main: Train iter. 69600/200000 (34.8%): 	Loss: 3.6327667236328125	recon_loss: 0.02418786659836769	bpp_loss: 2.907130718231201	aux_loss: 0.9955588579177856
13:48:01 INFO - main: Train iter. 69700/200000 (34.85%): 	Loss: 3.6082468032836914	recon_loss: 0.024014728143811226	bpp_loss: 2.8878049850463867	aux_loss: 0.14776065945625305
13:48:19 INFO - main: Train iter. 69800/200000 (34.9%): 	Loss: 3.624368190765381	recon_loss: 0.024107003584504128	bpp_loss: 2.901158094406128	aux_loss: 0.7145748138427734
13:48:39 INFO - main: Train iter. 69900/200000 (34.95%): 	Loss: 3.629189968109131	recon_loss: 0.02416674792766571	bpp_loss: 2.9041876792907715	aux_loss: 1.0049338340759277
13:48:57 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 3.633762836456299	recon_loss: 0.024178575724363327	bpp_loss: 2.9084055423736572	aux_loss: 0.5996953248977661
13:49:06 INFO - main: {'TEST MSE': 0.024151268978704288, 'TEST BPP': 2.9541875, 'TEST loss': 3.6300168807506563, 'TEST recon_loss': 0.024151268908753992, 'TEST bpp_loss': 2.9054788076877593}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:49:24 INFO - main: Train iter. 70100/200000 (35.05%): 	Loss: 3.6407313346862793	recon_loss: 0.02415880747139454	bpp_loss: 2.9159672260284424	aux_loss: 0.18439602851867676
13:49:42 INFO - main: Train iter. 70200/200000 (35.1%): 	Loss: 3.624441623687744	recon_loss: 0.02412322908639908	bpp_loss: 2.900744676589966	aux_loss: 0.33376121520996094
13:50:00 INFO - main: Train iter. 70300/200000 (35.15%): 	Loss: 3.6315791606903076	recon_loss: 0.02422727644443512	bpp_loss: 2.9047608375549316	aux_loss: 0.6928577423095703
13:50:18 INFO - main: Train iter. 70400/200000 (35.2%): 	Loss: 3.6421918869018555	recon_loss: 0.024191994220018387	bpp_loss: 2.9164321422576904	aux_loss: 0.3068324327468872
13:50:36 INFO - main: Train iter. 70500/200000 (35.25%): 	Loss: 3.62827205657959	recon_loss: 0.024163711816072464	bpp_loss: 2.9033608436584473	aux_loss: 0.2568936049938202
13:50:54 INFO - main: Train iter. 70600/200000 (35.3%): 	Loss: 3.616635322570801	recon_loss: 0.02407185174524784	bpp_loss: 2.894479751586914	aux_loss: 0.8083468675613403
13:51:11 INFO - main: Train iter. 70700/200000 (35.35%): 	Loss: 3.647608995437622	recon_loss: 0.024210724979639053	bpp_loss: 2.9212872982025146	aux_loss: 0.22231337428092957
13:51:29 INFO - main: Train iter. 70800/200000 (35.4%): 	Loss: 3.6228628158569336	recon_loss: 0.02413741871714592	bpp_loss: 2.898740291595459	aux_loss: 0.45748329162597656
13:51:47 INFO - main: Train iter. 70900/200000 (35.45%): 	Loss: 3.636349678039551	recon_loss: 0.024200472980737686	bpp_loss: 2.9103355407714844	aux_loss: 0.9391441345214844
13:52:05 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 3.6187658309936523	recon_loss: 0.02405894733965397	bpp_loss: 2.8969974517822266	aux_loss: 0.2594112157821655
13:52:23 INFO - main: Train iter. 71100/200000 (35.55%): 	Loss: 3.629070281982422	recon_loss: 0.024153972044587135	bpp_loss: 2.9044511318206787	aux_loss: 0.6089593172073364
13:52:40 INFO - main: Train iter. 71200/200000 (35.6%): 	Loss: 3.62117862701416	recon_loss: 0.024132024496793747	bpp_loss: 2.8972179889678955	aux_loss: 0.38842448592185974
13:52:58 INFO - main: Train iter. 71300/200000 (35.65%): 	Loss: 3.6311521530151367	recon_loss: 0.024166081100702286	bpp_loss: 2.9061696529388428	aux_loss: 0.18738093972206116
13:53:16 INFO - main: Train iter. 71400/200000 (35.7%): 	Loss: 3.6073737144470215	recon_loss: 0.0239753145724535	bpp_loss: 2.8881142139434814	aux_loss: 0.28916776180267334
13:53:34 INFO - main: Train iter. 71500/200000 (35.75%): 	Loss: 3.616406202316284	recon_loss: 0.024043438956141472	bpp_loss: 2.8951029777526855	aux_loss: 0.4882550537586212
13:53:52 INFO - main: Train iter. 71600/200000 (35.8%): 	Loss: 3.6153953075408936	recon_loss: 0.024095140397548676	bpp_loss: 2.8925411701202393	aux_loss: 0.6707475185394287
13:54:10 INFO - main: Train iter. 71700/200000 (35.85%): 	Loss: 3.6355130672454834	recon_loss: 0.024187752977013588	bpp_loss: 2.9098803997039795	aux_loss: 0.3182002305984497
13:54:28 INFO - main: Train iter. 71800/200000 (35.9%): 	Loss: 3.622814178466797	recon_loss: 0.024116607382893562	bpp_loss: 2.89931583404541	aux_loss: 0.22926762700080872
13:54:45 INFO - main: Train iter. 71900/200000 (35.95%): 	Loss: 3.6419081687927246	recon_loss: 0.024157416075468063	bpp_loss: 2.9171855449676514	aux_loss: 0.8815762996673584
13:55:03 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 3.6309845447540283	recon_loss: 0.024081580340862274	bpp_loss: 2.9085371494293213	aux_loss: 0.2825580835342407
13:55:21 INFO - main: Train iter. 72100/200000 (36.05%): 	Loss: 3.6266160011291504	recon_loss: 0.024109771475195885	bpp_loss: 2.90332293510437	aux_loss: 0.2867453098297119
13:55:39 INFO - main: Train iter. 72200/200000 (36.1%): 	Loss: 3.6160833835601807	recon_loss: 0.024098403751850128	bpp_loss: 2.8931312561035156	aux_loss: 0.7742932438850403
13:55:57 INFO - main: Train iter. 72300/200000 (36.15%): 	Loss: 3.637286424636841	recon_loss: 0.024174107238650322	bpp_loss: 2.9120631217956543	aux_loss: 0.46020978689193726
13:56:15 INFO - main: Train iter. 72400/200000 (36.2%): 	Loss: 3.6344428062438965	recon_loss: 0.024165857583284378	bpp_loss: 2.9094672203063965	aux_loss: 1.0765738487243652
13:56:32 INFO - main: Train iter. 72500/200000 (36.25%): 	Loss: 3.635716676712036	recon_loss: 0.024135364219546318	bpp_loss: 2.9116556644439697	aux_loss: 0.20145320892333984
13:56:50 INFO - main: Train iter. 72600/200000 (36.3%): 	Loss: 3.620763063430786	recon_loss: 0.024042176082730293	bpp_loss: 2.8994977474212646	aux_loss: 0.5184780359268188
13:57:08 INFO - main: Train iter. 72700/200000 (36.35%): 	Loss: 3.6161270141601562	recon_loss: 0.024101732298731804	bpp_loss: 2.8930749893188477	aux_loss: 0.21748396754264832
13:57:26 INFO - main: Train iter. 72800/200000 (36.4%): 	Loss: 3.61991024017334	recon_loss: 0.024098161607980728	bpp_loss: 2.896965265274048	aux_loss: 0.3443855047225952
13:57:44 INFO - main: Train iter. 72900/200000 (36.45%): 	Loss: 3.632112503051758	recon_loss: 0.02414567768573761	bpp_loss: 2.9077420234680176	aux_loss: 0.2261839359998703
13:58:01 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 3.6301822662353516	recon_loss: 0.024108001962304115	bpp_loss: 2.906942129135132	aux_loss: 0.2423994243144989
13:58:19 INFO - main: Train iter. 73100/200000 (36.55%): 	Loss: 3.6294901371002197	recon_loss: 0.024120265617966652	bpp_loss: 2.9058821201324463	aux_loss: 0.40009254217147827
13:58:39 INFO - main: Train iter. 73200/200000 (36.6%): 	Loss: 3.622073173522949	recon_loss: 0.02407204546034336	bpp_loss: 2.899911880493164	aux_loss: 0.30496448278427124
13:58:57 INFO - main: Train iter. 73300/200000 (36.65%): 	Loss: 3.6340556144714355	recon_loss: 0.024137385189533234	bpp_loss: 2.9099340438842773	aux_loss: 0.23310738801956177
13:59:14 INFO - main: Train iter. 73400/200000 (36.7%): 	Loss: 3.6292073726654053	recon_loss: 0.024140363559126854	bpp_loss: 2.904996395111084	aux_loss: 0.26564478874206543
13:59:32 INFO - main: Train iter. 73500/200000 (36.75%): 	Loss: 3.6156601905822754	recon_loss: 0.024062851443886757	bpp_loss: 2.8937745094299316	aux_loss: 0.361419141292572
13:59:50 INFO - main: Train iter. 73600/200000 (36.8%): 	Loss: 3.6220316886901855	recon_loss: 0.024117324501276016	bpp_loss: 2.8985118865966797	aux_loss: 0.23742452263832092
14:00:08 INFO - main: Train iter. 73700/200000 (36.85%): 	Loss: 3.6272826194763184	recon_loss: 0.02414850704371929	bpp_loss: 2.902827262878418	aux_loss: 0.4267410933971405
14:00:25 INFO - main: Train iter. 73800/200000 (36.9%): 	Loss: 3.6390957832336426	recon_loss: 0.02414689026772976	bpp_loss: 2.914689064025879	aux_loss: 1.0359593629837036
14:00:43 INFO - main: Train iter. 73900/200000 (36.95%): 	Loss: 3.6293227672576904	recon_loss: 0.024099430069327354	bpp_loss: 2.9063398838043213	aux_loss: 0.8252704739570618
14:01:01 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 3.6204891204833984	recon_loss: 0.024059129878878593	bpp_loss: 2.8987152576446533	aux_loss: 0.3003352880477905
14:01:18 INFO - main: Train iter. 74100/200000 (37.05%): 	Loss: 3.629943609237671	recon_loss: 0.024104926735162735	bpp_loss: 2.9067957401275635	aux_loss: 0.45782268047332764
14:01:36 INFO - main: Train iter. 74200/200000 (37.1%): 	Loss: 3.624074697494507	recon_loss: 0.024039100855588913	bpp_loss: 2.9029016494750977	aux_loss: 1.0573644638061523
14:01:54 INFO - main: Train iter. 74300/200000 (37.15%): 	Loss: 3.6349539756774902	recon_loss: 0.024337437003850937	bpp_loss: 2.9048309326171875	aux_loss: 1.1892387866973877
14:02:11 INFO - main: Train iter. 74400/200000 (37.2%): 	Loss: 3.6353542804718018	recon_loss: 0.024150975048542023	bpp_loss: 2.91082501411438	aux_loss: 0.25140053033828735
14:02:29 INFO - main: Train iter. 74500/200000 (37.25%): 	Loss: 3.626739978790283	recon_loss: 0.024111315608024597	bpp_loss: 2.903400421142578	aux_loss: 0.2334204763174057
14:02:47 INFO - main: Train iter. 74600/200000 (37.3%): 	Loss: 3.6531171798706055	recon_loss: 0.02426261082291603	bpp_loss: 2.925238847732544	aux_loss: 0.18245670199394226
14:03:04 INFO - main: Train iter. 74700/200000 (37.35%): 	Loss: 3.634232759475708	recon_loss: 0.024176176637411118	bpp_loss: 2.908947467803955	aux_loss: 0.44661229848861694
14:03:22 INFO - main: Train iter. 74800/200000 (37.4%): 	Loss: 3.6446213722229004	recon_loss: 0.02422543615102768	bpp_loss: 2.917858362197876	aux_loss: 0.596859335899353
14:03:40 INFO - main: Train iter. 74900/200000 (37.45%): 	Loss: 3.633995771408081	recon_loss: 0.02416747435927391	bpp_loss: 2.9089715480804443	aux_loss: 0.18759241700172424
14:03:57 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 3.631589412689209	recon_loss: 0.02412406913936138	bpp_loss: 2.907867431640625	aux_loss: 0.25849083065986633
14:04:07 INFO - main: {'TEST MSE': 0.02412079702208254, 'TEST BPP': 2.95478125, 'TEST loss': 3.6298937470912933, 'TEST recon_loss': 0.024120796943083406, 'TEST bpp_loss': 2.9062698402404785}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:04:25 INFO - main: Train iter. 75100/200000 (37.55%): 	Loss: 3.638279914855957	recon_loss: 0.024171223863959312	bpp_loss: 2.9131431579589844	aux_loss: 0.24385815858840942
14:04:42 INFO - main: Train iter. 75200/200000 (37.6%): 	Loss: 3.6166958808898926	recon_loss: 0.024061355739831924	bpp_loss: 2.894855260848999	aux_loss: 0.2845599055290222
14:05:00 INFO - main: Train iter. 75300/200000 (37.65%): 	Loss: 3.653991460800171	recon_loss: 0.024274159222841263	bpp_loss: 2.925766706466675	aux_loss: 0.2325741946697235
14:05:17 INFO - main: Train iter. 75400/200000 (37.7%): 	Loss: 3.62069034576416	recon_loss: 0.024061456322669983	bpp_loss: 2.8988466262817383	aux_loss: 0.436703622341156
14:05:35 INFO - main: Train iter. 75500/200000 (37.75%): 	Loss: 3.6307454109191895	recon_loss: 0.024106241762638092	bpp_loss: 2.9075582027435303	aux_loss: 0.806286096572876
14:05:53 INFO - main: Train iter. 75600/200000 (37.8%): 	Loss: 3.6309337615966797	recon_loss: 0.024134309962391853	bpp_loss: 2.906904458999634	aux_loss: 0.2872125208377838
14:06:10 INFO - main: Train iter. 75700/200000 (37.85%): 	Loss: 3.6326043605804443	recon_loss: 0.024118635803461075	bpp_loss: 2.9090452194213867	aux_loss: 0.39239129424095154
14:06:28 INFO - main: Train iter. 75800/200000 (37.9%): 	Loss: 3.639406681060791	recon_loss: 0.024165788665413857	bpp_loss: 2.914433002471924	aux_loss: 0.21417491137981415
14:06:46 INFO - main: Train iter. 75900/200000 (37.95%): 	Loss: 3.6254162788391113	recon_loss: 0.02412334829568863	bpp_loss: 2.9017157554626465	aux_loss: 0.4708905518054962
14:07:03 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 3.624617338180542	recon_loss: 0.0241265669465065	bpp_loss: 2.900820255279541	aux_loss: 0.2208823412656784
14:07:21 INFO - main: Train iter. 76100/200000 (38.05%): 	Loss: 3.623117208480835	recon_loss: 0.024055903777480125	bpp_loss: 2.901440143585205	aux_loss: 0.2928106486797333
14:07:39 INFO - main: Train iter. 76200/200000 (38.1%): 	Loss: 3.613642930984497	recon_loss: 0.024058924987912178	bpp_loss: 2.8918752670288086	aux_loss: 0.19548124074935913
14:07:57 INFO - main: Train iter. 76300/200000 (38.15%): 	Loss: 3.6247334480285645	recon_loss: 0.024139516055583954	bpp_loss: 2.900547981262207	aux_loss: 0.5660116076469421
14:08:14 INFO - main: Train iter. 76400/200000 (38.2%): 	Loss: 3.6218366622924805	recon_loss: 0.024070605635643005	bpp_loss: 2.8997185230255127	aux_loss: 0.6240753531455994
14:08:32 INFO - main: Train iter. 76500/200000 (38.25%): 	Loss: 3.6356372833251953	recon_loss: 0.024180050939321518	bpp_loss: 2.910235643386841	aux_loss: 0.2243872582912445
14:08:52 INFO - main: Train iter. 76600/200000 (38.3%): 	Loss: 3.632794141769409	recon_loss: 0.024165187031030655	bpp_loss: 2.9078385829925537	aux_loss: 0.4009762704372406
14:09:10 INFO - main: Train iter. 76700/200000 (38.35%): 	Loss: 3.621753215789795	recon_loss: 0.02408635802567005	bpp_loss: 2.899162530899048	aux_loss: 0.575509250164032
14:09:27 INFO - main: Train iter. 76800/200000 (38.4%): 	Loss: 3.6138124465942383	recon_loss: 0.024062305688858032	bpp_loss: 2.8919432163238525	aux_loss: 0.35703161358833313
14:09:45 INFO - main: Train iter. 76900/200000 (38.45%): 	Loss: 3.6379027366638184	recon_loss: 0.02425932139158249	bpp_loss: 2.910123109817505	aux_loss: 0.3146370053291321
14:10:03 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 3.6416306495666504	recon_loss: 0.024229535833001137	bpp_loss: 2.9147446155548096	aux_loss: 0.348760187625885
14:10:20 INFO - main: Train iter. 77100/200000 (38.55%): 	Loss: 3.6355435848236084	recon_loss: 0.024176539853215218	bpp_loss: 2.910247325897217	aux_loss: 0.9465656280517578
14:10:38 INFO - main: Train iter. 77200/200000 (38.6%): 	Loss: 3.6333792209625244	recon_loss: 0.024165358394384384	bpp_loss: 2.9084184169769287	aux_loss: 0.35623499751091003
14:10:56 INFO - main: Train iter. 77300/200000 (38.65%): 	Loss: 3.637763023376465	recon_loss: 0.024133550003170967	bpp_loss: 2.9137566089630127	aux_loss: 0.3406033515930176
14:11:13 INFO - main: Train iter. 77400/200000 (38.7%): 	Loss: 3.624007225036621	recon_loss: 0.024084972217679024	bpp_loss: 2.9014580249786377	aux_loss: 0.22854752838611603
14:11:31 INFO - main: Train iter. 77500/200000 (38.75%): 	Loss: 3.610701084136963	recon_loss: 0.02404528483748436	bpp_loss: 2.8893425464630127	aux_loss: 0.4891183376312256
14:11:49 INFO - main: Train iter. 77600/200000 (38.8%): 	Loss: 3.642305374145508	recon_loss: 0.02425982803106308	bpp_loss: 2.914510488510132	aux_loss: 0.26452770829200745
14:12:06 INFO - main: Train iter. 77700/200000 (38.85%): 	Loss: 3.621213912963867	recon_loss: 0.02409885637462139	bpp_loss: 2.8982481956481934	aux_loss: 0.23583011329174042
14:12:24 INFO - main: Train iter. 77800/200000 (38.9%): 	Loss: 3.6367645263671875	recon_loss: 0.024169253185391426	bpp_loss: 2.911686897277832	aux_loss: 0.19735264778137207
14:12:42 INFO - main: Train iter. 77900/200000 (38.95%): 	Loss: 3.6381115913391113	recon_loss: 0.02421407960355282	bpp_loss: 2.911689281463623	aux_loss: 1.0214582681655884
14:12:59 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 3.6399569511413574	recon_loss: 0.02417224645614624	bpp_loss: 2.9147896766662598	aux_loss: 0.2819053530693054
14:13:17 INFO - main: Train iter. 78100/200000 (39.05%): 	Loss: 3.627304792404175	recon_loss: 0.024105416610836983	bpp_loss: 2.904142379760742	aux_loss: 0.2637746334075928
14:13:35 INFO - main: Train iter. 78200/200000 (39.1%): 	Loss: 3.6166138648986816	recon_loss: 0.02401674911379814	bpp_loss: 2.896111488342285	aux_loss: 0.467141330242157
14:13:52 INFO - main: Train iter. 78300/200000 (39.15%): 	Loss: 3.6234195232391357	recon_loss: 0.024112707003951073	bpp_loss: 2.900038242340088	aux_loss: 0.5000555515289307
14:14:10 INFO - main: Train iter. 78400/200000 (39.2%): 	Loss: 3.633089065551758	recon_loss: 0.024140411987900734	bpp_loss: 2.908876657485962	aux_loss: 0.3437918722629547
14:14:27 INFO - main: Train iter. 78500/200000 (39.25%): 	Loss: 3.626420497894287	recon_loss: 0.02410072647035122	bpp_loss: 2.9033987522125244	aux_loss: 0.42541366815567017
14:14:45 INFO - main: Train iter. 78600/200000 (39.3%): 	Loss: 3.6284170150756836	recon_loss: 0.024130020290613174	bpp_loss: 2.9045164585113525	aux_loss: 0.29608118534088135
14:15:03 INFO - main: Train iter. 78700/200000 (39.35%): 	Loss: 3.6109836101531982	recon_loss: 0.02408021315932274	bpp_loss: 2.8885772228240967	aux_loss: 0.8958991169929504
14:15:20 INFO - main: Train iter. 78800/200000 (39.4%): 	Loss: 3.622770309448242	recon_loss: 0.02415635623037815	bpp_loss: 2.8980796337127686	aux_loss: 0.6108030080795288
14:15:38 INFO - main: Train iter. 78900/200000 (39.45%): 	Loss: 3.6346445083618164	recon_loss: 0.02416466362774372	bpp_loss: 2.9097046852111816	aux_loss: 0.208623006939888
14:15:56 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 3.6373891830444336	recon_loss: 0.02419699914753437	bpp_loss: 2.9114792346954346	aux_loss: 0.13214372098445892
14:16:14 INFO - main: Train iter. 79100/200000 (39.55%): 	Loss: 3.627455711364746	recon_loss: 0.024146689102053642	bpp_loss: 2.90305495262146	aux_loss: 0.8865333199501038
14:16:31 INFO - main: Train iter. 79200/200000 (39.6%): 	Loss: 3.6335763931274414	recon_loss: 0.024111879989504814	bpp_loss: 2.91021990776062	aux_loss: 0.1934007704257965
14:16:49 INFO - main: Train iter. 79300/200000 (39.65%): 	Loss: 3.6363906860351562	recon_loss: 0.024207986891269684	bpp_loss: 2.9101510047912598	aux_loss: 0.4289224445819855
14:17:07 INFO - main: Train iter. 79400/200000 (39.7%): 	Loss: 3.6230969429016113	recon_loss: 0.024061735719442368	bpp_loss: 2.901244878768921	aux_loss: 0.18778175115585327
14:17:24 INFO - main: Train iter. 79500/200000 (39.75%): 	Loss: 3.6277174949645996	recon_loss: 0.024105964228510857	bpp_loss: 2.904538631439209	aux_loss: 0.18481098115444183
14:17:42 INFO - main: Train iter. 79600/200000 (39.8%): 	Loss: 3.623931407928467	recon_loss: 0.024074122309684753	bpp_loss: 2.901707649230957	aux_loss: 0.4173922538757324
14:18:00 INFO - main: Train iter. 79700/200000 (39.85%): 	Loss: 3.6243648529052734	recon_loss: 0.02412937954068184	bpp_loss: 2.9004836082458496	aux_loss: 0.3407728672027588
14:18:17 INFO - main: Train iter. 79800/200000 (39.9%): 	Loss: 3.6213152408599854	recon_loss: 0.0240809116512537	bpp_loss: 2.898887872695923	aux_loss: 0.4066691994667053
14:18:37 INFO - main: Train iter. 79900/200000 (39.95%): 	Loss: 3.620659589767456	recon_loss: 0.0241289921104908	bpp_loss: 2.896789789199829	aux_loss: 0.7356980443000793
14:18:55 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 3.6162843704223633	recon_loss: 0.024102579802274704	bpp_loss: 2.89320707321167	aux_loss: 0.28864309191703796
14:19:05 INFO - main: {'TEST MSE': 0.02414944842744676, 'TEST BPP': 2.95415625, 'TEST loss': 3.63036519575119, 'TEST recon_loss': 0.024149448331445455, 'TEST bpp_loss': 2.9058817446231844}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:19:23 INFO - main: Train iter. 80100/200000 (40.05%): 	Loss: 3.623263359069824	recon_loss: 0.024108950048685074	bpp_loss: 2.8999948501586914	aux_loss: 0.20000404119491577
14:19:40 INFO - main: Train iter. 80200/200000 (40.1%): 	Loss: 3.616485357284546	recon_loss: 0.02408347837626934	bpp_loss: 2.8939809799194336	aux_loss: 0.6082195043563843
14:19:58 INFO - main: Train iter. 80300/200000 (40.15%): 	Loss: 3.631406307220459	recon_loss: 0.024150243028998375	bpp_loss: 2.9068989753723145	aux_loss: 0.2533082067966461
14:20:15 INFO - main: Train iter. 80400/200000 (40.2%): 	Loss: 3.6500513553619385	recon_loss: 0.02422417886555195	bpp_loss: 2.923326015472412	aux_loss: 0.18819424510002136
14:20:33 INFO - main: Train iter. 80500/200000 (40.25%): 	Loss: 3.6227097511291504	recon_loss: 0.024086277931928635	bpp_loss: 2.9001214504241943	aux_loss: 0.26303425431251526
14:20:51 INFO - main: Train iter. 80600/200000 (40.3%): 	Loss: 3.615997791290283	recon_loss: 0.02406240627169609	bpp_loss: 2.894125461578369	aux_loss: 0.2234763503074646
14:21:08 INFO - main: Train iter. 80700/200000 (40.35%): 	Loss: 3.6205716133117676	recon_loss: 0.024080729112029076	bpp_loss: 2.8981497287750244	aux_loss: 0.21315473318099976
14:21:26 INFO - main: Train iter. 80800/200000 (40.4%): 	Loss: 3.637326717376709	recon_loss: 0.024153919890522957	bpp_loss: 2.9127092361450195	aux_loss: 0.2693901062011719
14:21:44 INFO - main: Train iter. 80900/200000 (40.45%): 	Loss: 3.609657049179077	recon_loss: 0.024010680615901947	bpp_loss: 2.889336585998535	aux_loss: 0.39122313261032104
14:22:01 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 3.660094738006592	recon_loss: 0.024294724687933922	bpp_loss: 2.931252956390381	aux_loss: 0.29157739877700806
14:22:19 INFO - main: Train iter. 81100/200000 (40.55%): 	Loss: 3.6495463848114014	recon_loss: 0.024230625480413437	bpp_loss: 2.9226276874542236	aux_loss: 0.9097304940223694
14:22:36 INFO - main: Train iter. 81200/200000 (40.6%): 	Loss: 3.6342382431030273	recon_loss: 0.02416960895061493	bpp_loss: 2.9091501235961914	aux_loss: 0.35384875535964966
14:22:54 INFO - main: Train iter. 81300/200000 (40.65%): 	Loss: 3.6194422245025635	recon_loss: 0.02408379688858986	bpp_loss: 2.896928310394287	aux_loss: 0.28727638721466064
14:23:12 INFO - main: Train iter. 81400/200000 (40.7%): 	Loss: 3.63814640045166	recon_loss: 0.024190815165638924	bpp_loss: 2.912421941757202	aux_loss: 0.23251855373382568
14:23:29 INFO - main: Train iter. 81500/200000 (40.75%): 	Loss: 3.62528133392334	recon_loss: 0.02412552572786808	bpp_loss: 2.901515483856201	aux_loss: 0.3407860994338989
14:23:47 INFO - main: Train iter. 81600/200000 (40.8%): 	Loss: 3.637260913848877	recon_loss: 0.024153534322977066	bpp_loss: 2.9126548767089844	aux_loss: 0.5416638851165771
14:24:04 INFO - main: Train iter. 81700/200000 (40.85%): 	Loss: 3.639832019805908	recon_loss: 0.024171579629182816	bpp_loss: 2.914684772491455	aux_loss: 0.3408384621143341
14:24:22 INFO - main: Train iter. 81800/200000 (40.9%): 	Loss: 3.633155107498169	recon_loss: 0.024100400507450104	bpp_loss: 2.9101431369781494	aux_loss: 0.25080811977386475
14:24:40 INFO - main: Train iter. 81900/200000 (40.95%): 	Loss: 3.6381309032440186	recon_loss: 0.024216176941990852	bpp_loss: 2.9116456508636475	aux_loss: 0.43844977021217346
14:24:57 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 3.623915195465088	recon_loss: 0.02433878183364868	bpp_loss: 2.893751859664917	aux_loss: 0.342721551656723
14:25:15 INFO - main: Train iter. 82100/200000 (41.05%): 	Loss: 3.63314151763916	recon_loss: 0.024133285507559776	bpp_loss: 2.9091429710388184	aux_loss: 0.9047095775604248
14:25:32 INFO - main: Train iter. 82200/200000 (41.1%): 	Loss: 3.6365342140197754	recon_loss: 0.02416476048529148	bpp_loss: 2.9115912914276123	aux_loss: 0.5791506171226501
14:25:50 INFO - main: Train iter. 82300/200000 (41.15%): 	Loss: 3.6332268714904785	recon_loss: 0.024118464440107346	bpp_loss: 2.909672975540161	aux_loss: 0.3082738220691681
14:26:08 INFO - main: Train iter. 82400/200000 (41.2%): 	Loss: 3.624912977218628	recon_loss: 0.024114474654197693	bpp_loss: 2.9014787673950195	aux_loss: 0.9977481365203857
14:26:25 INFO - main: Train iter. 82500/200000 (41.25%): 	Loss: 3.637032985687256	recon_loss: 0.024177921935915947	bpp_loss: 2.9116952419281006	aux_loss: 0.7584421634674072
14:26:43 INFO - main: Train iter. 82600/200000 (41.3%): 	Loss: 3.636162281036377	recon_loss: 0.024155599996447563	bpp_loss: 2.911494255065918	aux_loss: 0.4381396770477295
14:27:00 INFO - main: Train iter. 82700/200000 (41.35%): 	Loss: 3.6291890144348145	recon_loss: 0.02416391670703888	bpp_loss: 2.9042716026306152	aux_loss: 0.3360678553581238
14:27:18 INFO - main: Train iter. 82800/200000 (41.4%): 	Loss: 3.636193037033081	recon_loss: 0.024152150377631187	bpp_loss: 2.911628484725952	aux_loss: 0.3317393362522125
14:27:36 INFO - main: Train iter. 82900/200000 (41.45%): 	Loss: 3.6545298099517822	recon_loss: 0.024276694282889366	bpp_loss: 2.9262290000915527	aux_loss: 0.2168276011943817
14:27:53 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 3.631463050842285	recon_loss: 0.024184424430131912	bpp_loss: 2.905930280685425	aux_loss: 0.48503777384757996
14:28:11 INFO - main: Train iter. 83100/200000 (41.55%): 	Loss: 3.6594858169555664	recon_loss: 0.02426047809422016	bpp_loss: 2.931671380996704	aux_loss: 0.41774457693099976
14:28:31 INFO - main: Train iter. 83200/200000 (41.6%): 	Loss: 3.633561611175537	recon_loss: 0.02416021190583706	bpp_loss: 2.908755302429199	aux_loss: 0.43551069498062134
14:28:49 INFO - main: Train iter. 83300/200000 (41.65%): 	Loss: 3.640220880508423	recon_loss: 0.024154815822839737	bpp_loss: 2.915576457977295	aux_loss: 0.18060174584388733
14:29:06 INFO - main: Train iter. 83400/200000 (41.7%): 	Loss: 3.6199445724487305	recon_loss: 0.024072499945759773	bpp_loss: 2.8977696895599365	aux_loss: 0.9334696531295776
14:29:24 INFO - main: Train iter. 83500/200000 (41.75%): 	Loss: 3.6098504066467285	recon_loss: 0.02403191290795803	bpp_loss: 2.888892889022827	aux_loss: 0.29417890310287476
14:29:42 INFO - main: Train iter. 83600/200000 (41.8%): 	Loss: 3.631042003631592	recon_loss: 0.024158785119652748	bpp_loss: 2.906278371810913	aux_loss: 0.1553165316581726
14:29:59 INFO - main: Train iter. 83700/200000 (41.85%): 	Loss: 3.631925106048584	recon_loss: 0.024126244708895683	bpp_loss: 2.908137798309326	aux_loss: 0.2662314772605896
14:30:17 INFO - main: Train iter. 83800/200000 (41.9%): 	Loss: 3.6260056495666504	recon_loss: 0.024060247465968132	bpp_loss: 2.904198169708252	aux_loss: 0.5137408971786499
14:30:35 INFO - main: Train iter. 83900/200000 (41.95%): 	Loss: 3.6431803703308105	recon_loss: 0.02418120950460434	bpp_loss: 2.9177441596984863	aux_loss: 0.20219719409942627
14:30:52 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 3.6287572383880615	recon_loss: 0.02412523701786995	bpp_loss: 2.9050002098083496	aux_loss: 0.22138431668281555
14:31:10 INFO - main: Train iter. 84100/200000 (42.05%): 	Loss: 3.6171512603759766	recon_loss: 0.024045784026384354	bpp_loss: 2.895777702331543	aux_loss: 0.3215153217315674
14:31:28 INFO - main: Train iter. 84200/200000 (42.1%): 	Loss: 3.623563528060913	recon_loss: 0.024129150435328484	bpp_loss: 2.899688959121704	aux_loss: 1.3321707248687744
14:31:45 INFO - main: Train iter. 84300/200000 (42.15%): 	Loss: 3.64845609664917	recon_loss: 0.024239791557192802	bpp_loss: 2.921262264251709	aux_loss: 0.5516448616981506
14:32:03 INFO - main: Train iter. 84400/200000 (42.2%): 	Loss: 3.610579490661621	recon_loss: 0.024114474654197693	bpp_loss: 2.8871452808380127	aux_loss: 0.4494795799255371
14:32:21 INFO - main: Train iter. 84500/200000 (42.25%): 	Loss: 3.614628791809082	recon_loss: 0.024031715467572212	bpp_loss: 2.8936774730682373	aux_loss: 0.3629014194011688
14:32:39 INFO - main: Train iter. 84600/200000 (42.3%): 	Loss: 3.640874147415161	recon_loss: 0.024210423231124878	bpp_loss: 2.9145615100860596	aux_loss: 0.25558167695999146
14:32:56 INFO - main: Train iter. 84700/200000 (42.35%): 	Loss: 3.6439878940582275	recon_loss: 0.024247661232948303	bpp_loss: 2.916558027267456	aux_loss: 0.4100281894207001
14:33:14 INFO - main: Train iter. 84800/200000 (42.4%): 	Loss: 3.6211838722229004	recon_loss: 0.02408410608768463	bpp_loss: 2.898660659790039	aux_loss: 0.9331154227256775
14:33:32 INFO - main: Train iter. 84900/200000 (42.45%): 	Loss: 3.6343913078308105	recon_loss: 0.02417096681892872	bpp_loss: 2.909262180328369	aux_loss: 0.4814305901527405
14:33:49 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 3.625844717025757	recon_loss: 0.024128295481204987	bpp_loss: 2.901995897293091	aux_loss: 1.0058863162994385
14:33:59 INFO - main: {'TEST MSE': 0.02414110827667611, 'TEST BPP': 2.9538125, 'TEST loss': 3.6293560028076173, 'TEST recon_loss': 0.02414110821299255, 'TEST bpp_loss': 2.905122758388519}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:34:16 INFO - main: Train iter. 85100/200000 (42.55%): 	Loss: 3.6227149963378906	recon_loss: 0.024112418293952942	bpp_loss: 2.8993425369262695	aux_loss: 0.2693505585193634
14:34:34 INFO - main: Train iter. 85200/200000 (42.6%): 	Loss: 3.619197368621826	recon_loss: 0.024093767628073692	bpp_loss: 2.8963844776153564	aux_loss: 0.26331308484077454
14:34:52 INFO - main: Train iter. 85300/200000 (42.65%): 	Loss: 3.632652759552002	recon_loss: 0.024170387536287308	bpp_loss: 2.907541036605835	aux_loss: 0.4328664243221283
14:35:09 INFO - main: Train iter. 85400/200000 (42.7%): 	Loss: 3.635054588317871	recon_loss: 0.02414632961153984	bpp_loss: 2.9106645584106445	aux_loss: 0.21463727951049805
14:35:27 INFO - main: Train iter. 85500/200000 (42.75%): 	Loss: 3.6369943618774414	recon_loss: 0.024212675169110298	bpp_loss: 2.910614013671875	aux_loss: 0.45015808939933777
14:35:44 INFO - main: Train iter. 85600/200000 (42.8%): 	Loss: 3.639709711074829	recon_loss: 0.024172434583306313	bpp_loss: 2.914536714553833	aux_loss: 0.6194058656692505
14:36:02 INFO - main: Train iter. 85700/200000 (42.85%): 	Loss: 3.6376874446868896	recon_loss: 0.02419641986489296	bpp_loss: 2.911794900894165	aux_loss: 0.2196112871170044
14:36:20 INFO - main: Train iter. 85800/200000 (42.9%): 	Loss: 3.6303369998931885	recon_loss: 0.024113429710268974	bpp_loss: 2.9069340229034424	aux_loss: 0.29185229539871216
14:36:38 INFO - main: Train iter. 85900/200000 (42.95%): 	Loss: 3.6229987144470215	recon_loss: 0.024059224873781204	bpp_loss: 2.901221990585327	aux_loss: 0.5129282474517822
14:36:55 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 3.6483287811279297	recon_loss: 0.024292726069688797	bpp_loss: 2.9195470809936523	aux_loss: 0.2204705774784088
14:37:13 INFO - main: Train iter. 86100/200000 (43.05%): 	Loss: 3.6372764110565186	recon_loss: 0.024173123762011528	bpp_loss: 2.9120826721191406	aux_loss: 0.26358529925346375
14:37:30 INFO - main: Train iter. 86200/200000 (43.1%): 	Loss: 3.628108263015747	recon_loss: 0.024107692763209343	bpp_loss: 2.9048774242401123	aux_loss: 0.2211761772632599
14:37:48 INFO - main: Train iter. 86300/200000 (43.15%): 	Loss: 3.63757061958313	recon_loss: 0.024192433804273605	bpp_loss: 2.911797523498535	aux_loss: 0.7177985906600952
14:38:05 INFO - main: Train iter. 86400/200000 (43.2%): 	Loss: 3.6334426403045654	recon_loss: 0.024133682250976562	bpp_loss: 2.9094321727752686	aux_loss: 0.6936596632003784
14:38:24 INFO - main: Train iter. 86500/200000 (43.25%): 	Loss: 3.6364495754241943	recon_loss: 0.02416635863482952	bpp_loss: 2.911458730697632	aux_loss: 0.2277182638645172
14:38:43 INFO - main: Train iter. 86600/200000 (43.3%): 	Loss: 3.640104055404663	recon_loss: 0.024187929928302765	bpp_loss: 2.914466142654419	aux_loss: 0.39637595415115356
14:39:01 INFO - main: Train iter. 86700/200000 (43.35%): 	Loss: 3.6359825134277344	recon_loss: 0.024184517562389374	bpp_loss: 2.910447120666504	aux_loss: 0.2469034492969513
14:39:19 INFO - main: Train iter. 86800/200000 (43.4%): 	Loss: 3.6249351501464844	recon_loss: 0.024081114679574966	bpp_loss: 2.9025015830993652	aux_loss: 1.1568440198898315
14:39:37 INFO - main: Train iter. 86900/200000 (43.45%): 	Loss: 3.6139631271362305	recon_loss: 0.0240639615803957	bpp_loss: 2.8920443058013916	aux_loss: 0.18723700940608978
14:39:54 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 3.626392126083374	recon_loss: 0.024101432412862778	bpp_loss: 2.9033491611480713	aux_loss: 0.2907341718673706
14:40:12 INFO - main: Train iter. 87100/200000 (43.55%): 	Loss: 3.6191017627716064	recon_loss: 0.024055693298578262	bpp_loss: 2.897430896759033	aux_loss: 0.7759275436401367
14:40:30 INFO - main: Train iter. 87200/200000 (43.6%): 	Loss: 3.645688533782959	recon_loss: 0.024233348667621613	bpp_loss: 2.9186880588531494	aux_loss: 0.6061867475509644
14:40:47 INFO - main: Train iter. 87300/200000 (43.65%): 	Loss: 3.617400646209717	recon_loss: 0.02407808229327202	bpp_loss: 2.8950581550598145	aux_loss: 0.6468424201011658
14:41:05 INFO - main: Train iter. 87400/200000 (43.7%): 	Loss: 3.6355626583099365	recon_loss: 0.024111006408929825	bpp_loss: 2.9122323989868164	aux_loss: 0.46385401487350464
14:41:23 INFO - main: Train iter. 87500/200000 (43.75%): 	Loss: 3.63033390045166	recon_loss: 0.02410048246383667	bpp_loss: 2.9073193073272705	aux_loss: 0.23099389672279358
14:41:40 INFO - main: Train iter. 87600/200000 (43.8%): 	Loss: 3.62719988822937	recon_loss: 0.024123821407556534	bpp_loss: 2.9034852981567383	aux_loss: 0.28790539503097534
14:41:58 INFO - main: Train iter. 87700/200000 (43.85%): 	Loss: 3.6349775791168213	recon_loss: 0.02419103868305683	bpp_loss: 2.9092464447021484	aux_loss: 0.2958711087703705
14:42:15 INFO - main: Train iter. 87800/200000 (43.9%): 	Loss: 3.645555019378662	recon_loss: 0.02426997199654579	bpp_loss: 2.9174559116363525	aux_loss: 0.2930196225643158
14:42:33 INFO - main: Train iter. 87900/200000 (43.95%): 	Loss: 3.63112735748291	recon_loss: 0.024086710065603256	bpp_loss: 2.9085259437561035	aux_loss: 0.49218621850013733
14:42:50 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 3.633120059967041	recon_loss: 0.024205675348639488	bpp_loss: 2.906949758529663	aux_loss: 0.6810780167579651
14:43:08 INFO - main: Train iter. 88100/200000 (44.05%): 	Loss: 3.6254496574401855	recon_loss: 0.024106593802571297	bpp_loss: 2.902251958847046	aux_loss: 0.28025588393211365
14:43:26 INFO - main: Train iter. 88200/200000 (44.1%): 	Loss: 3.6424150466918945	recon_loss: 0.024192599579691887	bpp_loss: 2.9166371822357178	aux_loss: 0.8505579233169556
14:43:43 INFO - main: Train iter. 88300/200000 (44.15%): 	Loss: 3.6121230125427246	recon_loss: 0.024017544463276863	bpp_loss: 2.891596555709839	aux_loss: 0.33961018919944763
14:44:01 INFO - main: Train iter. 88400/200000 (44.2%): 	Loss: 3.617098569869995	recon_loss: 0.024048740044236183	bpp_loss: 2.8956363201141357	aux_loss: 0.35042643547058105
14:44:19 INFO - main: Train iter. 88500/200000 (44.25%): 	Loss: 3.6361305713653564	recon_loss: 0.024155274033546448	bpp_loss: 2.9114723205566406	aux_loss: 0.2733299136161804
14:44:36 INFO - main: Train iter. 88600/200000 (44.3%): 	Loss: 3.624816417694092	recon_loss: 0.02408820390701294	bpp_loss: 2.902170419692993	aux_loss: 0.3867011070251465
14:44:54 INFO - main: Train iter. 88700/200000 (44.35%): 	Loss: 3.6338300704956055	recon_loss: 0.024151619523763657	bpp_loss: 2.9092814922332764	aux_loss: 0.684289276599884
14:45:12 INFO - main: Train iter. 88800/200000 (44.4%): 	Loss: 3.625831127166748	recon_loss: 0.024100756272673607	bpp_loss: 2.902808427810669	aux_loss: 0.6671104431152344
14:45:30 INFO - main: Train iter. 88900/200000 (44.45%): 	Loss: 3.624783992767334	recon_loss: 0.024089356884360313	bpp_loss: 2.9021034240722656	aux_loss: 0.3266252279281616
14:45:47 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 3.639955997467041	recon_loss: 0.024213572964072227	bpp_loss: 2.913548707962036	aux_loss: 0.6188940405845642
14:46:05 INFO - main: Train iter. 89100/200000 (44.55%): 	Loss: 3.630347490310669	recon_loss: 0.024150611832737923	bpp_loss: 2.9058291912078857	aux_loss: 0.3920325040817261
14:46:22 INFO - main: Train iter. 89200/200000 (44.6%): 	Loss: 3.6245925426483154	recon_loss: 0.02414030209183693	bpp_loss: 2.900383472442627	aux_loss: 0.6270427703857422
14:46:40 INFO - main: Train iter. 89300/200000 (44.65%): 	Loss: 3.627068042755127	recon_loss: 0.024126505479216576	bpp_loss: 2.903272867202759	aux_loss: 1.2189198732376099
14:46:58 INFO - main: Train iter. 89400/200000 (44.7%): 	Loss: 3.6156458854675293	recon_loss: 0.02404707670211792	bpp_loss: 2.894233465194702	aux_loss: 0.6669824123382568
14:47:15 INFO - main: Train iter. 89500/200000 (44.75%): 	Loss: 3.6357223987579346	recon_loss: 0.024172982200980186	bpp_loss: 2.9105329513549805	aux_loss: 0.3438776135444641
14:47:33 INFO - main: Train iter. 89600/200000 (44.8%): 	Loss: 3.619846820831299	recon_loss: 0.02411596290767193	bpp_loss: 2.8963680267333984	aux_loss: 0.18929742276668549
14:47:51 INFO - main: Train iter. 89700/200000 (44.85%): 	Loss: 3.6192684173583984	recon_loss: 0.024107474833726883	bpp_loss: 2.8960442543029785	aux_loss: 0.45197808742523193
14:48:08 INFO - main: Train iter. 89800/200000 (44.9%): 	Loss: 3.6262102127075195	recon_loss: 0.02411288395524025	bpp_loss: 2.9028236865997314	aux_loss: 0.22080036997795105
14:48:29 INFO - main: Train iter. 89900/200000 (44.95%): 	Loss: 3.6345982551574707	recon_loss: 0.024210115894675255	bpp_loss: 2.908294677734375	aux_loss: 0.3114086091518402
14:48:46 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 3.64123797416687	recon_loss: 0.024188946932554245	bpp_loss: 2.915569543838501	aux_loss: 0.2580583095550537
14:48:56 INFO - main: {'TEST MSE': 0.024142531787816352, 'TEST BPP': 2.95334375, 'TEST loss': 3.6292442727088927, 'TEST recon_loss': 0.02414253172837198, 'TEST bpp_loss': 2.9049683213233948}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:49:14 INFO - main: Train iter. 90100/200000 (45.05%): 	Loss: 3.6323132514953613	recon_loss: 0.024140408262610435	bpp_loss: 2.9081010818481445	aux_loss: 0.7038178443908691
14:49:32 INFO - main: Train iter. 90200/200000 (45.1%): 	Loss: 3.6214118003845215	recon_loss: 0.024117523804306984	bpp_loss: 2.897886037826538	aux_loss: 0.4216725826263428
14:49:49 INFO - main: Train iter. 90300/200000 (45.15%): 	Loss: 3.629103899002075	recon_loss: 0.024144355207681656	bpp_loss: 2.904773235321045	aux_loss: 0.2326989471912384
14:50:07 INFO - main: Train iter. 90400/200000 (45.2%): 	Loss: 3.627885580062866	recon_loss: 0.02413243241608143	bpp_loss: 2.9039125442504883	aux_loss: 0.31559085845947266
14:50:25 INFO - main: Train iter. 90500/200000 (45.25%): 	Loss: 3.6408755779266357	recon_loss: 0.024177076295018196	bpp_loss: 2.9155633449554443	aux_loss: 0.20551683008670807
14:50:43 INFO - main: Train iter. 90600/200000 (45.3%): 	Loss: 3.623887538909912	recon_loss: 0.02407280169427395	bpp_loss: 2.901703357696533	aux_loss: 0.22083976864814758
14:51:00 INFO - main: Train iter. 90700/200000 (45.35%): 	Loss: 3.625136375427246	recon_loss: 0.024111410602927208	bpp_loss: 2.901794195175171	aux_loss: 0.3226633369922638
14:51:18 INFO - main: Train iter. 90800/200000 (45.4%): 	Loss: 3.6266262531280518	recon_loss: 0.024072399362921715	bpp_loss: 2.904454231262207	aux_loss: 0.484603613615036
14:51:36 INFO - main: Train iter. 90900/200000 (45.45%): 	Loss: 3.625898838043213	recon_loss: 0.024155620485544205	bpp_loss: 2.9012300968170166	aux_loss: 0.47265127301216125
14:51:54 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 3.6333975791931152	recon_loss: 0.024188388139009476	bpp_loss: 2.9077460765838623	aux_loss: 0.9539968967437744
14:52:11 INFO - main: Train iter. 91100/200000 (45.55%): 	Loss: 3.6259210109710693	recon_loss: 0.024143880233168602	bpp_loss: 2.901604652404785	aux_loss: 0.34330540895462036
14:52:29 INFO - main: Train iter. 91200/200000 (45.6%): 	Loss: 3.642183542251587	recon_loss: 0.024155981838703156	bpp_loss: 2.917504072189331	aux_loss: 0.4410932660102844
14:52:47 INFO - main: Train iter. 91300/200000 (45.65%): 	Loss: 3.631197452545166	recon_loss: 0.024134088307619095	bpp_loss: 2.907174825668335	aux_loss: 0.4979354441165924
14:53:05 INFO - main: Train iter. 91400/200000 (45.7%): 	Loss: 3.6493685245513916	recon_loss: 0.02420767955482006	bpp_loss: 2.92313814163208	aux_loss: 0.9396134614944458
14:53:23 INFO - main: Train iter. 91500/200000 (45.75%): 	Loss: 3.6265347003936768	recon_loss: 0.024095438420772552	bpp_loss: 2.9036715030670166	aux_loss: 0.2255256474018097
14:53:40 INFO - main: Train iter. 91600/200000 (45.8%): 	Loss: 3.6161139011383057	recon_loss: 0.024079253897070885	bpp_loss: 2.8937363624572754	aux_loss: 0.5186026692390442
14:53:58 INFO - main: Train iter. 91700/200000 (45.85%): 	Loss: 3.6114349365234375	recon_loss: 0.024025436490774155	bpp_loss: 2.890671730041504	aux_loss: 0.22818948328495026
14:54:16 INFO - main: Train iter. 91800/200000 (45.9%): 	Loss: 3.634674549102783	recon_loss: 0.024195987731218338	bpp_loss: 2.90879487991333	aux_loss: 1.6327991485595703
14:54:34 INFO - main: Train iter. 91900/200000 (45.95%): 	Loss: 3.639845371246338	recon_loss: 0.024166174232959747	bpp_loss: 2.9148600101470947	aux_loss: 0.25623342394828796
14:54:52 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 3.6281919479370117	recon_loss: 0.024122321978211403	bpp_loss: 2.90452241897583	aux_loss: 0.32234442234039307
14:55:09 INFO - main: Train iter. 92100/200000 (46.05%): 	Loss: 3.6340343952178955	recon_loss: 0.024195266887545586	bpp_loss: 2.9081764221191406	aux_loss: 0.4841885566711426
14:55:27 INFO - main: Train iter. 92200/200000 (46.1%): 	Loss: 3.6355535984039307	recon_loss: 0.024180324748158455	bpp_loss: 2.9101438522338867	aux_loss: 0.549334704875946
14:55:45 INFO - main: Train iter. 92300/200000 (46.15%): 	Loss: 3.619382619857788	recon_loss: 0.024052191525697708	bpp_loss: 2.8978168964385986	aux_loss: 0.5439686179161072
14:56:03 INFO - main: Train iter. 92400/200000 (46.2%): 	Loss: 3.633202075958252	recon_loss: 0.024133116006851196	bpp_loss: 2.9092085361480713	aux_loss: 0.3696455955505371
14:56:21 INFO - main: Train iter. 92500/200000 (46.25%): 	Loss: 3.6392579078674316	recon_loss: 0.024186449125409126	bpp_loss: 2.9136645793914795	aux_loss: 0.41003870964050293
14:56:38 INFO - main: Train iter. 92600/200000 (46.3%): 	Loss: 3.626823663711548	recon_loss: 0.02416827157139778	bpp_loss: 2.901775598526001	aux_loss: 0.28681570291519165
14:56:56 INFO - main: Train iter. 92700/200000 (46.35%): 	Loss: 3.6229496002197266	recon_loss: 0.02406737580895424	bpp_loss: 2.900928258895874	aux_loss: 0.34707194566726685
14:57:14 INFO - main: Train iter. 92800/200000 (46.4%): 	Loss: 3.6421725749969482	recon_loss: 0.024211160838603973	bpp_loss: 2.9158377647399902	aux_loss: 0.24241799116134644
14:57:32 INFO - main: Train iter. 92900/200000 (46.45%): 	Loss: 3.6416542530059814	recon_loss: 0.02416900172829628	bpp_loss: 2.9165842533111572	aux_loss: 0.2256355881690979
14:57:49 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 3.621350049972534	recon_loss: 0.024036668241024017	bpp_loss: 2.90024995803833	aux_loss: 0.2745971083641052
14:58:07 INFO - main: Train iter. 93100/200000 (46.55%): 	Loss: 3.6202056407928467	recon_loss: 0.024077216163277626	bpp_loss: 2.8978891372680664	aux_loss: 0.2258194088935852
14:58:28 INFO - main: Train iter. 93200/200000 (46.6%): 	Loss: 3.637963056564331	recon_loss: 0.024163825437426567	bpp_loss: 2.913048267364502	aux_loss: 0.3353985548019409
14:58:45 INFO - main: Train iter. 93300/200000 (46.65%): 	Loss: 3.6228249073028564	recon_loss: 0.02408676967024803	bpp_loss: 2.900221824645996	aux_loss: 0.7987267971038818
14:59:03 INFO - main: Train iter. 93400/200000 (46.7%): 	Loss: 3.64395809173584	recon_loss: 0.02423478662967682	bpp_loss: 2.916914463043213	aux_loss: 0.8473926782608032
14:59:21 INFO - main: Train iter. 93500/200000 (46.75%): 	Loss: 3.642955780029297	recon_loss: 0.02419576235115528	bpp_loss: 2.9170830249786377	aux_loss: 0.544038712978363
14:59:39 INFO - main: Train iter. 93600/200000 (46.8%): 	Loss: 3.6340129375457764	recon_loss: 0.02416739985346794	bpp_loss: 2.9089908599853516	aux_loss: 0.6037487983703613
14:59:57 INFO - main: Train iter. 93700/200000 (46.85%): 	Loss: 3.6204328536987305	recon_loss: 0.024046296253800392	bpp_loss: 2.8990440368652344	aux_loss: 0.7485905885696411
15:00:15 INFO - main: Train iter. 93800/200000 (46.9%): 	Loss: 3.6179819107055664	recon_loss: 0.02402477338910103	bpp_loss: 2.8972387313842773	aux_loss: 0.3389011025428772
15:00:32 INFO - main: Train iter. 93900/200000 (46.95%): 	Loss: 3.6298959255218506	recon_loss: 0.024115266278386116	bpp_loss: 2.906437873840332	aux_loss: 0.16435176134109497
15:00:50 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 3.639820098876953	recon_loss: 0.024178842082619667	bpp_loss: 2.914454698562622	aux_loss: 0.24171200394630432
15:01:08 INFO - main: Train iter. 94100/200000 (47.05%): 	Loss: 3.6281967163085938	recon_loss: 0.024128518998622894	bpp_loss: 2.904341220855713	aux_loss: 0.34950917959213257
15:01:26 INFO - main: Train iter. 94200/200000 (47.1%): 	Loss: 3.6390912532806396	recon_loss: 0.024231864139437675	bpp_loss: 2.912135362625122	aux_loss: 0.30619022250175476
15:01:44 INFO - main: Train iter. 94300/200000 (47.15%): 	Loss: 3.639136791229248	recon_loss: 0.024194419384002686	bpp_loss: 2.913304090499878	aux_loss: 0.46766072511672974
15:02:02 INFO - main: Train iter. 94400/200000 (47.2%): 	Loss: 3.6361777782440186	recon_loss: 0.024168819189071655	bpp_loss: 2.9111132621765137	aux_loss: 0.742244303226471
15:02:19 INFO - main: Train iter. 94500/200000 (47.25%): 	Loss: 3.6347646713256836	recon_loss: 0.024089505895972252	bpp_loss: 2.9120795726776123	aux_loss: 0.2100125551223755
15:02:37 INFO - main: Train iter. 94600/200000 (47.3%): 	Loss: 3.634314775466919	recon_loss: 0.024178026244044304	bpp_loss: 2.9089739322662354	aux_loss: 0.21687594056129456
15:02:55 INFO - main: Train iter. 94700/200000 (47.35%): 	Loss: 3.6087374687194824	recon_loss: 0.02403319999575615	bpp_loss: 2.8877413272857666	aux_loss: 0.23035569489002228
15:03:13 INFO - main: Train iter. 94800/200000 (47.4%): 	Loss: 3.6335647106170654	recon_loss: 0.024136437103152275	bpp_loss: 2.9094715118408203	aux_loss: 0.3342205286026001
15:03:30 INFO - main: Train iter. 94900/200000 (47.45%): 	Loss: 3.6201868057250977	recon_loss: 0.02406010404229164	bpp_loss: 2.898383617401123	aux_loss: 0.31029531359672546
15:03:48 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 3.630864381790161	recon_loss: 0.02412145398557186	bpp_loss: 2.9072208404541016	aux_loss: 0.2864460349082947
15:03:58 INFO - main: {'TEST MSE': 0.024117553679981262, 'TEST BPP': 2.954, 'TEST loss': 3.6291924266815188, 'TEST recon_loss': 0.02411755359917879, 'TEST bpp_loss': 2.9056658163070677}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:04:16 INFO - main: Train iter. 95100/200000 (47.55%): 	Loss: 3.624173879623413	recon_loss: 0.02411935105919838	bpp_loss: 2.9005932807922363	aux_loss: 0.3943237066268921
15:04:33 INFO - main: Train iter. 95200/200000 (47.6%): 	Loss: 3.627622127532959	recon_loss: 0.024148806929588318	bpp_loss: 2.903157949447632	aux_loss: 0.3995676040649414
15:04:51 INFO - main: Train iter. 95300/200000 (47.65%): 	Loss: 3.6250147819519043	recon_loss: 0.024139929562807083	bpp_loss: 2.9008169174194336	aux_loss: 0.3198601305484772
15:05:08 INFO - main: Train iter. 95400/200000 (47.7%): 	Loss: 3.626861572265625	recon_loss: 0.024089191108942032	bpp_loss: 2.9041857719421387	aux_loss: 0.9367641806602478
15:05:26 INFO - main: Train iter. 95500/200000 (47.75%): 	Loss: 3.622286796569824	recon_loss: 0.02407754585146904	bpp_loss: 2.899960517883301	aux_loss: 0.23504972457885742
15:05:44 INFO - main: Train iter. 95600/200000 (47.8%): 	Loss: 3.625020980834961	recon_loss: 0.0240912064909935	bpp_loss: 2.902284860610962	aux_loss: 0.6280757188796997
15:06:02 INFO - main: Train iter. 95700/200000 (47.85%): 	Loss: 3.621311664581299	recon_loss: 0.024065831676125526	bpp_loss: 2.899336576461792	aux_loss: 0.4471128284931183
15:06:19 INFO - main: Train iter. 95800/200000 (47.9%): 	Loss: 3.610165596008301	recon_loss: 0.02400224655866623	bpp_loss: 2.8900983333587646	aux_loss: 0.38552844524383545
15:06:37 INFO - main: Train iter. 95900/200000 (47.95%): 	Loss: 3.621661424636841	recon_loss: 0.024054361507296562	bpp_loss: 2.9000306129455566	aux_loss: 0.27680546045303345
15:06:55 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 3.624938488006592	recon_loss: 0.0240922924131155	bpp_loss: 2.902169704437256	aux_loss: 0.4467405080795288
15:07:12 INFO - main: Train iter. 96100/200000 (48.05%): 	Loss: 3.6443865299224854	recon_loss: 0.024196909740567207	bpp_loss: 2.9184792041778564	aux_loss: 0.23005619645118713
15:07:30 INFO - main: Train iter. 96200/200000 (48.1%): 	Loss: 3.6111793518066406	recon_loss: 0.024073921144008636	bpp_loss: 2.8889617919921875	aux_loss: 0.27623122930526733
15:07:48 INFO - main: Train iter. 96300/200000 (48.15%): 	Loss: 3.6279094219207764	recon_loss: 0.0240883007645607	bpp_loss: 2.9052603244781494	aux_loss: 0.4431271553039551
15:08:06 INFO - main: Train iter. 96400/200000 (48.2%): 	Loss: 3.62325382232666	recon_loss: 0.024111242964863777	bpp_loss: 2.899916648864746	aux_loss: 0.48364052176475525
15:08:26 INFO - main: Train iter. 96500/200000 (48.25%): 	Loss: 3.639295816421509	recon_loss: 0.02417244203388691	bpp_loss: 2.9141225814819336	aux_loss: 0.28683388233184814
15:08:44 INFO - main: Train iter. 96600/200000 (48.3%): 	Loss: 3.6329402923583984	recon_loss: 0.02416077069938183	bpp_loss: 2.9081172943115234	aux_loss: 0.6740795373916626
15:09:02 INFO - main: Train iter. 96700/200000 (48.35%): 	Loss: 3.64461612701416	recon_loss: 0.024186493828892708	bpp_loss: 2.9190213680267334	aux_loss: 0.4788637161254883
15:09:20 INFO - main: Train iter. 96800/200000 (48.4%): 	Loss: 3.6254074573516846	recon_loss: 0.02411901205778122	bpp_loss: 2.901837110519409	aux_loss: 0.28777503967285156
15:09:38 INFO - main: Train iter. 96900/200000 (48.45%): 	Loss: 3.62480092048645	recon_loss: 0.02409631386399269	bpp_loss: 2.901911497116089	aux_loss: 0.2729482054710388
15:09:56 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 3.6451001167297363	recon_loss: 0.0241581778973341	bpp_loss: 2.9203548431396484	aux_loss: 1.05845308303833
15:10:14 INFO - main: Train iter. 97100/200000 (48.55%): 	Loss: 3.6247951984405518	recon_loss: 0.024125637486577034	bpp_loss: 2.9010260105133057	aux_loss: 0.3769824504852295
15:10:31 INFO - main: Train iter. 97200/200000 (48.6%): 	Loss: 3.6345717906951904	recon_loss: 0.024111872538924217	bpp_loss: 2.9112155437469482	aux_loss: 0.6138449907302856
15:10:49 INFO - main: Train iter. 97300/200000 (48.65%): 	Loss: 3.6402764320373535	recon_loss: 0.02420525625348091	bpp_loss: 2.914118766784668	aux_loss: 0.2219020426273346
15:11:07 INFO - main: Train iter. 97400/200000 (48.7%): 	Loss: 3.640634775161743	recon_loss: 0.024150928482413292	bpp_loss: 2.916106939315796	aux_loss: 0.31720319390296936
15:11:24 INFO - main: Train iter. 97500/200000 (48.75%): 	Loss: 3.6338391304016113	recon_loss: 0.024150008335709572	bpp_loss: 2.90933895111084	aux_loss: 0.7034443616867065
15:11:42 INFO - main: Train iter. 97600/200000 (48.8%): 	Loss: 3.6175289154052734	recon_loss: 0.024105282500386238	bpp_loss: 2.8943705558776855	aux_loss: 0.2597358822822571
15:12:00 INFO - main: Train iter. 97700/200000 (48.85%): 	Loss: 3.632725238800049	recon_loss: 0.02411106787621975	bpp_loss: 2.909393310546875	aux_loss: 0.3000651001930237
15:12:18 INFO - main: Train iter. 97800/200000 (48.9%): 	Loss: 3.634805202484131	recon_loss: 0.024147043004631996	bpp_loss: 2.9103939533233643	aux_loss: 0.39745309948921204
15:12:36 INFO - main: Train iter. 97900/200000 (48.95%): 	Loss: 3.618739604949951	recon_loss: 0.0239998959004879	bpp_loss: 2.89874267578125	aux_loss: 0.48278066515922546
15:12:54 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 3.6360056400299072	recon_loss: 0.024130869656801224	bpp_loss: 2.9120795726776123	aux_loss: 1.3293066024780273
15:13:11 INFO - main: Train iter. 98100/200000 (49.05%): 	Loss: 3.631887435913086	recon_loss: 0.02419327013194561	bpp_loss: 2.9060893058776855	aux_loss: 1.3123904466629028
15:13:29 INFO - main: Train iter. 98200/200000 (49.1%): 	Loss: 3.6293673515319824	recon_loss: 0.024118658155202866	bpp_loss: 2.9058077335357666	aux_loss: 0.3069400191307068
15:13:47 INFO - main: Train iter. 98300/200000 (49.15%): 	Loss: 3.6215877532958984	recon_loss: 0.024053562432527542	bpp_loss: 2.8999810218811035	aux_loss: 0.5025933980941772
15:14:05 INFO - main: Train iter. 98400/200000 (49.2%): 	Loss: 3.6280078887939453	recon_loss: 0.024150224402546883	bpp_loss: 2.903501272201538	aux_loss: 0.25398802757263184
15:14:22 INFO - main: Train iter. 98500/200000 (49.25%): 	Loss: 3.6278281211853027	recon_loss: 0.02412550151348114	bpp_loss: 2.9040629863739014	aux_loss: 1.0734180212020874
15:14:40 INFO - main: Train iter. 98600/200000 (49.3%): 	Loss: 3.638589382171631	recon_loss: 0.02419910579919815	bpp_loss: 2.91261625289917	aux_loss: 0.579929530620575
15:14:57 INFO - main: Train iter. 98700/200000 (49.35%): 	Loss: 3.6271636486053467	recon_loss: 0.024108324199914932	bpp_loss: 2.903913974761963	aux_loss: 0.17121315002441406
15:15:15 INFO - main: Train iter. 98800/200000 (49.4%): 	Loss: 3.605191469192505	recon_loss: 0.02395290695130825	bpp_loss: 2.8866043090820312	aux_loss: 0.230168879032135
15:15:33 INFO - main: Train iter. 98900/200000 (49.45%): 	Loss: 3.6414096355438232	recon_loss: 0.024205265566706657	bpp_loss: 2.9152517318725586	aux_loss: 0.32896527647972107
15:15:51 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 3.6331095695495605	recon_loss: 0.024139827117323875	bpp_loss: 2.908914804458618	aux_loss: 0.24652209877967834
15:16:08 INFO - main: Train iter. 99100/200000 (49.55%): 	Loss: 3.6178362369537354	recon_loss: 0.02405584044754505	bpp_loss: 2.8961610794067383	aux_loss: 0.35323238372802734
15:16:26 INFO - main: Train iter. 99200/200000 (49.6%): 	Loss: 3.6421260833740234	recon_loss: 0.024160023778676987	bpp_loss: 2.917325496673584	aux_loss: 0.45964452624320984
15:16:44 INFO - main: Train iter. 99300/200000 (49.65%): 	Loss: 3.6332883834838867	recon_loss: 0.024151666089892387	bpp_loss: 2.908738374710083	aux_loss: 0.36567121744155884
15:17:01 INFO - main: Train iter. 99400/200000 (49.7%): 	Loss: 3.639479875564575	recon_loss: 0.024231472983956337	bpp_loss: 2.9125356674194336	aux_loss: 0.6636067032814026
15:17:19 INFO - main: Train iter. 99500/200000 (49.75%): 	Loss: 3.6323800086975098	recon_loss: 0.024129260331392288	bpp_loss: 2.9085021018981934	aux_loss: 0.3171340525150299
15:17:37 INFO - main: Train iter. 99600/200000 (49.8%): 	Loss: 3.633031129837036	recon_loss: 0.024174226447939873	bpp_loss: 2.907804250717163	aux_loss: 0.41258203983306885
15:17:55 INFO - main: Train iter. 99700/200000 (49.85%): 	Loss: 3.631028413772583	recon_loss: 0.024139277637004852	bpp_loss: 2.9068500995635986	aux_loss: 0.26101982593536377
15:18:12 INFO - main: Train iter. 99800/200000 (49.9%): 	Loss: 3.618495464324951	recon_loss: 0.02404198981821537	bpp_loss: 2.897235631942749	aux_loss: 0.734536349773407
15:18:32 INFO - main: Train iter. 99900/200000 (49.95%): 	Loss: 3.624462604522705	recon_loss: 0.024057190865278244	bpp_loss: 2.9027469158172607	aux_loss: 0.27990761399269104
15:18:50 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 3.632990598678589	recon_loss: 0.024146372452378273	bpp_loss: 2.908599376678467	aux_loss: 0.31571513414382935
15:19:00 INFO - main: {'TEST MSE': 0.024144463029611443, 'TEST BPP': 2.9536875, 'TEST loss': 3.6292634398937227, 'TEST recon_loss': 0.024144462946802378, 'TEST bpp_loss': 2.904929556131363}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:19:18 INFO - main: Train iter. 100100/200000 (50.05%): 	Loss: 3.620453119277954	recon_loss: 0.02406764030456543	bpp_loss: 2.898423910140991	aux_loss: 0.3630863130092621
15:19:35 INFO - main: Train iter. 100200/200000 (50.1%): 	Loss: 3.6312615871429443	recon_loss: 0.02410542033612728	bpp_loss: 2.9080989360809326	aux_loss: 0.6930875182151794
15:19:53 INFO - main: Train iter. 100300/200000 (50.15%): 	Loss: 3.632051467895508	recon_loss: 0.024144558236002922	bpp_loss: 2.90771484375	aux_loss: 0.22509832680225372
15:20:11 INFO - main: Train iter. 100400/200000 (50.2%): 	Loss: 3.626147508621216	recon_loss: 0.02408706210553646	bpp_loss: 2.9035356044769287	aux_loss: 0.5812736749649048
15:20:28 INFO - main: Train iter. 100500/200000 (50.25%): 	Loss: 3.6182940006256104	recon_loss: 0.02405216172337532	bpp_loss: 2.8967292308807373	aux_loss: 0.6662406921386719
15:20:46 INFO - main: Train iter. 100600/200000 (50.3%): 	Loss: 3.635704517364502	recon_loss: 0.024157118052244186	bpp_loss: 2.9109909534454346	aux_loss: 0.43136560916900635
15:21:04 INFO - main: Train iter. 100700/200000 (50.35%): 	Loss: 3.6118578910827637	recon_loss: 0.024025507271289825	bpp_loss: 2.891092538833618	aux_loss: 0.3927682340145111
15:21:21 INFO - main: Train iter. 100800/200000 (50.4%): 	Loss: 3.6234662532806396	recon_loss: 0.02406378462910652	bpp_loss: 2.901552677154541	aux_loss: 0.4522775709629059
15:21:39 INFO - main: Train iter. 100900/200000 (50.45%): 	Loss: 3.6228833198547363	recon_loss: 0.02406991273164749	bpp_loss: 2.9007859230041504	aux_loss: 0.5652749538421631
15:21:57 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 3.621278762817383	recon_loss: 0.02414107695221901	bpp_loss: 2.8970463275909424	aux_loss: 0.709568977355957
15:22:15 INFO - main: Train iter. 101100/200000 (50.55%): 	Loss: 3.627600908279419	recon_loss: 0.024110080674290657	bpp_loss: 2.9042985439300537	aux_loss: 0.27552950382232666
15:22:32 INFO - main: Train iter. 101200/200000 (50.6%): 	Loss: 3.622035264968872	recon_loss: 0.024057166650891304	bpp_loss: 2.900320291519165	aux_loss: 0.27374693751335144
15:22:50 INFO - main: Train iter. 101300/200000 (50.65%): 	Loss: 3.6429476737976074	recon_loss: 0.024182641878724098	bpp_loss: 2.917468309402466	aux_loss: 0.45849138498306274
15:23:08 INFO - main: Train iter. 101400/200000 (50.7%): 	Loss: 3.6288063526153564	recon_loss: 0.024070022627711296	bpp_loss: 2.906705617904663	aux_loss: 0.5867999792098999
15:23:25 INFO - main: Train iter. 101500/200000 (50.75%): 	Loss: 3.626722574234009	recon_loss: 0.024090955033898354	bpp_loss: 2.903993844985962	aux_loss: 0.3225039839744568
15:23:43 INFO - main: Train iter. 101600/200000 (50.8%): 	Loss: 3.643827438354492	recon_loss: 0.024181267246603966	bpp_loss: 2.918389320373535	aux_loss: 0.18310746550559998
15:24:00 INFO - main: Train iter. 101700/200000 (50.85%): 	Loss: 3.631964921951294	recon_loss: 0.02415582537651062	bpp_loss: 2.90729022026062	aux_loss: 0.5456632375717163
15:24:18 INFO - main: Train iter. 101800/200000 (50.9%): 	Loss: 3.6243481636047363	recon_loss: 0.02408027835190296	bpp_loss: 2.901939868927002	aux_loss: 0.2203269749879837
15:24:36 INFO - main: Train iter. 101900/200000 (50.95%): 	Loss: 3.6311843395233154	recon_loss: 0.024113470688462257	bpp_loss: 2.907780170440674	aux_loss: 0.21932479739189148
15:24:53 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 3.6287689208984375	recon_loss: 0.024134935811161995	bpp_loss: 2.9047207832336426	aux_loss: 0.3594687879085541
15:25:11 INFO - main: Train iter. 102100/200000 (51.05%): 	Loss: 3.6457347869873047	recon_loss: 0.024222448468208313	bpp_loss: 2.9190614223480225	aux_loss: 0.4796587824821472
15:25:29 INFO - main: Train iter. 102200/200000 (51.1%): 	Loss: 3.6256027221679688	recon_loss: 0.024035081267356873	bpp_loss: 2.904550313949585	aux_loss: 1.0379343032836914
15:25:47 INFO - main: Train iter. 102300/200000 (51.15%): 	Loss: 3.622182846069336	recon_loss: 0.024134082719683647	bpp_loss: 2.898160457611084	aux_loss: 0.6000521779060364
15:26:04 INFO - main: Train iter. 102400/200000 (51.2%): 	Loss: 3.637922525405884	recon_loss: 0.02421649917960167	bpp_loss: 2.9114274978637695	aux_loss: 0.21363219618797302
15:26:22 INFO - main: Train iter. 102500/200000 (51.25%): 	Loss: 3.629408836364746	recon_loss: 0.024141380563378334	bpp_loss: 2.9051673412323	aux_loss: 0.5006221532821655
15:26:40 INFO - main: Train iter. 102600/200000 (51.3%): 	Loss: 3.6459667682647705	recon_loss: 0.02420550398528576	bpp_loss: 2.919801712036133	aux_loss: 0.33883413672447205
15:26:57 INFO - main: Train iter. 102700/200000 (51.35%): 	Loss: 3.6265201568603516	recon_loss: 0.0241536982357502	bpp_loss: 2.901909351348877	aux_loss: 0.2719108760356903
15:27:15 INFO - main: Train iter. 102800/200000 (51.4%): 	Loss: 3.6367595195770264	recon_loss: 0.024151060730218887	bpp_loss: 2.9122276306152344	aux_loss: 0.2104693502187729
15:27:33 INFO - main: Train iter. 102900/200000 (51.45%): 	Loss: 3.6236989498138428	recon_loss: 0.024060344323515892	bpp_loss: 2.901888608932495	aux_loss: 0.36549192667007446
15:27:50 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 3.6313726902008057	recon_loss: 0.024119272828102112	bpp_loss: 2.90779447555542	aux_loss: 0.4948688745498657
15:28:08 INFO - main: Train iter. 103100/200000 (51.55%): 	Loss: 3.629659652709961	recon_loss: 0.024115735664963722	bpp_loss: 2.9061875343322754	aux_loss: 0.4450744092464447
15:28:28 INFO - main: Train iter. 103200/200000 (51.6%): 	Loss: 3.631211042404175	recon_loss: 0.024096980690956116	bpp_loss: 2.908301591873169	aux_loss: 0.346226304769516
15:28:46 INFO - main: Train iter. 103300/200000 (51.65%): 	Loss: 3.6531548500061035	recon_loss: 0.024238884449005127	bpp_loss: 2.92598819732666	aux_loss: 0.3636786639690399
15:29:03 INFO - main: Train iter. 103400/200000 (51.7%): 	Loss: 3.61629581451416	recon_loss: 0.024024510756134987	bpp_loss: 2.8955605030059814	aux_loss: 0.4410649836063385
15:29:21 INFO - main: Train iter. 103500/200000 (51.75%): 	Loss: 3.633080005645752	recon_loss: 0.024110039696097374	bpp_loss: 2.9097788333892822	aux_loss: 0.410713255405426
15:29:39 INFO - main: Train iter. 103600/200000 (51.8%): 	Loss: 3.629997491836548	recon_loss: 0.02413698099553585	bpp_loss: 2.905888080596924	aux_loss: 0.2829464077949524
15:29:57 INFO - main: Train iter. 103700/200000 (51.85%): 	Loss: 3.636319398880005	recon_loss: 0.02416508086025715	bpp_loss: 2.9113669395446777	aux_loss: 0.3747466206550598
15:30:14 INFO - main: Train iter. 103800/200000 (51.9%): 	Loss: 3.614781141281128	recon_loss: 0.024051811546087265	bpp_loss: 2.8932268619537354	aux_loss: 0.8748332262039185
15:30:32 INFO - main: Train iter. 103900/200000 (51.95%): 	Loss: 3.634587526321411	recon_loss: 0.02412700653076172	bpp_loss: 2.9107773303985596	aux_loss: 0.2531546950340271
15:30:50 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 3.621735095977783	recon_loss: 0.02409781701862812	bpp_loss: 2.8988006114959717	aux_loss: 0.8202012777328491
15:31:07 INFO - main: Train iter. 104100/200000 (52.05%): 	Loss: 3.621645450592041	recon_loss: 0.02406708523631096	bpp_loss: 2.8996329307556152	aux_loss: 0.31594318151474
15:31:25 INFO - main: Train iter. 104200/200000 (52.1%): 	Loss: 3.6107282638549805	recon_loss: 0.02403969131410122	bpp_loss: 2.8895375728607178	aux_loss: 0.47417593002319336
15:31:43 INFO - main: Train iter. 104300/200000 (52.15%): 	Loss: 3.631692886352539	recon_loss: 0.024107934907078743	bpp_loss: 2.9084548950195312	aux_loss: 1.1690723896026611
15:32:00 INFO - main: Train iter. 104400/200000 (52.2%): 	Loss: 3.6184744834899902	recon_loss: 0.02406734973192215	bpp_loss: 2.896454095840454	aux_loss: 0.5019890069961548
15:32:18 INFO - main: Train iter. 104500/200000 (52.25%): 	Loss: 3.60768985748291	recon_loss: 0.023983489722013474	bpp_loss: 2.8881850242614746	aux_loss: 0.3444618582725525
15:32:35 INFO - main: Train iter. 104600/200000 (52.3%): 	Loss: 3.623749256134033	recon_loss: 0.024096623063087463	bpp_loss: 2.900850534439087	aux_loss: 0.2988889217376709
15:32:53 INFO - main: Train iter. 104700/200000 (52.35%): 	Loss: 3.638556718826294	recon_loss: 0.024201728403568268	bpp_loss: 2.9125049114227295	aux_loss: 0.676172137260437
15:33:11 INFO - main: Train iter. 104800/200000 (52.4%): 	Loss: 3.6471729278564453	recon_loss: 0.02420225366950035	bpp_loss: 2.92110538482666	aux_loss: 0.27881109714508057
15:33:28 INFO - main: Train iter. 104900/200000 (52.45%): 	Loss: 3.6255064010620117	recon_loss: 0.024048468098044395	bpp_loss: 2.904052495956421	aux_loss: 0.5207251310348511
15:33:45 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 3.640511989593506	recon_loss: 0.024221086874604225	bpp_loss: 2.91387939453125	aux_loss: 0.8417882919311523
15:33:55 INFO - main: {'TEST MSE': 0.024146032488496453, 'TEST BPP': 2.954125, 'TEST loss': 3.6294144940376283, 'TEST recon_loss': 0.024146032435819507, 'TEST bpp_loss': 2.9050335199832915}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:34:13 INFO - main: Train iter. 105100/200000 (52.55%): 	Loss: 3.6254982948303223	recon_loss: 0.024087226018309593	bpp_loss: 2.902881383895874	aux_loss: 0.28613564372062683
15:34:30 INFO - main: Train iter. 105200/200000 (52.6%): 	Loss: 3.6287543773651123	recon_loss: 0.024070054292678833	bpp_loss: 2.9066526889801025	aux_loss: 0.39780426025390625
15:34:48 INFO - main: Train iter. 105300/200000 (52.65%): 	Loss: 3.63627552986145	recon_loss: 0.024172872304916382	bpp_loss: 2.9110894203186035	aux_loss: 0.17771920561790466
15:35:05 INFO - main: Train iter. 105400/200000 (52.7%): 	Loss: 3.630810499191284	recon_loss: 0.02410816214978695	bpp_loss: 2.9075655937194824	aux_loss: 0.33171188831329346
15:35:23 INFO - main: Train iter. 105500/200000 (52.75%): 	Loss: 3.6359376907348633	recon_loss: 0.024150654673576355	bpp_loss: 2.9114181995391846	aux_loss: 0.31205910444259644
15:35:41 INFO - main: Train iter. 105600/200000 (52.8%): 	Loss: 3.6333277225494385	recon_loss: 0.02415645681321621	bpp_loss: 2.9086339473724365	aux_loss: 0.37546783685684204
15:35:59 INFO - main: Train iter. 105700/200000 (52.85%): 	Loss: 3.6204442977905273	recon_loss: 0.024023165926337242	bpp_loss: 2.899749279022217	aux_loss: 0.18746991455554962
15:36:16 INFO - main: Train iter. 105800/200000 (52.9%): 	Loss: 3.614839792251587	recon_loss: 0.02405216172337532	bpp_loss: 2.893275022506714	aux_loss: 0.27971363067626953
15:36:34 INFO - main: Train iter. 105900/200000 (52.95%): 	Loss: 3.6523289680480957	recon_loss: 0.024276522919535637	bpp_loss: 2.9240331649780273	aux_loss: 0.5091705918312073
15:36:51 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 3.631927967071533	recon_loss: 0.024135906249284744	bpp_loss: 2.907850742340088	aux_loss: 0.4988608956336975
15:37:09 INFO - main: Train iter. 106100/200000 (53.05%): 	Loss: 3.6217026710510254	recon_loss: 0.02403338812291622	bpp_loss: 2.9007010459899902	aux_loss: 0.442472368478775
15:37:26 INFO - main: Train iter. 106200/200000 (53.1%): 	Loss: 3.6219005584716797	recon_loss: 0.02404889278113842	bpp_loss: 2.9004337787628174	aux_loss: 0.21908783912658691
15:37:44 INFO - main: Train iter. 106300/200000 (53.15%): 	Loss: 3.6220204830169678	recon_loss: 0.024025145918130875	bpp_loss: 2.901266098022461	aux_loss: 0.9654409885406494
15:38:01 INFO - main: Train iter. 106400/200000 (53.2%): 	Loss: 3.6228959560394287	recon_loss: 0.02407952956855297	bpp_loss: 2.90051007270813	aux_loss: 0.18579921126365662
15:38:22 INFO - main: Train iter. 106500/200000 (53.25%): 	Loss: 3.6265530586242676	recon_loss: 0.024128012359142303	bpp_loss: 2.902712821960449	aux_loss: 0.42151564359664917
15:38:39 INFO - main: Train iter. 106600/200000 (53.3%): 	Loss: 3.637763023376465	recon_loss: 0.02413252554833889	bpp_loss: 2.9137871265411377	aux_loss: 0.33392831683158875
15:38:57 INFO - main: Train iter. 106700/200000 (53.35%): 	Loss: 3.623523235321045	recon_loss: 0.024067234247922897	bpp_loss: 2.901506185531616	aux_loss: 0.3895604610443115
15:39:15 INFO - main: Train iter. 106800/200000 (53.4%): 	Loss: 3.6343772411346436	recon_loss: 0.024170231074094772	bpp_loss: 2.9092702865600586	aux_loss: 1.0811529159545898
15:39:32 INFO - main: Train iter. 106900/200000 (53.45%): 	Loss: 3.6291353702545166	recon_loss: 0.024135591462254524	bpp_loss: 2.9050676822662354	aux_loss: 0.3291587233543396
15:39:50 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 3.6379451751708984	recon_loss: 0.02411777712404728	bpp_loss: 2.914411783218384	aux_loss: 0.3296010196208954
15:40:08 INFO - main: Train iter. 107100/200000 (53.55%): 	Loss: 3.6258668899536133	recon_loss: 0.02409280464053154	bpp_loss: 2.903082847595215	aux_loss: 0.40445369482040405
15:40:25 INFO - main: Train iter. 107200/200000 (53.6%): 	Loss: 3.6332550048828125	recon_loss: 0.02413366176187992	bpp_loss: 2.909245014190674	aux_loss: 0.48929697275161743
15:40:43 INFO - main: Train iter. 107300/200000 (53.65%): 	Loss: 3.6390743255615234	recon_loss: 0.02415797859430313	bpp_loss: 2.914335012435913	aux_loss: 0.33314746618270874
15:41:00 INFO - main: Train iter. 107400/200000 (53.7%): 	Loss: 3.6258771419525146	recon_loss: 0.0240978691726923	bpp_loss: 2.9029409885406494	aux_loss: 0.8367087841033936
15:41:18 INFO - main: Train iter. 107500/200000 (53.75%): 	Loss: 3.6248319149017334	recon_loss: 0.024066654965281487	bpp_loss: 2.902832269668579	aux_loss: 0.49478793144226074
15:41:36 INFO - main: Train iter. 107600/200000 (53.8%): 	Loss: 3.6323680877685547	recon_loss: 0.0240847896784544	bpp_loss: 2.9098243713378906	aux_loss: 0.8749760389328003
15:41:53 INFO - main: Train iter. 107700/200000 (53.85%): 	Loss: 3.651628017425537	recon_loss: 0.024201491847634315	bpp_loss: 2.9255831241607666	aux_loss: 0.781941294670105
15:42:11 INFO - main: Train iter. 107800/200000 (53.9%): 	Loss: 3.618110179901123	recon_loss: 0.024027321487665176	bpp_loss: 2.8972904682159424	aux_loss: 1.0791070461273193
15:42:28 INFO - main: Train iter. 107900/200000 (53.95%): 	Loss: 3.6097333431243896	recon_loss: 0.023973001167178154	bpp_loss: 2.890543222427368	aux_loss: 1.0396883487701416
15:42:46 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 3.628484010696411	recon_loss: 0.02407657355070114	bpp_loss: 2.906186819076538	aux_loss: 0.590843915939331
15:43:04 INFO - main: Train iter. 108100/200000 (54.05%): 	Loss: 3.6194941997528076	recon_loss: 0.024093685671687126	bpp_loss: 2.896683692932129	aux_loss: 0.4495018720626831
15:43:21 INFO - main: Train iter. 108200/200000 (54.1%): 	Loss: 3.6397407054901123	recon_loss: 0.024208394810557365	bpp_loss: 2.9134888648986816	aux_loss: 0.32538920640945435
15:43:39 INFO - main: Train iter. 108300/200000 (54.15%): 	Loss: 3.6424598693847656	recon_loss: 0.0242063757032156	bpp_loss: 2.9162685871124268	aux_loss: 0.6584017276763916
15:43:56 INFO - main: Train iter. 108400/200000 (54.2%): 	Loss: 3.6297554969787598	recon_loss: 0.02409655600786209	bpp_loss: 2.9068589210510254	aux_loss: 0.22880733013153076
15:44:14 INFO - main: Train iter. 108500/200000 (54.25%): 	Loss: 3.633023500442505	recon_loss: 0.02411346323788166	bpp_loss: 2.9096195697784424	aux_loss: 0.36343860626220703
15:44:32 INFO - main: Train iter. 108600/200000 (54.3%): 	Loss: 3.6304707527160645	recon_loss: 0.024127135053277016	bpp_loss: 2.9066567420959473	aux_loss: 0.34971076250076294
15:44:49 INFO - main: Train iter. 108700/200000 (54.35%): 	Loss: 3.635404586791992	recon_loss: 0.024168888106942177	bpp_loss: 2.9103379249572754	aux_loss: 0.5684767961502075
15:45:07 INFO - main: Train iter. 108800/200000 (54.4%): 	Loss: 3.6244378089904785	recon_loss: 0.024084949865937233	bpp_loss: 2.9018893241882324	aux_loss: 0.3179677128791809
15:45:25 INFO - main: Train iter. 108900/200000 (54.45%): 	Loss: 3.631995677947998	recon_loss: 0.024127129465341568	bpp_loss: 2.90818190574646	aux_loss: 0.20674747228622437
15:45:42 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 3.6148784160614014	recon_loss: 0.024033179506659508	bpp_loss: 2.893882989883423	aux_loss: 0.18498201668262482
15:46:00 INFO - main: Train iter. 109100/200000 (54.55%): 	Loss: 3.6239023208618164	recon_loss: 0.024090105667710304	bpp_loss: 2.9011991024017334	aux_loss: 0.28225988149642944
15:46:18 INFO - main: Train iter. 109200/200000 (54.6%): 	Loss: 3.631422996520996	recon_loss: 0.02418133057653904	bpp_loss: 2.9059829711914062	aux_loss: 0.6617991924285889
15:46:35 INFO - main: Train iter. 109300/200000 (54.65%): 	Loss: 3.6375808715820312	recon_loss: 0.02420462667942047	bpp_loss: 2.9114420413970947	aux_loss: 0.40877896547317505
15:46:53 INFO - main: Train iter. 109400/200000 (54.7%): 	Loss: 3.62739634513855	recon_loss: 0.024076612666249275	bpp_loss: 2.9050979614257812	aux_loss: 0.444357693195343
15:47:10 INFO - main: Train iter. 109500/200000 (54.75%): 	Loss: 3.6248488426208496	recon_loss: 0.02409171871840954	bpp_loss: 2.902097225189209	aux_loss: 0.35118865966796875
15:47:28 INFO - main: Train iter. 109600/200000 (54.8%): 	Loss: 3.6261725425720215	recon_loss: 0.024073168635368347	bpp_loss: 2.903977632522583	aux_loss: 0.2918270230293274
15:47:45 INFO - main: Train iter. 109700/200000 (54.85%): 	Loss: 3.628265619277954	recon_loss: 0.024152692407369614	bpp_loss: 2.9036848545074463	aux_loss: 0.36905646324157715
15:48:06 INFO - main: Train iter. 109800/200000 (54.9%): 	Loss: 3.6318955421447754	recon_loss: 0.024125931784510612	bpp_loss: 2.9081175327301025	aux_loss: 0.3430807888507843
15:48:23 INFO - main: Train iter. 109900/200000 (54.95%): 	Loss: 3.632793426513672	recon_loss: 0.024136284366250038	bpp_loss: 2.9087047576904297	aux_loss: 0.25432664155960083
15:48:41 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 3.6302521228790283	recon_loss: 0.02415880374610424	bpp_loss: 2.9054880142211914	aux_loss: 0.5326105356216431
15:48:51 INFO - main: {'TEST MSE': 0.024146895554847933, 'TEST BPP': 2.9530625, 'TEST loss': 3.6288376438617704, 'TEST recon_loss': 0.024146895496174693, 'TEST bpp_loss': 2.904430778503418}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:49:09 INFO - main: Train iter. 110100/200000 (55.05%): 	Loss: 3.626039981842041	recon_loss: 0.02407948300242424	bpp_loss: 2.903655529022217	aux_loss: 0.22743582725524902
15:49:26 INFO - main: Train iter. 110200/200000 (55.1%): 	Loss: 3.630882740020752	recon_loss: 0.02411520853638649	bpp_loss: 2.907426595687866	aux_loss: 0.5867258906364441
15:49:44 INFO - main: Train iter. 110300/200000 (55.15%): 	Loss: 3.628157377243042	recon_loss: 0.024097362533211708	bpp_loss: 2.9052364826202393	aux_loss: 0.3466469943523407
15:50:01 INFO - main: Train iter. 110400/200000 (55.2%): 	Loss: 3.627558708190918	recon_loss: 0.024102944880723953	bpp_loss: 2.904470443725586	aux_loss: 0.7634772658348083
15:50:19 INFO - main: Train iter. 110500/200000 (55.25%): 	Loss: 3.635277509689331	recon_loss: 0.024167761206626892	bpp_loss: 2.9102447032928467	aux_loss: 0.272820383310318
15:50:37 INFO - main: Train iter. 110600/200000 (55.3%): 	Loss: 3.617527961730957	recon_loss: 0.024087456986308098	bpp_loss: 2.894904136657715	aux_loss: 0.5440059900283813
15:50:54 INFO - main: Train iter. 110700/200000 (55.35%): 	Loss: 3.6385445594787598	recon_loss: 0.024187268689274788	bpp_loss: 2.912926435470581	aux_loss: 0.17800584435462952
15:51:12 INFO - main: Train iter. 110800/200000 (55.4%): 	Loss: 3.614921808242798	recon_loss: 0.024032076820731163	bpp_loss: 2.8939595222473145	aux_loss: 0.20721536874771118
15:51:30 INFO - main: Train iter. 110900/200000 (55.45%): 	Loss: 3.616499900817871	recon_loss: 0.0240124873816967	bpp_loss: 2.896125316619873	aux_loss: 0.9528980255126953
15:51:47 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 3.6083502769470215	recon_loss: 0.02402605302631855	bpp_loss: 2.887568712234497	aux_loss: 0.33497685194015503
15:52:05 INFO - main: Train iter. 111100/200000 (55.55%): 	Loss: 3.6258625984191895	recon_loss: 0.02405482344329357	bpp_loss: 2.9042179584503174	aux_loss: 0.6685271263122559
15:52:22 INFO - main: Train iter. 111200/200000 (55.6%): 	Loss: 3.6404120922088623	recon_loss: 0.024153057485818863	bpp_loss: 2.915820360183716	aux_loss: 0.2370884120464325
15:52:40 INFO - main: Train iter. 111300/200000 (55.65%): 	Loss: 3.626814603805542	recon_loss: 0.024069808423519135	bpp_loss: 2.9047203063964844	aux_loss: 0.6201455593109131
15:52:58 INFO - main: Train iter. 111400/200000 (55.7%): 	Loss: 3.629246234893799	recon_loss: 0.024108020588755608	bpp_loss: 2.906005620956421	aux_loss: 0.30585986375808716
15:53:15 INFO - main: Train iter. 111500/200000 (55.75%): 	Loss: 3.620295763015747	recon_loss: 0.024093015119433403	bpp_loss: 2.897505283355713	aux_loss: 0.24828669428825378
15:53:33 INFO - main: Train iter. 111600/200000 (55.8%): 	Loss: 3.616511344909668	recon_loss: 0.02407151646912098	bpp_loss: 2.8943657875061035	aux_loss: 0.5394442677497864
15:53:50 INFO - main: Train iter. 111700/200000 (55.85%): 	Loss: 3.6215176582336426	recon_loss: 0.024103296920657158	bpp_loss: 2.898418664932251	aux_loss: 0.5143865346908569
15:54:08 INFO - main: Train iter. 111800/200000 (55.9%): 	Loss: 3.6433193683624268	recon_loss: 0.02416335791349411	bpp_loss: 2.9184186458587646	aux_loss: 0.710426926612854
15:54:26 INFO - main: Train iter. 111900/200000 (55.95%): 	Loss: 3.6553468704223633	recon_loss: 0.02426011487841606	bpp_loss: 2.9275434017181396	aux_loss: 0.25861698389053345
15:54:43 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 3.626269578933716	recon_loss: 0.024115441367030144	bpp_loss: 2.902806282043457	aux_loss: 0.48208868503570557
15:55:01 INFO - main: Train iter. 112100/200000 (56.05%): 	Loss: 3.6270670890808105	recon_loss: 0.024065840989351273	bpp_loss: 2.9050920009613037	aux_loss: 0.2299702912569046
15:55:19 INFO - main: Train iter. 112200/200000 (56.1%): 	Loss: 3.6382241249084473	recon_loss: 0.024199770763516426	bpp_loss: 2.912230968475342	aux_loss: 0.6570656299591064
15:55:36 INFO - main: Train iter. 112300/200000 (56.15%): 	Loss: 3.619041919708252	recon_loss: 0.02404075302183628	bpp_loss: 2.8978192806243896	aux_loss: 0.27828365564346313
15:55:54 INFO - main: Train iter. 112400/200000 (56.2%): 	Loss: 3.6341137886047363	recon_loss: 0.02414269931614399	bpp_loss: 2.9098329544067383	aux_loss: 0.31097790598869324
15:56:12 INFO - main: Train iter. 112500/200000 (56.25%): 	Loss: 3.630817413330078	recon_loss: 0.02414702996611595	bpp_loss: 2.9064064025878906	aux_loss: 0.2566866874694824
15:56:29 INFO - main: Train iter. 112600/200000 (56.3%): 	Loss: 3.6423301696777344	recon_loss: 0.024124503135681152	bpp_loss: 2.9185950756073	aux_loss: 0.8274524807929993
15:56:47 INFO - main: Train iter. 112700/200000 (56.35%): 	Loss: 3.6283202171325684	recon_loss: 0.024069977924227715	bpp_loss: 2.9062209129333496	aux_loss: 0.7405389547348022
15:57:05 INFO - main: Train iter. 112800/200000 (56.4%): 	Loss: 3.610929489135742	recon_loss: 0.02399141900241375	bpp_loss: 2.8911869525909424	aux_loss: 0.5535721778869629
15:57:22 INFO - main: Train iter. 112900/200000 (56.45%): 	Loss: 3.623528480529785	recon_loss: 0.024044429883360863	bpp_loss: 2.902195453643799	aux_loss: 0.3412446975708008
15:57:40 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 3.6415228843688965	recon_loss: 0.02420898526906967	bpp_loss: 2.9152534008026123	aux_loss: 0.22984153032302856
15:57:58 INFO - main: Train iter. 113100/200000 (56.55%): 	Loss: 3.626741409301758	recon_loss: 0.02405332773923874	bpp_loss: 2.905141592025757	aux_loss: 1.140234112739563
15:58:18 INFO - main: Train iter. 113200/200000 (56.6%): 	Loss: 3.6118524074554443	recon_loss: 0.024069296196103096	bpp_loss: 2.8897736072540283	aux_loss: 0.5083693265914917
15:58:36 INFO - main: Train iter. 113300/200000 (56.65%): 	Loss: 3.6383330821990967	recon_loss: 0.02414415031671524	bpp_loss: 2.914008617401123	aux_loss: 0.4049636721611023
15:58:53 INFO - main: Train iter. 113400/200000 (56.7%): 	Loss: 3.621270179748535	recon_loss: 0.024070899933576584	bpp_loss: 2.8991432189941406	aux_loss: 0.40999019145965576
15:59:11 INFO - main: Train iter. 113500/200000 (56.75%): 	Loss: 3.6120808124542236	recon_loss: 0.02399183064699173	bpp_loss: 2.8923258781433105	aux_loss: 0.40803566575050354
15:59:29 INFO - main: Train iter. 113600/200000 (56.8%): 	Loss: 3.6215412616729736	recon_loss: 0.024094436317682266	bpp_loss: 2.8987081050872803	aux_loss: 0.7976593971252441
15:59:46 INFO - main: Train iter. 113700/200000 (56.85%): 	Loss: 3.6298205852508545	recon_loss: 0.02410530112683773	bpp_loss: 2.9066615104675293	aux_loss: 0.19896838068962097
16:00:04 INFO - main: Train iter. 113800/200000 (56.9%): 	Loss: 3.610356569290161	recon_loss: 0.024022679775953293	bpp_loss: 2.889676094055176	aux_loss: 0.26815998554229736
16:00:22 INFO - main: Train iter. 113900/200000 (56.95%): 	Loss: 3.639356851577759	recon_loss: 0.02422020398080349	bpp_loss: 2.912750720977783	aux_loss: 0.22673141956329346
16:00:40 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 3.625269651412964	recon_loss: 0.024076763540506363	bpp_loss: 2.9029667377471924	aux_loss: 0.5796197652816772
16:00:57 INFO - main: Train iter. 114100/200000 (57.05%): 	Loss: 3.6158533096313477	recon_loss: 0.024019896984100342	bpp_loss: 2.895256280899048	aux_loss: 0.35370469093322754
16:01:15 INFO - main: Train iter. 114200/200000 (57.1%): 	Loss: 3.636868715286255	recon_loss: 0.024172494187951088	bpp_loss: 2.911693811416626	aux_loss: 0.24682027101516724
16:01:33 INFO - main: Train iter. 114300/200000 (57.15%): 	Loss: 3.629422903060913	recon_loss: 0.024138571694493294	bpp_loss: 2.9052658081054688	aux_loss: 0.353859007358551
16:01:50 INFO - main: Train iter. 114400/200000 (57.2%): 	Loss: 3.626330852508545	recon_loss: 0.0240962952375412	bpp_loss: 2.903442144393921	aux_loss: 0.2194734513759613
16:02:08 INFO - main: Train iter. 114500/200000 (57.25%): 	Loss: 3.614748239517212	recon_loss: 0.02397051639854908	bpp_loss: 2.895632743835449	aux_loss: 1.0181492567062378
16:02:26 INFO - main: Train iter. 114600/200000 (57.3%): 	Loss: 3.6368279457092285	recon_loss: 0.02416844852268696	bpp_loss: 2.9117746353149414	aux_loss: 0.2924748659133911
16:02:43 INFO - main: Train iter. 114700/200000 (57.35%): 	Loss: 3.629314422607422	recon_loss: 0.024138696491718292	bpp_loss: 2.905153512954712	aux_loss: 0.3047950863838196
16:03:01 INFO - main: Train iter. 114800/200000 (57.4%): 	Loss: 3.6317832469940186	recon_loss: 0.02413998357951641	bpp_loss: 2.907583713531494	aux_loss: 0.7119221687316895
16:03:19 INFO - main: Train iter. 114900/200000 (57.45%): 	Loss: 3.644827127456665	recon_loss: 0.024220893159508705	bpp_loss: 2.9182002544403076	aux_loss: 0.4386136531829834
16:03:36 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 3.6351191997528076	recon_loss: 0.024104366078972816	bpp_loss: 2.9119882583618164	aux_loss: 0.23904235661029816
16:03:46 INFO - main: {'TEST MSE': 0.024090449038564294, 'TEST BPP': 2.9549375, 'TEST loss': 3.628870541334152, 'TEST recon_loss': 0.024090448942035436, 'TEST bpp_loss': 2.9061570732593536}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:04:04 INFO - main: Train iter. 115100/200000 (57.55%): 	Loss: 3.632347583770752	recon_loss: 0.024120859801769257	bpp_loss: 2.908721923828125	aux_loss: 0.20323596894741058
16:04:22 INFO - main: Train iter. 115200/200000 (57.6%): 	Loss: 3.6397197246551514	recon_loss: 0.02412455901503563	bpp_loss: 2.915982961654663	aux_loss: 0.8006396293640137
16:04:40 INFO - main: Train iter. 115300/200000 (57.65%): 	Loss: 3.632230281829834	recon_loss: 0.024126755073666573	bpp_loss: 2.9084277153015137	aux_loss: 0.4240373969078064
16:04:57 INFO - main: Train iter. 115400/200000 (57.7%): 	Loss: 3.6237869262695312	recon_loss: 0.024107882753014565	bpp_loss: 2.900550365447998	aux_loss: 0.6708962917327881
16:05:15 INFO - main: Train iter. 115500/200000 (57.75%): 	Loss: 3.613839864730835	recon_loss: 0.024063078686594963	bpp_loss: 2.8919475078582764	aux_loss: 0.2825096845626831
16:05:33 INFO - main: Train iter. 115600/200000 (57.8%): 	Loss: 3.6403653621673584	recon_loss: 0.0242137648165226	bpp_loss: 2.913952350616455	aux_loss: 0.3548343777656555
16:05:50 INFO - main: Train iter. 115700/200000 (57.85%): 	Loss: 3.6160314083099365	recon_loss: 0.02409709058701992	bpp_loss: 2.8931186199188232	aux_loss: 0.4630435109138489
16:06:08 INFO - main: Train iter. 115800/200000 (57.9%): 	Loss: 3.639751434326172	recon_loss: 0.024172835052013397	bpp_loss: 2.9145665168762207	aux_loss: 0.27510419487953186
16:06:26 INFO - main: Train iter. 115900/200000 (57.95%): 	Loss: 3.636801242828369	recon_loss: 0.024194994941353798	bpp_loss: 2.9109513759613037	aux_loss: 0.43217599391937256
16:06:43 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 3.6269779205322266	recon_loss: 0.024124905467033386	bpp_loss: 2.903230905532837	aux_loss: 0.37462013959884644
16:07:01 INFO - main: Train iter. 116100/200000 (58.05%): 	Loss: 3.6374077796936035	recon_loss: 0.024150853976607323	bpp_loss: 2.912882089614868	aux_loss: 0.7019878029823303
16:07:19 INFO - main: Train iter. 116200/200000 (58.1%): 	Loss: 3.62290358543396	recon_loss: 0.02404639683663845	bpp_loss: 2.9015116691589355	aux_loss: 0.34468379616737366
16:07:37 INFO - main: Train iter. 116300/200000 (58.15%): 	Loss: 3.614501476287842	recon_loss: 0.024023037403821945	bpp_loss: 2.893810272216797	aux_loss: 0.3386062681674957
16:07:54 INFO - main: Train iter. 116400/200000 (58.2%): 	Loss: 3.6300618648529053	recon_loss: 0.024136535823345184	bpp_loss: 2.905965805053711	aux_loss: 0.3636256158351898
16:08:15 INFO - main: Train iter. 116500/200000 (58.25%): 	Loss: 3.628748893737793	recon_loss: 0.024107551202178	bpp_loss: 2.905522346496582	aux_loss: 0.29759517312049866
16:08:32 INFO - main: Train iter. 116600/200000 (58.3%): 	Loss: 3.6460418701171875	recon_loss: 0.02423752099275589	bpp_loss: 2.9189162254333496	aux_loss: 0.5155206918716431
16:08:50 INFO - main: Train iter. 116700/200000 (58.35%): 	Loss: 3.6228365898132324	recon_loss: 0.024005843326449394	bpp_loss: 2.9026613235473633	aux_loss: 1.2960543632507324
16:09:08 INFO - main: Train iter. 116800/200000 (58.4%): 	Loss: 3.6310040950775146	recon_loss: 0.024181606248021126	bpp_loss: 2.9055559635162354	aux_loss: 0.2756645083427429
16:09:26 INFO - main: Train iter. 116900/200000 (58.45%): 	Loss: 3.641080379486084	recon_loss: 0.02416805550456047	bpp_loss: 2.916038751602173	aux_loss: 0.22356151044368744
16:09:43 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 3.6366448402404785	recon_loss: 0.02417588233947754	bpp_loss: 2.9113683700561523	aux_loss: 0.7608901262283325
16:10:01 INFO - main: Train iter. 117100/200000 (58.55%): 	Loss: 3.6401729583740234	recon_loss: 0.024186495691537857	bpp_loss: 2.9145781993865967	aux_loss: 0.4472702145576477
16:10:19 INFO - main: Train iter. 117200/200000 (58.6%): 	Loss: 3.619572162628174	recon_loss: 0.02407662384212017	bpp_loss: 2.897273302078247	aux_loss: 0.8296010494232178
16:10:37 INFO - main: Train iter. 117300/200000 (58.65%): 	Loss: 3.651620388031006	recon_loss: 0.024241404607892036	bpp_loss: 2.9243783950805664	aux_loss: 0.5421628952026367
16:10:54 INFO - main: Train iter. 117400/200000 (58.7%): 	Loss: 3.638305902481079	recon_loss: 0.024179434403777122	bpp_loss: 2.9129228591918945	aux_loss: 0.31448864936828613
16:11:12 INFO - main: Train iter. 117500/200000 (58.75%): 	Loss: 3.6355199813842773	recon_loss: 0.02418232336640358	bpp_loss: 2.910050392150879	aux_loss: 0.18024227023124695
16:11:30 INFO - main: Train iter. 117600/200000 (58.8%): 	Loss: 3.64306640625	recon_loss: 0.024163387715816498	bpp_loss: 2.9181647300720215	aux_loss: 0.5203551054000854
16:11:47 INFO - main: Train iter. 117700/200000 (58.85%): 	Loss: 3.6237473487854004	recon_loss: 0.024072401225566864	bpp_loss: 2.9015753269195557	aux_loss: 0.529302716255188
16:12:05 INFO - main: Train iter. 117800/200000 (58.9%): 	Loss: 3.6113357543945312	recon_loss: 0.02399720810353756	bpp_loss: 2.8914194107055664	aux_loss: 0.5431707501411438
16:12:23 INFO - main: Train iter. 117900/200000 (58.95%): 	Loss: 3.6236884593963623	recon_loss: 0.024103710427880287	bpp_loss: 2.9005770683288574	aux_loss: 0.3115815818309784
16:12:41 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 3.6134042739868164	recon_loss: 0.024049874395132065	bpp_loss: 2.8919079303741455	aux_loss: 0.6202113628387451
16:12:58 INFO - main: Train iter. 118100/200000 (59.05%): 	Loss: 3.6210484504699707	recon_loss: 0.024095797911286354	bpp_loss: 2.898174524307251	aux_loss: 0.803058385848999
16:13:16 INFO - main: Train iter. 118200/200000 (59.1%): 	Loss: 3.632279396057129	recon_loss: 0.024133263155817986	bpp_loss: 2.9082815647125244	aux_loss: 0.3754352927207947
16:13:34 INFO - main: Train iter. 118300/200000 (59.15%): 	Loss: 3.609483480453491	recon_loss: 0.02398102357983589	bpp_loss: 2.8900527954101562	aux_loss: 0.3806637227535248
16:13:51 INFO - main: Train iter. 118400/200000 (59.2%): 	Loss: 3.6259658336639404	recon_loss: 0.024082403630018234	bpp_loss: 2.903493642807007	aux_loss: 0.2153482735157013
16:14:09 INFO - main: Train iter. 118500/200000 (59.25%): 	Loss: 3.6322882175445557	recon_loss: 0.024141667410731316	bpp_loss: 2.9080381393432617	aux_loss: 0.20788569748401642
16:14:27 INFO - main: Train iter. 118600/200000 (59.3%): 	Loss: 3.6320650577545166	recon_loss: 0.024104762822389603	bpp_loss: 2.9089221954345703	aux_loss: 0.47965294122695923
16:14:44 INFO - main: Train iter. 118700/200000 (59.35%): 	Loss: 3.628110408782959	recon_loss: 0.02412905916571617	bpp_loss: 2.904238700866699	aux_loss: 0.24869972467422485
16:15:02 INFO - main: Train iter. 118800/200000 (59.4%): 	Loss: 3.6235599517822266	recon_loss: 0.024082988500595093	bpp_loss: 2.9010703563690186	aux_loss: 0.2807038724422455
16:15:20 INFO - main: Train iter. 118900/200000 (59.45%): 	Loss: 3.630319118499756	recon_loss: 0.024120492860674858	bpp_loss: 2.9067041873931885	aux_loss: 0.20416224002838135
16:15:37 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 3.6395576000213623	recon_loss: 0.02412777580320835	bpp_loss: 2.915724277496338	aux_loss: 0.3774205446243286
16:15:55 INFO - main: Train iter. 119100/200000 (59.55%): 	Loss: 3.633476734161377	recon_loss: 0.024119405075907707	bpp_loss: 2.9098944664001465	aux_loss: 0.47889724373817444
16:16:13 INFO - main: Train iter. 119200/200000 (59.6%): 	Loss: 3.6301984786987305	recon_loss: 0.024079523980617523	bpp_loss: 2.9078128337860107	aux_loss: 0.3076988458633423
16:16:30 INFO - main: Train iter. 119300/200000 (59.65%): 	Loss: 3.6286566257476807	recon_loss: 0.024118119850754738	bpp_loss: 2.9051129817962646	aux_loss: 0.33839619159698486
16:16:48 INFO - main: Train iter. 119400/200000 (59.7%): 	Loss: 3.628044843673706	recon_loss: 0.02413317933678627	bpp_loss: 2.9040493965148926	aux_loss: 0.35204893350601196
16:17:06 INFO - main: Train iter. 119500/200000 (59.75%): 	Loss: 3.625516414642334	recon_loss: 0.024083640426397324	bpp_loss: 2.9030072689056396	aux_loss: 0.3406681716442108
16:17:23 INFO - main: Train iter. 119600/200000 (59.8%): 	Loss: 3.620438575744629	recon_loss: 0.024064941331744194	bpp_loss: 2.8984901905059814	aux_loss: 0.23335006833076477
16:17:41 INFO - main: Train iter. 119700/200000 (59.85%): 	Loss: 3.6233434677124023	recon_loss: 0.02407439425587654	bpp_loss: 2.901111602783203	aux_loss: 0.4284556210041046
16:18:01 INFO - main: Train iter. 119800/200000 (59.9%): 	Loss: 3.636742115020752	recon_loss: 0.024134503677487373	bpp_loss: 2.9127070903778076	aux_loss: 0.265220582485199
16:18:19 INFO - main: Train iter. 119900/200000 (59.95%): 	Loss: 3.647658348083496	recon_loss: 0.024229463189840317	bpp_loss: 2.920774459838867	aux_loss: 0.2938801348209381
16:18:36 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 3.6397287845611572	recon_loss: 0.024142803624272346	bpp_loss: 2.9154446125030518	aux_loss: 0.282010555267334
16:18:46 INFO - main: {'TEST MSE': 0.02409881013951306, 'TEST BPP': 2.9543125, 'TEST loss': 3.6287275607585907, 'TEST recon_loss': 0.02409881007671356, 'TEST bpp_loss': 2.9057632603645325}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:19:04 INFO - main: Train iter. 120100/200000 (60.05%): 	Loss: 3.6342062950134277	recon_loss: 0.02413593791425228	bpp_loss: 2.910128116607666	aux_loss: 0.3381050229072571
16:19:22 INFO - main: Train iter. 120200/200000 (60.1%): 	Loss: 3.6176419258117676	recon_loss: 0.02403024211525917	bpp_loss: 2.8967347145080566	aux_loss: 0.20789293944835663
16:19:39 INFO - main: Train iter. 120300/200000 (60.15%): 	Loss: 3.6505932807922363	recon_loss: 0.02428865060210228	bpp_loss: 2.921933650970459	aux_loss: 0.4103087782859802
16:19:57 INFO - main: Train iter. 120400/200000 (60.2%): 	Loss: 3.6354336738586426	recon_loss: 0.024201778694987297	bpp_loss: 2.9093801975250244	aux_loss: 0.23835182189941406
16:20:14 INFO - main: Train iter. 120500/200000 (60.25%): 	Loss: 3.631131649017334	recon_loss: 0.024113459512591362	bpp_loss: 2.9077279567718506	aux_loss: 0.2572483718395233
16:20:32 INFO - main: Train iter. 120600/200000 (60.3%): 	Loss: 3.6342716217041016	recon_loss: 0.02416607178747654	bpp_loss: 2.9092893600463867	aux_loss: 0.3930795192718506
16:20:50 INFO - main: Train iter. 120700/200000 (60.35%): 	Loss: 3.6216018199920654	recon_loss: 0.024058304727077484	bpp_loss: 2.899852752685547	aux_loss: 0.23686310648918152
16:21:07 INFO - main: Train iter. 120800/200000 (60.4%): 	Loss: 3.6451668739318848	recon_loss: 0.024258268997073174	bpp_loss: 2.9174187183380127	aux_loss: 0.3142397999763489
16:21:25 INFO - main: Train iter. 120900/200000 (60.45%): 	Loss: 3.635265827178955	recon_loss: 0.024148959666490555	bpp_loss: 2.910797119140625	aux_loss: 0.2404261976480484
16:21:42 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 3.6336069107055664	recon_loss: 0.02414112165570259	bpp_loss: 2.9093732833862305	aux_loss: 0.26696324348449707
16:22:00 INFO - main: Train iter. 121100/200000 (60.55%): 	Loss: 3.634514331817627	recon_loss: 0.024167334660887718	bpp_loss: 2.909494400024414	aux_loss: 0.6703552007675171
16:22:18 INFO - main: Train iter. 121200/200000 (60.6%): 	Loss: 3.642218589782715	recon_loss: 0.02418893575668335	bpp_loss: 2.916550636291504	aux_loss: 0.26370617747306824
16:22:35 INFO - main: Train iter. 121300/200000 (60.65%): 	Loss: 3.6253342628479004	recon_loss: 0.024128997698426247	bpp_loss: 2.9014642238616943	aux_loss: 0.5351215600967407
16:22:53 INFO - main: Train iter. 121400/200000 (60.7%): 	Loss: 3.625699281692505	recon_loss: 0.0241023451089859	bpp_loss: 2.9026288986206055	aux_loss: 0.8800785541534424
16:23:11 INFO - main: Train iter. 121500/200000 (60.75%): 	Loss: 3.6431453227996826	recon_loss: 0.02421460673213005	bpp_loss: 2.9167070388793945	aux_loss: 0.2351207286119461
16:23:28 INFO - main: Train iter. 121600/200000 (60.8%): 	Loss: 3.612107992172241	recon_loss: 0.024056177586317062	bpp_loss: 2.8904225826263428	aux_loss: 0.8424391150474548
16:23:46 INFO - main: Train iter. 121700/200000 (60.85%): 	Loss: 3.641329765319824	recon_loss: 0.024232273921370506	bpp_loss: 2.9143614768981934	aux_loss: 1.0320806503295898
16:24:04 INFO - main: Train iter. 121800/200000 (60.9%): 	Loss: 3.6451292037963867	recon_loss: 0.024216726422309875	bpp_loss: 2.9186275005340576	aux_loss: 0.4694540202617645
16:24:21 INFO - main: Train iter. 121900/200000 (60.95%): 	Loss: 3.642531156539917	recon_loss: 0.02419119141995907	bpp_loss: 2.916795492172241	aux_loss: 0.3278239965438843
16:24:39 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 3.616466999053955	recon_loss: 0.024032024666666985	bpp_loss: 2.8955063819885254	aux_loss: 0.639556884765625
16:24:57 INFO - main: Train iter. 122100/200000 (61.05%): 	Loss: 3.6418204307556152	recon_loss: 0.024179140105843544	bpp_loss: 2.9164462089538574	aux_loss: 0.2379389852285385
16:25:14 INFO - main: Train iter. 122200/200000 (61.1%): 	Loss: 3.6334755420684814	recon_loss: 0.02415557950735092	bpp_loss: 2.9088082313537598	aux_loss: 0.25231489539146423
16:25:32 INFO - main: Train iter. 122300/200000 (61.15%): 	Loss: 3.614811420440674	recon_loss: 0.024036873131990433	bpp_loss: 2.893705129623413	aux_loss: 0.5711188912391663
16:25:50 INFO - main: Train iter. 122400/200000 (61.2%): 	Loss: 3.6202473640441895	recon_loss: 0.02403978630900383	bpp_loss: 2.8990538120269775	aux_loss: 0.1689344048500061
16:26:07 INFO - main: Train iter. 122500/200000 (61.25%): 	Loss: 3.6331088542938232	recon_loss: 0.024118727073073387	bpp_loss: 2.9095470905303955	aux_loss: 0.47364485263824463
16:26:25 INFO - main: Train iter. 122600/200000 (61.3%): 	Loss: 3.6377573013305664	recon_loss: 0.024161743000149727	bpp_loss: 2.912904977798462	aux_loss: 0.3829777240753174
16:26:43 INFO - main: Train iter. 122700/200000 (61.35%): 	Loss: 3.6279876232147217	recon_loss: 0.02413826994597912	bpp_loss: 2.903839588165283	aux_loss: 0.43141868710517883
16:27:00 INFO - main: Train iter. 122800/200000 (61.4%): 	Loss: 3.626811981201172	recon_loss: 0.024085721001029015	bpp_loss: 2.904240369796753	aux_loss: 0.5868976712226868
16:27:18 INFO - main: Train iter. 122900/200000 (61.45%): 	Loss: 3.616638660430908	recon_loss: 0.024000143632292747	bpp_loss: 2.896634340286255	aux_loss: 0.24439692497253418
16:27:35 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 3.645885467529297	recon_loss: 0.02421082742512226	bpp_loss: 2.919560670852661	aux_loss: 0.23206929862499237
16:27:56 INFO - main: Train iter. 123100/200000 (61.55%): 	Loss: 3.628439426422119	recon_loss: 0.024119479581713676	bpp_loss: 2.9048550128936768	aux_loss: 0.36635807156562805
16:28:13 INFO - main: Train iter. 123200/200000 (61.6%): 	Loss: 3.630382776260376	recon_loss: 0.02410360984504223	bpp_loss: 2.9072744846343994	aux_loss: 0.4079977869987488
16:28:31 INFO - main: Train iter. 123300/200000 (61.65%): 	Loss: 3.6243391036987305	recon_loss: 0.024037009105086327	bpp_loss: 2.903228759765625	aux_loss: 1.212477445602417
16:28:49 INFO - main: Train iter. 123400/200000 (61.7%): 	Loss: 3.6588940620422363	recon_loss: 0.024259299039840698	bpp_loss: 2.93111515045166	aux_loss: 0.463123083114624
16:29:06 INFO - main: Train iter. 123500/200000 (61.75%): 	Loss: 3.627047300338745	recon_loss: 0.024112779647111893	bpp_loss: 2.9036638736724854	aux_loss: 0.257854163646698
16:29:24 INFO - main: Train iter. 123600/200000 (61.8%): 	Loss: 3.623258113861084	recon_loss: 0.024059152230620384	bpp_loss: 2.9014835357666016	aux_loss: 0.1710861623287201
16:29:42 INFO - main: Train iter. 123700/200000 (61.85%): 	Loss: 3.6243629455566406	recon_loss: 0.02409939654171467	bpp_loss: 2.901381015777588	aux_loss: 0.3339686989784241
16:29:59 INFO - main: Train iter. 123800/200000 (61.9%): 	Loss: 3.6186153888702393	recon_loss: 0.02402634359896183	bpp_loss: 2.897825002670288	aux_loss: 0.5750133991241455
16:30:17 INFO - main: Train iter. 123900/200000 (61.95%): 	Loss: 3.6451733112335205	recon_loss: 0.02425665222108364	bpp_loss: 2.917473793029785	aux_loss: 1.3103208541870117
16:30:34 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 3.6413135528564453	recon_loss: 0.02416694164276123	bpp_loss: 2.9163053035736084	aux_loss: 0.3906630277633667
16:30:52 INFO - main: Train iter. 124100/200000 (62.05%): 	Loss: 3.6376051902770996	recon_loss: 0.024158965796232224	bpp_loss: 2.9128363132476807	aux_loss: 0.9642965793609619
16:31:10 INFO - main: Train iter. 124200/200000 (62.1%): 	Loss: 3.6202754974365234	recon_loss: 0.024108581244945526	bpp_loss: 2.8970181941986084	aux_loss: 0.7038642168045044
16:31:27 INFO - main: Train iter. 124300/200000 (62.15%): 	Loss: 3.634403944015503	recon_loss: 0.02418128401041031	bpp_loss: 2.9089653491973877	aux_loss: 0.355623722076416
16:31:45 INFO - main: Train iter. 124400/200000 (62.2%): 	Loss: 3.6439476013183594	recon_loss: 0.02421361207962036	bpp_loss: 2.917539119720459	aux_loss: 0.8055674433708191
16:32:02 INFO - main: Train iter. 124500/200000 (62.25%): 	Loss: 3.6283249855041504	recon_loss: 0.024113651365041733	bpp_loss: 2.9049153327941895	aux_loss: 0.2587512135505676
16:32:20 INFO - main: Train iter. 124600/200000 (62.3%): 	Loss: 3.6214728355407715	recon_loss: 0.024116933345794678	bpp_loss: 2.8979649543762207	aux_loss: 0.8048143982887268
16:32:38 INFO - main: Train iter. 124700/200000 (62.35%): 	Loss: 3.6219584941864014	recon_loss: 0.02408563159406185	bpp_loss: 2.8993895053863525	aux_loss: 0.17891962826251984
16:32:55 INFO - main: Train iter. 124800/200000 (62.4%): 	Loss: 3.6342039108276367	recon_loss: 0.024105245247483253	bpp_loss: 2.9110465049743652	aux_loss: 0.7969754338264465
16:33:13 INFO - main: Train iter. 124900/200000 (62.45%): 	Loss: 3.6468255519866943	recon_loss: 0.024244124069809914	bpp_loss: 2.919501781463623	aux_loss: 0.5108369588851929
16:33:31 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 3.65045428276062	recon_loss: 0.024191061034798622	bpp_loss: 2.92472243309021	aux_loss: 0.6851044297218323
16:33:40 INFO - main: {'TEST MSE': 0.02410011526264672, 'TEST BPP': 2.95396875, 'TEST loss': 3.6287233040332794, 'TEST recon_loss': 0.02410011515207589, 'TEST bpp_loss': 2.905719848155975}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:33:58 INFO - main: Train iter. 125100/200000 (62.55%): 	Loss: 3.6243743896484375	recon_loss: 0.02408602088689804	bpp_loss: 2.9017937183380127	aux_loss: 0.2339884489774704
16:34:15 INFO - main: Train iter. 125200/200000 (62.6%): 	Loss: 3.617140054702759	recon_loss: 0.024013441056013107	bpp_loss: 2.8967368602752686	aux_loss: 0.5300874710083008
16:34:33 INFO - main: Train iter. 125300/200000 (62.65%): 	Loss: 3.6371140480041504	recon_loss: 0.02416246198117733	bpp_loss: 2.9122402667999268	aux_loss: 0.31296277046203613
16:34:51 INFO - main: Train iter. 125400/200000 (62.7%): 	Loss: 3.6329212188720703	recon_loss: 0.024142643436789513	bpp_loss: 2.908642053604126	aux_loss: 0.3534957766532898
16:35:08 INFO - main: Train iter. 125500/200000 (62.75%): 	Loss: 3.6321706771850586	recon_loss: 0.024174289777874947	bpp_loss: 2.9069418907165527	aux_loss: 0.37330853939056396
16:35:26 INFO - main: Train iter. 125600/200000 (62.8%): 	Loss: 3.616748094558716	recon_loss: 0.024087561294436455	bpp_loss: 2.8941211700439453	aux_loss: 0.43657082319259644
16:35:44 INFO - main: Train iter. 125700/200000 (62.85%): 	Loss: 3.6231725215911865	recon_loss: 0.02404717355966568	bpp_loss: 2.90175724029541	aux_loss: 0.2680967152118683
16:36:01 INFO - main: Train iter. 125800/200000 (62.9%): 	Loss: 3.6270313262939453	recon_loss: 0.02408682368695736	bpp_loss: 2.9044265747070312	aux_loss: 0.2893980145454407
16:36:19 INFO - main: Train iter. 125900/200000 (62.95%): 	Loss: 3.6233763694763184	recon_loss: 0.02411678247153759	bpp_loss: 2.8998730182647705	aux_loss: 0.3443220853805542
16:36:37 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 3.6356441974639893	recon_loss: 0.02417094074189663	bpp_loss: 2.9105160236358643	aux_loss: 0.3212288022041321
16:36:54 INFO - main: Train iter. 126100/200000 (63.05%): 	Loss: 3.6453583240509033	recon_loss: 0.024224111810326576	bpp_loss: 2.9186348915100098	aux_loss: 0.24144427478313446
16:37:12 INFO - main: Train iter. 126200/200000 (63.1%): 	Loss: 3.638242244720459	recon_loss: 0.02414529211819172	bpp_loss: 2.9138834476470947	aux_loss: 0.21304135024547577
16:37:30 INFO - main: Train iter. 126300/200000 (63.15%): 	Loss: 3.63261342048645	recon_loss: 0.02412279322743416	bpp_loss: 2.9089295864105225	aux_loss: 0.23018504679203033
16:37:47 INFO - main: Train iter. 126400/200000 (63.2%): 	Loss: 3.6382081508636475	recon_loss: 0.024096781387925148	bpp_loss: 2.915304660797119	aux_loss: 1.0245355367660522
16:38:08 INFO - main: Train iter. 126500/200000 (63.25%): 	Loss: 3.630411148071289	recon_loss: 0.024139108136296272	bpp_loss: 2.906237840652466	aux_loss: 0.33375778794288635
16:38:25 INFO - main: Train iter. 126600/200000 (63.3%): 	Loss: 3.6042723655700684	recon_loss: 0.023946553468704224	bpp_loss: 2.885875701904297	aux_loss: 0.4742257595062256
16:38:43 INFO - main: Train iter. 126700/200000 (63.35%): 	Loss: 3.626908540725708	recon_loss: 0.024084359407424927	bpp_loss: 2.9043776988983154	aux_loss: 0.6124652028083801
16:39:01 INFO - main: Train iter. 126800/200000 (63.4%): 	Loss: 3.6213183403015137	recon_loss: 0.024025309830904007	bpp_loss: 2.900559186935425	aux_loss: 0.4567919969558716
16:39:18 INFO - main: Train iter. 126900/200000 (63.45%): 	Loss: 3.635728359222412	recon_loss: 0.024166544899344444	bpp_loss: 2.9107320308685303	aux_loss: 0.998104989528656
16:39:36 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 3.628096103668213	recon_loss: 0.024097921326756477	bpp_loss: 2.905158519744873	aux_loss: 0.5384608507156372
16:39:54 INFO - main: Train iter. 127100/200000 (63.55%): 	Loss: 3.6284067630767822	recon_loss: 0.024074984714388847	bpp_loss: 2.9061572551727295	aux_loss: 0.19071002304553986
16:40:11 INFO - main: Train iter. 127200/200000 (63.6%): 	Loss: 3.620262622833252	recon_loss: 0.02406352013349533	bpp_loss: 2.8983569145202637	aux_loss: 0.35761991143226624
16:40:29 INFO - main: Train iter. 127300/200000 (63.65%): 	Loss: 3.6263046264648438	recon_loss: 0.024125782772898674	bpp_loss: 2.902531147003174	aux_loss: 0.27628397941589355
16:40:47 INFO - main: Train iter. 127400/200000 (63.7%): 	Loss: 3.6303982734680176	recon_loss: 0.024106465280056	bpp_loss: 2.9072043895721436	aux_loss: 0.5199092626571655
16:41:04 INFO - main: Train iter. 127500/200000 (63.75%): 	Loss: 3.618165969848633	recon_loss: 0.024036245420575142	bpp_loss: 2.8970787525177	aux_loss: 0.3672807812690735
16:41:22 INFO - main: Train iter. 127600/200000 (63.8%): 	Loss: 3.630187511444092	recon_loss: 0.024123525246977806	bpp_loss: 2.9064817428588867	aux_loss: 0.341966837644577
16:41:40 INFO - main: Train iter. 127700/200000 (63.85%): 	Loss: 3.6224231719970703	recon_loss: 0.024084698408842087	bpp_loss: 2.8998820781707764	aux_loss: 0.20242184400558472
16:41:57 INFO - main: Train iter. 127800/200000 (63.9%): 	Loss: 3.6336357593536377	recon_loss: 0.024097800254821777	bpp_loss: 2.9107017517089844	aux_loss: 0.7561150789260864
16:42:15 INFO - main: Train iter. 127900/200000 (63.95%): 	Loss: 3.6309804916381836	recon_loss: 0.024104900658130646	bpp_loss: 2.9078333377838135	aux_loss: 0.4145580530166626
16:42:33 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 3.629261016845703	recon_loss: 0.024078650400042534	bpp_loss: 2.9069013595581055	aux_loss: 0.7960358262062073
16:42:50 INFO - main: Train iter. 128100/200000 (64.05%): 	Loss: 3.632235527038574	recon_loss: 0.024077925831079483	bpp_loss: 2.909897804260254	aux_loss: 0.3958011567592621
16:43:08 INFO - main: Train iter. 128200/200000 (64.1%): 	Loss: 3.624251127243042	recon_loss: 0.0240484531968832	bpp_loss: 2.9027974605560303	aux_loss: 0.28141939640045166
16:43:26 INFO - main: Train iter. 128300/200000 (64.15%): 	Loss: 3.639674186706543	recon_loss: 0.02413003146648407	bpp_loss: 2.9157731533050537	aux_loss: 0.16651508212089539
16:43:43 INFO - main: Train iter. 128400/200000 (64.2%): 	Loss: 3.6247215270996094	recon_loss: 0.02404661662876606	bpp_loss: 2.90332293510437	aux_loss: 0.5962454080581665
16:44:01 INFO - main: Train iter. 128500/200000 (64.25%): 	Loss: 3.626521587371826	recon_loss: 0.024089070037007332	bpp_loss: 2.9038493633270264	aux_loss: 0.25118488073349
16:44:18 INFO - main: Train iter. 128600/200000 (64.3%): 	Loss: 3.6263372898101807	recon_loss: 0.024149935692548752	bpp_loss: 2.901839256286621	aux_loss: 0.33533620834350586
16:44:36 INFO - main: Train iter. 128700/200000 (64.35%): 	Loss: 3.629378318786621	recon_loss: 0.024116670712828636	bpp_loss: 2.9058783054351807	aux_loss: 0.2939296364784241
16:44:54 INFO - main: Train iter. 128800/200000 (64.4%): 	Loss: 3.6256611347198486	recon_loss: 0.02410062775015831	bpp_loss: 2.902642250061035	aux_loss: 1.124328851699829
16:45:11 INFO - main: Train iter. 128900/200000 (64.45%): 	Loss: 3.6305131912231445	recon_loss: 0.024108586832880974	bpp_loss: 2.9072556495666504	aux_loss: 0.5293925404548645
16:45:29 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 3.6179513931274414	recon_loss: 0.024063603952527046	bpp_loss: 2.896043300628662	aux_loss: 0.39655014872550964
16:45:47 INFO - main: Train iter. 129100/200000 (64.55%): 	Loss: 3.621142625808716	recon_loss: 0.024083388969302177	bpp_loss: 2.8986408710479736	aux_loss: 0.7589287161827087
16:46:04 INFO - main: Train iter. 129200/200000 (64.6%): 	Loss: 3.623135805130005	recon_loss: 0.02407420240342617	bpp_loss: 2.900909662246704	aux_loss: 1.2206153869628906
16:46:22 INFO - main: Train iter. 129300/200000 (64.65%): 	Loss: 3.6364850997924805	recon_loss: 0.024134213104844093	bpp_loss: 2.912458658218384	aux_loss: 0.422432005405426
16:46:40 INFO - main: Train iter. 129400/200000 (64.7%): 	Loss: 3.639535665512085	recon_loss: 0.02420293726027012	bpp_loss: 2.913447618484497	aux_loss: 0.4417140483856201
16:46:57 INFO - main: Train iter. 129500/200000 (64.75%): 	Loss: 3.6226489543914795	recon_loss: 0.02413899078965187	bpp_loss: 2.8984792232513428	aux_loss: 0.4966315031051636
16:47:15 INFO - main: Train iter. 129600/200000 (64.8%): 	Loss: 3.6349692344665527	recon_loss: 0.024124538525938988	bpp_loss: 2.9112329483032227	aux_loss: 0.5911674499511719
16:47:33 INFO - main: Train iter. 129700/200000 (64.85%): 	Loss: 3.627154588699341	recon_loss: 0.02408592589199543	bpp_loss: 2.9045767784118652	aux_loss: 0.3114619851112366
16:47:53 INFO - main: Train iter. 129800/200000 (64.9%): 	Loss: 3.6273224353790283	recon_loss: 0.02412354201078415	bpp_loss: 2.903616189956665	aux_loss: 1.169548511505127
16:48:11 INFO - main: Train iter. 129900/200000 (64.95%): 	Loss: 3.6144113540649414	recon_loss: 0.02399727888405323	bpp_loss: 2.8944931030273438	aux_loss: 0.6147342920303345
16:48:28 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 3.6357829570770264	recon_loss: 0.024174325168132782	bpp_loss: 2.910553216934204	aux_loss: 0.22089342772960663
16:48:38 INFO - main: {'TEST MSE': 0.024139341809235472, 'TEST BPP': 2.953625, 'TEST loss': 3.6292118513584137, 'TEST recon_loss': 0.024139341732487083, 'TEST bpp_loss': 2.9050316059589387}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:48:56 INFO - main: Train iter. 130100/200000 (65.05%): 	Loss: 3.6168301105499268	recon_loss: 0.024042366072535515	bpp_loss: 2.895559072494507	aux_loss: 0.4253649115562439
16:49:13 INFO - main: Train iter. 130200/200000 (65.1%): 	Loss: 3.6148085594177246	recon_loss: 0.024033978581428528	bpp_loss: 2.893789291381836	aux_loss: 0.23230502009391785
16:49:31 INFO - main: Train iter. 130300/200000 (65.15%): 	Loss: 3.6246230602264404	recon_loss: 0.024082792922854424	bpp_loss: 2.902139186859131	aux_loss: 0.6353791952133179
16:49:49 INFO - main: Train iter. 130400/200000 (65.2%): 	Loss: 3.6129519939422607	recon_loss: 0.024035686627030373	bpp_loss: 2.8918814659118652	aux_loss: 0.8986409902572632
16:50:06 INFO - main: Train iter. 130500/200000 (65.25%): 	Loss: 3.630488395690918	recon_loss: 0.02409421280026436	bpp_loss: 2.9076619148254395	aux_loss: 0.32498931884765625
16:50:24 INFO - main: Train iter. 130600/200000 (65.3%): 	Loss: 3.629732608795166	recon_loss: 0.024170156568288803	bpp_loss: 2.904628038406372	aux_loss: 1.187363624572754
16:50:42 INFO - main: Train iter. 130700/200000 (65.35%): 	Loss: 3.62786865234375	recon_loss: 0.024077115580439568	bpp_loss: 2.905555248260498	aux_loss: 0.8209494352340698
16:51:00 INFO - main: Train iter. 130800/200000 (65.4%): 	Loss: 3.6337273120880127	recon_loss: 0.02410810813307762	bpp_loss: 2.9104840755462646	aux_loss: 0.35673561692237854
16:51:17 INFO - main: Train iter. 130900/200000 (65.45%): 	Loss: 3.640328884124756	recon_loss: 0.02414289116859436	bpp_loss: 2.9160420894622803	aux_loss: 0.3405197858810425
16:51:35 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 3.6259512901306152	recon_loss: 0.024109968915581703	bpp_loss: 2.9026522636413574	aux_loss: 0.35050368309020996
16:51:53 INFO - main: Train iter. 131100/200000 (65.55%): 	Loss: 3.6319849491119385	recon_loss: 0.02408732660114765	bpp_loss: 2.909365177154541	aux_loss: 0.5899847149848938
16:52:11 INFO - main: Train iter. 131200/200000 (65.6%): 	Loss: 3.621983528137207	recon_loss: 0.024063440039753914	bpp_loss: 2.9000802040100098	aux_loss: 0.3209317624568939
16:52:28 INFO - main: Train iter. 131300/200000 (65.65%): 	Loss: 3.625133514404297	recon_loss: 0.024052361026406288	bpp_loss: 2.9035627841949463	aux_loss: 0.5491020679473877
16:52:46 INFO - main: Train iter. 131400/200000 (65.7%): 	Loss: 3.623342990875244	recon_loss: 0.02405615709722042	bpp_loss: 2.901658296585083	aux_loss: 0.3657331168651581
16:53:04 INFO - main: Train iter. 131500/200000 (65.75%): 	Loss: 3.615628480911255	recon_loss: 0.02403745800256729	bpp_loss: 2.8945047855377197	aux_loss: 0.30349427461624146
16:53:21 INFO - main: Train iter. 131600/200000 (65.8%): 	Loss: 3.629612445831299	recon_loss: 0.02412436343729496	bpp_loss: 2.905881404876709	aux_loss: 0.3196529150009155
16:53:39 INFO - main: Train iter. 131700/200000 (65.85%): 	Loss: 3.622798442840576	recon_loss: 0.024070696905255318	bpp_loss: 2.9006776809692383	aux_loss: 1.281582236289978
16:53:57 INFO - main: Train iter. 131800/200000 (65.9%): 	Loss: 3.622373104095459	recon_loss: 0.02410351112484932	bpp_loss: 2.8992676734924316	aux_loss: 0.4013948440551758
16:54:15 INFO - main: Train iter. 131900/200000 (65.95%): 	Loss: 3.638054132461548	recon_loss: 0.024178799241781235	bpp_loss: 2.9126901626586914	aux_loss: 0.3006557822227478
16:54:33 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 3.6395554542541504	recon_loss: 0.0241530928760767	bpp_loss: 2.9149627685546875	aux_loss: 0.20847177505493164
16:54:50 INFO - main: Train iter. 132100/200000 (66.05%): 	Loss: 3.6307289600372314	recon_loss: 0.02416938915848732	bpp_loss: 2.9056472778320312	aux_loss: 0.29248130321502686
16:55:08 INFO - main: Train iter. 132200/200000 (66.1%): 	Loss: 3.625441074371338	recon_loss: 0.024109898135066032	bpp_loss: 2.902144193649292	aux_loss: 0.3628956079483032
16:55:26 INFO - main: Train iter. 132300/200000 (66.15%): 	Loss: 3.6186513900756836	recon_loss: 0.02404012158513069	bpp_loss: 2.8974478244781494	aux_loss: 0.7177330255508423
16:55:43 INFO - main: Train iter. 132400/200000 (66.2%): 	Loss: 3.637803792953491	recon_loss: 0.024168135598301888	bpp_loss: 2.912759780883789	aux_loss: 0.17136818170547485
16:56:01 INFO - main: Train iter. 132500/200000 (66.25%): 	Loss: 3.628726005554199	recon_loss: 0.024156609550118446	bpp_loss: 2.9040277004241943	aux_loss: 0.7041426301002502
16:56:19 INFO - main: Train iter. 132600/200000 (66.3%): 	Loss: 3.6168322563171387	recon_loss: 0.024025067687034607	bpp_loss: 2.896080255508423	aux_loss: 0.6636393070220947
16:56:36 INFO - main: Train iter. 132700/200000 (66.35%): 	Loss: 3.6505489349365234	recon_loss: 0.02428087778389454	bpp_loss: 2.9221224784851074	aux_loss: 1.2022507190704346
16:56:54 INFO - main: Train iter. 132800/200000 (66.4%): 	Loss: 3.6315958499908447	recon_loss: 0.024134714156389236	bpp_loss: 2.9075543880462646	aux_loss: 0.33249008655548096
16:57:12 INFO - main: Train iter. 132900/200000 (66.45%): 	Loss: 3.649357557296753	recon_loss: 0.024249766021966934	bpp_loss: 2.9218645095825195	aux_loss: 0.18481934070587158
16:57:30 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 3.6260266304016113	recon_loss: 0.024086426943540573	bpp_loss: 2.9034337997436523	aux_loss: 0.3972938656806946
16:57:50 INFO - main: Train iter. 133100/200000 (66.55%): 	Loss: 3.619983434677124	recon_loss: 0.024092882871627808	bpp_loss: 2.8971970081329346	aux_loss: 0.1714346706867218
16:58:07 INFO - main: Train iter. 133200/200000 (66.6%): 	Loss: 3.6247549057006836	recon_loss: 0.02407749928534031	bpp_loss: 2.9024300575256348	aux_loss: 0.3417484760284424
16:58:25 INFO - main: Train iter. 133300/200000 (66.65%): 	Loss: 3.6142566204071045	recon_loss: 0.024002082645893097	bpp_loss: 2.8941941261291504	aux_loss: 0.3419445753097534
16:58:43 INFO - main: Train iter. 133400/200000 (66.7%): 	Loss: 3.6317331790924072	recon_loss: 0.02413608320057392	bpp_loss: 2.9076507091522217	aux_loss: 0.9478693008422852
16:59:00 INFO - main: Train iter. 133500/200000 (66.75%): 	Loss: 3.6343750953674316	recon_loss: 0.024143222719430923	bpp_loss: 2.910078525543213	aux_loss: 0.7379084825515747
16:59:18 INFO - main: Train iter. 133600/200000 (66.8%): 	Loss: 3.6305747032165527	recon_loss: 0.024107754230499268	bpp_loss: 2.907341957092285	aux_loss: 0.3529389798641205
16:59:36 INFO - main: Train iter. 133700/200000 (66.85%): 	Loss: 3.6337332725524902	recon_loss: 0.024140754714608192	bpp_loss: 2.909510612487793	aux_loss: 0.6964824795722961
16:59:53 INFO - main: Train iter. 133800/200000 (66.9%): 	Loss: 3.6218433380126953	recon_loss: 0.024071451276540756	bpp_loss: 2.8996999263763428	aux_loss: 0.5427213311195374
17:00:11 INFO - main: Train iter. 133900/200000 (66.95%): 	Loss: 3.62616229057312	recon_loss: 0.024102598428726196	bpp_loss: 2.9030842781066895	aux_loss: 0.3231644034385681
17:00:29 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 3.629030227661133	recon_loss: 0.024086257442831993	bpp_loss: 2.906442403793335	aux_loss: 0.4364221692085266
17:00:46 INFO - main: Train iter. 134100/200000 (67.05%): 	Loss: 3.6203601360321045	recon_loss: 0.024091241881251335	bpp_loss: 2.89762282371521	aux_loss: 0.6200841665267944
17:01:04 INFO - main: Train iter. 134200/200000 (67.1%): 	Loss: 3.635939836502075	recon_loss: 0.02413720078766346	bpp_loss: 2.9118237495422363	aux_loss: 0.25018399953842163
17:01:22 INFO - main: Train iter. 134300/200000 (67.15%): 	Loss: 3.6153664588928223	recon_loss: 0.02406696043908596	bpp_loss: 2.893357753753662	aux_loss: 0.8314536809921265
17:01:39 INFO - main: Train iter. 134400/200000 (67.2%): 	Loss: 3.6224608421325684	recon_loss: 0.024081602692604065	bpp_loss: 2.900012731552124	aux_loss: 0.4332275092601776
17:01:57 INFO - main: Train iter. 134500/200000 (67.25%): 	Loss: 3.643521308898926	recon_loss: 0.024206314235925674	bpp_loss: 2.9173319339752197	aux_loss: 0.2929210662841797
17:02:15 INFO - main: Train iter. 134600/200000 (67.3%): 	Loss: 3.62282657623291	recon_loss: 0.02410072274506092	bpp_loss: 2.8998048305511475	aux_loss: 0.33253830671310425
17:02:32 INFO - main: Train iter. 134700/200000 (67.35%): 	Loss: 3.625600576400757	recon_loss: 0.0240247193723917	bpp_loss: 2.9048590660095215	aux_loss: 0.8118923902511597
17:02:50 INFO - main: Train iter. 134800/200000 (67.4%): 	Loss: 3.6276533603668213	recon_loss: 0.02409527264535427	bpp_loss: 2.9047951698303223	aux_loss: 0.25306665897369385
17:03:07 INFO - main: Train iter. 134900/200000 (67.45%): 	Loss: 3.6221890449523926	recon_loss: 0.024039454758167267	bpp_loss: 2.901005268096924	aux_loss: 0.7507501840591431
17:03:25 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 3.6317780017852783	recon_loss: 0.0241070743650198	bpp_loss: 2.9085657596588135	aux_loss: 0.16411739587783813
17:03:35 INFO - main: {'TEST MSE': 0.024112765395200558, 'TEST BPP': 2.953625, 'TEST loss': 3.6284938592910767, 'TEST recon_loss': 0.024112765312194823, 'TEST bpp_loss': 2.9051109035015106}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:03:52 INFO - main: Train iter. 135100/200000 (67.55%): 	Loss: 3.6078968048095703	recon_loss: 0.02400565892457962	bpp_loss: 2.8877270221710205	aux_loss: 0.6081812977790833
17:04:10 INFO - main: Train iter. 135200/200000 (67.6%): 	Loss: 3.612546443939209	recon_loss: 0.024015016853809357	bpp_loss: 2.8920960426330566	aux_loss: 0.6162909269332886
17:04:27 INFO - main: Train iter. 135300/200000 (67.65%): 	Loss: 3.633085250854492	recon_loss: 0.02412964403629303	bpp_loss: 2.909195899963379	aux_loss: 0.25611257553100586
17:04:45 INFO - main: Train iter. 135400/200000 (67.7%): 	Loss: 3.6421680450439453	recon_loss: 0.024217020720243454	bpp_loss: 2.9156575202941895	aux_loss: 0.3323725163936615
17:05:02 INFO - main: Train iter. 135500/200000 (67.75%): 	Loss: 3.6199002265930176	recon_loss: 0.024049658328294754	bpp_loss: 2.8984105587005615	aux_loss: 0.32525837421417236
17:05:20 INFO - main: Train iter. 135600/200000 (67.8%): 	Loss: 3.6308655738830566	recon_loss: 0.02415454015135765	bpp_loss: 2.9062294960021973	aux_loss: 0.37595850229263306
17:05:38 INFO - main: Train iter. 135700/200000 (67.85%): 	Loss: 3.612020254135132	recon_loss: 0.02398558333516121	bpp_loss: 2.8924527168273926	aux_loss: 0.24293532967567444
17:05:55 INFO - main: Train iter. 135800/200000 (67.9%): 	Loss: 3.6181626319885254	recon_loss: 0.024049777537584305	bpp_loss: 2.896669387817383	aux_loss: 0.43741413950920105
17:06:13 INFO - main: Train iter. 135900/200000 (67.95%): 	Loss: 3.639796495437622	recon_loss: 0.024162350222468376	bpp_loss: 2.914926052093506	aux_loss: 0.26815065741539
17:06:30 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 3.62037992477417	recon_loss: 0.024042826145887375	bpp_loss: 2.899095058441162	aux_loss: 0.3251138925552368
17:06:48 INFO - main: Train iter. 136100/200000 (68.05%): 	Loss: 3.6286239624023438	recon_loss: 0.02407713048160076	bpp_loss: 2.9063100814819336	aux_loss: 0.7888400554656982
17:07:06 INFO - main: Train iter. 136200/200000 (68.1%): 	Loss: 3.632805347442627	recon_loss: 0.024111432954669	bpp_loss: 2.9094622135162354	aux_loss: 0.4248436689376831
17:07:23 INFO - main: Train iter. 136300/200000 (68.15%): 	Loss: 3.6382124423980713	recon_loss: 0.02420409396290779	bpp_loss: 2.9120895862579346	aux_loss: 0.5573805570602417
17:07:41 INFO - main: Train iter. 136400/200000 (68.2%): 	Loss: 3.6193504333496094	recon_loss: 0.02407551184296608	bpp_loss: 2.897084951400757	aux_loss: 0.2527943253517151
17:08:01 INFO - main: Train iter. 136500/200000 (68.25%): 	Loss: 3.6352624893188477	recon_loss: 0.0241084024310112	bpp_loss: 2.912010431289673	aux_loss: 0.2119830995798111
17:08:19 INFO - main: Train iter. 136600/200000 (68.3%): 	Loss: 3.6164801120758057	recon_loss: 0.02403721585869789	bpp_loss: 2.8953635692596436	aux_loss: 0.488938570022583
17:08:37 INFO - main: Train iter. 136700/200000 (68.35%): 	Loss: 3.6088757514953613	recon_loss: 0.023989534005522728	bpp_loss: 2.8891897201538086	aux_loss: 0.25105470418930054
17:08:54 INFO - main: Train iter. 136800/200000 (68.4%): 	Loss: 3.6228296756744385	recon_loss: 0.02406255155801773	bpp_loss: 2.9009530544281006	aux_loss: 0.5023927688598633
17:09:12 INFO - main: Train iter. 136900/200000 (68.45%): 	Loss: 3.62144136428833	recon_loss: 0.024069160223007202	bpp_loss: 2.899366617202759	aux_loss: 0.3600406050682068
17:09:30 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 3.6374430656433105	recon_loss: 0.024156395345926285	bpp_loss: 2.9127511978149414	aux_loss: 0.6484451293945312
17:09:47 INFO - main: Train iter. 137100/200000 (68.55%): 	Loss: 3.628268003463745	recon_loss: 0.02410048432648182	bpp_loss: 2.9052534103393555	aux_loss: 0.9653688073158264
17:10:05 INFO - main: Train iter. 137200/200000 (68.6%): 	Loss: 3.635141611099243	recon_loss: 0.024155639111995697	bpp_loss: 2.9104723930358887	aux_loss: 0.7770116925239563
17:10:23 INFO - main: Train iter. 137300/200000 (68.65%): 	Loss: 3.6340255737304688	recon_loss: 0.024145489558577538	bpp_loss: 2.909660816192627	aux_loss: 0.26133036613464355
17:10:40 INFO - main: Train iter. 137400/200000 (68.7%): 	Loss: 3.6323952674865723	recon_loss: 0.02414926327764988	bpp_loss: 2.9079172611236572	aux_loss: 0.1931300163269043
17:10:58 INFO - main: Train iter. 137500/200000 (68.75%): 	Loss: 3.6324002742767334	recon_loss: 0.02410190738737583	bpp_loss: 2.9093430042266846	aux_loss: 0.29354697465896606
17:11:15 INFO - main: Train iter. 137600/200000 (68.8%): 	Loss: 3.6421937942504883	recon_loss: 0.024116791784763336	bpp_loss: 2.9186899662017822	aux_loss: 1.1472394466400146
17:11:33 INFO - main: Train iter. 137700/200000 (68.85%): 	Loss: 3.626573324203491	recon_loss: 0.024102885276079178	bpp_loss: 2.903486728668213	aux_loss: 0.5209193229675293
17:11:51 INFO - main: Train iter. 137800/200000 (68.9%): 	Loss: 3.6352076530456543	recon_loss: 0.024183372035622597	bpp_loss: 2.9097063541412354	aux_loss: 0.29232048988342285
17:12:08 INFO - main: Train iter. 137900/200000 (68.95%): 	Loss: 3.623760223388672	recon_loss: 0.02413037233054638	bpp_loss: 2.8998489379882812	aux_loss: 0.2333233803510666
17:12:26 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 3.6468145847320557	recon_loss: 0.024243274703621864	bpp_loss: 2.9195163249969482	aux_loss: 0.278511106967926
17:12:44 INFO - main: Train iter. 138100/200000 (69.05%): 	Loss: 3.6372790336608887	recon_loss: 0.024155478924512863	bpp_loss: 2.912614583969116	aux_loss: 0.19421043992042542
17:13:01 INFO - main: Train iter. 138200/200000 (69.1%): 	Loss: 3.6253762245178223	recon_loss: 0.02407282032072544	bpp_loss: 2.903191566467285	aux_loss: 0.22325068712234497
17:13:19 INFO - main: Train iter. 138300/200000 (69.15%): 	Loss: 3.6238880157470703	recon_loss: 0.02407991513609886	bpp_loss: 2.9014904499053955	aux_loss: 0.21085865795612335
17:13:37 INFO - main: Train iter. 138400/200000 (69.2%): 	Loss: 3.6252713203430176	recon_loss: 0.024098757654428482	bpp_loss: 2.902308702468872	aux_loss: 0.28874117136001587
17:13:54 INFO - main: Train iter. 138500/200000 (69.25%): 	Loss: 3.6246159076690674	recon_loss: 0.024099119007587433	bpp_loss: 2.901642322540283	aux_loss: 0.2081793248653412
17:14:12 INFO - main: Train iter. 138600/200000 (69.3%): 	Loss: 3.6351478099823	recon_loss: 0.024147428572177887	bpp_loss: 2.9107248783111572	aux_loss: 0.2276555746793747
17:14:30 INFO - main: Train iter. 138700/200000 (69.35%): 	Loss: 3.633150815963745	recon_loss: 0.024171527475118637	bpp_loss: 2.9080049991607666	aux_loss: 0.7338482141494751
17:14:47 INFO - main: Train iter. 138800/200000 (69.4%): 	Loss: 3.6240761280059814	recon_loss: 0.024079376831650734	bpp_loss: 2.9016947746276855	aux_loss: 0.36650389432907104
17:15:05 INFO - main: Train iter. 138900/200000 (69.45%): 	Loss: 3.6369950771331787	recon_loss: 0.024139173328876495	bpp_loss: 2.9128198623657227	aux_loss: 0.2721793055534363
17:15:23 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 3.6237635612487793	recon_loss: 0.024076921865344048	bpp_loss: 2.901455879211426	aux_loss: 0.3166320025920868
17:15:40 INFO - main: Train iter. 139100/200000 (69.55%): 	Loss: 3.6243197917938232	recon_loss: 0.02410161681473255	bpp_loss: 2.901271343231201	aux_loss: 0.6256387233734131
17:15:58 INFO - main: Train iter. 139200/200000 (69.6%): 	Loss: 3.618563652038574	recon_loss: 0.024073444306850433	bpp_loss: 2.896360397338867	aux_loss: 0.5260453224182129
17:16:16 INFO - main: Train iter. 139300/200000 (69.65%): 	Loss: 3.6420295238494873	recon_loss: 0.02415757067501545	bpp_loss: 2.917302370071411	aux_loss: 0.7116318941116333
17:16:33 INFO - main: Train iter. 139400/200000 (69.7%): 	Loss: 3.6112029552459717	recon_loss: 0.024042179808020592	bpp_loss: 2.88993763923645	aux_loss: 0.594940185546875
17:16:51 INFO - main: Train iter. 139500/200000 (69.75%): 	Loss: 3.6289141178131104	recon_loss: 0.024086713790893555	bpp_loss: 2.9063127040863037	aux_loss: 0.6300510168075562
17:17:09 INFO - main: Train iter. 139600/200000 (69.8%): 	Loss: 3.618448257446289	recon_loss: 0.02403569594025612	bpp_loss: 2.8973774909973145	aux_loss: 0.5389028191566467
17:17:26 INFO - main: Train iter. 139700/200000 (69.85%): 	Loss: 3.634838104248047	recon_loss: 0.024120554327964783	bpp_loss: 2.911221504211426	aux_loss: 0.3018667697906494
17:17:47 INFO - main: Train iter. 139800/200000 (69.9%): 	Loss: 3.6305782794952393	recon_loss: 0.024079587310552597	bpp_loss: 2.9081907272338867	aux_loss: 0.30976149439811707
17:18:04 INFO - main: Train iter. 139900/200000 (69.95%): 	Loss: 3.6280970573425293	recon_loss: 0.024108707904815674	bpp_loss: 2.9048357009887695	aux_loss: 0.252124160528183
17:18:22 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 3.6355433464050293	recon_loss: 0.024132484570145607	bpp_loss: 2.9115688800811768	aux_loss: 0.4855574369430542
17:18:32 INFO - main: {'TEST MSE': 0.02409134486907604, 'TEST BPP': 2.95384375, 'TEST loss': 3.6281382937431337, 'TEST recon_loss': 0.024091344755142928, 'TEST bpp_loss': 2.9053979525566103}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:18:49 INFO - main: Train iter. 140100/200000 (70.05%): 	Loss: 3.6253538131713867	recon_loss: 0.02407952956855297	bpp_loss: 2.902967929840088	aux_loss: 0.503940761089325
17:19:07 INFO - main: Train iter. 140200/200000 (70.1%): 	Loss: 3.623847007751465	recon_loss: 0.02408026158809662	bpp_loss: 2.9014391899108887	aux_loss: 0.2669529914855957
17:19:25 INFO - main: Train iter. 140300/200000 (70.15%): 	Loss: 3.6275010108947754	recon_loss: 0.024146059527993202	bpp_loss: 2.9031190872192383	aux_loss: 0.4841650426387787
17:19:42 INFO - main: Train iter. 140400/200000 (70.2%): 	Loss: 3.615037679672241	recon_loss: 0.024069739505648613	bpp_loss: 2.8929455280303955	aux_loss: 0.613311767578125
17:20:00 INFO - main: Train iter. 140500/200000 (70.25%): 	Loss: 3.6075191497802734	recon_loss: 0.023964226245880127	bpp_loss: 2.88859224319458	aux_loss: 0.45520514249801636
17:20:18 INFO - main: Train iter. 140600/200000 (70.3%): 	Loss: 3.6291909217834473	recon_loss: 0.02412628009915352	bpp_loss: 2.905402660369873	aux_loss: 0.2220589518547058
17:20:35 INFO - main: Train iter. 140700/200000 (70.35%): 	Loss: 3.6273114681243896	recon_loss: 0.024059638381004333	bpp_loss: 2.905522346496582	aux_loss: 0.3279764652252197
17:20:53 INFO - main: Train iter. 140800/200000 (70.4%): 	Loss: 3.625232696533203	recon_loss: 0.024099430069327354	bpp_loss: 2.902249813079834	aux_loss: 0.261347234249115
17:21:11 INFO - main: Train iter. 140900/200000 (70.45%): 	Loss: 3.6413462162017822	recon_loss: 0.024237126111984253	bpp_loss: 2.9142324924468994	aux_loss: 0.9666618704795837
17:21:28 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 3.6095941066741943	recon_loss: 0.024046534672379494	bpp_loss: 2.888198137283325	aux_loss: 0.4088243842124939
17:21:46 INFO - main: Train iter. 141100/200000 (70.55%): 	Loss: 3.6265203952789307	recon_loss: 0.02405734732747078	bpp_loss: 2.9047999382019043	aux_loss: 0.27412378787994385
17:22:03 INFO - main: Train iter. 141200/200000 (70.6%): 	Loss: 3.621459722518921	recon_loss: 0.02406456507742405	bpp_loss: 2.8995227813720703	aux_loss: 0.38440409302711487
17:22:21 INFO - main: Train iter. 141300/200000 (70.65%): 	Loss: 3.629210948944092	recon_loss: 0.024063678458333015	bpp_loss: 2.9073007106781006	aux_loss: 0.6400899887084961
17:22:39 INFO - main: Train iter. 141400/200000 (70.7%): 	Loss: 3.629607915878296	recon_loss: 0.024107685312628746	bpp_loss: 2.9063773155212402	aux_loss: 0.23771747946739197
17:22:56 INFO - main: Train iter. 141500/200000 (70.75%): 	Loss: 3.6192026138305664	recon_loss: 0.02405538782477379	bpp_loss: 2.897541046142578	aux_loss: 0.16705122590065002
17:23:14 INFO - main: Train iter. 141600/200000 (70.8%): 	Loss: 3.6230363845825195	recon_loss: 0.024102721363306046	bpp_loss: 2.8999547958374023	aux_loss: 0.37090861797332764
17:23:32 INFO - main: Train iter. 141700/200000 (70.85%): 	Loss: 3.6185505390167236	recon_loss: 0.024042503908276558	bpp_loss: 2.897275447845459	aux_loss: 0.24267202615737915
17:23:49 INFO - main: Train iter. 141800/200000 (70.9%): 	Loss: 3.6321513652801514	recon_loss: 0.024119935929775238	bpp_loss: 2.9085533618927	aux_loss: 0.2989268898963928
17:24:07 INFO - main: Train iter. 141900/200000 (70.95%): 	Loss: 3.620710849761963	recon_loss: 0.02403157204389572	bpp_loss: 2.899763584136963	aux_loss: 0.6015097498893738
17:24:25 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 3.61734938621521	recon_loss: 0.024035772308707237	bpp_loss: 2.8962762355804443	aux_loss: 0.1918485462665558
17:24:42 INFO - main: Train iter. 142100/200000 (71.05%): 	Loss: 3.633746385574341	recon_loss: 0.02413535863161087	bpp_loss: 2.9096856117248535	aux_loss: 0.19827334582805634
17:25:00 INFO - main: Train iter. 142200/200000 (71.1%): 	Loss: 3.6440374851226807	recon_loss: 0.024198317900300026	bpp_loss: 2.918087959289551	aux_loss: 0.23495402932167053
17:25:18 INFO - main: Train iter. 142300/200000 (71.15%): 	Loss: 3.6347317695617676	recon_loss: 0.024132153019309044	bpp_loss: 2.910767078399658	aux_loss: 0.2714921236038208
17:25:35 INFO - main: Train iter. 142400/200000 (71.2%): 	Loss: 3.6187961101531982	recon_loss: 0.024046173319220543	bpp_loss: 2.8974108695983887	aux_loss: 0.25013089179992676
17:25:53 INFO - main: Train iter. 142500/200000 (71.25%): 	Loss: 3.6503686904907227	recon_loss: 0.024223286658525467	bpp_loss: 2.9236700534820557	aux_loss: 0.5054023265838623
17:26:11 INFO - main: Train iter. 142600/200000 (71.3%): 	Loss: 3.6294498443603516	recon_loss: 0.024100076407194138	bpp_loss: 2.906447649002075	aux_loss: 0.6954277157783508
17:26:28 INFO - main: Train iter. 142700/200000 (71.35%): 	Loss: 3.6314921379089355	recon_loss: 0.024135688319802284	bpp_loss: 2.907421350479126	aux_loss: 0.28274524211883545
17:26:46 INFO - main: Train iter. 142800/200000 (71.4%): 	Loss: 3.623762607574463	recon_loss: 0.024046462029218674	bpp_loss: 2.9023687839508057	aux_loss: 0.38527655601501465
17:27:03 INFO - main: Train iter. 142900/200000 (71.45%): 	Loss: 3.6276865005493164	recon_loss: 0.024069160223007202	bpp_loss: 2.905611753463745	aux_loss: 0.7236877083778381
17:27:21 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 3.604879856109619	recon_loss: 0.023983437567949295	bpp_loss: 2.8853766918182373	aux_loss: 0.16793829202651978
17:27:41 INFO - main: Train iter. 143100/200000 (71.55%): 	Loss: 3.6388440132141113	recon_loss: 0.024156956002116203	bpp_loss: 2.914135217666626	aux_loss: 0.43008431792259216
17:27:59 INFO - main: Train iter. 143200/200000 (71.6%): 	Loss: 3.6227500438690186	recon_loss: 0.024049043655395508	bpp_loss: 2.9012787342071533	aux_loss: 0.267742395401001
17:28:17 INFO - main: Train iter. 143300/200000 (71.65%): 	Loss: 3.6335904598236084	recon_loss: 0.024102188646793365	bpp_loss: 2.910524845123291	aux_loss: 0.14511817693710327
17:28:35 INFO - main: Train iter. 143400/200000 (71.7%): 	Loss: 3.644240140914917	recon_loss: 0.02417522482573986	bpp_loss: 2.9189834594726562	aux_loss: 0.2505899667739868
17:28:52 INFO - main: Train iter. 143500/200000 (71.75%): 	Loss: 3.6360621452331543	recon_loss: 0.024122348055243492	bpp_loss: 2.9123916625976562	aux_loss: 0.27143532037734985
17:29:10 INFO - main: Train iter. 143600/200000 (71.8%): 	Loss: 3.6257483959198	recon_loss: 0.02406599558889866	bpp_loss: 2.903768539428711	aux_loss: 0.27590495347976685
17:29:28 INFO - main: Train iter. 143700/200000 (71.85%): 	Loss: 3.6261982917785645	recon_loss: 0.02407047525048256	bpp_loss: 2.9040839672088623	aux_loss: 0.20645935833454132
17:29:45 INFO - main: Train iter. 143800/200000 (71.9%): 	Loss: 3.629586935043335	recon_loss: 0.024147529155015945	bpp_loss: 2.905161142349243	aux_loss: 0.20571881532669067
17:30:03 INFO - main: Train iter. 143900/200000 (71.95%): 	Loss: 3.6316022872924805	recon_loss: 0.024087753146886826	bpp_loss: 2.9089696407318115	aux_loss: 0.25041893124580383
17:30:21 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 3.624305486679077	recon_loss: 0.024075975641608238	bpp_loss: 2.9020261764526367	aux_loss: 0.3801212012767792
17:30:38 INFO - main: Train iter. 144100/200000 (72.05%): 	Loss: 3.6174087524414062	recon_loss: 0.024049576371908188	bpp_loss: 2.895921468734741	aux_loss: 0.2426653653383255
17:30:56 INFO - main: Train iter. 144200/200000 (72.1%): 	Loss: 3.6295511722564697	recon_loss: 0.024118520319461823	bpp_loss: 2.9059956073760986	aux_loss: 0.24063146114349365
17:31:13 INFO - main: Train iter. 144300/200000 (72.15%): 	Loss: 3.628753662109375	recon_loss: 0.02412552945315838	bpp_loss: 2.9049878120422363	aux_loss: 0.6445524096488953
17:31:31 INFO - main: Train iter. 144400/200000 (72.2%): 	Loss: 3.6264853477478027	recon_loss: 0.024071015417575836	bpp_loss: 2.9043548107147217	aux_loss: 0.3677211403846741
17:31:49 INFO - main: Train iter. 144500/200000 (72.25%): 	Loss: 3.6354074478149414	recon_loss: 0.024173090234398842	bpp_loss: 2.91021466255188	aux_loss: 0.8694956302642822
17:32:06 INFO - main: Train iter. 144600/200000 (72.3%): 	Loss: 3.621439218521118	recon_loss: 0.024027571082115173	bpp_loss: 2.9006121158599854	aux_loss: 0.7252668142318726
17:32:24 INFO - main: Train iter. 144700/200000 (72.35%): 	Loss: 3.613736152648926	recon_loss: 0.023982223123311996	bpp_loss: 2.8942694664001465	aux_loss: 0.47708114981651306
17:32:42 INFO - main: Train iter. 144800/200000 (72.4%): 	Loss: 3.621140956878662	recon_loss: 0.024060962721705437	bpp_loss: 2.8993120193481445	aux_loss: 1.0171680450439453
17:32:59 INFO - main: Train iter. 144900/200000 (72.45%): 	Loss: 3.6312265396118164	recon_loss: 0.024068651720881462	bpp_loss: 2.9091670513153076	aux_loss: 1.0105412006378174
17:33:17 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 3.626991033554077	recon_loss: 0.024077584967017174	bpp_loss: 2.904663562774658	aux_loss: 0.36931732296943665
17:33:26 INFO - main: {'TEST MSE': 0.02411748223440637, 'TEST BPP': 2.953125, 'TEST loss': 3.6283269729614256, 'TEST recon_loss': 0.024117482163012027, 'TEST bpp_loss': 2.90480250787735}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:33:44 INFO - main: Train iter. 145100/200000 (72.55%): 	Loss: 3.6307480335235596	recon_loss: 0.024148518219590187	bpp_loss: 2.90629243850708	aux_loss: 0.23986630141735077
17:34:02 INFO - main: Train iter. 145200/200000 (72.6%): 	Loss: 3.625291585922241	recon_loss: 0.02404003031551838	bpp_loss: 2.904090642929077	aux_loss: 0.4516701400279999
17:34:19 INFO - main: Train iter. 145300/200000 (72.65%): 	Loss: 3.630571126937866	recon_loss: 0.02416425570845604	bpp_loss: 2.9056434631347656	aux_loss: 0.24664261937141418
17:34:37 INFO - main: Train iter. 145400/200000 (72.7%): 	Loss: 3.623237133026123	recon_loss: 0.02409391663968563	bpp_loss: 2.9004197120666504	aux_loss: 0.3049386441707611
17:34:54 INFO - main: Train iter. 145500/200000 (72.75%): 	Loss: 3.6192286014556885	recon_loss: 0.024026211351156235	bpp_loss: 2.898442268371582	aux_loss: 0.43632251024246216
17:35:12 INFO - main: Train iter. 145600/200000 (72.8%): 	Loss: 3.614769458770752	recon_loss: 0.024028049781918526	bpp_loss: 2.893928050994873	aux_loss: 0.2357633113861084
17:35:29 INFO - main: Train iter. 145700/200000 (72.85%): 	Loss: 3.6038475036621094	recon_loss: 0.023971283808350563	bpp_loss: 2.884708881378174	aux_loss: 0.45169147849082947
17:35:47 INFO - main: Train iter. 145800/200000 (72.9%): 	Loss: 3.632042407989502	recon_loss: 0.02410515956580639	bpp_loss: 2.9088876247406006	aux_loss: 0.19498597085475922
17:36:05 INFO - main: Train iter. 145900/200000 (72.95%): 	Loss: 3.6339845657348633	recon_loss: 0.02414451539516449	bpp_loss: 2.909649133682251	aux_loss: 0.23237204551696777
17:36:22 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 3.6360023021698	recon_loss: 0.024194687604904175	bpp_loss: 2.9101617336273193	aux_loss: 0.5295881032943726
17:36:40 INFO - main: Train iter. 146100/200000 (73.05%): 	Loss: 3.6357176303863525	recon_loss: 0.024167513474822044	bpp_loss: 2.9106922149658203	aux_loss: 0.7248013019561768
17:36:58 INFO - main: Train iter. 146200/200000 (73.1%): 	Loss: 3.6383166313171387	recon_loss: 0.02416418120265007	bpp_loss: 2.91339111328125	aux_loss: 0.7448287010192871
17:37:15 INFO - main: Train iter. 146300/200000 (73.15%): 	Loss: 3.6359095573425293	recon_loss: 0.02416212111711502	bpp_loss: 2.911045789718628	aux_loss: 0.6263422966003418
17:37:36 INFO - main: Train iter. 146400/200000 (73.2%): 	Loss: 3.632828712463379	recon_loss: 0.024159660562872887	bpp_loss: 2.908038854598999	aux_loss: 0.774734616279602
17:37:53 INFO - main: Train iter. 146500/200000 (73.25%): 	Loss: 3.63503360748291	recon_loss: 0.024165332317352295	bpp_loss: 2.910073757171631	aux_loss: 1.1246368885040283
17:38:11 INFO - main: Train iter. 146600/200000 (73.3%): 	Loss: 3.634432554244995	recon_loss: 0.02411847934126854	bpp_loss: 2.9108781814575195	aux_loss: 0.2684341371059418
17:38:29 INFO - main: Train iter. 146700/200000 (73.35%): 	Loss: 3.632072925567627	recon_loss: 0.024107448756694794	bpp_loss: 2.9088494777679443	aux_loss: 0.21511386334896088
17:38:46 INFO - main: Train iter. 146800/200000 (73.4%): 	Loss: 3.629377841949463	recon_loss: 0.024132343009114265	bpp_loss: 2.905407428741455	aux_loss: 0.5015643239021301
17:39:04 INFO - main: Train iter. 146900/200000 (73.45%): 	Loss: 3.643153190612793	recon_loss: 0.02423417940735817	bpp_loss: 2.916127920150757	aux_loss: 0.8054761290550232
17:39:22 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 3.629682779312134	recon_loss: 0.024126023054122925	bpp_loss: 2.905902147293091	aux_loss: 0.6324576139450073
17:39:39 INFO - main: Train iter. 147100/200000 (73.55%): 	Loss: 3.605626106262207	recon_loss: 0.02396540343761444	bpp_loss: 2.8866641521453857	aux_loss: 0.4081707000732422
17:39:57 INFO - main: Train iter. 147200/200000 (73.6%): 	Loss: 3.626009941101074	recon_loss: 0.024087605997920036	bpp_loss: 2.903381824493408	aux_loss: 0.6819828748703003
17:40:15 INFO - main: Train iter. 147300/200000 (73.65%): 	Loss: 3.6317222118377686	recon_loss: 0.02417569048702717	bpp_loss: 2.906451463699341	aux_loss: 0.500758945941925
17:40:33 INFO - main: Train iter. 147400/200000 (73.7%): 	Loss: 3.629255533218384	recon_loss: 0.024125266820192337	bpp_loss: 2.9054975509643555	aux_loss: 0.34669190645217896
17:40:51 INFO - main: Train iter. 147500/200000 (73.75%): 	Loss: 3.628955841064453	recon_loss: 0.024101657792925835	bpp_loss: 2.9059059619903564	aux_loss: 0.4047865867614746
17:41:08 INFO - main: Train iter. 147600/200000 (73.8%): 	Loss: 3.623363733291626	recon_loss: 0.024072924628853798	bpp_loss: 2.9011759757995605	aux_loss: 0.253476083278656
17:41:26 INFO - main: Train iter. 147700/200000 (73.85%): 	Loss: 3.626748561859131	recon_loss: 0.024085571989417076	bpp_loss: 2.904181480407715	aux_loss: 0.4020049571990967
17:41:44 INFO - main: Train iter. 147800/200000 (73.9%): 	Loss: 3.618112564086914	recon_loss: 0.024040240794420242	bpp_loss: 2.8969054222106934	aux_loss: 0.2334345132112503
17:42:01 INFO - main: Train iter. 147900/200000 (73.95%): 	Loss: 3.62603497505188	recon_loss: 0.02410087361931801	bpp_loss: 2.9030086994171143	aux_loss: 0.8269965052604675
17:42:19 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 3.6213183403015137	recon_loss: 0.02407000958919525	bpp_loss: 2.8992180824279785	aux_loss: 0.7297370433807373
17:42:36 INFO - main: Train iter. 148100/200000 (74.05%): 	Loss: 3.629948616027832	recon_loss: 0.0240667462348938	bpp_loss: 2.9079463481903076	aux_loss: 0.41764551401138306
17:42:54 INFO - main: Train iter. 148200/200000 (74.1%): 	Loss: 3.619353771209717	recon_loss: 0.02406156435608864	bpp_loss: 2.8975069522857666	aux_loss: 0.2927556037902832
17:43:12 INFO - main: Train iter. 148300/200000 (74.15%): 	Loss: 3.6115493774414062	recon_loss: 0.023940106853842735	bpp_loss: 2.893346071243286	aux_loss: 0.41712486743927
17:43:30 INFO - main: Train iter. 148400/200000 (74.2%): 	Loss: 3.610797166824341	recon_loss: 0.02399240992963314	bpp_loss: 2.8910248279571533	aux_loss: 0.3123747408390045
17:43:47 INFO - main: Train iter. 148500/200000 (74.25%): 	Loss: 3.6383583545684814	recon_loss: 0.0241436455398798	bpp_loss: 2.914048910140991	aux_loss: 0.1605428010225296
17:44:05 INFO - main: Train iter. 148600/200000 (74.3%): 	Loss: 3.6183362007141113	recon_loss: 0.024032942950725555	bpp_loss: 2.897347927093506	aux_loss: 0.3228372037410736
17:44:22 INFO - main: Train iter. 148700/200000 (74.35%): 	Loss: 3.6260271072387695	recon_loss: 0.02412012778222561	bpp_loss: 2.902423143386841	aux_loss: 0.24371322989463806
17:44:40 INFO - main: Train iter. 148800/200000 (74.4%): 	Loss: 3.63197922706604	recon_loss: 0.02410786785185337	bpp_loss: 2.908743143081665	aux_loss: 0.3156188428401947
17:44:58 INFO - main: Train iter. 148900/200000 (74.45%): 	Loss: 3.6334567070007324	recon_loss: 0.0241125226020813	bpp_loss: 2.910080909729004	aux_loss: 0.20685866475105286
17:45:15 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 3.636554718017578	recon_loss: 0.02414979785680771	bpp_loss: 2.9120607376098633	aux_loss: 0.4967617392539978
17:45:33 INFO - main: Train iter. 149100/200000 (74.55%): 	Loss: 3.6183876991271973	recon_loss: 0.02402898296713829	bpp_loss: 2.8975181579589844	aux_loss: 0.46814867854118347
17:45:51 INFO - main: Train iter. 149200/200000 (74.6%): 	Loss: 3.6117665767669678	recon_loss: 0.024030135944485664	bpp_loss: 2.890862464904785	aux_loss: 0.25051695108413696
17:46:08 INFO - main: Train iter. 149300/200000 (74.65%): 	Loss: 3.6275980472564697	recon_loss: 0.024099702015519142	bpp_loss: 2.904607057571411	aux_loss: 0.2109946310520172
17:46:26 INFO - main: Train iter. 149400/200000 (74.7%): 	Loss: 3.622828960418701	recon_loss: 0.02405606582760811	bpp_loss: 2.9011471271514893	aux_loss: 0.27885258197784424
17:46:43 INFO - main: Train iter. 149500/200000 (74.75%): 	Loss: 3.6348540782928467	recon_loss: 0.024105459451675415	bpp_loss: 2.9116902351379395	aux_loss: 0.5267394781112671
17:47:01 INFO - main: Train iter. 149600/200000 (74.8%): 	Loss: 3.6387791633605957	recon_loss: 0.024168897420167923	bpp_loss: 2.9137122631073	aux_loss: 0.3014254868030548
17:47:19 INFO - main: Train iter. 149700/200000 (74.85%): 	Loss: 3.63185715675354	recon_loss: 0.024152183905243874	bpp_loss: 2.9072916507720947	aux_loss: 0.4860686957836151
17:47:39 INFO - main: Train iter. 149800/200000 (74.9%): 	Loss: 3.609950065612793	recon_loss: 0.024014174938201904	bpp_loss: 2.8895249366760254	aux_loss: 0.5552952289581299
17:47:57 INFO - main: Train iter. 149900/200000 (74.95%): 	Loss: 3.6275129318237305	recon_loss: 0.024102533236145973	bpp_loss: 2.9044368267059326	aux_loss: 0.2878687083721161
17:48:14 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 3.627775192260742	recon_loss: 0.02405615709722042	bpp_loss: 2.906090497970581	aux_loss: 0.4311456084251404
17:48:24 INFO - main: {'TEST MSE': 0.024079053360204397, 'TEST BPP': 2.95359375, 'TEST loss': 3.627909412145615, 'TEST recon_loss': 0.02407905327156186, 'TEST bpp_loss': 2.9055378148555757}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:48:42 INFO - main: Train iter. 150100/200000 (75.05%): 	Loss: 3.625330924987793	recon_loss: 0.0240306556224823	bpp_loss: 2.9044113159179688	aux_loss: 0.7541452050209045
17:49:00 INFO - main: Train iter. 150200/200000 (75.1%): 	Loss: 3.6556081771850586	recon_loss: 0.024241425096988678	bpp_loss: 2.928365468978882	aux_loss: 0.2588038146495819
17:49:17 INFO - main: Train iter. 150300/200000 (75.15%): 	Loss: 3.6265623569488525	recon_loss: 0.024073055014014244	bpp_loss: 2.9043707847595215	aux_loss: 0.3897034227848053
17:49:35 INFO - main: Train iter. 150400/200000 (75.2%): 	Loss: 3.617743492126465	recon_loss: 0.024009115993976593	bpp_loss: 2.897469997406006	aux_loss: 0.9055854082107544
17:49:52 INFO - main: Train iter. 150500/200000 (75.25%): 	Loss: 3.6229805946350098	recon_loss: 0.024053549394011497	bpp_loss: 2.901374101638794	aux_loss: 0.2812293469905853
17:50:10 INFO - main: Train iter. 150600/200000 (75.3%): 	Loss: 3.629347324371338	recon_loss: 0.02414288930594921	bpp_loss: 2.9050607681274414	aux_loss: 0.7556613683700562
17:50:28 INFO - main: Train iter. 150700/200000 (75.35%): 	Loss: 3.622964382171631	recon_loss: 0.024089688435196877	bpp_loss: 2.9002737998962402	aux_loss: 0.7304671406745911
17:50:45 INFO - main: Train iter. 150800/200000 (75.4%): 	Loss: 3.632474660873413	recon_loss: 0.024136489257216454	bpp_loss: 2.9083800315856934	aux_loss: 0.6881250143051147
17:51:03 INFO - main: Train iter. 150900/200000 (75.45%): 	Loss: 3.6329731941223145	recon_loss: 0.02413869835436344	bpp_loss: 2.9088122844696045	aux_loss: 0.23303157091140747
17:51:21 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 3.621134042739868	recon_loss: 0.024010617285966873	bpp_loss: 2.900815486907959	aux_loss: 0.482077419757843
17:51:38 INFO - main: Train iter. 151100/200000 (75.55%): 	Loss: 3.655838966369629	recon_loss: 0.024235308170318604	bpp_loss: 2.9287798404693604	aux_loss: 0.4882407784461975
17:51:56 INFO - main: Train iter. 151200/200000 (75.6%): 	Loss: 3.634716510772705	recon_loss: 0.024150148034095764	bpp_loss: 2.9102120399475098	aux_loss: 1.1329917907714844
17:52:14 INFO - main: Train iter. 151300/200000 (75.65%): 	Loss: 3.615355968475342	recon_loss: 0.024044709280133247	bpp_loss: 2.894014596939087	aux_loss: 0.6224304437637329
17:52:31 INFO - main: Train iter. 151400/200000 (75.7%): 	Loss: 3.6098294258117676	recon_loss: 0.023981235921382904	bpp_loss: 2.890392303466797	aux_loss: 0.24000942707061768
17:52:49 INFO - main: Train iter. 151500/200000 (75.75%): 	Loss: 3.6188759803771973	recon_loss: 0.024040481075644493	bpp_loss: 2.8976616859436035	aux_loss: 0.7273859977722168
17:53:07 INFO - main: Train iter. 151600/200000 (75.8%): 	Loss: 3.6351428031921387	recon_loss: 0.024107763543725014	bpp_loss: 2.911909818649292	aux_loss: 0.42085063457489014
17:53:24 INFO - main: Train iter. 151700/200000 (75.85%): 	Loss: 3.6241233348846436	recon_loss: 0.024118445813655853	bpp_loss: 2.9005699157714844	aux_loss: 1.108353614807129
17:53:42 INFO - main: Train iter. 151800/200000 (75.9%): 	Loss: 3.629578113555908	recon_loss: 0.02412448823451996	bpp_loss: 2.905843496322632	aux_loss: 0.4502961039543152
17:54:00 INFO - main: Train iter. 151900/200000 (75.95%): 	Loss: 3.6409897804260254	recon_loss: 0.024182554334402084	bpp_loss: 2.915513038635254	aux_loss: 0.19772782921791077
17:54:17 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 3.6291205883026123	recon_loss: 0.02408010885119438	bpp_loss: 2.906717300415039	aux_loss: 0.2941318154335022
17:54:35 INFO - main: Train iter. 152100/200000 (76.05%): 	Loss: 3.6368346214294434	recon_loss: 0.02417215146124363	bpp_loss: 2.911669969558716	aux_loss: 0.49652522802352905
17:54:53 INFO - main: Train iter. 152200/200000 (76.1%): 	Loss: 3.6308271884918213	recon_loss: 0.024107694625854492	bpp_loss: 2.9075963497161865	aux_loss: 0.7002682089805603
17:55:10 INFO - main: Train iter. 152300/200000 (76.15%): 	Loss: 3.625680446624756	recon_loss: 0.024140285328030586	bpp_loss: 2.9014718532562256	aux_loss: 0.7177154421806335
17:55:28 INFO - main: Train iter. 152400/200000 (76.2%): 	Loss: 3.620021343231201	recon_loss: 0.02400532178580761	bpp_loss: 2.8998618125915527	aux_loss: 1.078718662261963
17:55:46 INFO - main: Train iter. 152500/200000 (76.25%): 	Loss: 3.6302130222320557	recon_loss: 0.02412274107336998	bpp_loss: 2.9065308570861816	aux_loss: 0.31836676597595215
17:56:03 INFO - main: Train iter. 152600/200000 (76.3%): 	Loss: 3.6159629821777344	recon_loss: 0.024050993844866753	bpp_loss: 2.8944332599639893	aux_loss: 0.30090248584747314
17:56:21 INFO - main: Train iter. 152700/200000 (76.35%): 	Loss: 3.621748924255371	recon_loss: 0.024093041196465492	bpp_loss: 2.8989577293395996	aux_loss: 0.26931190490722656
17:56:39 INFO - main: Train iter. 152800/200000 (76.4%): 	Loss: 3.6069650650024414	recon_loss: 0.02400737814605236	bpp_loss: 2.8867437839508057	aux_loss: 0.6022933721542358
17:56:56 INFO - main: Train iter. 152900/200000 (76.45%): 	Loss: 3.6401052474975586	recon_loss: 0.02417164295911789	bpp_loss: 2.9149558544158936	aux_loss: 0.37207359075546265
17:57:14 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 3.625415325164795	recon_loss: 0.02407343126833439	bpp_loss: 2.903212308883667	aux_loss: 0.33408647775650024
17:57:34 INFO - main: Train iter. 153100/200000 (76.55%): 	Loss: 3.6328654289245605	recon_loss: 0.02412891760468483	bpp_loss: 2.9089977741241455	aux_loss: 0.27312415838241577
17:57:52 INFO - main: Train iter. 153200/200000 (76.6%): 	Loss: 3.6386594772338867	recon_loss: 0.02414039336144924	bpp_loss: 2.914447546005249	aux_loss: 0.2748297452926636
17:58:10 INFO - main: Train iter. 153300/200000 (76.65%): 	Loss: 3.6458113193511963	recon_loss: 0.024174708873033524	bpp_loss: 2.920570135116577	aux_loss: 0.2112143188714981
17:58:27 INFO - main: Train iter. 153400/200000 (76.7%): 	Loss: 3.650672435760498	recon_loss: 0.02419786900281906	bpp_loss: 2.924736261367798	aux_loss: 0.7318989038467407
17:58:45 INFO - main: Train iter. 153500/200000 (76.75%): 	Loss: 3.6407227516174316	recon_loss: 0.024200711399316788	bpp_loss: 2.914701461791992	aux_loss: 0.22769373655319214
17:59:03 INFO - main: Train iter. 153600/200000 (76.8%): 	Loss: 3.6251332759857178	recon_loss: 0.024079499766230583	bpp_loss: 2.9027483463287354	aux_loss: 0.6117674708366394
17:59:20 INFO - main: Train iter. 153700/200000 (76.85%): 	Loss: 3.6246695518493652	recon_loss: 0.02409394457936287	bpp_loss: 2.901851177215576	aux_loss: 0.3385721445083618
17:59:38 INFO - main: Train iter. 153800/200000 (76.9%): 	Loss: 3.6307458877563477	recon_loss: 0.02411317452788353	bpp_loss: 2.907350540161133	aux_loss: 0.1393059939146042
17:59:56 INFO - main: Train iter. 153900/200000 (76.95%): 	Loss: 3.6363697052001953	recon_loss: 0.02416427992284298	bpp_loss: 2.9114413261413574	aux_loss: 0.624107837677002
18:00:13 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 3.6410539150238037	recon_loss: 0.024211155250668526	bpp_loss: 2.914719343185425	aux_loss: 0.15433992445468903
18:00:31 INFO - main: Train iter. 154100/200000 (77.05%): 	Loss: 3.627439022064209	recon_loss: 0.024148453027009964	bpp_loss: 2.9029853343963623	aux_loss: 0.7467597723007202
18:00:49 INFO - main: Train iter. 154200/200000 (77.1%): 	Loss: 3.6182541847229004	recon_loss: 0.024054214358329773	bpp_loss: 2.89662766456604	aux_loss: 0.26458874344825745
18:01:06 INFO - main: Train iter. 154300/200000 (77.15%): 	Loss: 3.629361152648926	recon_loss: 0.024118687957525253	bpp_loss: 2.9058005809783936	aux_loss: 0.36986055970191956
18:01:24 INFO - main: Train iter. 154400/200000 (77.2%): 	Loss: 3.6295597553253174	recon_loss: 0.024103624746203423	bpp_loss: 2.9064509868621826	aux_loss: 0.45310652256011963
18:01:42 INFO - main: Train iter. 154500/200000 (77.25%): 	Loss: 3.6187872886657715	recon_loss: 0.02403508499264717	bpp_loss: 2.8977348804473877	aux_loss: 0.2030162215232849
18:01:59 INFO - main: Train iter. 154600/200000 (77.3%): 	Loss: 3.639714241027832	recon_loss: 0.024139612913131714	bpp_loss: 2.9155259132385254	aux_loss: 0.24204829335212708
18:02:17 INFO - main: Train iter. 154700/200000 (77.35%): 	Loss: 3.611138343811035	recon_loss: 0.02399507910013199	bpp_loss: 2.8912858963012695	aux_loss: 0.4578126072883606
18:02:34 INFO - main: Train iter. 154800/200000 (77.4%): 	Loss: 3.641375780105591	recon_loss: 0.02417522855103016	bpp_loss: 2.916118860244751	aux_loss: 0.2720119059085846
18:02:52 INFO - main: Train iter. 154900/200000 (77.45%): 	Loss: 3.644444465637207	recon_loss: 0.024255193769931793	bpp_loss: 2.9167885780334473	aux_loss: 0.32654961943626404
18:03:10 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 3.637134552001953	recon_loss: 0.024119889363646507	bpp_loss: 2.9135377407073975	aux_loss: 0.245702862739563
18:03:19 INFO - main: {'TEST MSE': 0.024097371492816152, 'TEST BPP': 2.9531875, 'TEST loss': 3.627791463136673, 'TEST recon_loss': 0.02409737138822675, 'TEST bpp_loss': 2.904870320558548}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:03:37 INFO - main: Train iter. 155100/200000 (77.55%): 	Loss: 3.6325759887695312	recon_loss: 0.02411028742790222	bpp_loss: 2.9092674255371094	aux_loss: 0.385894775390625
18:03:54 INFO - main: Train iter. 155200/200000 (77.6%): 	Loss: 3.6301798820495605	recon_loss: 0.02406327612698078	bpp_loss: 2.9082815647125244	aux_loss: 0.3786815404891968
18:04:12 INFO - main: Train iter. 155300/200000 (77.65%): 	Loss: 3.6515467166900635	recon_loss: 0.024237817153334618	bpp_loss: 2.924412250518799	aux_loss: 0.22019678354263306
18:04:29 INFO - main: Train iter. 155400/200000 (77.7%): 	Loss: 3.63250470161438	recon_loss: 0.024113574996590614	bpp_loss: 2.90909743309021	aux_loss: 0.4479823410511017
18:04:47 INFO - main: Train iter. 155500/200000 (77.75%): 	Loss: 3.627370834350586	recon_loss: 0.02407418191432953	bpp_loss: 2.9051454067230225	aux_loss: 0.2456803321838379
18:05:05 INFO - main: Train iter. 155600/200000 (77.8%): 	Loss: 3.6290626525878906	recon_loss: 0.02414671890437603	bpp_loss: 2.904660940170288	aux_loss: 0.8917983174324036
18:05:22 INFO - main: Train iter. 155700/200000 (77.85%): 	Loss: 3.6180660724639893	recon_loss: 0.024048853665590286	bpp_loss: 2.8966004848480225	aux_loss: 0.4397800862789154
18:05:40 INFO - main: Train iter. 155800/200000 (77.9%): 	Loss: 3.611398458480835	recon_loss: 0.02398647367954254	bpp_loss: 2.8918042182922363	aux_loss: 0.3835461437702179
18:05:58 INFO - main: Train iter. 155900/200000 (77.95%): 	Loss: 3.6218066215515137	recon_loss: 0.024042926728725433	bpp_loss: 2.9005188941955566	aux_loss: 0.4613793194293976
18:06:15 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 3.637253999710083	recon_loss: 0.02415894903242588	bpp_loss: 2.9124855995178223	aux_loss: 0.2599395513534546
18:06:33 INFO - main: Train iter. 156100/200000 (78.05%): 	Loss: 3.6227715015411377	recon_loss: 0.024054549634456635	bpp_loss: 2.901134967803955	aux_loss: 0.2731252908706665
18:06:51 INFO - main: Train iter. 156200/200000 (78.1%): 	Loss: 3.629930257797241	recon_loss: 0.024106185883283615	bpp_loss: 2.9067447185516357	aux_loss: 0.6709613800048828
18:07:08 INFO - main: Train iter. 156300/200000 (78.15%): 	Loss: 3.6293230056762695	recon_loss: 0.024100858718156815	bpp_loss: 2.906297206878662	aux_loss: 0.24585652351379395
18:07:28 INFO - main: Train iter. 156400/200000 (78.2%): 	Loss: 3.641374111175537	recon_loss: 0.024141592904925346	bpp_loss: 2.917126417160034	aux_loss: 0.39108163118362427
18:07:46 INFO - main: Train iter. 156500/200000 (78.25%): 	Loss: 3.6504485607147217	recon_loss: 0.024229463189840317	bpp_loss: 2.9235646724700928	aux_loss: 0.5325363278388977
18:08:04 INFO - main: Train iter. 156600/200000 (78.3%): 	Loss: 3.639525890350342	recon_loss: 0.024175887927412987	bpp_loss: 2.9142491817474365	aux_loss: 0.29680535197257996
18:08:21 INFO - main: Train iter. 156700/200000 (78.35%): 	Loss: 3.6248342990875244	recon_loss: 0.024087470024824142	bpp_loss: 2.902210235595703	aux_loss: 0.3107689917087555
18:08:39 INFO - main: Train iter. 156800/200000 (78.4%): 	Loss: 3.6043920516967773	recon_loss: 0.023978205397725105	bpp_loss: 2.8850457668304443	aux_loss: 0.27722281217575073
18:08:57 INFO - main: Train iter. 156900/200000 (78.45%): 	Loss: 3.6284189224243164	recon_loss: 0.024127604439854622	bpp_loss: 2.9045908451080322	aux_loss: 0.8812611699104309
18:09:15 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 3.6289570331573486	recon_loss: 0.024079449474811554	bpp_loss: 2.906573534011841	aux_loss: 0.6589069366455078
18:09:32 INFO - main: Train iter. 157100/200000 (78.55%): 	Loss: 3.629483938217163	recon_loss: 0.024105215445160866	bpp_loss: 2.906327486038208	aux_loss: 0.28069350123405457
18:09:50 INFO - main: Train iter. 157200/200000 (78.6%): 	Loss: 3.6157593727111816	recon_loss: 0.02402959205210209	bpp_loss: 2.894871711730957	aux_loss: 0.3797895610332489
18:10:08 INFO - main: Train iter. 157300/200000 (78.65%): 	Loss: 3.6226906776428223	recon_loss: 0.024058440700173378	bpp_loss: 2.90093731880188	aux_loss: 0.9611901640892029
18:10:25 INFO - main: Train iter. 157400/200000 (78.7%): 	Loss: 3.6271462440490723	recon_loss: 0.024046674370765686	bpp_loss: 2.9057459831237793	aux_loss: 1.061551570892334
18:10:43 INFO - main: Train iter. 157500/200000 (78.75%): 	Loss: 3.618424892425537	recon_loss: 0.024032333865761757	bpp_loss: 2.8974549770355225	aux_loss: 0.5668845176696777
18:11:00 INFO - main: Train iter. 157600/200000 (78.8%): 	Loss: 3.617657423019409	recon_loss: 0.02406652830541134	bpp_loss: 2.8956615924835205	aux_loss: 0.330147385597229
18:11:18 INFO - main: Train iter. 157700/200000 (78.85%): 	Loss: 3.634230852127075	recon_loss: 0.024152033030986786	bpp_loss: 2.909669876098633	aux_loss: 0.48673707246780396
18:11:36 INFO - main: Train iter. 157800/200000 (78.9%): 	Loss: 3.6264262199401855	recon_loss: 0.02405354753136635	bpp_loss: 2.9048197269439697	aux_loss: 0.8234680891036987
18:11:53 INFO - main: Train iter. 157900/200000 (78.95%): 	Loss: 3.619849443435669	recon_loss: 0.024065162986516953	bpp_loss: 2.8978946208953857	aux_loss: 0.16516102850437164
18:12:11 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 3.637422561645508	recon_loss: 0.024196311831474304	bpp_loss: 2.9115333557128906	aux_loss: 0.9422833919525146
18:12:29 INFO - main: Train iter. 158100/200000 (79.05%): 	Loss: 3.652580738067627	recon_loss: 0.02428264729678631	bpp_loss: 2.9241013526916504	aux_loss: 0.6992863416671753
18:12:46 INFO - main: Train iter. 158200/200000 (79.1%): 	Loss: 3.62935733795166	recon_loss: 0.02407371625304222	bpp_loss: 2.9071457386016846	aux_loss: 0.3555981516838074
18:13:04 INFO - main: Train iter. 158300/200000 (79.15%): 	Loss: 3.6210553646087646	recon_loss: 0.024058235809206963	bpp_loss: 2.899308204650879	aux_loss: 0.40737056732177734
18:13:21 INFO - main: Train iter. 158400/200000 (79.2%): 	Loss: 3.6089656352996826	recon_loss: 0.023984426632523537	bpp_loss: 2.889432907104492	aux_loss: 0.7622970342636108
18:13:39 INFO - main: Train iter. 158500/200000 (79.25%): 	Loss: 3.6307098865509033	recon_loss: 0.024096926674246788	bpp_loss: 2.907802104949951	aux_loss: 0.32710838317871094
18:13:57 INFO - main: Train iter. 158600/200000 (79.3%): 	Loss: 3.6290314197540283	recon_loss: 0.024165166541934013	bpp_loss: 2.904076337814331	aux_loss: 0.3437785506248474
18:14:14 INFO - main: Train iter. 158700/200000 (79.35%): 	Loss: 3.6182286739349365	recon_loss: 0.024042779579758644	bpp_loss: 2.8969452381134033	aux_loss: 0.4165876805782318
18:14:32 INFO - main: Train iter. 158800/200000 (79.4%): 	Loss: 3.622973918914795	recon_loss: 0.024066967889666557	bpp_loss: 2.9009647369384766	aux_loss: 0.27633148431777954
18:14:50 INFO - main: Train iter. 158900/200000 (79.45%): 	Loss: 3.6251888275146484	recon_loss: 0.024094045162200928	bpp_loss: 2.90236759185791	aux_loss: 0.3307637572288513
18:15:07 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 3.6270041465759277	recon_loss: 0.024084853008389473	bpp_loss: 2.904458522796631	aux_loss: 0.3893722891807556
18:15:25 INFO - main: Train iter. 159100/200000 (79.55%): 	Loss: 3.6325535774230957	recon_loss: 0.024108344689011574	bpp_loss: 2.9093031883239746	aux_loss: 0.7836072444915771
18:15:43 INFO - main: Train iter. 159200/200000 (79.6%): 	Loss: 3.6162123680114746	recon_loss: 0.024047672748565674	bpp_loss: 2.894782304763794	aux_loss: 0.6027228832244873
18:16:00 INFO - main: Train iter. 159300/200000 (79.65%): 	Loss: 3.6298680305480957	recon_loss: 0.02411678247153759	bpp_loss: 2.906364679336548	aux_loss: 0.3505513668060303
18:16:18 INFO - main: Train iter. 159400/200000 (79.7%): 	Loss: 3.627420425415039	recon_loss: 0.02407849393785	bpp_loss: 2.9050655364990234	aux_loss: 0.22599196434020996
18:16:36 INFO - main: Train iter. 159500/200000 (79.75%): 	Loss: 3.6250791549682617	recon_loss: 0.024120336398482323	bpp_loss: 2.9014689922332764	aux_loss: 0.2002812623977661
18:16:53 INFO - main: Train iter. 159600/200000 (79.8%): 	Loss: 3.6175310611724854	recon_loss: 0.024030590429902077	bpp_loss: 2.896613359451294	aux_loss: 0.9205018281936646
18:17:14 INFO - main: Train iter. 159700/200000 (79.85%): 	Loss: 3.6296074390411377	recon_loss: 0.024123014882206917	bpp_loss: 2.905916929244995	aux_loss: 0.23523297905921936
18:17:31 INFO - main: Train iter. 159800/200000 (79.9%): 	Loss: 3.6263017654418945	recon_loss: 0.024058744311332703	bpp_loss: 2.9045395851135254	aux_loss: 0.8128302097320557
18:17:49 INFO - main: Train iter. 159900/200000 (79.95%): 	Loss: 3.6107404232025146	recon_loss: 0.02399345301091671	bpp_loss: 2.890936851501465	aux_loss: 0.18520823121070862
18:18:07 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 3.6342954635620117	recon_loss: 0.024130865931510925	bpp_loss: 2.910369396209717	aux_loss: 0.9658178091049194
18:18:16 INFO - main: {'TEST MSE': 0.024113661052169364, 'TEST BPP': 2.9526875, 'TEST loss': 3.6277883656024934, 'TEST recon_loss': 0.024113660970702767, 'TEST bpp_loss': 2.9043785383701324}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:18:34 INFO - main: Train iter. 160100/200000 (80.05%): 	Loss: 3.658830404281616	recon_loss: 0.024266226217150688	bpp_loss: 2.9308435916900635	aux_loss: 0.1728266477584839
18:18:52 INFO - main: Train iter. 160200/200000 (80.1%): 	Loss: 3.64400577545166	recon_loss: 0.024185119196772575	bpp_loss: 2.918452262878418	aux_loss: 0.2275683432817459
18:19:09 INFO - main: Train iter. 160300/200000 (80.15%): 	Loss: 3.6301302909851074	recon_loss: 0.024154482409358025	bpp_loss: 2.9054958820343018	aux_loss: 0.315275102853775
18:19:27 INFO - main: Train iter. 160400/200000 (80.2%): 	Loss: 3.627398729324341	recon_loss: 0.02408895455300808	bpp_loss: 2.9047300815582275	aux_loss: 0.26280245184898376
18:19:44 INFO - main: Train iter. 160500/200000 (80.25%): 	Loss: 3.61918306350708	recon_loss: 0.02407759800553322	bpp_loss: 2.896855115890503	aux_loss: 0.27206602692604065
18:20:02 INFO - main: Train iter. 160600/200000 (80.3%): 	Loss: 3.6149027347564697	recon_loss: 0.024019582197070122	bpp_loss: 2.894315242767334	aux_loss: 0.20449909567832947
18:20:19 INFO - main: Train iter. 160700/200000 (80.35%): 	Loss: 3.630336284637451	recon_loss: 0.024114085361361504	bpp_loss: 2.9069137573242188	aux_loss: 0.4380378723144531
18:20:37 INFO - main: Train iter. 160800/200000 (80.4%): 	Loss: 3.6256601810455322	recon_loss: 0.024112049490213394	bpp_loss: 2.90229868888855	aux_loss: 0.5855407118797302
18:20:55 INFO - main: Train iter. 160900/200000 (80.45%): 	Loss: 3.632791519165039	recon_loss: 0.024133935570716858	bpp_loss: 2.908773422241211	aux_loss: 0.2455267757177353
18:21:12 INFO - main: Train iter. 161000/200000 (80.5%): 	Loss: 3.626079559326172	recon_loss: 0.024077488109469414	bpp_loss: 2.903754949569702	aux_loss: 1.008117914199829
18:21:30 INFO - main: Train iter. 161100/200000 (80.55%): 	Loss: 3.624570369720459	recon_loss: 0.02407178282737732	bpp_loss: 2.902416944503784	aux_loss: 0.3517577648162842
18:21:48 INFO - main: Train iter. 161200/200000 (80.6%): 	Loss: 3.6161558628082275	recon_loss: 0.024018576368689537	bpp_loss: 2.8955986499786377	aux_loss: 0.5013161897659302
18:22:05 INFO - main: Train iter. 161300/200000 (80.65%): 	Loss: 3.616225242614746	recon_loss: 0.024051330983638763	bpp_loss: 2.8946852684020996	aux_loss: 0.5820739269256592
18:22:23 INFO - main: Train iter. 161400/200000 (80.7%): 	Loss: 3.632821798324585	recon_loss: 0.024157486855983734	bpp_loss: 2.908097267150879	aux_loss: 0.29108816385269165
18:22:41 INFO - main: Train iter. 161500/200000 (80.75%): 	Loss: 3.6247425079345703	recon_loss: 0.0240861214697361	bpp_loss: 2.902158737182617	aux_loss: 0.20827025175094604
18:22:58 INFO - main: Train iter. 161600/200000 (80.8%): 	Loss: 3.624641180038452	recon_loss: 0.024066591635346413	bpp_loss: 2.9026434421539307	aux_loss: 0.2851438820362091
18:23:16 INFO - main: Train iter. 161700/200000 (80.85%): 	Loss: 3.6257212162017822	recon_loss: 0.024101195856928825	bpp_loss: 2.9026854038238525	aux_loss: 0.18186581134796143
18:23:34 INFO - main: Train iter. 161800/200000 (80.9%): 	Loss: 3.630098342895508	recon_loss: 0.024096624925732613	bpp_loss: 2.9071996212005615	aux_loss: 0.5900768637657166
18:23:51 INFO - main: Train iter. 161900/200000 (80.95%): 	Loss: 3.6310923099517822	recon_loss: 0.024133974686264992	bpp_loss: 2.9070730209350586	aux_loss: 0.28302085399627686
18:24:09 INFO - main: Train iter. 162000/200000 (81.0%): 	Loss: 3.6331429481506348	recon_loss: 0.024127284064888954	bpp_loss: 2.9093244075775146	aux_loss: 0.25539395213127136
18:24:26 INFO - main: Train iter. 162100/200000 (81.05%): 	Loss: 3.6212542057037354	recon_loss: 0.024110212922096252	bpp_loss: 2.8979477882385254	aux_loss: 0.2691715657711029
18:24:44 INFO - main: Train iter. 162200/200000 (81.1%): 	Loss: 3.6305654048919678	recon_loss: 0.024134015664458275	bpp_loss: 2.9065449237823486	aux_loss: 0.5012568831443787
18:25:02 INFO - main: Train iter. 162300/200000 (81.15%): 	Loss: 3.645508289337158	recon_loss: 0.024227099493145943	bpp_loss: 2.9186954498291016	aux_loss: 0.2533642053604126
18:25:19 INFO - main: Train iter. 162400/200000 (81.2%): 	Loss: 3.639664888381958	recon_loss: 0.024154463782906532	bpp_loss: 2.9150309562683105	aux_loss: 0.27543845772743225
18:25:37 INFO - main: Train iter. 162500/200000 (81.25%): 	Loss: 3.6249635219573975	recon_loss: 0.024088257923722267	bpp_loss: 2.902315855026245	aux_loss: 0.1963927149772644
18:25:55 INFO - main: Train iter. 162600/200000 (81.3%): 	Loss: 3.6513936519622803	recon_loss: 0.024195749312639236	bpp_loss: 2.9255211353302	aux_loss: 0.6153168082237244
18:26:12 INFO - main: Train iter. 162700/200000 (81.35%): 	Loss: 3.624631404876709	recon_loss: 0.024129807949066162	bpp_loss: 2.9007370471954346	aux_loss: 0.5772416591644287
18:26:30 INFO - main: Train iter. 162800/200000 (81.4%): 	Loss: 3.6146578788757324	recon_loss: 0.024030180647969246	bpp_loss: 2.8937525749206543	aux_loss: 0.4457833170890808
18:26:48 INFO - main: Train iter. 162900/200000 (81.45%): 	Loss: 3.6356773376464844	recon_loss: 0.02415311336517334	bpp_loss: 2.911083936691284	aux_loss: 0.5179978609085083
18:27:06 INFO - main: Train iter. 163000/200000 (81.5%): 	Loss: 3.632180690765381	recon_loss: 0.024130528792738914	bpp_loss: 2.9082648754119873	aux_loss: 0.24571958184242249
18:27:26 INFO - main: Train iter. 163100/200000 (81.55%): 	Loss: 3.630755662918091	recon_loss: 0.02416035905480385	bpp_loss: 2.90594482421875	aux_loss: 0.3410996198654175
18:27:44 INFO - main: Train iter. 163200/200000 (81.6%): 	Loss: 3.611609697341919	recon_loss: 0.024019312113523483	bpp_loss: 2.8910303115844727	aux_loss: 0.46788662672042847
18:28:01 INFO - main: Train iter. 163300/200000 (81.65%): 	Loss: 3.618157148361206	recon_loss: 0.0240376815199852	bpp_loss: 2.897026777267456	aux_loss: 0.2348233461380005
18:28:19 INFO - main: Train iter. 163400/200000 (81.7%): 	Loss: 3.6276235580444336	recon_loss: 0.024080194532871246	bpp_loss: 2.9052176475524902	aux_loss: 0.3673335611820221
18:28:37 INFO - main: Train iter. 163500/200000 (81.75%): 	Loss: 3.6283936500549316	recon_loss: 0.024066084995865822	bpp_loss: 2.9064111709594727	aux_loss: 0.5364091396331787
18:28:54 INFO - main: Train iter. 163600/200000 (81.8%): 	Loss: 3.611311435699463	recon_loss: 0.023993391543626785	bpp_loss: 2.891509771347046	aux_loss: 0.3719661831855774
18:29:12 INFO - main: Train iter. 163700/200000 (81.85%): 	Loss: 3.6203951835632324	recon_loss: 0.024097001180052757	bpp_loss: 2.8974852561950684	aux_loss: 0.33297035098075867
18:29:30 INFO - main: Train iter. 163800/200000 (81.9%): 	Loss: 3.6117074489593506	recon_loss: 0.02401079051196575	bpp_loss: 2.891383647918701	aux_loss: 0.3007815480232239
18:29:47 INFO - main: Train iter. 163900/200000 (81.95%): 	Loss: 3.6258511543273926	recon_loss: 0.024070942774415016	bpp_loss: 2.9037230014801025	aux_loss: 0.5971568822860718
18:30:05 INFO - main: Train iter. 164000/200000 (82.0%): 	Loss: 3.629760503768921	recon_loss: 0.024094583466649055	bpp_loss: 2.9069230556488037	aux_loss: 0.25927188992500305
18:30:23 INFO - main: Train iter. 164100/200000 (82.05%): 	Loss: 3.627786874771118	recon_loss: 0.024103639647364616	bpp_loss: 2.904677629470825	aux_loss: 0.42227432131767273
18:30:40 INFO - main: Train iter. 164200/200000 (82.1%): 	Loss: 3.6261396408081055	recon_loss: 0.024066491052508354	bpp_loss: 2.904144763946533	aux_loss: 0.6332615613937378
18:30:58 INFO - main: Train iter. 164300/200000 (82.15%): 	Loss: 3.6403918266296387	recon_loss: 0.024190235882997513	bpp_loss: 2.914684772491455	aux_loss: 0.6342188715934753
18:31:16 INFO - main: Train iter. 164400/200000 (82.2%): 	Loss: 3.6322731971740723	recon_loss: 0.024131495505571365	bpp_loss: 2.9083282947540283	aux_loss: 0.22091743350028992
18:31:33 INFO - main: Train iter. 164500/200000 (82.25%): 	Loss: 3.643613815307617	recon_loss: 0.02416541986167431	bpp_loss: 2.9186511039733887	aux_loss: 0.46835267543792725
18:31:51 INFO - main: Train iter. 164600/200000 (82.3%): 	Loss: 3.6142120361328125	recon_loss: 0.024028543382883072	bpp_loss: 2.89335560798645	aux_loss: 0.32636797428131104
18:32:09 INFO - main: Train iter. 164700/200000 (82.35%): 	Loss: 3.622502326965332	recon_loss: 0.02404075115919113	bpp_loss: 2.901279926300049	aux_loss: 0.4889553487300873
18:32:26 INFO - main: Train iter. 164800/200000 (82.4%): 	Loss: 3.61812424659729	recon_loss: 0.02404341660439968	bpp_loss: 2.8968217372894287	aux_loss: 0.292915016412735
18:32:44 INFO - main: Train iter. 164900/200000 (82.45%): 	Loss: 3.6267757415771484	recon_loss: 0.024134555831551552	bpp_loss: 2.9027390480041504	aux_loss: 0.5810363292694092
18:33:01 INFO - main: Train iter. 165000/200000 (82.5%): 	Loss: 3.6232757568359375	recon_loss: 0.024048229679465294	bpp_loss: 2.9018287658691406	aux_loss: 0.29660725593566895
18:33:11 INFO - main: {'TEST MSE': 0.024102060925300137, 'TEST BPP': 2.9531875, 'TEST loss': 3.6276352787017823, 'TEST recon_loss': 0.024102060848847032, 'TEST bpp_loss': 2.904573453426361}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:33:29 INFO - main: Train iter. 165100/200000 (82.55%): 	Loss: 3.639908790588379	recon_loss: 0.024138011038303375	bpp_loss: 2.9157683849334717	aux_loss: 0.34755587577819824
18:33:46 INFO - main: Train iter. 165200/200000 (82.6%): 	Loss: 3.6185154914855957	recon_loss: 0.024058716371655464	bpp_loss: 2.896754026412964	aux_loss: 0.335475355386734
18:34:04 INFO - main: Train iter. 165300/200000 (82.65%): 	Loss: 3.6324868202209473	recon_loss: 0.024131309241056442	bpp_loss: 2.9085474014282227	aux_loss: 0.356900155544281
18:34:21 INFO - main: Train iter. 165400/200000 (82.7%): 	Loss: 3.628175735473633	recon_loss: 0.024123329669237137	bpp_loss: 2.9044759273529053	aux_loss: 0.2630506455898285
18:34:39 INFO - main: Train iter. 165500/200000 (82.75%): 	Loss: 3.635540246963501	recon_loss: 0.02415924146771431	bpp_loss: 2.9107630252838135	aux_loss: 0.34266480803489685
18:34:57 INFO - main: Train iter. 165600/200000 (82.8%): 	Loss: 3.6303930282592773	recon_loss: 0.0241362527012825	bpp_loss: 2.9063055515289307	aux_loss: 0.22004643082618713
18:35:14 INFO - main: Train iter. 165700/200000 (82.85%): 	Loss: 3.610819101333618	recon_loss: 0.02399163879454136	bpp_loss: 2.8910698890686035	aux_loss: 0.2343774437904358
18:35:32 INFO - main: Train iter. 165800/200000 (82.9%): 	Loss: 3.6246886253356934	recon_loss: 0.024050064384937286	bpp_loss: 2.903186798095703	aux_loss: 0.3165241479873657
18:35:49 INFO - main: Train iter. 165900/200000 (82.95%): 	Loss: 3.637179374694824	recon_loss: 0.02413138933479786	bpp_loss: 2.9132378101348877	aux_loss: 0.3118414878845215
18:36:07 INFO - main: Train iter. 166000/200000 (83.0%): 	Loss: 3.6330432891845703	recon_loss: 0.024130886420607567	bpp_loss: 2.909116744995117	aux_loss: 0.21405240893363953
18:36:25 INFO - main: Train iter. 166100/200000 (83.05%): 	Loss: 3.6424715518951416	recon_loss: 0.024202220141887665	bpp_loss: 2.916404962539673	aux_loss: 0.2131066769361496
18:36:42 INFO - main: Train iter. 166200/200000 (83.1%): 	Loss: 3.6284596920013428	recon_loss: 0.024118639528751373	bpp_loss: 2.904900550842285	aux_loss: 0.26461467146873474
18:37:00 INFO - main: Train iter. 166300/200000 (83.15%): 	Loss: 3.6322524547576904	recon_loss: 0.02410789392888546	bpp_loss: 2.909015655517578	aux_loss: 0.2967965602874756
18:37:20 INFO - main: Train iter. 166400/200000 (83.2%): 	Loss: 3.6222548484802246	recon_loss: 0.02404301054775715	bpp_loss: 2.9009644985198975	aux_loss: 0.2261156141757965
18:37:38 INFO - main: Train iter. 166500/200000 (83.25%): 	Loss: 3.62487530708313	recon_loss: 0.02409178577363491	bpp_loss: 2.9021217823028564	aux_loss: 0.30280691385269165
18:37:55 INFO - main: Train iter. 166600/200000 (83.3%): 	Loss: 3.622863292694092	recon_loss: 0.024037331342697144	bpp_loss: 2.9017434120178223	aux_loss: 0.7625408172607422
18:38:13 INFO - main: Train iter. 166700/200000 (83.35%): 	Loss: 3.6320912837982178	recon_loss: 0.024112174287438393	bpp_loss: 2.9087259769439697	aux_loss: 0.3850831389427185
18:38:31 INFO - main: Train iter. 166800/200000 (83.4%): 	Loss: 3.6222238540649414	recon_loss: 0.024072982370853424	bpp_loss: 2.9000344276428223	aux_loss: 0.31120193004608154
18:38:48 INFO - main: Train iter. 166900/200000 (83.45%): 	Loss: 3.6361773014068604	recon_loss: 0.024140479043126106	bpp_loss: 2.9119629859924316	aux_loss: 0.587776780128479
18:39:06 INFO - main: Train iter. 167000/200000 (83.5%): 	Loss: 3.6210885047912598	recon_loss: 0.02401156537234783	bpp_loss: 2.9007415771484375	aux_loss: 0.6625284552574158
18:39:24 INFO - main: Train iter. 167100/200000 (83.55%): 	Loss: 3.615581512451172	recon_loss: 0.023996390402317047	bpp_loss: 2.8956897258758545	aux_loss: 0.6441048979759216
18:39:41 INFO - main: Train iter. 167200/200000 (83.6%): 	Loss: 3.610072135925293	recon_loss: 0.024014703929424286	bpp_loss: 2.8896310329437256	aux_loss: 0.32728588581085205
18:39:59 INFO - main: Train iter. 167300/200000 (83.65%): 	Loss: 3.6403980255126953	recon_loss: 0.024128183722496033	bpp_loss: 2.9165525436401367	aux_loss: 0.9799866080284119
18:40:17 INFO - main: Train iter. 167400/200000 (83.7%): 	Loss: 3.609250545501709	recon_loss: 0.024011237546801567	bpp_loss: 2.88891339302063	aux_loss: 0.31834664940834045
18:40:34 INFO - main: Train iter. 167500/200000 (83.75%): 	Loss: 3.621333122253418	recon_loss: 0.02405398339033127	bpp_loss: 2.8997135162353516	aux_loss: 0.19521118700504303
18:40:52 INFO - main: Train iter. 167600/200000 (83.8%): 	Loss: 3.6429710388183594	recon_loss: 0.024195479229092598	bpp_loss: 2.9171066284179688	aux_loss: 0.3564036786556244
18:41:10 INFO - main: Train iter. 167700/200000 (83.85%): 	Loss: 3.6198439598083496	recon_loss: 0.024042941629886627	bpp_loss: 2.8985557556152344	aux_loss: 0.5670461654663086
18:41:27 INFO - main: Train iter. 167800/200000 (83.9%): 	Loss: 3.6250813007354736	recon_loss: 0.024061335250735283	bpp_loss: 2.9032411575317383	aux_loss: 0.8006851673126221
18:41:45 INFO - main: Train iter. 167900/200000 (83.95%): 	Loss: 3.635939359664917	recon_loss: 0.024155152961611748	bpp_loss: 2.9112846851348877	aux_loss: 0.2696589529514313
18:42:02 INFO - main: Train iter. 168000/200000 (84.0%): 	Loss: 3.6325223445892334	recon_loss: 0.024113425984978676	bpp_loss: 2.9091196060180664	aux_loss: 0.28594881296157837
18:42:20 INFO - main: Train iter. 168100/200000 (84.05%): 	Loss: 3.625720977783203	recon_loss: 0.02411927655339241	bpp_loss: 2.9021427631378174	aux_loss: 0.7942712306976318
18:42:38 INFO - main: Train iter. 168200/200000 (84.1%): 	Loss: 3.6251282691955566	recon_loss: 0.02403629757463932	bpp_loss: 2.9040393829345703	aux_loss: 0.22233426570892334
18:42:55 INFO - main: Train iter. 168300/200000 (84.15%): 	Loss: 3.634880304336548	recon_loss: 0.024130966514348984	bpp_loss: 2.9109513759613037	aux_loss: 0.7377153635025024
18:43:13 INFO - main: Train iter. 168400/200000 (84.2%): 	Loss: 3.62857723236084	recon_loss: 0.02411011978983879	bpp_loss: 2.905273675918579	aux_loss: 0.4891263246536255
18:43:31 INFO - main: Train iter. 168500/200000 (84.25%): 	Loss: 3.6101765632629395	recon_loss: 0.02401752956211567	bpp_loss: 2.889650821685791	aux_loss: 0.710412323474884
18:43:48 INFO - main: Train iter. 168600/200000 (84.3%): 	Loss: 3.6329712867736816	recon_loss: 0.0241601150482893	bpp_loss: 2.908167839050293	aux_loss: 0.458917498588562
18:44:06 INFO - main: Train iter. 168700/200000 (84.35%): 	Loss: 3.636522054672241	recon_loss: 0.024195455014705658	bpp_loss: 2.910658359527588	aux_loss: 0.8457657098770142
18:44:24 INFO - main: Train iter. 168800/200000 (84.4%): 	Loss: 3.6291561126708984	recon_loss: 0.024133045226335526	bpp_loss: 2.9051647186279297	aux_loss: 0.8171416521072388
18:44:41 INFO - main: Train iter. 168900/200000 (84.45%): 	Loss: 3.613528251647949	recon_loss: 0.024015231058001518	bpp_loss: 2.893071413040161	aux_loss: 0.24333402514457703
18:44:59 INFO - main: Train iter. 169000/200000 (84.5%): 	Loss: 3.62579607963562	recon_loss: 0.024137740954756737	bpp_loss: 2.9016637802124023	aux_loss: 0.8890281319618225
18:45:16 INFO - main: Train iter. 169100/200000 (84.55%): 	Loss: 3.6219587326049805	recon_loss: 0.024094007909297943	bpp_loss: 2.8991384506225586	aux_loss: 0.6389786005020142
18:45:34 INFO - main: Train iter. 169200/200000 (84.6%): 	Loss: 3.6128129959106445	recon_loss: 0.024055182933807373	bpp_loss: 2.891157388687134	aux_loss: 0.38702431321144104
18:45:52 INFO - main: Train iter. 169300/200000 (84.65%): 	Loss: 3.637911558151245	recon_loss: 0.024135373532772064	bpp_loss: 2.9138503074645996	aux_loss: 0.6727359294891357
18:46:09 INFO - main: Train iter. 169400/200000 (84.7%): 	Loss: 3.606869697570801	recon_loss: 0.024000734090805054	bpp_loss: 2.886847734451294	aux_loss: 0.4044521152973175
18:46:27 INFO - main: Train iter. 169500/200000 (84.75%): 	Loss: 3.6294937133789062	recon_loss: 0.024107802659273148	bpp_loss: 2.906259536743164	aux_loss: 0.23204752802848816
18:46:45 INFO - main: Train iter. 169600/200000 (84.8%): 	Loss: 3.6141061782836914	recon_loss: 0.02403981052339077	bpp_loss: 2.892911911010742	aux_loss: 0.3709675371646881
18:47:05 INFO - main: Train iter. 169700/200000 (84.85%): 	Loss: 3.647726535797119	recon_loss: 0.024217015132308006	bpp_loss: 2.9212160110473633	aux_loss: 1.3110809326171875
18:47:23 INFO - main: Train iter. 169800/200000 (84.9%): 	Loss: 3.628070831298828	recon_loss: 0.02408849075436592	bpp_loss: 2.9054160118103027	aux_loss: 0.14966252446174622
18:47:40 INFO - main: Train iter. 169900/200000 (84.95%): 	Loss: 3.6354763507843018	recon_loss: 0.02412058413028717	bpp_loss: 2.9118587970733643	aux_loss: 0.6215775609016418
18:47:58 INFO - main: Train iter. 170000/200000 (85.0%): 	Loss: 3.6176223754882812	recon_loss: 0.02401176653802395	bpp_loss: 2.8972694873809814	aux_loss: 0.5314952731132507
18:48:08 INFO - main: {'TEST MSE': 0.024090366167146292, 'TEST BPP': 2.9535, 'TEST loss': 3.6274989953041077, 'TEST recon_loss': 0.024090366074815392, 'TEST bpp_loss': 2.9047880198955536}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:48:25 INFO - main: Train iter. 170100/200000 (85.05%): 	Loss: 3.6147868633270264	recon_loss: 0.024014782160520554	bpp_loss: 2.894343376159668	aux_loss: 0.8104085326194763
18:48:43 INFO - main: Train iter. 170200/200000 (85.1%): 	Loss: 3.6265554428100586	recon_loss: 0.024066057056188583	bpp_loss: 2.904573678970337	aux_loss: 0.4548243284225464
18:49:01 INFO - main: Train iter. 170300/200000 (85.15%): 	Loss: 3.6136474609375	recon_loss: 0.024026993662118912	bpp_loss: 2.8928375244140625	aux_loss: 0.3772926330566406
18:49:18 INFO - main: Train iter. 170400/200000 (85.2%): 	Loss: 3.6188087463378906	recon_loss: 0.024045847356319427	bpp_loss: 2.897433280944824	aux_loss: 0.7493249773979187
18:49:36 INFO - main: Train iter. 170500/200000 (85.25%): 	Loss: 3.6268954277038574	recon_loss: 0.02411910519003868	bpp_loss: 2.903322219848633	aux_loss: 0.2827882170677185
18:49:53 INFO - main: Train iter. 170600/200000 (85.3%): 	Loss: 3.622312545776367	recon_loss: 0.024094615131616592	bpp_loss: 2.8994741439819336	aux_loss: 0.25991129875183105
18:50:11 INFO - main: Train iter. 170700/200000 (85.35%): 	Loss: 3.6352968215942383	recon_loss: 0.024187611415982246	bpp_loss: 2.909668445587158	aux_loss: 0.4388238787651062
18:50:29 INFO - main: Train iter. 170800/200000 (85.4%): 	Loss: 3.6190285682678223	recon_loss: 0.02402592822909355	bpp_loss: 2.8982508182525635	aux_loss: 0.8570448756217957
18:50:46 INFO - main: Train iter. 170900/200000 (85.45%): 	Loss: 3.624398708343506	recon_loss: 0.024118546396493912	bpp_loss: 2.9008424282073975	aux_loss: 0.9669504761695862
18:51:04 INFO - main: Train iter. 171000/200000 (85.5%): 	Loss: 3.6123015880584717	recon_loss: 0.024025702849030495	bpp_loss: 2.8915305137634277	aux_loss: 0.40114808082580566
18:51:22 INFO - main: Train iter. 171100/200000 (85.55%): 	Loss: 3.6253645420074463	recon_loss: 0.024054042994976044	bpp_loss: 2.903743267059326	aux_loss: 0.2543320655822754
18:51:39 INFO - main: Train iter. 171200/200000 (85.6%): 	Loss: 3.6231093406677246	recon_loss: 0.02407737448811531	bpp_loss: 2.9007880687713623	aux_loss: 0.22678139805793762
18:51:57 INFO - main: Train iter. 171300/200000 (85.65%): 	Loss: 3.6264774799346924	recon_loss: 0.02408023551106453	bpp_loss: 2.9040703773498535	aux_loss: 0.23275019228458405
18:52:15 INFO - main: Train iter. 171400/200000 (85.7%): 	Loss: 3.6297059059143066	recon_loss: 0.024111982434988022	bpp_loss: 2.906346559524536	aux_loss: 0.605975329875946
18:52:32 INFO - main: Train iter. 171500/200000 (85.75%): 	Loss: 3.6205034255981445	recon_loss: 0.02402423694729805	bpp_loss: 2.8997764587402344	aux_loss: 0.23979441821575165
18:52:50 INFO - main: Train iter. 171600/200000 (85.8%): 	Loss: 3.6246883869171143	recon_loss: 0.02412026934325695	bpp_loss: 2.901080369949341	aux_loss: 0.2625434398651123
18:53:08 INFO - main: Train iter. 171700/200000 (85.85%): 	Loss: 3.612705707550049	recon_loss: 0.024028686806559563	bpp_loss: 2.891845226287842	aux_loss: 0.7551641464233398
18:53:25 INFO - main: Train iter. 171800/200000 (85.9%): 	Loss: 3.617828369140625	recon_loss: 0.02398747391998768	bpp_loss: 2.8982040882110596	aux_loss: 1.241263508796692
18:53:43 INFO - main: Train iter. 171900/200000 (85.95%): 	Loss: 3.6479480266571045	recon_loss: 0.024220619350671768	bpp_loss: 2.9213294982910156	aux_loss: 0.22791039943695068
18:54:01 INFO - main: Train iter. 172000/200000 (86.0%): 	Loss: 3.6081299781799316	recon_loss: 0.023962611332535744	bpp_loss: 2.889251708984375	aux_loss: 0.35070717334747314
18:54:19 INFO - main: Train iter. 172100/200000 (86.05%): 	Loss: 3.633312940597534	recon_loss: 0.024131672456860542	bpp_loss: 2.90936279296875	aux_loss: 0.5985391736030579
18:54:36 INFO - main: Train iter. 172200/200000 (86.1%): 	Loss: 3.6195297241210938	recon_loss: 0.02406584657728672	bpp_loss: 2.897554397583008	aux_loss: 0.2237095981836319
18:54:54 INFO - main: Train iter. 172300/200000 (86.15%): 	Loss: 3.6226210594177246	recon_loss: 0.024076534435153008	bpp_loss: 2.900325059890747	aux_loss: 0.65082186460495
18:55:12 INFO - main: Train iter. 172400/200000 (86.2%): 	Loss: 3.6282901763916016	recon_loss: 0.024065744131803513	bpp_loss: 2.906317949295044	aux_loss: 0.28080523014068604
18:55:29 INFO - main: Train iter. 172500/200000 (86.25%): 	Loss: 3.613220453262329	recon_loss: 0.024048926308751106	bpp_loss: 2.8917527198791504	aux_loss: 0.28209125995635986
18:55:47 INFO - main: Train iter. 172600/200000 (86.3%): 	Loss: 3.6296896934509277	recon_loss: 0.02407589927315712	bpp_loss: 2.9074127674102783	aux_loss: 0.20456364750862122
18:56:05 INFO - main: Train iter. 172700/200000 (86.35%): 	Loss: 3.619947910308838	recon_loss: 0.024067271500825882	bpp_loss: 2.8979299068450928	aux_loss: 0.4427596926689148
18:56:22 INFO - main: Train iter. 172800/200000 (86.4%): 	Loss: 3.633882522583008	recon_loss: 0.02417212352156639	bpp_loss: 2.9087188243865967	aux_loss: 0.3995569348335266
18:56:40 INFO - main: Train iter. 172900/200000 (86.45%): 	Loss: 3.608678102493286	recon_loss: 0.024016834795475006	bpp_loss: 2.8881731033325195	aux_loss: 0.24196144938468933
18:56:58 INFO - main: Train iter. 173000/200000 (86.5%): 	Loss: 3.6434011459350586	recon_loss: 0.024175725877285004	bpp_loss: 2.9181294441223145	aux_loss: 0.4908107817173004
18:57:18 INFO - main: Train iter. 173100/200000 (86.55%): 	Loss: 3.631338596343994	recon_loss: 0.024090446531772614	bpp_loss: 2.9086251258850098	aux_loss: 1.193366527557373
18:57:36 INFO - main: Train iter. 173200/200000 (86.6%): 	Loss: 3.6250336170196533	recon_loss: 0.024053039029240608	bpp_loss: 2.9034423828125	aux_loss: 0.43553102016448975
18:57:53 INFO - main: Train iter. 173300/200000 (86.65%): 	Loss: 3.6295318603515625	recon_loss: 0.024093614891171455	bpp_loss: 2.9067234992980957	aux_loss: 0.2803146243095398
18:58:11 INFO - main: Train iter. 173400/200000 (86.7%): 	Loss: 3.6279616355895996	recon_loss: 0.02407257817685604	bpp_loss: 2.9057843685150146	aux_loss: 1.097618818283081
18:58:29 INFO - main: Train iter. 173500/200000 (86.75%): 	Loss: 3.616004467010498	recon_loss: 0.024023791775107384	bpp_loss: 2.8952908515930176	aux_loss: 0.24063464999198914
18:58:46 INFO - main: Train iter. 173600/200000 (86.8%): 	Loss: 3.6321921348571777	recon_loss: 0.02414594776928425	bpp_loss: 2.907813787460327	aux_loss: 0.31903332471847534
18:59:04 INFO - main: Train iter. 173700/200000 (86.85%): 	Loss: 3.6387479305267334	recon_loss: 0.024175595492124557	bpp_loss: 2.913480043411255	aux_loss: 0.3672855496406555
18:59:22 INFO - main: Train iter. 173800/200000 (86.9%): 	Loss: 3.6343491077423096	recon_loss: 0.024158308282494545	bpp_loss: 2.909599781036377	aux_loss: 0.21271272003650665
18:59:39 INFO - main: Train iter. 173900/200000 (86.95%): 	Loss: 3.6212728023529053	recon_loss: 0.024053944274783134	bpp_loss: 2.8996543884277344	aux_loss: 0.29935166239738464
18:59:57 INFO - main: Train iter. 174000/200000 (87.0%): 	Loss: 3.6338930130004883	recon_loss: 0.024157602339982986	bpp_loss: 2.9091649055480957	aux_loss: 0.565667450428009
19:00:15 INFO - main: Train iter. 174100/200000 (87.05%): 	Loss: 3.632648468017578	recon_loss: 0.02416033111512661	bpp_loss: 2.9078385829925537	aux_loss: 0.23459839820861816
19:00:32 INFO - main: Train iter. 174200/200000 (87.1%): 	Loss: 3.6391677856445312	recon_loss: 0.024145396426320076	bpp_loss: 2.9148058891296387	aux_loss: 0.5328121781349182
19:00:50 INFO - main: Train iter. 174300/200000 (87.15%): 	Loss: 3.6311838626861572	recon_loss: 0.024095894768834114	bpp_loss: 2.9083070755004883	aux_loss: 0.5659329295158386
19:01:07 INFO - main: Train iter. 174400/200000 (87.2%): 	Loss: 3.622608184814453	recon_loss: 0.024059021845459938	bpp_loss: 2.9008374214172363	aux_loss: 0.6090092658996582
19:01:25 INFO - main: Train iter. 174500/200000 (87.25%): 	Loss: 3.6216187477111816	recon_loss: 0.02404661662876606	bpp_loss: 2.9002203941345215	aux_loss: 0.20220288634300232
19:01:43 INFO - main: Train iter. 174600/200000 (87.3%): 	Loss: 3.6220338344573975	recon_loss: 0.024053622037172318	bpp_loss: 2.9004251956939697	aux_loss: 0.16671127080917358
19:02:00 INFO - main: Train iter. 174700/200000 (87.35%): 	Loss: 3.6309499740600586	recon_loss: 0.024104900658130646	bpp_loss: 2.9078028202056885	aux_loss: 0.42193275690078735
19:02:18 INFO - main: Train iter. 174800/200000 (87.4%): 	Loss: 3.6222431659698486	recon_loss: 0.024076448753476143	bpp_loss: 2.899949789047241	aux_loss: 0.649806797504425
19:02:36 INFO - main: Train iter. 174900/200000 (87.45%): 	Loss: 3.608379364013672	recon_loss: 0.023994609713554382	bpp_loss: 2.8885412216186523	aux_loss: 0.37176358699798584
19:02:53 INFO - main: Train iter. 175000/200000 (87.5%): 	Loss: 3.6318142414093018	recon_loss: 0.024093320593237877	bpp_loss: 2.9090147018432617	aux_loss: 0.2613295912742615
19:03:03 INFO - main: {'TEST MSE': 0.02406758748652518, 'TEST BPP': 2.954, 'TEST loss': 3.627583503961563, 'TEST recon_loss': 0.024067587409168482, 'TEST bpp_loss': 2.905555883407593}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:03:21 INFO - main: Train iter. 175100/200000 (87.55%): 	Loss: 3.6343185901641846	recon_loss: 0.024160195142030716	bpp_loss: 2.909512758255005	aux_loss: 0.49382978677749634
19:03:38 INFO - main: Train iter. 175200/200000 (87.6%): 	Loss: 3.6350257396698	recon_loss: 0.0241218414157629	bpp_loss: 2.9113705158233643	aux_loss: 0.2391987144947052
19:03:56 INFO - main: Train iter. 175300/200000 (87.65%): 	Loss: 3.635183811187744	recon_loss: 0.02417188137769699	bpp_loss: 2.910027503967285	aux_loss: 0.35956716537475586
19:04:13 INFO - main: Train iter. 175400/200000 (87.7%): 	Loss: 3.6355457305908203	recon_loss: 0.02417805604636669	bpp_loss: 2.9102039337158203	aux_loss: 0.40966475009918213
19:04:31 INFO - main: Train iter. 175500/200000 (87.75%): 	Loss: 3.6333391666412354	recon_loss: 0.02413526363670826	bpp_loss: 2.9092812538146973	aux_loss: 0.24962641298770905
19:04:48 INFO - main: Train iter. 175600/200000 (87.8%): 	Loss: 3.639498233795166	recon_loss: 0.024191997945308685	bpp_loss: 2.913738250732422	aux_loss: 0.25084295868873596
19:05:06 INFO - main: Train iter. 175700/200000 (87.85%): 	Loss: 3.63016939163208	recon_loss: 0.024134930223226547	bpp_loss: 2.9061214923858643	aux_loss: 0.4270718991756439
19:05:24 INFO - main: Train iter. 175800/200000 (87.9%): 	Loss: 3.6284985542297363	recon_loss: 0.024106357246637344	bpp_loss: 2.9053077697753906	aux_loss: 0.4439883232116699
19:05:41 INFO - main: Train iter. 175900/200000 (87.95%): 	Loss: 3.627361297607422	recon_loss: 0.024112138897180557	bpp_loss: 2.9039971828460693	aux_loss: 0.25439202785491943
19:05:59 INFO - main: Train iter. 176000/200000 (88.0%): 	Loss: 3.6274232864379883	recon_loss: 0.0240833330899477	bpp_loss: 2.9049232006073	aux_loss: 0.2728220820426941
19:06:16 INFO - main: Train iter. 176100/200000 (88.05%): 	Loss: 3.646969795227051	recon_loss: 0.024268461391329765	bpp_loss: 2.9189159870147705	aux_loss: 0.8788595199584961
19:06:34 INFO - main: Train iter. 176200/200000 (88.1%): 	Loss: 3.6325161457061768	recon_loss: 0.024153802543878555	bpp_loss: 2.9079020023345947	aux_loss: 0.36001136898994446
19:06:52 INFO - main: Train iter. 176300/200000 (88.15%): 	Loss: 3.6183509826660156	recon_loss: 0.0240402203053236	bpp_loss: 2.897144317626953	aux_loss: 0.2659373879432678
19:07:12 INFO - main: Train iter. 176400/200000 (88.2%): 	Loss: 3.615417242050171	recon_loss: 0.02402627281844616	bpp_loss: 2.8946290016174316	aux_loss: 0.21984735131263733
19:07:30 INFO - main: Train iter. 176500/200000 (88.25%): 	Loss: 3.620814561843872	recon_loss: 0.02402874454855919	bpp_loss: 2.8999521732330322	aux_loss: 0.3811613917350769
19:07:47 INFO - main: Train iter. 176600/200000 (88.3%): 	Loss: 3.629611015319824	recon_loss: 0.024093247950077057	bpp_loss: 2.906813621520996	aux_loss: 0.987747311592102
19:08:05 INFO - main: Train iter. 176700/200000 (88.35%): 	Loss: 3.6277694702148438	recon_loss: 0.024066539481282234	bpp_loss: 2.905773401260376	aux_loss: 0.31299516558647156
19:08:23 INFO - main: Train iter. 176800/200000 (88.4%): 	Loss: 3.628847122192383	recon_loss: 0.0241241492331028	bpp_loss: 2.905122756958008	aux_loss: 0.31341010332107544
19:08:40 INFO - main: Train iter. 176900/200000 (88.45%): 	Loss: 3.6120078563690186	recon_loss: 0.02397892251610756	bpp_loss: 2.8926401138305664	aux_loss: 0.5739689469337463
19:08:58 INFO - main: Train iter. 177000/200000 (88.5%): 	Loss: 3.640763998031616	recon_loss: 0.024168075993657112	bpp_loss: 2.9157216548919678	aux_loss: 0.21278682351112366
19:09:16 INFO - main: Train iter. 177100/200000 (88.55%): 	Loss: 3.6196460723876953	recon_loss: 0.024047166109085083	bpp_loss: 2.898231029510498	aux_loss: 0.4674105644226074
19:09:33 INFO - main: Train iter. 177200/200000 (88.6%): 	Loss: 3.6339855194091797	recon_loss: 0.02414337359368801	bpp_loss: 2.909684419631958	aux_loss: 0.25166141986846924
19:09:51 INFO - main: Train iter. 177300/200000 (88.65%): 	Loss: 3.6311123371124268	recon_loss: 0.02408636175096035	bpp_loss: 2.9085214138031006	aux_loss: 0.549294650554657
19:10:08 INFO - main: Train iter. 177400/200000 (88.7%): 	Loss: 3.637155532836914	recon_loss: 0.024161282926797867	bpp_loss: 2.9123170375823975	aux_loss: 0.31370675563812256
19:10:26 INFO - main: Train iter. 177500/200000 (88.75%): 	Loss: 3.6185507774353027	recon_loss: 0.024073995649814606	bpp_loss: 2.8963308334350586	aux_loss: 0.22683849930763245
19:10:44 INFO - main: Train iter. 177600/200000 (88.8%): 	Loss: 3.6185407638549805	recon_loss: 0.02403484471142292	bpp_loss: 2.8974955081939697	aux_loss: 0.32470497488975525
19:11:01 INFO - main: Train iter. 177700/200000 (88.85%): 	Loss: 3.6252431869506836	recon_loss: 0.024058226495981216	bpp_loss: 2.903496265411377	aux_loss: 0.28882235288619995
19:11:19 INFO - main: Train iter. 177800/200000 (88.9%): 	Loss: 3.64279842376709	recon_loss: 0.024126699194312096	bpp_loss: 2.9189975261688232	aux_loss: 1.8531242609024048
19:11:37 INFO - main: Train iter. 177900/200000 (88.95%): 	Loss: 3.6356289386749268	recon_loss: 0.02413187175989151	bpp_loss: 2.911672830581665	aux_loss: 0.1934058964252472
19:11:54 INFO - main: Train iter. 178000/200000 (89.0%): 	Loss: 3.6266212463378906	recon_loss: 0.024092858657240868	bpp_loss: 2.9038355350494385	aux_loss: 0.5453522801399231
19:12:12 INFO - main: Train iter. 178100/200000 (89.05%): 	Loss: 3.628293514251709	recon_loss: 0.024093041196465492	bpp_loss: 2.9055023193359375	aux_loss: 0.3617904782295227
19:12:30 INFO - main: Train iter. 178200/200000 (89.1%): 	Loss: 3.632521390914917	recon_loss: 0.024100923910737038	bpp_loss: 2.9094936847686768	aux_loss: 0.3759613633155823
19:12:48 INFO - main: Train iter. 178300/200000 (89.15%): 	Loss: 3.6356420516967773	recon_loss: 0.024128727614879608	bpp_loss: 2.91178035736084	aux_loss: 0.3186678886413574
19:13:05 INFO - main: Train iter. 178400/200000 (89.2%): 	Loss: 3.6393675804138184	recon_loss: 0.024193862453103065	bpp_loss: 2.9135518074035645	aux_loss: 0.26281237602233887
19:13:23 INFO - main: Train iter. 178500/200000 (89.25%): 	Loss: 3.6280667781829834	recon_loss: 0.024098973721265793	bpp_loss: 2.905097484588623	aux_loss: 0.20270410180091858
19:13:40 INFO - main: Train iter. 178600/200000 (89.3%): 	Loss: 3.6375458240509033	recon_loss: 0.024068929255008698	bpp_loss: 2.915477991104126	aux_loss: 0.30889007449150085
19:13:58 INFO - main: Train iter. 178700/200000 (89.35%): 	Loss: 3.6336355209350586	recon_loss: 0.024127159267663956	bpp_loss: 2.909820795059204	aux_loss: 0.2034449279308319
19:14:16 INFO - main: Train iter. 178800/200000 (89.4%): 	Loss: 3.625283718109131	recon_loss: 0.024110455065965652	bpp_loss: 2.901970148086548	aux_loss: 0.5704969167709351
19:14:33 INFO - main: Train iter. 178900/200000 (89.45%): 	Loss: 3.6310129165649414	recon_loss: 0.024091914296150208	bpp_loss: 2.9082555770874023	aux_loss: 0.233027845621109
19:14:51 INFO - main: Train iter. 179000/200000 (89.5%): 	Loss: 3.6258020401000977	recon_loss: 0.024067629128694534	bpp_loss: 2.903773307800293	aux_loss: 0.23146873712539673
19:15:09 INFO - main: Train iter. 179100/200000 (89.55%): 	Loss: 3.640245199203491	recon_loss: 0.02420167066156864	bpp_loss: 2.9141950607299805	aux_loss: 0.35397231578826904
19:15:27 INFO - main: Train iter. 179200/200000 (89.6%): 	Loss: 3.6335182189941406	recon_loss: 0.024156412109732628	bpp_loss: 2.9088258743286133	aux_loss: 0.4958198070526123
19:15:45 INFO - main: Train iter. 179300/200000 (89.65%): 	Loss: 3.623277187347412	recon_loss: 0.024058092385530472	bpp_loss: 2.90153431892395	aux_loss: 0.43182653188705444
19:16:02 INFO - main: Train iter. 179400/200000 (89.7%): 	Loss: 3.630549192428589	recon_loss: 0.024093978106975555	bpp_loss: 2.9077298641204834	aux_loss: 0.206356942653656
19:16:20 INFO - main: Train iter. 179500/200000 (89.75%): 	Loss: 3.6278536319732666	recon_loss: 0.024084387347102165	bpp_loss: 2.9053220748901367	aux_loss: 0.41870781779289246
19:16:38 INFO - main: Train iter. 179600/200000 (89.8%): 	Loss: 3.6334598064422607	recon_loss: 0.024083834141492844	bpp_loss: 2.910944700241089	aux_loss: 0.3305811285972595
19:16:58 INFO - main: Train iter. 179700/200000 (89.85%): 	Loss: 3.624528169631958	recon_loss: 0.02406654879450798	bpp_loss: 2.902531623840332	aux_loss: 1.2874289751052856
19:17:15 INFO - main: Train iter. 179800/200000 (89.9%): 	Loss: 3.6217305660247803	recon_loss: 0.02406761422753334	bpp_loss: 2.8997020721435547	aux_loss: 0.371623158454895
19:17:33 INFO - main: Train iter. 179900/200000 (89.95%): 	Loss: 3.63277530670166	recon_loss: 0.02408507838845253	bpp_loss: 2.9102230072021484	aux_loss: 0.45599043369293213
19:17:51 INFO - main: Train iter. 180000/200000 (90.0%): 	Loss: 3.6228575706481934	recon_loss: 0.024035939946770668	bpp_loss: 2.9017794132232666	aux_loss: 0.924008846282959
19:18:00 INFO - main: {'TEST MSE': 0.024118459296075447, 'TEST BPP': 2.95253125, 'TEST loss': 3.6276922707557677, 'TEST recon_loss': 0.02411845920793712, 'TEST bpp_loss': 2.904138486623764}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:18:18 INFO - main: Train iter. 180100/200000 (90.05%): 	Loss: 3.6244194507598877	recon_loss: 0.024039825424551964	bpp_loss: 2.9032247066497803	aux_loss: 0.7396595478057861
19:18:36 INFO - main: Train iter. 180200/200000 (90.1%): 	Loss: 3.6242222785949707	recon_loss: 0.02407987043261528	bpp_loss: 2.9018261432647705	aux_loss: 0.24752196669578552
19:18:53 INFO - main: Train iter. 180300/200000 (90.15%): 	Loss: 3.617518901824951	recon_loss: 0.024066131561994553	bpp_loss: 2.8955349922180176	aux_loss: 0.40689176321029663
19:19:11 INFO - main: Train iter. 180400/200000 (90.2%): 	Loss: 3.6322038173675537	recon_loss: 0.02408767305314541	bpp_loss: 2.909573554992676	aux_loss: 0.4669433534145355
19:19:28 INFO - main: Train iter. 180500/200000 (90.25%): 	Loss: 3.6201975345611572	recon_loss: 0.02403104119002819	bpp_loss: 2.899266242980957	aux_loss: 0.1526023894548416
19:19:46 INFO - main: Train iter. 180600/200000 (90.3%): 	Loss: 3.6418585777282715	recon_loss: 0.024210643023252487	bpp_loss: 2.915539264678955	aux_loss: 0.5290029048919678
19:20:03 INFO - main: Train iter. 180700/200000 (90.35%): 	Loss: 3.639801502227783	recon_loss: 0.02417094260454178	bpp_loss: 2.914673089981079	aux_loss: 0.2113240659236908
19:20:21 INFO - main: Train iter. 180800/200000 (90.4%): 	Loss: 3.646543264389038	recon_loss: 0.024227015674114227	bpp_loss: 2.9197328090667725	aux_loss: 0.22078387439250946
19:20:39 INFO - main: Train iter. 180900/200000 (90.45%): 	Loss: 3.624706983566284	recon_loss: 0.024089502170681953	bpp_loss: 2.902021884918213	aux_loss: 0.3567948639392853
19:20:56 INFO - main: Train iter. 181000/200000 (90.5%): 	Loss: 3.6338634490966797	recon_loss: 0.024123499169945717	bpp_loss: 2.910158395767212	aux_loss: 0.26161932945251465
19:21:14 INFO - main: Train iter. 181100/200000 (90.55%): 	Loss: 3.629883050918579	recon_loss: 0.024096041917800903	bpp_loss: 2.9070017337799072	aux_loss: 0.24477757513523102
19:21:31 INFO - main: Train iter. 181200/200000 (90.6%): 	Loss: 3.6322615146636963	recon_loss: 0.024126585572957993	bpp_loss: 2.908463954925537	aux_loss: 0.2945086359977722
19:21:49 INFO - main: Train iter. 181300/200000 (90.65%): 	Loss: 3.630258083343506	recon_loss: 0.02414187788963318	bpp_loss: 2.9060018062591553	aux_loss: 0.3660677671432495
19:22:07 INFO - main: Train iter. 181400/200000 (90.7%): 	Loss: 3.6362199783325195	recon_loss: 0.024126475676894188	bpp_loss: 2.9124257564544678	aux_loss: 0.6387320160865784
19:22:24 INFO - main: Train iter. 181500/200000 (90.75%): 	Loss: 3.6245808601379395	recon_loss: 0.024118216708302498	bpp_loss: 2.901034355163574	aux_loss: 0.23546341061592102
19:22:42 INFO - main: Train iter. 181600/200000 (90.8%): 	Loss: 3.6162972450256348	recon_loss: 0.024029862135648727	bpp_loss: 2.8954014778137207	aux_loss: 0.9445487260818481
19:23:00 INFO - main: Train iter. 181700/200000 (90.85%): 	Loss: 3.6171326637268066	recon_loss: 0.024034248664975166	bpp_loss: 2.8961052894592285	aux_loss: 0.2657303810119629
19:23:17 INFO - main: Train iter. 181800/200000 (90.9%): 	Loss: 3.6285626888275146	recon_loss: 0.024058276787400246	bpp_loss: 2.9068143367767334	aux_loss: 0.36222320795059204
19:23:35 INFO - main: Train iter. 181900/200000 (90.95%): 	Loss: 3.6321139335632324	recon_loss: 0.024092601612210274	bpp_loss: 2.9093358516693115	aux_loss: 0.24308697879314423
19:23:53 INFO - main: Train iter. 182000/200000 (91.0%): 	Loss: 3.630319118499756	recon_loss: 0.024073662236332893	bpp_loss: 2.908109188079834	aux_loss: 0.5764697194099426
19:24:10 INFO - main: Train iter. 182100/200000 (91.05%): 	Loss: 3.638909339904785	recon_loss: 0.024163881316781044	bpp_loss: 2.9139928817749023	aux_loss: 0.17758148908615112
19:24:28 INFO - main: Train iter. 182200/200000 (91.1%): 	Loss: 3.6348257064819336	recon_loss: 0.024090534076094627	bpp_loss: 2.912109613418579	aux_loss: 0.9443695545196533
19:24:46 INFO - main: Train iter. 182300/200000 (91.15%): 	Loss: 3.632894277572632	recon_loss: 0.02409650757908821	bpp_loss: 2.909999132156372	aux_loss: 0.31934046745300293
19:25:03 INFO - main: Train iter. 182400/200000 (91.2%): 	Loss: 3.623975992202759	recon_loss: 0.02408159337937832	bpp_loss: 2.9015281200408936	aux_loss: 0.4189937710762024
19:25:21 INFO - main: Train iter. 182500/200000 (91.25%): 	Loss: 3.613595724105835	recon_loss: 0.024047480896115303	bpp_loss: 2.8921713829040527	aux_loss: 0.7838711738586426
19:25:39 INFO - main: Train iter. 182600/200000 (91.3%): 	Loss: 3.6134438514709473	recon_loss: 0.02402079477906227	bpp_loss: 2.892820119857788	aux_loss: 0.6106438636779785
19:25:56 INFO - main: Train iter. 182700/200000 (91.35%): 	Loss: 3.615532159805298	recon_loss: 0.024020615965127945	bpp_loss: 2.894913673400879	aux_loss: 0.25726884603500366
19:26:14 INFO - main: Train iter. 182800/200000 (91.4%): 	Loss: 3.632478713989258	recon_loss: 0.024103490635752678	bpp_loss: 2.9093739986419678	aux_loss: 0.2552800178527832
19:26:32 INFO - main: Train iter. 182900/200000 (91.45%): 	Loss: 3.624232292175293	recon_loss: 0.02412446215748787	bpp_loss: 2.900498390197754	aux_loss: 0.4513934850692749
19:26:52 INFO - main: Train iter. 183000/200000 (91.5%): 	Loss: 3.621575117111206	recon_loss: 0.024066146463155746	bpp_loss: 2.8995907306671143	aux_loss: 0.4055856466293335
19:27:10 INFO - main: Train iter. 183100/200000 (91.55%): 	Loss: 3.6356184482574463	recon_loss: 0.024139882996678352	bpp_loss: 2.91142201423645	aux_loss: 0.226919487118721
19:27:27 INFO - main: Train iter. 183200/200000 (91.6%): 	Loss: 3.6270790100097656	recon_loss: 0.024087820202112198	bpp_loss: 2.904444456100464	aux_loss: 0.28232547640800476
19:27:45 INFO - main: Train iter. 183300/200000 (91.65%): 	Loss: 3.6325926780700684	recon_loss: 0.024098986759781837	bpp_loss: 2.909623146057129	aux_loss: 0.8452504873275757
19:28:02 INFO - main: Train iter. 183400/200000 (91.7%): 	Loss: 3.646235227584839	recon_loss: 0.024185877293348312	bpp_loss: 2.920658826828003	aux_loss: 1.304019808769226
19:28:20 INFO - main: Train iter. 183500/200000 (91.75%): 	Loss: 3.617429733276367	recon_loss: 0.024064576253294945	bpp_loss: 2.8954923152923584	aux_loss: 1.0554208755493164
19:28:38 INFO - main: Train iter. 183600/200000 (91.8%): 	Loss: 3.626862049102783	recon_loss: 0.024094974622130394	bpp_loss: 2.904012680053711	aux_loss: 0.6982784271240234
19:28:55 INFO - main: Train iter. 183700/200000 (91.85%): 	Loss: 3.627986431121826	recon_loss: 0.02410489320755005	bpp_loss: 2.904839515686035	aux_loss: 0.47149527072906494
19:29:13 INFO - main: Train iter. 183800/200000 (91.9%): 	Loss: 3.628757953643799	recon_loss: 0.02410029247403145	bpp_loss: 2.9057490825653076	aux_loss: 0.5493841171264648
19:29:30 INFO - main: Train iter. 183900/200000 (91.95%): 	Loss: 3.6294960975646973	recon_loss: 0.02410714700818062	bpp_loss: 2.9062817096710205	aux_loss: 0.20487582683563232
19:29:48 INFO - main: Train iter. 184000/200000 (92.0%): 	Loss: 3.618316411972046	recon_loss: 0.02405613847076893	bpp_loss: 2.896632194519043	aux_loss: 0.26812809705734253
19:30:06 INFO - main: Train iter. 184100/200000 (92.05%): 	Loss: 3.619518995285034	recon_loss: 0.024073481559753418	bpp_loss: 2.8973145484924316	aux_loss: 0.28093546628952026
19:30:23 INFO - main: Train iter. 184200/200000 (92.1%): 	Loss: 3.6215274333953857	recon_loss: 0.02404666133224964	bpp_loss: 2.900127649307251	aux_loss: 0.40068933367729187
19:30:41 INFO - main: Train iter. 184300/200000 (92.15%): 	Loss: 3.6368861198425293	recon_loss: 0.024135520681738853	bpp_loss: 2.91282057762146	aux_loss: 0.18418744206428528
19:30:59 INFO - main: Train iter. 184400/200000 (92.2%): 	Loss: 3.6204237937927246	recon_loss: 0.024051930755376816	bpp_loss: 2.8988659381866455	aux_loss: 0.7703351974487305
19:31:16 INFO - main: Train iter. 184500/200000 (92.25%): 	Loss: 3.6279337406158447	recon_loss: 0.024132071062922478	bpp_loss: 2.9039716720581055	aux_loss: 0.7430071234703064
19:31:34 INFO - main: Train iter. 184600/200000 (92.3%): 	Loss: 3.630528688430786	recon_loss: 0.024098016321659088	bpp_loss: 2.907588243484497	aux_loss: 0.18216444551944733
19:31:51 INFO - main: Train iter. 184700/200000 (92.35%): 	Loss: 3.6078438758850098	recon_loss: 0.023986537009477615	bpp_loss: 2.8882477283477783	aux_loss: 0.7923586368560791
19:32:09 INFO - main: Train iter. 184800/200000 (92.4%): 	Loss: 3.6057229042053223	recon_loss: 0.023963596671819687	bpp_loss: 2.886815071105957	aux_loss: 0.47518470883369446
19:32:27 INFO - main: Train iter. 184900/200000 (92.45%): 	Loss: 3.6287310123443604	recon_loss: 0.02418113313615322	bpp_loss: 2.903296947479248	aux_loss: 1.2782827615737915
19:32:44 INFO - main: Train iter. 185000/200000 (92.5%): 	Loss: 3.623717784881592	recon_loss: 0.024012213572859764	bpp_loss: 2.903351306915283	aux_loss: 0.3758482336997986
19:32:54 INFO - main: {'TEST MSE': 0.024063854872766282, 'TEST BPP': 2.9543125, 'TEST loss': 3.6275024762153625, 'TEST recon_loss': 0.02406385481543839, 'TEST bpp_loss': 2.9055868320465086}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:33:12 INFO - main: Train iter. 185100/200000 (92.55%): 	Loss: 3.6366920471191406	recon_loss: 0.024123866111040115	bpp_loss: 2.912976026535034	aux_loss: 0.6607666611671448
19:33:29 INFO - main: Train iter. 185200/200000 (92.6%): 	Loss: 3.629753589630127	recon_loss: 0.024107741191983223	bpp_loss: 2.9065213203430176	aux_loss: 0.6358131766319275
19:33:47 INFO - main: Train iter. 185300/200000 (92.65%): 	Loss: 3.6207661628723145	recon_loss: 0.024074941873550415	bpp_loss: 2.8985178470611572	aux_loss: 0.7021486759185791
19:34:04 INFO - main: Train iter. 185400/200000 (92.7%): 	Loss: 3.645439386367798	recon_loss: 0.02422667108476162	bpp_loss: 2.9186391830444336	aux_loss: 0.30275440216064453
19:34:22 INFO - main: Train iter. 185500/200000 (92.75%): 	Loss: 3.625037670135498	recon_loss: 0.02405787631869316	bpp_loss: 2.903301239013672	aux_loss: 0.2247805893421173
19:34:39 INFO - main: Train iter. 185600/200000 (92.8%): 	Loss: 3.647585153579712	recon_loss: 0.024233629927039146	bpp_loss: 2.920576333999634	aux_loss: 0.22701409459114075
19:34:57 INFO - main: Train iter. 185700/200000 (92.85%): 	Loss: 3.6321535110473633	recon_loss: 0.02414907142519951	bpp_loss: 2.907681465148926	aux_loss: 0.33558225631713867
19:35:14 INFO - main: Train iter. 185800/200000 (92.9%): 	Loss: 3.6291182041168213	recon_loss: 0.024119172245264053	bpp_loss: 2.905543088912964	aux_loss: 0.26075345277786255
19:35:32 INFO - main: Train iter. 185900/200000 (92.95%): 	Loss: 3.612215280532837	recon_loss: 0.024025756865739822	bpp_loss: 2.8914425373077393	aux_loss: 0.23069782555103302
19:35:50 INFO - main: Train iter. 186000/200000 (93.0%): 	Loss: 3.619682788848877	recon_loss: 0.024054808542132378	bpp_loss: 2.898038387298584	aux_loss: 0.3193773627281189
19:36:07 INFO - main: Train iter. 186100/200000 (93.05%): 	Loss: 3.6240711212158203	recon_loss: 0.02404787950217724	bpp_loss: 2.902634859085083	aux_loss: 0.41788461804389954
19:36:25 INFO - main: Train iter. 186200/200000 (93.1%): 	Loss: 3.621148109436035	recon_loss: 0.024034837260842323	bpp_loss: 2.9001028537750244	aux_loss: 0.4621811509132385
19:36:43 INFO - main: Train iter. 186300/200000 (93.15%): 	Loss: 3.6255664825439453	recon_loss: 0.024039342999458313	bpp_loss: 2.904386281967163	aux_loss: 0.38422977924346924
19:37:03 INFO - main: Train iter. 186400/200000 (93.2%): 	Loss: 3.6262707710266113	recon_loss: 0.024091515690088272	bpp_loss: 2.9035253524780273	aux_loss: 0.7541189789772034
19:37:21 INFO - main: Train iter. 186500/200000 (93.25%): 	Loss: 3.6393308639526367	recon_loss: 0.02418353222310543	bpp_loss: 2.913825035095215	aux_loss: 0.2695856988430023
19:37:38 INFO - main: Train iter. 186600/200000 (93.3%): 	Loss: 3.623915433883667	recon_loss: 0.024092253297567368	bpp_loss: 2.9011478424072266	aux_loss: 0.19617152214050293
19:37:56 INFO - main: Train iter. 186700/200000 (93.35%): 	Loss: 3.630220651626587	recon_loss: 0.024105826392769814	bpp_loss: 2.907045841217041	aux_loss: 0.2110794335603714
19:38:13 INFO - main: Train iter. 186800/200000 (93.4%): 	Loss: 3.6301259994506836	recon_loss: 0.024114549160003662	bpp_loss: 2.9066896438598633	aux_loss: 0.732069730758667
19:38:31 INFO - main: Train iter. 186900/200000 (93.45%): 	Loss: 3.6315195560455322	recon_loss: 0.02409442514181137	bpp_loss: 2.908686876296997	aux_loss: 0.6524419784545898
19:38:49 INFO - main: Train iter. 187000/200000 (93.5%): 	Loss: 3.6099064350128174	recon_loss: 0.02400791645050049	bpp_loss: 2.8896689414978027	aux_loss: 0.3006868064403534
19:39:06 INFO - main: Train iter. 187100/200000 (93.55%): 	Loss: 3.651524305343628	recon_loss: 0.024218931794166565	bpp_loss: 2.9249563217163086	aux_loss: 0.6680454015731812
19:39:24 INFO - main: Train iter. 187200/200000 (93.6%): 	Loss: 3.6292333602905273	recon_loss: 0.024087058380246162	bpp_loss: 2.9066216945648193	aux_loss: 0.33248835802078247
19:39:42 INFO - main: Train iter. 187300/200000 (93.65%): 	Loss: 3.6199913024902344	recon_loss: 0.024045178666710854	bpp_loss: 2.8986358642578125	aux_loss: 0.3314937949180603
19:39:59 INFO - main: Train iter. 187400/200000 (93.7%): 	Loss: 3.614013195037842	recon_loss: 0.02402382530272007	bpp_loss: 2.893298387527466	aux_loss: 0.2747246026992798
19:40:17 INFO - main: Train iter. 187500/200000 (93.75%): 	Loss: 3.6294422149658203	recon_loss: 0.024062717333436012	bpp_loss: 2.9075605869293213	aux_loss: 0.2651827037334442
19:40:35 INFO - main: Train iter. 187600/200000 (93.8%): 	Loss: 3.6212821006774902	recon_loss: 0.02407056838274002	bpp_loss: 2.899165153503418	aux_loss: 0.2727046012878418
19:40:52 INFO - main: Train iter. 187700/200000 (93.85%): 	Loss: 3.6355481147766113	recon_loss: 0.024164708331227303	bpp_loss: 2.910606861114502	aux_loss: 0.2849753797054291
19:41:10 INFO - main: Train iter. 187800/200000 (93.9%): 	Loss: 3.6241304874420166	recon_loss: 0.02408120408654213	bpp_loss: 2.9016942977905273	aux_loss: 0.45519834756851196
19:41:27 INFO - main: Train iter. 187900/200000 (93.95%): 	Loss: 3.6261913776397705	recon_loss: 0.02410328947007656	bpp_loss: 2.903092622756958	aux_loss: 0.2751258313655853
19:41:45 INFO - main: Train iter. 188000/200000 (94.0%): 	Loss: 3.631112575531006	recon_loss: 0.024109268561005592	bpp_loss: 2.907834529876709	aux_loss: 0.2683752775192261
19:42:03 INFO - main: Train iter. 188100/200000 (94.05%): 	Loss: 3.630190134048462	recon_loss: 0.024120396003127098	bpp_loss: 2.906578302383423	aux_loss: 0.17194175720214844
19:42:20 INFO - main: Train iter. 188200/200000 (94.1%): 	Loss: 3.6418755054473877	recon_loss: 0.024230584502220154	bpp_loss: 2.9149580001831055	aux_loss: 0.28456687927246094
19:42:38 INFO - main: Train iter. 188300/200000 (94.15%): 	Loss: 3.6112442016601562	recon_loss: 0.023971788585186005	bpp_loss: 2.8920905590057373	aux_loss: 0.48968306183815
19:42:56 INFO - main: Train iter. 188400/200000 (94.2%): 	Loss: 3.632007598876953	recon_loss: 0.02411237359046936	bpp_loss: 2.9086363315582275	aux_loss: 0.4298071265220642
19:43:13 INFO - main: Train iter. 188500/200000 (94.25%): 	Loss: 3.623399257659912	recon_loss: 0.024037133902311325	bpp_loss: 2.90228533744812	aux_loss: 0.18193203210830688
19:43:31 INFO - main: Train iter. 188600/200000 (94.3%): 	Loss: 3.6277780532836914	recon_loss: 0.024102039635181427	bpp_loss: 2.904716730117798	aux_loss: 0.639781653881073
19:43:49 INFO - main: Train iter. 188700/200000 (94.35%): 	Loss: 3.630769729614258	recon_loss: 0.024134041741490364	bpp_loss: 2.9067485332489014	aux_loss: 0.3924040198326111
19:44:07 INFO - main: Train iter. 188800/200000 (94.4%): 	Loss: 3.629362106323242	recon_loss: 0.024092333391308784	bpp_loss: 2.9065921306610107	aux_loss: 0.41710758209228516
19:44:24 INFO - main: Train iter. 188900/200000 (94.45%): 	Loss: 3.63191556930542	recon_loss: 0.02409474551677704	bpp_loss: 2.9090733528137207	aux_loss: 0.18876102566719055
19:44:42 INFO - main: Train iter. 189000/200000 (94.5%): 	Loss: 3.6370437145233154	recon_loss: 0.024148255586624146	bpp_loss: 2.9125959873199463	aux_loss: 0.43162721395492554
19:44:59 INFO - main: Train iter. 189100/200000 (94.55%): 	Loss: 3.626485824584961	recon_loss: 0.024050399661064148	bpp_loss: 2.9049739837646484	aux_loss: 0.2408917397260666
19:45:17 INFO - main: Train iter. 189200/200000 (94.6%): 	Loss: 3.6285512447357178	recon_loss: 0.024083325639367104	bpp_loss: 2.9060513973236084	aux_loss: 0.40920424461364746
19:45:35 INFO - main: Train iter. 189300/200000 (94.65%): 	Loss: 3.6135454177856445	recon_loss: 0.02396516501903534	bpp_loss: 2.894590377807617	aux_loss: 0.8538223505020142
19:45:52 INFO - main: Train iter. 189400/200000 (94.7%): 	Loss: 3.638209342956543	recon_loss: 0.024127312004566193	bpp_loss: 2.9143900871276855	aux_loss: 0.5072047710418701
19:46:10 INFO - main: Train iter. 189500/200000 (94.75%): 	Loss: 3.627526044845581	recon_loss: 0.024117551743984222	bpp_loss: 2.9039995670318604	aux_loss: 0.33954542875289917
19:46:27 INFO - main: Train iter. 189600/200000 (94.8%): 	Loss: 3.6194753646850586	recon_loss: 0.024086065590381622	bpp_loss: 2.896893262863159	aux_loss: 0.5305665731430054
19:46:48 INFO - main: Train iter. 189700/200000 (94.85%): 	Loss: 3.6106910705566406	recon_loss: 0.0240005049854517	bpp_loss: 2.8906760215759277	aux_loss: 0.35934096574783325
19:47:05 INFO - main: Train iter. 189800/200000 (94.9%): 	Loss: 3.6416878700256348	recon_loss: 0.024159755557775497	bpp_loss: 2.9168951511383057	aux_loss: 0.6970345973968506
19:47:23 INFO - main: Train iter. 189900/200000 (94.95%): 	Loss: 3.6177947521209717	recon_loss: 0.024051889777183533	bpp_loss: 2.896238088607788	aux_loss: 0.4118049740791321
19:47:40 INFO - main: Train iter. 190000/200000 (95.0%): 	Loss: 3.6203393936157227	recon_loss: 0.02398441731929779	bpp_loss: 2.9008069038391113	aux_loss: 0.7037690877914429
19:47:50 INFO - main: {'TEST MSE': 0.024066009895380776, 'TEST BPP': 2.9535625, 'TEST loss': 3.627349484205246, 'TEST recon_loss': 0.02406600980088115, 'TEST bpp_loss': 2.905369186401367}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:48:08 INFO - main: Train iter. 190100/200000 (95.05%): 	Loss: 3.602893352508545	recon_loss: 0.023929959163069725	bpp_loss: 2.8849945068359375	aux_loss: 0.5007612705230713
19:48:25 INFO - main: Train iter. 190200/200000 (95.1%): 	Loss: 3.6348283290863037	recon_loss: 0.024125918745994568	bpp_loss: 2.911050796508789	aux_loss: 0.39697733521461487
19:48:43 INFO - main: Train iter. 190300/200000 (95.15%): 	Loss: 3.629643440246582	recon_loss: 0.024133898317813873	bpp_loss: 2.9056265354156494	aux_loss: 0.24878674745559692
19:49:01 INFO - main: Train iter. 190400/200000 (95.2%): 	Loss: 3.6375651359558105	recon_loss: 0.02417485974729061	bpp_loss: 2.9123194217681885	aux_loss: 0.36853042244911194
19:49:18 INFO - main: Train iter. 190500/200000 (95.25%): 	Loss: 3.6271674633026123	recon_loss: 0.02408757247030735	bpp_loss: 2.9045403003692627	aux_loss: 0.25930917263031006
19:49:36 INFO - main: Train iter. 190600/200000 (95.3%): 	Loss: 3.641037940979004	recon_loss: 0.024173613637685776	bpp_loss: 2.915829658508301	aux_loss: 0.4248485565185547
19:49:53 INFO - main: Train iter. 190700/200000 (95.35%): 	Loss: 3.630568027496338	recon_loss: 0.0241140965372324	bpp_loss: 2.9071452617645264	aux_loss: 0.5347402095794678
19:50:11 INFO - main: Train iter. 190800/200000 (95.4%): 	Loss: 3.623286485671997	recon_loss: 0.024098530411720276	bpp_loss: 2.9003305435180664	aux_loss: 0.5589834451675415
19:50:29 INFO - main: Train iter. 190900/200000 (95.45%): 	Loss: 3.6240389347076416	recon_loss: 0.024045418947935104	bpp_loss: 2.9026763439178467	aux_loss: 0.3850173354148865
19:50:46 INFO - main: Train iter. 191000/200000 (95.5%): 	Loss: 3.625499963760376	recon_loss: 0.02404012717306614	bpp_loss: 2.9042961597442627	aux_loss: 0.3544963598251343
19:51:04 INFO - main: Train iter. 191100/200000 (95.55%): 	Loss: 3.6401805877685547	recon_loss: 0.024196557700634003	bpp_loss: 2.9142837524414062	aux_loss: 0.88865727186203
19:51:22 INFO - main: Train iter. 191200/200000 (95.6%): 	Loss: 3.627134084701538	recon_loss: 0.024107079952955246	bpp_loss: 2.903921604156494	aux_loss: 0.2306896597146988
19:51:39 INFO - main: Train iter. 191300/200000 (95.65%): 	Loss: 3.634340763092041	recon_loss: 0.024132808670401573	bpp_loss: 2.9103565216064453	aux_loss: 0.27920669317245483
19:51:57 INFO - main: Train iter. 191400/200000 (95.7%): 	Loss: 3.6401586532592773	recon_loss: 0.024177594110369682	bpp_loss: 2.9148306846618652	aux_loss: 0.29739341139793396
19:52:15 INFO - main: Train iter. 191500/200000 (95.75%): 	Loss: 3.628948211669922	recon_loss: 0.02408372238278389	bpp_loss: 2.9064366817474365	aux_loss: 0.3597399592399597
19:52:32 INFO - main: Train iter. 191600/200000 (95.8%): 	Loss: 3.623788833618164	recon_loss: 0.024093767628073692	bpp_loss: 2.9009757041931152	aux_loss: 0.3121125102043152
19:52:50 INFO - main: Train iter. 191700/200000 (95.85%): 	Loss: 3.6298694610595703	recon_loss: 0.024066263809800148	bpp_loss: 2.907881498336792	aux_loss: 0.6150738596916199
19:53:08 INFO - main: Train iter. 191800/200000 (95.9%): 	Loss: 3.633899688720703	recon_loss: 0.02415153756737709	bpp_loss: 2.909353494644165	aux_loss: 0.39373594522476196
19:53:25 INFO - main: Train iter. 191900/200000 (95.95%): 	Loss: 3.624929428100586	recon_loss: 0.024044333025813103	bpp_loss: 2.903599500656128	aux_loss: 0.33236682415008545
19:53:43 INFO - main: Train iter. 192000/200000 (96.0%): 	Loss: 3.612044334411621	recon_loss: 0.02396603673696518	bpp_loss: 2.8930633068084717	aux_loss: 0.3569026589393616
19:54:00 INFO - main: Train iter. 192100/200000 (96.05%): 	Loss: 3.629746675491333	recon_loss: 0.02409064769744873	bpp_loss: 2.907027244567871	aux_loss: 0.2907447814941406
19:54:18 INFO - main: Train iter. 192200/200000 (96.1%): 	Loss: 3.6299290657043457	recon_loss: 0.02407175488770008	bpp_loss: 2.907776355743408	aux_loss: 0.27351176738739014
19:54:36 INFO - main: Train iter. 192300/200000 (96.15%): 	Loss: 3.615438461303711	recon_loss: 0.0240575410425663	bpp_loss: 2.893712282180786	aux_loss: 0.42451608180999756
19:54:53 INFO - main: Train iter. 192400/200000 (96.2%): 	Loss: 3.6359012126922607	recon_loss: 0.02413390763103962	bpp_loss: 2.911884069442749	aux_loss: 0.24010173976421356
19:55:11 INFO - main: Train iter. 192500/200000 (96.25%): 	Loss: 3.6222968101501465	recon_loss: 0.02403426356613636	bpp_loss: 2.90126895904541	aux_loss: 0.25537651777267456
19:55:29 INFO - main: Train iter. 192600/200000 (96.3%): 	Loss: 3.621065378189087	recon_loss: 0.024034174159169197	bpp_loss: 2.9000401496887207	aux_loss: 0.3249947130680084
19:55:46 INFO - main: Train iter. 192700/200000 (96.35%): 	Loss: 3.6304173469543457	recon_loss: 0.024122044444084167	bpp_loss: 2.9067561626434326	aux_loss: 0.20668205618858337
19:56:04 INFO - main: Train iter. 192800/200000 (96.4%): 	Loss: 3.613462448120117	recon_loss: 0.02402166835963726	bpp_loss: 2.892812490463257	aux_loss: 0.33357536792755127
19:56:22 INFO - main: Train iter. 192900/200000 (96.45%): 	Loss: 3.6168107986450195	recon_loss: 0.024028178304433823	bpp_loss: 2.895965576171875	aux_loss: 0.3088254928588867
19:56:42 INFO - main: Train iter. 193000/200000 (96.5%): 	Loss: 3.6168694496154785	recon_loss: 0.02399788424372673	bpp_loss: 2.89693284034729	aux_loss: 0.8439267873764038
19:57:00 INFO - main: Train iter. 193100/200000 (96.55%): 	Loss: 3.6302297115325928	recon_loss: 0.024133818224072456	bpp_loss: 2.906215190887451	aux_loss: 0.2598620057106018
19:57:17 INFO - main: Train iter. 193200/200000 (96.6%): 	Loss: 3.6268181800842285	recon_loss: 0.02410963550209999	bpp_loss: 2.903529167175293	aux_loss: 0.6344811320304871
19:57:35 INFO - main: Train iter. 193300/200000 (96.65%): 	Loss: 3.629706382751465	recon_loss: 0.024122973904013634	bpp_loss: 2.9060170650482178	aux_loss: 0.22623398900032043
19:57:52 INFO - main: Train iter. 193400/200000 (96.7%): 	Loss: 3.631580114364624	recon_loss: 0.024153511971235275	bpp_loss: 2.9069747924804688	aux_loss: 0.3970583379268646
19:58:10 INFO - main: Train iter. 193500/200000 (96.75%): 	Loss: 3.6195178031921387	recon_loss: 0.02405289001762867	bpp_loss: 2.8979310989379883	aux_loss: 0.38084322214126587
19:58:28 INFO - main: Train iter. 193600/200000 (96.8%): 	Loss: 3.631789207458496	recon_loss: 0.024115586653351784	bpp_loss: 2.9083216190338135	aux_loss: 0.27344319224357605
19:58:46 INFO - main: Train iter. 193700/200000 (96.85%): 	Loss: 3.6332194805145264	recon_loss: 0.024159042164683342	bpp_loss: 2.9084482192993164	aux_loss: 0.4787706136703491
19:59:03 INFO - main: Train iter. 193800/200000 (96.9%): 	Loss: 3.6240336894989014	recon_loss: 0.02406179904937744	bpp_loss: 2.902179718017578	aux_loss: 0.4159355163574219
19:59:21 INFO - main: Train iter. 193900/200000 (96.95%): 	Loss: 3.6234705448150635	recon_loss: 0.024052245542407036	bpp_loss: 2.9019031524658203	aux_loss: 0.5529985427856445
19:59:39 INFO - main: Train iter. 194000/200000 (97.0%): 	Loss: 3.6375999450683594	recon_loss: 0.02415960282087326	bpp_loss: 2.912811756134033	aux_loss: 0.34021836519241333
19:59:56 INFO - main: Train iter. 194100/200000 (97.05%): 	Loss: 3.624812602996826	recon_loss: 0.024060359224677086	bpp_loss: 2.9030017852783203	aux_loss: 0.5195315480232239
20:00:14 INFO - main: Train iter. 194200/200000 (97.1%): 	Loss: 3.628547191619873	recon_loss: 0.024105766788125038	bpp_loss: 2.905374050140381	aux_loss: 0.22850853204727173
20:00:32 INFO - main: Train iter. 194300/200000 (97.15%): 	Loss: 3.6309821605682373	recon_loss: 0.02407575398683548	bpp_loss: 2.9087095260620117	aux_loss: 0.14776739478111267
20:00:49 INFO - main: Train iter. 194400/200000 (97.2%): 	Loss: 3.6307175159454346	recon_loss: 0.024117231369018555	bpp_loss: 2.907200574874878	aux_loss: 0.3425278961658478
20:01:07 INFO - main: Train iter. 194500/200000 (97.25%): 	Loss: 3.6043553352355957	recon_loss: 0.02400043234229088	bpp_loss: 2.8843424320220947	aux_loss: 0.44604334235191345
20:01:25 INFO - main: Train iter. 194600/200000 (97.3%): 	Loss: 3.6284093856811523	recon_loss: 0.024080026894807816	bpp_loss: 2.906008720397949	aux_loss: 0.4423288404941559
20:01:42 INFO - main: Train iter. 194700/200000 (97.35%): 	Loss: 3.655399799346924	recon_loss: 0.02420724928379059	bpp_loss: 2.929182291030884	aux_loss: 1.229792833328247
20:02:00 INFO - main: Train iter. 194800/200000 (97.4%): 	Loss: 3.6267929077148438	recon_loss: 0.02408626675605774	bpp_loss: 2.904204845428467	aux_loss: 0.2537969946861267
20:02:18 INFO - main: Train iter. 194900/200000 (97.45%): 	Loss: 3.627363443374634	recon_loss: 0.024115627631545067	bpp_loss: 2.9038946628570557	aux_loss: 0.7370172739028931
20:02:35 INFO - main: Train iter. 195000/200000 (97.5%): 	Loss: 3.6323723793029785	recon_loss: 0.024139946326613426	bpp_loss: 2.9081740379333496	aux_loss: 0.771477460861206
20:02:45 INFO - main: {'TEST MSE': 0.02414750164329543, 'TEST BPP': 2.95134375, 'TEST loss': 3.627411894083023, 'TEST recon_loss': 0.024147501554340124, 'TEST bpp_loss': 2.902986848592758}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
20:03:03 INFO - main: Train iter. 195100/200000 (97.55%): 	Loss: 3.6454544067382812	recon_loss: 0.02423320710659027	bpp_loss: 2.9184582233428955	aux_loss: 0.3383159637451172
20:03:20 INFO - main: Train iter. 195200/200000 (97.6%): 	Loss: 3.621445655822754	recon_loss: 0.02405029535293579	bpp_loss: 2.8999369144439697	aux_loss: 0.2174273133277893
20:03:38 INFO - main: Train iter. 195300/200000 (97.65%): 	Loss: 3.624769926071167	recon_loss: 0.024074530228972435	bpp_loss: 2.902534008026123	aux_loss: 0.23372003436088562
20:03:56 INFO - main: Train iter. 195400/200000 (97.7%): 	Loss: 3.636185646057129	recon_loss: 0.02414677105844021	bpp_loss: 2.9117825031280518	aux_loss: 0.5758180022239685
20:04:13 INFO - main: Train iter. 195500/200000 (97.75%): 	Loss: 3.6207823753356934	recon_loss: 0.02404116466641426	bpp_loss: 2.8995473384857178	aux_loss: 0.37447473406791687
20:04:31 INFO - main: Train iter. 195600/200000 (97.8%): 	Loss: 3.6350085735321045	recon_loss: 0.02413739077746868	bpp_loss: 2.910886764526367	aux_loss: 0.19445361196994781
20:04:48 INFO - main: Train iter. 195700/200000 (97.85%): 	Loss: 3.631500005722046	recon_loss: 0.024109572172164917	bpp_loss: 2.908212900161743	aux_loss: 0.30308109521865845
20:05:06 INFO - main: Train iter. 195800/200000 (97.9%): 	Loss: 3.6210989952087402	recon_loss: 0.02400793321430683	bpp_loss: 2.9008610248565674	aux_loss: 0.7720363140106201
20:05:24 INFO - main: Train iter. 195900/200000 (97.95%): 	Loss: 3.630826234817505	recon_loss: 0.02411077544093132	bpp_loss: 2.9075028896331787	aux_loss: 0.40036457777023315
20:05:41 INFO - main: Train iter. 196000/200000 (98.0%): 	Loss: 3.6248860359191895	recon_loss: 0.024107851088047028	bpp_loss: 2.9016504287719727	aux_loss: 0.45578598976135254
20:05:59 INFO - main: Train iter. 196100/200000 (98.05%): 	Loss: 3.619203567504883	recon_loss: 0.024043725803494453	bpp_loss: 2.8978917598724365	aux_loss: 0.6146515607833862
20:06:17 INFO - main: Train iter. 196200/200000 (98.1%): 	Loss: 3.6215133666992188	recon_loss: 0.0240531824529171	bpp_loss: 2.8999178409576416	aux_loss: 0.34961259365081787
20:06:37 INFO - main: Train iter. 196300/200000 (98.15%): 	Loss: 3.6251983642578125	recon_loss: 0.0241389162838459	bpp_loss: 2.9010307788848877	aux_loss: 1.1029456853866577
20:06:55 INFO - main: Train iter. 196400/200000 (98.2%): 	Loss: 3.630923271179199	recon_loss: 0.02413630299270153	bpp_loss: 2.906834125518799	aux_loss: 0.7909820079803467
20:07:12 INFO - main: Train iter. 196500/200000 (98.25%): 	Loss: 3.633787155151367	recon_loss: 0.024136826395988464	bpp_loss: 2.909682273864746	aux_loss: 0.2073303610086441
20:07:30 INFO - main: Train iter. 196600/200000 (98.3%): 	Loss: 3.6269659996032715	recon_loss: 0.02406492456793785	bpp_loss: 2.9050183296203613	aux_loss: 0.4313122034072876
20:07:48 INFO - main: Train iter. 196700/200000 (98.35%): 	Loss: 3.6379382610321045	recon_loss: 0.02410542033612728	bpp_loss: 2.9147756099700928	aux_loss: 1.1606762409210205
20:08:05 INFO - main: Train iter. 196800/200000 (98.4%): 	Loss: 3.6332292556762695	recon_loss: 0.024101870134472847	bpp_loss: 2.910173177719116	aux_loss: 0.17484858632087708
20:08:23 INFO - main: Train iter. 196900/200000 (98.45%): 	Loss: 3.6185567378997803	recon_loss: 0.024113599210977554	bpp_loss: 2.895148754119873	aux_loss: 0.24917379021644592
20:08:41 INFO - main: Train iter. 197000/200000 (98.5%): 	Loss: 3.6418049335479736	recon_loss: 0.02419533021748066	bpp_loss: 2.915945053100586	aux_loss: 0.20136448740959167
20:08:58 INFO - main: Train iter. 197100/200000 (98.55%): 	Loss: 3.621519088745117	recon_loss: 0.02404228411614895	bpp_loss: 2.9002506732940674	aux_loss: 0.16610607504844666
20:09:16 INFO - main: Train iter. 197200/200000 (98.6%): 	Loss: 3.6225428581237793	recon_loss: 0.02407154254615307	bpp_loss: 2.9003965854644775	aux_loss: 0.31900134682655334
20:09:34 INFO - main: Train iter. 197300/200000 (98.65%): 	Loss: 3.612281322479248	recon_loss: 0.023988064378499985	bpp_loss: 2.892639398574829	aux_loss: 0.33382895588874817
20:09:51 INFO - main: Train iter. 197400/200000 (98.7%): 	Loss: 3.6282620429992676	recon_loss: 0.024142729118466377	bpp_loss: 2.903980255126953	aux_loss: 1.3394392728805542
20:10:09 INFO - main: Train iter. 197500/200000 (98.75%): 	Loss: 3.6319499015808105	recon_loss: 0.024120675399899483	bpp_loss: 2.908329725265503	aux_loss: 0.36012041568756104
20:10:26 INFO - main: Train iter. 197600/200000 (98.8%): 	Loss: 3.6107122898101807	recon_loss: 0.024043971672654152	bpp_loss: 2.8893930912017822	aux_loss: 0.7553067207336426
20:10:44 INFO - main: Train iter. 197700/200000 (98.85%): 	Loss: 3.6243667602539062	recon_loss: 0.02405819483101368	bpp_loss: 2.902621030807495	aux_loss: 0.2862790822982788
20:11:02 INFO - main: Train iter. 197800/200000 (98.9%): 	Loss: 3.6407198905944824	recon_loss: 0.024166245013475418	bpp_loss: 2.9157326221466064	aux_loss: 0.3910922110080719
20:11:19 INFO - main: Train iter. 197900/200000 (98.95%): 	Loss: 3.6319446563720703	recon_loss: 0.024112597107887268	bpp_loss: 2.90856671333313	aux_loss: 0.2700132429599762
20:11:37 INFO - main: Train iter. 198000/200000 (99.0%): 	Loss: 3.641184091567993	recon_loss: 0.024144982919096947	bpp_loss: 2.916834592819214	aux_loss: 0.2825670838356018
20:11:55 INFO - main: Train iter. 198100/200000 (99.05%): 	Loss: 3.631272792816162	recon_loss: 0.02410767413675785	bpp_loss: 2.9080426692962646	aux_loss: 0.3976694941520691
20:12:13 INFO - main: Train iter. 198200/200000 (99.1%): 	Loss: 3.633500099182129	recon_loss: 0.024133892729878426	bpp_loss: 2.9094831943511963	aux_loss: 0.4154190421104431
20:12:30 INFO - main: Train iter. 198300/200000 (99.15%): 	Loss: 3.630218505859375	recon_loss: 0.024089055135846138	bpp_loss: 2.9075469970703125	aux_loss: 0.3892264664173126
20:12:48 INFO - main: Train iter. 198400/200000 (99.2%): 	Loss: 3.632697820663452	recon_loss: 0.024131152778863907	bpp_loss: 2.9087631702423096	aux_loss: 0.244653582572937
20:13:06 INFO - main: Train iter. 198500/200000 (99.25%): 	Loss: 3.6174261569976807	recon_loss: 0.02405356615781784	bpp_loss: 2.8958191871643066	aux_loss: 0.23962190747261047
20:13:24 INFO - main: Train iter. 198600/200000 (99.3%): 	Loss: 3.6385183334350586	recon_loss: 0.024149660021066666	bpp_loss: 2.9140286445617676	aux_loss: 0.26448917388916016
20:13:42 INFO - main: Train iter. 198700/200000 (99.35%): 	Loss: 3.6402103900909424	recon_loss: 0.02415299601852894	bpp_loss: 2.9156205654144287	aux_loss: 0.496991366147995
20:13:59 INFO - main: Train iter. 198800/200000 (99.4%): 	Loss: 3.642092227935791	recon_loss: 0.02416805364191532	bpp_loss: 2.91705060005188	aux_loss: 0.19145239889621735
20:14:17 INFO - main: Train iter. 198900/200000 (99.45%): 	Loss: 3.6361193656921387	recon_loss: 0.024144532158970833	bpp_loss: 2.911783456802368	aux_loss: 0.18819822371006012
20:14:35 INFO - main: Train iter. 199000/200000 (99.5%): 	Loss: 3.620149850845337	recon_loss: 0.024055689573287964	bpp_loss: 2.8984792232513428	aux_loss: 0.35388296842575073
20:14:53 INFO - main: Train iter. 199100/200000 (99.55%): 	Loss: 3.646942615509033	recon_loss: 0.024219201877713203	bpp_loss: 2.9203665256500244	aux_loss: 0.7144118547439575
20:15:10 INFO - main: Train iter. 199200/200000 (99.6%): 	Loss: 3.6305742263793945	recon_loss: 0.024112477898597717	bpp_loss: 2.9071998596191406	aux_loss: 0.4365820288658142
20:15:28 INFO - main: Train iter. 199300/200000 (99.65%): 	Loss: 3.6182072162628174	recon_loss: 0.02401035837829113	bpp_loss: 2.8978965282440186	aux_loss: 0.33278223872184753
20:15:46 INFO - main: Train iter. 199400/200000 (99.7%): 	Loss: 3.616130828857422	recon_loss: 0.024044077843427658	bpp_loss: 2.894808530807495	aux_loss: 0.5478060841560364
20:16:04 INFO - main: Train iter. 199500/200000 (99.75%): 	Loss: 3.622339963912964	recon_loss: 0.024072306230664253	bpp_loss: 2.9001708030700684	aux_loss: 0.2608903646469116
20:16:21 INFO - main: Train iter. 199600/200000 (99.8%): 	Loss: 3.616694688796997	recon_loss: 0.02404342219233513	bpp_loss: 2.8953919410705566	aux_loss: 0.35113346576690674
20:16:42 INFO - main: Train iter. 199700/200000 (99.85%): 	Loss: 3.6236143112182617	recon_loss: 0.024041609838604927	bpp_loss: 2.9023661613464355	aux_loss: 0.2509135603904724
20:17:00 INFO - main: Train iter. 199800/200000 (99.9%): 	Loss: 3.621734619140625	recon_loss: 0.024089109152555466	bpp_loss: 2.8990612030029297	aux_loss: 0.31863152980804443
20:17:18 INFO - main: Train iter. 199900/200000 (99.95%): 	Loss: 3.6292848587036133	recon_loss: 0.024070901796221733	bpp_loss: 2.9071576595306396	aux_loss: 0.22510996460914612
20:17:35 INFO - main: Train iter. 200000/200000 (100.0%): 	Loss: 3.6130378246307373	recon_loss: 0.023974332958459854	bpp_loss: 2.893807888031006	aux_loss: 0.9558669328689575
20:17:45 INFO - main: {'TEST MSE': 0.024070632454119955, 'TEST BPP': 2.95371875, 'TEST loss': 3.6273293735980987, 'TEST recon_loss': 0.024070632377639414, 'TEST bpp_loss': 2.9052104029655457}
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:        TEST BPP ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        TEST MSE ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   TEST bpp_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       TEST loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: TEST recon_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        bpp_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            loss ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ
wandb:      recon_loss ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:        TEST BPP 2.95372
wandb:        TEST MSE 0.02407
wandb:   TEST bpp_loss 2.90521
wandb:       TEST loss 3.62733
wandb: TEST recon_loss 0.02407
wandb:        bpp_loss 2.89381
wandb:            loss 3.61304
wandb:      recon_loss 0.02397
wandb: 
wandb: üöÄ View run nwc at: https://wandb.ai/maskedkd/NWC_VQVAE/runs/0lz6qm33
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/maskedkd/NWC_VQVAE
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250401_101831-0lz6qm33/logs
