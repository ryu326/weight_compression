/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/opt/conda/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
10:18:31 INFO - logger_setup: /workspace/Weight_compression/NWC/utils/util.py
10:18:31 INFO - before_main: Create new exp folder!
10:18:31 INFO - before_main: seed : 100
10:18:31 INFO - before_main: exp name : block_seq_scaler_meta-llama--Llama-2-7b-hf__scaled3_RHT_sig0.0001_col_4096.pt/lmbda300_rdloss_size16_encdim512_M16_Q0_R0_m0_batch_size1024_total_iter200000_lr0.0001_seed100
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ryu326 (maskedkd) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /workspace/Weight_compression/NWC/wandb/run-20250401_101831-wpel4dfr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run nwc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/NWC_VQVAE
wandb: üöÄ View run at https://wandb.ai/maskedkd/NWC_VQVAE/runs/wpel4dfr
10:18:32 INFO - main: Create experiment save folder
{'entropy_bottleneck.quantiles'}
10:18:43 INFO - main: Training mode : scratch!
10:18:43 INFO - main: batch_size : 1024
10:18:43 INFO - main: num of gpus: 1
10:18:43 INFO - main: Namespace(iter=200000, dataset='block_seq', dataset_path='../Wparam_dataset/block_pt/meta-llama--Llama-2-7b-hf/scaled3_RHT_sig0.0001_col_4096.pt', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, N=0, R=0, m=0, Q=0, C=0, clip_max_norm=1.0, save_dir='', architecture='nwc', loss='rdloss', checkpoint='None', lmbda=300, dataset_stat_type='scaler', save_path='./checkpoint/nwc/block_seq_scaler_meta-llama--Llama-2-7b-hf__scaled3_RHT_sig0.0001_col_4096.pt/lmbda300_rdloss_size16_encdim512_M16_Q0_R0_m0_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:18:45 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 901.2503051757812	recon_loss: 2.9862284660339355	bpp_loss: 5.381791591644287	aux_loss: 658.1149291992188
10:18:55 INFO - main: {'TEST MSE': 2.0332458780587856, 'TEST BPP': 5.390625, 'TEST loss': 615.3547813415528, 'TEST recon_loss': 2.033245944619179, 'TEST bpp_loss': 5.380998600959778}
10:18:55 INFO - main: can not find prev_mse_best_model!
10:18:55 INFO - main: can not find prev_bpp_best_model!
10:18:55 INFO - main: can not find prev_bpp_best_model!
10:18:55 INFO - main: can not find recent_saved_model!
/workspace/Weight_compression/NWC/train_nwc.py:418: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  csv_file = pd.concat([csv_file, pd.DataFrame([new_row])], ignore_index=True)
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:19:26 INFO - main: Train iter. 100/200000 (0.05%): 	Loss: 15.688251495361328	recon_loss: 0.03461027890443802	bpp_loss: 5.3051676750183105	aux_loss: 654.8333740234375
10:19:58 INFO - main: Train iter. 200/200000 (0.1%): 	Loss: 11.290969848632812	recon_loss: 0.02026177942752838	bpp_loss: 5.212436199188232	aux_loss: 651.96337890625
10:20:30 INFO - main: Train iter. 300/200000 (0.15%): 	Loss: 9.64175796508789	recon_loss: 0.015055960975587368	bpp_loss: 5.124969959259033	aux_loss: 649.0107421875
10:21:02 INFO - main: Train iter. 400/200000 (0.2%): 	Loss: 8.691033363342285	recon_loss: 0.012153263203799725	bpp_loss: 5.0450544357299805	aux_loss: 646.040283203125
10:21:33 INFO - main: Train iter. 500/200000 (0.25%): 	Loss: 8.070429801940918	recon_loss: 0.010337318293750286	bpp_loss: 4.969234466552734	aux_loss: 642.8972778320312
10:22:05 INFO - main: Train iter. 600/200000 (0.3%): 	Loss: 7.7648210525512695	recon_loss: 0.009561347775161266	bpp_loss: 4.896416664123535	aux_loss: 639.49072265625
10:22:37 INFO - main: Train iter. 700/200000 (0.35%): 	Loss: 7.350724220275879	recon_loss: 0.008397664874792099	bpp_loss: 4.831424713134766	aux_loss: 636.3038330078125
10:23:09 INFO - main: Train iter. 800/200000 (0.4%): 	Loss: 7.069479942321777	recon_loss: 0.007676040753722191	bpp_loss: 4.76666784286499	aux_loss: 632.9511108398438
10:23:41 INFO - main: Train iter. 900/200000 (0.45%): 	Loss: 6.956976890563965	recon_loss: 0.007449320517480373	bpp_loss: 4.7221808433532715	aux_loss: 630.0816650390625
10:24:13 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 6.721058368682861	recon_loss: 0.00682746572420001	bpp_loss: 4.672818660736084	aux_loss: 626.7594604492188
10:24:45 INFO - main: Train iter. 1100/200000 (0.55%): 	Loss: 6.575581073760986	recon_loss: 0.006496255751699209	bpp_loss: 4.626704216003418	aux_loss: 623.0364990234375
10:25:17 INFO - main: Train iter. 1200/200000 (0.6%): 	Loss: 6.428659439086914	recon_loss: 0.006147625390440226	bpp_loss: 4.584372043609619	aux_loss: 619.6519775390625
10:25:49 INFO - main: Train iter. 1300/200000 (0.65%): 	Loss: 6.3062520027160645	recon_loss: 0.005857465788722038	bpp_loss: 4.549012184143066	aux_loss: 616.176025390625
10:26:22 INFO - main: Train iter. 1400/200000 (0.7%): 	Loss: 6.185508728027344	recon_loss: 0.005547787062823772	bpp_loss: 4.521172523498535	aux_loss: 612.783203125
10:26:54 INFO - main: Train iter. 1500/200000 (0.75%): 	Loss: 6.066214561462402	recon_loss: 0.005240396596491337	bpp_loss: 4.494095802307129	aux_loss: 609.7901611328125
10:27:26 INFO - main: Train iter. 1600/200000 (0.8%): 	Loss: 6.079926490783691	recon_loss: 0.005351984407752752	bpp_loss: 4.474330902099609	aux_loss: 606.0899658203125
10:27:58 INFO - main: Train iter. 1700/200000 (0.85%): 	Loss: 6.030710697174072	recon_loss: 0.005222291685640812	bpp_loss: 4.464023113250732	aux_loss: 602.6456298828125
10:28:30 INFO - main: Train iter. 1800/200000 (0.9%): 	Loss: 5.931643962860107	recon_loss: 0.004947069101035595	bpp_loss: 4.44752311706543	aux_loss: 598.98974609375
10:29:02 INFO - main: Train iter. 1900/200000 (0.95%): 	Loss: 5.861141204833984	recon_loss: 0.00473759276792407	bpp_loss: 4.439863204956055	aux_loss: 595.239990234375
10:29:34 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 5.776371955871582	recon_loss: 0.004476211033761501	bpp_loss: 4.433508396148682	aux_loss: 591.5780029296875
10:30:06 INFO - main: Train iter. 2100/200000 (1.05%): 	Loss: 5.806690692901611	recon_loss: 0.004584724083542824	bpp_loss: 4.431273460388184	aux_loss: 588.451171875
10:30:38 INFO - main: Train iter. 2200/200000 (1.1%): 	Loss: 5.71027135848999	recon_loss: 0.004282871726900339	bpp_loss: 4.42540979385376	aux_loss: 585.3815307617188
10:31:09 INFO - main: Train iter. 2300/200000 (1.15%): 	Loss: 5.692336559295654	recon_loss: 0.004225329961627722	bpp_loss: 4.424737453460693	aux_loss: 582.4796142578125
10:31:41 INFO - main: Train iter. 2400/200000 (1.2%): 	Loss: 5.6585187911987305	recon_loss: 0.004114679526537657	bpp_loss: 4.42411470413208	aux_loss: 579.89990234375
10:32:13 INFO - main: Train iter. 2500/200000 (1.25%): 	Loss: 5.63352108001709	recon_loss: 0.004013224970549345	bpp_loss: 4.429553508758545	aux_loss: 577.412109375
10:32:45 INFO - main: Train iter. 2600/200000 (1.3%): 	Loss: 5.720486164093018	recon_loss: 0.0043103620409965515	bpp_loss: 4.427377700805664	aux_loss: 575.2664794921875
10:33:17 INFO - main: Train iter. 2700/200000 (1.35%): 	Loss: 5.76531982421875	recon_loss: 0.004433599300682545	bpp_loss: 4.435240268707275	aux_loss: 573.2085571289062
10:33:50 INFO - main: Train iter. 2800/200000 (1.4%): 	Loss: 5.630503177642822	recon_loss: 0.003984644077718258	bpp_loss: 4.435110092163086	aux_loss: 571.1475219726562
10:34:22 INFO - main: Train iter. 2900/200000 (1.45%): 	Loss: 5.587165832519531	recon_loss: 0.003856432158499956	bpp_loss: 4.430236339569092	aux_loss: 569.3953857421875
10:34:54 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 5.672977447509766	recon_loss: 0.004101083148270845	bpp_loss: 4.442652702331543	aux_loss: 567.8826904296875
10:35:26 INFO - main: Train iter. 3100/200000 (1.55%): 	Loss: 5.6290059089660645	recon_loss: 0.00391044607385993	bpp_loss: 4.455872058868408	aux_loss: 566.27978515625
10:35:58 INFO - main: Train iter. 3200/200000 (1.6%): 	Loss: 5.576519966125488	recon_loss: 0.0037642994429916143	bpp_loss: 4.447230339050293	aux_loss: 564.7493286132812
10:36:30 INFO - main: Train iter. 3300/200000 (1.65%): 	Loss: 5.552679061889648	recon_loss: 0.003667601151391864	bpp_loss: 4.452398777008057	aux_loss: 563.392822265625
10:37:02 INFO - main: Train iter. 3400/200000 (1.7%): 	Loss: 5.5546555519104	recon_loss: 0.003606306156143546	bpp_loss: 4.472763538360596	aux_loss: 562.19873046875
10:37:34 INFO - main: Train iter. 3500/200000 (1.75%): 	Loss: 5.627102375030518	recon_loss: 0.0038465866819024086	bpp_loss: 4.473126411437988	aux_loss: 561.0499267578125
10:38:06 INFO - main: Train iter. 3600/200000 (1.8%): 	Loss: 5.646207332611084	recon_loss: 0.003937490284442902	bpp_loss: 4.464960098266602	aux_loss: 559.5838623046875
10:38:38 INFO - main: Train iter. 3700/200000 (1.85%): 	Loss: 5.495053291320801	recon_loss: 0.0034600039944052696	bpp_loss: 4.457052230834961	aux_loss: 558.1210327148438
10:39:10 INFO - main: Train iter. 3800/200000 (1.9%): 	Loss: 5.529797077178955	recon_loss: 0.003526197047904134	bpp_loss: 4.471938133239746	aux_loss: 556.8641967773438
10:39:42 INFO - main: Train iter. 3900/200000 (1.95%): 	Loss: 5.493934154510498	recon_loss: 0.00340474396944046	bpp_loss: 4.472510814666748	aux_loss: 555.8212890625
10:40:13 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 5.591973781585693	recon_loss: 0.003675761166960001	bpp_loss: 4.489245414733887	aux_loss: 554.9674072265625
10:40:46 INFO - main: Train iter. 4100/200000 (2.05%): 	Loss: 5.515579700469971	recon_loss: 0.003428681520745158	bpp_loss: 4.486975193023682	aux_loss: 553.5814819335938
10:41:19 INFO - main: Train iter. 4200/200000 (2.1%): 	Loss: 5.496982574462891	recon_loss: 0.0033861736301332712	bpp_loss: 4.481130599975586	aux_loss: 552.3303833007812
10:41:51 INFO - main: Train iter. 4300/200000 (2.15%): 	Loss: 5.489100456237793	recon_loss: 0.0033223885111510754	bpp_loss: 4.49238395690918	aux_loss: 551.2199096679688
10:42:23 INFO - main: Train iter. 4400/200000 (2.2%): 	Loss: 5.460686206817627	recon_loss: 0.0032246161717921495	bpp_loss: 4.4933013916015625	aux_loss: 550.0889282226562
10:42:55 INFO - main: Train iter. 4500/200000 (2.25%): 	Loss: 5.512562274932861	recon_loss: 0.003364167409017682	bpp_loss: 4.503312110900879	aux_loss: 548.72705078125
10:43:26 INFO - main: Train iter. 4600/200000 (2.3%): 	Loss: 5.484374523162842	recon_loss: 0.0032635086681693792	bpp_loss: 4.505321979522705	aux_loss: 547.234375
10:43:58 INFO - main: Train iter. 4700/200000 (2.35%): 	Loss: 5.4794769287109375	recon_loss: 0.003213033312931657	bpp_loss: 4.515566825866699	aux_loss: 545.988037109375
10:44:30 INFO - main: Train iter. 4800/200000 (2.4%): 	Loss: 5.481289863586426	recon_loss: 0.003188017290085554	bpp_loss: 4.5248847007751465	aux_loss: 544.8616943359375
10:45:02 INFO - main: Train iter. 4900/200000 (2.45%): 	Loss: 5.465322494506836	recon_loss: 0.0031785909086465836	bpp_loss: 4.511745452880859	aux_loss: 543.2293090820312
10:45:34 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 5.498440265655518	recon_loss: 0.00326664000749588	bpp_loss: 4.518448352813721	aux_loss: 541.7830810546875
10:45:45 INFO - main: {'TEST MSE': 0.0031909832153481023, 'TEST BPP': 4.62934375, 'TEST loss': 5.47693662071228, 'TEST recon_loss': 0.003190983320353553, 'TEST bpp_loss': 4.519641627311707}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
10:46:17 INFO - main: Train iter. 5100/200000 (2.55%): 	Loss: 5.469089984893799	recon_loss: 0.003200346603989601	bpp_loss: 4.508985996246338	aux_loss: 540.2493896484375
10:46:49 INFO - main: Train iter. 5200/200000 (2.6%): 	Loss: 5.479809761047363	recon_loss: 0.003159366548061371	bpp_loss: 4.531999588012695	aux_loss: 538.9852905273438
10:47:20 INFO - main: Train iter. 5300/200000 (2.65%): 	Loss: 5.502298355102539	recon_loss: 0.0033247056417167187	bpp_loss: 4.504886627197266	aux_loss: 537.5086059570312
10:47:52 INFO - main: Train iter. 5400/200000 (2.7%): 	Loss: 5.484040260314941	recon_loss: 0.0032102877739816904	bpp_loss: 4.520954132080078	aux_loss: 535.6771240234375
10:48:25 INFO - main: Train iter. 5500/200000 (2.75%): 	Loss: 5.466732978820801	recon_loss: 0.0031296201050281525	bpp_loss: 4.527846813201904	aux_loss: 534.257080078125
10:48:57 INFO - main: Train iter. 5600/200000 (2.8%): 	Loss: 5.529244899749756	recon_loss: 0.0033702217042446136	bpp_loss: 4.518178462982178	aux_loss: 532.8150634765625
10:49:29 INFO - main: Train iter. 5700/200000 (2.85%): 	Loss: 5.464470386505127	recon_loss: 0.003106850665062666	bpp_loss: 4.532415390014648	aux_loss: 531.1302490234375
10:50:01 INFO - main: Train iter. 5800/200000 (2.9%): 	Loss: 5.443716049194336	recon_loss: 0.003062871750444174	bpp_loss: 4.52485466003418	aux_loss: 529.4788818359375
10:50:33 INFO - main: Train iter. 5900/200000 (2.95%): 	Loss: 5.415116310119629	recon_loss: 0.0029947692528367043	bpp_loss: 4.516685485839844	aux_loss: 528.04833984375
10:51:05 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 5.4577813148498535	recon_loss: 0.003063633106648922	bpp_loss: 4.538691520690918	aux_loss: 526.2996826171875
10:51:37 INFO - main: Train iter. 6100/200000 (3.05%): 	Loss: 5.446788787841797	recon_loss: 0.003040862735360861	bpp_loss: 4.534530162811279	aux_loss: 524.56103515625
10:52:09 INFO - main: Train iter. 6200/200000 (3.1%): 	Loss: 5.434041500091553	recon_loss: 0.0030045267194509506	bpp_loss: 4.532683372497559	aux_loss: 523.0537719726562
10:52:41 INFO - main: Train iter. 6300/200000 (3.15%): 	Loss: 5.430185794830322	recon_loss: 0.002967360196635127	bpp_loss: 4.539977550506592	aux_loss: 521.3179931640625
10:53:13 INFO - main: Train iter. 6400/200000 (3.2%): 	Loss: 5.479147911071777	recon_loss: 0.0031764020677655935	bpp_loss: 4.5262274742126465	aux_loss: 519.5132446289062
10:53:45 INFO - main: Train iter. 6500/200000 (3.25%): 	Loss: 5.475611686706543	recon_loss: 0.0031623791437596083	bpp_loss: 4.52689790725708	aux_loss: 517.3555908203125
10:54:17 INFO - main: Train iter. 6600/200000 (3.3%): 	Loss: 5.425268173217773	recon_loss: 0.0029932844918221235	bpp_loss: 4.52728271484375	aux_loss: 515.6786499023438
10:54:49 INFO - main: Train iter. 6700/200000 (3.35%): 	Loss: 5.412464141845703	recon_loss: 0.0029209826607257128	bpp_loss: 4.536169528961182	aux_loss: 513.9132690429688
10:55:20 INFO - main: Train iter. 6800/200000 (3.4%): 	Loss: 5.424885272979736	recon_loss: 0.002972469897940755	bpp_loss: 4.533144474029541	aux_loss: 512.275390625
10:55:54 INFO - main: Train iter. 6900/200000 (3.45%): 	Loss: 5.434057712554932	recon_loss: 0.002975725568830967	bpp_loss: 4.541339874267578	aux_loss: 510.3194274902344
10:56:26 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 5.456101417541504	recon_loss: 0.0030770227313041687	bpp_loss: 4.532994747161865	aux_loss: 508.18804931640625
10:56:57 INFO - main: Train iter. 7100/200000 (3.55%): 	Loss: 5.478260517120361	recon_loss: 0.003153648693114519	bpp_loss: 4.532166004180908	aux_loss: 506.29180908203125
10:57:29 INFO - main: Train iter. 7200/200000 (3.6%): 	Loss: 5.543099403381348	recon_loss: 0.003350071609020233	bpp_loss: 4.5380778312683105	aux_loss: 504.564453125
10:58:01 INFO - main: Train iter. 7300/200000 (3.65%): 	Loss: 5.427749156951904	recon_loss: 0.002983204321935773	bpp_loss: 4.532787799835205	aux_loss: 502.5814208984375
10:58:33 INFO - main: Train iter. 7400/200000 (3.7%): 	Loss: 5.422423362731934	recon_loss: 0.0029729895759373903	bpp_loss: 4.530526638031006	aux_loss: 500.451904296875
10:59:05 INFO - main: Train iter. 7500/200000 (3.75%): 	Loss: 5.425076007843018	recon_loss: 0.002935762982815504	bpp_loss: 4.544347286224365	aux_loss: 498.77459716796875
10:59:37 INFO - main: Train iter. 7600/200000 (3.8%): 	Loss: 5.405982494354248	recon_loss: 0.002871770178899169	bpp_loss: 4.5444512367248535	aux_loss: 497.01605224609375
11:00:09 INFO - main: Train iter. 7700/200000 (3.85%): 	Loss: 5.578061103820801	recon_loss: 0.003439063671976328	bpp_loss: 4.546341896057129	aux_loss: 495.2783203125
11:00:41 INFO - main: Train iter. 7800/200000 (3.9%): 	Loss: 5.426547527313232	recon_loss: 0.0029794524889439344	bpp_loss: 4.532711982727051	aux_loss: 493.19915771484375
11:01:13 INFO - main: Train iter. 7900/200000 (3.95%): 	Loss: 5.390280723571777	recon_loss: 0.0028022844344377518	bpp_loss: 4.549595355987549	aux_loss: 491.0574951171875
11:01:45 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 5.4237260818481445	recon_loss: 0.002898304956033826	bpp_loss: 4.554234504699707	aux_loss: 489.18365478515625
11:02:17 INFO - main: Train iter. 8100/200000 (4.05%): 	Loss: 5.392218589782715	recon_loss: 0.0028454058337956667	bpp_loss: 4.538597106933594	aux_loss: 487.45587158203125
11:02:49 INFO - main: Train iter. 8200/200000 (4.1%): 	Loss: 5.390827655792236	recon_loss: 0.0028053431306034327	bpp_loss: 4.549224853515625	aux_loss: 485.54461669921875
11:03:22 INFO - main: Train iter. 8300/200000 (4.15%): 	Loss: 5.364742279052734	recon_loss: 0.0027601595502346754	bpp_loss: 4.536694526672363	aux_loss: 483.70050048828125
11:03:54 INFO - main: Train iter. 8400/200000 (4.2%): 	Loss: 5.421909809112549	recon_loss: 0.002933281008154154	bpp_loss: 4.541925430297852	aux_loss: 481.59173583984375
11:04:26 INFO - main: Train iter. 8500/200000 (4.25%): 	Loss: 5.390024185180664	recon_loss: 0.0028247348964214325	bpp_loss: 4.542603969573975	aux_loss: 479.85699462890625
11:04:58 INFO - main: Train iter. 8600/200000 (4.3%): 	Loss: 5.379846096038818	recon_loss: 0.002786932047456503	bpp_loss: 4.543766498565674	aux_loss: 478.21893310546875
11:05:30 INFO - main: Train iter. 8700/200000 (4.35%): 	Loss: 5.467861652374268	recon_loss: 0.0030576535500586033	bpp_loss: 4.550565719604492	aux_loss: 476.5439453125
11:06:02 INFO - main: Train iter. 8800/200000 (4.4%): 	Loss: 5.401492595672607	recon_loss: 0.0028216212522238493	bpp_loss: 4.55500602722168	aux_loss: 474.94805908203125
11:06:34 INFO - main: Train iter. 8900/200000 (4.45%): 	Loss: 5.390739440917969	recon_loss: 0.0027673523873090744	bpp_loss: 4.56053352355957	aux_loss: 473.5108337402344
11:07:05 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 5.411996841430664	recon_loss: 0.002846888732165098	bpp_loss: 4.5579304695129395	aux_loss: 471.5916442871094
11:07:37 INFO - main: Train iter. 9100/200000 (4.55%): 	Loss: 5.397192478179932	recon_loss: 0.0028028381057083607	bpp_loss: 4.556341171264648	aux_loss: 469.81671142578125
11:08:09 INFO - main: Train iter. 9200/200000 (4.6%): 	Loss: 5.387354850769043	recon_loss: 0.0027639970649033785	bpp_loss: 4.558155536651611	aux_loss: 468.4201354980469
11:08:41 INFO - main: Train iter. 9300/200000 (4.65%): 	Loss: 5.398746013641357	recon_loss: 0.0028203430119901896	bpp_loss: 4.552643299102783	aux_loss: 466.80389404296875
11:09:13 INFO - main: Train iter. 9400/200000 (4.7%): 	Loss: 5.429654121398926	recon_loss: 0.0029413949232548475	bpp_loss: 4.547235488891602	aux_loss: 464.6866760253906
11:09:45 INFO - main: Train iter. 9500/200000 (4.75%): 	Loss: 5.438148498535156	recon_loss: 0.0028973708394914865	bpp_loss: 4.568937301635742	aux_loss: 463.5860290527344
11:10:18 INFO - main: Train iter. 9600/200000 (4.8%): 	Loss: 5.359850883483887	recon_loss: 0.002730732783675194	bpp_loss: 4.54063081741333	aux_loss: 461.2742919921875
11:10:50 INFO - main: Train iter. 9700/200000 (4.85%): 	Loss: 5.470437526702881	recon_loss: 0.0030295690521597862	bpp_loss: 4.5615668296813965	aux_loss: 459.923828125
11:11:22 INFO - main: Train iter. 9800/200000 (4.9%): 	Loss: 5.398995399475098	recon_loss: 0.0028177916537970304	bpp_loss: 4.5536580085754395	aux_loss: 458.941650390625
11:11:54 INFO - main: Train iter. 9900/200000 (4.95%): 	Loss: 5.395261287689209	recon_loss: 0.002779931528493762	bpp_loss: 4.561281681060791	aux_loss: 457.624267578125
11:12:26 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 5.384736061096191	recon_loss: 0.0027399843093007803	bpp_loss: 4.562740802764893	aux_loss: 456.4197082519531
11:12:37 INFO - main: {'TEST MSE': 0.0027172069590796683, 'TEST BPP': 4.583890625, 'TEST loss': 5.377573629856109, 'TEST recon_loss': 0.0027172070485539735, 'TEST bpp_loss': 4.562411523342132}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:13:09 INFO - main: Train iter. 10100/200000 (5.05%): 	Loss: 5.442252159118652	recon_loss: 0.002938430290669203	bpp_loss: 4.560723304748535	aux_loss: 454.86846923828125
11:13:41 INFO - main: Train iter. 10200/200000 (5.1%): 	Loss: 5.439436912536621	recon_loss: 0.0029506548307836056	bpp_loss: 4.554240703582764	aux_loss: 453.5037536621094
11:14:13 INFO - main: Train iter. 10300/200000 (5.15%): 	Loss: 5.402462482452393	recon_loss: 0.002803896786645055	bpp_loss: 4.561293601989746	aux_loss: 452.05975341796875
11:14:44 INFO - main: Train iter. 10400/200000 (5.2%): 	Loss: 5.382391452789307	recon_loss: 0.0027492495719343424	bpp_loss: 4.557616710662842	aux_loss: 450.633544921875
11:15:16 INFO - main: Train iter. 10500/200000 (5.25%): 	Loss: 5.38128137588501	recon_loss: 0.0027368166483938694	bpp_loss: 4.56023645401001	aux_loss: 449.64141845703125
11:15:48 INFO - main: Train iter. 10600/200000 (5.3%): 	Loss: 5.516361713409424	recon_loss: 0.003179671475663781	bpp_loss: 4.562460422515869	aux_loss: 448.1016845703125
11:16:20 INFO - main: Train iter. 10700/200000 (5.35%): 	Loss: 5.359025001525879	recon_loss: 0.0026969381142407656	bpp_loss: 4.549943447113037	aux_loss: 446.5750427246094
11:16:52 INFO - main: Train iter. 10800/200000 (5.4%): 	Loss: 5.36827278137207	recon_loss: 0.002689435612410307	bpp_loss: 4.561441898345947	aux_loss: 445.0926818847656
11:17:24 INFO - main: Train iter. 10900/200000 (5.45%): 	Loss: 5.530146598815918	recon_loss: 0.0031966036185622215	bpp_loss: 4.571165561676025	aux_loss: 444.13214111328125
11:17:57 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 5.3861284255981445	recon_loss: 0.002720612334087491	bpp_loss: 4.569944858551025	aux_loss: 442.6966247558594
11:18:29 INFO - main: Train iter. 11100/200000 (5.55%): 	Loss: 5.3905415534973145	recon_loss: 0.0027618631720542908	bpp_loss: 4.56198263168335	aux_loss: 441.4229431152344
11:19:01 INFO - main: Train iter. 11200/200000 (5.6%): 	Loss: 5.4237060546875	recon_loss: 0.0028618292417377234	bpp_loss: 4.565157413482666	aux_loss: 439.83160400390625
11:19:33 INFO - main: Train iter. 11300/200000 (5.65%): 	Loss: 5.408689022064209	recon_loss: 0.0027935728430747986	bpp_loss: 4.570617198944092	aux_loss: 436.66412353515625
11:20:05 INFO - main: Train iter. 11400/200000 (5.7%): 	Loss: 5.376530647277832	recon_loss: 0.0027566750068217516	bpp_loss: 4.549528121948242	aux_loss: 436.1806945800781
11:20:37 INFO - main: Train iter. 11500/200000 (5.75%): 	Loss: 5.421675682067871	recon_loss: 0.002858188236132264	bpp_loss: 4.564218997955322	aux_loss: 434.99493408203125
11:21:09 INFO - main: Train iter. 11600/200000 (5.8%): 	Loss: 5.447938442230225	recon_loss: 0.0029967972077429295	bpp_loss: 4.548899173736572	aux_loss: 433.4150695800781
11:21:41 INFO - main: Train iter. 11700/200000 (5.85%): 	Loss: 5.403883934020996	recon_loss: 0.002802776638418436	bpp_loss: 4.563050746917725	aux_loss: 431.4828796386719
11:22:12 INFO - main: Train iter. 11800/200000 (5.9%): 	Loss: 5.381556034088135	recon_loss: 0.002759326947852969	bpp_loss: 4.553758144378662	aux_loss: 430.28997802734375
11:22:45 INFO - main: Train iter. 11900/200000 (5.95%): 	Loss: 5.378534317016602	recon_loss: 0.0027056902181357145	bpp_loss: 4.566827297210693	aux_loss: 429.57366943359375
11:23:17 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 5.35838508605957	recon_loss: 0.002681322628632188	bpp_loss: 4.553988456726074	aux_loss: 428.7178039550781
11:23:48 INFO - main: Train iter. 12100/200000 (6.05%): 	Loss: 5.3685712814331055	recon_loss: 0.0026551601476967335	bpp_loss: 4.572023391723633	aux_loss: 427.33935546875
11:24:20 INFO - main: Train iter. 12200/200000 (6.1%): 	Loss: 5.421838283538818	recon_loss: 0.002846545772626996	bpp_loss: 4.567874431610107	aux_loss: 426.0496826171875
11:24:52 INFO - main: Train iter. 12300/200000 (6.15%): 	Loss: 5.400839805603027	recon_loss: 0.0027600994799286127	bpp_loss: 4.572810173034668	aux_loss: 424.3524169921875
11:25:25 INFO - main: Train iter. 12400/200000 (6.2%): 	Loss: 5.381800174713135	recon_loss: 0.0027205911464989185	bpp_loss: 4.565622806549072	aux_loss: 423.050048828125
11:25:57 INFO - main: Train iter. 12500/200000 (6.25%): 	Loss: 5.37257194519043	recon_loss: 0.002695690607652068	bpp_loss: 4.563864707946777	aux_loss: 421.84442138671875
11:26:29 INFO - main: Train iter. 12600/200000 (6.3%): 	Loss: 5.376221656799316	recon_loss: 0.002673950046300888	bpp_loss: 4.574036598205566	aux_loss: 420.5830078125
11:27:01 INFO - main: Train iter. 12700/200000 (6.35%): 	Loss: 5.358358860015869	recon_loss: 0.002648321446031332	bpp_loss: 4.563862323760986	aux_loss: 419.36248779296875
11:27:33 INFO - main: Train iter. 12800/200000 (6.4%): 	Loss: 5.3663249015808105	recon_loss: 0.002696035895496607	bpp_loss: 4.557514190673828	aux_loss: 418.14971923828125
11:28:05 INFO - main: Train iter. 12900/200000 (6.45%): 	Loss: 5.356337547302246	recon_loss: 0.002640772145241499	bpp_loss: 4.564105987548828	aux_loss: 416.7442932128906
11:28:37 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 5.398313045501709	recon_loss: 0.002754638670012355	bpp_loss: 4.571921348571777	aux_loss: 415.37396240234375
11:29:09 INFO - main: Train iter. 13100/200000 (6.55%): 	Loss: 5.38145637512207	recon_loss: 0.00267900712788105	bpp_loss: 4.577754020690918	aux_loss: 414.0931701660156
11:29:40 INFO - main: Train iter. 13200/200000 (6.6%): 	Loss: 5.366556644439697	recon_loss: 0.0026370782870799303	bpp_loss: 4.575433254241943	aux_loss: 412.83843994140625
11:30:12 INFO - main: Train iter. 13300/200000 (6.65%): 	Loss: 5.416362285614014	recon_loss: 0.002812838414683938	bpp_loss: 4.572510719299316	aux_loss: 411.1838073730469
11:30:44 INFO - main: Train iter. 13400/200000 (6.7%): 	Loss: 5.378716468811035	recon_loss: 0.0026678091380745173	bpp_loss: 4.578373908996582	aux_loss: 409.6828918457031
11:31:16 INFO - main: Train iter. 13500/200000 (6.75%): 	Loss: 5.441070079803467	recon_loss: 0.0029059071093797684	bpp_loss: 4.569297790527344	aux_loss: 408.4673156738281
11:31:48 INFO - main: Train iter. 13600/200000 (6.8%): 	Loss: 5.380791187286377	recon_loss: 0.0027028468903154135	bpp_loss: 4.569937229156494	aux_loss: 406.67718505859375
11:32:21 INFO - main: Train iter. 13700/200000 (6.85%): 	Loss: 5.374452590942383	recon_loss: 0.0026848562993109226	bpp_loss: 4.568995475769043	aux_loss: 404.6983642578125
11:32:53 INFO - main: Train iter. 13800/200000 (6.9%): 	Loss: 5.36116886138916	recon_loss: 0.002638609614223242	bpp_loss: 4.569585800170898	aux_loss: 403.8340148925781
11:33:25 INFO - main: Train iter. 13900/200000 (6.95%): 	Loss: 5.354489803314209	recon_loss: 0.002604914829134941	bpp_loss: 4.573015213012695	aux_loss: 403.27587890625
11:33:57 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 5.4956841468811035	recon_loss: 0.003104985458776355	bpp_loss: 4.564188480377197	aux_loss: 401.21807861328125
11:34:29 INFO - main: Train iter. 14100/200000 (7.05%): 	Loss: 5.360912799835205	recon_loss: 0.0027191482950001955	bpp_loss: 4.545168399810791	aux_loss: 398.457763671875
11:35:01 INFO - main: Train iter. 14200/200000 (7.1%): 	Loss: 5.391192436218262	recon_loss: 0.002749417442828417	bpp_loss: 4.566367149353027	aux_loss: 396.7030029296875
11:35:33 INFO - main: Train iter. 14300/200000 (7.15%): 	Loss: 5.392867088317871	recon_loss: 0.0027593891136348248	bpp_loss: 4.56505012512207	aux_loss: 395.1888427734375
11:36:05 INFO - main: Train iter. 14400/200000 (7.2%): 	Loss: 5.373431205749512	recon_loss: 0.0026675043627619743	bpp_loss: 4.573179721832275	aux_loss: 394.83489990234375
11:36:36 INFO - main: Train iter. 14500/200000 (7.25%): 	Loss: 5.345557689666748	recon_loss: 0.00258633797056973	bpp_loss: 4.5696563720703125	aux_loss: 393.8178405761719
11:37:08 INFO - main: Train iter. 14600/200000 (7.3%): 	Loss: 5.376339435577393	recon_loss: 0.002662510611116886	bpp_loss: 4.5775861740112305	aux_loss: 392.90411376953125
11:37:40 INFO - main: Train iter. 14700/200000 (7.35%): 	Loss: 5.371598243713379	recon_loss: 0.0026391777209937572	bpp_loss: 4.579844951629639	aux_loss: 391.46844482421875
11:38:12 INFO - main: Train iter. 14800/200000 (7.4%): 	Loss: 5.359879970550537	recon_loss: 0.0026084387209266424	bpp_loss: 4.577348232269287	aux_loss: 390.5396728515625
11:38:44 INFO - main: Train iter. 14900/200000 (7.45%): 	Loss: 5.406976222991943	recon_loss: 0.0027702252846211195	bpp_loss: 4.575908660888672	aux_loss: 389.28546142578125
11:39:16 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 5.455838203430176	recon_loss: 0.0029302032198756933	bpp_loss: 4.57677698135376	aux_loss: 386.83465576171875
11:39:27 INFO - main: {'TEST MSE': 0.002722945188270939, 'TEST BPP': 4.5870625, 'TEST loss': 5.3908326420784, 'TEST recon_loss': 0.0027229452785104513, 'TEST bpp_loss': 4.573949058055877}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
11:40:00 INFO - main: Train iter. 15100/200000 (7.55%): 	Loss: 5.36299467086792	recon_loss: 0.0026539003010839224	bpp_loss: 4.566824436187744	aux_loss: 384.9857177734375
11:40:32 INFO - main: Train iter. 15200/200000 (7.6%): 	Loss: 5.376084327697754	recon_loss: 0.002700249897316098	bpp_loss: 4.566009521484375	aux_loss: 383.0031433105469
11:41:03 INFO - main: Train iter. 15300/200000 (7.65%): 	Loss: 5.379009246826172	recon_loss: 0.002675562398508191	bpp_loss: 4.576340675354004	aux_loss: 382.0489501953125
11:41:35 INFO - main: Train iter. 15400/200000 (7.7%): 	Loss: 5.351993560791016	recon_loss: 0.002624341519549489	bpp_loss: 4.564691066741943	aux_loss: 381.52447509765625
11:42:07 INFO - main: Train iter. 15500/200000 (7.75%): 	Loss: 5.390660762786865	recon_loss: 0.002674151910468936	bpp_loss: 4.588415145874023	aux_loss: 380.5002136230469
11:42:39 INFO - main: Train iter. 15600/200000 (7.8%): 	Loss: 5.403996467590332	recon_loss: 0.0027534908149391413	bpp_loss: 4.577949047088623	aux_loss: 379.4106140136719
11:43:11 INFO - main: Train iter. 15700/200000 (7.85%): 	Loss: 5.384305000305176	recon_loss: 0.0026612221263349056	bpp_loss: 4.585938453674316	aux_loss: 377.83404541015625
11:43:43 INFO - main: Train iter. 15800/200000 (7.9%): 	Loss: 5.369733810424805	recon_loss: 0.0026400121860206127	bpp_loss: 4.577730178833008	aux_loss: 376.71502685546875
11:44:14 INFO - main: Train iter. 15900/200000 (7.95%): 	Loss: 5.360452175140381	recon_loss: 0.0026135235093533993	bpp_loss: 4.576395034790039	aux_loss: 375.3381042480469
11:44:46 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 5.358908176422119	recon_loss: 0.0026281264144927263	bpp_loss: 4.570470333099365	aux_loss: 373.67120361328125
11:45:18 INFO - main: Train iter. 16100/200000 (8.05%): 	Loss: 5.362947940826416	recon_loss: 0.00261109322309494	bpp_loss: 4.579619884490967	aux_loss: 372.879150390625
11:45:50 INFO - main: Train iter. 16200/200000 (8.1%): 	Loss: 5.375522613525391	recon_loss: 0.0026675222907215357	bpp_loss: 4.575265884399414	aux_loss: 371.106201171875
11:46:22 INFO - main: Train iter. 16300/200000 (8.15%): 	Loss: 5.373591423034668	recon_loss: 0.0026468192227184772	bpp_loss: 4.579545497894287	aux_loss: 369.4682312011719
11:46:53 INFO - main: Train iter. 16400/200000 (8.2%): 	Loss: 5.388769149780273	recon_loss: 0.0027291965670883656	bpp_loss: 4.570010185241699	aux_loss: 367.25469970703125
11:47:27 INFO - main: Train iter. 16500/200000 (8.25%): 	Loss: 5.379469394683838	recon_loss: 0.002677309326827526	bpp_loss: 4.576276779174805	aux_loss: 365.746337890625
11:47:59 INFO - main: Train iter. 16600/200000 (8.3%): 	Loss: 5.367096424102783	recon_loss: 0.002612875308841467	bpp_loss: 4.583233833312988	aux_loss: 365.1579284667969
11:48:31 INFO - main: Train iter. 16700/200000 (8.35%): 	Loss: 5.367297172546387	recon_loss: 0.0026384214870631695	bpp_loss: 4.575770854949951	aux_loss: 363.3062744140625
11:49:02 INFO - main: Train iter. 16800/200000 (8.4%): 	Loss: 5.3643388748168945	recon_loss: 0.002616014564409852	bpp_loss: 4.579534530639648	aux_loss: 362.46307373046875
11:49:34 INFO - main: Train iter. 16900/200000 (8.45%): 	Loss: 5.3699564933776855	recon_loss: 0.0025976391043514013	bpp_loss: 4.590664863586426	aux_loss: 361.3235778808594
11:50:06 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 5.399348735809326	recon_loss: 0.0027167981024831533	bpp_loss: 4.584309101104736	aux_loss: 360.54046630859375
11:50:38 INFO - main: Train iter. 17100/200000 (8.55%): 	Loss: 5.378973960876465	recon_loss: 0.0026469938457012177	bpp_loss: 4.58487606048584	aux_loss: 358.2640075683594
11:51:10 INFO - main: Train iter. 17200/200000 (8.6%): 	Loss: 5.36051607131958	recon_loss: 0.002619431121274829	bpp_loss: 4.574686527252197	aux_loss: 357.3656005859375
11:51:42 INFO - main: Train iter. 17300/200000 (8.65%): 	Loss: 5.352331638336182	recon_loss: 0.0025862569455057383	bpp_loss: 4.5764546394348145	aux_loss: 355.7817687988281
11:52:14 INFO - main: Train iter. 17400/200000 (8.7%): 	Loss: 5.354640960693359	recon_loss: 0.002573290141299367	bpp_loss: 4.582653999328613	aux_loss: 354.4935607910156
11:52:45 INFO - main: Train iter. 17500/200000 (8.75%): 	Loss: 5.381369590759277	recon_loss: 0.002635051030665636	bpp_loss: 4.590854167938232	aux_loss: 352.81939697265625
11:53:17 INFO - main: Train iter. 17600/200000 (8.8%): 	Loss: 5.354850769042969	recon_loss: 0.0025988449342548847	bpp_loss: 4.575197219848633	aux_loss: 351.4783020019531
11:53:49 INFO - main: Train iter. 17700/200000 (8.85%): 	Loss: 5.3452348709106445	recon_loss: 0.0025637736544013023	bpp_loss: 4.5761027336120605	aux_loss: 350.7706298828125
11:54:22 INFO - main: Train iter. 17800/200000 (8.9%): 	Loss: 5.360750198364258	recon_loss: 0.0026205626782029867	bpp_loss: 4.574581146240234	aux_loss: 349.5865783691406
11:54:54 INFO - main: Train iter. 17900/200000 (8.95%): 	Loss: 5.356396675109863	recon_loss: 0.0025953075382858515	bpp_loss: 4.5778045654296875	aux_loss: 347.6688232421875
11:55:26 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 5.3532328605651855	recon_loss: 0.0025803123135119677	bpp_loss: 4.579139232635498	aux_loss: 346.8907470703125
11:55:58 INFO - main: Train iter. 18100/200000 (9.05%): 	Loss: 5.391055107116699	recon_loss: 0.0027255795430392027	bpp_loss: 4.573381423950195	aux_loss: 345.6850280761719
11:56:30 INFO - main: Train iter. 18200/200000 (9.1%): 	Loss: 5.359638690948486	recon_loss: 0.002653192263096571	bpp_loss: 4.563681125640869	aux_loss: 342.1497802734375
11:57:02 INFO - main: Train iter. 18300/200000 (9.15%): 	Loss: 5.3549017906188965	recon_loss: 0.0025782405864447355	bpp_loss: 4.581429481506348	aux_loss: 341.6028137207031
11:57:34 INFO - main: Train iter. 18400/200000 (9.2%): 	Loss: 5.40090274810791	recon_loss: 0.0027609725948423147	bpp_loss: 4.572610855102539	aux_loss: 340.85809326171875
11:58:06 INFO - main: Train iter. 18500/200000 (9.25%): 	Loss: 5.374308109283447	recon_loss: 0.0026299122255295515	bpp_loss: 4.585334300994873	aux_loss: 339.518310546875
11:58:37 INFO - main: Train iter. 18600/200000 (9.3%): 	Loss: 5.370692253112793	recon_loss: 0.0026085989084094763	bpp_loss: 4.588112831115723	aux_loss: 337.94384765625
11:59:09 INFO - main: Train iter. 18700/200000 (9.35%): 	Loss: 5.351757526397705	recon_loss: 0.0025804738979786634	bpp_loss: 4.577615261077881	aux_loss: 336.6584167480469
11:59:41 INFO - main: Train iter. 18800/200000 (9.4%): 	Loss: 5.3537397384643555	recon_loss: 0.002606782130897045	bpp_loss: 4.571705341339111	aux_loss: 334.8493347167969
12:00:13 INFO - main: Train iter. 18900/200000 (9.45%): 	Loss: 5.38201904296875	recon_loss: 0.002687883796170354	bpp_loss: 4.575654029846191	aux_loss: 332.7187805175781
12:00:45 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 5.360814094543457	recon_loss: 0.002576697152107954	bpp_loss: 4.587804794311523	aux_loss: 331.3692932128906
12:01:17 INFO - main: Train iter. 19100/200000 (9.55%): 	Loss: 5.373073101043701	recon_loss: 0.002665231702849269	bpp_loss: 4.573503494262695	aux_loss: 330.95550537109375
12:01:50 INFO - main: Train iter. 19200/200000 (9.6%): 	Loss: 5.346467018127441	recon_loss: 0.0025891687255352736	bpp_loss: 4.569716453552246	aux_loss: 329.2821044921875
12:02:22 INFO - main: Train iter. 19300/200000 (9.65%): 	Loss: 5.359898090362549	recon_loss: 0.0025850299280136824	bpp_loss: 4.5843892097473145	aux_loss: 328.04229736328125
12:02:54 INFO - main: Train iter. 19400/200000 (9.7%): 	Loss: 5.393557548522949	recon_loss: 0.0027251518331468105	bpp_loss: 4.576012134552002	aux_loss: 326.98394775390625
12:03:25 INFO - main: Train iter. 19500/200000 (9.75%): 	Loss: 5.355088710784912	recon_loss: 0.0026248644571751356	bpp_loss: 4.567629337310791	aux_loss: 325.6145935058594
12:03:57 INFO - main: Train iter. 19600/200000 (9.8%): 	Loss: 5.348426818847656	recon_loss: 0.0025937652681022882	bpp_loss: 4.5702972412109375	aux_loss: 324.6004943847656
12:04:29 INFO - main: Train iter. 19700/200000 (9.85%): 	Loss: 5.358151912689209	recon_loss: 0.0025940374471247196	bpp_loss: 4.5799407958984375	aux_loss: 322.74603271484375
12:05:01 INFO - main: Train iter. 19800/200000 (9.9%): 	Loss: 5.388278484344482	recon_loss: 0.0026604102458804846	bpp_loss: 4.590155601501465	aux_loss: 321.86883544921875
12:05:33 INFO - main: Train iter. 19900/200000 (9.95%): 	Loss: 5.340031623840332	recon_loss: 0.0025382093153893948	bpp_loss: 4.578568935394287	aux_loss: 320.51727294921875
12:06:05 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 5.366023540496826	recon_loss: 0.0026007906999439	bpp_loss: 4.58578634262085	aux_loss: 318.85638427734375
12:06:16 INFO - main: {'TEST MSE': 0.0025803370061827846, 'TEST BPP': 4.59815625, 'TEST loss': 5.359957699775696, 'TEST recon_loss': 0.0025803370920475573, 'TEST bpp_loss': 4.585856574058533}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:06:47 INFO - main: Train iter. 20100/200000 (10.05%): 	Loss: 5.356320858001709	recon_loss: 0.0025761111173778772	bpp_loss: 4.583487510681152	aux_loss: 317.44573974609375
12:07:19 INFO - main: Train iter. 20200/200000 (10.1%): 	Loss: 5.368640422821045	recon_loss: 0.0026293578557670116	bpp_loss: 4.579833030700684	aux_loss: 316.0378112792969
12:07:51 INFO - main: Train iter. 20300/200000 (10.15%): 	Loss: 5.3749589920043945	recon_loss: 0.0025821698363870382	bpp_loss: 4.600307941436768	aux_loss: 314.5776672363281
12:08:23 INFO - main: Train iter. 20400/200000 (10.2%): 	Loss: 5.365293979644775	recon_loss: 0.0026135749649256468	bpp_loss: 4.581221580505371	aux_loss: 313.134765625
12:08:55 INFO - main: Train iter. 20500/200000 (10.25%): 	Loss: 5.356945037841797	recon_loss: 0.002584237838163972	bpp_loss: 4.581673622131348	aux_loss: 311.5965576171875
12:09:28 INFO - main: Train iter. 20600/200000 (10.3%): 	Loss: 5.4134297370910645	recon_loss: 0.002816268475726247	bpp_loss: 4.568549156188965	aux_loss: 310.3590393066406
12:10:00 INFO - main: Train iter. 20700/200000 (10.35%): 	Loss: 5.353903770446777	recon_loss: 0.0025891787372529507	bpp_loss: 4.577150344848633	aux_loss: 309.7335205078125
12:10:32 INFO - main: Train iter. 20800/200000 (10.4%): 	Loss: 5.348259449005127	recon_loss: 0.0025623587425798178	bpp_loss: 4.579551696777344	aux_loss: 308.11749267578125
12:11:03 INFO - main: Train iter. 20900/200000 (10.45%): 	Loss: 5.361368179321289	recon_loss: 0.0026100915856659412	bpp_loss: 4.578340530395508	aux_loss: 307.08819580078125
12:11:35 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 5.365141868591309	recon_loss: 0.002592256059870124	bpp_loss: 4.587465286254883	aux_loss: 305.2808532714844
12:12:07 INFO - main: Train iter. 21100/200000 (10.55%): 	Loss: 5.3563385009765625	recon_loss: 0.002573019592091441	bpp_loss: 4.584432601928711	aux_loss: 303.742431640625
12:12:39 INFO - main: Train iter. 21200/200000 (10.6%): 	Loss: 5.343492031097412	recon_loss: 0.0025553733576089144	bpp_loss: 4.576879978179932	aux_loss: 303.091064453125
12:13:11 INFO - main: Train iter. 21300/200000 (10.65%): 	Loss: 5.395206451416016	recon_loss: 0.0027053607627749443	bpp_loss: 4.5835981369018555	aux_loss: 300.99822998046875
12:13:43 INFO - main: Train iter. 21400/200000 (10.7%): 	Loss: 5.347926139831543	recon_loss: 0.002578030340373516	bpp_loss: 4.574517250061035	aux_loss: 299.63128662109375
12:14:15 INFO - main: Train iter. 21500/200000 (10.75%): 	Loss: 5.397678375244141	recon_loss: 0.0026880104560405016	bpp_loss: 4.591275215148926	aux_loss: 298.8321533203125
12:14:47 INFO - main: Train iter. 21600/200000 (10.8%): 	Loss: 5.351726055145264	recon_loss: 0.002565142698585987	bpp_loss: 4.582183361053467	aux_loss: 296.2201843261719
12:15:18 INFO - main: Train iter. 21700/200000 (10.85%): 	Loss: 5.352701187133789	recon_loss: 0.0025433246046304703	bpp_loss: 4.589703559875488	aux_loss: 296.021484375
12:15:50 INFO - main: Train iter. 21800/200000 (10.9%): 	Loss: 5.369992733001709	recon_loss: 0.0026268225628882647	bpp_loss: 4.581945896148682	aux_loss: 293.60052490234375
12:16:23 INFO - main: Train iter. 21900/200000 (10.95%): 	Loss: 5.367580890655518	recon_loss: 0.0025847197975963354	bpp_loss: 4.592164993286133	aux_loss: 292.60260009765625
12:16:55 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 5.353331089019775	recon_loss: 0.0025576006155461073	bpp_loss: 4.586050987243652	aux_loss: 291.3437805175781
12:17:27 INFO - main: Train iter. 22100/200000 (11.05%): 	Loss: 5.365836143493652	recon_loss: 0.0025927976239472628	bpp_loss: 4.587996959686279	aux_loss: 290.1499938964844
12:17:59 INFO - main: Train iter. 22200/200000 (11.1%): 	Loss: 5.356651782989502	recon_loss: 0.002644124673679471	bpp_loss: 4.563414573669434	aux_loss: 288.595947265625
12:18:31 INFO - main: Train iter. 22300/200000 (11.15%): 	Loss: 5.3623762130737305	recon_loss: 0.0025898206513375044	bpp_loss: 4.585430145263672	aux_loss: 287.2099304199219
12:19:03 INFO - main: Train iter. 22400/200000 (11.2%): 	Loss: 5.366838455200195	recon_loss: 0.0025689147878438234	bpp_loss: 4.596164226531982	aux_loss: 286.5537109375
12:19:35 INFO - main: Train iter. 22500/200000 (11.25%): 	Loss: 5.399905681610107	recon_loss: 0.002694646595045924	bpp_loss: 4.5915117263793945	aux_loss: 284.96112060546875
12:20:07 INFO - main: Train iter. 22600/200000 (11.3%): 	Loss: 5.354935646057129	recon_loss: 0.0025796168483793736	bpp_loss: 4.581050395965576	aux_loss: 283.753662109375
12:20:39 INFO - main: Train iter. 22700/200000 (11.35%): 	Loss: 5.4378533363342285	recon_loss: 0.002834262792021036	bpp_loss: 4.587574481964111	aux_loss: 282.2251892089844
12:21:10 INFO - main: Train iter. 22800/200000 (11.4%): 	Loss: 5.364774227142334	recon_loss: 0.002599239582195878	bpp_loss: 4.585002422332764	aux_loss: 279.9599609375
12:21:42 INFO - main: Train iter. 22900/200000 (11.45%): 	Loss: 5.346199989318848	recon_loss: 0.002552378224208951	bpp_loss: 4.580486297607422	aux_loss: 279.3172912597656
12:22:14 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 5.376115798950195	recon_loss: 0.002651949878782034	bpp_loss: 4.580530643463135	aux_loss: 279.86474609375
12:22:46 INFO - main: Train iter. 23100/200000 (11.55%): 	Loss: 5.359012126922607	recon_loss: 0.0025776559486985207	bpp_loss: 4.585715293884277	aux_loss: 277.1706848144531
12:23:18 INFO - main: Train iter. 23200/200000 (11.6%): 	Loss: 5.356386184692383	recon_loss: 0.0025502322241663933	bpp_loss: 4.5913166999816895	aux_loss: 276.20635986328125
12:23:51 INFO - main: Train iter. 23300/200000 (11.65%): 	Loss: 5.348287582397461	recon_loss: 0.0025485653895884752	bpp_loss: 4.5837178230285645	aux_loss: 275.0798645019531
12:24:23 INFO - main: Train iter. 23400/200000 (11.7%): 	Loss: 5.378388404846191	recon_loss: 0.002642205683514476	bpp_loss: 4.585726737976074	aux_loss: 272.74542236328125
12:24:55 INFO - main: Train iter. 23500/200000 (11.75%): 	Loss: 5.352008819580078	recon_loss: 0.0025760112330317497	bpp_loss: 4.579205513000488	aux_loss: 271.6141662597656
12:25:26 INFO - main: Train iter. 23600/200000 (11.8%): 	Loss: 5.357813358306885	recon_loss: 0.0025575945619493723	bpp_loss: 4.5905351638793945	aux_loss: 270.6817626953125
12:25:58 INFO - main: Train iter. 23700/200000 (11.85%): 	Loss: 5.355418682098389	recon_loss: 0.002537122229114175	bpp_loss: 4.594282150268555	aux_loss: 269.17926025390625
12:26:30 INFO - main: Train iter. 23800/200000 (11.9%): 	Loss: 5.3763813972473145	recon_loss: 0.002592239761725068	bpp_loss: 4.598709583282471	aux_loss: 267.34429931640625
12:27:02 INFO - main: Train iter. 23900/200000 (11.95%): 	Loss: 5.336426258087158	recon_loss: 0.002539436100050807	bpp_loss: 4.5745954513549805	aux_loss: 266.5990905761719
12:27:34 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 5.364346981048584	recon_loss: 0.0026133358478546143	bpp_loss: 4.58034610748291	aux_loss: 265.79754638671875
12:28:06 INFO - main: Train iter. 24100/200000 (12.05%): 	Loss: 5.343878746032715	recon_loss: 0.002545272931456566	bpp_loss: 4.580296993255615	aux_loss: 263.5278625488281
12:28:38 INFO - main: Train iter. 24200/200000 (12.1%): 	Loss: 5.3497467041015625	recon_loss: 0.002565753413364291	bpp_loss: 4.580020427703857	aux_loss: 261.8074951171875
12:29:10 INFO - main: Train iter. 24300/200000 (12.15%): 	Loss: 5.364081382751465	recon_loss: 0.0025614588521420956	bpp_loss: 4.595643520355225	aux_loss: 260.54052734375
12:29:41 INFO - main: Train iter. 24400/200000 (12.2%): 	Loss: 5.35226583480835	recon_loss: 0.0025366456247866154	bpp_loss: 4.591272354125977	aux_loss: 259.4862976074219
12:30:13 INFO - main: Train iter. 24500/200000 (12.25%): 	Loss: 5.336148262023926	recon_loss: 0.0025139267090708017	bpp_loss: 4.58197021484375	aux_loss: 258.9093017578125
12:30:45 INFO - main: Train iter. 24600/200000 (12.3%): 	Loss: 5.382732391357422	recon_loss: 0.002697520423680544	bpp_loss: 4.573476314544678	aux_loss: 256.3944091796875
12:31:18 INFO - main: Train iter. 24700/200000 (12.35%): 	Loss: 5.354400634765625	recon_loss: 0.002553073223680258	bpp_loss: 4.5884785652160645	aux_loss: 254.41873168945312
12:31:50 INFO - main: Train iter. 24800/200000 (12.4%): 	Loss: 5.352957248687744	recon_loss: 0.002592073753476143	bpp_loss: 4.5753350257873535	aux_loss: 254.71006774902344
12:32:22 INFO - main: Train iter. 24900/200000 (12.45%): 	Loss: 5.345008373260498	recon_loss: 0.0025605561677366495	bpp_loss: 4.576841354370117	aux_loss: 251.73858642578125
12:32:54 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 5.350467205047607	recon_loss: 0.002536836778745055	bpp_loss: 4.589416027069092	aux_loss: 251.68405151367188
12:33:05 INFO - main: {'TEST MSE': 0.00254727883277053, 'TEST BPP': 4.59928125, 'TEST loss': 5.351133857727051, 'TEST recon_loss': 0.002547278919024393, 'TEST bpp_loss': 4.586950177192688}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
12:33:37 INFO - main: Train iter. 25100/200000 (12.55%): 	Loss: 5.35346794128418	recon_loss: 0.0025856331922113895	bpp_loss: 4.577777862548828	aux_loss: 249.10250854492188
12:34:09 INFO - main: Train iter. 25200/200000 (12.6%): 	Loss: 5.352148532867432	recon_loss: 0.002548512304201722	bpp_loss: 4.587594985961914	aux_loss: 248.66830444335938
12:34:40 INFO - main: Train iter. 25300/200000 (12.65%): 	Loss: 5.339216709136963	recon_loss: 0.0025371022056788206	bpp_loss: 4.578085899353027	aux_loss: 247.97711181640625
12:35:12 INFO - main: Train iter. 25400/200000 (12.7%): 	Loss: 5.348400115966797	recon_loss: 0.0025294055230915546	bpp_loss: 4.589578628540039	aux_loss: 246.48245239257812
12:35:44 INFO - main: Train iter. 25500/200000 (12.75%): 	Loss: 5.355993747711182	recon_loss: 0.0025627645663917065	bpp_loss: 4.587164402008057	aux_loss: 245.394775390625
12:36:16 INFO - main: Train iter. 25600/200000 (12.8%): 	Loss: 5.343013763427734	recon_loss: 0.0025231570471078157	bpp_loss: 4.586066722869873	aux_loss: 244.66810607910156
12:36:48 INFO - main: Train iter. 25700/200000 (12.85%): 	Loss: 5.351164817810059	recon_loss: 0.0025428743101656437	bpp_loss: 4.5883026123046875	aux_loss: 242.869140625
12:37:20 INFO - main: Train iter. 25800/200000 (12.9%): 	Loss: 5.339904308319092	recon_loss: 0.002521070186048746	bpp_loss: 4.583583354949951	aux_loss: 241.83377075195312
12:37:52 INFO - main: Train iter. 25900/200000 (12.95%): 	Loss: 5.350872039794922	recon_loss: 0.002513376995921135	bpp_loss: 4.596858978271484	aux_loss: 240.36334228515625
12:38:25 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 5.343088626861572	recon_loss: 0.002537933411076665	bpp_loss: 4.5817084312438965	aux_loss: 237.97035217285156
12:38:57 INFO - main: Train iter. 26100/200000 (13.05%): 	Loss: 5.3386664390563965	recon_loss: 0.002508784644305706	bpp_loss: 4.586030960083008	aux_loss: 237.93460083007812
12:39:29 INFO - main: Train iter. 26200/200000 (13.1%): 	Loss: 5.458987236022949	recon_loss: 0.0028999210335314274	bpp_loss: 4.589010715484619	aux_loss: 236.4949493408203
12:40:00 INFO - main: Train iter. 26300/200000 (13.15%): 	Loss: 5.359020233154297	recon_loss: 0.0025957755278795958	bpp_loss: 4.580287456512451	aux_loss: 232.37738037109375
12:40:32 INFO - main: Train iter. 26400/200000 (13.2%): 	Loss: 5.353885173797607	recon_loss: 0.002539018401876092	bpp_loss: 4.592179775238037	aux_loss: 232.34481811523438
12:41:04 INFO - main: Train iter. 26500/200000 (13.25%): 	Loss: 5.376600742340088	recon_loss: 0.0026390685234218836	bpp_loss: 4.584880352020264	aux_loss: 231.8098602294922
12:41:36 INFO - main: Train iter. 26600/200000 (13.3%): 	Loss: 5.345981121063232	recon_loss: 0.002572881756350398	bpp_loss: 4.5741167068481445	aux_loss: 228.70225524902344
12:42:08 INFO - main: Train iter. 26700/200000 (13.35%): 	Loss: 5.341945648193359	recon_loss: 0.002531576668843627	bpp_loss: 4.582472801208496	aux_loss: 228.57269287109375
12:42:40 INFO - main: Train iter. 26800/200000 (13.4%): 	Loss: 5.35348653793335	recon_loss: 0.0025561728980392218	bpp_loss: 4.586634635925293	aux_loss: 227.47447204589844
12:43:12 INFO - main: Train iter. 26900/200000 (13.45%): 	Loss: 5.347997665405273	recon_loss: 0.0025386339984834194	bpp_loss: 4.586407661437988	aux_loss: 226.45492553710938
12:43:44 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 5.352754592895508	recon_loss: 0.0025150792207568884	bpp_loss: 4.598230838775635	aux_loss: 225.6556396484375
12:44:16 INFO - main: Train iter. 27100/200000 (13.55%): 	Loss: 5.359864711761475	recon_loss: 0.00250201765447855	bpp_loss: 4.609259605407715	aux_loss: 225.02911376953125
12:44:47 INFO - main: Train iter. 27200/200000 (13.6%): 	Loss: 5.3680009841918945	recon_loss: 0.002591281197965145	bpp_loss: 4.590616703033447	aux_loss: 223.45022583007812
12:45:19 INFO - main: Train iter. 27300/200000 (13.65%): 	Loss: 5.36392879486084	recon_loss: 0.002624456537887454	bpp_loss: 4.576591968536377	aux_loss: 219.62435913085938
12:45:53 INFO - main: Train iter. 27400/200000 (13.7%): 	Loss: 5.346976280212402	recon_loss: 0.0025350856594741344	bpp_loss: 4.586450576782227	aux_loss: 219.5167694091797
12:46:24 INFO - main: Train iter. 27500/200000 (13.75%): 	Loss: 5.42354154586792	recon_loss: 0.0027333302423357964	bpp_loss: 4.603542327880859	aux_loss: 218.97219848632812
12:46:56 INFO - main: Train iter. 27600/200000 (13.8%): 	Loss: 5.354224681854248	recon_loss: 0.0025512499269098043	bpp_loss: 4.5888495445251465	aux_loss: 217.7275390625
12:47:28 INFO - main: Train iter. 27700/200000 (13.85%): 	Loss: 5.350107669830322	recon_loss: 0.0025142927188426256	bpp_loss: 4.59581995010376	aux_loss: 216.18121337890625
12:48:00 INFO - main: Train iter. 27800/200000 (13.9%): 	Loss: 5.340049743652344	recon_loss: 0.0024995633866637945	bpp_loss: 4.59018087387085	aux_loss: 215.11769104003906
12:48:32 INFO - main: Train iter. 27900/200000 (13.95%): 	Loss: 5.350635051727295	recon_loss: 0.0025648248847573996	bpp_loss: 4.581187725067139	aux_loss: 212.8708038330078
12:49:04 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 5.341723918914795	recon_loss: 0.0025149730499833822	bpp_loss: 4.5872321128845215	aux_loss: 212.36468505859375
12:49:35 INFO - main: Train iter. 28100/200000 (14.05%): 	Loss: 5.356762409210205	recon_loss: 0.0025442768819630146	bpp_loss: 4.593479156494141	aux_loss: 211.14822387695312
12:50:07 INFO - main: Train iter. 28200/200000 (14.1%): 	Loss: 5.338512420654297	recon_loss: 0.002501558279618621	bpp_loss: 4.588045120239258	aux_loss: 209.70220947265625
12:50:39 INFO - main: Train iter. 28300/200000 (14.15%): 	Loss: 5.358490943908691	recon_loss: 0.002581042004749179	bpp_loss: 4.584178447723389	aux_loss: 209.0695037841797
12:51:11 INFO - main: Train iter. 28400/200000 (14.2%): 	Loss: 5.35587215423584	recon_loss: 0.002549614990130067	bpp_loss: 4.590987682342529	aux_loss: 206.94100952148438
12:51:43 INFO - main: Train iter. 28500/200000 (14.25%): 	Loss: 5.344780445098877	recon_loss: 0.002518362831324339	bpp_loss: 4.589271545410156	aux_loss: 206.85684204101562
12:52:15 INFO - main: Train iter. 28600/200000 (14.3%): 	Loss: 5.3354620933532715	recon_loss: 0.0024944962933659554	bpp_loss: 4.587113380432129	aux_loss: 205.07308959960938
12:52:47 INFO - main: Train iter. 28700/200000 (14.35%): 	Loss: 5.354122161865234	recon_loss: 0.0025481809861958027	bpp_loss: 4.589667797088623	aux_loss: 202.77598571777344
12:53:20 INFO - main: Train iter. 28800/200000 (14.4%): 	Loss: 5.350069999694824	recon_loss: 0.0025545363314449787	bpp_loss: 4.583709239959717	aux_loss: 199.09474182128906
12:53:52 INFO - main: Train iter. 28900/200000 (14.45%): 	Loss: 5.350597858428955	recon_loss: 0.0025187497958540916	bpp_loss: 4.594973087310791	aux_loss: 199.59902954101562
12:54:24 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 5.342194080352783	recon_loss: 0.0024965328630059958	bpp_loss: 4.593234062194824	aux_loss: 199.516357421875
12:54:56 INFO - main: Train iter. 29100/200000 (14.55%): 	Loss: 5.354477405548096	recon_loss: 0.0025558513589203358	bpp_loss: 4.587721824645996	aux_loss: 198.94384765625
12:55:27 INFO - main: Train iter. 29200/200000 (14.6%): 	Loss: 5.348117828369141	recon_loss: 0.002526680938899517	bpp_loss: 4.590113639831543	aux_loss: 196.5228271484375
12:55:59 INFO - main: Train iter. 29300/200000 (14.65%): 	Loss: 5.344437122344971	recon_loss: 0.002525534015148878	bpp_loss: 4.5867767333984375	aux_loss: 195.9707489013672
12:56:31 INFO - main: Train iter. 29400/200000 (14.7%): 	Loss: 5.361386299133301	recon_loss: 0.0025126193650066853	bpp_loss: 4.607600688934326	aux_loss: 194.19664001464844
12:57:03 INFO - main: Train iter. 29500/200000 (14.75%): 	Loss: 5.32990837097168	recon_loss: 0.002499051857739687	bpp_loss: 4.580193042755127	aux_loss: 194.06600952148438
12:57:35 INFO - main: Train iter. 29600/200000 (14.8%): 	Loss: 5.350374698638916	recon_loss: 0.0025403767358511686	bpp_loss: 4.588261604309082	aux_loss: 190.69827270507812
12:58:07 INFO - main: Train iter. 29700/200000 (14.85%): 	Loss: 5.349007606506348	recon_loss: 0.002524987095966935	bpp_loss: 4.591511249542236	aux_loss: 189.42213439941406
12:58:39 INFO - main: Train iter. 29800/200000 (14.9%): 	Loss: 5.346807956695557	recon_loss: 0.0024989473167806864	bpp_loss: 4.597123622894287	aux_loss: 188.60569763183594
12:59:10 INFO - main: Train iter. 29900/200000 (14.95%): 	Loss: 5.360067844390869	recon_loss: 0.0025854429695755243	bpp_loss: 4.584434986114502	aux_loss: 187.71408081054688
12:59:42 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 5.34511661529541	recon_loss: 0.0025126836262643337	bpp_loss: 4.591311454772949	aux_loss: 186.1626434326172
12:59:53 INFO - main: {'TEST MSE': 0.0025030825814759553, 'TEST BPP': 4.607578125, 'TEST loss': 5.345515446662903, 'TEST recon_loss': 0.0025030826637521385, 'TEST bpp_loss': 4.5945906472206115}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:00:26 INFO - main: Train iter. 30100/200000 (15.05%): 	Loss: 5.3669610023498535	recon_loss: 0.0025884928181767464	bpp_loss: 4.5904130935668945	aux_loss: 185.80685424804688
13:00:58 INFO - main: Train iter. 30200/200000 (15.1%): 	Loss: 5.360084533691406	recon_loss: 0.0025408905930817127	bpp_loss: 4.597817420959473	aux_loss: 183.2709503173828
13:01:30 INFO - main: Train iter. 30300/200000 (15.15%): 	Loss: 5.340756416320801	recon_loss: 0.002497554523870349	bpp_loss: 4.591490268707275	aux_loss: 182.5165557861328
13:02:02 INFO - main: Train iter. 30400/200000 (15.2%): 	Loss: 5.340005397796631	recon_loss: 0.0025322220753878355	bpp_loss: 4.580338954925537	aux_loss: 179.56324768066406
13:02:34 INFO - main: Train iter. 30500/200000 (15.25%): 	Loss: 5.350228309631348	recon_loss: 0.0025007526855915785	bpp_loss: 4.600002288818359	aux_loss: 179.76393127441406
13:03:05 INFO - main: Train iter. 30600/200000 (15.3%): 	Loss: 5.336338043212891	recon_loss: 0.002488155383616686	bpp_loss: 4.58989143371582	aux_loss: 179.74758911132812
13:03:37 INFO - main: Train iter. 30700/200000 (15.35%): 	Loss: 5.363037109375	recon_loss: 0.002522303257137537	bpp_loss: 4.606346130371094	aux_loss: 176.68179321289062
13:04:09 INFO - main: Train iter. 30800/200000 (15.4%): 	Loss: 5.353137969970703	recon_loss: 0.0025045291986316442	bpp_loss: 4.601778984069824	aux_loss: 176.52688598632812
13:04:41 INFO - main: Train iter. 30900/200000 (15.45%): 	Loss: 5.347388744354248	recon_loss: 0.002516437554731965	bpp_loss: 4.592457294464111	aux_loss: 175.2846221923828
13:05:13 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 5.323361396789551	recon_loss: 0.0024857905227690935	bpp_loss: 4.577624320983887	aux_loss: 172.5583038330078
13:05:45 INFO - main: Train iter. 31100/200000 (15.55%): 	Loss: 5.338766574859619	recon_loss: 0.002504358533769846	bpp_loss: 4.587459087371826	aux_loss: 172.0175323486328
13:06:17 INFO - main: Train iter. 31200/200000 (15.6%): 	Loss: 5.336343288421631	recon_loss: 0.0024977284483611584	bpp_loss: 4.587024688720703	aux_loss: 171.4153289794922
13:06:49 INFO - main: Train iter. 31300/200000 (15.65%): 	Loss: 5.353582382202148	recon_loss: 0.0025513269938528538	bpp_loss: 4.588184356689453	aux_loss: 167.90504455566406
13:07:21 INFO - main: Train iter. 31400/200000 (15.7%): 	Loss: 5.358032703399658	recon_loss: 0.0025246639270335436	bpp_loss: 4.60063362121582	aux_loss: 165.88616943359375
13:07:54 INFO - main: Train iter. 31500/200000 (15.75%): 	Loss: 5.354806900024414	recon_loss: 0.002507265191525221	bpp_loss: 4.602627277374268	aux_loss: 166.54891967773438
13:08:26 INFO - main: Train iter. 31600/200000 (15.8%): 	Loss: 5.3423237800598145	recon_loss: 0.0025332090444862843	bpp_loss: 4.582361221313477	aux_loss: 164.0008544921875
13:08:58 INFO - main: Train iter. 31700/200000 (15.85%): 	Loss: 5.3430891036987305	recon_loss: 0.0024953035172075033	bpp_loss: 4.594498157501221	aux_loss: 163.5196533203125
13:09:29 INFO - main: Train iter. 31800/200000 (15.9%): 	Loss: 5.343544960021973	recon_loss: 0.002521839691326022	bpp_loss: 4.586993217468262	aux_loss: 162.6161346435547
13:10:01 INFO - main: Train iter. 31900/200000 (15.95%): 	Loss: 5.355569362640381	recon_loss: 0.002499961294233799	bpp_loss: 4.605580806732178	aux_loss: 161.3974609375
13:10:33 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 5.348825931549072	recon_loss: 0.0024913372471928596	bpp_loss: 4.601424694061279	aux_loss: 161.16212463378906
13:11:05 INFO - main: Train iter. 32100/200000 (16.05%): 	Loss: 5.355613708496094	recon_loss: 0.0025351550430059433	bpp_loss: 4.595067024230957	aux_loss: 159.09010314941406
13:11:37 INFO - main: Train iter. 32200/200000 (16.1%): 	Loss: 5.336389541625977	recon_loss: 0.0025142324157059193	bpp_loss: 4.582119941711426	aux_loss: 157.688720703125
13:12:09 INFO - main: Train iter. 32300/200000 (16.15%): 	Loss: 5.351484298706055	recon_loss: 0.0024972420651465654	bpp_loss: 4.602311611175537	aux_loss: 156.7189483642578
13:12:40 INFO - main: Train iter. 32400/200000 (16.2%): 	Loss: 5.368138790130615	recon_loss: 0.0025784107856452465	bpp_loss: 4.594615459442139	aux_loss: 155.510498046875
13:13:12 INFO - main: Train iter. 32500/200000 (16.25%): 	Loss: 5.351408958435059	recon_loss: 0.002531682839617133	bpp_loss: 4.591904163360596	aux_loss: 151.94192504882812
13:13:44 INFO - main: Train iter. 32600/200000 (16.3%): 	Loss: 5.341536045074463	recon_loss: 0.0024960534647107124	bpp_loss: 4.592720031738281	aux_loss: 152.4791259765625
13:14:16 INFO - main: Train iter. 32700/200000 (16.35%): 	Loss: 5.34438943862915	recon_loss: 0.0024971957318484783	bpp_loss: 4.595230579376221	aux_loss: 150.6934814453125
13:14:48 INFO - main: Train iter. 32800/200000 (16.4%): 	Loss: 5.344369888305664	recon_loss: 0.0025738838594406843	bpp_loss: 4.57220458984375	aux_loss: 147.00100708007812
13:15:21 INFO - main: Train iter. 32900/200000 (16.45%): 	Loss: 5.343548774719238	recon_loss: 0.002536771586164832	bpp_loss: 4.582517147064209	aux_loss: 145.54466247558594
13:15:53 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 5.334357261657715	recon_loss: 0.0024968853686004877	bpp_loss: 4.585291862487793	aux_loss: 146.53643798828125
13:16:25 INFO - main: Train iter. 33100/200000 (16.55%): 	Loss: 5.356582164764404	recon_loss: 0.002529724733904004	bpp_loss: 4.597664833068848	aux_loss: 145.47572326660156
13:16:56 INFO - main: Train iter. 33200/200000 (16.6%): 	Loss: 5.330318927764893	recon_loss: 0.002479161601513624	bpp_loss: 4.5865702629089355	aux_loss: 144.32601928710938
13:17:28 INFO - main: Train iter. 33300/200000 (16.65%): 	Loss: 5.329463005065918	recon_loss: 0.0024618706665933132	bpp_loss: 4.590901851654053	aux_loss: 143.3861541748047
13:18:00 INFO - main: Train iter. 33400/200000 (16.7%): 	Loss: 5.333759307861328	recon_loss: 0.0025043764617294073	bpp_loss: 4.582446575164795	aux_loss: 142.26243591308594
13:18:32 INFO - main: Train iter. 33500/200000 (16.75%): 	Loss: 5.337708473205566	recon_loss: 0.0024858249817043543	bpp_loss: 4.591960906982422	aux_loss: 141.8162841796875
13:19:04 INFO - main: Train iter. 33600/200000 (16.8%): 	Loss: 5.344941139221191	recon_loss: 0.0024930916260927916	bpp_loss: 4.597013473510742	aux_loss: 141.36236572265625
13:19:36 INFO - main: Train iter. 33700/200000 (16.85%): 	Loss: 5.344078540802002	recon_loss: 0.0024865565355867147	bpp_loss: 4.598111629486084	aux_loss: 137.47900390625
13:20:08 INFO - main: Train iter. 33800/200000 (16.9%): 	Loss: 5.351547718048096	recon_loss: 0.002528999000787735	bpp_loss: 4.59284782409668	aux_loss: 135.43093872070312
13:20:39 INFO - main: Train iter. 33900/200000 (16.95%): 	Loss: 5.324653625488281	recon_loss: 0.0024854368530213833	bpp_loss: 4.579022407531738	aux_loss: 135.39642333984375
13:21:11 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 5.3558526039123535	recon_loss: 0.002533513819798827	bpp_loss: 4.595798492431641	aux_loss: 134.78866577148438
13:21:43 INFO - main: Train iter. 34100/200000 (17.05%): 	Loss: 5.330173492431641	recon_loss: 0.0024872208014130592	bpp_loss: 4.584007263183594	aux_loss: 132.60704040527344
13:22:16 INFO - main: Train iter. 34200/200000 (17.1%): 	Loss: 5.384793281555176	recon_loss: 0.00263966154307127	bpp_loss: 4.592894554138184	aux_loss: 131.77090454101562
13:22:48 INFO - main: Train iter. 34300/200000 (17.15%): 	Loss: 5.359677314758301	recon_loss: 0.002554180333390832	bpp_loss: 4.593423366546631	aux_loss: 128.3761749267578
13:23:20 INFO - main: Train iter. 34400/200000 (17.2%): 	Loss: 5.33381986618042	recon_loss: 0.0024980311281979084	bpp_loss: 4.584410667419434	aux_loss: 128.0975341796875
13:23:52 INFO - main: Train iter. 34500/200000 (17.25%): 	Loss: 5.350159645080566	recon_loss: 0.002479508053511381	bpp_loss: 4.606307029724121	aux_loss: 127.93782806396484
13:24:24 INFO - main: Train iter. 34600/200000 (17.3%): 	Loss: 5.348645210266113	recon_loss: 0.002498716115951538	bpp_loss: 4.599030494689941	aux_loss: 126.0182113647461
13:24:56 INFO - main: Train iter. 34700/200000 (17.35%): 	Loss: 5.329734802246094	recon_loss: 0.0024817532394081354	bpp_loss: 4.585208892822266	aux_loss: 124.89268493652344
13:25:27 INFO - main: Train iter. 34800/200000 (17.4%): 	Loss: 5.344002723693848	recon_loss: 0.002540776738896966	bpp_loss: 4.5817694664001465	aux_loss: 121.580810546875
13:25:59 INFO - main: Train iter. 34900/200000 (17.45%): 	Loss: 5.334074020385742	recon_loss: 0.002502670045942068	bpp_loss: 4.583272933959961	aux_loss: 121.56853485107422
13:26:31 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 5.3609089851379395	recon_loss: 0.0025550751015543938	bpp_loss: 4.594386577606201	aux_loss: 120.70854949951172
13:26:42 INFO - main: {'TEST MSE': 0.00252595440187797, 'TEST BPP': 4.610734375, 'TEST loss': 5.355294209003448, 'TEST recon_loss': 0.002525954484939575, 'TEST bpp_loss': 4.597507866382599}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:27:14 INFO - main: Train iter. 35100/200000 (17.55%): 	Loss: 5.3522748947143555	recon_loss: 0.0025013673584908247	bpp_loss: 4.601864814758301	aux_loss: 119.1426010131836
13:27:46 INFO - main: Train iter. 35200/200000 (17.6%): 	Loss: 5.328279495239258	recon_loss: 0.0024728369899094105	bpp_loss: 4.586428642272949	aux_loss: 118.00997924804688
13:28:17 INFO - main: Train iter. 35300/200000 (17.65%): 	Loss: 5.341885566711426	recon_loss: 0.0024794582277536392	bpp_loss: 4.598048210144043	aux_loss: 118.13788604736328
13:28:49 INFO - main: Train iter. 35400/200000 (17.7%): 	Loss: 5.3583664894104	recon_loss: 0.0025660162791609764	bpp_loss: 4.588561534881592	aux_loss: 115.13868713378906
13:29:21 INFO - main: Train iter. 35500/200000 (17.75%): 	Loss: 5.3469367027282715	recon_loss: 0.0024974446278065443	bpp_loss: 4.597703456878662	aux_loss: 114.01759338378906
13:29:54 INFO - main: Train iter. 35600/200000 (17.8%): 	Loss: 5.341599464416504	recon_loss: 0.002484335331246257	bpp_loss: 4.596298694610596	aux_loss: 112.89837646484375
13:30:26 INFO - main: Train iter. 35700/200000 (17.85%): 	Loss: 5.373493671417236	recon_loss: 0.0026129859033972025	bpp_loss: 4.589597702026367	aux_loss: 111.83008575439453
13:30:58 INFO - main: Train iter. 35800/200000 (17.9%): 	Loss: 5.3306193351745605	recon_loss: 0.002507055178284645	bpp_loss: 4.578502655029297	aux_loss: 107.68879699707031
13:31:30 INFO - main: Train iter. 35900/200000 (17.95%): 	Loss: 5.339813709259033	recon_loss: 0.0024823364801704884	bpp_loss: 4.5951128005981445	aux_loss: 108.88597869873047
13:32:02 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 5.363334655761719	recon_loss: 0.0025976235046982765	bpp_loss: 4.584047794342041	aux_loss: 107.29138946533203
13:32:34 INFO - main: Train iter. 36100/200000 (18.05%): 	Loss: 5.3312602043151855	recon_loss: 0.002515628235414624	bpp_loss: 4.576571941375732	aux_loss: 103.22835540771484
13:33:06 INFO - main: Train iter. 36200/200000 (18.1%): 	Loss: 5.340738296508789	recon_loss: 0.0025266800075769424	bpp_loss: 4.582734107971191	aux_loss: 101.857421875
13:33:37 INFO - main: Train iter. 36300/200000 (18.15%): 	Loss: 5.346113681793213	recon_loss: 0.002491414314135909	bpp_loss: 4.598689556121826	aux_loss: 102.53971099853516
13:34:09 INFO - main: Train iter. 36400/200000 (18.2%): 	Loss: 5.353763580322266	recon_loss: 0.0024931454099714756	bpp_loss: 4.6058197021484375	aux_loss: 101.45613098144531
13:34:41 INFO - main: Train iter. 36500/200000 (18.25%): 	Loss: 5.343865394592285	recon_loss: 0.0024773776531219482	bpp_loss: 4.60065221786499	aux_loss: 101.1434326171875
13:35:13 INFO - main: Train iter. 36600/200000 (18.3%): 	Loss: 5.33404541015625	recon_loss: 0.0025025238282978535	bpp_loss: 4.583288192749023	aux_loss: 99.31997680664062
13:35:45 INFO - main: Train iter. 36700/200000 (18.35%): 	Loss: 5.32808780670166	recon_loss: 0.0024765864945948124	bpp_loss: 4.585111618041992	aux_loss: 98.54786682128906
13:36:17 INFO - main: Train iter. 36800/200000 (18.4%): 	Loss: 5.3489251136779785	recon_loss: 0.0024926611222326756	bpp_loss: 4.601126670837402	aux_loss: 97.19509887695312
13:36:49 INFO - main: Train iter. 36900/200000 (18.45%): 	Loss: 5.341508388519287	recon_loss: 0.0024842487182468176	bpp_loss: 4.59623384475708	aux_loss: 96.45791625976562
13:37:22 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 5.367653846740723	recon_loss: 0.002611162606626749	bpp_loss: 4.5843048095703125	aux_loss: 93.8705825805664
13:37:54 INFO - main: Train iter. 37100/200000 (18.55%): 	Loss: 5.341525554656982	recon_loss: 0.00249839317984879	bpp_loss: 4.592007637023926	aux_loss: 92.23097229003906
13:38:25 INFO - main: Train iter. 37200/200000 (18.6%): 	Loss: 5.326602458953857	recon_loss: 0.0024651146959513426	bpp_loss: 4.5870680809021	aux_loss: 91.14183807373047
13:38:57 INFO - main: Train iter. 37300/200000 (18.65%): 	Loss: 5.3406524658203125	recon_loss: 0.002494731917977333	bpp_loss: 4.592232704162598	aux_loss: 88.42218017578125
13:39:29 INFO - main: Train iter. 37400/200000 (18.7%): 	Loss: 5.33395528793335	recon_loss: 0.002462768694385886	bpp_loss: 4.5951247215271	aux_loss: 87.49136352539062
13:40:01 INFO - main: Train iter. 37500/200000 (18.75%): 	Loss: 5.353999137878418	recon_loss: 0.0025407441426068544	bpp_loss: 4.591775894165039	aux_loss: 86.71510314941406
13:40:33 INFO - main: Train iter. 37600/200000 (18.8%): 	Loss: 5.341424465179443	recon_loss: 0.0024728074204176664	bpp_loss: 4.599582195281982	aux_loss: 86.33195495605469
13:41:05 INFO - main: Train iter. 37700/200000 (18.85%): 	Loss: 5.33063268661499	recon_loss: 0.002462134463712573	bpp_loss: 4.591992378234863	aux_loss: 83.52826690673828
13:41:37 INFO - main: Train iter. 37800/200000 (18.9%): 	Loss: 5.342469692230225	recon_loss: 0.0024654092267155647	bpp_loss: 4.602847099304199	aux_loss: 83.67247009277344
13:42:09 INFO - main: Train iter. 37900/200000 (18.95%): 	Loss: 5.342900276184082	recon_loss: 0.002470726380124688	bpp_loss: 4.601682186126709	aux_loss: 81.74880981445312
13:42:40 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 5.354301929473877	recon_loss: 0.002531633712351322	bpp_loss: 4.594811916351318	aux_loss: 80.18804168701172
13:43:12 INFO - main: Train iter. 38100/200000 (19.05%): 	Loss: 5.334597587585449	recon_loss: 0.002470973413437605	bpp_loss: 4.593305587768555	aux_loss: 79.7569580078125
13:43:44 INFO - main: Train iter. 38200/200000 (19.1%): 	Loss: 5.336007118225098	recon_loss: 0.0024898480623960495	bpp_loss: 4.589052677154541	aux_loss: 77.8271484375
13:44:17 INFO - main: Train iter. 38300/200000 (19.15%): 	Loss: 5.338835716247559	recon_loss: 0.0024757124483585358	bpp_loss: 4.596121788024902	aux_loss: 77.18470764160156
13:44:49 INFO - main: Train iter. 38400/200000 (19.2%): 	Loss: 5.339710235595703	recon_loss: 0.002460802672430873	bpp_loss: 4.60146951675415	aux_loss: 76.10734558105469
13:45:21 INFO - main: Train iter. 38500/200000 (19.25%): 	Loss: 5.332681655883789	recon_loss: 0.0024600441101938486	bpp_loss: 4.594668388366699	aux_loss: 74.71573638916016
13:45:53 INFO - main: Train iter. 38600/200000 (19.3%): 	Loss: 5.3329596519470215	recon_loss: 0.0024750472512096167	bpp_loss: 4.590445518493652	aux_loss: 72.2375259399414
13:46:25 INFO - main: Train iter. 38700/200000 (19.35%): 	Loss: 5.324270725250244	recon_loss: 0.0024597770534455776	bpp_loss: 4.586337566375732	aux_loss: 72.17601013183594
13:46:57 INFO - main: Train iter. 38800/200000 (19.4%): 	Loss: 5.366498947143555	recon_loss: 0.0025372388772666454	bpp_loss: 4.605327129364014	aux_loss: 69.95093536376953
13:47:28 INFO - main: Train iter. 38900/200000 (19.45%): 	Loss: 5.334792613983154	recon_loss: 0.0024996695574373007	bpp_loss: 4.5848917961120605	aux_loss: 66.45073699951172
13:48:00 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 5.34381628036499	recon_loss: 0.0024965463671833277	bpp_loss: 4.594852447509766	aux_loss: 65.6549301147461
13:48:32 INFO - main: Train iter. 39100/200000 (19.55%): 	Loss: 5.3473005294799805	recon_loss: 0.002478494308888912	bpp_loss: 4.603752136230469	aux_loss: 65.3531494140625
13:49:04 INFO - main: Train iter. 39200/200000 (19.6%): 	Loss: 5.32937479019165	recon_loss: 0.002466414123773575	bpp_loss: 4.589450359344482	aux_loss: 63.8875846862793
13:49:36 INFO - main: Train iter. 39300/200000 (19.65%): 	Loss: 5.333263397216797	recon_loss: 0.002455920446664095	bpp_loss: 4.596487522125244	aux_loss: 63.036346435546875
13:50:08 INFO - main: Train iter. 39400/200000 (19.7%): 	Loss: 5.339474201202393	recon_loss: 0.002502148039638996	bpp_loss: 4.58882999420166	aux_loss: 61.447418212890625
13:50:40 INFO - main: Train iter. 39500/200000 (19.75%): 	Loss: 5.346828937530518	recon_loss: 0.0024802456609904766	bpp_loss: 4.602755069732666	aux_loss: 62.3162841796875
13:51:11 INFO - main: Train iter. 39600/200000 (19.8%): 	Loss: 5.345466613769531	recon_loss: 0.002469582948833704	bpp_loss: 4.6045918464660645	aux_loss: 60.09613800048828
13:51:45 INFO - main: Train iter. 39700/200000 (19.85%): 	Loss: 5.336968898773193	recon_loss: 0.0024741841480135918	bpp_loss: 4.5947136878967285	aux_loss: 58.49899673461914
13:52:16 INFO - main: Train iter. 39800/200000 (19.9%): 	Loss: 5.3592658042907715	recon_loss: 0.0025718952529132366	bpp_loss: 4.5876970291137695	aux_loss: 56.67082214355469
13:52:48 INFO - main: Train iter. 39900/200000 (19.95%): 	Loss: 5.355453968048096	recon_loss: 0.0024961570743471384	bpp_loss: 4.606606960296631	aux_loss: 53.49974060058594
13:53:21 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 5.34056282043457	recon_loss: 0.0024753801990300417	bpp_loss: 4.5979485511779785	aux_loss: 53.371116638183594
13:53:31 INFO - main: {'TEST MSE': 0.0024703055636045245, 'TEST BPP': 4.6098671875, 'TEST loss': 5.33738325548172, 'TEST recon_loss': 0.0024703056481666865, 'TEST bpp_loss': 4.59629156255722}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
13:54:03 INFO - main: Train iter. 40100/200000 (20.05%): 	Loss: 5.3389058113098145	recon_loss: 0.0024632809218019247	bpp_loss: 4.599921703338623	aux_loss: 51.6907844543457
13:54:35 INFO - main: Train iter. 40200/200000 (20.1%): 	Loss: 5.352807998657227	recon_loss: 0.0024802880361676216	bpp_loss: 4.608721733093262	aux_loss: 51.26915740966797
13:55:06 INFO - main: Train iter. 40300/200000 (20.15%): 	Loss: 5.3357110023498535	recon_loss: 0.0024599654134362936	bpp_loss: 4.597721576690674	aux_loss: 50.054229736328125
13:55:38 INFO - main: Train iter. 40400/200000 (20.2%): 	Loss: 5.335916996002197	recon_loss: 0.002461004536598921	bpp_loss: 4.597615718841553	aux_loss: 49.1658821105957
13:56:10 INFO - main: Train iter. 40500/200000 (20.25%): 	Loss: 5.326629638671875	recon_loss: 0.0024699124041944742	bpp_loss: 4.585655689239502	aux_loss: 48.45456314086914
13:56:42 INFO - main: Train iter. 40600/200000 (20.3%): 	Loss: 5.330652236938477	recon_loss: 0.0024542715400457382	bpp_loss: 4.5943708419799805	aux_loss: 48.48326110839844
13:57:14 INFO - main: Train iter. 40700/200000 (20.35%): 	Loss: 5.323800563812256	recon_loss: 0.002464011777192354	bpp_loss: 4.584597110748291	aux_loss: 46.45025634765625
13:57:46 INFO - main: Train iter. 40800/200000 (20.4%): 	Loss: 5.330005645751953	recon_loss: 0.002458119299262762	bpp_loss: 4.592569828033447	aux_loss: 45.16633987426758
13:58:17 INFO - main: Train iter. 40900/200000 (20.45%): 	Loss: 5.326072692871094	recon_loss: 0.0024554936680942774	bpp_loss: 4.5894246101379395	aux_loss: 44.769500732421875
13:58:49 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 5.323684215545654	recon_loss: 0.002447789302095771	bpp_loss: 4.5893473625183105	aux_loss: 43.74507141113281
13:59:22 INFO - main: Train iter. 41100/200000 (20.55%): 	Loss: 5.329712867736816	recon_loss: 0.0024531250819563866	bpp_loss: 4.593775272369385	aux_loss: 42.197933197021484
13:59:54 INFO - main: Train iter. 41200/200000 (20.6%): 	Loss: 5.333331108093262	recon_loss: 0.0024652767460793257	bpp_loss: 4.593748092651367	aux_loss: 41.04397201538086
14:00:26 INFO - main: Train iter. 41300/200000 (20.65%): 	Loss: 5.3378095626831055	recon_loss: 0.0024555849377065897	bpp_loss: 4.601134300231934	aux_loss: 40.00596618652344
14:00:58 INFO - main: Train iter. 41400/200000 (20.7%): 	Loss: 5.341559886932373	recon_loss: 0.0024551970418542624	bpp_loss: 4.605000972747803	aux_loss: 38.43662643432617
14:01:30 INFO - main: Train iter. 41500/200000 (20.75%): 	Loss: 5.340255260467529	recon_loss: 0.002457072027027607	bpp_loss: 4.603133678436279	aux_loss: 37.77825164794922
14:02:02 INFO - main: Train iter. 41600/200000 (20.8%): 	Loss: 5.333547115325928	recon_loss: 0.00244892411865294	bpp_loss: 4.598869800567627	aux_loss: 36.294044494628906
14:02:34 INFO - main: Train iter. 41700/200000 (20.85%): 	Loss: 5.368781566619873	recon_loss: 0.002556503051891923	bpp_loss: 4.60183048248291	aux_loss: 35.60396957397461
14:03:06 INFO - main: Train iter. 41800/200000 (20.9%): 	Loss: 5.3263840675354	recon_loss: 0.0024774132762104273	bpp_loss: 4.583159923553467	aux_loss: 34.04528045654297
14:03:37 INFO - main: Train iter. 41900/200000 (20.95%): 	Loss: 5.334488868713379	recon_loss: 0.002456142334267497	bpp_loss: 4.597646236419678	aux_loss: 33.473731994628906
14:04:09 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 5.358695983886719	recon_loss: 0.0025435667484998703	bpp_loss: 4.595625877380371	aux_loss: 32.299896240234375
14:04:41 INFO - main: Train iter. 42100/200000 (21.05%): 	Loss: 5.352971076965332	recon_loss: 0.0024715352337807417	bpp_loss: 4.611510276794434	aux_loss: 30.47182846069336
14:05:13 INFO - main: Train iter. 42200/200000 (21.1%): 	Loss: 5.338278770446777	recon_loss: 0.0024537134449929	bpp_loss: 4.6021647453308105	aux_loss: 29.620882034301758
14:05:45 INFO - main: Train iter. 42300/200000 (21.15%): 	Loss: 5.331325054168701	recon_loss: 0.002474663546308875	bpp_loss: 4.588925838470459	aux_loss: 28.704954147338867
14:06:18 INFO - main: Train iter. 42400/200000 (21.2%): 	Loss: 5.344647407531738	recon_loss: 0.0024628739338368177	bpp_loss: 4.605785369873047	aux_loss: 27.04533576965332
14:06:50 INFO - main: Train iter. 42500/200000 (21.25%): 	Loss: 5.325716972351074	recon_loss: 0.002451658947393298	bpp_loss: 4.590219497680664	aux_loss: 27.022457122802734
14:07:22 INFO - main: Train iter. 42600/200000 (21.3%): 	Loss: 5.331808090209961	recon_loss: 0.0024698360357433558	bpp_loss: 4.59085750579834	aux_loss: 25.287853240966797
14:07:53 INFO - main: Train iter. 42700/200000 (21.35%): 	Loss: 5.335065841674805	recon_loss: 0.0024583013728260994	bpp_loss: 4.597575664520264	aux_loss: 24.433807373046875
14:08:25 INFO - main: Train iter. 42800/200000 (21.4%): 	Loss: 5.33338737487793	recon_loss: 0.0024979047011584044	bpp_loss: 4.584015846252441	aux_loss: 22.847503662109375
14:08:57 INFO - main: Train iter. 42900/200000 (21.45%): 	Loss: 5.331557273864746	recon_loss: 0.0024676586035639048	bpp_loss: 4.591259479522705	aux_loss: 22.122806549072266
14:09:29 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 5.331178665161133	recon_loss: 0.0024511038791388273	bpp_loss: 4.5958476066589355	aux_loss: 21.970523834228516
14:10:01 INFO - main: Train iter. 43100/200000 (21.55%): 	Loss: 5.3396759033203125	recon_loss: 0.002463296987116337	bpp_loss: 4.600687026977539	aux_loss: 21.228607177734375
14:10:33 INFO - main: Train iter. 43200/200000 (21.6%): 	Loss: 5.334869384765625	recon_loss: 0.002453951397910714	bpp_loss: 4.598683834075928	aux_loss: 20.586185455322266
14:11:04 INFO - main: Train iter. 43300/200000 (21.65%): 	Loss: 5.3405656814575195	recon_loss: 0.002453380264341831	bpp_loss: 4.604551792144775	aux_loss: 19.12490463256836
14:11:36 INFO - main: Train iter. 43400/200000 (21.7%): 	Loss: 5.337766170501709	recon_loss: 0.002456730231642723	bpp_loss: 4.600747108459473	aux_loss: 19.83031463623047
14:12:08 INFO - main: Train iter. 43500/200000 (21.75%): 	Loss: 5.3405303955078125	recon_loss: 0.002455034526064992	bpp_loss: 4.604020118713379	aux_loss: 17.305278778076172
14:12:40 INFO - main: Train iter. 43600/200000 (21.8%): 	Loss: 5.332686424255371	recon_loss: 0.0024546582717448473	bpp_loss: 4.596288681030273	aux_loss: 16.825838088989258
14:13:12 INFO - main: Train iter. 43700/200000 (21.85%): 	Loss: 5.322293758392334	recon_loss: 0.002445382997393608	bpp_loss: 4.58867883682251	aux_loss: 15.984033584594727
14:13:45 INFO - main: Train iter. 43800/200000 (21.9%): 	Loss: 5.337189674377441	recon_loss: 0.002447499195113778	bpp_loss: 4.602940082550049	aux_loss: 15.22691535949707
14:14:17 INFO - main: Train iter. 43900/200000 (21.95%): 	Loss: 5.332860469818115	recon_loss: 0.0024474388919770718	bpp_loss: 4.598628997802734	aux_loss: 14.330816268920898
14:14:49 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 5.329701900482178	recon_loss: 0.002458231756463647	bpp_loss: 4.5922322273254395	aux_loss: 13.786786079406738
14:15:21 INFO - main: Train iter. 44100/200000 (22.05%): 	Loss: 5.331280708312988	recon_loss: 0.002448352752253413	bpp_loss: 4.596775054931641	aux_loss: 13.050374984741211
14:15:53 INFO - main: Train iter. 44200/200000 (22.1%): 	Loss: 5.323575973510742	recon_loss: 0.002456117421388626	bpp_loss: 4.586740970611572	aux_loss: 12.664835929870605
14:16:24 INFO - main: Train iter. 44300/200000 (22.15%): 	Loss: 5.333664417266846	recon_loss: 0.0024425580631941557	bpp_loss: 4.600896835327148	aux_loss: 12.016159057617188
14:16:56 INFO - main: Train iter. 44400/200000 (22.2%): 	Loss: 5.330752849578857	recon_loss: 0.0024532789830118418	bpp_loss: 4.59476900100708	aux_loss: 11.610221862792969
14:17:28 INFO - main: Train iter. 44500/200000 (22.25%): 	Loss: 5.328354358673096	recon_loss: 0.002451437059789896	bpp_loss: 4.592923164367676	aux_loss: 11.137062072753906
14:18:00 INFO - main: Train iter. 44600/200000 (22.3%): 	Loss: 5.332339286804199	recon_loss: 0.002448810264468193	bpp_loss: 4.597696304321289	aux_loss: 10.731657028198242
14:18:32 INFO - main: Train iter. 44700/200000 (22.35%): 	Loss: 5.338028430938721	recon_loss: 0.0024540068116039038	bpp_loss: 4.601826190948486	aux_loss: 11.031819343566895
14:19:04 INFO - main: Train iter. 44800/200000 (22.4%): 	Loss: 5.336380481719971	recon_loss: 0.0024494335521012545	bpp_loss: 4.601550579071045	aux_loss: 9.918110847473145
14:19:36 INFO - main: Train iter. 44900/200000 (22.45%): 	Loss: 5.33636999130249	recon_loss: 0.0024402576964348555	bpp_loss: 4.604292869567871	aux_loss: 9.366872787475586
14:20:08 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 5.339929103851318	recon_loss: 0.002445712685585022	bpp_loss: 4.606215476989746	aux_loss: 8.761984825134277
14:20:19 INFO - main: {'TEST MSE': 0.0024473583758781816, 'TEST BPP': 4.6145546875, 'TEST loss': 5.334523275852203, 'TEST recon_loss': 0.0024473584555089476, 'TEST bpp_loss': 4.600315737724304}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:20:51 INFO - main: Train iter. 45100/200000 (22.55%): 	Loss: 5.337048053741455	recon_loss: 0.0024492943193763494	bpp_loss: 4.602259635925293	aux_loss: 8.566146850585938
14:21:24 INFO - main: Train iter. 45200/200000 (22.6%): 	Loss: 5.334539413452148	recon_loss: 0.002452649176120758	bpp_loss: 4.598744869232178	aux_loss: 8.144745826721191
14:21:56 INFO - main: Train iter. 45300/200000 (22.65%): 	Loss: 5.3326897621154785	recon_loss: 0.002448995830491185	bpp_loss: 4.597990989685059	aux_loss: 8.226633071899414
14:22:28 INFO - main: Train iter. 45400/200000 (22.7%): 	Loss: 5.323155879974365	recon_loss: 0.002441888442263007	bpp_loss: 4.59058952331543	aux_loss: 7.4202680587768555
14:22:59 INFO - main: Train iter. 45500/200000 (22.75%): 	Loss: 5.327219486236572	recon_loss: 0.0024430754128843546	bpp_loss: 4.594296932220459	aux_loss: 7.231421947479248
14:23:31 INFO - main: Train iter. 45600/200000 (22.8%): 	Loss: 5.320407390594482	recon_loss: 0.0024453909136354923	bpp_loss: 4.586790084838867	aux_loss: 7.191254138946533
14:24:03 INFO - main: Train iter. 45700/200000 (22.85%): 	Loss: 5.3381757736206055	recon_loss: 0.0024596380535513163	bpp_loss: 4.600284099578857	aux_loss: 6.4064202308654785
14:24:35 INFO - main: Train iter. 45800/200000 (22.9%): 	Loss: 5.336078643798828	recon_loss: 0.0024462135042995214	bpp_loss: 4.602214813232422	aux_loss: 6.145866394042969
14:25:07 INFO - main: Train iter. 45900/200000 (22.95%): 	Loss: 5.334385871887207	recon_loss: 0.002456109970808029	bpp_loss: 4.59755277633667	aux_loss: 5.982598304748535
14:25:39 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 5.31932258605957	recon_loss: 0.002446971833705902	bpp_loss: 4.585230827331543	aux_loss: 5.674561977386475
14:26:11 INFO - main: Train iter. 46100/200000 (23.05%): 	Loss: 5.338564872741699	recon_loss: 0.0024441315326839685	bpp_loss: 4.605325222015381	aux_loss: 5.1373114585876465
14:26:42 INFO - main: Train iter. 46200/200000 (23.1%): 	Loss: 5.324080467224121	recon_loss: 0.0024561614263802767	bpp_loss: 4.5872321128845215	aux_loss: 4.981698036193848
14:27:14 INFO - main: Train iter. 46300/200000 (23.15%): 	Loss: 5.32766056060791	recon_loss: 0.002443061675876379	bpp_loss: 4.594742298126221	aux_loss: 4.696651935577393
14:27:46 INFO - main: Train iter. 46400/200000 (23.2%): 	Loss: 5.322967052459717	recon_loss: 0.002446438418701291	bpp_loss: 4.589035511016846	aux_loss: 4.47314453125
14:28:19 INFO - main: Train iter. 46500/200000 (23.25%): 	Loss: 5.327160835266113	recon_loss: 0.002442573197185993	bpp_loss: 4.594388961791992	aux_loss: 4.521933555603027
14:28:51 INFO - main: Train iter. 46600/200000 (23.3%): 	Loss: 5.327784061431885	recon_loss: 0.0024478270206600428	bpp_loss: 4.593435764312744	aux_loss: 3.8764548301696777
14:29:23 INFO - main: Train iter. 46700/200000 (23.35%): 	Loss: 5.334645748138428	recon_loss: 0.0024443843867629766	bpp_loss: 4.601330280303955	aux_loss: 3.475313663482666
14:29:55 INFO - main: Train iter. 46800/200000 (23.4%): 	Loss: 5.326775550842285	recon_loss: 0.002442756434902549	bpp_loss: 4.593948841094971	aux_loss: 3.1812551021575928
14:30:27 INFO - main: Train iter. 46900/200000 (23.45%): 	Loss: 5.3313422203063965	recon_loss: 0.0024497900158166885	bpp_loss: 4.596405029296875	aux_loss: 3.1660547256469727
14:30:58 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 5.333335876464844	recon_loss: 0.0024428232572972775	bpp_loss: 4.600489139556885	aux_loss: 3.4104971885681152
14:31:30 INFO - main: Train iter. 47100/200000 (23.55%): 	Loss: 5.334049224853516	recon_loss: 0.0024418148677796125	bpp_loss: 4.601504802703857	aux_loss: 2.5137457847595215
14:32:02 INFO - main: Train iter. 47200/200000 (23.6%): 	Loss: 5.321264266967773	recon_loss: 0.0024486971087753773	bpp_loss: 4.586655139923096	aux_loss: 2.3000519275665283
14:32:34 INFO - main: Train iter. 47300/200000 (23.65%): 	Loss: 5.3288164138793945	recon_loss: 0.002447414444759488	bpp_loss: 4.594592094421387	aux_loss: 2.132312059402466
14:33:06 INFO - main: Train iter. 47400/200000 (23.7%): 	Loss: 5.334836006164551	recon_loss: 0.0024560438469052315	bpp_loss: 4.598022937774658	aux_loss: 2.0725762844085693
14:33:38 INFO - main: Train iter. 47500/200000 (23.75%): 	Loss: 5.314669609069824	recon_loss: 0.0024460626300424337	bpp_loss: 4.580850601196289	aux_loss: 1.8478729724884033
14:34:09 INFO - main: Train iter. 47600/200000 (23.8%): 	Loss: 5.330299377441406	recon_loss: 0.0024480223655700684	bpp_loss: 4.595892429351807	aux_loss: 1.708048701286316
14:34:41 INFO - main: Train iter. 47700/200000 (23.85%): 	Loss: 5.333906173706055	recon_loss: 0.002440112642943859	bpp_loss: 4.601872444152832	aux_loss: 1.4038467407226562
14:35:13 INFO - main: Train iter. 47800/200000 (23.9%): 	Loss: 5.329322814941406	recon_loss: 0.0024478647392243147	bpp_loss: 4.594963550567627	aux_loss: 1.2916972637176514
14:35:46 INFO - main: Train iter. 47900/200000 (23.95%): 	Loss: 5.337928771972656	recon_loss: 0.0024447618052363396	bpp_loss: 4.6045002937316895	aux_loss: 1.4557851552963257
14:36:19 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 5.327130317687988	recon_loss: 0.0024451788049191236	bpp_loss: 4.593576908111572	aux_loss: 1.2152116298675537
14:36:51 INFO - main: Train iter. 48100/200000 (24.05%): 	Loss: 5.322865962982178	recon_loss: 0.0024471981450915337	bpp_loss: 4.5887064933776855	aux_loss: 1.0197246074676514
14:37:22 INFO - main: Train iter. 48200/200000 (24.1%): 	Loss: 5.330239295959473	recon_loss: 0.0024491422809660435	bpp_loss: 4.595496654510498	aux_loss: 1.1321938037872314
14:37:54 INFO - main: Train iter. 48300/200000 (24.15%): 	Loss: 5.334083080291748	recon_loss: 0.002444986952468753	bpp_loss: 4.600586891174316	aux_loss: 0.8420110940933228
14:38:26 INFO - main: Train iter. 48400/200000 (24.2%): 	Loss: 5.3252410888671875	recon_loss: 0.0024471753276884556	bpp_loss: 4.59108829498291	aux_loss: 0.7239160537719727
14:38:58 INFO - main: Train iter. 48500/200000 (24.25%): 	Loss: 5.322957992553711	recon_loss: 0.0024554969277232885	bpp_loss: 4.58630895614624	aux_loss: 0.6703792810440063
14:39:30 INFO - main: Train iter. 48600/200000 (24.3%): 	Loss: 5.33015775680542	recon_loss: 0.0024441955611109734	bpp_loss: 4.596899032592773	aux_loss: 0.8226479887962341
14:40:02 INFO - main: Train iter. 48700/200000 (24.35%): 	Loss: 5.327996730804443	recon_loss: 0.0024489928036928177	bpp_loss: 4.59329891204834	aux_loss: 0.7213003635406494
14:40:34 INFO - main: Train iter. 48800/200000 (24.4%): 	Loss: 5.336133003234863	recon_loss: 0.0024596089497208595	bpp_loss: 4.598250389099121	aux_loss: 1.2658467292785645
14:41:06 INFO - main: Train iter. 48900/200000 (24.45%): 	Loss: 5.331082344055176	recon_loss: 0.0024467078037559986	bpp_loss: 4.597070217132568	aux_loss: 0.4868362843990326
14:41:38 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 5.340691566467285	recon_loss: 0.0024401757400482893	bpp_loss: 4.608638763427734	aux_loss: 0.8052033185958862
14:42:09 INFO - main: Train iter. 49100/200000 (24.55%): 	Loss: 5.3280415534973145	recon_loss: 0.0024510761722922325	bpp_loss: 4.592718601226807	aux_loss: 0.3947501480579376
14:42:41 INFO - main: Train iter. 49200/200000 (24.6%): 	Loss: 5.336925983428955	recon_loss: 0.002447324339300394	bpp_loss: 4.602728843688965	aux_loss: 0.8634178638458252
14:43:14 INFO - main: Train iter. 49300/200000 (24.65%): 	Loss: 5.327539443969727	recon_loss: 0.0024442754220217466	bpp_loss: 4.59425687789917	aux_loss: 0.3811061978340149
14:43:46 INFO - main: Train iter. 49400/200000 (24.7%): 	Loss: 5.347295761108398	recon_loss: 0.002463253913447261	bpp_loss: 4.6083197593688965	aux_loss: 0.1743728220462799
14:44:18 INFO - main: Train iter. 49500/200000 (24.75%): 	Loss: 5.333477020263672	recon_loss: 0.0024486493784934282	bpp_loss: 4.59888219833374	aux_loss: 0.22964677214622498
14:44:50 INFO - main: Train iter. 49600/200000 (24.8%): 	Loss: 5.328546047210693	recon_loss: 0.0024477376136928797	bpp_loss: 4.59422492980957	aux_loss: 0.3624078035354614
14:45:22 INFO - main: Train iter. 49700/200000 (24.85%): 	Loss: 5.335939884185791	recon_loss: 0.0024481110740453005	bpp_loss: 4.60150671005249	aux_loss: 0.39182591438293457
14:45:54 INFO - main: Train iter. 49800/200000 (24.9%): 	Loss: 5.333527088165283	recon_loss: 0.0024550415109843016	bpp_loss: 4.597014427185059	aux_loss: 1.2333078384399414
14:46:26 INFO - main: Train iter. 49900/200000 (24.95%): 	Loss: 5.335640907287598	recon_loss: 0.0024386965669691563	bpp_loss: 4.604032039642334	aux_loss: 0.27239835262298584
14:46:57 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 5.3349480628967285	recon_loss: 0.0024386660661548376	bpp_loss: 4.603348255157471	aux_loss: 0.7837600111961365
14:47:09 INFO - main: {'TEST MSE': 0.0024450439996191024, 'TEST BPP': 4.6155390625, 'TEST loss': 5.334827867984772, 'TEST recon_loss': 0.0024450440800283103, 'TEST bpp_loss': 4.601314646244049}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
14:47:40 INFO - main: Train iter. 50100/200000 (25.05%): 	Loss: 5.330189228057861	recon_loss: 0.002456866903230548	bpp_loss: 4.5931291580200195	aux_loss: 0.5854495167732239
14:48:12 INFO - main: Train iter. 50200/200000 (25.1%): 	Loss: 5.312946796417236	recon_loss: 0.0024451648350805044	bpp_loss: 4.579397201538086	aux_loss: 0.31599825620651245
14:48:44 INFO - main: Train iter. 50300/200000 (25.15%): 	Loss: 5.32108736038208	recon_loss: 0.0024589814711362123	bpp_loss: 4.583393096923828	aux_loss: 0.4956675171852112
14:49:16 INFO - main: Train iter. 50400/200000 (25.2%): 	Loss: 5.33669376373291	recon_loss: 0.0024524806067347527	bpp_loss: 4.600949764251709	aux_loss: 0.3103070855140686
14:49:48 INFO - main: Train iter. 50500/200000 (25.25%): 	Loss: 5.337594985961914	recon_loss: 0.002440869342535734	bpp_loss: 4.605334281921387	aux_loss: 0.2509753108024597
14:50:21 INFO - main: Train iter. 50600/200000 (25.3%): 	Loss: 5.32504940032959	recon_loss: 0.0024507087655365467	bpp_loss: 4.589836597442627	aux_loss: 0.41683143377304077
14:50:53 INFO - main: Train iter. 50700/200000 (25.35%): 	Loss: 5.3250017166137695	recon_loss: 0.0024428556207567453	bpp_loss: 4.592144966125488	aux_loss: 0.8974764347076416
14:51:25 INFO - main: Train iter. 50800/200000 (25.4%): 	Loss: 5.333323955535889	recon_loss: 0.0024361086543649435	bpp_loss: 4.60249137878418	aux_loss: 0.2181861698627472
14:51:56 INFO - main: Train iter. 50900/200000 (25.45%): 	Loss: 5.31986141204834	recon_loss: 0.002436809940263629	bpp_loss: 4.588818550109863	aux_loss: 0.21720731258392334
14:52:28 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 5.331269264221191	recon_loss: 0.002450928557664156	bpp_loss: 4.5959906578063965	aux_loss: 0.30158311128616333
14:53:00 INFO - main: Train iter. 51100/200000 (25.55%): 	Loss: 5.328717231750488	recon_loss: 0.002439597388729453	bpp_loss: 4.596837997436523	aux_loss: 0.25323286652565
14:53:32 INFO - main: Train iter. 51200/200000 (25.6%): 	Loss: 5.332298278808594	recon_loss: 0.002448636805638671	bpp_loss: 4.597707271575928	aux_loss: 0.4905491769313812
14:54:04 INFO - main: Train iter. 51300/200000 (25.65%): 	Loss: 5.335330963134766	recon_loss: 0.002452294807881117	bpp_loss: 4.599642276763916	aux_loss: 0.4543747305870056
14:54:36 INFO - main: Train iter. 51400/200000 (25.7%): 	Loss: 5.3306684494018555	recon_loss: 0.0024515895638614893	bpp_loss: 4.595191478729248	aux_loss: 0.4115258455276489
14:55:08 INFO - main: Train iter. 51500/200000 (25.75%): 	Loss: 5.323404312133789	recon_loss: 0.002438951749354601	bpp_loss: 4.591718673706055	aux_loss: 0.7421281337738037
14:55:40 INFO - main: Train iter. 51600/200000 (25.8%): 	Loss: 5.319020748138428	recon_loss: 0.002438722178339958	bpp_loss: 4.587404251098633	aux_loss: 0.7356711626052856
14:56:12 INFO - main: Train iter. 51700/200000 (25.85%): 	Loss: 5.331127643585205	recon_loss: 0.002445520833134651	bpp_loss: 4.597471237182617	aux_loss: 0.5969681143760681
14:56:44 INFO - main: Train iter. 51800/200000 (25.9%): 	Loss: 5.341060161590576	recon_loss: 0.00244330195710063	bpp_loss: 4.60806941986084	aux_loss: 0.5411537885665894
14:57:16 INFO - main: Train iter. 51900/200000 (25.95%): 	Loss: 5.3358659744262695	recon_loss: 0.0024399682879447937	bpp_loss: 4.603875637054443	aux_loss: 0.2317529171705246
14:57:49 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 5.323511123657227	recon_loss: 0.0024386339355260134	bpp_loss: 4.591920852661133	aux_loss: 0.4138258993625641
14:58:21 INFO - main: Train iter. 52100/200000 (26.05%): 	Loss: 5.321573257446289	recon_loss: 0.002437824849039316	bpp_loss: 4.590225696563721	aux_loss: 0.3413262367248535
14:58:53 INFO - main: Train iter. 52200/200000 (26.1%): 	Loss: 5.3222784996032715	recon_loss: 0.0024465294554829597	bpp_loss: 4.588319778442383	aux_loss: 0.22656790912151337
14:59:24 INFO - main: Train iter. 52300/200000 (26.15%): 	Loss: 5.340527057647705	recon_loss: 0.002446083351969719	bpp_loss: 4.606701850891113	aux_loss: 0.22027510404586792
14:59:56 INFO - main: Train iter. 52400/200000 (26.2%): 	Loss: 5.321281909942627	recon_loss: 0.002438448602333665	bpp_loss: 4.589747428894043	aux_loss: 0.7866663932800293
15:00:28 INFO - main: Train iter. 52500/200000 (26.25%): 	Loss: 5.32266092300415	recon_loss: 0.0024452160578221083	bpp_loss: 4.5890960693359375	aux_loss: 0.5008088946342468
15:01:00 INFO - main: Train iter. 52600/200000 (26.3%): 	Loss: 5.335653305053711	recon_loss: 0.0024593800771981478	bpp_loss: 4.59783935546875	aux_loss: 1.0882952213287354
15:01:32 INFO - main: Train iter. 52700/200000 (26.35%): 	Loss: 5.338715553283691	recon_loss: 0.002440026728436351	bpp_loss: 4.606707572937012	aux_loss: 0.3074910342693329
15:02:04 INFO - main: Train iter. 52800/200000 (26.4%): 	Loss: 5.329538345336914	recon_loss: 0.0024385724682360888	bpp_loss: 4.59796667098999	aux_loss: 0.3739854693412781
15:02:36 INFO - main: Train iter. 52900/200000 (26.45%): 	Loss: 5.333196640014648	recon_loss: 0.002453963737934828	bpp_loss: 4.5970072746276855	aux_loss: 0.19401228427886963
15:03:08 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 5.328141212463379	recon_loss: 0.0024444195441901684	bpp_loss: 4.594815254211426	aux_loss: 0.30809304118156433
15:03:40 INFO - main: Train iter. 53100/200000 (26.55%): 	Loss: 5.315084934234619	recon_loss: 0.0024376981891691685	bpp_loss: 4.583775520324707	aux_loss: 0.47161731123924255
15:04:12 INFO - main: Train iter. 53200/200000 (26.6%): 	Loss: 5.340710163116455	recon_loss: 0.0024422432761639357	bpp_loss: 4.608036994934082	aux_loss: 0.25016337633132935
15:04:43 INFO - main: Train iter. 53300/200000 (26.65%): 	Loss: 5.335202217102051	recon_loss: 0.0024496500845998526	bpp_loss: 4.600306987762451	aux_loss: 0.6641262769699097
15:05:17 INFO - main: Train iter. 53400/200000 (26.7%): 	Loss: 5.326347827911377	recon_loss: 0.0024452712386846542	bpp_loss: 4.592766284942627	aux_loss: 1.0256638526916504
15:05:49 INFO - main: Train iter. 53500/200000 (26.75%): 	Loss: 5.331793785095215	recon_loss: 0.002443555509671569	bpp_loss: 4.598727226257324	aux_loss: 0.2031213641166687
15:06:20 INFO - main: Train iter. 53600/200000 (26.8%): 	Loss: 5.33402156829834	recon_loss: 0.0024483446031808853	bpp_loss: 4.599518299102783	aux_loss: 0.6381570100784302
15:06:52 INFO - main: Train iter. 53700/200000 (26.85%): 	Loss: 5.335055351257324	recon_loss: 0.0024404190480709076	bpp_loss: 4.602929592132568	aux_loss: 0.2366114854812622
15:07:24 INFO - main: Train iter. 53800/200000 (26.9%): 	Loss: 5.328457832336426	recon_loss: 0.0024384157732129097	bpp_loss: 4.596933364868164	aux_loss: 0.34343641996383667
15:07:56 INFO - main: Train iter. 53900/200000 (26.95%): 	Loss: 5.343562602996826	recon_loss: 0.0024432186037302017	bpp_loss: 4.610597133636475	aux_loss: 0.350959450006485
15:08:28 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 5.329597473144531	recon_loss: 0.0024450283963233232	bpp_loss: 4.596088886260986	aux_loss: 0.17877404391765594
15:09:00 INFO - main: Train iter. 54100/200000 (27.05%): 	Loss: 5.3238983154296875	recon_loss: 0.002446852158755064	bpp_loss: 4.589842796325684	aux_loss: 0.6865559816360474
15:09:32 INFO - main: Train iter. 54200/200000 (27.1%): 	Loss: 5.341435432434082	recon_loss: 0.0024409228935837746	bpp_loss: 4.609158515930176	aux_loss: 0.5422121286392212
15:10:04 INFO - main: Train iter. 54300/200000 (27.15%): 	Loss: 5.339731216430664	recon_loss: 0.0024446616880595684	bpp_loss: 4.606332778930664	aux_loss: 0.9491480588912964
15:10:36 INFO - main: Train iter. 54400/200000 (27.2%): 	Loss: 5.317127227783203	recon_loss: 0.002432554494589567	bpp_loss: 4.587360858917236	aux_loss: 0.3185487389564514
15:11:07 INFO - main: Train iter. 54500/200000 (27.25%): 	Loss: 5.320147514343262	recon_loss: 0.0024429603945463896	bpp_loss: 4.587259292602539	aux_loss: 0.26714107394218445
15:11:39 INFO - main: Train iter. 54600/200000 (27.3%): 	Loss: 5.32670259475708	recon_loss: 0.0024361691903322935	bpp_loss: 4.595851898193359	aux_loss: 0.5874935388565063
15:12:12 INFO - main: Train iter. 54700/200000 (27.35%): 	Loss: 5.333908557891846	recon_loss: 0.002443554112687707	bpp_loss: 4.600842475891113	aux_loss: 0.7380475401878357
15:12:44 INFO - main: Train iter. 54800/200000 (27.4%): 	Loss: 5.3321332931518555	recon_loss: 0.0024419014807790518	bpp_loss: 4.599562644958496	aux_loss: 0.4736660420894623
15:13:16 INFO - main: Train iter. 54900/200000 (27.45%): 	Loss: 5.327736854553223	recon_loss: 0.0024387314915657043	bpp_loss: 4.5961174964904785	aux_loss: 0.24012184143066406
15:13:48 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 5.326355934143066	recon_loss: 0.002438821131363511	bpp_loss: 4.594709396362305	aux_loss: 0.6499704122543335
15:13:59 INFO - main: {'TEST MSE': 0.002444293607317114, 'TEST BPP': 4.6155078125, 'TEST loss': 5.334514074325561, 'TEST recon_loss': 0.002444293688517064, 'TEST bpp_loss': 4.6012259612083435}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:14:31 INFO - main: Train iter. 55100/200000 (27.55%): 	Loss: 5.338263511657715	recon_loss: 0.0024387200828641653	bpp_loss: 4.606647491455078	aux_loss: 0.2588910460472107
15:15:03 INFO - main: Train iter. 55200/200000 (27.6%): 	Loss: 5.345548629760742	recon_loss: 0.0024542706087231636	bpp_loss: 4.609267234802246	aux_loss: 0.282726913690567
15:15:34 INFO - main: Train iter. 55300/200000 (27.65%): 	Loss: 5.328307628631592	recon_loss: 0.0024531418457627296	bpp_loss: 4.592365264892578	aux_loss: 0.517683744430542
15:16:06 INFO - main: Train iter. 55400/200000 (27.7%): 	Loss: 5.322987079620361	recon_loss: 0.0024399026297032833	bpp_loss: 4.5910162925720215	aux_loss: 0.27159178256988525
15:16:38 INFO - main: Train iter. 55500/200000 (27.75%): 	Loss: 5.326610565185547	recon_loss: 0.002439840231090784	bpp_loss: 4.594658374786377	aux_loss: 0.21109333634376526
15:17:10 INFO - main: Train iter. 55600/200000 (27.8%): 	Loss: 5.334275722503662	recon_loss: 0.0024381240364164114	bpp_loss: 4.602838516235352	aux_loss: 0.24740305542945862
15:17:41 INFO - main: Train iter. 55700/200000 (27.85%): 	Loss: 5.328378677368164	recon_loss: 0.0024420246481895447	bpp_loss: 4.595771312713623	aux_loss: 1.133415937423706
15:18:13 INFO - main: Train iter. 55800/200000 (27.9%): 	Loss: 5.334015369415283	recon_loss: 0.0024523416068404913	bpp_loss: 4.598312854766846	aux_loss: 0.25580084323883057
15:18:45 INFO - main: Train iter. 55900/200000 (27.95%): 	Loss: 5.324320316314697	recon_loss: 0.002444589976221323	bpp_loss: 4.590943336486816	aux_loss: 0.3527168035507202
15:19:17 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 5.322391986846924	recon_loss: 0.0024371666368097067	bpp_loss: 4.591241836547852	aux_loss: 0.2045809030532837
15:19:50 INFO - main: Train iter. 56100/200000 (28.05%): 	Loss: 5.326693534851074	recon_loss: 0.0024430209305137396	bpp_loss: 4.59378719329834	aux_loss: 0.58632493019104
15:20:22 INFO - main: Train iter. 56200/200000 (28.1%): 	Loss: 5.318635940551758	recon_loss: 0.002445689169690013	bpp_loss: 4.5849289894104	aux_loss: 0.27326977252960205
15:20:54 INFO - main: Train iter. 56300/200000 (28.15%): 	Loss: 5.32426643371582	recon_loss: 0.00244149356149137	bpp_loss: 4.591818332672119	aux_loss: 0.4567517042160034
15:21:26 INFO - main: Train iter. 56400/200000 (28.2%): 	Loss: 5.334155559539795	recon_loss: 0.0024386823642998934	bpp_loss: 4.602550983428955	aux_loss: 0.4355875253677368
15:21:58 INFO - main: Train iter. 56500/200000 (28.25%): 	Loss: 5.320326328277588	recon_loss: 0.002444543642923236	bpp_loss: 4.586963176727295	aux_loss: 0.17424634099006653
15:22:30 INFO - main: Train iter. 56600/200000 (28.3%): 	Loss: 5.32824182510376	recon_loss: 0.0024694346357136965	bpp_loss: 4.587411403656006	aux_loss: 0.22797511518001556
15:23:02 INFO - main: Train iter. 56700/200000 (28.35%): 	Loss: 5.3395161628723145	recon_loss: 0.002463363576680422	bpp_loss: 4.6005072593688965	aux_loss: 0.34741830825805664
15:23:34 INFO - main: Train iter. 56800/200000 (28.4%): 	Loss: 5.336741924285889	recon_loss: 0.002451574429869652	bpp_loss: 4.601269721984863	aux_loss: 0.2505488693714142
15:24:05 INFO - main: Train iter. 56900/200000 (28.45%): 	Loss: 5.334551811218262	recon_loss: 0.0024589814711362123	bpp_loss: 4.59685754776001	aux_loss: 0.8660498261451721
15:24:37 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 5.331638813018799	recon_loss: 0.0024451620411127806	bpp_loss: 4.598090171813965	aux_loss: 0.4298614263534546
15:25:09 INFO - main: Train iter. 57100/200000 (28.55%): 	Loss: 5.325530052185059	recon_loss: 0.002450664294883609	bpp_loss: 4.590330600738525	aux_loss: 0.3556728661060333
15:25:41 INFO - main: Train iter. 57200/200000 (28.6%): 	Loss: 5.338458061218262	recon_loss: 0.0024817476514726877	bpp_loss: 4.593933582305908	aux_loss: 0.5740060806274414
15:26:13 INFO - main: Train iter. 57300/200000 (28.65%): 	Loss: 5.343361854553223	recon_loss: 0.002444469602778554	bpp_loss: 4.610021114349365	aux_loss: 0.5238719582557678
15:26:45 INFO - main: Train iter. 57400/200000 (28.7%): 	Loss: 5.332121849060059	recon_loss: 0.002462532138451934	bpp_loss: 4.593362331390381	aux_loss: 0.29748043417930603
15:27:18 INFO - main: Train iter. 57500/200000 (28.75%): 	Loss: 5.339597225189209	recon_loss: 0.002470992738381028	bpp_loss: 4.598299503326416	aux_loss: 0.31459343433380127
15:27:50 INFO - main: Train iter. 57600/200000 (28.8%): 	Loss: 5.329879283905029	recon_loss: 0.002450899686664343	bpp_loss: 4.594609260559082	aux_loss: 0.4384381175041199
15:28:21 INFO - main: Train iter. 57700/200000 (28.85%): 	Loss: 5.340235710144043	recon_loss: 0.0024472293443977833	bpp_loss: 4.606066703796387	aux_loss: 0.456469863653183
15:28:53 INFO - main: Train iter. 57800/200000 (28.9%): 	Loss: 5.364133358001709	recon_loss: 0.002541352529078722	bpp_loss: 4.601727485656738	aux_loss: 0.6229607462882996
15:29:25 INFO - main: Train iter. 57900/200000 (28.95%): 	Loss: 5.325855255126953	recon_loss: 0.0024616550654172897	bpp_loss: 4.587358474731445	aux_loss: 0.42338496446609497
15:29:57 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 5.34157133102417	recon_loss: 0.0024809620808809996	bpp_loss: 4.597282886505127	aux_loss: 0.3330884873867035
15:30:29 INFO - main: Train iter. 58100/200000 (29.05%): 	Loss: 5.338886260986328	recon_loss: 0.0024563204497098923	bpp_loss: 4.601990222930908	aux_loss: 0.6020939350128174
15:31:01 INFO - main: Train iter. 58200/200000 (29.1%): 	Loss: 5.328250885009766	recon_loss: 0.0024453948717564344	bpp_loss: 4.594632625579834	aux_loss: 0.3837127983570099
15:31:33 INFO - main: Train iter. 58300/200000 (29.15%): 	Loss: 5.3403544425964355	recon_loss: 0.002449984895065427	bpp_loss: 4.605359077453613	aux_loss: 0.5514112114906311
15:32:04 INFO - main: Train iter. 58400/200000 (29.2%): 	Loss: 5.336278915405273	recon_loss: 0.0024453375954180956	bpp_loss: 4.602677822113037	aux_loss: 0.37801313400268555
15:32:36 INFO - main: Train iter. 58500/200000 (29.25%): 	Loss: 5.341480255126953	recon_loss: 0.002483602147549391	bpp_loss: 4.596399784088135	aux_loss: 0.2723424732685089
15:33:08 INFO - main: Train iter. 58600/200000 (29.3%): 	Loss: 5.342549800872803	recon_loss: 0.002460417104884982	bpp_loss: 4.604424476623535	aux_loss: 0.5034436583518982
15:33:40 INFO - main: Train iter. 58700/200000 (29.35%): 	Loss: 5.320589542388916	recon_loss: 0.002446285216137767	bpp_loss: 4.586703777313232	aux_loss: 0.34727737307548523
15:34:13 INFO - main: Train iter. 58800/200000 (29.4%): 	Loss: 5.343296051025391	recon_loss: 0.0025132764130830765	bpp_loss: 4.58931303024292	aux_loss: 0.9693705439567566
15:34:45 INFO - main: Train iter. 58900/200000 (29.45%): 	Loss: 5.330867767333984	recon_loss: 0.002463757526129484	bpp_loss: 4.591740608215332	aux_loss: 0.4943801462650299
15:35:17 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 5.342329978942871	recon_loss: 0.002525477670133114	bpp_loss: 4.584686756134033	aux_loss: 0.5140339732170105
15:35:49 INFO - main: Train iter. 59100/200000 (29.55%): 	Loss: 5.332402229309082	recon_loss: 0.0024850035551935434	bpp_loss: 4.5869011878967285	aux_loss: 0.6250189542770386
15:36:21 INFO - main: Train iter. 59200/200000 (29.6%): 	Loss: 5.345160961151123	recon_loss: 0.002482970943674445	bpp_loss: 4.600269794464111	aux_loss: 1.0704853534698486
15:36:52 INFO - main: Train iter. 59300/200000 (29.65%): 	Loss: 5.336984157562256	recon_loss: 0.0024737997446209192	bpp_loss: 4.594844341278076	aux_loss: 0.5229179859161377
15:37:24 INFO - main: Train iter. 59400/200000 (29.7%): 	Loss: 5.340786933898926	recon_loss: 0.00246008881367743	bpp_loss: 4.602760314941406	aux_loss: 0.4035680890083313
15:37:56 INFO - main: Train iter. 59500/200000 (29.75%): 	Loss: 5.335771560668945	recon_loss: 0.002463748911395669	bpp_loss: 4.596646785736084	aux_loss: 1.3822904825210571
15:38:28 INFO - main: Train iter. 59600/200000 (29.8%): 	Loss: 5.339053153991699	recon_loss: 0.0024499911814928055	bpp_loss: 4.604055881500244	aux_loss: 0.7696629762649536
15:39:00 INFO - main: Train iter. 59700/200000 (29.85%): 	Loss: 5.32809591293335	recon_loss: 0.0024470605421811342	bpp_loss: 4.593977928161621	aux_loss: 0.951130747795105
15:39:31 INFO - main: Train iter. 59800/200000 (29.9%): 	Loss: 5.325404167175293	recon_loss: 0.0024438691325485706	bpp_loss: 4.592243194580078	aux_loss: 0.2274530529975891
15:40:03 INFO - main: Train iter. 59900/200000 (29.95%): 	Loss: 5.3363871574401855	recon_loss: 0.002442945260554552	bpp_loss: 4.603503704071045	aux_loss: 0.5264320373535156
15:40:35 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 5.328967094421387	recon_loss: 0.0024457459803670645	bpp_loss: 4.595243453979492	aux_loss: 0.6462260484695435
15:40:46 INFO - main: {'TEST MSE': 0.002438343385427184, 'TEST BPP': 4.61484375, 'TEST loss': 5.3320370321273804, 'TEST recon_loss': 0.002438343466259539, 'TEST bpp_loss': 4.600533992767334}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
15:41:18 INFO - main: Train iter. 60100/200000 (30.05%): 	Loss: 5.327991485595703	recon_loss: 0.0024430917110294104	bpp_loss: 4.595064163208008	aux_loss: 0.3544085919857025
15:41:51 INFO - main: Train iter. 60200/200000 (30.1%): 	Loss: 5.320748329162598	recon_loss: 0.0024419163819402456	bpp_loss: 4.5881733894348145	aux_loss: 0.21218466758728027
15:42:23 INFO - main: Train iter. 60300/200000 (30.15%): 	Loss: 5.330771446228027	recon_loss: 0.0024560019373893738	bpp_loss: 4.593970775604248	aux_loss: 0.889788031578064
15:42:54 INFO - main: Train iter. 60400/200000 (30.2%): 	Loss: 5.312346458435059	recon_loss: 0.002434951951727271	bpp_loss: 4.5818610191345215	aux_loss: 0.1440982222557068
15:43:26 INFO - main: Train iter. 60500/200000 (30.25%): 	Loss: 5.320438861846924	recon_loss: 0.002434531692415476	bpp_loss: 4.590079307556152	aux_loss: 1.1843688488006592
15:43:58 INFO - main: Train iter. 60600/200000 (30.3%): 	Loss: 5.319287300109863	recon_loss: 0.002444454235956073	bpp_loss: 4.58595085144043	aux_loss: 0.372372031211853
15:44:30 INFO - main: Train iter. 60700/200000 (30.35%): 	Loss: 5.323334217071533	recon_loss: 0.002436206443235278	bpp_loss: 4.592472076416016	aux_loss: 0.776281476020813
15:45:02 INFO - main: Train iter. 60800/200000 (30.4%): 	Loss: 5.34210205078125	recon_loss: 0.0024655857123434544	bpp_loss: 4.602426528930664	aux_loss: 0.49472254514694214
15:45:34 INFO - main: Train iter. 60900/200000 (30.45%): 	Loss: 5.3309478759765625	recon_loss: 0.002463835757225752	bpp_loss: 4.591797351837158	aux_loss: 0.5323296189308167
15:46:06 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 5.341428279876709	recon_loss: 0.0024520575534552336	bpp_loss: 4.60581111907959	aux_loss: 0.5972817540168762
15:46:37 INFO - main: Train iter. 61100/200000 (30.55%): 	Loss: 5.324747085571289	recon_loss: 0.0024449394550174475	bpp_loss: 4.5912652015686035	aux_loss: 1.110539436340332
15:47:09 INFO - main: Train iter. 61200/200000 (30.6%): 	Loss: 5.349163055419922	recon_loss: 0.0024822407867759466	bpp_loss: 4.604490756988525	aux_loss: 0.26903098821640015
15:47:41 INFO - main: Train iter. 61300/200000 (30.65%): 	Loss: 5.327293872833252	recon_loss: 0.00246702809818089	bpp_loss: 4.587185382843018	aux_loss: 1.310288906097412
15:48:13 INFO - main: Train iter. 61400/200000 (30.7%): 	Loss: 5.334338188171387	recon_loss: 0.002454482251778245	bpp_loss: 4.59799337387085	aux_loss: 0.7416702508926392
15:48:45 INFO - main: Train iter. 61500/200000 (30.75%): 	Loss: 5.326447486877441	recon_loss: 0.0024607349187135696	bpp_loss: 4.588227272033691	aux_loss: 0.4242056906223297
15:49:18 INFO - main: Train iter. 61600/200000 (30.8%): 	Loss: 5.335196018218994	recon_loss: 0.002450311789289117	bpp_loss: 4.600102424621582	aux_loss: 0.32385116815567017
15:49:50 INFO - main: Train iter. 61700/200000 (30.85%): 	Loss: 5.353308200836182	recon_loss: 0.0024892103392630816	bpp_loss: 4.6065449714660645	aux_loss: 0.32815101742744446
15:50:22 INFO - main: Train iter. 61800/200000 (30.9%): 	Loss: 5.342540740966797	recon_loss: 0.002458753529936075	bpp_loss: 4.604914665222168	aux_loss: 0.612932562828064
15:50:53 INFO - main: Train iter. 61900/200000 (30.95%): 	Loss: 5.325308322906494	recon_loss: 0.0024494952522218227	bpp_loss: 4.590459823608398	aux_loss: 0.5129199028015137
15:51:25 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 5.333207607269287	recon_loss: 0.0025056092999875546	bpp_loss: 4.581524848937988	aux_loss: 1.861484408378601
15:51:57 INFO - main: Train iter. 62100/200000 (31.05%): 	Loss: 5.33022403717041	recon_loss: 0.0024555176496505737	bpp_loss: 4.593568801879883	aux_loss: 0.8704093098640442
15:52:29 INFO - main: Train iter. 62200/200000 (31.1%): 	Loss: 5.334009170532227	recon_loss: 0.002458295552060008	bpp_loss: 4.59652042388916	aux_loss: 0.7629808783531189
15:53:00 INFO - main: Train iter. 62300/200000 (31.15%): 	Loss: 5.3295817375183105	recon_loss: 0.0024478675331920385	bpp_loss: 4.595221519470215	aux_loss: 1.0808207988739014
15:53:32 INFO - main: Train iter. 62400/200000 (31.2%): 	Loss: 5.338778018951416	recon_loss: 0.0024464039597660303	bpp_loss: 4.604856967926025	aux_loss: 1.1858668327331543
15:54:04 INFO - main: Train iter. 62500/200000 (31.25%): 	Loss: 5.329007148742676	recon_loss: 0.002444748068228364	bpp_loss: 4.595582962036133	aux_loss: 1.5634171962738037
15:54:36 INFO - main: Train iter. 62600/200000 (31.3%): 	Loss: 5.334554672241211	recon_loss: 0.0024426188319921494	bpp_loss: 4.601768970489502	aux_loss: 0.2633390426635742
15:55:08 INFO - main: Train iter. 62700/200000 (31.35%): 	Loss: 5.327311038970947	recon_loss: 0.0024377021472901106	bpp_loss: 4.5960001945495605	aux_loss: 0.5269620418548584
15:55:39 INFO - main: Train iter. 62800/200000 (31.4%): 	Loss: 5.336158275604248	recon_loss: 0.002444618847221136	bpp_loss: 4.6027727127075195	aux_loss: 0.6986286640167236
15:56:13 INFO - main: Train iter. 62900/200000 (31.45%): 	Loss: 5.3297224044799805	recon_loss: 0.0024565360508859158	bpp_loss: 4.592761516571045	aux_loss: 0.5520228743553162
15:56:44 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 5.33885383605957	recon_loss: 0.002441998105496168	bpp_loss: 4.606254577636719	aux_loss: 0.23370835185050964
15:57:16 INFO - main: Train iter. 63100/200000 (31.55%): 	Loss: 5.339896202087402	recon_loss: 0.0024391543120145798	bpp_loss: 4.608150005340576	aux_loss: 1.7495434284210205
15:57:48 INFO - main: Train iter. 63200/200000 (31.6%): 	Loss: 5.3227858543396	recon_loss: 0.002439915668219328	bpp_loss: 4.590811252593994	aux_loss: 0.9708585143089294
15:58:20 INFO - main: Train iter. 63300/200000 (31.65%): 	Loss: 5.34570837020874	recon_loss: 0.0024364639539271593	bpp_loss: 4.614768981933594	aux_loss: 1.0018556118011475
15:58:52 INFO - main: Train iter. 63400/200000 (31.7%): 	Loss: 5.3298726081848145	recon_loss: 0.0024394241627305746	bpp_loss: 4.598045349121094	aux_loss: 0.3705863058567047
15:59:24 INFO - main: Train iter. 63500/200000 (31.75%): 	Loss: 5.325891494750977	recon_loss: 0.0024423678405582905	bpp_loss: 4.593181133270264	aux_loss: 0.4511525630950928
15:59:55 INFO - main: Train iter. 63600/200000 (31.8%): 	Loss: 5.344380855560303	recon_loss: 0.0024361449759453535	bpp_loss: 4.613537311553955	aux_loss: 0.1714664101600647
16:00:27 INFO - main: Train iter. 63700/200000 (31.85%): 	Loss: 5.3265700340271	recon_loss: 0.002432664390653372	bpp_loss: 4.596770763397217	aux_loss: 1.0936018228530884
16:00:59 INFO - main: Train iter. 63800/200000 (31.9%): 	Loss: 5.326750755310059	recon_loss: 0.00243710121139884	bpp_loss: 4.595620155334473	aux_loss: 0.7733847498893738
16:01:31 INFO - main: Train iter. 63900/200000 (31.95%): 	Loss: 5.328679084777832	recon_loss: 0.0024422830902040005	bpp_loss: 4.595993995666504	aux_loss: 0.6739550828933716
16:02:03 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 5.333978176116943	recon_loss: 0.0024372227489948273	bpp_loss: 4.602811336517334	aux_loss: 0.8654983043670654
16:02:35 INFO - main: Train iter. 64100/200000 (32.05%): 	Loss: 5.315387725830078	recon_loss: 0.002433032263070345	bpp_loss: 4.585477828979492	aux_loss: 0.8784745931625366
16:03:07 INFO - main: Train iter. 64200/200000 (32.1%): 	Loss: 5.339588642120361	recon_loss: 0.0024383303243666887	bpp_loss: 4.608089447021484	aux_loss: 0.21082666516304016
16:03:40 INFO - main: Train iter. 64300/200000 (32.15%): 	Loss: 5.328162670135498	recon_loss: 0.0024438092950731516	bpp_loss: 4.595019817352295	aux_loss: 0.8335415124893188
16:04:12 INFO - main: Train iter. 64400/200000 (32.2%): 	Loss: 5.331568717956543	recon_loss: 0.002438983181491494	bpp_loss: 4.599874019622803	aux_loss: 0.28879982233047485
16:04:44 INFO - main: Train iter. 64500/200000 (32.25%): 	Loss: 5.333542823791504	recon_loss: 0.002436811802908778	bpp_loss: 4.602499485015869	aux_loss: 0.5607362389564514
16:05:15 INFO - main: Train iter. 64600/200000 (32.3%): 	Loss: 5.3348917961120605	recon_loss: 0.002440094482153654	bpp_loss: 4.602863311767578	aux_loss: 0.2298801690340042
16:05:47 INFO - main: Train iter. 64700/200000 (32.35%): 	Loss: 5.331018924713135	recon_loss: 0.00244790967553854	bpp_loss: 4.596645832061768	aux_loss: 1.1446590423583984
16:06:19 INFO - main: Train iter. 64800/200000 (32.4%): 	Loss: 5.329699993133545	recon_loss: 0.002435544040054083	bpp_loss: 4.599036693572998	aux_loss: 0.3040926158428192
16:06:51 INFO - main: Train iter. 64900/200000 (32.45%): 	Loss: 5.3294148445129395	recon_loss: 0.002434507478028536	bpp_loss: 4.599062442779541	aux_loss: 1.0995157957077026
16:07:23 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 5.3394622802734375	recon_loss: 0.0024372637271881104	bpp_loss: 4.608283042907715	aux_loss: 0.2142825573682785
16:07:34 INFO - main: {'TEST MSE': 0.0024355661031106083, 'TEST BPP': 4.6160078125, 'TEST loss': 5.332567277908325, 'TEST recon_loss': 0.002435566181782633, 'TEST bpp_loss': 4.601897423744202}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:08:05 INFO - main: Train iter. 65100/200000 (32.55%): 	Loss: 5.338226318359375	recon_loss: 0.0024490002542734146	bpp_loss: 4.6035261154174805	aux_loss: 0.39684247970581055
16:08:37 INFO - main: Train iter. 65200/200000 (32.6%): 	Loss: 5.331593990325928	recon_loss: 0.002441723132506013	bpp_loss: 4.599077224731445	aux_loss: 1.3563398122787476
16:09:09 INFO - main: Train iter. 65300/200000 (32.65%): 	Loss: 5.3246002197265625	recon_loss: 0.0024342131800949574	bpp_loss: 4.594336032867432	aux_loss: 0.684898316860199
16:09:41 INFO - main: Train iter. 65400/200000 (32.7%): 	Loss: 5.323014259338379	recon_loss: 0.0024365067947655916	bpp_loss: 4.592062473297119	aux_loss: 0.2705323100090027
16:10:13 INFO - main: Train iter. 65500/200000 (32.75%): 	Loss: 5.320113658905029	recon_loss: 0.0024338129442185163	bpp_loss: 4.589969635009766	aux_loss: 0.2635163366794586
16:10:45 INFO - main: Train iter. 65600/200000 (32.8%): 	Loss: 5.325162887573242	recon_loss: 0.0024358248338103294	bpp_loss: 4.594415187835693	aux_loss: 0.5419108271598816
16:11:18 INFO - main: Train iter. 65700/200000 (32.85%): 	Loss: 5.34100866317749	recon_loss: 0.0024378919042646885	bpp_loss: 4.609641075134277	aux_loss: 0.4094715118408203
16:11:50 INFO - main: Train iter. 65800/200000 (32.9%): 	Loss: 5.324926853179932	recon_loss: 0.002436104929074645	bpp_loss: 4.594095230102539	aux_loss: 0.32130691409111023
16:12:21 INFO - main: Train iter. 65900/200000 (32.95%): 	Loss: 5.3336334228515625	recon_loss: 0.0024380243849009275	bpp_loss: 4.602226257324219	aux_loss: 0.30739784240722656
16:12:53 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 5.334498882293701	recon_loss: 0.0024406996089965105	bpp_loss: 4.602289199829102	aux_loss: 0.5080187320709229
16:13:25 INFO - main: Train iter. 66100/200000 (33.05%): 	Loss: 5.323796272277832	recon_loss: 0.0024321458768099546	bpp_loss: 4.594152450561523	aux_loss: 0.3256700932979584
16:13:57 INFO - main: Train iter. 66200/200000 (33.1%): 	Loss: 5.330848693847656	recon_loss: 0.0024425301235169172	bpp_loss: 4.598089694976807	aux_loss: 0.4821168780326843
16:14:29 INFO - main: Train iter. 66300/200000 (33.15%): 	Loss: 5.342005252838135	recon_loss: 0.0024395387154072523	bpp_loss: 4.610143661499023	aux_loss: 0.27467894554138184
16:15:01 INFO - main: Train iter. 66400/200000 (33.2%): 	Loss: 5.329196453094482	recon_loss: 0.0024451380595564842	bpp_loss: 4.5956549644470215	aux_loss: 0.4322589039802551
16:15:32 INFO - main: Train iter. 66500/200000 (33.25%): 	Loss: 5.325798034667969	recon_loss: 0.0024376993533223867	bpp_loss: 4.594488143920898	aux_loss: 0.2444830685853958
16:16:04 INFO - main: Train iter. 66600/200000 (33.3%): 	Loss: 5.319083213806152	recon_loss: 0.002433677203953266	bpp_loss: 4.588980197906494	aux_loss: 0.27081015706062317
16:16:36 INFO - main: Train iter. 66700/200000 (33.35%): 	Loss: 5.333715438842773	recon_loss: 0.002444822806864977	bpp_loss: 4.600268363952637	aux_loss: 0.5902043581008911
16:17:08 INFO - main: Train iter. 66800/200000 (33.4%): 	Loss: 5.336538791656494	recon_loss: 0.002442811382934451	bpp_loss: 4.603695392608643	aux_loss: 0.18582668900489807
16:17:39 INFO - main: Train iter. 66900/200000 (33.45%): 	Loss: 5.332932949066162	recon_loss: 0.0024321156088262796	bpp_loss: 4.603298187255859	aux_loss: 0.33115628361701965
16:18:13 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 5.331168174743652	recon_loss: 0.0024360110983252525	bpp_loss: 4.600364685058594	aux_loss: 0.29063546657562256
16:18:44 INFO - main: Train iter. 67100/200000 (33.55%): 	Loss: 5.334756374359131	recon_loss: 0.0024398129899054766	bpp_loss: 4.60281229019165	aux_loss: 0.24629813432693481
16:19:16 INFO - main: Train iter. 67200/200000 (33.6%): 	Loss: 5.33685827255249	recon_loss: 0.0024397161323577166	bpp_loss: 4.60494327545166	aux_loss: 1.510529637336731
16:19:48 INFO - main: Train iter. 67300/200000 (33.65%): 	Loss: 5.332501411437988	recon_loss: 0.002436673501506448	bpp_loss: 4.601499557495117	aux_loss: 0.5120130181312561
16:20:20 INFO - main: Train iter. 67400/200000 (33.7%): 	Loss: 5.33355712890625	recon_loss: 0.002440109383314848	bpp_loss: 4.601524353027344	aux_loss: 0.3875940442085266
16:20:52 INFO - main: Train iter. 67500/200000 (33.75%): 	Loss: 5.329638481140137	recon_loss: 0.0024367712903767824	bpp_loss: 4.598607063293457	aux_loss: 0.28636354207992554
16:21:23 INFO - main: Train iter. 67600/200000 (33.8%): 	Loss: 5.318630695343018	recon_loss: 0.002436188980937004	bpp_loss: 4.58777379989624	aux_loss: 0.33319222927093506
16:21:55 INFO - main: Train iter. 67700/200000 (33.85%): 	Loss: 5.332796573638916	recon_loss: 0.0024329230654984713	bpp_loss: 4.602919578552246	aux_loss: 0.34809374809265137
16:22:27 INFO - main: Train iter. 67800/200000 (33.9%): 	Loss: 5.339183330535889	recon_loss: 0.0024451124481856823	bpp_loss: 4.605649471282959	aux_loss: 0.2851688265800476
16:22:59 INFO - main: Train iter. 67900/200000 (33.95%): 	Loss: 5.326857089996338	recon_loss: 0.0024467715993523598	bpp_loss: 4.592825412750244	aux_loss: 0.6834615468978882
16:23:30 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 5.329535484313965	recon_loss: 0.0024421883281320333	bpp_loss: 4.596879005432129	aux_loss: 0.7829415202140808
16:24:02 INFO - main: Train iter. 68100/200000 (34.05%): 	Loss: 5.322293281555176	recon_loss: 0.00243472121655941	bpp_loss: 4.591876983642578	aux_loss: 0.7403885126113892
16:24:34 INFO - main: Train iter. 68200/200000 (34.1%): 	Loss: 5.333268165588379	recon_loss: 0.002435082569718361	bpp_loss: 4.602743148803711	aux_loss: 0.5320420265197754
16:25:06 INFO - main: Train iter. 68300/200000 (34.15%): 	Loss: 5.320638656616211	recon_loss: 0.00243712542578578	bpp_loss: 4.589500904083252	aux_loss: 0.5270401239395142
16:25:39 INFO - main: Train iter. 68400/200000 (34.2%): 	Loss: 5.3237714767456055	recon_loss: 0.002438206225633621	bpp_loss: 4.592309474945068	aux_loss: 0.3802868127822876
16:26:11 INFO - main: Train iter. 68500/200000 (34.25%): 	Loss: 5.337038516998291	recon_loss: 0.0024440952111035585	bpp_loss: 4.603809833526611	aux_loss: 0.24862059950828552
16:26:43 INFO - main: Train iter. 68600/200000 (34.3%): 	Loss: 5.338534355163574	recon_loss: 0.0024426740128546953	bpp_loss: 4.605731964111328	aux_loss: 1.0630576610565186
16:27:15 INFO - main: Train iter. 68700/200000 (34.35%): 	Loss: 5.344067573547363	recon_loss: 0.0024391834158450365	bpp_loss: 4.612312316894531	aux_loss: 0.6641726493835449
16:27:46 INFO - main: Train iter. 68800/200000 (34.4%): 	Loss: 5.3344855308532715	recon_loss: 0.002431704429909587	bpp_loss: 4.604974269866943	aux_loss: 0.24535700678825378
16:28:18 INFO - main: Train iter. 68900/200000 (34.45%): 	Loss: 5.347641944885254	recon_loss: 0.0025135925970971584	bpp_loss: 4.593564033508301	aux_loss: 0.22801579535007477
16:28:50 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 5.334921360015869	recon_loss: 0.002448970451951027	bpp_loss: 4.6002302169799805	aux_loss: 0.2691490650177002
16:29:22 INFO - main: Train iter. 69100/200000 (34.55%): 	Loss: 5.32591438293457	recon_loss: 0.002439010189846158	bpp_loss: 4.594211101531982	aux_loss: 0.35712698101997375
16:29:54 INFO - main: Train iter. 69200/200000 (34.6%): 	Loss: 5.348269939422607	recon_loss: 0.0024615244474262	bpp_loss: 4.6098127365112305	aux_loss: 0.23604269325733185
16:30:25 INFO - main: Train iter. 69300/200000 (34.65%): 	Loss: 5.320773601531982	recon_loss: 0.0024430821649730206	bpp_loss: 4.587849140167236	aux_loss: 0.3523416519165039
16:30:57 INFO - main: Train iter. 69400/200000 (34.7%): 	Loss: 5.335050582885742	recon_loss: 0.0024379100650548935	bpp_loss: 4.603677749633789	aux_loss: 0.39473965764045715
16:31:29 INFO - main: Train iter. 69500/200000 (34.75%): 	Loss: 5.335263252258301	recon_loss: 0.0024556173011660576	bpp_loss: 4.598577976226807	aux_loss: 0.9367522597312927
16:32:01 INFO - main: Train iter. 69600/200000 (34.8%): 	Loss: 5.337405204772949	recon_loss: 0.0024435180239379406	bpp_loss: 4.604349613189697	aux_loss: 0.4206954836845398
16:32:33 INFO - main: Train iter. 69700/200000 (34.85%): 	Loss: 5.338347434997559	recon_loss: 0.0024554941337555647	bpp_loss: 4.601699352264404	aux_loss: 0.33223196864128113
16:33:06 INFO - main: Train iter. 69800/200000 (34.9%): 	Loss: 5.341580390930176	recon_loss: 0.002447546226903796	bpp_loss: 4.607316493988037	aux_loss: 0.6479958891868591
16:33:38 INFO - main: Train iter. 69900/200000 (34.95%): 	Loss: 5.3246307373046875	recon_loss: 0.0024561157915741205	bpp_loss: 4.587796211242676	aux_loss: 0.5539093613624573
16:34:09 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 5.340338706970215	recon_loss: 0.002484482480213046	bpp_loss: 4.594994068145752	aux_loss: 1.2427093982696533
16:34:21 INFO - main: {'TEST MSE': 0.002476445070317271, 'TEST BPP': 4.6083984375, 'TEST loss': 5.337330380916596, 'TEST recon_loss': 0.0024764451545197515, 'TEST bpp_loss': 4.594396830558777}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
16:34:52 INFO - main: Train iter. 70100/200000 (35.05%): 	Loss: 5.3279595375061035	recon_loss: 0.0024518552236258984	bpp_loss: 4.592402935028076	aux_loss: 0.7754156589508057
16:35:24 INFO - main: Train iter. 70200/200000 (35.1%): 	Loss: 5.3342671394348145	recon_loss: 0.0024579400196671486	bpp_loss: 4.5968852043151855	aux_loss: 0.5814208984375
16:35:56 INFO - main: Train iter. 70300/200000 (35.15%): 	Loss: 5.327363967895508	recon_loss: 0.0024429108016192913	bpp_loss: 4.5944905281066895	aux_loss: 1.0743706226348877
16:36:28 INFO - main: Train iter. 70400/200000 (35.2%): 	Loss: 5.321406364440918	recon_loss: 0.0024406015872955322	bpp_loss: 4.589225769042969	aux_loss: 0.34892427921295166
16:36:59 INFO - main: Train iter. 70500/200000 (35.25%): 	Loss: 5.334936618804932	recon_loss: 0.002439438132569194	bpp_loss: 4.603105068206787	aux_loss: 1.4793119430541992
16:37:31 INFO - main: Train iter. 70600/200000 (35.3%): 	Loss: 5.320314407348633	recon_loss: 0.0024353773333132267	bpp_loss: 4.589701175689697	aux_loss: 0.9005075693130493
16:38:03 INFO - main: Train iter. 70700/200000 (35.35%): 	Loss: 5.340530872344971	recon_loss: 0.0024485113099217415	bpp_loss: 4.605977535247803	aux_loss: 0.24427059292793274
16:38:35 INFO - main: Train iter. 70800/200000 (35.4%): 	Loss: 5.336453914642334	recon_loss: 0.0024352779146283865	bpp_loss: 4.605870723724365	aux_loss: 0.6125117540359497
16:39:07 INFO - main: Train iter. 70900/200000 (35.45%): 	Loss: 5.32183837890625	recon_loss: 0.002439466305077076	bpp_loss: 4.589998245239258	aux_loss: 0.39742177724838257
16:39:39 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 5.330813884735107	recon_loss: 0.0024347316939383745	bpp_loss: 4.600394248962402	aux_loss: 0.25598523020744324
16:40:12 INFO - main: Train iter. 71100/200000 (35.55%): 	Loss: 5.325887203216553	recon_loss: 0.002455327659845352	bpp_loss: 4.589288711547852	aux_loss: 0.44864946603775024
16:40:44 INFO - main: Train iter. 71200/200000 (35.6%): 	Loss: 5.335705757141113	recon_loss: 0.002439308213070035	bpp_loss: 4.603913307189941	aux_loss: 0.7462150454521179
16:41:16 INFO - main: Train iter. 71300/200000 (35.65%): 	Loss: 5.322833061218262	recon_loss: 0.0024446272291243076	bpp_loss: 4.589445114135742	aux_loss: 0.8503004908561707
16:41:48 INFO - main: Train iter. 71400/200000 (35.7%): 	Loss: 5.3296613693237305	recon_loss: 0.0024295600596815348	bpp_loss: 4.600793361663818	aux_loss: 0.4269152283668518
16:42:19 INFO - main: Train iter. 71500/200000 (35.75%): 	Loss: 5.3444108963012695	recon_loss: 0.002432388486340642	bpp_loss: 4.614694118499756	aux_loss: 0.18299104273319244
16:42:51 INFO - main: Train iter. 71600/200000 (35.8%): 	Loss: 5.326279163360596	recon_loss: 0.0024371601175516844	bpp_loss: 4.595130920410156	aux_loss: 0.21893714368343353
16:43:23 INFO - main: Train iter. 71700/200000 (35.85%): 	Loss: 5.34333610534668	recon_loss: 0.0024450516793876886	bpp_loss: 4.609820365905762	aux_loss: 0.8997882008552551
16:43:55 INFO - main: Train iter. 71800/200000 (35.9%): 	Loss: 5.330602169036865	recon_loss: 0.0024383217096328735	bpp_loss: 4.5991058349609375	aux_loss: 0.20132462680339813
16:44:27 INFO - main: Train iter. 71900/200000 (35.95%): 	Loss: 5.322279930114746	recon_loss: 0.0024358518421649933	bpp_loss: 4.591524124145508	aux_loss: 0.3483760952949524
16:44:59 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 5.329809665679932	recon_loss: 0.0024309030268341303	bpp_loss: 4.600538730621338	aux_loss: 0.8549062013626099
16:45:30 INFO - main: Train iter. 72100/200000 (36.05%): 	Loss: 5.320363998413086	recon_loss: 0.00243285670876503	bpp_loss: 4.5905070304870605	aux_loss: 0.316866397857666
16:46:02 INFO - main: Train iter. 72200/200000 (36.1%): 	Loss: 5.319097518920898	recon_loss: 0.002432962181046605	bpp_loss: 4.589208602905273	aux_loss: 0.280692458152771
16:46:34 INFO - main: Train iter. 72300/200000 (36.15%): 	Loss: 5.343846797943115	recon_loss: 0.0024413131177425385	bpp_loss: 4.611453056335449	aux_loss: 0.6941890716552734
16:47:06 INFO - main: Train iter. 72400/200000 (36.2%): 	Loss: 5.3258891105651855	recon_loss: 0.002434908878058195	bpp_loss: 4.59541654586792	aux_loss: 0.4818260967731476
16:47:39 INFO - main: Train iter. 72500/200000 (36.25%): 	Loss: 5.333949565887451	recon_loss: 0.0024356250651180744	bpp_loss: 4.603261947631836	aux_loss: 0.5959826707839966
16:48:11 INFO - main: Train iter. 72600/200000 (36.3%): 	Loss: 5.33447265625	recon_loss: 0.0024396327789872885	bpp_loss: 4.602582931518555	aux_loss: 0.42245548963546753
16:48:43 INFO - main: Train iter. 72700/200000 (36.35%): 	Loss: 5.336235523223877	recon_loss: 0.0024392828345298767	bpp_loss: 4.604450702667236	aux_loss: 0.4384830594062805
16:49:14 INFO - main: Train iter. 72800/200000 (36.4%): 	Loss: 5.329532623291016	recon_loss: 0.002436727751046419	bpp_loss: 4.598514080047607	aux_loss: 0.4747456908226013
16:49:46 INFO - main: Train iter. 72900/200000 (36.45%): 	Loss: 5.340475559234619	recon_loss: 0.0024667761754244566	bpp_loss: 4.600442886352539	aux_loss: 0.24825599789619446
16:50:18 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 5.332576751708984	recon_loss: 0.0024433338548988104	bpp_loss: 4.599576473236084	aux_loss: 0.39898473024368286
16:50:50 INFO - main: Train iter. 73100/200000 (36.55%): 	Loss: 5.351690292358398	recon_loss: 0.0025001978501677513	bpp_loss: 4.601631164550781	aux_loss: 0.5244439840316772
16:51:22 INFO - main: Train iter. 73200/200000 (36.6%): 	Loss: 5.335807800292969	recon_loss: 0.0024474693927913904	bpp_loss: 4.601566791534424	aux_loss: 0.3469465672969818
16:51:53 INFO - main: Train iter. 73300/200000 (36.65%): 	Loss: 5.322091102600098	recon_loss: 0.0024377291556447744	bpp_loss: 4.5907721519470215	aux_loss: 0.2883051931858063
16:52:25 INFO - main: Train iter. 73400/200000 (36.7%): 	Loss: 5.336854457855225	recon_loss: 0.0024478265549987555	bpp_loss: 4.602506637573242	aux_loss: 0.3457719683647156
16:52:57 INFO - main: Train iter. 73500/200000 (36.75%): 	Loss: 5.352997779846191	recon_loss: 0.002451412845402956	bpp_loss: 4.6175737380981445	aux_loss: 0.42092347145080566
16:53:29 INFO - main: Train iter. 73600/200000 (36.8%): 	Loss: 5.337282180786133	recon_loss: 0.0024557821452617645	bpp_loss: 4.600547790527344	aux_loss: 0.2890431582927704
16:54:00 INFO - main: Train iter. 73700/200000 (36.85%): 	Loss: 5.324402332305908	recon_loss: 0.002451543463394046	bpp_loss: 4.588939189910889	aux_loss: 0.4226135015487671
16:54:33 INFO - main: Train iter. 73800/200000 (36.9%): 	Loss: 5.332466125488281	recon_loss: 0.0024516559205949306	bpp_loss: 4.596969127655029	aux_loss: 0.5397936105728149
16:55:06 INFO - main: Train iter. 73900/200000 (36.95%): 	Loss: 5.359328746795654	recon_loss: 0.0025396316777914762	bpp_loss: 4.597439289093018	aux_loss: 0.38239380717277527
16:55:37 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 5.335088729858398	recon_loss: 0.0024605323560535908	bpp_loss: 4.59692907333374	aux_loss: 0.40325504541397095
16:56:09 INFO - main: Train iter. 74100/200000 (37.05%): 	Loss: 5.3398871421813965	recon_loss: 0.0024506887421011925	bpp_loss: 4.60468053817749	aux_loss: 0.4530615210533142
16:56:41 INFO - main: Train iter. 74200/200000 (37.1%): 	Loss: 5.338172912597656	recon_loss: 0.002444701734930277	bpp_loss: 4.604762554168701	aux_loss: 0.38902774453163147
16:57:13 INFO - main: Train iter. 74300/200000 (37.15%): 	Loss: 5.343626976013184	recon_loss: 0.0024835967924445868	bpp_loss: 4.59854793548584	aux_loss: 0.9034954309463501
16:57:45 INFO - main: Train iter. 74400/200000 (37.2%): 	Loss: 5.33040189743042	recon_loss: 0.0024481264408677816	bpp_loss: 4.595963954925537	aux_loss: 0.3294740617275238
16:58:17 INFO - main: Train iter. 74500/200000 (37.25%): 	Loss: 5.361897945404053	recon_loss: 0.0025333231315016747	bpp_loss: 4.601901054382324	aux_loss: 0.32416629791259766
16:58:49 INFO - main: Train iter. 74600/200000 (37.3%): 	Loss: 5.341067314147949	recon_loss: 0.0024629677645862103	bpp_loss: 4.602177143096924	aux_loss: 0.6508040428161621
16:59:21 INFO - main: Train iter. 74700/200000 (37.35%): 	Loss: 5.325357437133789	recon_loss: 0.0024507648777216673	bpp_loss: 4.590127944946289	aux_loss: 1.2453951835632324
16:59:53 INFO - main: Train iter. 74800/200000 (37.4%): 	Loss: 5.33275032043457	recon_loss: 0.002458638045936823	bpp_loss: 4.59515905380249	aux_loss: 0.8955869078636169
17:00:24 INFO - main: Train iter. 74900/200000 (37.45%): 	Loss: 5.320066928863525	recon_loss: 0.002436760812997818	bpp_loss: 4.589038848876953	aux_loss: 0.69045090675354
17:00:56 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 5.334718704223633	recon_loss: 0.002460659481585026	bpp_loss: 4.596520900726318	aux_loss: 0.8100783824920654
17:01:07 INFO - main: {'TEST MSE': 0.0024938908054025753, 'TEST BPP': 4.614296875, 'TEST loss': 5.347887237548828, 'TEST recon_loss': 0.0024938908901531247, 'TEST bpp_loss': 4.599719968795776}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:01:39 INFO - main: Train iter. 75100/200000 (37.55%): 	Loss: 5.3356781005859375	recon_loss: 0.0024686672259122133	bpp_loss: 4.595077991485596	aux_loss: 0.6643438339233398
17:02:12 INFO - main: Train iter. 75200/200000 (37.6%): 	Loss: 5.363201141357422	recon_loss: 0.0025540366768836975	bpp_loss: 4.59699010848999	aux_loss: 0.7959294319152832
17:02:44 INFO - main: Train iter. 75300/200000 (37.65%): 	Loss: 5.324522018432617	recon_loss: 0.0024480782449245453	bpp_loss: 4.5900983810424805	aux_loss: 0.9362983703613281
17:03:16 INFO - main: Train iter. 75400/200000 (37.7%): 	Loss: 5.328098297119141	recon_loss: 0.002432594308629632	bpp_loss: 4.598320007324219	aux_loss: 0.35788214206695557
17:03:47 INFO - main: Train iter. 75500/200000 (37.75%): 	Loss: 5.32744836807251	recon_loss: 0.0024457252584397793	bpp_loss: 4.593730926513672	aux_loss: 1.1617642641067505
17:04:19 INFO - main: Train iter. 75600/200000 (37.8%): 	Loss: 5.338345050811768	recon_loss: 0.002474304987117648	bpp_loss: 4.596053600311279	aux_loss: 1.3641430139541626
17:04:51 INFO - main: Train iter. 75700/200000 (37.85%): 	Loss: 5.325108051300049	recon_loss: 0.0024601242039352655	bpp_loss: 4.587070941925049	aux_loss: 0.533140242099762
17:05:23 INFO - main: Train iter. 75800/200000 (37.9%): 	Loss: 5.322020053863525	recon_loss: 0.0024371612817049026	bpp_loss: 4.590871810913086	aux_loss: 0.7096607089042664
17:05:55 INFO - main: Train iter. 75900/200000 (37.95%): 	Loss: 5.333506107330322	recon_loss: 0.002452598186209798	bpp_loss: 4.597726821899414	aux_loss: 0.6050541996955872
17:06:27 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 5.332004070281982	recon_loss: 0.0024366017896682024	bpp_loss: 4.6010236740112305	aux_loss: 1.3884230852127075
17:06:59 INFO - main: Train iter. 76100/200000 (38.05%): 	Loss: 5.340947151184082	recon_loss: 0.0024490298237651587	bpp_loss: 4.60623836517334	aux_loss: 0.34361380338668823
17:07:30 INFO - main: Train iter. 76200/200000 (38.1%): 	Loss: 5.330563068389893	recon_loss: 0.0024489103816449642	bpp_loss: 4.595890045166016	aux_loss: 0.3608907461166382
17:08:02 INFO - main: Train iter. 76300/200000 (38.15%): 	Loss: 5.339352607727051	recon_loss: 0.0024535078555345535	bpp_loss: 4.603300094604492	aux_loss: 0.2729185223579407
17:08:34 INFO - main: Train iter. 76400/200000 (38.2%): 	Loss: 5.324059009552002	recon_loss: 0.0024321319069713354	bpp_loss: 4.594419479370117	aux_loss: 0.28481489419937134
17:09:06 INFO - main: Train iter. 76500/200000 (38.25%): 	Loss: 5.330862045288086	recon_loss: 0.0024517946876585484	bpp_loss: 4.59532356262207	aux_loss: 0.29834043979644775
17:09:39 INFO - main: Train iter. 76600/200000 (38.3%): 	Loss: 5.330458164215088	recon_loss: 0.0024529865477234125	bpp_loss: 4.59456205368042	aux_loss: 0.32963496446609497
17:10:11 INFO - main: Train iter. 76700/200000 (38.35%): 	Loss: 5.329226493835449	recon_loss: 0.002437976421788335	bpp_loss: 4.597833633422852	aux_loss: 0.81929612159729
17:10:43 INFO - main: Train iter. 76800/200000 (38.4%): 	Loss: 5.317777633666992	recon_loss: 0.0024347123689949512	bpp_loss: 4.5873637199401855	aux_loss: 0.5097173452377319
17:11:15 INFO - main: Train iter. 76900/200000 (38.45%): 	Loss: 5.3311004638671875	recon_loss: 0.002433636225759983	bpp_loss: 4.601009368896484	aux_loss: 1.2988642454147339
17:11:47 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 5.329108238220215	recon_loss: 0.0024399315007030964	bpp_loss: 4.597128868103027	aux_loss: 1.0347294807434082
17:12:18 INFO - main: Train iter. 77100/200000 (38.55%): 	Loss: 5.324064254760742	recon_loss: 0.0024347917642444372	bpp_loss: 4.593626499176025	aux_loss: 0.16463452577590942
17:12:50 INFO - main: Train iter. 77200/200000 (38.6%): 	Loss: 5.325045585632324	recon_loss: 0.0024429820477962494	bpp_loss: 4.592151165008545	aux_loss: 0.9829595685005188
17:13:22 INFO - main: Train iter. 77300/200000 (38.65%): 	Loss: 5.330803871154785	recon_loss: 0.0024381994735449553	bpp_loss: 4.599344253540039	aux_loss: 0.7380409240722656
17:13:54 INFO - main: Train iter. 77400/200000 (38.7%): 	Loss: 5.341089725494385	recon_loss: 0.002450167667120695	bpp_loss: 4.606039524078369	aux_loss: 0.6313955783843994
17:14:26 INFO - main: Train iter. 77500/200000 (38.75%): 	Loss: 5.32647705078125	recon_loss: 0.0024329228326678276	bpp_loss: 4.59660005569458	aux_loss: 1.2379069328308105
17:14:58 INFO - main: Train iter. 77600/200000 (38.8%): 	Loss: 5.3340229988098145	recon_loss: 0.0024413224309682846	bpp_loss: 4.601626396179199	aux_loss: 0.49730971455574036
17:15:30 INFO - main: Train iter. 77700/200000 (38.85%): 	Loss: 5.338001728057861	recon_loss: 0.0024425263982266188	bpp_loss: 4.605243682861328	aux_loss: 1.0887033939361572
17:16:02 INFO - main: Train iter. 77800/200000 (38.9%): 	Loss: 5.3291449546813965	recon_loss: 0.0024362709373235703	bpp_loss: 4.598263740539551	aux_loss: 0.52873694896698
17:16:33 INFO - main: Train iter. 77900/200000 (38.95%): 	Loss: 5.315922260284424	recon_loss: 0.0024331368040293455	bpp_loss: 4.585981369018555	aux_loss: 0.40704742074012756
17:17:07 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 5.3313517570495605	recon_loss: 0.0024482475128024817	bpp_loss: 4.596877574920654	aux_loss: 0.8976302742958069
17:17:38 INFO - main: Train iter. 78100/200000 (39.05%): 	Loss: 5.333358287811279	recon_loss: 0.002439047209918499	bpp_loss: 4.601644039154053	aux_loss: 0.3292442560195923
17:18:10 INFO - main: Train iter. 78200/200000 (39.1%): 	Loss: 5.329216480255127	recon_loss: 0.0024295318871736526	bpp_loss: 4.6003570556640625	aux_loss: 0.1774289309978485
17:18:42 INFO - main: Train iter. 78300/200000 (39.15%): 	Loss: 5.32309627532959	recon_loss: 0.002434751484543085	bpp_loss: 4.592670917510986	aux_loss: 0.23401612043380737
17:19:14 INFO - main: Train iter. 78400/200000 (39.2%): 	Loss: 5.322943210601807	recon_loss: 0.0024334839545190334	bpp_loss: 4.592897891998291	aux_loss: 0.31111854314804077
17:19:46 INFO - main: Train iter. 78500/200000 (39.25%): 	Loss: 5.333657264709473	recon_loss: 0.0024324918631464243	bpp_loss: 4.603909969329834	aux_loss: 0.4703271985054016
17:20:17 INFO - main: Train iter. 78600/200000 (39.3%): 	Loss: 5.336329936981201	recon_loss: 0.00243998016230762	bpp_loss: 4.604335784912109	aux_loss: 0.6786168217658997
17:20:49 INFO - main: Train iter. 78700/200000 (39.35%): 	Loss: 5.321680545806885	recon_loss: 0.0024351596366614103	bpp_loss: 4.591132640838623	aux_loss: 1.0282692909240723
17:21:21 INFO - main: Train iter. 78800/200000 (39.4%): 	Loss: 5.340616703033447	recon_loss: 0.0024638636969029903	bpp_loss: 4.601457595825195	aux_loss: 0.37068596482276917
17:21:53 INFO - main: Train iter. 78900/200000 (39.45%): 	Loss: 5.325983047485352	recon_loss: 0.0024474195670336485	bpp_loss: 4.591757297515869	aux_loss: 0.20243394374847412
17:22:25 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 5.3264899253845215	recon_loss: 0.00243566557765007	bpp_loss: 4.595790386199951	aux_loss: 0.6914190649986267
17:22:57 INFO - main: Train iter. 79100/200000 (39.55%): 	Loss: 5.336928367614746	recon_loss: 0.0024626925587654114	bpp_loss: 4.59812068939209	aux_loss: 0.22257231175899506
17:23:28 INFO - main: Train iter. 79200/200000 (39.6%): 	Loss: 5.340832710266113	recon_loss: 0.002446478232741356	bpp_loss: 4.606889247894287	aux_loss: 0.5658997297286987
17:24:02 INFO - main: Train iter. 79300/200000 (39.65%): 	Loss: 5.334939479827881	recon_loss: 0.002440816955640912	bpp_loss: 4.602694511413574	aux_loss: 0.2658213973045349
17:24:33 INFO - main: Train iter. 79400/200000 (39.7%): 	Loss: 5.341946601867676	recon_loss: 0.0024592666886746883	bpp_loss: 4.604166507720947	aux_loss: 0.4031292796134949
17:25:05 INFO - main: Train iter. 79500/200000 (39.75%): 	Loss: 5.328207969665527	recon_loss: 0.002459849463775754	bpp_loss: 4.590252876281738	aux_loss: 0.5242193937301636
17:25:37 INFO - main: Train iter. 79600/200000 (39.8%): 	Loss: 5.336878776550293	recon_loss: 0.002440687036141753	bpp_loss: 4.604672431945801	aux_loss: 0.6963693499565125
17:26:09 INFO - main: Train iter. 79700/200000 (39.85%): 	Loss: 5.337115287780762	recon_loss: 0.0024338620714843273	bpp_loss: 4.606956481933594	aux_loss: 0.3896326720714569
17:26:41 INFO - main: Train iter. 79800/200000 (39.9%): 	Loss: 5.323538780212402	recon_loss: 0.0024331517051905394	bpp_loss: 4.593593120574951	aux_loss: 0.8511041402816772
17:27:13 INFO - main: Train iter. 79900/200000 (39.95%): 	Loss: 5.32560920715332	recon_loss: 0.002435532631352544	bpp_loss: 4.594949245452881	aux_loss: 0.755333662033081
17:27:44 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 5.330417633056641	recon_loss: 0.00243798503652215	bpp_loss: 4.599021911621094	aux_loss: 0.21042826771736145
17:27:56 INFO - main: {'TEST MSE': 0.0024319688218299856, 'TEST BPP': 4.6163359375, 'TEST loss': 5.3315454139709475, 'TEST recon_loss': 0.0024319689031690357, 'TEST bpp_loss': 4.601954745292663}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:28:27 INFO - main: Train iter. 80100/200000 (40.05%): 	Loss: 5.328703880310059	recon_loss: 0.0024381361436098814	bpp_loss: 4.597262859344482	aux_loss: 0.28220826387405396
17:28:59 INFO - main: Train iter. 80200/200000 (40.1%): 	Loss: 5.317058086395264	recon_loss: 0.0024398635141551495	bpp_loss: 4.585099220275879	aux_loss: 0.6081334948539734
17:29:31 INFO - main: Train iter. 80300/200000 (40.15%): 	Loss: 5.327152252197266	recon_loss: 0.0024338914081454277	bpp_loss: 4.59698486328125	aux_loss: 0.38526004552841187
17:30:02 INFO - main: Train iter. 80400/200000 (40.2%): 	Loss: 5.3334550857543945	recon_loss: 0.0024404660798609257	bpp_loss: 4.601315498352051	aux_loss: 0.41987723112106323
17:30:34 INFO - main: Train iter. 80500/200000 (40.25%): 	Loss: 5.336362361907959	recon_loss: 0.0024334683548659086	bpp_loss: 4.606321811676025	aux_loss: 0.3360305726528168
17:31:06 INFO - main: Train iter. 80600/200000 (40.3%): 	Loss: 5.330169200897217	recon_loss: 0.002432997338473797	bpp_loss: 4.600269794464111	aux_loss: 0.8394924402236938
17:31:39 INFO - main: Train iter. 80700/200000 (40.35%): 	Loss: 5.336663722991943	recon_loss: 0.0024448796175420284	bpp_loss: 4.6031999588012695	aux_loss: 0.7153971791267395
17:32:11 INFO - main: Train iter. 80800/200000 (40.4%): 	Loss: 5.317126750946045	recon_loss: 0.0024335053749382496	bpp_loss: 4.587075233459473	aux_loss: 0.2634785771369934
17:32:43 INFO - main: Train iter. 80900/200000 (40.45%): 	Loss: 5.325736045837402	recon_loss: 0.0024364362470805645	bpp_loss: 4.5948052406311035	aux_loss: 0.5550379157066345
17:33:14 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 5.330243110656738	recon_loss: 0.002439359435811639	bpp_loss: 4.598435401916504	aux_loss: 0.9821004867553711
17:33:46 INFO - main: Train iter. 81100/200000 (40.55%): 	Loss: 5.309816360473633	recon_loss: 0.0024290841538459063	bpp_loss: 4.581090927124023	aux_loss: 0.33504900336265564
17:34:18 INFO - main: Train iter. 81200/200000 (40.6%): 	Loss: 5.318678379058838	recon_loss: 0.002434126567095518	bpp_loss: 4.588440418243408	aux_loss: 0.29487544298171997
17:34:50 INFO - main: Train iter. 81300/200000 (40.65%): 	Loss: 5.32421875	recon_loss: 0.0024308806750923395	bpp_loss: 4.594954490661621	aux_loss: 0.8751800060272217
17:35:22 INFO - main: Train iter. 81400/200000 (40.7%): 	Loss: 5.331519603729248	recon_loss: 0.0024310427252203226	bpp_loss: 4.602206707000732	aux_loss: 0.2978261709213257
17:35:54 INFO - main: Train iter. 81500/200000 (40.75%): 	Loss: 5.337960243225098	recon_loss: 0.002429004991427064	bpp_loss: 4.609258651733398	aux_loss: 0.5581824779510498
17:36:25 INFO - main: Train iter. 81600/200000 (40.8%): 	Loss: 5.325148105621338	recon_loss: 0.0024307644926011562	bpp_loss: 4.595918655395508	aux_loss: 0.8783494234085083
17:36:57 INFO - main: Train iter. 81700/200000 (40.85%): 	Loss: 5.337178707122803	recon_loss: 0.002445813501253724	bpp_loss: 4.6034345626831055	aux_loss: 0.41794630885124207
17:37:29 INFO - main: Train iter. 81800/200000 (40.9%): 	Loss: 5.332979679107666	recon_loss: 0.0024361275136470795	bpp_loss: 4.602141380310059	aux_loss: 0.19517730176448822
17:38:01 INFO - main: Train iter. 81900/200000 (40.95%): 	Loss: 5.33711576461792	recon_loss: 0.0024406835436820984	bpp_loss: 4.604910850524902	aux_loss: 0.3061296343803406
17:38:32 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 5.317214012145996	recon_loss: 0.002430656226351857	bpp_loss: 4.588016986846924	aux_loss: 0.2986912131309509
17:39:05 INFO - main: Train iter. 82100/200000 (41.05%): 	Loss: 5.334766387939453	recon_loss: 0.002443614648655057	bpp_loss: 4.601682186126709	aux_loss: 0.6497984528541565
17:39:37 INFO - main: Train iter. 82200/200000 (41.1%): 	Loss: 5.322212219238281	recon_loss: 0.0024397314991801977	bpp_loss: 4.590292930603027	aux_loss: 0.4248945713043213
17:40:09 INFO - main: Train iter. 82300/200000 (41.15%): 	Loss: 5.319645404815674	recon_loss: 0.002429319778457284	bpp_loss: 4.59084939956665	aux_loss: 0.5072975158691406
17:40:41 INFO - main: Train iter. 82400/200000 (41.2%): 	Loss: 5.330503940582275	recon_loss: 0.0024312823079526424	bpp_loss: 4.601119041442871	aux_loss: 0.2273765504360199
17:41:13 INFO - main: Train iter. 82500/200000 (41.25%): 	Loss: 5.32332706451416	recon_loss: 0.0024293388705700636	bpp_loss: 4.594525337219238	aux_loss: 0.7295107841491699
17:41:45 INFO - main: Train iter. 82600/200000 (41.3%): 	Loss: 5.3233962059021	recon_loss: 0.002431802684441209	bpp_loss: 4.593855381011963	aux_loss: 0.49126505851745605
17:42:17 INFO - main: Train iter. 82700/200000 (41.35%): 	Loss: 5.337501525878906	recon_loss: 0.0024367200676351786	bpp_loss: 4.606485366821289	aux_loss: 0.30501750111579895
17:42:49 INFO - main: Train iter. 82800/200000 (41.4%): 	Loss: 5.3405046463012695	recon_loss: 0.0024338425137102604	bpp_loss: 4.610352039337158	aux_loss: 0.14210449159145355
17:43:21 INFO - main: Train iter. 82900/200000 (41.45%): 	Loss: 5.327532768249512	recon_loss: 0.0024322890676558018	bpp_loss: 4.597846031188965	aux_loss: 0.976344645023346
17:43:53 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 5.334676265716553	recon_loss: 0.0024529662914574146	bpp_loss: 4.598786354064941	aux_loss: 0.296487033367157
17:44:24 INFO - main: Train iter. 83100/200000 (41.55%): 	Loss: 5.320991516113281	recon_loss: 0.0024570205714553595	bpp_loss: 4.583885192871094	aux_loss: 0.5222702026367188
17:44:56 INFO - main: Train iter. 83200/200000 (41.6%): 	Loss: 5.330617427825928	recon_loss: 0.0024503995664417744	bpp_loss: 4.5954976081848145	aux_loss: 0.3049919009208679
17:45:28 INFO - main: Train iter. 83300/200000 (41.65%): 	Loss: 5.3278326988220215	recon_loss: 0.0024413589853793383	bpp_loss: 4.595425128936768	aux_loss: 0.9347452521324158
17:46:01 INFO - main: Train iter. 83400/200000 (41.7%): 	Loss: 5.335871696472168	recon_loss: 0.002440054900944233	bpp_loss: 4.603855133056641	aux_loss: 0.422896146774292
17:46:33 INFO - main: Train iter. 83500/200000 (41.75%): 	Loss: 5.33162784576416	recon_loss: 0.002452253829687834	bpp_loss: 4.595951557159424	aux_loss: 0.5199184417724609
17:47:05 INFO - main: Train iter. 83600/200000 (41.8%): 	Loss: 5.319049835205078	recon_loss: 0.002434749389067292	bpp_loss: 4.588624954223633	aux_loss: 0.9400913119316101
17:47:37 INFO - main: Train iter. 83700/200000 (41.85%): 	Loss: 5.335481643676758	recon_loss: 0.0024468260817229748	bpp_loss: 4.601433753967285	aux_loss: 0.3104417026042938
17:48:09 INFO - main: Train iter. 83800/200000 (41.9%): 	Loss: 5.331719875335693	recon_loss: 0.002448562067002058	bpp_loss: 4.597151279449463	aux_loss: 0.3371986150741577
17:48:41 INFO - main: Train iter. 83900/200000 (41.95%): 	Loss: 5.326937675476074	recon_loss: 0.002445294987410307	bpp_loss: 4.593348979949951	aux_loss: 0.28532925248146057
17:49:12 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 5.347781181335449	recon_loss: 0.0024857870303094387	bpp_loss: 4.602045059204102	aux_loss: 0.3376280665397644
17:49:44 INFO - main: Train iter. 84100/200000 (42.05%): 	Loss: 5.322456359863281	recon_loss: 0.002461042022332549	bpp_loss: 4.58414363861084	aux_loss: 0.7584732174873352
17:50:16 INFO - main: Train iter. 84200/200000 (42.1%): 	Loss: 5.324687957763672	recon_loss: 0.0024571134708821774	bpp_loss: 4.587553977966309	aux_loss: 0.37088173627853394
17:50:48 INFO - main: Train iter. 84300/200000 (42.15%): 	Loss: 5.322299957275391	recon_loss: 0.0024469424970448017	bpp_loss: 4.588217258453369	aux_loss: 0.3994710147380829
17:51:20 INFO - main: Train iter. 84400/200000 (42.2%): 	Loss: 5.332842826843262	recon_loss: 0.00246240827254951	bpp_loss: 4.594120502471924	aux_loss: 0.4700595736503601
17:51:52 INFO - main: Train iter. 84500/200000 (42.25%): 	Loss: 5.334045886993408	recon_loss: 0.0024621847551316023	bpp_loss: 4.595390319824219	aux_loss: 0.44826793670654297
17:52:24 INFO - main: Train iter. 84600/200000 (42.3%): 	Loss: 5.329617023468018	recon_loss: 0.002457253634929657	bpp_loss: 4.592441082000732	aux_loss: 0.845174252986908
17:52:55 INFO - main: Train iter. 84700/200000 (42.35%): 	Loss: 5.340420246124268	recon_loss: 0.0024920091964304447	bpp_loss: 4.592817306518555	aux_loss: 0.39361363649368286
17:53:29 INFO - main: Train iter. 84800/200000 (42.4%): 	Loss: 5.333339214324951	recon_loss: 0.0024543479084968567	bpp_loss: 4.597034931182861	aux_loss: 0.30438339710235596
17:54:00 INFO - main: Train iter. 84900/200000 (42.45%): 	Loss: 5.341315269470215	recon_loss: 0.0024399019312113523	bpp_loss: 4.609344482421875	aux_loss: 0.589282751083374
17:54:32 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 5.333508491516113	recon_loss: 0.0024622324854135513	bpp_loss: 4.594838619232178	aux_loss: 1.182765245437622
17:54:43 INFO - main: {'TEST MSE': 0.002456978989925113, 'TEST BPP': 4.613328125, 'TEST loss': 5.335792870044708, 'TEST recon_loss': 0.0024569790735840796, 'TEST bpp_loss': 4.598699145793915}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
17:55:15 INFO - main: Train iter. 85100/200000 (42.55%): 	Loss: 5.336130142211914	recon_loss: 0.002452830085530877	bpp_loss: 4.600281238555908	aux_loss: 0.8126026391983032
17:55:47 INFO - main: Train iter. 85200/200000 (42.6%): 	Loss: 5.343847751617432	recon_loss: 0.0024449580814689398	bpp_loss: 4.610360145568848	aux_loss: 0.4755364656448364
17:56:19 INFO - main: Train iter. 85300/200000 (42.65%): 	Loss: 5.338082313537598	recon_loss: 0.0024416218511760235	bpp_loss: 4.605595588684082	aux_loss: 0.5128032565116882
17:56:51 INFO - main: Train iter. 85400/200000 (42.7%): 	Loss: 5.326167106628418	recon_loss: 0.0024399396497756243	bpp_loss: 4.5941853523254395	aux_loss: 0.4354202151298523
17:57:22 INFO - main: Train iter. 85500/200000 (42.75%): 	Loss: 5.346080780029297	recon_loss: 0.0024536882992833853	bpp_loss: 4.609974384307861	aux_loss: 0.7720434665679932
17:57:54 INFO - main: Train iter. 85600/200000 (42.8%): 	Loss: 5.340425968170166	recon_loss: 0.0024370020255446434	bpp_loss: 4.609325408935547	aux_loss: 0.3349599540233612
17:58:26 INFO - main: Train iter. 85700/200000 (42.85%): 	Loss: 5.331565856933594	recon_loss: 0.0024416991509497166	bpp_loss: 4.599056243896484	aux_loss: 0.906502902507782
17:58:58 INFO - main: Train iter. 85800/200000 (42.9%): 	Loss: 5.328744411468506	recon_loss: 0.0024364632554352283	bpp_loss: 4.597805500030518	aux_loss: 1.5688254833221436
17:59:30 INFO - main: Train iter. 85900/200000 (42.95%): 	Loss: 5.34629487991333	recon_loss: 0.0024427243042737246	bpp_loss: 4.61347770690918	aux_loss: 0.49600210785865784
18:00:02 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 5.328634738922119	recon_loss: 0.0024305672850459814	bpp_loss: 4.599464416503906	aux_loss: 0.32189682126045227
18:00:33 INFO - main: Train iter. 86100/200000 (43.05%): 	Loss: 5.325381278991699	recon_loss: 0.002438364550471306	bpp_loss: 4.5938720703125	aux_loss: 0.5236973166465759
18:01:07 INFO - main: Train iter. 86200/200000 (43.1%): 	Loss: 5.32130241394043	recon_loss: 0.002439848380163312	bpp_loss: 4.589347839355469	aux_loss: 0.37427911162376404
18:01:39 INFO - main: Train iter. 86300/200000 (43.15%): 	Loss: 5.319535255432129	recon_loss: 0.002436645096167922	bpp_loss: 4.5885419845581055	aux_loss: 0.2797117531299591
18:02:11 INFO - main: Train iter. 86400/200000 (43.2%): 	Loss: 5.32963752746582	recon_loss: 0.0024329533334821463	bpp_loss: 4.5997514724731445	aux_loss: 1.2228198051452637
18:02:42 INFO - main: Train iter. 86500/200000 (43.25%): 	Loss: 5.308787822723389	recon_loss: 0.0024313959293067455	bpp_loss: 4.579369068145752	aux_loss: 0.31033170223236084
18:03:14 INFO - main: Train iter. 86600/200000 (43.3%): 	Loss: 5.314054012298584	recon_loss: 0.0024295940529555082	bpp_loss: 4.58517599105835	aux_loss: 1.0254172086715698
18:03:46 INFO - main: Train iter. 86700/200000 (43.35%): 	Loss: 5.318419933319092	recon_loss: 0.002432904439046979	bpp_loss: 4.58854866027832	aux_loss: 1.4669420719146729
18:04:18 INFO - main: Train iter. 86800/200000 (43.4%): 	Loss: 5.330167770385742	recon_loss: 0.0024313931353390217	bpp_loss: 4.600749969482422	aux_loss: 0.7451397776603699
18:04:50 INFO - main: Train iter. 86900/200000 (43.45%): 	Loss: 5.329650402069092	recon_loss: 0.0024399578105658293	bpp_loss: 4.597662925720215	aux_loss: 0.47916164994239807
18:05:22 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 5.328730583190918	recon_loss: 0.0024313481990247965	bpp_loss: 4.599326133728027	aux_loss: 1.029508352279663
18:05:53 INFO - main: Train iter. 87100/200000 (43.55%): 	Loss: 5.328226566314697	recon_loss: 0.002435768721625209	bpp_loss: 4.597496032714844	aux_loss: 0.44291192293167114
18:06:25 INFO - main: Train iter. 87200/200000 (43.6%): 	Loss: 5.333363056182861	recon_loss: 0.002431566594168544	bpp_loss: 4.603893280029297	aux_loss: 0.2810492217540741
18:06:57 INFO - main: Train iter. 87300/200000 (43.65%): 	Loss: 5.32175874710083	recon_loss: 0.0024306417908519506	bpp_loss: 4.592566013336182	aux_loss: 0.26621922850608826
18:07:29 INFO - main: Train iter. 87400/200000 (43.7%): 	Loss: 5.3289570808410645	recon_loss: 0.0024305498227477074	bpp_loss: 4.599792003631592	aux_loss: 0.6108188629150391
18:08:02 INFO - main: Train iter. 87500/200000 (43.75%): 	Loss: 5.325416564941406	recon_loss: 0.0024348320439457893	bpp_loss: 4.594966888427734	aux_loss: 1.032013177871704
18:08:34 INFO - main: Train iter. 87600/200000 (43.8%): 	Loss: 5.3204345703125	recon_loss: 0.00243328046053648	bpp_loss: 4.590450286865234	aux_loss: 0.3016422688961029
18:09:06 INFO - main: Train iter. 87700/200000 (43.85%): 	Loss: 5.327633857727051	recon_loss: 0.0024343214463442564	bpp_loss: 4.597337245941162	aux_loss: 0.3455173969268799
18:09:38 INFO - main: Train iter. 87800/200000 (43.9%): 	Loss: 5.32008171081543	recon_loss: 0.0024324594996869564	bpp_loss: 4.590343952178955	aux_loss: 0.18658888339996338
18:10:09 INFO - main: Train iter. 87900/200000 (43.95%): 	Loss: 5.330827713012695	recon_loss: 0.0024347188882529736	bpp_loss: 4.600411891937256	aux_loss: 0.47030213475227356
18:10:41 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 5.312821865081787	recon_loss: 0.0024357785005122423	bpp_loss: 4.582088470458984	aux_loss: 1.0571317672729492
18:11:13 INFO - main: Train iter. 88100/200000 (44.05%): 	Loss: 5.327985763549805	recon_loss: 0.0024364504497498274	bpp_loss: 4.597050666809082	aux_loss: 0.4565579891204834
18:11:45 INFO - main: Train iter. 88200/200000 (44.1%): 	Loss: 5.326754570007324	recon_loss: 0.002432056237012148	bpp_loss: 4.597137928009033	aux_loss: 0.19045203924179077
18:12:17 INFO - main: Train iter. 88300/200000 (44.15%): 	Loss: 5.324164390563965	recon_loss: 0.0024441664572805166	bpp_loss: 4.590914249420166	aux_loss: 0.5166195034980774
18:12:49 INFO - main: Train iter. 88400/200000 (44.2%): 	Loss: 5.332418441772461	recon_loss: 0.0024379605893045664	bpp_loss: 4.601030349731445	aux_loss: 0.29191651940345764
18:13:20 INFO - main: Train iter. 88500/200000 (44.25%): 	Loss: 5.325390815734863	recon_loss: 0.0024415054358541965	bpp_loss: 4.592939376831055	aux_loss: 0.2235119640827179
18:13:52 INFO - main: Train iter. 88600/200000 (44.3%): 	Loss: 5.32176399230957	recon_loss: 0.0024316010531038046	bpp_loss: 4.592283725738525	aux_loss: 0.27206510305404663
18:14:24 INFO - main: Train iter. 88700/200000 (44.35%): 	Loss: 5.321946620941162	recon_loss: 0.0024401857517659664	bpp_loss: 4.589890956878662	aux_loss: 1.0094619989395142
18:14:56 INFO - main: Train iter. 88800/200000 (44.4%): 	Loss: 5.321135520935059	recon_loss: 0.00243283505551517	bpp_loss: 4.591285228729248	aux_loss: 0.5357017517089844
18:15:29 INFO - main: Train iter. 88900/200000 (44.45%): 	Loss: 5.330730438232422	recon_loss: 0.0024403007701039314	bpp_loss: 4.598640441894531	aux_loss: 1.2256429195404053
18:16:01 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 5.3217620849609375	recon_loss: 0.002437660237774253	bpp_loss: 4.590464115142822	aux_loss: 0.6347777843475342
18:16:33 INFO - main: Train iter. 89100/200000 (44.55%): 	Loss: 5.3292975425720215	recon_loss: 0.0024393214844167233	bpp_loss: 4.597501277923584	aux_loss: 0.3143862187862396
18:17:05 INFO - main: Train iter. 89200/200000 (44.6%): 	Loss: 5.330146789550781	recon_loss: 0.002430455759167671	bpp_loss: 4.601009845733643	aux_loss: 0.2600008249282837
18:17:37 INFO - main: Train iter. 89300/200000 (44.65%): 	Loss: 5.3287787437438965	recon_loss: 0.0024368111044168472	bpp_loss: 4.597735404968262	aux_loss: 0.5678704380989075
18:18:08 INFO - main: Train iter. 89400/200000 (44.7%): 	Loss: 5.317394256591797	recon_loss: 0.002434162423014641	bpp_loss: 4.5871453285217285	aux_loss: 0.15582579374313354
18:18:40 INFO - main: Train iter. 89500/200000 (44.75%): 	Loss: 5.328959941864014	recon_loss: 0.002436417853459716	bpp_loss: 4.598034381866455	aux_loss: 0.4164012670516968
18:19:12 INFO - main: Train iter. 89600/200000 (44.8%): 	Loss: 5.327098846435547	recon_loss: 0.0024363496340811253	bpp_loss: 4.596193790435791	aux_loss: 0.7284245491027832
18:19:44 INFO - main: Train iter. 89700/200000 (44.85%): 	Loss: 5.315235614776611	recon_loss: 0.002432282315567136	bpp_loss: 4.585550785064697	aux_loss: 0.9991275072097778
18:20:16 INFO - main: Train iter. 89800/200000 (44.9%): 	Loss: 5.339697360992432	recon_loss: 0.002434195252135396	bpp_loss: 4.609438896179199	aux_loss: 0.20168949663639069
18:20:48 INFO - main: Train iter. 89900/200000 (44.95%): 	Loss: 5.331908702850342	recon_loss: 0.0024304050020873547	bpp_loss: 4.602787017822266	aux_loss: 0.4798576235771179
18:21:20 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 5.3414082527160645	recon_loss: 0.0024417622480541468	bpp_loss: 4.608879566192627	aux_loss: 0.7321007251739502
18:21:31 INFO - main: {'TEST MSE': 0.00244549205134099, 'TEST BPP': 4.616375, 'TEST loss': 5.335730974674225, 'TEST recon_loss': 0.0024454921337310224, 'TEST bpp_loss': 4.602083340644836}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:22:03 INFO - main: Train iter. 90100/200000 (45.05%): 	Loss: 5.326035022735596	recon_loss: 0.002434554509818554	bpp_loss: 4.595668792724609	aux_loss: 0.30854809284210205
18:22:34 INFO - main: Train iter. 90200/200000 (45.1%): 	Loss: 5.3246541023254395	recon_loss: 0.0024388155434280634	bpp_loss: 4.5930094718933105	aux_loss: 0.26360321044921875
18:23:08 INFO - main: Train iter. 90300/200000 (45.15%): 	Loss: 5.328429698944092	recon_loss: 0.0024314159527420998	bpp_loss: 4.599004745483398	aux_loss: 0.2902465760707855
18:23:39 INFO - main: Train iter. 90400/200000 (45.2%): 	Loss: 5.325373649597168	recon_loss: 0.002431225497275591	bpp_loss: 4.596005916595459	aux_loss: 0.39100202918052673
18:24:11 INFO - main: Train iter. 90500/200000 (45.25%): 	Loss: 5.325141429901123	recon_loss: 0.002438917523249984	bpp_loss: 4.593466281890869	aux_loss: 0.2560518980026245
18:24:43 INFO - main: Train iter. 90600/200000 (45.3%): 	Loss: 5.347497940063477	recon_loss: 0.002456649439409375	bpp_loss: 4.610503196716309	aux_loss: 0.5175952911376953
18:25:15 INFO - main: Train iter. 90700/200000 (45.35%): 	Loss: 5.327469825744629	recon_loss: 0.0024392055347561836	bpp_loss: 4.59570837020874	aux_loss: 0.24510718882083893
18:25:46 INFO - main: Train iter. 90800/200000 (45.4%): 	Loss: 5.327864646911621	recon_loss: 0.002451537409797311	bpp_loss: 4.592403411865234	aux_loss: 0.5795248746871948
18:26:19 INFO - main: Train iter. 90900/200000 (45.45%): 	Loss: 5.325876235961914	recon_loss: 0.0024352932814508677	bpp_loss: 4.595288276672363	aux_loss: 0.4017574191093445
18:26:50 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 5.326556205749512	recon_loss: 0.002432944718748331	bpp_loss: 4.596672534942627	aux_loss: 0.610295832157135
18:27:22 INFO - main: Train iter. 91100/200000 (45.55%): 	Loss: 5.329184055328369	recon_loss: 0.0024417450185865164	bpp_loss: 4.596660614013672	aux_loss: 0.799166202545166
18:27:54 INFO - main: Train iter. 91200/200000 (45.6%): 	Loss: 5.33695125579834	recon_loss: 0.0024420940317213535	bpp_loss: 4.604322910308838	aux_loss: 0.8188177943229675
18:28:26 INFO - main: Train iter. 91300/200000 (45.65%): 	Loss: 5.327808856964111	recon_loss: 0.0024370006285607815	bpp_loss: 4.59670877456665	aux_loss: 0.42806023359298706
18:28:58 INFO - main: Train iter. 91400/200000 (45.7%): 	Loss: 5.321512222290039	recon_loss: 0.002425772836431861	bpp_loss: 4.593780517578125	aux_loss: 1.2355684041976929
18:29:30 INFO - main: Train iter. 91500/200000 (45.75%): 	Loss: 5.326103210449219	recon_loss: 0.0024480817373842	bpp_loss: 4.591678619384766	aux_loss: 0.21801789104938507
18:30:03 INFO - main: Train iter. 91600/200000 (45.8%): 	Loss: 5.33070707321167	recon_loss: 0.0024348865263164043	bpp_loss: 4.600241184234619	aux_loss: 0.7030865550041199
18:30:35 INFO - main: Train iter. 91700/200000 (45.85%): 	Loss: 5.326678276062012	recon_loss: 0.0024331482127308846	bpp_loss: 4.596733570098877	aux_loss: 0.46378421783447266
18:31:06 INFO - main: Train iter. 91800/200000 (45.9%): 	Loss: 5.334644317626953	recon_loss: 0.002432658104225993	bpp_loss: 4.604846954345703	aux_loss: 0.1757940948009491
18:31:38 INFO - main: Train iter. 91900/200000 (45.95%): 	Loss: 5.332345008850098	recon_loss: 0.002436485141515732	bpp_loss: 4.6013994216918945	aux_loss: 0.7025023698806763
18:32:10 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 5.331971168518066	recon_loss: 0.002439263043925166	bpp_loss: 4.600192070007324	aux_loss: 0.8360148668289185
18:32:42 INFO - main: Train iter. 92100/200000 (46.05%): 	Loss: 5.34268856048584	recon_loss: 0.002437087008729577	bpp_loss: 4.611562252044678	aux_loss: 0.8671460747718811
18:33:14 INFO - main: Train iter. 92200/200000 (46.1%): 	Loss: 5.3351640701293945	recon_loss: 0.002444222802296281	bpp_loss: 4.601897239685059	aux_loss: 0.5102341771125793
18:33:45 INFO - main: Train iter. 92300/200000 (46.15%): 	Loss: 5.327950477600098	recon_loss: 0.002442736877128482	bpp_loss: 4.595129489898682	aux_loss: 0.4686602056026459
18:34:17 INFO - main: Train iter. 92400/200000 (46.2%): 	Loss: 5.321404933929443	recon_loss: 0.0024312660098075867	bpp_loss: 4.592025279998779	aux_loss: 0.3714669346809387
18:34:49 INFO - main: Train iter. 92500/200000 (46.25%): 	Loss: 5.322720050811768	recon_loss: 0.0024357796646654606	bpp_loss: 4.591986179351807	aux_loss: 0.20351901650428772
18:35:21 INFO - main: Train iter. 92600/200000 (46.3%): 	Loss: 5.326111793518066	recon_loss: 0.002425197744742036	bpp_loss: 4.598552703857422	aux_loss: 0.2981990575790405
18:35:53 INFO - main: Train iter. 92700/200000 (46.35%): 	Loss: 5.324763298034668	recon_loss: 0.0024449974298477173	bpp_loss: 4.591264247894287	aux_loss: 0.45203617215156555
18:36:24 INFO - main: Train iter. 92800/200000 (46.4%): 	Loss: 5.3245134353637695	recon_loss: 0.0024309700820595026	bpp_loss: 4.595222473144531	aux_loss: 0.31307846307754517
18:36:56 INFO - main: Train iter. 92900/200000 (46.45%): 	Loss: 5.327205657958984	recon_loss: 0.00242864852771163	bpp_loss: 4.598610877990723	aux_loss: 0.33818429708480835
18:37:29 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 5.333377838134766	recon_loss: 0.002433624118566513	bpp_loss: 4.603290557861328	aux_loss: 1.1292178630828857
18:38:01 INFO - main: Train iter. 93100/200000 (46.55%): 	Loss: 5.334203720092773	recon_loss: 0.002432372886687517	bpp_loss: 4.604491710662842	aux_loss: 0.4323662519454956
18:38:33 INFO - main: Train iter. 93200/200000 (46.6%): 	Loss: 5.332923889160156	recon_loss: 0.002434336580336094	bpp_loss: 4.602622985839844	aux_loss: 0.22440847754478455
18:39:05 INFO - main: Train iter. 93300/200000 (46.65%): 	Loss: 5.332559585571289	recon_loss: 0.0024314220063388348	bpp_loss: 4.603132724761963	aux_loss: 0.25816670060157776
18:39:37 INFO - main: Train iter. 93400/200000 (46.7%): 	Loss: 5.338990688323975	recon_loss: 0.002435792703181505	bpp_loss: 4.608253002166748	aux_loss: 0.35101258754730225
18:40:09 INFO - main: Train iter. 93500/200000 (46.75%): 	Loss: 5.3197712898254395	recon_loss: 0.0024348292499780655	bpp_loss: 4.589322566986084	aux_loss: 1.2476379871368408
18:40:41 INFO - main: Train iter. 93600/200000 (46.8%): 	Loss: 5.32858943939209	recon_loss: 0.0024329661391675472	bpp_loss: 4.598699569702148	aux_loss: 0.6495640873908997
18:41:12 INFO - main: Train iter. 93700/200000 (46.85%): 	Loss: 5.335207939147949	recon_loss: 0.0024391452316194773	bpp_loss: 4.603464603424072	aux_loss: 0.35428494215011597
18:41:44 INFO - main: Train iter. 93800/200000 (46.9%): 	Loss: 5.330097198486328	recon_loss: 0.002436008071526885	bpp_loss: 4.599294662475586	aux_loss: 0.7453728914260864
18:42:16 INFO - main: Train iter. 93900/200000 (46.95%): 	Loss: 5.332801818847656	recon_loss: 0.0024318278301507235	bpp_loss: 4.603253364562988	aux_loss: 0.9205396771430969
18:42:48 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 5.322159290313721	recon_loss: 0.002427074359729886	bpp_loss: 4.594037055969238	aux_loss: 0.23083047568798065
18:43:20 INFO - main: Train iter. 94100/200000 (47.05%): 	Loss: 5.325223445892334	recon_loss: 0.0024319137446582317	bpp_loss: 4.595649242401123	aux_loss: 0.3706985414028168
18:43:52 INFO - main: Train iter. 94200/200000 (47.1%): 	Loss: 5.321331024169922	recon_loss: 0.002428698120638728	bpp_loss: 4.592721462249756	aux_loss: 1.4080442190170288
18:44:24 INFO - main: Train iter. 94300/200000 (47.15%): 	Loss: 5.326323509216309	recon_loss: 0.002427005209028721	bpp_loss: 4.598221778869629	aux_loss: 0.313919335603714
18:44:57 INFO - main: Train iter. 94400/200000 (47.2%): 	Loss: 5.337697982788086	recon_loss: 0.002426789840683341	bpp_loss: 4.609661102294922	aux_loss: 0.584385871887207
18:45:29 INFO - main: Train iter. 94500/200000 (47.25%): 	Loss: 5.330084800720215	recon_loss: 0.00242879637517035	bpp_loss: 4.601446151733398	aux_loss: 0.41227322816848755
18:46:00 INFO - main: Train iter. 94600/200000 (47.3%): 	Loss: 5.324357032775879	recon_loss: 0.002442981582134962	bpp_loss: 4.5914626121521	aux_loss: 0.9019034504890442
18:46:32 INFO - main: Train iter. 94700/200000 (47.35%): 	Loss: 5.332108497619629	recon_loss: 0.00244493898935616	bpp_loss: 4.598626613616943	aux_loss: 0.23014883697032928
18:47:04 INFO - main: Train iter. 94800/200000 (47.4%): 	Loss: 5.331932067871094	recon_loss: 0.0024361968971788883	bpp_loss: 4.601073265075684	aux_loss: 0.7913075685501099
18:47:36 INFO - main: Train iter. 94900/200000 (47.45%): 	Loss: 5.334198951721191	recon_loss: 0.0024286156985908747	bpp_loss: 4.605614185333252	aux_loss: 0.551311194896698
18:48:08 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 5.322734832763672	recon_loss: 0.002432809676975012	bpp_loss: 4.592891693115234	aux_loss: 0.1535719931125641
18:48:19 INFO - main: {'TEST MSE': 0.0024252576832725897, 'TEST BPP': 4.6168203125, 'TEST loss': 5.33014587688446, 'TEST recon_loss': 0.002425257764523849, 'TEST bpp_loss': 4.602568556785584}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
18:48:51 INFO - main: Train iter. 95100/200000 (47.55%): 	Loss: 5.337629318237305	recon_loss: 0.0024341668467968702	bpp_loss: 4.60737943649292	aux_loss: 0.6290088891983032
18:49:22 INFO - main: Train iter. 95200/200000 (47.6%): 	Loss: 5.325140953063965	recon_loss: 0.0024273465387523174	bpp_loss: 4.59693717956543	aux_loss: 0.16865575313568115
18:49:54 INFO - main: Train iter. 95300/200000 (47.65%): 	Loss: 5.331361293792725	recon_loss: 0.0024334362242370844	bpp_loss: 4.601330280303955	aux_loss: 0.5537728071212769
18:50:26 INFO - main: Train iter. 95400/200000 (47.7%): 	Loss: 5.324472904205322	recon_loss: 0.0024330364540219307	bpp_loss: 4.59456205368042	aux_loss: 0.23492804169654846
18:50:58 INFO - main: Train iter. 95500/200000 (47.75%): 	Loss: 5.329070568084717	recon_loss: 0.002433337038382888	bpp_loss: 4.599069595336914	aux_loss: 0.6535740494728088
18:51:30 INFO - main: Train iter. 95600/200000 (47.8%): 	Loss: 5.3289899826049805	recon_loss: 0.002429437357932329	bpp_loss: 4.60015869140625	aux_loss: 0.3876207768917084
18:52:03 INFO - main: Train iter. 95700/200000 (47.85%): 	Loss: 5.3213276863098145	recon_loss: 0.0024283097591251135	bpp_loss: 4.592834949493408	aux_loss: 0.20206093788146973
18:52:35 INFO - main: Train iter. 95800/200000 (47.9%): 	Loss: 5.332136631011963	recon_loss: 0.0024287160485982895	bpp_loss: 4.603521823883057	aux_loss: 0.1914575695991516
18:53:06 INFO - main: Train iter. 95900/200000 (47.95%): 	Loss: 5.3196797370910645	recon_loss: 0.002434105845168233	bpp_loss: 4.589447975158691	aux_loss: 1.0999196767807007
18:53:38 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 5.318313121795654	recon_loss: 0.0024280045181512833	bpp_loss: 4.589911937713623	aux_loss: 0.4354923367500305
18:54:10 INFO - main: Train iter. 96100/200000 (48.05%): 	Loss: 5.326591491699219	recon_loss: 0.0024392057675868273	bpp_loss: 4.594829559326172	aux_loss: 0.2414223849773407
18:54:42 INFO - main: Train iter. 96200/200000 (48.1%): 	Loss: 5.320526123046875	recon_loss: 0.0024311565794050694	bpp_loss: 4.591179370880127	aux_loss: 0.615879476070404
18:55:14 INFO - main: Train iter. 96300/200000 (48.15%): 	Loss: 5.328707695007324	recon_loss: 0.0024321270175278187	bpp_loss: 4.599069595336914	aux_loss: 0.8210127353668213
18:55:46 INFO - main: Train iter. 96400/200000 (48.2%): 	Loss: 5.341635227203369	recon_loss: 0.002451068488880992	bpp_loss: 4.606314659118652	aux_loss: 0.6546503901481628
18:56:17 INFO - main: Train iter. 96500/200000 (48.25%): 	Loss: 5.320423126220703	recon_loss: 0.002433975925669074	bpp_loss: 4.590230464935303	aux_loss: 0.3512222468852997
18:56:49 INFO - main: Train iter. 96600/200000 (48.3%): 	Loss: 5.329389572143555	recon_loss: 0.0024499453138560057	bpp_loss: 4.5944061279296875	aux_loss: 0.4000195860862732
18:57:21 INFO - main: Train iter. 96700/200000 (48.35%): 	Loss: 5.331526279449463	recon_loss: 0.0024402663111686707	bpp_loss: 4.5994462966918945	aux_loss: 0.33647865056991577
18:57:53 INFO - main: Train iter. 96800/200000 (48.4%): 	Loss: 5.335125923156738	recon_loss: 0.0024459504056721926	bpp_loss: 4.6013407707214355	aux_loss: 0.5908043384552002
18:58:25 INFO - main: Train iter. 96900/200000 (48.45%): 	Loss: 5.3274455070495605	recon_loss: 0.0024326005950570107	bpp_loss: 4.597665309906006	aux_loss: 0.6135423183441162
18:58:56 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 5.329769134521484	recon_loss: 0.0024447471369057894	bpp_loss: 4.596344947814941	aux_loss: 0.34637176990509033
18:59:30 INFO - main: Train iter. 97100/200000 (48.55%): 	Loss: 5.331960201263428	recon_loss: 0.00244081555865705	bpp_loss: 4.599715709686279	aux_loss: 0.3169776499271393
19:00:01 INFO - main: Train iter. 97200/200000 (48.6%): 	Loss: 5.336003303527832	recon_loss: 0.002463199896737933	bpp_loss: 4.597043514251709	aux_loss: 0.3834644556045532
19:00:33 INFO - main: Train iter. 97300/200000 (48.65%): 	Loss: 5.338391304016113	recon_loss: 0.0024441806599497795	bpp_loss: 4.605137348175049	aux_loss: 0.44587838649749756
19:01:05 INFO - main: Train iter. 97400/200000 (48.7%): 	Loss: 5.334912300109863	recon_loss: 0.002459608018398285	bpp_loss: 4.597029685974121	aux_loss: 0.8597548007965088
19:01:37 INFO - main: Train iter. 97500/200000 (48.75%): 	Loss: 5.3284759521484375	recon_loss: 0.002467827405780554	bpp_loss: 4.588127613067627	aux_loss: 0.2664795517921448
19:02:09 INFO - main: Train iter. 97600/200000 (48.8%): 	Loss: 5.324532508850098	recon_loss: 0.00244445214048028	bpp_loss: 4.5911970138549805	aux_loss: 0.4272118806838989
19:02:41 INFO - main: Train iter. 97700/200000 (48.85%): 	Loss: 5.325707912445068	recon_loss: 0.0024411724880337715	bpp_loss: 4.593356132507324	aux_loss: 0.974997341632843
19:03:12 INFO - main: Train iter. 97800/200000 (48.9%): 	Loss: 5.339044570922852	recon_loss: 0.0024875947274267673	bpp_loss: 4.592766284942627	aux_loss: 0.933159589767456
19:03:44 INFO - main: Train iter. 97900/200000 (48.95%): 	Loss: 5.3248395919799805	recon_loss: 0.002447322476655245	bpp_loss: 4.590642929077148	aux_loss: 0.6164042949676514
19:04:16 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 5.339323997497559	recon_loss: 0.002453609835356474	bpp_loss: 4.603240966796875	aux_loss: 0.37174832820892334
19:04:48 INFO - main: Train iter. 98100/200000 (49.05%): 	Loss: 5.331375598907471	recon_loss: 0.0024745205882936716	bpp_loss: 4.589019298553467	aux_loss: 0.6052670478820801
19:05:20 INFO - main: Train iter. 98200/200000 (49.1%): 	Loss: 5.33195686340332	recon_loss: 0.0024393487256020308	bpp_loss: 4.600152015686035	aux_loss: 1.1079046726226807
19:05:51 INFO - main: Train iter. 98300/200000 (49.15%): 	Loss: 5.33671760559082	recon_loss: 0.0024535919073969126	bpp_loss: 4.600639820098877	aux_loss: 0.3107004761695862
19:06:23 INFO - main: Train iter. 98400/200000 (49.2%): 	Loss: 5.351569652557373	recon_loss: 0.0024462721776217222	bpp_loss: 4.617688179016113	aux_loss: 0.36119401454925537
19:06:56 INFO - main: Train iter. 98500/200000 (49.25%): 	Loss: 5.325523853302002	recon_loss: 0.0024343456607311964	bpp_loss: 4.59522008895874	aux_loss: 0.8043034076690674
19:07:28 INFO - main: Train iter. 98600/200000 (49.3%): 	Loss: 5.323960781097412	recon_loss: 0.0024304755497723818	bpp_loss: 4.594818115234375	aux_loss: 1.5451905727386475
19:08:00 INFO - main: Train iter. 98700/200000 (49.35%): 	Loss: 5.331945419311523	recon_loss: 0.002445835154503584	bpp_loss: 4.5981950759887695	aux_loss: 1.3165063858032227
19:08:32 INFO - main: Train iter. 98800/200000 (49.4%): 	Loss: 5.338766098022461	recon_loss: 0.002476524328812957	bpp_loss: 4.595808982849121	aux_loss: 0.7085819244384766
19:09:04 INFO - main: Train iter. 98900/200000 (49.45%): 	Loss: 5.323769569396973	recon_loss: 0.0024385331198573112	bpp_loss: 4.592209815979004	aux_loss: 0.730059027671814
19:09:36 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 5.321369647979736	recon_loss: 0.002447959501296282	bpp_loss: 4.586981773376465	aux_loss: 0.43545275926589966
19:10:07 INFO - main: Train iter. 99100/200000 (49.55%): 	Loss: 5.336730480194092	recon_loss: 0.002459654351696372	bpp_loss: 4.598834037780762	aux_loss: 0.7809633612632751
19:10:39 INFO - main: Train iter. 99200/200000 (49.6%): 	Loss: 5.335831642150879	recon_loss: 0.002444170182570815	bpp_loss: 4.602580547332764	aux_loss: 0.355678915977478
19:11:11 INFO - main: Train iter. 99300/200000 (49.65%): 	Loss: 5.324160575866699	recon_loss: 0.002438770141452551	bpp_loss: 4.592529773712158	aux_loss: 0.6124042272567749
19:11:43 INFO - main: Train iter. 99400/200000 (49.7%): 	Loss: 5.330076217651367	recon_loss: 0.0024475727695971727	bpp_loss: 4.595804214477539	aux_loss: 0.8033366203308105
19:12:15 INFO - main: Train iter. 99500/200000 (49.75%): 	Loss: 5.337317943572998	recon_loss: 0.002434999216347933	bpp_loss: 4.606818199157715	aux_loss: 0.29181480407714844
19:12:47 INFO - main: Train iter. 99600/200000 (49.8%): 	Loss: 5.321979522705078	recon_loss: 0.002432306529954076	bpp_loss: 4.592287540435791	aux_loss: 0.4956125020980835
19:13:19 INFO - main: Train iter. 99700/200000 (49.85%): 	Loss: 5.338261604309082	recon_loss: 0.002441618824377656	bpp_loss: 4.605775833129883	aux_loss: 0.28029119968414307
19:13:52 INFO - main: Train iter. 99800/200000 (49.9%): 	Loss: 5.325961112976074	recon_loss: 0.002435248577967286	bpp_loss: 4.595386505126953	aux_loss: 0.1776561141014099
19:14:24 INFO - main: Train iter. 99900/200000 (49.95%): 	Loss: 5.31264066696167	recon_loss: 0.0024404702708125114	bpp_loss: 4.580499649047852	aux_loss: 0.2325572371482849
19:14:56 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 5.328112602233887	recon_loss: 0.0024347256403416395	bpp_loss: 4.5976948738098145	aux_loss: 0.4813871383666992
19:15:07 INFO - main: {'TEST MSE': 0.0024312714861789314, 'TEST BPP': 4.6157578125, 'TEST loss': 5.3310590443611146, 'TEST recon_loss': 0.002431271567707881, 'TEST bpp_loss': 4.601677578449249}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:15:39 INFO - main: Train iter. 100100/200000 (50.05%): 	Loss: 5.334854602813721	recon_loss: 0.0024331072345376015	bpp_loss: 4.604922294616699	aux_loss: 0.5718804597854614
19:16:10 INFO - main: Train iter. 100200/200000 (50.1%): 	Loss: 5.320808410644531	recon_loss: 0.0024352457839995623	bpp_loss: 4.590234756469727	aux_loss: 1.51182222366333
19:16:42 INFO - main: Train iter. 100300/200000 (50.15%): 	Loss: 5.335778713226318	recon_loss: 0.002434341236948967	bpp_loss: 4.605476379394531	aux_loss: 0.2769761085510254
19:17:14 INFO - main: Train iter. 100400/200000 (50.2%): 	Loss: 5.336658477783203	recon_loss: 0.0024451494682580233	bpp_loss: 4.603113651275635	aux_loss: 0.8882598876953125
19:17:46 INFO - main: Train iter. 100500/200000 (50.25%): 	Loss: 5.329648017883301	recon_loss: 0.002431008731946349	bpp_loss: 4.600345134735107	aux_loss: 0.7892777323722839
19:18:18 INFO - main: Train iter. 100600/200000 (50.3%): 	Loss: 5.3306074142456055	recon_loss: 0.002432748442515731	bpp_loss: 4.600782871246338	aux_loss: 0.5754449367523193
19:18:49 INFO - main: Train iter. 100700/200000 (50.35%): 	Loss: 5.343738555908203	recon_loss: 0.0024356963112950325	bpp_loss: 4.613029479980469	aux_loss: 0.4799247980117798
19:19:21 INFO - main: Train iter. 100800/200000 (50.4%): 	Loss: 5.331467628479004	recon_loss: 0.0024362271651625633	bpp_loss: 4.60059928894043	aux_loss: 0.5179028511047363
19:19:53 INFO - main: Train iter. 100900/200000 (50.45%): 	Loss: 5.324268341064453	recon_loss: 0.0024322608951479197	bpp_loss: 4.594590187072754	aux_loss: 0.838004469871521
19:20:25 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 5.3275980949401855	recon_loss: 0.002441534772515297	bpp_loss: 4.595137596130371	aux_loss: 0.4388112425804138
19:20:57 INFO - main: Train iter. 101100/200000 (50.55%): 	Loss: 5.3333048820495605	recon_loss: 0.002427690429612994	bpp_loss: 4.604997634887695	aux_loss: 1.013967514038086
19:21:30 INFO - main: Train iter. 101200/200000 (50.6%): 	Loss: 5.326239585876465	recon_loss: 0.002433566842228174	bpp_loss: 4.596169471740723	aux_loss: 0.7875005006790161
19:22:02 INFO - main: Train iter. 101300/200000 (50.65%): 	Loss: 5.334291934967041	recon_loss: 0.002431748202070594	bpp_loss: 4.604767322540283	aux_loss: 0.2473917305469513
19:22:33 INFO - main: Train iter. 101400/200000 (50.7%): 	Loss: 5.326275825500488	recon_loss: 0.0024293072056025267	bpp_loss: 4.5974836349487305	aux_loss: 0.5191007852554321
19:23:05 INFO - main: Train iter. 101500/200000 (50.75%): 	Loss: 5.328558921813965	recon_loss: 0.002438837196677923	bpp_loss: 4.596907615661621	aux_loss: 0.32941490411758423
19:23:37 INFO - main: Train iter. 101600/200000 (50.8%): 	Loss: 5.326185703277588	recon_loss: 0.002444057958200574	bpp_loss: 4.592968463897705	aux_loss: 0.22723159193992615
19:24:09 INFO - main: Train iter. 101700/200000 (50.85%): 	Loss: 5.339568138122559	recon_loss: 0.002435012487694621	bpp_loss: 4.60906457901001	aux_loss: 0.30489903688430786
19:24:41 INFO - main: Train iter. 101800/200000 (50.9%): 	Loss: 5.339574813842773	recon_loss: 0.0024274277966469526	bpp_loss: 4.61134672164917	aux_loss: 0.6515280604362488
19:25:13 INFO - main: Train iter. 101900/200000 (50.95%): 	Loss: 5.334064483642578	recon_loss: 0.0024415424559265375	bpp_loss: 4.601601600646973	aux_loss: 0.3930231034755707
19:25:44 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 5.3263373374938965	recon_loss: 0.0024305323604494333	bpp_loss: 4.597177505493164	aux_loss: 0.24124053120613098
19:26:16 INFO - main: Train iter. 102100/200000 (51.05%): 	Loss: 5.339453220367432	recon_loss: 0.002447734121233225	bpp_loss: 4.605133056640625	aux_loss: 0.5971144437789917
19:26:48 INFO - main: Train iter. 102200/200000 (51.1%): 	Loss: 5.324642658233643	recon_loss: 0.0024384725838899612	bpp_loss: 4.5931010246276855	aux_loss: 0.3787464499473572
19:27:20 INFO - main: Train iter. 102300/200000 (51.15%): 	Loss: 5.33510160446167	recon_loss: 0.002441415097564459	bpp_loss: 4.602676868438721	aux_loss: 0.24698203802108765
19:27:52 INFO - main: Train iter. 102400/200000 (51.2%): 	Loss: 5.344915390014648	recon_loss: 0.0024327405262738466	bpp_loss: 4.615093231201172	aux_loss: 0.2377808839082718
19:28:24 INFO - main: Train iter. 102500/200000 (51.25%): 	Loss: 5.329510688781738	recon_loss: 0.0024250145070254803	bpp_loss: 4.602006435394287	aux_loss: 0.5155029296875
19:28:57 INFO - main: Train iter. 102600/200000 (51.3%): 	Loss: 5.334656238555908	recon_loss: 0.002451489446684718	bpp_loss: 4.599209308624268	aux_loss: 0.8613994717597961
19:29:29 INFO - main: Train iter. 102700/200000 (51.35%): 	Loss: 5.336766242980957	recon_loss: 0.0024400281254202127	bpp_loss: 4.604757785797119	aux_loss: 0.8632916808128357
19:30:00 INFO - main: Train iter. 102800/200000 (51.4%): 	Loss: 5.336287021636963	recon_loss: 0.0024908771738409996	bpp_loss: 4.589024066925049	aux_loss: 0.4275286793708801
19:30:32 INFO - main: Train iter. 102900/200000 (51.45%): 	Loss: 5.336437702178955	recon_loss: 0.0024421089328825474	bpp_loss: 4.603805065155029	aux_loss: 0.7069067358970642
19:31:04 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 5.324565887451172	recon_loss: 0.002454291097819805	bpp_loss: 4.588278770446777	aux_loss: 0.8279341459274292
19:31:36 INFO - main: Train iter. 103100/200000 (51.55%): 	Loss: 5.335368633270264	recon_loss: 0.0024479522835463285	bpp_loss: 4.600983142852783	aux_loss: 1.6066370010375977
19:32:07 INFO - main: Train iter. 103200/200000 (51.6%): 	Loss: 5.323229789733887	recon_loss: 0.0024448649492114782	bpp_loss: 4.589770317077637	aux_loss: 0.6555719375610352
19:32:39 INFO - main: Train iter. 103300/200000 (51.65%): 	Loss: 5.324153423309326	recon_loss: 0.002446139696985483	bpp_loss: 4.590311527252197	aux_loss: 1.026935338973999
19:33:11 INFO - main: Train iter. 103400/200000 (51.7%): 	Loss: 5.3297882080078125	recon_loss: 0.0024389829486608505	bpp_loss: 4.598093509674072	aux_loss: 0.5968261957168579
19:33:43 INFO - main: Train iter. 103500/200000 (51.75%): 	Loss: 5.3211750984191895	recon_loss: 0.002431752858683467	bpp_loss: 4.591649055480957	aux_loss: 0.3031061291694641
19:34:15 INFO - main: Train iter. 103600/200000 (51.8%): 	Loss: 5.330109596252441	recon_loss: 0.002438437659293413	bpp_loss: 4.598578453063965	aux_loss: 0.7813400030136108
19:34:46 INFO - main: Train iter. 103700/200000 (51.85%): 	Loss: 5.334012985229492	recon_loss: 0.0024369917809963226	bpp_loss: 4.602915287017822	aux_loss: 0.2421177178621292
19:35:18 INFO - main: Train iter. 103800/200000 (51.9%): 	Loss: 5.318068504333496	recon_loss: 0.002430277643725276	bpp_loss: 4.588985443115234	aux_loss: 1.023716688156128
19:35:51 INFO - main: Train iter. 103900/200000 (51.95%): 	Loss: 5.339570045471191	recon_loss: 0.0024360092356801033	bpp_loss: 4.608767032623291	aux_loss: 0.24074386060237885
19:36:23 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 5.314208507537842	recon_loss: 0.002430061111226678	bpp_loss: 4.585190296173096	aux_loss: 0.7917324304580688
19:36:55 INFO - main: Train iter. 104100/200000 (52.05%): 	Loss: 5.332400321960449	recon_loss: 0.002438897965475917	bpp_loss: 4.600730895996094	aux_loss: 0.294280081987381
19:37:27 INFO - main: Train iter. 104200/200000 (52.1%): 	Loss: 5.335804462432861	recon_loss: 0.0024518442805856466	bpp_loss: 4.600251197814941	aux_loss: 0.9090380072593689
19:37:59 INFO - main: Train iter. 104300/200000 (52.15%): 	Loss: 5.339559078216553	recon_loss: 0.002445345278829336	bpp_loss: 4.605955600738525	aux_loss: 0.4547278881072998
19:38:31 INFO - main: Train iter. 104400/200000 (52.2%): 	Loss: 5.331455230712891	recon_loss: 0.0024768428411334753	bpp_loss: 4.588402271270752	aux_loss: 0.9789923429489136
19:39:02 INFO - main: Train iter. 104500/200000 (52.25%): 	Loss: 5.33469820022583	recon_loss: 0.002439924981445074	bpp_loss: 4.602720737457275	aux_loss: 0.44106224179267883
19:39:34 INFO - main: Train iter. 104600/200000 (52.3%): 	Loss: 5.33914041519165	recon_loss: 0.002433726331219077	bpp_loss: 4.609022617340088	aux_loss: 0.28096041083335876
19:40:06 INFO - main: Train iter. 104700/200000 (52.35%): 	Loss: 5.3285040855407715	recon_loss: 0.002438388066366315	bpp_loss: 4.596987724304199	aux_loss: 0.7513013482093811
19:40:38 INFO - main: Train iter. 104800/200000 (52.4%): 	Loss: 5.330111503601074	recon_loss: 0.0024468875490128994	bpp_loss: 4.59604549407959	aux_loss: 0.34750550985336304
19:41:10 INFO - main: Train iter. 104900/200000 (52.45%): 	Loss: 5.329037189483643	recon_loss: 0.0024331556633114815	bpp_loss: 4.599090576171875	aux_loss: 0.729891300201416
19:41:42 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 5.330515384674072	recon_loss: 0.0024491422809660435	bpp_loss: 4.595772743225098	aux_loss: 0.3518741726875305
19:41:53 INFO - main: {'TEST MSE': 0.0024475393186317433, 'TEST BPP': 4.6146015625, 'TEST loss': 5.334502005577088, 'TEST recon_loss': 0.002447539399843663, 'TEST bpp_loss': 4.600240184783935}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
19:42:24 INFO - main: Train iter. 105100/200000 (52.55%): 	Loss: 5.334557056427002	recon_loss: 0.002448219107463956	bpp_loss: 4.600091457366943	aux_loss: 1.4784785509109497
19:42:56 INFO - main: Train iter. 105200/200000 (52.6%): 	Loss: 5.333332061767578	recon_loss: 0.0024363489355891943	bpp_loss: 4.6024274826049805	aux_loss: 0.35971957445144653
19:43:29 INFO - main: Train iter. 105300/200000 (52.65%): 	Loss: 5.327362060546875	recon_loss: 0.0024378288071602583	bpp_loss: 4.59601354598999	aux_loss: 0.48688575625419617
19:44:01 INFO - main: Train iter. 105400/200000 (52.7%): 	Loss: 5.312633037567139	recon_loss: 0.0024335894268006086	bpp_loss: 4.582556247711182	aux_loss: 0.5523476600646973
19:44:33 INFO - main: Train iter. 105500/200000 (52.75%): 	Loss: 5.333552837371826	recon_loss: 0.0024349165614694357	bpp_loss: 4.6030778884887695	aux_loss: 0.3428768515586853
19:45:05 INFO - main: Train iter. 105600/200000 (52.8%): 	Loss: 5.34104061126709	recon_loss: 0.002431232947856188	bpp_loss: 4.611670970916748	aux_loss: 0.20599669218063354
19:45:37 INFO - main: Train iter. 105700/200000 (52.85%): 	Loss: 5.341560363769531	recon_loss: 0.002451719017699361	bpp_loss: 4.606044769287109	aux_loss: 0.5624995231628418
19:46:08 INFO - main: Train iter. 105800/200000 (52.9%): 	Loss: 5.324223041534424	recon_loss: 0.0024311833549290895	bpp_loss: 4.594868183135986	aux_loss: 0.6346603035926819
19:46:40 INFO - main: Train iter. 105900/200000 (52.95%): 	Loss: 5.339320659637451	recon_loss: 0.0024361738469451666	bpp_loss: 4.608468532562256	aux_loss: 0.24266916513442993
19:47:12 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 5.326269149780273	recon_loss: 0.002440299140289426	bpp_loss: 4.594179153442383	aux_loss: 0.30193501710891724
19:47:44 INFO - main: Train iter. 106100/200000 (53.05%): 	Loss: 5.321131706237793	recon_loss: 0.002434358699247241	bpp_loss: 4.590824127197266	aux_loss: 0.17601576447486877
19:48:16 INFO - main: Train iter. 106200/200000 (53.1%): 	Loss: 5.329376220703125	recon_loss: 0.00243052514269948	bpp_loss: 4.600218772888184	aux_loss: 0.473594069480896
19:48:48 INFO - main: Train iter. 106300/200000 (53.15%): 	Loss: 5.303997039794922	recon_loss: 0.0024298932403326035	bpp_loss: 4.575028896331787	aux_loss: 0.2407989501953125
19:49:19 INFO - main: Train iter. 106400/200000 (53.2%): 	Loss: 5.327859401702881	recon_loss: 0.0024362567346543074	bpp_loss: 4.596982479095459	aux_loss: 0.37035343050956726
19:49:51 INFO - main: Train iter. 106500/200000 (53.25%): 	Loss: 5.32285737991333	recon_loss: 0.0024289435241371393	bpp_loss: 4.594174385070801	aux_loss: 0.7788639068603516
19:50:23 INFO - main: Train iter. 106600/200000 (53.3%): 	Loss: 5.309809684753418	recon_loss: 0.00243157590739429	bpp_loss: 4.580337047576904	aux_loss: 0.3538739085197449
19:50:56 INFO - main: Train iter. 106700/200000 (53.35%): 	Loss: 5.3317108154296875	recon_loss: 0.0024756351485848427	bpp_loss: 4.589020252227783	aux_loss: 0.5562698841094971
19:51:28 INFO - main: Train iter. 106800/200000 (53.4%): 	Loss: 5.330984115600586	recon_loss: 0.0024363051634281874	bpp_loss: 4.60009241104126	aux_loss: 0.45171719789505005
19:52:00 INFO - main: Train iter. 106900/200000 (53.45%): 	Loss: 5.33416748046875	recon_loss: 0.0024308827705681324	bpp_loss: 4.604902744293213	aux_loss: 0.5241124629974365
19:52:32 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 5.333434104919434	recon_loss: 0.0024530438240617514	bpp_loss: 4.59752082824707	aux_loss: 0.3267936706542969
19:53:04 INFO - main: Train iter. 107100/200000 (53.55%): 	Loss: 5.350379943847656	recon_loss: 0.002445062156766653	bpp_loss: 4.616861343383789	aux_loss: 0.18983149528503418
19:53:35 INFO - main: Train iter. 107200/200000 (53.6%): 	Loss: 5.329672813415527	recon_loss: 0.002431652508676052	bpp_loss: 4.60017728805542	aux_loss: 0.3883405923843384
19:54:07 INFO - main: Train iter. 107300/200000 (53.65%): 	Loss: 5.3390655517578125	recon_loss: 0.002450041240081191	bpp_loss: 4.604053020477295	aux_loss: 0.32689303159713745
19:54:39 INFO - main: Train iter. 107400/200000 (53.7%): 	Loss: 5.340372085571289	recon_loss: 0.0024315854534506798	bpp_loss: 4.610896587371826	aux_loss: 0.5947073698043823
19:55:11 INFO - main: Train iter. 107500/200000 (53.75%): 	Loss: 5.334774017333984	recon_loss: 0.0024461073335260153	bpp_loss: 4.6009416580200195	aux_loss: 0.3358566462993622
19:55:43 INFO - main: Train iter. 107600/200000 (53.8%): 	Loss: 5.352879524230957	recon_loss: 0.002434787806123495	bpp_loss: 4.622443199157715	aux_loss: 0.7360603213310242
19:56:14 INFO - main: Train iter. 107700/200000 (53.85%): 	Loss: 5.347709655761719	recon_loss: 0.002493150532245636	bpp_loss: 4.599764347076416	aux_loss: 0.3167176842689514
19:56:46 INFO - main: Train iter. 107800/200000 (53.9%): 	Loss: 5.331698894500732	recon_loss: 0.002446802332997322	bpp_loss: 4.597658157348633	aux_loss: 0.27915263175964355
19:57:18 INFO - main: Train iter. 107900/200000 (53.95%): 	Loss: 5.338752746582031	recon_loss: 0.0024496421683579683	bpp_loss: 4.603859901428223	aux_loss: 0.3276995122432709
19:57:51 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 5.325815677642822	recon_loss: 0.0024309412110596895	bpp_loss: 4.596533298492432	aux_loss: 0.4467683434486389
19:58:23 INFO - main: Train iter. 108100/200000 (54.05%): 	Loss: 5.327224254608154	recon_loss: 0.002438195049762726	bpp_loss: 4.595765590667725	aux_loss: 0.28360021114349365
19:58:55 INFO - main: Train iter. 108200/200000 (54.1%): 	Loss: 5.337560176849365	recon_loss: 0.0024589223321527243	bpp_loss: 4.599883556365967	aux_loss: 0.4822375476360321
19:59:27 INFO - main: Train iter. 108300/200000 (54.15%): 	Loss: 5.326241970062256	recon_loss: 0.0024386027362197638	bpp_loss: 4.594661235809326	aux_loss: 0.3728046417236328
19:59:59 INFO - main: Train iter. 108400/200000 (54.2%): 	Loss: 5.327879428863525	recon_loss: 0.0024413750506937504	bpp_loss: 4.5954670906066895	aux_loss: 1.5197831392288208
20:00:30 INFO - main: Train iter. 108500/200000 (54.25%): 	Loss: 5.32653284072876	recon_loss: 0.0024448067415505648	bpp_loss: 4.593091011047363	aux_loss: 1.6352230310440063
20:01:02 INFO - main: Train iter. 108600/200000 (54.3%): 	Loss: 5.322361946105957	recon_loss: 0.0024419687688350677	bpp_loss: 4.589771270751953	aux_loss: 0.37178030610084534
20:01:34 INFO - main: Train iter. 108700/200000 (54.35%): 	Loss: 5.3341875076293945	recon_loss: 0.0024340746458619833	bpp_loss: 4.6039652824401855	aux_loss: 0.4004392921924591
20:02:06 INFO - main: Train iter. 108800/200000 (54.4%): 	Loss: 5.336618423461914	recon_loss: 0.0024353761691600084	bpp_loss: 4.606005668640137	aux_loss: 0.5110358595848083
20:02:38 INFO - main: Train iter. 108900/200000 (54.45%): 	Loss: 5.330985069274902	recon_loss: 0.002434099791571498	bpp_loss: 4.600755214691162	aux_loss: 1.725398063659668
20:03:10 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 5.316465854644775	recon_loss: 0.0024329128209501505	bpp_loss: 4.586592197418213	aux_loss: 0.22660988569259644
20:03:41 INFO - main: Train iter. 109100/200000 (54.55%): 	Loss: 5.317046642303467	recon_loss: 0.00243120058439672	bpp_loss: 4.587686538696289	aux_loss: 0.4620019793510437
20:04:13 INFO - main: Train iter. 109200/200000 (54.6%): 	Loss: 5.347542762756348	recon_loss: 0.0024340846575796604	bpp_loss: 4.617317199707031	aux_loss: 0.3669404089450836
20:04:45 INFO - main: Train iter. 109300/200000 (54.65%): 	Loss: 5.3207011222839355	recon_loss: 0.0024397673550993204	bpp_loss: 4.588770866394043	aux_loss: 0.19286033511161804
20:05:18 INFO - main: Train iter. 109400/200000 (54.7%): 	Loss: 5.332058429718018	recon_loss: 0.0024503327440470457	bpp_loss: 4.596958637237549	aux_loss: 0.37046200037002563
20:05:50 INFO - main: Train iter. 109500/200000 (54.75%): 	Loss: 5.31411075592041	recon_loss: 0.0024375268258154392	bpp_loss: 4.582852840423584	aux_loss: 0.33460748195648193
20:06:22 INFO - main: Train iter. 109600/200000 (54.8%): 	Loss: 5.332287311553955	recon_loss: 0.0024419380351901054	bpp_loss: 4.599705696105957	aux_loss: 0.3689541518688202
20:06:54 INFO - main: Train iter. 109700/200000 (54.85%): 	Loss: 5.3236403465271	recon_loss: 0.0024322529789060354	bpp_loss: 4.593964576721191	aux_loss: 0.2197912484407425
20:07:25 INFO - main: Train iter. 109800/200000 (54.9%): 	Loss: 5.345526218414307	recon_loss: 0.0024648988619446754	bpp_loss: 4.6060566902160645	aux_loss: 0.59516441822052
20:07:57 INFO - main: Train iter. 109900/200000 (54.95%): 	Loss: 5.327897548675537	recon_loss: 0.002433474874123931	bpp_loss: 4.597855091094971	aux_loss: 0.36598193645477295
20:08:29 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 5.331175327301025	recon_loss: 0.0024418258108198643	bpp_loss: 4.59862756729126	aux_loss: 0.333553284406662
20:08:40 INFO - main: {'TEST MSE': 0.0024480236798916093, 'TEST BPP': 4.617109375, 'TEST loss': 5.336980247974396, 'TEST recon_loss': 0.0024480237578973175, 'TEST bpp_loss': 4.602573115825653}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
20:09:12 INFO - main: Train iter. 110100/200000 (55.05%): 	Loss: 5.335199356079102	recon_loss: 0.002430902561172843	bpp_loss: 4.605928421020508	aux_loss: 0.37341219186782837
20:09:44 INFO - main: Train iter. 110200/200000 (55.1%): 	Loss: 5.33984375	recon_loss: 0.0024608836974948645	bpp_loss: 4.601578712463379	aux_loss: 0.49946340918540955
20:10:15 INFO - main: Train iter. 110300/200000 (55.15%): 	Loss: 5.336396217346191	recon_loss: 0.0024411994963884354	bpp_loss: 4.604036331176758	aux_loss: 0.38740792870521545
20:10:47 INFO - main: Train iter. 110400/200000 (55.2%): 	Loss: 5.341279029846191	recon_loss: 0.002454226603731513	bpp_loss: 4.605010986328125	aux_loss: 0.6682952642440796
20:11:19 INFO - main: Train iter. 110500/200000 (55.25%): 	Loss: 5.3150529861450195	recon_loss: 0.0024374050553888083	bpp_loss: 4.583831310272217	aux_loss: 0.3382337689399719
20:11:51 INFO - main: Train iter. 110600/200000 (55.3%): 	Loss: 5.324261665344238	recon_loss: 0.0024388765450567007	bpp_loss: 4.592598915100098	aux_loss: 0.39441943168640137
20:12:23 INFO - main: Train iter. 110700/200000 (55.35%): 	Loss: 5.332437992095947	recon_loss: 0.002428262960165739	bpp_loss: 4.603959083557129	aux_loss: 0.4300299882888794
20:12:56 INFO - main: Train iter. 110800/200000 (55.4%): 	Loss: 5.327895641326904	recon_loss: 0.0024452346842736006	bpp_loss: 4.594325065612793	aux_loss: 0.6848422288894653
20:13:28 INFO - main: Train iter. 110900/200000 (55.45%): 	Loss: 5.340252876281738	recon_loss: 0.002438857452943921	bpp_loss: 4.608595848083496	aux_loss: 0.25341373682022095
20:13:59 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 5.3229780197143555	recon_loss: 0.002426696941256523	bpp_loss: 4.594968795776367	aux_loss: 0.6048118472099304
20:14:31 INFO - main: Train iter. 111100/200000 (55.55%): 	Loss: 5.334293365478516	recon_loss: 0.0024277318734675646	bpp_loss: 4.605973720550537	aux_loss: 0.7420579195022583
20:15:03 INFO - main: Train iter. 111200/200000 (55.6%): 	Loss: 5.329859733581543	recon_loss: 0.0024270161520689726	bpp_loss: 4.601754665374756	aux_loss: 0.20927461981773376
20:15:35 INFO - main: Train iter. 111300/200000 (55.65%): 	Loss: 5.32364559173584	recon_loss: 0.0024347153957933187	bpp_loss: 4.593231201171875	aux_loss: 0.6259968280792236
20:16:07 INFO - main: Train iter. 111400/200000 (55.7%): 	Loss: 5.306636333465576	recon_loss: 0.0024276464246213436	bpp_loss: 4.578342437744141	aux_loss: 0.43085330724716187
20:16:38 INFO - main: Train iter. 111500/200000 (55.75%): 	Loss: 5.325076580047607	recon_loss: 0.002433521207422018	bpp_loss: 4.595020294189453	aux_loss: 0.18931585550308228
20:17:10 INFO - main: Train iter. 111600/200000 (55.8%): 	Loss: 5.337630748748779	recon_loss: 0.0024298420175909996	bpp_loss: 4.608678340911865	aux_loss: 0.4698777496814728
20:17:42 INFO - main: Train iter. 111700/200000 (55.85%): 	Loss: 5.341300964355469	recon_loss: 0.0024327540304511786	bpp_loss: 4.611474514007568	aux_loss: 0.749885618686676
20:18:14 INFO - main: Train iter. 111800/200000 (55.9%): 	Loss: 5.312993049621582	recon_loss: 0.00242779403924942	bpp_loss: 4.584654808044434	aux_loss: 0.4233245849609375
20:18:46 INFO - main: Train iter. 111900/200000 (55.95%): 	Loss: 5.329699993133545	recon_loss: 0.0024301796220242977	bpp_loss: 4.600646018981934	aux_loss: 0.2457524538040161
20:19:17 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 5.327325820922852	recon_loss: 0.002434229478240013	bpp_loss: 4.597056865692139	aux_loss: 0.5773955583572388
20:19:51 INFO - main: Train iter. 112100/200000 (56.05%): 	Loss: 5.330084800720215	recon_loss: 0.002427837811410427	bpp_loss: 4.601733207702637	aux_loss: 0.8827590346336365
20:20:22 INFO - main: Train iter. 112200/200000 (56.1%): 	Loss: 5.31357479095459	recon_loss: 0.0024298327043652534	bpp_loss: 4.584625244140625	aux_loss: 0.2853027880191803
20:20:54 INFO - main: Train iter. 112300/200000 (56.15%): 	Loss: 5.331489562988281	recon_loss: 0.002435688627883792	bpp_loss: 4.600782871246338	aux_loss: 0.49632352590560913
20:21:26 INFO - main: Train iter. 112400/200000 (56.2%): 	Loss: 5.320484161376953	recon_loss: 0.002428792417049408	bpp_loss: 4.591846466064453	aux_loss: 0.31509843468666077
20:21:58 INFO - main: Train iter. 112500/200000 (56.25%): 	Loss: 5.326189041137695	recon_loss: 0.0024390157777816057	bpp_loss: 4.594484329223633	aux_loss: 0.17991849780082703
20:22:30 INFO - main: Train iter. 112600/200000 (56.3%): 	Loss: 5.330111503601074	recon_loss: 0.0024219099432229996	bpp_loss: 4.603538513183594	aux_loss: 0.3885161578655243
20:23:01 INFO - main: Train iter. 112700/200000 (56.35%): 	Loss: 5.333021640777588	recon_loss: 0.002435718197375536	bpp_loss: 4.602306365966797	aux_loss: 0.34806087613105774
20:23:33 INFO - main: Train iter. 112800/200000 (56.4%): 	Loss: 5.3285651206970215	recon_loss: 0.0024325603153556585	bpp_loss: 4.598796844482422	aux_loss: 0.2730388641357422
20:24:05 INFO - main: Train iter. 112900/200000 (56.45%): 	Loss: 5.323260307312012	recon_loss: 0.0024309728760272264	bpp_loss: 4.593968391418457	aux_loss: 0.2312634289264679
20:24:37 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 5.322412490844727	recon_loss: 0.002428271109238267	bpp_loss: 4.593931198120117	aux_loss: 0.2656521797180176
20:25:09 INFO - main: Train iter. 113100/200000 (56.55%): 	Loss: 5.3268208503723145	recon_loss: 0.002431080909445882	bpp_loss: 4.597496509552002	aux_loss: 1.1912569999694824
20:25:41 INFO - main: Train iter. 113200/200000 (56.6%): 	Loss: 5.329137325286865	recon_loss: 0.002436322160065174	bpp_loss: 4.598240852355957	aux_loss: 0.2253202497959137
20:26:13 INFO - main: Train iter. 113300/200000 (56.65%): 	Loss: 5.330323219299316	recon_loss: 0.0024356727954000235	bpp_loss: 4.599621295928955	aux_loss: 0.2649601697921753
20:26:45 INFO - main: Train iter. 113400/200000 (56.7%): 	Loss: 5.318403244018555	recon_loss: 0.002431662054732442	bpp_loss: 4.58890438079834	aux_loss: 0.26212310791015625
20:27:18 INFO - main: Train iter. 113500/200000 (56.75%): 	Loss: 5.3297014236450195	recon_loss: 0.002432948676869273	bpp_loss: 4.599816799163818	aux_loss: 0.31379300355911255
20:27:50 INFO - main: Train iter. 113600/200000 (56.8%): 	Loss: 5.326740264892578	recon_loss: 0.0024252147413790226	bpp_loss: 4.599175930023193	aux_loss: 0.48183494806289673
20:28:21 INFO - main: Train iter. 113700/200000 (56.85%): 	Loss: 5.336197376251221	recon_loss: 0.002438328694552183	bpp_loss: 4.604698657989502	aux_loss: 0.23551301658153534
20:28:53 INFO - main: Train iter. 113800/200000 (56.9%): 	Loss: 5.315297603607178	recon_loss: 0.0024318047799170017	bpp_loss: 4.585756301879883	aux_loss: 0.32025378942489624
20:29:25 INFO - main: Train iter. 113900/200000 (56.95%): 	Loss: 5.336372375488281	recon_loss: 0.00243067042902112	bpp_loss: 4.607171058654785	aux_loss: 0.5434452891349792
20:29:57 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 5.342865467071533	recon_loss: 0.0024248287081718445	bpp_loss: 4.615417003631592	aux_loss: 0.8307058215141296
20:30:29 INFO - main: Train iter. 114100/200000 (57.05%): 	Loss: 5.3309407234191895	recon_loss: 0.0024259283673018217	bpp_loss: 4.6031622886657715	aux_loss: 0.31661298871040344
20:31:01 INFO - main: Train iter. 114200/200000 (57.1%): 	Loss: 5.333414077758789	recon_loss: 0.002429328626021743	bpp_loss: 4.604615688323975	aux_loss: 0.29218822717666626
20:31:33 INFO - main: Train iter. 114300/200000 (57.15%): 	Loss: 5.324509143829346	recon_loss: 0.0024279591161757708	bpp_loss: 4.596121311187744	aux_loss: 0.4803839325904846
20:32:05 INFO - main: Train iter. 114400/200000 (57.2%): 	Loss: 5.326868057250977	recon_loss: 0.0024293819442391396	bpp_loss: 4.598053455352783	aux_loss: 0.43201035261154175
20:32:36 INFO - main: Train iter. 114500/200000 (57.25%): 	Loss: 5.319665431976318	recon_loss: 0.002427466446533799	bpp_loss: 4.59142541885376	aux_loss: 0.9378547072410583
20:33:08 INFO - main: Train iter. 114600/200000 (57.3%): 	Loss: 5.326292037963867	recon_loss: 0.0024288021959364414	bpp_loss: 4.597651481628418	aux_loss: 0.30952370166778564
20:33:40 INFO - main: Train iter. 114700/200000 (57.35%): 	Loss: 5.330799102783203	recon_loss: 0.002431051339954138	bpp_loss: 4.6014838218688965	aux_loss: 0.27911463379859924
20:34:12 INFO - main: Train iter. 114800/200000 (57.4%): 	Loss: 5.318892002105713	recon_loss: 0.0024268608540296555	bpp_loss: 4.59083366394043	aux_loss: 0.6553560495376587
20:34:45 INFO - main: Train iter. 114900/200000 (57.45%): 	Loss: 5.337498188018799	recon_loss: 0.002430584980174899	bpp_loss: 4.608322620391846	aux_loss: 0.21389296650886536
20:35:17 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 5.326588153839111	recon_loss: 0.0024312655441462994	bpp_loss: 4.597208499908447	aux_loss: 0.4627562165260315
20:35:28 INFO - main: {'TEST MSE': 0.002429313383068159, 'TEST BPP': 4.6165625, 'TEST loss': 5.33105483341217, 'TEST recon_loss': 0.0024293134657200426, 'TEST bpp_loss': 4.602260788917541}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
20:36:00 INFO - main: Train iter. 115100/200000 (57.55%): 	Loss: 5.330304145812988	recon_loss: 0.0024319745134562254	bpp_loss: 4.600711822509766	aux_loss: 0.5637837648391724
20:36:31 INFO - main: Train iter. 115200/200000 (57.6%): 	Loss: 5.318389892578125	recon_loss: 0.0024297907948493958	bpp_loss: 4.589452743530273	aux_loss: 1.529618501663208
20:37:03 INFO - main: Train iter. 115300/200000 (57.65%): 	Loss: 5.3272504806518555	recon_loss: 0.0024344802368432283	bpp_loss: 4.5969061851501465	aux_loss: 0.2352236807346344
20:37:35 INFO - main: Train iter. 115400/200000 (57.7%): 	Loss: 5.3299031257629395	recon_loss: 0.0024276752956211567	bpp_loss: 4.601600646972656	aux_loss: 0.2572561502456665
20:38:07 INFO - main: Train iter. 115500/200000 (57.75%): 	Loss: 5.3187575340271	recon_loss: 0.0024358374066650867	bpp_loss: 4.588006496429443	aux_loss: 0.2953973412513733
20:38:38 INFO - main: Train iter. 115600/200000 (57.8%): 	Loss: 5.3316731452941895	recon_loss: 0.0024375664070248604	bpp_loss: 4.600403308868408	aux_loss: 0.40500712394714355
20:39:10 INFO - main: Train iter. 115700/200000 (57.85%): 	Loss: 5.326272964477539	recon_loss: 0.0024273840244859457	bpp_loss: 4.598057746887207	aux_loss: 0.33915504813194275
20:39:42 INFO - main: Train iter. 115800/200000 (57.9%): 	Loss: 5.32973575592041	recon_loss: 0.0024269733112305403	bpp_loss: 4.6016435623168945	aux_loss: 0.3861517906188965
20:40:14 INFO - main: Train iter. 115900/200000 (57.95%): 	Loss: 5.32497501373291	recon_loss: 0.002430930035188794	bpp_loss: 4.595695972442627	aux_loss: 0.2101113498210907
20:40:46 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 5.313877105712891	recon_loss: 0.002431808039546013	bpp_loss: 4.584334850311279	aux_loss: 0.23458760976791382
20:41:17 INFO - main: Train iter. 116100/200000 (58.05%): 	Loss: 5.329184055328369	recon_loss: 0.0024262124206870794	bpp_loss: 4.601320266723633	aux_loss: 0.9929245710372925
20:41:50 INFO - main: Train iter. 116200/200000 (58.1%): 	Loss: 5.316289901733398	recon_loss: 0.00243001920171082	bpp_loss: 4.587284088134766	aux_loss: 0.5563657283782959
20:42:22 INFO - main: Train iter. 116300/200000 (58.15%): 	Loss: 5.332952976226807	recon_loss: 0.002431729109957814	bpp_loss: 4.603434085845947	aux_loss: 0.3492046892642975
20:42:54 INFO - main: Train iter. 116400/200000 (58.2%): 	Loss: 5.339418888092041	recon_loss: 0.0024334555491805077	bpp_loss: 4.609382152557373	aux_loss: 0.5521579384803772
20:43:26 INFO - main: Train iter. 116500/200000 (58.25%): 	Loss: 5.325664043426514	recon_loss: 0.0024301609955728054	bpp_loss: 4.596615791320801	aux_loss: 0.49288010597229004
20:43:58 INFO - main: Train iter. 116600/200000 (58.3%): 	Loss: 5.330385684967041	recon_loss: 0.0024279053322970867	bpp_loss: 4.602014064788818	aux_loss: 0.44448748230934143
20:44:30 INFO - main: Train iter. 116700/200000 (58.35%): 	Loss: 5.33352518081665	recon_loss: 0.002428819192573428	bpp_loss: 4.604879379272461	aux_loss: 0.3082171678543091
20:45:01 INFO - main: Train iter. 116800/200000 (58.4%): 	Loss: 5.346895694732666	recon_loss: 0.002427776111289859	bpp_loss: 4.618562698364258	aux_loss: 1.3362987041473389
20:45:33 INFO - main: Train iter. 116900/200000 (58.45%): 	Loss: 5.325078964233398	recon_loss: 0.002431684173643589	bpp_loss: 4.595573902130127	aux_loss: 0.2837424576282501
20:46:05 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 5.337302207946777	recon_loss: 0.0024380472023040056	bpp_loss: 4.6058878898620605	aux_loss: 0.5470989942550659
20:46:37 INFO - main: Train iter. 117100/200000 (58.55%): 	Loss: 5.3266520500183105	recon_loss: 0.0024331773165613413	bpp_loss: 4.596698760986328	aux_loss: 0.26773515343666077
20:47:09 INFO - main: Train iter. 117200/200000 (58.6%): 	Loss: 5.333112716674805	recon_loss: 0.002433095360174775	bpp_loss: 4.603184223175049	aux_loss: 0.6439772248268127
20:47:41 INFO - main: Train iter. 117300/200000 (58.65%): 	Loss: 5.319821834564209	recon_loss: 0.0024265118408948183	bpp_loss: 4.5918684005737305	aux_loss: 0.9753333926200867
20:48:13 INFO - main: Train iter. 117400/200000 (58.7%): 	Loss: 5.3323845863342285	recon_loss: 0.002433272311463952	bpp_loss: 4.602402687072754	aux_loss: 0.2182358354330063
20:48:44 INFO - main: Train iter. 117500/200000 (58.75%): 	Loss: 5.328441143035889	recon_loss: 0.002432179404422641	bpp_loss: 4.598787307739258	aux_loss: 0.6742802262306213
20:49:18 INFO - main: Train iter. 117600/200000 (58.8%): 	Loss: 5.327014446258545	recon_loss: 0.002431659260764718	bpp_loss: 4.5975165367126465	aux_loss: 1.3167803287506104
20:49:50 INFO - main: Train iter. 117700/200000 (58.85%): 	Loss: 5.326373100280762	recon_loss: 0.0024242657236754894	bpp_loss: 4.599093437194824	aux_loss: 1.0596510171890259
20:50:21 INFO - main: Train iter. 117800/200000 (58.9%): 	Loss: 5.328304290771484	recon_loss: 0.0024274231400340796	bpp_loss: 4.600077152252197	aux_loss: 0.5720338821411133
20:50:53 INFO - main: Train iter. 117900/200000 (58.95%): 	Loss: 5.338895797729492	recon_loss: 0.002431970089673996	bpp_loss: 4.609304904937744	aux_loss: 0.3291195333003998
20:51:25 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 5.317905426025391	recon_loss: 0.0024337340146303177	bpp_loss: 4.587785243988037	aux_loss: 0.5066701769828796
20:51:57 INFO - main: Train iter. 118100/200000 (59.05%): 	Loss: 5.331912994384766	recon_loss: 0.0024277742486447096	bpp_loss: 4.603580474853516	aux_loss: 0.28412380814552307
20:52:28 INFO - main: Train iter. 118200/200000 (59.1%): 	Loss: 5.333799362182617	recon_loss: 0.0024288087151944637	bpp_loss: 4.605156898498535	aux_loss: 0.6719211339950562
20:53:00 INFO - main: Train iter. 118300/200000 (59.15%): 	Loss: 5.31885290145874	recon_loss: 0.0024270834401249886	bpp_loss: 4.590727806091309	aux_loss: 0.34826916456222534
20:53:32 INFO - main: Train iter. 118400/200000 (59.2%): 	Loss: 5.319327354431152	recon_loss: 0.0024298911448568106	bpp_loss: 4.590360164642334	aux_loss: 0.338631272315979
20:54:04 INFO - main: Train iter. 118500/200000 (59.25%): 	Loss: 5.3294358253479	recon_loss: 0.002431577304378152	bpp_loss: 4.5999627113342285	aux_loss: 0.30578625202178955
20:54:36 INFO - main: Train iter. 118600/200000 (59.3%): 	Loss: 5.347196578979492	recon_loss: 0.002435809699818492	bpp_loss: 4.616453647613525	aux_loss: 0.7010105848312378
20:55:08 INFO - main: Train iter. 118700/200000 (59.35%): 	Loss: 5.334316730499268	recon_loss: 0.002435550559312105	bpp_loss: 4.603651523590088	aux_loss: 0.8270969390869141
20:55:40 INFO - main: Train iter. 118800/200000 (59.4%): 	Loss: 5.325142860412598	recon_loss: 0.0024361934047192335	bpp_loss: 4.594285011291504	aux_loss: 0.5304325819015503
20:56:11 INFO - main: Train iter. 118900/200000 (59.45%): 	Loss: 5.329862117767334	recon_loss: 0.0024418141692876816	bpp_loss: 4.597317695617676	aux_loss: 0.2837904095649719
20:56:45 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 5.325808525085449	recon_loss: 0.0024268480483442545	bpp_loss: 4.597754001617432	aux_loss: 0.3266954720020294
20:57:16 INFO - main: Train iter. 119100/200000 (59.55%): 	Loss: 5.331647872924805	recon_loss: 0.002446542028337717	bpp_loss: 4.59768533706665	aux_loss: 0.6598912477493286
20:57:48 INFO - main: Train iter. 119200/200000 (59.6%): 	Loss: 5.323322296142578	recon_loss: 0.0024329510051757097	bpp_loss: 4.593437194824219	aux_loss: 0.3952683210372925
20:58:20 INFO - main: Train iter. 119300/200000 (59.65%): 	Loss: 5.338057041168213	recon_loss: 0.00243670167401433	bpp_loss: 4.607046604156494	aux_loss: 0.7091779112815857
20:58:52 INFO - main: Train iter. 119400/200000 (59.7%): 	Loss: 5.325881004333496	recon_loss: 0.002429017098620534	bpp_loss: 4.5971760749816895	aux_loss: 0.47504734992980957
20:59:24 INFO - main: Train iter. 119500/200000 (59.75%): 	Loss: 5.330843925476074	recon_loss: 0.0024341936223208904	bpp_loss: 4.6005859375	aux_loss: 0.4048110842704773
20:59:55 INFO - main: Train iter. 119600/200000 (59.8%): 	Loss: 5.332221508026123	recon_loss: 0.002432462526485324	bpp_loss: 4.602482795715332	aux_loss: 0.5626798868179321
21:00:27 INFO - main: Train iter. 119700/200000 (59.85%): 	Loss: 5.3539228439331055	recon_loss: 0.00246417592279613	bpp_loss: 4.6146697998046875	aux_loss: 0.32769352197647095
21:00:59 INFO - main: Train iter. 119800/200000 (59.9%): 	Loss: 5.328625679016113	recon_loss: 0.0024321074597537518	bpp_loss: 4.598993301391602	aux_loss: 0.29486268758773804
21:01:31 INFO - main: Train iter. 119900/200000 (59.95%): 	Loss: 5.338197231292725	recon_loss: 0.0024437077809125185	bpp_loss: 4.6050848960876465	aux_loss: 0.3457960784435272
21:02:02 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 5.326626777648926	recon_loss: 0.0024337919894605875	bpp_loss: 4.596489429473877	aux_loss: 0.6883195638656616
21:02:13 INFO - main: {'TEST MSE': 0.002428646381743516, 'TEST BPP': 4.6177421875, 'TEST loss': 5.332329689025879, 'TEST recon_loss': 0.002428646462736651, 'TEST bpp_loss': 4.603735751628876}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
21:02:45 INFO - main: Train iter. 120100/200000 (60.05%): 	Loss: 5.34247350692749	recon_loss: 0.0024499327410012484	bpp_loss: 4.607493877410889	aux_loss: 0.853152871131897
21:03:17 INFO - main: Train iter. 120200/200000 (60.1%): 	Loss: 5.330777645111084	recon_loss: 0.002470214618369937	bpp_loss: 4.589713096618652	aux_loss: 0.8572441935539246
21:03:50 INFO - main: Train iter. 120300/200000 (60.15%): 	Loss: 5.3336100578308105	recon_loss: 0.002463630633428693	bpp_loss: 4.5945210456848145	aux_loss: 0.6027684211730957
21:04:21 INFO - main: Train iter. 120400/200000 (60.2%): 	Loss: 5.34001350402832	recon_loss: 0.0024305307306349277	bpp_loss: 4.610854148864746	aux_loss: 0.49893611669540405
21:04:53 INFO - main: Train iter. 120500/200000 (60.25%): 	Loss: 5.3362298011779785	recon_loss: 0.0024377950467169285	bpp_loss: 4.604891300201416	aux_loss: 0.6918559074401855
21:05:25 INFO - main: Train iter. 120600/200000 (60.3%): 	Loss: 5.326412677764893	recon_loss: 0.0024380162358283997	bpp_loss: 4.59500789642334	aux_loss: 0.30743786692619324
21:05:57 INFO - main: Train iter. 120700/200000 (60.35%): 	Loss: 5.320521354675293	recon_loss: 0.0024342609103769064	bpp_loss: 4.590242862701416	aux_loss: 0.7571112513542175
21:06:29 INFO - main: Train iter. 120800/200000 (60.4%): 	Loss: 5.337364673614502	recon_loss: 0.002436071401461959	bpp_loss: 4.606543064117432	aux_loss: 0.729893147945404
21:07:00 INFO - main: Train iter. 120900/200000 (60.45%): 	Loss: 5.328327655792236	recon_loss: 0.002440238604322076	bpp_loss: 4.596256256103516	aux_loss: 0.5138363242149353
21:07:32 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 5.330397605895996	recon_loss: 0.0024330883752554655	bpp_loss: 4.600471019744873	aux_loss: 0.9674889445304871
21:08:04 INFO - main: Train iter. 121100/200000 (60.55%): 	Loss: 5.327114105224609	recon_loss: 0.0024438609834760427	bpp_loss: 4.593955993652344	aux_loss: 0.1858719289302826
21:08:36 INFO - main: Train iter. 121200/200000 (60.6%): 	Loss: 5.330806255340576	recon_loss: 0.0024341123644262552	bpp_loss: 4.60057258605957	aux_loss: 0.27110612392425537
21:09:08 INFO - main: Train iter. 121300/200000 (60.65%): 	Loss: 5.320075511932373	recon_loss: 0.002428829437121749	bpp_loss: 4.591426849365234	aux_loss: 0.4671669006347656
21:09:40 INFO - main: Train iter. 121400/200000 (60.7%): 	Loss: 5.340592384338379	recon_loss: 0.0024377903901040554	bpp_loss: 4.609255313873291	aux_loss: 0.5107664465904236
21:10:11 INFO - main: Train iter. 121500/200000 (60.75%): 	Loss: 5.333551406860352	recon_loss: 0.0024268911220133305	bpp_loss: 4.6054840087890625	aux_loss: 0.25226569175720215
21:10:43 INFO - main: Train iter. 121600/200000 (60.8%): 	Loss: 5.323687553405762	recon_loss: 0.002426812658086419	bpp_loss: 4.595643997192383	aux_loss: 0.2221655249595642
21:11:16 INFO - main: Train iter. 121700/200000 (60.85%): 	Loss: 5.328661918640137	recon_loss: 0.002431250410154462	bpp_loss: 4.599287033081055	aux_loss: 0.7449257373809814
21:11:48 INFO - main: Train iter. 121800/200000 (60.9%): 	Loss: 5.3361005783081055	recon_loss: 0.002434492576867342	bpp_loss: 4.605752944946289	aux_loss: 0.4465397596359253
21:12:20 INFO - main: Train iter. 121900/200000 (60.95%): 	Loss: 5.3213725090026855	recon_loss: 0.002430977998301387	bpp_loss: 4.592079162597656	aux_loss: 0.38041773438453674
21:12:52 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 5.333289623260498	recon_loss: 0.002428434556350112	bpp_loss: 4.604759216308594	aux_loss: 0.3424348533153534
21:13:24 INFO - main: Train iter. 122100/200000 (61.05%): 	Loss: 5.327069282531738	recon_loss: 0.002425983315333724	bpp_loss: 4.599274158477783	aux_loss: 0.31306153535842896
21:13:55 INFO - main: Train iter. 122200/200000 (61.1%): 	Loss: 5.326269149780273	recon_loss: 0.002439461648464203	bpp_loss: 4.594430923461914	aux_loss: 0.6486178040504456
21:14:27 INFO - main: Train iter. 122300/200000 (61.15%): 	Loss: 5.336311340332031	recon_loss: 0.002440658863633871	bpp_loss: 4.604113578796387	aux_loss: 0.5884585380554199
21:14:59 INFO - main: Train iter. 122400/200000 (61.2%): 	Loss: 5.339967727661133	recon_loss: 0.0024309069849550724	bpp_loss: 4.610695838928223	aux_loss: 0.3282025456428528
21:15:31 INFO - main: Train iter. 122500/200000 (61.25%): 	Loss: 5.334722995758057	recon_loss: 0.0024494987446814775	bpp_loss: 4.5998735427856445	aux_loss: 0.4705045223236084
21:16:03 INFO - main: Train iter. 122600/200000 (61.3%): 	Loss: 5.328072547912598	recon_loss: 0.0024304096587002277	bpp_loss: 4.598949432373047	aux_loss: 0.787474513053894
21:16:34 INFO - main: Train iter. 122700/200000 (61.35%): 	Loss: 5.325211524963379	recon_loss: 0.002426993800327182	bpp_loss: 4.597113609313965	aux_loss: 0.47413116693496704
21:17:06 INFO - main: Train iter. 122800/200000 (61.4%): 	Loss: 5.3296918869018555	recon_loss: 0.0024314236361533403	bpp_loss: 4.600265026092529	aux_loss: 0.5996053218841553
21:17:38 INFO - main: Train iter. 122900/200000 (61.45%): 	Loss: 5.314508438110352	recon_loss: 0.002431014087051153	bpp_loss: 4.585204124450684	aux_loss: 0.4704490900039673
21:18:10 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 5.328030109405518	recon_loss: 0.002436848822981119	bpp_loss: 4.596975326538086	aux_loss: 0.6096634268760681
21:18:43 INFO - main: Train iter. 123100/200000 (61.55%): 	Loss: 5.323392391204834	recon_loss: 0.002428807085379958	bpp_loss: 4.59475040435791	aux_loss: 0.2813470959663391
21:19:15 INFO - main: Train iter. 123200/200000 (61.6%): 	Loss: 5.325568675994873	recon_loss: 0.002433804562315345	bpp_loss: 4.595427513122559	aux_loss: 0.2985658645629883
21:19:47 INFO - main: Train iter. 123300/200000 (61.65%): 	Loss: 5.340764045715332	recon_loss: 0.002436336362734437	bpp_loss: 4.60986328125	aux_loss: 0.8027557134628296
21:20:18 INFO - main: Train iter. 123400/200000 (61.7%): 	Loss: 5.329043865203857	recon_loss: 0.002438534749671817	bpp_loss: 4.5974836349487305	aux_loss: 1.102609634399414
21:20:50 INFO - main: Train iter. 123500/200000 (61.75%): 	Loss: 5.327092170715332	recon_loss: 0.0024332592729479074	bpp_loss: 4.597114562988281	aux_loss: 0.27768847346305847
21:21:22 INFO - main: Train iter. 123600/200000 (61.8%): 	Loss: 5.324263572692871	recon_loss: 0.0024327971041202545	bpp_loss: 4.594424247741699	aux_loss: 0.2551233172416687
21:21:54 INFO - main: Train iter. 123700/200000 (61.85%): 	Loss: 5.330206871032715	recon_loss: 0.002433501649647951	bpp_loss: 4.600156307220459	aux_loss: 0.3285599946975708
21:22:26 INFO - main: Train iter. 123800/200000 (61.9%): 	Loss: 5.326179504394531	recon_loss: 0.0024275456089526415	bpp_loss: 4.5979156494140625	aux_loss: 0.2229514718055725
21:22:57 INFO - main: Train iter. 123900/200000 (61.95%): 	Loss: 5.327634334564209	recon_loss: 0.0024340632371604443	bpp_loss: 4.597415447235107	aux_loss: 0.5342745184898376
21:23:29 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 5.326976299285889	recon_loss: 0.0024378171656280756	bpp_loss: 4.595631122589111	aux_loss: 0.5022348165512085
21:24:01 INFO - main: Train iter. 124100/200000 (62.05%): 	Loss: 5.320713043212891	recon_loss: 0.0024248389527201653	bpp_loss: 4.593261241912842	aux_loss: 0.32823270559310913
21:24:33 INFO - main: Train iter. 124200/200000 (62.1%): 	Loss: 5.330877304077148	recon_loss: 0.0024350713938474655	bpp_loss: 4.600355625152588	aux_loss: 0.7027220726013184
21:25:05 INFO - main: Train iter. 124300/200000 (62.15%): 	Loss: 5.333461761474609	recon_loss: 0.0024329510051757097	bpp_loss: 4.60357666015625	aux_loss: 0.2279038429260254
21:25:38 INFO - main: Train iter. 124400/200000 (62.2%): 	Loss: 5.323009014129639	recon_loss: 0.0024275099858641624	bpp_loss: 4.594756126403809	aux_loss: 0.3041854500770569
21:26:10 INFO - main: Train iter. 124500/200000 (62.25%): 	Loss: 5.3236799240112305	recon_loss: 0.00242645014077425	bpp_loss: 4.595745086669922	aux_loss: 1.3475849628448486
21:26:41 INFO - main: Train iter. 124600/200000 (62.3%): 	Loss: 5.33200740814209	recon_loss: 0.0024274266324937344	bpp_loss: 4.603779315948486	aux_loss: 0.5456632375717163
21:27:13 INFO - main: Train iter. 124700/200000 (62.35%): 	Loss: 5.322383403778076	recon_loss: 0.0024273230228573084	bpp_loss: 4.594186305999756	aux_loss: 0.23636619746685028
21:27:45 INFO - main: Train iter. 124800/200000 (62.4%): 	Loss: 5.334390163421631	recon_loss: 0.0024409375619143248	bpp_loss: 4.602108955383301	aux_loss: 0.4101661145687103
21:28:17 INFO - main: Train iter. 124900/200000 (62.45%): 	Loss: 5.3300557136535645	recon_loss: 0.002433486981317401	bpp_loss: 4.600009441375732	aux_loss: 0.5910029411315918
21:28:49 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 5.335771083831787	recon_loss: 0.0024296806659549475	bpp_loss: 4.606866836547852	aux_loss: 0.5555539131164551
21:29:00 INFO - main: {'TEST MSE': 0.002430408574901828, 'TEST BPP': 4.6174765625, 'TEST loss': 5.332501095771789, 'TEST recon_loss': 0.002430408657062799, 'TEST bpp_loss': 4.603378501415253}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
21:29:31 INFO - main: Train iter. 125100/200000 (62.55%): 	Loss: 5.345393657684326	recon_loss: 0.0024549018125981092	bpp_loss: 4.608922958374023	aux_loss: 0.37007051706314087
21:30:03 INFO - main: Train iter. 125200/200000 (62.6%): 	Loss: 5.33469820022583	recon_loss: 0.002432567300274968	bpp_loss: 4.604928016662598	aux_loss: 0.255959153175354
21:30:35 INFO - main: Train iter. 125300/200000 (62.65%): 	Loss: 5.342390537261963	recon_loss: 0.0024338942021131516	bpp_loss: 4.612222194671631	aux_loss: 0.2938478887081146
21:31:07 INFO - main: Train iter. 125400/200000 (62.7%): 	Loss: 5.313724994659424	recon_loss: 0.0024265553802251816	bpp_loss: 4.585758209228516	aux_loss: 0.27079683542251587
21:31:39 INFO - main: Train iter. 125500/200000 (62.75%): 	Loss: 5.33250617980957	recon_loss: 0.0024520994629710913	bpp_loss: 4.59687614440918	aux_loss: 0.2706673741340637
21:32:10 INFO - main: Train iter. 125600/200000 (62.8%): 	Loss: 5.3263325691223145	recon_loss: 0.0024379375390708447	bpp_loss: 4.594951152801514	aux_loss: 0.2631545066833496
21:32:42 INFO - main: Train iter. 125700/200000 (62.85%): 	Loss: 5.323205471038818	recon_loss: 0.002439215313643217	bpp_loss: 4.591440677642822	aux_loss: 0.3053753972053528
21:33:15 INFO - main: Train iter. 125800/200000 (62.9%): 	Loss: 5.339666366577148	recon_loss: 0.0024386525619775057	bpp_loss: 4.6080708503723145	aux_loss: 0.6618087887763977
21:33:47 INFO - main: Train iter. 125900/200000 (62.95%): 	Loss: 5.328402042388916	recon_loss: 0.00243925373069942	bpp_loss: 4.596625804901123	aux_loss: 0.6533739566802979
21:34:19 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 5.314780235290527	recon_loss: 0.002435790840536356	bpp_loss: 4.584043025970459	aux_loss: 0.2725602388381958
21:34:51 INFO - main: Train iter. 126100/200000 (63.05%): 	Loss: 5.328319549560547	recon_loss: 0.002441572258248925	bpp_loss: 4.595848083496094	aux_loss: 0.32881730794906616
21:35:23 INFO - main: Train iter. 126200/200000 (63.1%): 	Loss: 5.332251071929932	recon_loss: 0.0024365263525396585	bpp_loss: 4.601293087005615	aux_loss: 0.9068595170974731
21:35:55 INFO - main: Train iter. 126300/200000 (63.15%): 	Loss: 5.337608337402344	recon_loss: 0.0024360755924135447	bpp_loss: 4.606785774230957	aux_loss: 0.5458303093910217
21:36:27 INFO - main: Train iter. 126400/200000 (63.2%): 	Loss: 5.321025848388672	recon_loss: 0.002430833177641034	bpp_loss: 4.591775894165039	aux_loss: 1.0168615579605103
21:36:58 INFO - main: Train iter. 126500/200000 (63.25%): 	Loss: 5.334896087646484	recon_loss: 0.002431169617921114	bpp_loss: 4.6055450439453125	aux_loss: 0.4125972390174866
21:37:30 INFO - main: Train iter. 126600/200000 (63.3%): 	Loss: 5.327339172363281	recon_loss: 0.0024516868870705366	bpp_loss: 4.591833114624023	aux_loss: 0.20928210020065308
21:38:02 INFO - main: Train iter. 126700/200000 (63.35%): 	Loss: 5.324948310852051	recon_loss: 0.002434407826513052	bpp_loss: 4.594625949859619	aux_loss: 1.9467272758483887
21:38:34 INFO - main: Train iter. 126800/200000 (63.4%): 	Loss: 5.336022853851318	recon_loss: 0.002446807688102126	bpp_loss: 4.601980686187744	aux_loss: 0.3660508990287781
21:39:06 INFO - main: Train iter. 126900/200000 (63.45%): 	Loss: 5.318078517913818	recon_loss: 0.0024380197282880545	bpp_loss: 4.586672782897949	aux_loss: 0.6844322681427002
21:39:37 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 5.333096027374268	recon_loss: 0.002437714021652937	bpp_loss: 4.601781845092773	aux_loss: 0.6422235369682312
21:40:09 INFO - main: Train iter. 127100/200000 (63.55%): 	Loss: 5.324775695800781	recon_loss: 0.0024364241398870945	bpp_loss: 4.593848705291748	aux_loss: 0.7753983736038208
21:40:42 INFO - main: Train iter. 127200/200000 (63.6%): 	Loss: 5.3224992752075195	recon_loss: 0.002447689650580287	bpp_loss: 4.588192462921143	aux_loss: 0.6595745086669922
21:41:14 INFO - main: Train iter. 127300/200000 (63.65%): 	Loss: 5.33712100982666	recon_loss: 0.0024348744191229343	bpp_loss: 4.606658935546875	aux_loss: 0.6022516489028931
21:41:46 INFO - main: Train iter. 127400/200000 (63.7%): 	Loss: 5.340327739715576	recon_loss: 0.0024309202563017607	bpp_loss: 4.611051559448242	aux_loss: 0.31841224431991577
21:42:18 INFO - main: Train iter. 127500/200000 (63.75%): 	Loss: 5.323244571685791	recon_loss: 0.0024332304019480944	bpp_loss: 4.593275547027588	aux_loss: 0.21971037983894348
21:42:49 INFO - main: Train iter. 127600/200000 (63.8%): 	Loss: 5.327007293701172	recon_loss: 0.002426993800327182	bpp_loss: 4.5989089012146	aux_loss: 0.3675522208213806
21:43:21 INFO - main: Train iter. 127700/200000 (63.85%): 	Loss: 5.329620838165283	recon_loss: 0.002442497992888093	bpp_loss: 4.596871376037598	aux_loss: 0.27134230732917786
21:43:53 INFO - main: Train iter. 127800/200000 (63.9%): 	Loss: 5.321901798248291	recon_loss: 0.0024302578531205654	bpp_loss: 4.592824459075928	aux_loss: 0.7784245014190674
21:44:25 INFO - main: Train iter. 127900/200000 (63.95%): 	Loss: 5.338486671447754	recon_loss: 0.002448242623358965	bpp_loss: 4.604013919830322	aux_loss: 0.6633387804031372
21:44:56 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 5.330267429351807	recon_loss: 0.002449468243867159	bpp_loss: 4.5954270362854	aux_loss: 1.444105625152588
21:45:28 INFO - main: Train iter. 128100/200000 (64.05%): 	Loss: 5.324952602386475	recon_loss: 0.0024412062484771013	bpp_loss: 4.592590808868408	aux_loss: 0.41790086030960083
21:46:00 INFO - main: Train iter. 128200/200000 (64.1%): 	Loss: 5.337835788726807	recon_loss: 0.002459094161167741	bpp_loss: 4.600107669830322	aux_loss: 0.5534873604774475
21:46:32 INFO - main: Train iter. 128300/200000 (64.15%): 	Loss: 5.328321933746338	recon_loss: 0.0024343535769730806	bpp_loss: 4.598015785217285	aux_loss: 0.4023186266422272
21:47:03 INFO - main: Train iter. 128400/200000 (64.2%): 	Loss: 5.344094276428223	recon_loss: 0.002434168942272663	bpp_loss: 4.6138434410095215	aux_loss: 0.21608199179172516
21:47:37 INFO - main: Train iter. 128500/200000 (64.25%): 	Loss: 5.327406406402588	recon_loss: 0.0024439727421849966	bpp_loss: 4.59421443939209	aux_loss: 0.4122219979763031
21:48:08 INFO - main: Train iter. 128600/200000 (64.3%): 	Loss: 5.339195728302002	recon_loss: 0.002436985494568944	bpp_loss: 4.608099937438965	aux_loss: 0.4027152359485626
21:48:40 INFO - main: Train iter. 128700/200000 (64.35%): 	Loss: 5.32280158996582	recon_loss: 0.002434407826513052	bpp_loss: 4.592479228973389	aux_loss: 0.24283470213413239
21:49:12 INFO - main: Train iter. 128800/200000 (64.4%): 	Loss: 5.327876091003418	recon_loss: 0.002434484427794814	bpp_loss: 4.597530841827393	aux_loss: 0.20670360326766968
21:49:44 INFO - main: Train iter. 128900/200000 (64.45%): 	Loss: 5.332772731781006	recon_loss: 0.002440396696329117	bpp_loss: 4.600653648376465	aux_loss: 0.2660525441169739
21:50:15 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 5.321393013000488	recon_loss: 0.002430686494335532	bpp_loss: 4.59218692779541	aux_loss: 0.6003684997558594
21:50:47 INFO - main: Train iter. 129100/200000 (64.55%): 	Loss: 5.337757587432861	recon_loss: 0.002433262998238206	bpp_loss: 4.607778549194336	aux_loss: 0.5498426556587219
21:51:19 INFO - main: Train iter. 129200/200000 (64.6%): 	Loss: 5.321306228637695	recon_loss: 0.0024323787074536085	bpp_loss: 4.591592788696289	aux_loss: 0.331570565700531
21:51:51 INFO - main: Train iter. 129300/200000 (64.65%): 	Loss: 5.336831092834473	recon_loss: 0.0024408067110925913	bpp_loss: 4.604588985443115	aux_loss: 1.149885654449463
21:52:23 INFO - main: Train iter. 129400/200000 (64.7%): 	Loss: 5.317533493041992	recon_loss: 0.0024392236955463886	bpp_loss: 4.585766315460205	aux_loss: 0.8178988099098206
21:52:54 INFO - main: Train iter. 129500/200000 (64.75%): 	Loss: 5.3374552726745605	recon_loss: 0.002438349649310112	bpp_loss: 4.605950355529785	aux_loss: 0.5768203735351562
21:53:26 INFO - main: Train iter. 129600/200000 (64.8%): 	Loss: 5.351878643035889	recon_loss: 0.002439281437546015	bpp_loss: 4.620094299316406	aux_loss: 0.8012577295303345
21:53:58 INFO - main: Train iter. 129700/200000 (64.85%): 	Loss: 5.330562591552734	recon_loss: 0.002440491458401084	bpp_loss: 4.598414897918701	aux_loss: 1.067840337753296
21:54:30 INFO - main: Train iter. 129800/200000 (64.9%): 	Loss: 5.332942008972168	recon_loss: 0.002430918160825968	bpp_loss: 4.60366678237915	aux_loss: 2.0042777061462402
21:55:03 INFO - main: Train iter. 129900/200000 (64.95%): 	Loss: 5.323397636413574	recon_loss: 0.002427908591926098	bpp_loss: 4.595025062561035	aux_loss: 0.6818317174911499
21:55:35 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 5.32451057434082	recon_loss: 0.0024276557378470898	bpp_loss: 4.5962138175964355	aux_loss: 0.7533522844314575
21:55:46 INFO - main: {'TEST MSE': 0.0024293341635443387, 'TEST BPP': 4.61634375, 'TEST loss': 5.330602823257446, 'TEST recon_loss': 0.0024293342421296982, 'TEST bpp_loss': 4.601802553653717}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
21:56:18 INFO - main: Train iter. 130100/200000 (65.05%): 	Loss: 5.333712100982666	recon_loss: 0.0024458481930196285	bpp_loss: 4.599957466125488	aux_loss: 0.8614320158958435
21:56:50 INFO - main: Train iter. 130200/200000 (65.1%): 	Loss: 5.317014694213867	recon_loss: 0.002433078596368432	bpp_loss: 4.587090969085693	aux_loss: 0.28959453105926514
21:57:21 INFO - main: Train iter. 130300/200000 (65.15%): 	Loss: 5.334810256958008	recon_loss: 0.0024415215011686087	bpp_loss: 4.602354049682617	aux_loss: 0.5535438060760498
21:57:53 INFO - main: Train iter. 130400/200000 (65.2%): 	Loss: 5.331120491027832	recon_loss: 0.0024488784838467836	bpp_loss: 4.596457004547119	aux_loss: 0.42205676436424255
21:58:25 INFO - main: Train iter. 130500/200000 (65.25%): 	Loss: 5.332253932952881	recon_loss: 0.0024373079650104046	bpp_loss: 4.6010613441467285	aux_loss: 0.42287546396255493
21:58:57 INFO - main: Train iter. 130600/200000 (65.3%): 	Loss: 5.33900785446167	recon_loss: 0.002433302579447627	bpp_loss: 4.6090168952941895	aux_loss: 0.3198222219944
21:59:29 INFO - main: Train iter. 130700/200000 (65.35%): 	Loss: 5.337274074554443	recon_loss: 0.0024521569721400738	bpp_loss: 4.601626873016357	aux_loss: 0.7278047800064087
22:00:00 INFO - main: Train iter. 130800/200000 (65.4%): 	Loss: 5.334763050079346	recon_loss: 0.002441251650452614	bpp_loss: 4.602387428283691	aux_loss: 0.3620750308036804
22:00:32 INFO - main: Train iter. 130900/200000 (65.45%): 	Loss: 5.3254899978637695	recon_loss: 0.0024441059213131666	bpp_loss: 4.592257976531982	aux_loss: 0.3850473165512085
22:01:04 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 5.337391376495361	recon_loss: 0.0024447764735668898	bpp_loss: 4.603958606719971	aux_loss: 0.4117003083229065
22:01:36 INFO - main: Train iter. 131100/200000 (65.55%): 	Loss: 5.336152076721191	recon_loss: 0.0024402355775237083	bpp_loss: 4.604081630706787	aux_loss: 0.5015320777893066
22:02:08 INFO - main: Train iter. 131200/200000 (65.6%): 	Loss: 5.325181484222412	recon_loss: 0.0024344990961253643	bpp_loss: 4.594831943511963	aux_loss: 0.4715559184551239
22:02:41 INFO - main: Train iter. 131300/200000 (65.65%): 	Loss: 5.325145721435547	recon_loss: 0.0024250787682831287	bpp_loss: 4.597621917724609	aux_loss: 0.40954652428627014
22:03:13 INFO - main: Train iter. 131400/200000 (65.7%): 	Loss: 5.3274078369140625	recon_loss: 0.0024368935264647007	bpp_loss: 4.596339702606201	aux_loss: 0.543066143989563
22:03:45 INFO - main: Train iter. 131500/200000 (65.75%): 	Loss: 5.318664073944092	recon_loss: 0.0024176372680813074	bpp_loss: 4.593372821807861	aux_loss: 0.5574395656585693
22:04:17 INFO - main: Train iter. 131600/200000 (65.8%): 	Loss: 5.339695930480957	recon_loss: 0.0024548072833567858	bpp_loss: 4.6032538414001465	aux_loss: 1.5300616025924683
22:04:48 INFO - main: Train iter. 131700/200000 (65.85%): 	Loss: 5.340327262878418	recon_loss: 0.0024572478141635656	bpp_loss: 4.603152751922607	aux_loss: 0.9651541709899902
22:05:20 INFO - main: Train iter. 131800/200000 (65.9%): 	Loss: 5.328509330749512	recon_loss: 0.002449613530188799	bpp_loss: 4.593625068664551	aux_loss: 0.49180570244789124
22:05:52 INFO - main: Train iter. 131900/200000 (65.95%): 	Loss: 5.332848072052002	recon_loss: 0.0024407722521573305	bpp_loss: 4.600616455078125	aux_loss: 0.6220411062240601
22:06:24 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 5.329101085662842	recon_loss: 0.002447444014251232	bpp_loss: 4.594867706298828	aux_loss: 0.5736104249954224
22:06:56 INFO - main: Train iter. 132100/200000 (66.05%): 	Loss: 5.329643249511719	recon_loss: 0.002439250238239765	bpp_loss: 4.597867965698242	aux_loss: 0.29845285415649414
22:07:28 INFO - main: Train iter. 132200/200000 (66.1%): 	Loss: 5.333536148071289	recon_loss: 0.002430995926260948	bpp_loss: 4.6042375564575195	aux_loss: 0.32371723651885986
22:07:59 INFO - main: Train iter. 132300/200000 (66.15%): 	Loss: 5.332078456878662	recon_loss: 0.002433267654851079	bpp_loss: 4.602097988128662	aux_loss: 0.3623412549495697
22:08:31 INFO - main: Train iter. 132400/200000 (66.2%): 	Loss: 5.339521884918213	recon_loss: 0.002432934008538723	bpp_loss: 4.6096415519714355	aux_loss: 0.4030506908893585
22:09:03 INFO - main: Train iter. 132500/200000 (66.25%): 	Loss: 5.324501037597656	recon_loss: 0.0024380378890782595	bpp_loss: 4.593089580535889	aux_loss: 0.381486713886261
22:09:36 INFO - main: Train iter. 132600/200000 (66.3%): 	Loss: 5.3372344970703125	recon_loss: 0.002433244837448001	bpp_loss: 4.6072611808776855	aux_loss: 0.5034226179122925
22:10:08 INFO - main: Train iter. 132700/200000 (66.35%): 	Loss: 5.328812599182129	recon_loss: 0.0024259949568659067	bpp_loss: 4.601014137268066	aux_loss: 0.46168869733810425
22:10:40 INFO - main: Train iter. 132800/200000 (66.4%): 	Loss: 5.332027435302734	recon_loss: 0.0024343833792954683	bpp_loss: 4.601712226867676	aux_loss: 1.1277377605438232
22:11:11 INFO - main: Train iter. 132900/200000 (66.45%): 	Loss: 5.329050540924072	recon_loss: 0.002442172961309552	bpp_loss: 4.596398830413818	aux_loss: 0.32139718532562256
22:11:43 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 5.3272385597229	recon_loss: 0.0024421745911240578	bpp_loss: 4.594586372375488	aux_loss: 0.45448318123817444
22:12:15 INFO - main: Train iter. 133100/200000 (66.55%): 	Loss: 5.3237199783325195	recon_loss: 0.0024379626847803593	bpp_loss: 4.5923309326171875	aux_loss: 0.32388728857040405
22:12:47 INFO - main: Train iter. 133200/200000 (66.6%): 	Loss: 5.323154449462891	recon_loss: 0.002435379894450307	bpp_loss: 4.592540264129639	aux_loss: 0.30007559061050415
22:13:19 INFO - main: Train iter. 133300/200000 (66.65%): 	Loss: 5.323272228240967	recon_loss: 0.0024305249098688364	bpp_loss: 4.594114780426025	aux_loss: 1.084448218345642
22:13:51 INFO - main: Train iter. 133400/200000 (66.7%): 	Loss: 5.332395076751709	recon_loss: 0.002429012209177017	bpp_loss: 4.603691577911377	aux_loss: 0.3903055489063263
22:14:22 INFO - main: Train iter. 133500/200000 (66.75%): 	Loss: 5.33292293548584	recon_loss: 0.0024344404228031635	bpp_loss: 4.602590560913086	aux_loss: 0.4394557774066925
22:14:54 INFO - main: Train iter. 133600/200000 (66.8%): 	Loss: 5.331589221954346	recon_loss: 0.002430580323562026	bpp_loss: 4.602415084838867	aux_loss: 1.0826568603515625
22:15:26 INFO - main: Train iter. 133700/200000 (66.85%): 	Loss: 5.325703144073486	recon_loss: 0.0024310820735991	bpp_loss: 4.596378326416016	aux_loss: 1.2386069297790527
22:15:58 INFO - main: Train iter. 133800/200000 (66.9%): 	Loss: 5.323611259460449	recon_loss: 0.002428073901683092	bpp_loss: 4.595189094543457	aux_loss: 0.1668151319026947
22:16:30 INFO - main: Train iter. 133900/200000 (66.95%): 	Loss: 5.325662612915039	recon_loss: 0.0024268999695777893	bpp_loss: 4.597592830657959	aux_loss: 0.21195723116397858
22:17:03 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 5.3197712898254395	recon_loss: 0.002428168198093772	bpp_loss: 4.591320991516113	aux_loss: 0.32318180799484253
22:17:35 INFO - main: Train iter. 134100/200000 (67.05%): 	Loss: 5.320366859436035	recon_loss: 0.0024288997519761324	bpp_loss: 4.591696739196777	aux_loss: 0.5603585243225098
22:18:07 INFO - main: Train iter. 134200/200000 (67.1%): 	Loss: 5.315225601196289	recon_loss: 0.002430092776194215	bpp_loss: 4.586197853088379	aux_loss: 0.47802823781967163
22:18:38 INFO - main: Train iter. 134300/200000 (67.15%): 	Loss: 5.330424785614014	recon_loss: 0.002431864384561777	bpp_loss: 4.600865364074707	aux_loss: 0.7593829035758972
22:19:10 INFO - main: Train iter. 134400/200000 (67.2%): 	Loss: 5.329283237457275	recon_loss: 0.0024289172142744064	bpp_loss: 4.600607872009277	aux_loss: 0.7333781123161316
22:19:42 INFO - main: Train iter. 134500/200000 (67.25%): 	Loss: 5.324728488922119	recon_loss: 0.002433712361380458	bpp_loss: 4.5946149826049805	aux_loss: 0.5476101636886597
22:20:14 INFO - main: Train iter. 134600/200000 (67.3%): 	Loss: 5.326769828796387	recon_loss: 0.0024261402431875467	bpp_loss: 4.5989274978637695	aux_loss: 0.5215917825698853
22:20:46 INFO - main: Train iter. 134700/200000 (67.35%): 	Loss: 5.324239730834961	recon_loss: 0.002438053721562028	bpp_loss: 4.592823505401611	aux_loss: 0.27233922481536865
22:21:18 INFO - main: Train iter. 134800/200000 (67.4%): 	Loss: 5.329466819763184	recon_loss: 0.002436940325424075	bpp_loss: 4.598384857177734	aux_loss: 0.5660973787307739
22:21:50 INFO - main: Train iter. 134900/200000 (67.45%): 	Loss: 5.319626808166504	recon_loss: 0.0024305779952555895	bpp_loss: 4.590453624725342	aux_loss: 0.4152008891105652
22:22:22 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 5.331414222717285	recon_loss: 0.0024393571075052023	bpp_loss: 4.599606990814209	aux_loss: 0.26055124402046204
22:22:33 INFO - main: {'TEST MSE': 0.0024357254066455663, 'TEST BPP': 4.6168515625, 'TEST loss': 5.332854566574096, 'TEST recon_loss': 0.0024357254880014805, 'TEST bpp_loss': 4.602136925220489}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
22:23:04 INFO - main: Train iter. 135100/200000 (67.55%): 	Loss: 5.3269734382629395	recon_loss: 0.0024287234991788864	bpp_loss: 4.598356246948242	aux_loss: 0.35694360733032227
22:23:36 INFO - main: Train iter. 135200/200000 (67.6%): 	Loss: 5.323713779449463	recon_loss: 0.00242544524371624	bpp_loss: 4.596080303192139	aux_loss: 0.7808594107627869
22:24:08 INFO - main: Train iter. 135300/200000 (67.65%): 	Loss: 5.333459377288818	recon_loss: 0.0024313924368470907	bpp_loss: 4.604041576385498	aux_loss: 0.26657065749168396
22:24:41 INFO - main: Train iter. 135400/200000 (67.7%): 	Loss: 5.336364269256592	recon_loss: 0.0024351782631129026	bpp_loss: 4.605810642242432	aux_loss: 0.19013217091560364
22:25:13 INFO - main: Train iter. 135500/200000 (67.75%): 	Loss: 5.324431419372559	recon_loss: 0.0024264566600322723	bpp_loss: 4.596494197845459	aux_loss: 0.8958377838134766
22:25:45 INFO - main: Train iter. 135600/200000 (67.8%): 	Loss: 5.330665111541748	recon_loss: 0.0024283071979880333	bpp_loss: 4.6021728515625	aux_loss: 0.4454948902130127
22:26:16 INFO - main: Train iter. 135700/200000 (67.85%): 	Loss: 5.335996150970459	recon_loss: 0.0024358101654797792	bpp_loss: 4.605253219604492	aux_loss: 0.43304604291915894
22:26:48 INFO - main: Train iter. 135800/200000 (67.9%): 	Loss: 5.333133697509766	recon_loss: 0.0024364383425563574	bpp_loss: 4.60220193862915	aux_loss: 0.3401082158088684
22:27:20 INFO - main: Train iter. 135900/200000 (67.95%): 	Loss: 5.3206048011779785	recon_loss: 0.0024320073425769806	bpp_loss: 4.591002464294434	aux_loss: 0.3709411025047302
22:27:52 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 5.32747745513916	recon_loss: 0.0024339656811207533	bpp_loss: 4.597287654876709	aux_loss: 0.7005918025970459
22:28:24 INFO - main: Train iter. 136100/200000 (68.05%): 	Loss: 5.3320770263671875	recon_loss: 0.00242819101549685	bpp_loss: 4.603619575500488	aux_loss: 0.37379029393196106
22:28:56 INFO - main: Train iter. 136200/200000 (68.1%): 	Loss: 5.328160762786865	recon_loss: 0.0024382115807384253	bpp_loss: 4.5966973304748535	aux_loss: 0.41331905126571655
22:29:28 INFO - main: Train iter. 136300/200000 (68.15%): 	Loss: 5.329934597015381	recon_loss: 0.0024348865263164043	bpp_loss: 4.59946870803833	aux_loss: 0.3463255763053894
22:29:59 INFO - main: Train iter. 136400/200000 (68.2%): 	Loss: 5.334792137145996	recon_loss: 0.002428185660392046	bpp_loss: 4.60633659362793	aux_loss: 0.3394638001918793
22:30:31 INFO - main: Train iter. 136500/200000 (68.25%): 	Loss: 5.33393669128418	recon_loss: 0.0024396772496402264	bpp_loss: 4.602033615112305	aux_loss: 0.26974186301231384
22:31:03 INFO - main: Train iter. 136600/200000 (68.3%): 	Loss: 5.341866493225098	recon_loss: 0.0024378581438213587	bpp_loss: 4.610508918762207	aux_loss: 0.30968499183654785
22:31:35 INFO - main: Train iter. 136700/200000 (68.35%): 	Loss: 5.328377723693848	recon_loss: 0.0024383957497775555	bpp_loss: 4.596858978271484	aux_loss: 0.31320613622665405
22:32:08 INFO - main: Train iter. 136800/200000 (68.4%): 	Loss: 5.336443901062012	recon_loss: 0.002430352382361889	bpp_loss: 4.607337951660156	aux_loss: 0.47740212082862854
22:32:40 INFO - main: Train iter. 136900/200000 (68.45%): 	Loss: 5.3332977294921875	recon_loss: 0.0024523846805095673	bpp_loss: 4.5975823402404785	aux_loss: 0.2924276292324066
22:33:12 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 5.333414077758789	recon_loss: 0.0024693175218999386	bpp_loss: 4.592618942260742	aux_loss: 0.7466044425964355
22:33:43 INFO - main: Train iter. 137100/200000 (68.55%): 	Loss: 5.321773052215576	recon_loss: 0.00245426082983613	bpp_loss: 4.5854949951171875	aux_loss: 0.7787898778915405
22:34:15 INFO - main: Train iter. 137200/200000 (68.6%): 	Loss: 5.344708442687988	recon_loss: 0.002454769564792514	bpp_loss: 4.608277320861816	aux_loss: 0.6952303647994995
22:34:47 INFO - main: Train iter. 137300/200000 (68.65%): 	Loss: 5.3375935554504395	recon_loss: 0.002443700795993209	bpp_loss: 4.604483127593994	aux_loss: 0.6290881633758545
22:35:19 INFO - main: Train iter. 137400/200000 (68.7%): 	Loss: 5.334134101867676	recon_loss: 0.0024408733006566763	bpp_loss: 4.601871967315674	aux_loss: 0.2686648368835449
22:35:51 INFO - main: Train iter. 137500/200000 (68.75%): 	Loss: 5.333279132843018	recon_loss: 0.002441469579935074	bpp_loss: 4.6008381843566895	aux_loss: 0.2873436212539673
22:36:22 INFO - main: Train iter. 137600/200000 (68.8%): 	Loss: 5.330458164215088	recon_loss: 0.0024415436200797558	bpp_loss: 4.597995281219482	aux_loss: 0.44909748435020447
22:36:54 INFO - main: Train iter. 137700/200000 (68.85%): 	Loss: 5.325273513793945	recon_loss: 0.002436272567138076	bpp_loss: 4.594391822814941	aux_loss: 0.787188708782196
22:37:26 INFO - main: Train iter. 137800/200000 (68.9%): 	Loss: 5.333718776702881	recon_loss: 0.0024328893050551414	bpp_loss: 4.603851795196533	aux_loss: 0.27319711446762085
22:37:58 INFO - main: Train iter. 137900/200000 (68.95%): 	Loss: 5.326994895935059	recon_loss: 0.00243597524240613	bpp_loss: 4.596202373504639	aux_loss: 0.4027683138847351
22:38:29 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 5.328967571258545	recon_loss: 0.0024259157944470644	bpp_loss: 4.601192951202393	aux_loss: 0.2034873515367508
22:39:03 INFO - main: Train iter. 138100/200000 (69.05%): 	Loss: 5.327225685119629	recon_loss: 0.0024315090849995613	bpp_loss: 4.59777307510376	aux_loss: 0.34311532974243164
22:39:34 INFO - main: Train iter. 138200/200000 (69.1%): 	Loss: 5.34289026260376	recon_loss: 0.0024395931977778673	bpp_loss: 4.6110124588012695	aux_loss: 0.6190978288650513
22:40:06 INFO - main: Train iter. 138300/200000 (69.15%): 	Loss: 5.339137077331543	recon_loss: 0.002428875770419836	bpp_loss: 4.610474586486816	aux_loss: 0.679591178894043
22:40:38 INFO - main: Train iter. 138400/200000 (69.2%): 	Loss: 5.324854850769043	recon_loss: 0.0024348886217921972	bpp_loss: 4.594388008117676	aux_loss: 0.6937946677207947
22:41:10 INFO - main: Train iter. 138500/200000 (69.25%): 	Loss: 5.336414813995361	recon_loss: 0.002434088382869959	bpp_loss: 4.6061882972717285	aux_loss: 0.8565404415130615
22:41:42 INFO - main: Train iter. 138600/200000 (69.3%): 	Loss: 5.332388401031494	recon_loss: 0.0024321801029145718	bpp_loss: 4.602734565734863	aux_loss: 0.43319496512413025
22:42:14 INFO - main: Train iter. 138700/200000 (69.35%): 	Loss: 5.331841468811035	recon_loss: 0.002425606595352292	bpp_loss: 4.604159355163574	aux_loss: 0.5507413148880005
22:42:45 INFO - main: Train iter. 138800/200000 (69.4%): 	Loss: 5.337509632110596	recon_loss: 0.0024383352138102055	bpp_loss: 4.606009006500244	aux_loss: 1.3819206953048706
22:43:17 INFO - main: Train iter. 138900/200000 (69.45%): 	Loss: 5.335717678070068	recon_loss: 0.0024509872309863567	bpp_loss: 4.60042142868042	aux_loss: 0.9810040593147278
22:43:49 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 5.324152946472168	recon_loss: 0.0024377228692173958	bpp_loss: 4.592835903167725	aux_loss: 0.5081281661987305
22:44:21 INFO - main: Train iter. 139100/200000 (69.55%): 	Loss: 5.340471267700195	recon_loss: 0.0024418404791504145	bpp_loss: 4.607919216156006	aux_loss: 0.4791843891143799
22:44:53 INFO - main: Train iter. 139200/200000 (69.6%): 	Loss: 5.321403503417969	recon_loss: 0.002437836956232786	bpp_loss: 4.590052604675293	aux_loss: 0.9147850275039673
22:45:25 INFO - main: Train iter. 139300/200000 (69.65%): 	Loss: 5.332863807678223	recon_loss: 0.0024396905209869146	bpp_loss: 4.600956916809082	aux_loss: 0.2999238967895508
22:45:57 INFO - main: Train iter. 139400/200000 (69.7%): 	Loss: 5.32628870010376	recon_loss: 0.002440886339172721	bpp_loss: 4.594022750854492	aux_loss: 1.1674984693527222
22:46:30 INFO - main: Train iter. 139500/200000 (69.75%): 	Loss: 5.329232215881348	recon_loss: 0.0024443562142550945	bpp_loss: 4.595925331115723	aux_loss: 0.9247560501098633
22:47:01 INFO - main: Train iter. 139600/200000 (69.8%): 	Loss: 5.337310791015625	recon_loss: 0.00243537500500679	bpp_loss: 4.606698036193848	aux_loss: 0.3639162480831146
22:47:33 INFO - main: Train iter. 139700/200000 (69.85%): 	Loss: 5.334566116333008	recon_loss: 0.002434853697195649	bpp_loss: 4.604110240936279	aux_loss: 0.537344217300415
22:48:05 INFO - main: Train iter. 139800/200000 (69.9%): 	Loss: 5.327877521514893	recon_loss: 0.0024447839241474867	bpp_loss: 4.594442367553711	aux_loss: 0.5003856420516968
22:48:37 INFO - main: Train iter. 139900/200000 (69.95%): 	Loss: 5.335613250732422	recon_loss: 0.002444161567837	bpp_loss: 4.602364540100098	aux_loss: 0.8563730716705322
22:49:09 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 5.322817802429199	recon_loss: 0.0024364697746932507	bpp_loss: 4.591876983642578	aux_loss: 0.34173348546028137
22:49:20 INFO - main: {'TEST MSE': 0.002435301998377681, 'TEST BPP': 4.6155234375, 'TEST loss': 5.331646519184113, 'TEST recon_loss': 0.0024353020812850445, 'TEST bpp_loss': 4.6010558958053585}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
22:49:52 INFO - main: Train iter. 140100/200000 (70.05%): 	Loss: 5.327134609222412	recon_loss: 0.0024373247288167477	bpp_loss: 4.595937252044678	aux_loss: 0.6645457148551941
22:50:23 INFO - main: Train iter. 140200/200000 (70.1%): 	Loss: 5.335684776306152	recon_loss: 0.0024307004641741514	bpp_loss: 4.606474876403809	aux_loss: 0.6275757551193237
22:50:55 INFO - main: Train iter. 140300/200000 (70.15%): 	Loss: 5.33201789855957	recon_loss: 0.0024454013910144567	bpp_loss: 4.598397731781006	aux_loss: 0.5916092395782471
22:51:27 INFO - main: Train iter. 140400/200000 (70.2%): 	Loss: 5.335468292236328	recon_loss: 0.0024316648487001657	bpp_loss: 4.605968952178955	aux_loss: 0.460363507270813
22:51:59 INFO - main: Train iter. 140500/200000 (70.25%): 	Loss: 5.3361897468566895	recon_loss: 0.0024287784472107887	bpp_loss: 4.607556343078613	aux_loss: 0.31622791290283203
22:52:31 INFO - main: Train iter. 140600/200000 (70.3%): 	Loss: 5.311008930206299	recon_loss: 0.0024272778537124395	bpp_loss: 4.582825660705566	aux_loss: 0.6314682960510254
22:53:02 INFO - main: Train iter. 140700/200000 (70.35%): 	Loss: 5.318384647369385	recon_loss: 0.0024330250453203917	bpp_loss: 4.58847713470459	aux_loss: 0.35623615980148315
22:53:34 INFO - main: Train iter. 140800/200000 (70.4%): 	Loss: 5.339081764221191	recon_loss: 0.0024333978071808815	bpp_loss: 4.609062671661377	aux_loss: 0.4088142216205597
22:54:07 INFO - main: Train iter. 140900/200000 (70.45%): 	Loss: 5.321237087249756	recon_loss: 0.0024267849512398243	bpp_loss: 4.593201637268066	aux_loss: 0.6350244283676147
22:54:39 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 5.318974494934082	recon_loss: 0.002428267849609256	bpp_loss: 4.590494155883789	aux_loss: 0.23727402091026306
22:55:11 INFO - main: Train iter. 141100/200000 (70.55%): 	Loss: 5.316892147064209	recon_loss: 0.0024267646949738264	bpp_loss: 4.588862895965576	aux_loss: 0.2885863780975342
22:55:43 INFO - main: Train iter. 141200/200000 (70.6%): 	Loss: 5.317041873931885	recon_loss: 0.0024280743673443794	bpp_loss: 4.588619709014893	aux_loss: 0.3957297205924988
22:56:14 INFO - main: Train iter. 141300/200000 (70.65%): 	Loss: 5.3301286697387695	recon_loss: 0.0024354916531592607	bpp_loss: 4.599481105804443	aux_loss: 0.23656600713729858
22:56:46 INFO - main: Train iter. 141400/200000 (70.7%): 	Loss: 5.339635372161865	recon_loss: 0.0024359719827771187	bpp_loss: 4.608843803405762	aux_loss: 1.1417477130889893
22:57:18 INFO - main: Train iter. 141500/200000 (70.75%): 	Loss: 5.327004432678223	recon_loss: 0.002431241562590003	bpp_loss: 4.597631931304932	aux_loss: 1.1361383199691772
22:57:50 INFO - main: Train iter. 141600/200000 (70.8%): 	Loss: 5.333022117614746	recon_loss: 0.002427829662337899	bpp_loss: 4.604673385620117	aux_loss: 0.8527854681015015
22:58:21 INFO - main: Train iter. 141700/200000 (70.85%): 	Loss: 5.325784206390381	recon_loss: 0.0024252107832580805	bpp_loss: 4.5982208251953125	aux_loss: 0.6407298445701599
22:58:53 INFO - main: Train iter. 141800/200000 (70.9%): 	Loss: 5.333013534545898	recon_loss: 0.0024331144522875547	bpp_loss: 4.603079319000244	aux_loss: 0.5729004144668579
22:59:25 INFO - main: Train iter. 141900/200000 (70.95%): 	Loss: 5.322961330413818	recon_loss: 0.002431633183732629	bpp_loss: 4.593471527099609	aux_loss: 0.36815017461776733
22:59:57 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 5.320212364196777	recon_loss: 0.0024350041057914495	bpp_loss: 4.5897111892700195	aux_loss: 0.33633190393447876
23:00:29 INFO - main: Train iter. 142100/200000 (71.05%): 	Loss: 5.330056190490723	recon_loss: 0.002428526757284999	bpp_loss: 4.601498126983643	aux_loss: 0.21054527163505554
23:01:02 INFO - main: Train iter. 142200/200000 (71.1%): 	Loss: 5.320470809936523	recon_loss: 0.002432467881590128	bpp_loss: 4.590730667114258	aux_loss: 1.2950773239135742
23:01:34 INFO - main: Train iter. 142300/200000 (71.15%): 	Loss: 5.318514823913574	recon_loss: 0.002423032419756055	bpp_loss: 4.591605186462402	aux_loss: 0.25350096821784973
23:02:05 INFO - main: Train iter. 142400/200000 (71.2%): 	Loss: 5.325549125671387	recon_loss: 0.002434315625578165	bpp_loss: 4.595254421234131	aux_loss: 0.9456456899642944
23:02:37 INFO - main: Train iter. 142500/200000 (71.25%): 	Loss: 5.320572376251221	recon_loss: 0.0024269260466098785	bpp_loss: 4.592494487762451	aux_loss: 1.1170551776885986
23:03:09 INFO - main: Train iter. 142600/200000 (71.3%): 	Loss: 5.329731464385986	recon_loss: 0.002430560067296028	bpp_loss: 4.6005635261535645	aux_loss: 0.3674948811531067
23:03:41 INFO - main: Train iter. 142700/200000 (71.35%): 	Loss: 5.333439826965332	recon_loss: 0.0024346422869712114	bpp_loss: 4.6030473709106445	aux_loss: 0.21936888992786407
23:04:13 INFO - main: Train iter. 142800/200000 (71.4%): 	Loss: 5.3379974365234375	recon_loss: 0.002425355836749077	bpp_loss: 4.610390663146973	aux_loss: 0.647661566734314
23:04:44 INFO - main: Train iter. 142900/200000 (71.45%): 	Loss: 5.325231552124023	recon_loss: 0.0024416178930550814	bpp_loss: 4.592746257781982	aux_loss: 0.6568201780319214
23:05:16 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 5.322688579559326	recon_loss: 0.0024342781398445368	bpp_loss: 4.592405319213867	aux_loss: 0.24729815125465393
23:05:48 INFO - main: Train iter. 143100/200000 (71.55%): 	Loss: 5.32660436630249	recon_loss: 0.0024324164260178804	bpp_loss: 4.596879482269287	aux_loss: 0.4506274461746216
23:06:20 INFO - main: Train iter. 143200/200000 (71.6%): 	Loss: 5.332560062408447	recon_loss: 0.002428072039037943	bpp_loss: 4.604138374328613	aux_loss: 0.27171754837036133
23:06:52 INFO - main: Train iter. 143300/200000 (71.65%): 	Loss: 5.308768272399902	recon_loss: 0.0024306653067469597	bpp_loss: 4.579568862915039	aux_loss: 0.571822464466095
23:07:24 INFO - main: Train iter. 143400/200000 (71.7%): 	Loss: 5.333255290985107	recon_loss: 0.002435763366520405	bpp_loss: 4.6025261878967285	aux_loss: 1.187391996383667
23:07:55 INFO - main: Train iter. 143500/200000 (71.75%): 	Loss: 5.332622051239014	recon_loss: 0.002435693284496665	bpp_loss: 4.601913928985596	aux_loss: 0.1868441104888916
23:08:29 INFO - main: Train iter. 143600/200000 (71.8%): 	Loss: 5.328676223754883	recon_loss: 0.002433766145259142	bpp_loss: 4.598546504974365	aux_loss: 0.6667664051055908
23:09:00 INFO - main: Train iter. 143700/200000 (71.85%): 	Loss: 5.324808120727539	recon_loss: 0.0024280771613121033	bpp_loss: 4.5963850021362305	aux_loss: 0.7270904779434204
23:09:32 INFO - main: Train iter. 143800/200000 (71.9%): 	Loss: 5.336715221405029	recon_loss: 0.0024390665348619223	bpp_loss: 4.604995250701904	aux_loss: 0.39237210154533386
23:10:04 INFO - main: Train iter. 143900/200000 (71.95%): 	Loss: 5.321389675140381	recon_loss: 0.0024326182901859283	bpp_loss: 4.591604232788086	aux_loss: 0.8537588715553284
23:10:36 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 5.317811489105225	recon_loss: 0.0024276021867990494	bpp_loss: 4.589530944824219	aux_loss: 0.6577059626579285
23:11:08 INFO - main: Train iter. 144100/200000 (72.05%): 	Loss: 5.334720134735107	recon_loss: 0.002434337278828025	bpp_loss: 4.604418754577637	aux_loss: 0.41219091415405273
23:11:40 INFO - main: Train iter. 144200/200000 (72.1%): 	Loss: 5.331018447875977	recon_loss: 0.002447522943839431	bpp_loss: 4.596761703491211	aux_loss: 1.4051114320755005
23:12:12 INFO - main: Train iter. 144300/200000 (72.15%): 	Loss: 5.329442024230957	recon_loss: 0.002445538993924856	bpp_loss: 4.595780372619629	aux_loss: 0.5872895121574402
23:12:43 INFO - main: Train iter. 144400/200000 (72.2%): 	Loss: 5.326840400695801	recon_loss: 0.002431995701044798	bpp_loss: 4.5972418785095215	aux_loss: 0.4056011438369751
23:13:15 INFO - main: Train iter. 144500/200000 (72.25%): 	Loss: 5.319117069244385	recon_loss: 0.0024296999908983707	bpp_loss: 4.590207099914551	aux_loss: 0.4661519527435303
23:13:47 INFO - main: Train iter. 144600/200000 (72.3%): 	Loss: 5.332937240600586	recon_loss: 0.0024296084884554148	bpp_loss: 4.6040544509887695	aux_loss: 0.280604749917984
23:14:19 INFO - main: Train iter. 144700/200000 (72.35%): 	Loss: 5.327197551727295	recon_loss: 0.002427414758130908	bpp_loss: 4.598973274230957	aux_loss: 0.6730433702468872
23:14:51 INFO - main: Train iter. 144800/200000 (72.4%): 	Loss: 5.3242878913879395	recon_loss: 0.002436727052554488	bpp_loss: 4.5932698249816895	aux_loss: 1.3909074068069458
23:15:23 INFO - main: Train iter. 144900/200000 (72.45%): 	Loss: 5.335227012634277	recon_loss: 0.0024353587068617344	bpp_loss: 4.60461950302124	aux_loss: 0.5298972725868225
23:15:56 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 5.313540935516357	recon_loss: 0.002429860644042492	bpp_loss: 4.584582805633545	aux_loss: 0.39807528257369995
23:16:08 INFO - main: {'TEST MSE': 0.0024308655635424856, 'TEST BPP': 4.616984375, 'TEST loss': 5.3317143654823305, 'TEST recon_loss': 0.0024308656440116465, 'TEST bpp_loss': 4.602454673290253}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
23:16:40 INFO - main: Train iter. 145100/200000 (72.55%): 	Loss: 5.326888561248779	recon_loss: 0.0024267202243208885	bpp_loss: 4.598872661590576	aux_loss: 0.8856244087219238
23:17:12 INFO - main: Train iter. 145200/200000 (72.6%): 	Loss: 5.34395170211792	recon_loss: 0.0024312161840498447	bpp_loss: 4.61458683013916	aux_loss: 1.01189386844635
23:17:43 INFO - main: Train iter. 145300/200000 (72.65%): 	Loss: 5.313706874847412	recon_loss: 0.002426228951662779	bpp_loss: 4.585838317871094	aux_loss: 0.23799081146717072
23:18:15 INFO - main: Train iter. 145400/200000 (72.7%): 	Loss: 5.3358564376831055	recon_loss: 0.0024291430599987507	bpp_loss: 4.607113361358643	aux_loss: 0.7233998775482178
23:18:47 INFO - main: Train iter. 145500/200000 (72.75%): 	Loss: 5.341887950897217	recon_loss: 0.0024253176525235176	bpp_loss: 4.614292621612549	aux_loss: 0.254568874835968
23:19:19 INFO - main: Train iter. 145600/200000 (72.8%): 	Loss: 5.319061279296875	recon_loss: 0.002434732858091593	bpp_loss: 4.58864164352417	aux_loss: 0.7430278658866882
23:19:51 INFO - main: Train iter. 145700/200000 (72.85%): 	Loss: 5.327700614929199	recon_loss: 0.00242532417178154	bpp_loss: 4.600103378295898	aux_loss: 0.6680654883384705
23:20:22 INFO - main: Train iter. 145800/200000 (72.9%): 	Loss: 5.338835716247559	recon_loss: 0.0024328273721039295	bpp_loss: 4.608987331390381	aux_loss: 0.6596003770828247
23:20:54 INFO - main: Train iter. 145900/200000 (72.95%): 	Loss: 5.3222126960754395	recon_loss: 0.002430965192615986	bpp_loss: 4.592923164367676	aux_loss: 0.530945897102356
23:21:26 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 5.323100566864014	recon_loss: 0.0024319186341017485	bpp_loss: 4.593524932861328	aux_loss: 0.6251717209815979
23:21:58 INFO - main: Train iter. 146100/200000 (73.05%): 	Loss: 5.333034992218018	recon_loss: 0.002461312571540475	bpp_loss: 4.594641208648682	aux_loss: 0.6521382331848145
23:22:30 INFO - main: Train iter. 146200/200000 (73.1%): 	Loss: 5.328037261962891	recon_loss: 0.002433049725368619	bpp_loss: 4.5981221199035645	aux_loss: 0.3456924557685852
23:23:03 INFO - main: Train iter. 146300/200000 (73.15%): 	Loss: 5.323032855987549	recon_loss: 0.0024262091610580683	bpp_loss: 4.595170021057129	aux_loss: 0.28726688027381897
23:23:35 INFO - main: Train iter. 146400/200000 (73.2%): 	Loss: 5.330467224121094	recon_loss: 0.002430383348837495	bpp_loss: 4.601352214813232	aux_loss: 0.28986984491348267
23:24:06 INFO - main: Train iter. 146500/200000 (73.25%): 	Loss: 5.344703674316406	recon_loss: 0.0024415121879428625	bpp_loss: 4.612249851226807	aux_loss: 1.0117883682250977
23:24:38 INFO - main: Train iter. 146600/200000 (73.3%): 	Loss: 5.340365409851074	recon_loss: 0.0024494121316820383	bpp_loss: 4.605541706085205	aux_loss: 1.132322072982788
23:25:10 INFO - main: Train iter. 146700/200000 (73.35%): 	Loss: 5.3248443603515625	recon_loss: 0.0024390523321926594	bpp_loss: 4.593128681182861	aux_loss: 0.9977869987487793
23:25:42 INFO - main: Train iter. 146800/200000 (73.4%): 	Loss: 5.324312210083008	recon_loss: 0.002433426445350051	bpp_loss: 4.594284534454346	aux_loss: 0.26512855291366577
23:26:14 INFO - main: Train iter. 146900/200000 (73.45%): 	Loss: 5.330311298370361	recon_loss: 0.0024368350859731436	bpp_loss: 4.5992608070373535	aux_loss: 0.6870896220207214
23:26:45 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 5.338676452636719	recon_loss: 0.0024371484760195017	bpp_loss: 4.607532024383545	aux_loss: 0.9873411059379578
23:27:17 INFO - main: Train iter. 147100/200000 (73.55%): 	Loss: 5.314359664916992	recon_loss: 0.0024373973719775677	bpp_loss: 4.5831403732299805	aux_loss: 0.325924813747406
23:27:49 INFO - main: Train iter. 147200/200000 (73.6%): 	Loss: 5.323065757751465	recon_loss: 0.0024350571911782026	bpp_loss: 4.592548847198486	aux_loss: 0.7475640177726746
23:28:21 INFO - main: Train iter. 147300/200000 (73.65%): 	Loss: 5.334836483001709	recon_loss: 0.002431464847177267	bpp_loss: 4.6053972244262695	aux_loss: 0.28569695353507996
23:28:53 INFO - main: Train iter. 147400/200000 (73.7%): 	Loss: 5.336618423461914	recon_loss: 0.0024386600125581026	bpp_loss: 4.605020523071289	aux_loss: 0.3145112991333008
23:29:25 INFO - main: Train iter. 147500/200000 (73.75%): 	Loss: 5.338766574859619	recon_loss: 0.002432697918266058	bpp_loss: 4.608957290649414	aux_loss: 0.43524235486984253
23:29:56 INFO - main: Train iter. 147600/200000 (73.8%): 	Loss: 5.330092906951904	recon_loss: 0.0024254184681922197	bpp_loss: 4.6024675369262695	aux_loss: 0.491790235042572
23:30:30 INFO - main: Train iter. 147700/200000 (73.85%): 	Loss: 5.314854621887207	recon_loss: 0.002430893946439028	bpp_loss: 4.5855865478515625	aux_loss: 0.5127397179603577
23:31:01 INFO - main: Train iter. 147800/200000 (73.9%): 	Loss: 5.322965621948242	recon_loss: 0.0024226089008152485	bpp_loss: 4.596182823181152	aux_loss: 0.31842532753944397
23:31:33 INFO - main: Train iter. 147900/200000 (73.95%): 	Loss: 5.329412937164307	recon_loss: 0.002437927294522524	bpp_loss: 4.598034858703613	aux_loss: 0.7896044254302979
23:32:05 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 5.329928874969482	recon_loss: 0.002432864159345627	bpp_loss: 4.600069522857666	aux_loss: 0.4046069383621216
23:32:37 INFO - main: Train iter. 148100/200000 (74.05%): 	Loss: 5.326197147369385	recon_loss: 0.002431751461699605	bpp_loss: 4.5966715812683105	aux_loss: 0.3539152145385742
23:33:09 INFO - main: Train iter. 148200/200000 (74.1%): 	Loss: 5.338850021362305	recon_loss: 0.0024320599623024464	bpp_loss: 4.609231948852539	aux_loss: 0.26631635427474976
23:33:41 INFO - main: Train iter. 148300/200000 (74.15%): 	Loss: 5.335339546203613	recon_loss: 0.00243201432749629	bpp_loss: 4.6057353019714355	aux_loss: 0.2802576720714569
23:34:13 INFO - main: Train iter. 148400/200000 (74.2%): 	Loss: 5.33827018737793	recon_loss: 0.0024288054555654526	bpp_loss: 4.609628677368164	aux_loss: 0.55230712890625
23:34:44 INFO - main: Train iter. 148500/200000 (74.25%): 	Loss: 5.321959495544434	recon_loss: 0.0024309854488819838	bpp_loss: 4.592663764953613	aux_loss: 0.43273037672042847
23:35:16 INFO - main: Train iter. 148600/200000 (74.3%): 	Loss: 5.331500053405762	recon_loss: 0.0024281784426420927	bpp_loss: 4.603046417236328	aux_loss: 0.2716670334339142
23:35:48 INFO - main: Train iter. 148700/200000 (74.35%): 	Loss: 5.322283744812012	recon_loss: 0.0024279842618852854	bpp_loss: 4.593888282775879	aux_loss: 0.37311244010925293
23:36:20 INFO - main: Train iter. 148800/200000 (74.4%): 	Loss: 5.324417591094971	recon_loss: 0.002432981040328741	bpp_loss: 4.5945234298706055	aux_loss: 0.33700478076934814
23:36:52 INFO - main: Train iter. 148900/200000 (74.45%): 	Loss: 5.326447486877441	recon_loss: 0.0024335773196071386	bpp_loss: 4.59637451171875	aux_loss: 0.2560129463672638
23:37:24 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 5.332267761230469	recon_loss: 0.0024376590736210346	bpp_loss: 4.6009697914123535	aux_loss: 0.2876913547515869
23:37:57 INFO - main: Train iter. 149100/200000 (74.55%): 	Loss: 5.33317756652832	recon_loss: 0.0024333777837455273	bpp_loss: 4.603164196014404	aux_loss: 0.28253108263015747
23:38:28 INFO - main: Train iter. 149200/200000 (74.6%): 	Loss: 5.32507848739624	recon_loss: 0.002429978223517537	bpp_loss: 4.596085071563721	aux_loss: 0.37832191586494446
23:39:00 INFO - main: Train iter. 149300/200000 (74.65%): 	Loss: 5.3284478187561035	recon_loss: 0.0024397068191319704	bpp_loss: 4.596535682678223	aux_loss: 0.9995217323303223
23:39:32 INFO - main: Train iter. 149400/200000 (74.7%): 	Loss: 5.327015399932861	recon_loss: 0.0024437520187348127	bpp_loss: 4.5938897132873535	aux_loss: 1.0397529602050781
23:40:04 INFO - main: Train iter. 149500/200000 (74.75%): 	Loss: 5.328437805175781	recon_loss: 0.002444856334477663	bpp_loss: 4.594980716705322	aux_loss: 1.3297297954559326
23:40:36 INFO - main: Train iter. 149600/200000 (74.8%): 	Loss: 5.331430435180664	recon_loss: 0.0024361740797758102	bpp_loss: 4.600578308105469	aux_loss: 0.8135575652122498
23:41:08 INFO - main: Train iter. 149700/200000 (74.85%): 	Loss: 5.325972557067871	recon_loss: 0.0024305295664817095	bpp_loss: 4.596813678741455	aux_loss: 0.6904362440109253
23:41:40 INFO - main: Train iter. 149800/200000 (74.9%): 	Loss: 5.325721263885498	recon_loss: 0.002434095134958625	bpp_loss: 4.595492839813232	aux_loss: 0.3267238140106201
23:42:11 INFO - main: Train iter. 149900/200000 (74.95%): 	Loss: 5.326202869415283	recon_loss: 0.0024358052760362625	bpp_loss: 4.595461368560791	aux_loss: 0.2806362509727478
23:42:43 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 5.325174808502197	recon_loss: 0.00242694653570652	bpp_loss: 4.597090721130371	aux_loss: 1.347846269607544
23:42:54 INFO - main: {'TEST MSE': 0.0024368850057966914, 'TEST BPP': 4.6157421875, 'TEST loss': 5.332702035903931, 'TEST recon_loss': 0.0024368850882165133, 'TEST bpp_loss': 4.601636509418488}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
23:43:26 INFO - main: Train iter. 150100/200000 (75.05%): 	Loss: 5.339471817016602	recon_loss: 0.002433197572827339	bpp_loss: 4.609512805938721	aux_loss: 0.4334627687931061
23:43:58 INFO - main: Train iter. 150200/200000 (75.1%): 	Loss: 5.335790634155273	recon_loss: 0.0024293684400618076	bpp_loss: 4.606980323791504	aux_loss: 0.20679771900177002
23:44:29 INFO - main: Train iter. 150300/200000 (75.15%): 	Loss: 5.335897445678711	recon_loss: 0.0024291665758937597	bpp_loss: 4.607147693634033	aux_loss: 0.2421899288892746
23:45:02 INFO - main: Train iter. 150400/200000 (75.2%): 	Loss: 5.339273452758789	recon_loss: 0.002433057874441147	bpp_loss: 4.609355926513672	aux_loss: 0.8572655320167542
23:45:34 INFO - main: Train iter. 150500/200000 (75.25%): 	Loss: 5.335146427154541	recon_loss: 0.0024436882231384516	bpp_loss: 4.602039813995361	aux_loss: 0.6842362880706787
23:46:06 INFO - main: Train iter. 150600/200000 (75.3%): 	Loss: 5.338004112243652	recon_loss: 0.0024316238705068827	bpp_loss: 4.608517169952393	aux_loss: 0.2662881016731262
23:46:38 INFO - main: Train iter. 150700/200000 (75.35%): 	Loss: 5.323275089263916	recon_loss: 0.002442307770252228	bpp_loss: 4.590582847595215	aux_loss: 0.27919697761535645
23:47:10 INFO - main: Train iter. 150800/200000 (75.4%): 	Loss: 5.326005935668945	recon_loss: 0.0024323691613972187	bpp_loss: 4.596295356750488	aux_loss: 0.3519182801246643
23:47:41 INFO - main: Train iter. 150900/200000 (75.45%): 	Loss: 5.33198881149292	recon_loss: 0.0024319130461663008	bpp_loss: 4.602415084838867	aux_loss: 0.25128471851348877
23:48:13 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 5.333095073699951	recon_loss: 0.002427902538329363	bpp_loss: 4.604724407196045	aux_loss: 0.6753963232040405
23:48:45 INFO - main: Train iter. 151100/200000 (75.55%): 	Loss: 5.325972557067871	recon_loss: 0.002421676181256771	bpp_loss: 4.5994696617126465	aux_loss: 0.2716263234615326
23:49:17 INFO - main: Train iter. 151200/200000 (75.6%): 	Loss: 5.32314920425415	recon_loss: 0.0024274983443319798	bpp_loss: 4.594899654388428	aux_loss: 0.8219049572944641
23:49:49 INFO - main: Train iter. 151300/200000 (75.65%): 	Loss: 5.31882905960083	recon_loss: 0.002434064634144306	bpp_loss: 4.58860969543457	aux_loss: 0.8382996320724487
23:50:21 INFO - main: Train iter. 151400/200000 (75.7%): 	Loss: 5.344762325286865	recon_loss: 0.0024283609818667173	bpp_loss: 4.616253852844238	aux_loss: 1.2494196891784668
23:50:53 INFO - main: Train iter. 151500/200000 (75.75%): 	Loss: 5.32664155960083	recon_loss: 0.0024286648258566856	bpp_loss: 4.598042011260986	aux_loss: 0.21708589792251587
23:51:24 INFO - main: Train iter. 151600/200000 (75.8%): 	Loss: 5.328186988830566	recon_loss: 0.002424451522529125	bpp_loss: 4.600851535797119	aux_loss: 0.21377117931842804
23:51:56 INFO - main: Train iter. 151700/200000 (75.85%): 	Loss: 5.3271379470825195	recon_loss: 0.0024283165112137794	bpp_loss: 4.598642826080322	aux_loss: 0.1966724395751953
23:52:29 INFO - main: Train iter. 151800/200000 (75.9%): 	Loss: 5.345384120941162	recon_loss: 0.0024285793770104647	bpp_loss: 4.616810321807861	aux_loss: 0.6213492751121521
23:53:01 INFO - main: Train iter. 151900/200000 (75.95%): 	Loss: 5.313953399658203	recon_loss: 0.0024275672622025013	bpp_loss: 4.585683345794678	aux_loss: 0.22941038012504578
23:53:33 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 5.324980735778809	recon_loss: 0.00242732185870409	bpp_loss: 4.5967841148376465	aux_loss: 0.428209125995636
23:54:04 INFO - main: Train iter. 152100/200000 (76.05%): 	Loss: 5.331124305725098	recon_loss: 0.002431135857477784	bpp_loss: 4.601783752441406	aux_loss: 0.25805920362472534
23:54:36 INFO - main: Train iter. 152200/200000 (76.1%): 	Loss: 5.330206871032715	recon_loss: 0.002426285995170474	bpp_loss: 4.602321147918701	aux_loss: 0.5224881768226624
23:55:08 INFO - main: Train iter. 152300/200000 (76.15%): 	Loss: 5.326174736022949	recon_loss: 0.0024287474807351828	bpp_loss: 4.597550392150879	aux_loss: 0.3492264747619629
23:55:40 INFO - main: Train iter. 152400/200000 (76.2%): 	Loss: 5.316555976867676	recon_loss: 0.0024348455481231213	bpp_loss: 4.586102485656738	aux_loss: 0.39037472009658813
23:56:12 INFO - main: Train iter. 152500/200000 (76.25%): 	Loss: 5.324671268463135	recon_loss: 0.0024334171321243048	bpp_loss: 4.594645977020264	aux_loss: 0.6398470401763916
23:56:43 INFO - main: Train iter. 152600/200000 (76.3%): 	Loss: 5.321650505065918	recon_loss: 0.0024277642369270325	bpp_loss: 4.593321323394775	aux_loss: 0.6344480514526367
23:57:15 INFO - main: Train iter. 152700/200000 (76.35%): 	Loss: 5.3326416015625	recon_loss: 0.0024240619968622923	bpp_loss: 4.6054229736328125	aux_loss: 0.3031366467475891
23:57:47 INFO - main: Train iter. 152800/200000 (76.4%): 	Loss: 5.323193550109863	recon_loss: 0.0024352241307497025	bpp_loss: 4.592626571655273	aux_loss: 0.5895510315895081
23:58:19 INFO - main: Train iter. 152900/200000 (76.45%): 	Loss: 5.338360786437988	recon_loss: 0.0024285719264298677	bpp_loss: 4.6097893714904785	aux_loss: 0.5964158773422241
23:58:50 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 5.332059383392334	recon_loss: 0.0024361624382436275	bpp_loss: 4.601210594177246	aux_loss: 0.28796660900115967
23:59:22 INFO - main: Train iter. 153100/200000 (76.55%): 	Loss: 5.328951835632324	recon_loss: 0.002426311606541276	bpp_loss: 4.601058483123779	aux_loss: 0.22788400948047638
23:59:55 INFO - main: Train iter. 153200/200000 (76.6%): 	Loss: 5.3334126472473145	recon_loss: 0.0024348392616957426	bpp_loss: 4.60296106338501	aux_loss: 1.0304923057556152
00:00:27 INFO - main: Train iter. 153300/200000 (76.65%): 	Loss: 5.32295560836792	recon_loss: 0.0024251816794276237	bpp_loss: 4.595401287078857	aux_loss: 0.2989819347858429
00:00:59 INFO - main: Train iter. 153400/200000 (76.7%): 	Loss: 5.322402000427246	recon_loss: 0.00243060989305377	bpp_loss: 4.593218803405762	aux_loss: 0.6998680830001831
00:01:31 INFO - main: Train iter. 153500/200000 (76.75%): 	Loss: 5.3308868408203125	recon_loss: 0.00243134587071836	bpp_loss: 4.601483345031738	aux_loss: 0.25805288553237915
00:02:03 INFO - main: Train iter. 153600/200000 (76.8%): 	Loss: 5.324747562408447	recon_loss: 0.0024369764141738415	bpp_loss: 4.593654632568359	aux_loss: 0.4212278425693512
00:02:35 INFO - main: Train iter. 153700/200000 (76.85%): 	Loss: 5.329784870147705	recon_loss: 0.0024287302512675524	bpp_loss: 4.601165771484375	aux_loss: 1.3727216720581055
00:03:07 INFO - main: Train iter. 153800/200000 (76.9%): 	Loss: 5.323883056640625	recon_loss: 0.002434482565149665	bpp_loss: 4.593538284301758	aux_loss: 0.3024126887321472
00:03:38 INFO - main: Train iter. 153900/200000 (76.95%): 	Loss: 5.324836254119873	recon_loss: 0.0024476947728544474	bpp_loss: 4.5905280113220215	aux_loss: 0.3376132845878601
00:04:10 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 5.325568199157715	recon_loss: 0.0024374229833483696	bpp_loss: 4.594341278076172	aux_loss: 0.32513824105262756
00:04:42 INFO - main: Train iter. 154100/200000 (77.05%): 	Loss: 5.328463554382324	recon_loss: 0.0024323572870343924	bpp_loss: 4.598756313323975	aux_loss: 0.35746660828590393
00:05:14 INFO - main: Train iter. 154200/200000 (77.1%): 	Loss: 5.322239875793457	recon_loss: 0.002438935451209545	bpp_loss: 4.590559482574463	aux_loss: 0.8317573070526123
00:05:46 INFO - main: Train iter. 154300/200000 (77.15%): 	Loss: 5.336558818817139	recon_loss: 0.0024361913092434406	bpp_loss: 4.605701446533203	aux_loss: 0.6333616971969604
00:06:17 INFO - main: Train iter. 154400/200000 (77.2%): 	Loss: 5.337340831756592	recon_loss: 0.0024409883189946413	bpp_loss: 4.605044364929199	aux_loss: 0.6761058568954468
00:06:51 INFO - main: Train iter. 154500/200000 (77.25%): 	Loss: 5.319271564483643	recon_loss: 0.0024300559889525175	bpp_loss: 4.590254783630371	aux_loss: 0.36202746629714966
00:07:22 INFO - main: Train iter. 154600/200000 (77.3%): 	Loss: 5.338055610656738	recon_loss: 0.002439669333398342	bpp_loss: 4.606154918670654	aux_loss: 0.8319290280342102
00:07:54 INFO - main: Train iter. 154700/200000 (77.35%): 	Loss: 5.334510326385498	recon_loss: 0.0024357913061976433	bpp_loss: 4.60377311706543	aux_loss: 0.24856838583946228
00:08:26 INFO - main: Train iter. 154800/200000 (77.4%): 	Loss: 5.327342510223389	recon_loss: 0.0024281011428683996	bpp_loss: 4.598912239074707	aux_loss: 0.5034847259521484
00:08:58 INFO - main: Train iter. 154900/200000 (77.45%): 	Loss: 5.3302001953125	recon_loss: 0.0024329398293048143	bpp_loss: 4.600318431854248	aux_loss: 0.35842907428741455
00:09:30 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 5.3261566162109375	recon_loss: 0.0024416709784418344	bpp_loss: 4.593655586242676	aux_loss: 0.4610981047153473
00:09:41 INFO - main: {'TEST MSE': 0.0024401337976793793, 'TEST BPP': 4.615984375, 'TEST loss': 5.333544919967651, 'TEST recon_loss': 0.002440133876167238, 'TEST bpp_loss': 4.601504757881164}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
00:10:12 INFO - main: Train iter. 155100/200000 (77.55%): 	Loss: 5.316094398498535	recon_loss: 0.0024338888470083475	bpp_loss: 4.585927486419678	aux_loss: 0.27960190176963806
00:10:44 INFO - main: Train iter. 155200/200000 (77.6%): 	Loss: 5.337628364562988	recon_loss: 0.0024357005022466183	bpp_loss: 4.6069183349609375	aux_loss: 0.5023593902587891
00:11:16 INFO - main: Train iter. 155300/200000 (77.65%): 	Loss: 5.32321310043335	recon_loss: 0.0024311798624694347	bpp_loss: 4.5938591957092285	aux_loss: 0.9809184074401855
00:11:48 INFO - main: Train iter. 155400/200000 (77.7%): 	Loss: 5.333188533782959	recon_loss: 0.002433439949527383	bpp_loss: 4.603156566619873	aux_loss: 0.518916130065918
00:12:19 INFO - main: Train iter. 155500/200000 (77.75%): 	Loss: 5.326760292053223	recon_loss: 0.0024300829973071814	bpp_loss: 4.597735404968262	aux_loss: 0.8199876546859741
00:12:51 INFO - main: Train iter. 155600/200000 (77.8%): 	Loss: 5.320175647735596	recon_loss: 0.002429644577205181	bpp_loss: 4.591282367706299	aux_loss: 1.2797279357910156
00:13:23 INFO - main: Train iter. 155700/200000 (77.85%): 	Loss: 5.326038837432861	recon_loss: 0.0024284347891807556	bpp_loss: 4.597508430480957	aux_loss: 0.5210418701171875
00:13:55 INFO - main: Train iter. 155800/200000 (77.9%): 	Loss: 5.320110321044922	recon_loss: 0.002427272032946348	bpp_loss: 4.591928482055664	aux_loss: 0.21424457430839539
00:14:28 INFO - main: Train iter. 155900/200000 (77.95%): 	Loss: 5.332336902618408	recon_loss: 0.002424357458949089	bpp_loss: 4.605029582977295	aux_loss: 0.37584614753723145
00:15:00 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 5.343997955322266	recon_loss: 0.0024303889367729425	bpp_loss: 4.6148810386657715	aux_loss: 0.2546893060207367
00:15:31 INFO - main: Train iter. 156100/200000 (78.05%): 	Loss: 5.337130546569824	recon_loss: 0.002430184278637171	bpp_loss: 4.608075141906738	aux_loss: 0.30964112281799316
00:16:03 INFO - main: Train iter. 156200/200000 (78.1%): 	Loss: 5.324975490570068	recon_loss: 0.00242630229331553	bpp_loss: 4.597084999084473	aux_loss: 0.20256288349628448
00:16:35 INFO - main: Train iter. 156300/200000 (78.15%): 	Loss: 5.327437877655029	recon_loss: 0.002426247810944915	bpp_loss: 4.5995635986328125	aux_loss: 0.4825321137905121
00:17:07 INFO - main: Train iter. 156400/200000 (78.2%): 	Loss: 5.3308186531066895	recon_loss: 0.0024316597264260054	bpp_loss: 4.601320743560791	aux_loss: 0.2424544394016266
00:17:39 INFO - main: Train iter. 156500/200000 (78.25%): 	Loss: 5.321708679199219	recon_loss: 0.0024251583963632584	bpp_loss: 4.594161033630371	aux_loss: 0.48772749304771423
00:18:10 INFO - main: Train iter. 156600/200000 (78.3%): 	Loss: 5.324428081512451	recon_loss: 0.002431443426758051	bpp_loss: 4.594995021820068	aux_loss: 0.3288830518722534
00:18:42 INFO - main: Train iter. 156700/200000 (78.35%): 	Loss: 5.327869415283203	recon_loss: 0.002428105566650629	bpp_loss: 4.599437713623047	aux_loss: 0.4542776346206665
00:19:14 INFO - main: Train iter. 156800/200000 (78.4%): 	Loss: 5.341054439544678	recon_loss: 0.0024230494163930416	bpp_loss: 4.614139556884766	aux_loss: 0.4304405450820923
00:19:46 INFO - main: Train iter. 156900/200000 (78.45%): 	Loss: 5.328042030334473	recon_loss: 0.0024226198438555002	bpp_loss: 4.601255893707275	aux_loss: 0.648388683795929
00:20:18 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 5.3404154777526855	recon_loss: 0.002434273948892951	bpp_loss: 4.610133171081543	aux_loss: 0.20327329635620117
00:20:49 INFO - main: Train iter. 157100/200000 (78.55%): 	Loss: 5.319314479827881	recon_loss: 0.0024254005402326584	bpp_loss: 4.591694355010986	aux_loss: 0.7119724154472351
00:21:21 INFO - main: Train iter. 157200/200000 (78.6%): 	Loss: 5.3246073722839355	recon_loss: 0.002428540028631687	bpp_loss: 4.59604549407959	aux_loss: 0.39554670453071594
00:21:54 INFO - main: Train iter. 157300/200000 (78.65%): 	Loss: 5.325016498565674	recon_loss: 0.002433382673189044	bpp_loss: 4.595001697540283	aux_loss: 0.5923975706100464
00:22:26 INFO - main: Train iter. 157400/200000 (78.7%): 	Loss: 5.330639362335205	recon_loss: 0.002424549777060747	bpp_loss: 4.603274345397949	aux_loss: 0.5538070201873779
00:22:58 INFO - main: Train iter. 157500/200000 (78.75%): 	Loss: 5.315449237823486	recon_loss: 0.0024293342139571905	bpp_loss: 4.586648941040039	aux_loss: 0.4137754440307617
00:23:30 INFO - main: Train iter. 157600/200000 (78.8%): 	Loss: 5.320013999938965	recon_loss: 0.002433269750326872	bpp_loss: 4.590033054351807	aux_loss: 0.5788090229034424
00:24:01 INFO - main: Train iter. 157700/200000 (78.85%): 	Loss: 5.337465763092041	recon_loss: 0.002430064370855689	bpp_loss: 4.6084465980529785	aux_loss: 0.585746169090271
00:24:33 INFO - main: Train iter. 157800/200000 (78.9%): 	Loss: 5.344575881958008	recon_loss: 0.002425858983770013	bpp_loss: 4.616817951202393	aux_loss: 1.2582728862762451
00:25:05 INFO - main: Train iter. 157900/200000 (78.95%): 	Loss: 5.329719066619873	recon_loss: 0.002425601240247488	bpp_loss: 4.602038860321045	aux_loss: 0.5474505424499512
00:25:36 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 5.319489002227783	recon_loss: 0.002426499966531992	bpp_loss: 4.591538906097412	aux_loss: 0.48451071977615356
00:26:08 INFO - main: Train iter. 158100/200000 (79.05%): 	Loss: 5.3272881507873535	recon_loss: 0.0024311458691954613	bpp_loss: 4.597944259643555	aux_loss: 0.31609344482421875
00:26:40 INFO - main: Train iter. 158200/200000 (79.1%): 	Loss: 5.334708213806152	recon_loss: 0.0024269348941743374	bpp_loss: 4.606627941131592	aux_loss: 0.6942148804664612
00:27:12 INFO - main: Train iter. 158300/200000 (79.15%): 	Loss: 5.326394081115723	recon_loss: 0.0024272282607853413	bpp_loss: 4.5982255935668945	aux_loss: 1.2368600368499756
00:27:43 INFO - main: Train iter. 158400/200000 (79.2%): 	Loss: 5.335607528686523	recon_loss: 0.0024347954895347357	bpp_loss: 4.60516881942749	aux_loss: 0.4568173587322235
00:28:15 INFO - main: Train iter. 158500/200000 (79.25%): 	Loss: 5.331748008728027	recon_loss: 0.0024304690305143595	bpp_loss: 4.602607250213623	aux_loss: 0.40301939845085144
00:28:48 INFO - main: Train iter. 158600/200000 (79.3%): 	Loss: 5.320516109466553	recon_loss: 0.002423128578811884	bpp_loss: 4.5935773849487305	aux_loss: 0.6324383020401001
00:29:20 INFO - main: Train iter. 158700/200000 (79.35%): 	Loss: 5.325740814208984	recon_loss: 0.002427077619358897	bpp_loss: 4.5976176261901855	aux_loss: 0.5854985117912292
00:29:51 INFO - main: Train iter. 158800/200000 (79.4%): 	Loss: 5.311694145202637	recon_loss: 0.0024276869371533394	bpp_loss: 4.583388328552246	aux_loss: 0.6080138683319092
00:30:23 INFO - main: Train iter. 158900/200000 (79.45%): 	Loss: 5.337153911590576	recon_loss: 0.0024289730936288834	bpp_loss: 4.608461856842041	aux_loss: 0.36221328377723694
00:30:55 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 5.328399181365967	recon_loss: 0.002431524684652686	bpp_loss: 4.598941802978516	aux_loss: 0.2282063364982605
00:31:26 INFO - main: Train iter. 159100/200000 (79.55%): 	Loss: 5.324580192565918	recon_loss: 0.002428490901365876	bpp_loss: 4.596033096313477	aux_loss: 0.37021762132644653
00:31:58 INFO - main: Train iter. 159200/200000 (79.6%): 	Loss: 5.312246799468994	recon_loss: 0.002427602419629693	bpp_loss: 4.583966255187988	aux_loss: 1.0716009140014648
00:32:30 INFO - main: Train iter. 159300/200000 (79.65%): 	Loss: 5.322282791137695	recon_loss: 0.002432667650282383	bpp_loss: 4.592482566833496	aux_loss: 0.8265297412872314
00:33:01 INFO - main: Train iter. 159400/200000 (79.7%): 	Loss: 5.329249382019043	recon_loss: 0.0024276284966617823	bpp_loss: 4.600960731506348	aux_loss: 0.5924525260925293
00:33:33 INFO - main: Train iter. 159500/200000 (79.75%): 	Loss: 5.327323913574219	recon_loss: 0.0024338369257748127	bpp_loss: 4.597172737121582	aux_loss: 0.6570196151733398
00:34:05 INFO - main: Train iter. 159600/200000 (79.8%): 	Loss: 5.3344573974609375	recon_loss: 0.00244047399610281	bpp_loss: 4.602315425872803	aux_loss: 0.344394326210022
00:34:37 INFO - main: Train iter. 159700/200000 (79.85%): 	Loss: 5.328887939453125	recon_loss: 0.0024307623971253633	bpp_loss: 4.599658966064453	aux_loss: 0.5451341867446899
00:35:08 INFO - main: Train iter. 159800/200000 (79.9%): 	Loss: 5.3307695388793945	recon_loss: 0.002431464148685336	bpp_loss: 4.601330280303955	aux_loss: 0.28079789876937866
00:35:40 INFO - main: Train iter. 159900/200000 (79.95%): 	Loss: 5.330968379974365	recon_loss: 0.0024281141813844442	bpp_loss: 4.602534294128418	aux_loss: 0.2597907781600952
00:36:13 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 5.33743143081665	recon_loss: 0.00243252026848495	bpp_loss: 4.607675552368164	aux_loss: 0.1970462203025818
00:36:23 INFO - main: {'TEST MSE': 0.0024283936099570276, 'TEST BPP': 4.6175390625, 'TEST loss': 5.33186802482605, 'TEST recon_loss': 0.0024283936908468602, 'TEST bpp_loss': 4.603349911212921}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
00:36:55 INFO - main: Train iter. 160100/200000 (80.05%): 	Loss: 5.339419841766357	recon_loss: 0.0024437408428639174	bpp_loss: 4.606297492980957	aux_loss: 0.5738000869750977
00:37:27 INFO - main: Train iter. 160200/200000 (80.1%): 	Loss: 5.334684371948242	recon_loss: 0.002428507199510932	bpp_loss: 4.6061320304870605	aux_loss: 0.7616281509399414
00:37:58 INFO - main: Train iter. 160300/200000 (80.15%): 	Loss: 5.330989360809326	recon_loss: 0.0024392527993768454	bpp_loss: 4.599213600158691	aux_loss: 0.47052690386772156
00:38:30 INFO - main: Train iter. 160400/200000 (80.2%): 	Loss: 5.318501949310303	recon_loss: 0.0024380353279411793	bpp_loss: 4.587091445922852	aux_loss: 0.7666693925857544
00:39:02 INFO - main: Train iter. 160500/200000 (80.25%): 	Loss: 5.3283281326293945	recon_loss: 0.002436287933960557	bpp_loss: 4.597441673278809	aux_loss: 0.2837977707386017
00:39:33 INFO - main: Train iter. 160600/200000 (80.3%): 	Loss: 5.344764709472656	recon_loss: 0.0024344767443835735	bpp_loss: 4.614421844482422	aux_loss: 1.014805555343628
00:40:05 INFO - main: Train iter. 160700/200000 (80.35%): 	Loss: 5.332970142364502	recon_loss: 0.0024273612070828676	bpp_loss: 4.604761600494385	aux_loss: 0.2286030501127243
00:40:36 INFO - main: Train iter. 160800/200000 (80.4%): 	Loss: 5.318911552429199	recon_loss: 0.002432080917060375	bpp_loss: 4.589287281036377	aux_loss: 0.6555274128913879
00:41:08 INFO - main: Train iter. 160900/200000 (80.45%): 	Loss: 5.332433700561523	recon_loss: 0.0024385331198573112	bpp_loss: 4.600873947143555	aux_loss: 1.1892504692077637
00:41:40 INFO - main: Train iter. 161000/200000 (80.5%): 	Loss: 5.322449684143066	recon_loss: 0.0024323598481714725	bpp_loss: 4.592741966247559	aux_loss: 0.3468751311302185
00:42:12 INFO - main: Train iter. 161100/200000 (80.55%): 	Loss: 5.3248467445373535	recon_loss: 0.002437556628137827	bpp_loss: 4.5935797691345215	aux_loss: 0.9834386706352234
00:42:43 INFO - main: Train iter. 161200/200000 (80.6%): 	Loss: 5.332030773162842	recon_loss: 0.0024291847366839647	bpp_loss: 4.603275299072266	aux_loss: 0.5159863829612732
00:43:15 INFO - main: Train iter. 161300/200000 (80.65%): 	Loss: 5.3284010887146	recon_loss: 0.0024296934716403484	bpp_loss: 4.599493026733398	aux_loss: 0.2634229063987732
00:43:48 INFO - main: Train iter. 161400/200000 (80.7%): 	Loss: 5.3399434089660645	recon_loss: 0.0024210403207689524	bpp_loss: 4.613631248474121	aux_loss: 0.2642669379711151
00:44:20 INFO - main: Train iter. 161500/200000 (80.75%): 	Loss: 5.336030006408691	recon_loss: 0.0024244310334324837	bpp_loss: 4.608700752258301	aux_loss: 0.33805274963378906
00:44:51 INFO - main: Train iter. 161600/200000 (80.8%): 	Loss: 5.326200485229492	recon_loss: 0.0024271486327052116	bpp_loss: 4.598055839538574	aux_loss: 0.7465121746063232
00:45:23 INFO - main: Train iter. 161700/200000 (80.85%): 	Loss: 5.333697319030762	recon_loss: 0.002428199164569378	bpp_loss: 4.6052374839782715	aux_loss: 0.6377804279327393
00:45:55 INFO - main: Train iter. 161800/200000 (80.9%): 	Loss: 5.3389058113098145	recon_loss: 0.002432412700727582	bpp_loss: 4.609181880950928	aux_loss: 0.9770187139511108
00:46:27 INFO - main: Train iter. 161900/200000 (80.95%): 	Loss: 5.329383373260498	recon_loss: 0.0024260811042040586	bpp_loss: 4.601559162139893	aux_loss: 0.43447956442832947
00:46:58 INFO - main: Train iter. 162000/200000 (81.0%): 	Loss: 5.321579456329346	recon_loss: 0.002423166763037443	bpp_loss: 4.594629287719727	aux_loss: 0.24581389129161835
00:47:30 INFO - main: Train iter. 162100/200000 (81.05%): 	Loss: 5.333846569061279	recon_loss: 0.0024286163970828056	bpp_loss: 4.60526180267334	aux_loss: 0.37189358472824097
00:48:02 INFO - main: Train iter. 162200/200000 (81.1%): 	Loss: 5.329231262207031	recon_loss: 0.0024246349930763245	bpp_loss: 4.601840496063232	aux_loss: 0.3951772451400757
00:48:33 INFO - main: Train iter. 162300/200000 (81.15%): 	Loss: 5.327542781829834	recon_loss: 0.00242445757612586	bpp_loss: 4.600205421447754	aux_loss: 0.6323944330215454
00:49:05 INFO - main: Train iter. 162400/200000 (81.2%): 	Loss: 5.337264060974121	recon_loss: 0.002430272288620472	bpp_loss: 4.608182430267334	aux_loss: 0.2404841035604477
00:49:37 INFO - main: Train iter. 162500/200000 (81.25%): 	Loss: 5.316751956939697	recon_loss: 0.0024252785369753838	bpp_loss: 4.589168548583984	aux_loss: 0.8387141227722168
00:50:09 INFO - main: Train iter. 162600/200000 (81.3%): 	Loss: 5.342508316040039	recon_loss: 0.002437266521155834	bpp_loss: 4.611328125	aux_loss: 0.6867666244506836
00:50:42 INFO - main: Train iter. 162700/200000 (81.35%): 	Loss: 5.31424617767334	recon_loss: 0.0024271279107779264	bpp_loss: 4.5861077308654785	aux_loss: 0.3520510196685791
00:51:14 INFO - main: Train iter. 162800/200000 (81.4%): 	Loss: 5.32113790512085	recon_loss: 0.002434979658573866	bpp_loss: 4.590643882751465	aux_loss: 0.29662981629371643
00:51:45 INFO - main: Train iter. 162900/200000 (81.45%): 	Loss: 5.334455966949463	recon_loss: 0.0024372173938900232	bpp_loss: 4.603290557861328	aux_loss: 0.37571829557418823
00:52:17 INFO - main: Train iter. 163000/200000 (81.5%): 	Loss: 5.322514533996582	recon_loss: 0.0024282587692141533	bpp_loss: 4.594037055969238	aux_loss: 0.6333053708076477
00:52:49 INFO - main: Train iter. 163100/200000 (81.55%): 	Loss: 5.329983234405518	recon_loss: 0.0024321286473423243	bpp_loss: 4.600344657897949	aux_loss: 0.24848672747612
00:53:21 INFO - main: Train iter. 163200/200000 (81.6%): 	Loss: 5.340307712554932	recon_loss: 0.002446667989715934	bpp_loss: 4.606307506561279	aux_loss: 0.30337396264076233
00:53:52 INFO - main: Train iter. 163300/200000 (81.65%): 	Loss: 5.323987007141113	recon_loss: 0.0024235863238573074	bpp_loss: 4.5969109535217285	aux_loss: 0.8605086803436279
00:54:24 INFO - main: Train iter. 163400/200000 (81.7%): 	Loss: 5.3384623527526855	recon_loss: 0.00244654668495059	bpp_loss: 4.604498386383057	aux_loss: 1.115944266319275
00:54:56 INFO - main: Train iter. 163500/200000 (81.75%): 	Loss: 5.3154683113098145	recon_loss: 0.002431519329547882	bpp_loss: 4.586012363433838	aux_loss: 0.8713960647583008
00:55:27 INFO - main: Train iter. 163600/200000 (81.8%): 	Loss: 5.332026481628418	recon_loss: 0.0024315635673701763	bpp_loss: 4.602557182312012	aux_loss: 0.25350096821784973
00:55:59 INFO - main: Train iter. 163700/200000 (81.85%): 	Loss: 5.337337970733643	recon_loss: 0.002434802008792758	bpp_loss: 4.606897354125977	aux_loss: 0.4876987338066101
00:56:31 INFO - main: Train iter. 163800/200000 (81.9%): 	Loss: 5.331238269805908	recon_loss: 0.0024331624154001474	bpp_loss: 4.601289749145508	aux_loss: 0.5244622230529785
00:57:02 INFO - main: Train iter. 163900/200000 (81.95%): 	Loss: 5.328991889953613	recon_loss: 0.0024391801562160254	bpp_loss: 4.597237586975098	aux_loss: 0.8694550395011902
00:57:34 INFO - main: Train iter. 164000/200000 (82.0%): 	Loss: 5.321126461029053	recon_loss: 0.00243794871494174	bpp_loss: 4.5897417068481445	aux_loss: 0.4716285467147827
00:58:07 INFO - main: Train iter. 164100/200000 (82.05%): 	Loss: 5.342511177062988	recon_loss: 0.0024337400682270527	bpp_loss: 4.612389087677002	aux_loss: 0.2913374602794647
00:58:39 INFO - main: Train iter. 164200/200000 (82.1%): 	Loss: 5.33064603805542	recon_loss: 0.0024396644439548254	bpp_loss: 4.5987467765808105	aux_loss: 0.7075148820877075
00:59:10 INFO - main: Train iter. 164300/200000 (82.15%): 	Loss: 5.317169666290283	recon_loss: 0.002435947535559535	bpp_loss: 4.586385250091553	aux_loss: 0.6280860900878906
00:59:42 INFO - main: Train iter. 164400/200000 (82.2%): 	Loss: 5.316310882568359	recon_loss: 0.0024314504116773605	bpp_loss: 4.586875915527344	aux_loss: 0.25263333320617676
01:00:14 INFO - main: Train iter. 164500/200000 (82.25%): 	Loss: 5.323995590209961	recon_loss: 0.002439015544950962	bpp_loss: 4.592290878295898	aux_loss: 0.41082319617271423
01:00:45 INFO - main: Train iter. 164600/200000 (82.3%): 	Loss: 5.324339866638184	recon_loss: 0.002436912152916193	bpp_loss: 4.593266487121582	aux_loss: 0.8454791307449341
01:01:17 INFO - main: Train iter. 164700/200000 (82.35%): 	Loss: 5.325211048126221	recon_loss: 0.002433880465105176	bpp_loss: 4.5950469970703125	aux_loss: 0.4427032172679901
01:01:49 INFO - main: Train iter. 164800/200000 (82.4%): 	Loss: 5.329248428344727	recon_loss: 0.0024321102537214756	bpp_loss: 4.599615573883057	aux_loss: 0.8583617210388184
01:02:21 INFO - main: Train iter. 164900/200000 (82.45%): 	Loss: 5.322802543640137	recon_loss: 0.00242810626514256	bpp_loss: 4.5943708419799805	aux_loss: 0.7580065727233887
01:02:52 INFO - main: Train iter. 165000/200000 (82.5%): 	Loss: 5.330191135406494	recon_loss: 0.0024305253755301237	bpp_loss: 4.601033687591553	aux_loss: 0.2064271867275238
01:03:02 INFO - main: {'TEST MSE': 0.0024295840676763665, 'TEST BPP': 4.6162890625, 'TEST loss': 5.33082301902771, 'TEST recon_loss': 0.0024295841469429433, 'TEST bpp_loss': 4.601947776317596}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
01:03:34 INFO - main: Train iter. 165100/200000 (82.55%): 	Loss: 5.329986572265625	recon_loss: 0.0024332355242222548	bpp_loss: 4.600016117095947	aux_loss: 1.673452377319336
01:04:06 INFO - main: Train iter. 165200/200000 (82.6%): 	Loss: 5.319428443908691	recon_loss: 0.0024273775052279234	bpp_loss: 4.591215133666992	aux_loss: 0.5972023010253906
01:04:37 INFO - main: Train iter. 165300/200000 (82.65%): 	Loss: 5.321300983428955	recon_loss: 0.0024298769421875477	bpp_loss: 4.5923380851745605	aux_loss: 0.5517039895057678
01:05:09 INFO - main: Train iter. 165400/200000 (82.7%): 	Loss: 5.3290205001831055	recon_loss: 0.002424494829028845	bpp_loss: 4.601672172546387	aux_loss: 0.39135921001434326
01:05:42 INFO - main: Train iter. 165500/200000 (82.75%): 	Loss: 5.320250511169434	recon_loss: 0.0024298466742038727	bpp_loss: 4.591296672821045	aux_loss: 0.5570033192634583
01:06:13 INFO - main: Train iter. 165600/200000 (82.8%): 	Loss: 5.338475704193115	recon_loss: 0.002430931432172656	bpp_loss: 4.609196186065674	aux_loss: 0.28875845670700073
01:06:45 INFO - main: Train iter. 165700/200000 (82.85%): 	Loss: 5.330784320831299	recon_loss: 0.0024280084762722254	bpp_loss: 4.602381706237793	aux_loss: 0.8066266179084778
01:07:17 INFO - main: Train iter. 165800/200000 (82.9%): 	Loss: 5.348299503326416	recon_loss: 0.0024348723236471415	bpp_loss: 4.617837905883789	aux_loss: 0.28702619671821594
01:07:49 INFO - main: Train iter. 165900/200000 (82.95%): 	Loss: 5.3323845863342285	recon_loss: 0.00242782523855567	bpp_loss: 4.604036808013916	aux_loss: 0.656419038772583
01:08:20 INFO - main: Train iter. 166000/200000 (83.0%): 	Loss: 5.331098556518555	recon_loss: 0.0024372132029384375	bpp_loss: 4.5999345779418945	aux_loss: 0.44526350498199463
01:08:52 INFO - main: Train iter. 166100/200000 (83.05%): 	Loss: 5.3195929527282715	recon_loss: 0.0024241749197244644	bpp_loss: 4.592340469360352	aux_loss: 0.3748657703399658
01:09:24 INFO - main: Train iter. 166200/200000 (83.1%): 	Loss: 5.323054313659668	recon_loss: 0.0024279081262648106	bpp_loss: 4.594681739807129	aux_loss: 0.5506139397621155
01:09:55 INFO - main: Train iter. 166300/200000 (83.15%): 	Loss: 5.337948322296143	recon_loss: 0.0024367524310946465	bpp_loss: 4.606922626495361	aux_loss: 0.6985881328582764
01:10:27 INFO - main: Train iter. 166400/200000 (83.2%): 	Loss: 5.329640865325928	recon_loss: 0.0024406358134001493	bpp_loss: 4.597450256347656	aux_loss: 0.7332096695899963
01:10:59 INFO - main: Train iter. 166500/200000 (83.25%): 	Loss: 5.333786964416504	recon_loss: 0.0024294161703437567	bpp_loss: 4.60496187210083	aux_loss: 0.48935067653656006
01:11:30 INFO - main: Train iter. 166600/200000 (83.3%): 	Loss: 5.3299689292907715	recon_loss: 0.0024342192336916924	bpp_loss: 4.599703311920166	aux_loss: 0.2448987364768982
01:12:02 INFO - main: Train iter. 166700/200000 (83.35%): 	Loss: 5.346487522125244	recon_loss: 0.0024377561639994383	bpp_loss: 4.6151604652404785	aux_loss: 0.2774190604686737
01:12:35 INFO - main: Train iter. 166800/200000 (83.4%): 	Loss: 5.318540573120117	recon_loss: 0.0024332634638994932	bpp_loss: 4.588561534881592	aux_loss: 0.34799784421920776
01:13:07 INFO - main: Train iter. 166900/200000 (83.45%): 	Loss: 5.332838535308838	recon_loss: 0.002441193675622344	bpp_loss: 4.600480556488037	aux_loss: 0.7577264308929443
01:13:38 INFO - main: Train iter. 167000/200000 (83.5%): 	Loss: 5.335415840148926	recon_loss: 0.0024240303318947554	bpp_loss: 4.608206748962402	aux_loss: 0.3268539011478424
01:14:10 INFO - main: Train iter. 167100/200000 (83.55%): 	Loss: 5.319333076477051	recon_loss: 0.0024257844779640436	bpp_loss: 4.591597557067871	aux_loss: 0.23152077198028564
01:14:42 INFO - main: Train iter. 167200/200000 (83.6%): 	Loss: 5.330014705657959	recon_loss: 0.002424523001536727	bpp_loss: 4.602657794952393	aux_loss: 0.7895355224609375
01:15:13 INFO - main: Train iter. 167300/200000 (83.65%): 	Loss: 5.314913749694824	recon_loss: 0.0024245537351816893	bpp_loss: 4.587547779083252	aux_loss: 0.6838737726211548
01:15:45 INFO - main: Train iter. 167400/200000 (83.7%): 	Loss: 5.324284553527832	recon_loss: 0.002432285575196147	bpp_loss: 4.594598770141602	aux_loss: 0.29088282585144043
01:16:17 INFO - main: Train iter. 167500/200000 (83.75%): 	Loss: 5.324052810668945	recon_loss: 0.002427708590403199	bpp_loss: 4.59574031829834	aux_loss: 0.40592193603515625
01:16:48 INFO - main: Train iter. 167600/200000 (83.8%): 	Loss: 5.336252212524414	recon_loss: 0.002429771702736616	bpp_loss: 4.607320785522461	aux_loss: 0.8583955764770508
01:17:20 INFO - main: Train iter. 167700/200000 (83.85%): 	Loss: 5.335165023803711	recon_loss: 0.0024409620091319084	bpp_loss: 4.602876663208008	aux_loss: 0.9803045392036438
01:17:52 INFO - main: Train iter. 167800/200000 (83.9%): 	Loss: 5.319726943969727	recon_loss: 0.0024329014122486115	bpp_loss: 4.5898566246032715	aux_loss: 1.0854430198669434
01:18:23 INFO - main: Train iter. 167900/200000 (83.95%): 	Loss: 5.333691596984863	recon_loss: 0.0024295393377542496	bpp_loss: 4.604829788208008	aux_loss: 0.2240690439939499
01:18:55 INFO - main: Train iter. 168000/200000 (84.0%): 	Loss: 5.322884559631348	recon_loss: 0.002425183542072773	bpp_loss: 4.595329284667969	aux_loss: 0.36159640550613403
01:19:27 INFO - main: Train iter. 168100/200000 (84.05%): 	Loss: 5.325771808624268	recon_loss: 0.0024234610609710217	bpp_loss: 4.598733425140381	aux_loss: 0.2924421429634094
01:20:00 INFO - main: Train iter. 168200/200000 (84.1%): 	Loss: 5.335834503173828	recon_loss: 0.0024286992847919464	bpp_loss: 4.607224464416504	aux_loss: 0.7142180800437927
01:20:32 INFO - main: Train iter. 168300/200000 (84.15%): 	Loss: 5.339747905731201	recon_loss: 0.0024307139683514833	bpp_loss: 4.610533714294434	aux_loss: 0.2674916386604309
01:21:03 INFO - main: Train iter. 168400/200000 (84.2%): 	Loss: 5.31745719909668	recon_loss: 0.002423961414024234	bpp_loss: 4.590268611907959	aux_loss: 1.1268324851989746
01:21:35 INFO - main: Train iter. 168500/200000 (84.25%): 	Loss: 5.33633279800415	recon_loss: 0.0024308853317052126	bpp_loss: 4.607067108154297	aux_loss: 0.2216707170009613
01:22:07 INFO - main: Train iter. 168600/200000 (84.3%): 	Loss: 5.335334777832031	recon_loss: 0.0024255418684333563	bpp_loss: 4.607672214508057	aux_loss: 0.5558236241340637
01:22:39 INFO - main: Train iter. 168700/200000 (84.35%): 	Loss: 5.329282760620117	recon_loss: 0.002425726503133774	bpp_loss: 4.601564884185791	aux_loss: 0.9025766253471375
01:23:10 INFO - main: Train iter. 168800/200000 (84.4%): 	Loss: 5.320979595184326	recon_loss: 0.0024293079040944576	bpp_loss: 4.592187404632568	aux_loss: 0.5912109017372131
01:23:42 INFO - main: Train iter. 168900/200000 (84.45%): 	Loss: 5.327902317047119	recon_loss: 0.002426495309919119	bpp_loss: 4.599953651428223	aux_loss: 0.24286511540412903
01:24:14 INFO - main: Train iter. 169000/200000 (84.5%): 	Loss: 5.330808639526367	recon_loss: 0.002428468083962798	bpp_loss: 4.602268218994141	aux_loss: 0.5149391293525696
01:24:46 INFO - main: Train iter. 169100/200000 (84.55%): 	Loss: 5.32210636138916	recon_loss: 0.0024238652549684048	bpp_loss: 4.59494686126709	aux_loss: 0.4242886006832123
01:25:17 INFO - main: Train iter. 169200/200000 (84.6%): 	Loss: 5.310649871826172	recon_loss: 0.0024221704807132483	bpp_loss: 4.583998680114746	aux_loss: 0.35067111253738403
01:25:49 INFO - main: Train iter. 169300/200000 (84.65%): 	Loss: 5.331578254699707	recon_loss: 0.0024260415229946375	bpp_loss: 4.603765964508057	aux_loss: 1.0369493961334229
01:26:21 INFO - main: Train iter. 169400/200000 (84.7%): 	Loss: 5.334177494049072	recon_loss: 0.002432414097711444	bpp_loss: 4.604453086853027	aux_loss: 1.5779386758804321
01:26:52 INFO - main: Train iter. 169500/200000 (84.75%): 	Loss: 5.336867332458496	recon_loss: 0.002426185179501772	bpp_loss: 4.609011650085449	aux_loss: 0.5756210088729858
01:27:25 INFO - main: Train iter. 169600/200000 (84.8%): 	Loss: 5.331867694854736	recon_loss: 0.0024230200797319412	bpp_loss: 4.60496187210083	aux_loss: 0.2954874634742737
01:27:57 INFO - main: Train iter. 169700/200000 (84.85%): 	Loss: 5.315790176391602	recon_loss: 0.002427802886813879	bpp_loss: 4.587449073791504	aux_loss: 0.20844483375549316
01:28:29 INFO - main: Train iter. 169800/200000 (84.9%): 	Loss: 5.325968265533447	recon_loss: 0.0024321700911968946	bpp_loss: 4.596317291259766	aux_loss: 0.2984260618686676
01:29:00 INFO - main: Train iter. 169900/200000 (84.95%): 	Loss: 5.32951545715332	recon_loss: 0.00243331678211689	bpp_loss: 4.599520683288574	aux_loss: 0.16663037240505219
01:29:32 INFO - main: Train iter. 170000/200000 (85.0%): 	Loss: 5.3240556716918945	recon_loss: 0.0024423084687441587	bpp_loss: 4.591362953186035	aux_loss: 0.7447997331619263
01:29:42 INFO - main: {'TEST MSE': 0.0024300803294705214, 'TEST BPP': 4.6162734375, 'TEST loss': 5.331222274303436, 'TEST recon_loss': 0.0024300804103259, 'TEST bpp_loss': 4.602198154449463}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
01:30:14 INFO - main: Train iter. 170100/200000 (85.05%): 	Loss: 5.3315815925598145	recon_loss: 0.0024257933255285025	bpp_loss: 4.603843688964844	aux_loss: 0.3771626651287079
01:30:45 INFO - main: Train iter. 170200/200000 (85.1%): 	Loss: 5.32381010055542	recon_loss: 0.002429892774671316	bpp_loss: 4.594842433929443	aux_loss: 0.2559451460838318
01:31:17 INFO - main: Train iter. 170300/200000 (85.15%): 	Loss: 5.327597618103027	recon_loss: 0.0024221118073910475	bpp_loss: 4.600964069366455	aux_loss: 0.4708555340766907
01:31:49 INFO - main: Train iter. 170400/200000 (85.2%): 	Loss: 5.30808687210083	recon_loss: 0.0024302962701767683	bpp_loss: 4.57899808883667	aux_loss: 0.38403111696243286
01:32:21 INFO - main: Train iter. 170500/200000 (85.25%): 	Loss: 5.331501483917236	recon_loss: 0.0024362707044929266	bpp_loss: 4.600620269775391	aux_loss: 0.24761222302913666
01:32:52 INFO - main: Train iter. 170600/200000 (85.3%): 	Loss: 5.3273701667785645	recon_loss: 0.002442734083160758	bpp_loss: 4.594550132751465	aux_loss: 0.6866708397865295
01:33:24 INFO - main: Train iter. 170700/200000 (85.35%): 	Loss: 5.330554008483887	recon_loss: 0.002428962616249919	bpp_loss: 4.601865291595459	aux_loss: 0.5119049549102783
01:33:56 INFO - main: Train iter. 170800/200000 (85.4%): 	Loss: 5.333049774169922	recon_loss: 0.002439360599964857	bpp_loss: 4.601241588592529	aux_loss: 0.3661586046218872
01:34:29 INFO - main: Train iter. 170900/200000 (85.45%): 	Loss: 5.324656009674072	recon_loss: 0.002432032721117139	bpp_loss: 4.595046043395996	aux_loss: 0.6883111000061035
01:35:00 INFO - main: Train iter. 171000/200000 (85.5%): 	Loss: 5.328291893005371	recon_loss: 0.002437848597764969	bpp_loss: 4.59693717956543	aux_loss: 0.43187832832336426
01:35:32 INFO - main: Train iter. 171100/200000 (85.55%): 	Loss: 5.326676845550537	recon_loss: 0.0024341547396034002	bpp_loss: 4.59643030166626	aux_loss: 0.5303421020507812
01:36:04 INFO - main: Train iter. 171200/200000 (85.6%): 	Loss: 5.328798294067383	recon_loss: 0.0024288829881697893	bpp_loss: 4.600133419036865	aux_loss: 0.33971846103668213
01:36:35 INFO - main: Train iter. 171300/200000 (85.65%): 	Loss: 5.333071708679199	recon_loss: 0.002433544723317027	bpp_loss: 4.603008270263672	aux_loss: 0.23037125170230865
01:37:07 INFO - main: Train iter. 171400/200000 (85.7%): 	Loss: 5.327483654022217	recon_loss: 0.002431945176795125	bpp_loss: 4.597899913787842	aux_loss: 0.3151113986968994
01:37:39 INFO - main: Train iter. 171500/200000 (85.75%): 	Loss: 5.344993591308594	recon_loss: 0.002432239707559347	bpp_loss: 4.615321636199951	aux_loss: 0.41249242424964905
01:38:10 INFO - main: Train iter. 171600/200000 (85.8%): 	Loss: 5.318811416625977	recon_loss: 0.0024334576446563005	bpp_loss: 4.58877420425415	aux_loss: 0.7245410680770874
01:38:42 INFO - main: Train iter. 171700/200000 (85.85%): 	Loss: 5.331826210021973	recon_loss: 0.002429958898574114	bpp_loss: 4.602838516235352	aux_loss: 0.260029673576355
01:39:14 INFO - main: Train iter. 171800/200000 (85.9%): 	Loss: 5.323300361633301	recon_loss: 0.0024318229407072067	bpp_loss: 4.593753337860107	aux_loss: 1.2121531963348389
01:39:45 INFO - main: Train iter. 171900/200000 (85.95%): 	Loss: 5.328126907348633	recon_loss: 0.002425976563245058	bpp_loss: 4.600334167480469	aux_loss: 0.9148473143577576
01:40:17 INFO - main: Train iter. 172000/200000 (86.0%): 	Loss: 5.323000431060791	recon_loss: 0.0024266885593533516	bpp_loss: 4.594994068145752	aux_loss: 0.35521626472473145
01:40:48 INFO - main: Train iter. 172100/200000 (86.05%): 	Loss: 5.324460983276367	recon_loss: 0.0024302853271365166	bpp_loss: 4.5953755378723145	aux_loss: 0.5321577787399292
01:41:20 INFO - main: Train iter. 172200/200000 (86.1%): 	Loss: 5.337512969970703	recon_loss: 0.0024307735729962587	bpp_loss: 4.608280658721924	aux_loss: 1.2622631788253784
01:41:53 INFO - main: Train iter. 172300/200000 (86.15%): 	Loss: 5.321044921875	recon_loss: 0.0024328604340553284	bpp_loss: 4.591187000274658	aux_loss: 0.4427613317966461
01:42:25 INFO - main: Train iter. 172400/200000 (86.2%): 	Loss: 5.3366570472717285	recon_loss: 0.002432455075904727	bpp_loss: 4.6069207191467285	aux_loss: 0.6577246785163879
01:42:57 INFO - main: Train iter. 172500/200000 (86.25%): 	Loss: 5.338037967681885	recon_loss: 0.0024279511999338865	bpp_loss: 4.609652519226074	aux_loss: 0.221848726272583
01:43:28 INFO - main: Train iter. 172600/200000 (86.3%): 	Loss: 5.3333539962768555	recon_loss: 0.0024360681418329477	bpp_loss: 4.60253381729126	aux_loss: 0.5587119460105896
01:44:00 INFO - main: Train iter. 172700/200000 (86.35%): 	Loss: 5.330236911773682	recon_loss: 0.002428476233035326	bpp_loss: 4.601694107055664	aux_loss: 0.3732333183288574
01:44:32 INFO - main: Train iter. 172800/200000 (86.4%): 	Loss: 5.3134446144104	recon_loss: 0.0024282962549477816	bpp_loss: 4.58495569229126	aux_loss: 0.7801165580749512
01:45:03 INFO - main: Train iter. 172900/200000 (86.45%): 	Loss: 5.328135967254639	recon_loss: 0.0024340818636119366	bpp_loss: 4.597911357879639	aux_loss: 0.6590079069137573
01:45:35 INFO - main: Train iter. 173000/200000 (86.5%): 	Loss: 5.32871675491333	recon_loss: 0.0024353540502488613	bpp_loss: 4.598110675811768	aux_loss: 0.4603384733200073
01:46:07 INFO - main: Train iter. 173100/200000 (86.55%): 	Loss: 5.328791618347168	recon_loss: 0.002436903538182378	bpp_loss: 4.597720623016357	aux_loss: 0.9599077701568604
01:46:39 INFO - main: Train iter. 173200/200000 (86.6%): 	Loss: 5.324110984802246	recon_loss: 0.0024388607125729322	bpp_loss: 4.592452526092529	aux_loss: 1.1398730278015137
01:47:10 INFO - main: Train iter. 173300/200000 (86.65%): 	Loss: 5.331521511077881	recon_loss: 0.0024301609955728054	bpp_loss: 4.602473258972168	aux_loss: 0.38379186391830444
01:47:42 INFO - main: Train iter. 173400/200000 (86.7%): 	Loss: 5.33610725402832	recon_loss: 0.0024344082921743393	bpp_loss: 4.605784893035889	aux_loss: 0.3746042847633362
01:48:14 INFO - main: Train iter. 173500/200000 (86.75%): 	Loss: 5.322710990905762	recon_loss: 0.0024278510827571154	bpp_loss: 4.594355583190918	aux_loss: 0.35823363065719604
01:48:45 INFO - main: Train iter. 173600/200000 (86.8%): 	Loss: 5.327892303466797	recon_loss: 0.0024224394001066685	bpp_loss: 4.601160526275635	aux_loss: 0.6879599094390869
01:49:18 INFO - main: Train iter. 173700/200000 (86.85%): 	Loss: 5.3337721824646	recon_loss: 0.002423661993816495	bpp_loss: 4.606673717498779	aux_loss: 0.2574141025543213
01:49:50 INFO - main: Train iter. 173800/200000 (86.9%): 	Loss: 5.329862594604492	recon_loss: 0.0024383943527936935	bpp_loss: 4.598344326019287	aux_loss: 1.2485475540161133
01:50:22 INFO - main: Train iter. 173900/200000 (86.95%): 	Loss: 5.321071624755859	recon_loss: 0.002429154235869646	bpp_loss: 4.592325210571289	aux_loss: 0.9646511077880859
01:50:53 INFO - main: Train iter. 174000/200000 (87.0%): 	Loss: 5.321038246154785	recon_loss: 0.0024284173268824816	bpp_loss: 4.592513084411621	aux_loss: 0.310317724943161
01:51:25 INFO - main: Train iter. 174100/200000 (87.05%): 	Loss: 5.3197197914123535	recon_loss: 0.002426255727186799	bpp_loss: 4.591843128204346	aux_loss: 0.3912925124168396
01:51:57 INFO - main: Train iter. 174200/200000 (87.1%): 	Loss: 5.3398308753967285	recon_loss: 0.00243580830283463	bpp_loss: 4.60908842086792	aux_loss: 0.2919193506240845
01:52:28 INFO - main: Train iter. 174300/200000 (87.15%): 	Loss: 5.335184574127197	recon_loss: 0.0024345749989151955	bpp_loss: 4.604812145233154	aux_loss: 0.3845071792602539
01:53:00 INFO - main: Train iter. 174400/200000 (87.2%): 	Loss: 5.3310546875	recon_loss: 0.0024289514403790236	bpp_loss: 4.60236930847168	aux_loss: 0.21931414306163788
01:53:32 INFO - main: Train iter. 174500/200000 (87.25%): 	Loss: 5.32816743850708	recon_loss: 0.0024350876919925213	bpp_loss: 4.5976409912109375	aux_loss: 0.28322356939315796
01:54:04 INFO - main: Train iter. 174600/200000 (87.3%): 	Loss: 5.314639568328857	recon_loss: 0.002426551654934883	bpp_loss: 4.586674213409424	aux_loss: 1.111506700515747
01:54:35 INFO - main: Train iter. 174700/200000 (87.35%): 	Loss: 5.328069686889648	recon_loss: 0.002430784283205867	bpp_loss: 4.59883451461792	aux_loss: 0.4645272493362427
01:55:07 INFO - main: Train iter. 174800/200000 (87.4%): 	Loss: 5.325962543487549	recon_loss: 0.0024235290475189686	bpp_loss: 4.598903656005859	aux_loss: 0.5814598798751831
01:55:39 INFO - main: Train iter. 174900/200000 (87.45%): 	Loss: 5.3366312980651855	recon_loss: 0.0024259784258902073	bpp_loss: 4.608837604522705	aux_loss: 0.8561264276504517
01:56:12 INFO - main: Train iter. 175000/200000 (87.5%): 	Loss: 5.323795318603516	recon_loss: 0.0024323719553649426	bpp_loss: 4.594083786010742	aux_loss: 0.6747263669967651
01:56:22 INFO - main: {'TEST MSE': 0.002440882432694492, 'TEST BPP': 4.616, 'TEST loss': 5.333494505882263, 'TEST recon_loss': 0.00244088251539506, 'TEST bpp_loss': 4.6012297496795656}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
01:56:54 INFO - main: Train iter. 175100/200000 (87.55%): 	Loss: 5.335600852966309	recon_loss: 0.0024292278103530407	bpp_loss: 4.606832504272461	aux_loss: 0.2652670443058014
01:57:25 INFO - main: Train iter. 175200/200000 (87.6%): 	Loss: 5.329344272613525	recon_loss: 0.002437588991597295	bpp_loss: 4.598067760467529	aux_loss: 0.5510165691375732
01:57:57 INFO - main: Train iter. 175300/200000 (87.65%): 	Loss: 5.321272850036621	recon_loss: 0.002428435254842043	bpp_loss: 4.592742443084717	aux_loss: 1.1473803520202637
01:58:29 INFO - main: Train iter. 175400/200000 (87.7%): 	Loss: 5.347175121307373	recon_loss: 0.002439189236611128	bpp_loss: 4.615418434143066	aux_loss: 1.3761276006698608
01:59:00 INFO - main: Train iter. 175500/200000 (87.75%): 	Loss: 5.329785346984863	recon_loss: 0.0024303316604346037	bpp_loss: 4.6006855964660645	aux_loss: 0.2270762175321579
01:59:32 INFO - main: Train iter. 175600/200000 (87.8%): 	Loss: 5.327845573425293	recon_loss: 0.002424362115561962	bpp_loss: 4.600536823272705	aux_loss: 0.8291792869567871
02:00:03 INFO - main: Train iter. 175700/200000 (87.85%): 	Loss: 5.336216926574707	recon_loss: 0.0024351447355002165	bpp_loss: 4.605673313140869	aux_loss: 0.8130372762680054
02:00:35 INFO - main: Train iter. 175800/200000 (87.9%): 	Loss: 5.32954216003418	recon_loss: 0.0024265185929834843	bpp_loss: 4.601586818695068	aux_loss: 0.607207179069519
02:01:07 INFO - main: Train iter. 175900/200000 (87.95%): 	Loss: 5.339817523956299	recon_loss: 0.0024368243757635355	bpp_loss: 4.608770370483398	aux_loss: 1.1816365718841553
02:01:38 INFO - main: Train iter. 176000/200000 (88.0%): 	Loss: 5.334687232971191	recon_loss: 0.002430490916594863	bpp_loss: 4.605539798736572	aux_loss: 0.348679780960083
02:02:10 INFO - main: Train iter. 176100/200000 (88.05%): 	Loss: 5.325125217437744	recon_loss: 0.0024332094471901655	bpp_loss: 4.595162391662598	aux_loss: 0.6979023218154907
02:02:42 INFO - main: Train iter. 176200/200000 (88.1%): 	Loss: 5.329880714416504	recon_loss: 0.0024312955792993307	bpp_loss: 4.600492000579834	aux_loss: 0.351804256439209
02:03:13 INFO - main: Train iter. 176300/200000 (88.15%): 	Loss: 5.319808483123779	recon_loss: 0.0024357703514397144	bpp_loss: 4.589077472686768	aux_loss: 0.6298239827156067
02:03:46 INFO - main: Train iter. 176400/200000 (88.2%): 	Loss: 5.324501037597656	recon_loss: 0.0024316904600709677	bpp_loss: 4.594994068145752	aux_loss: 0.34883546829223633
02:04:18 INFO - main: Train iter. 176500/200000 (88.25%): 	Loss: 5.330464839935303	recon_loss: 0.0024239448830485344	bpp_loss: 4.603281497955322	aux_loss: 0.498188316822052
02:04:50 INFO - main: Train iter. 176600/200000 (88.3%): 	Loss: 5.3169026374816895	recon_loss: 0.0024322066456079483	bpp_loss: 4.587240695953369	aux_loss: 0.29307156801223755
02:05:21 INFO - main: Train iter. 176700/200000 (88.35%): 	Loss: 5.346042156219482	recon_loss: 0.0024399745743721724	bpp_loss: 4.614049911499023	aux_loss: 0.3092220425605774
02:05:53 INFO - main: Train iter. 176800/200000 (88.4%): 	Loss: 5.321888446807861	recon_loss: 0.0024303982499986887	bpp_loss: 4.592769145965576	aux_loss: 0.7272897958755493
02:06:25 INFO - main: Train iter. 176900/200000 (88.45%): 	Loss: 5.342668533325195	recon_loss: 0.002427989849820733	bpp_loss: 4.614271640777588	aux_loss: 0.5293416976928711
02:06:57 INFO - main: Train iter. 177000/200000 (88.5%): 	Loss: 5.321781635284424	recon_loss: 0.0024313677567988634	bpp_loss: 4.592371463775635	aux_loss: 0.6508493423461914
02:07:28 INFO - main: Train iter. 177100/200000 (88.55%): 	Loss: 5.328005313873291	recon_loss: 0.0024308091960847378	bpp_loss: 4.598762512207031	aux_loss: 0.5173203349113464
02:08:00 INFO - main: Train iter. 177200/200000 (88.6%): 	Loss: 5.316019058227539	recon_loss: 0.0024254436139017344	bpp_loss: 4.588386058807373	aux_loss: 0.6243058443069458
02:08:32 INFO - main: Train iter. 177300/200000 (88.65%): 	Loss: 5.330331325531006	recon_loss: 0.002432793378829956	bpp_loss: 4.600493431091309	aux_loss: 0.576765775680542
02:09:04 INFO - main: Train iter. 177400/200000 (88.7%): 	Loss: 5.328034400939941	recon_loss: 0.0024300471413880587	bpp_loss: 4.599020004272461	aux_loss: 0.30593037605285645
02:09:35 INFO - main: Train iter. 177500/200000 (88.75%): 	Loss: 5.335305690765381	recon_loss: 0.002430445048958063	bpp_loss: 4.60617208480835	aux_loss: 0.29086053371429443
02:10:07 INFO - main: Train iter. 177600/200000 (88.8%): 	Loss: 5.332525730133057	recon_loss: 0.0024333184119313955	bpp_loss: 4.602530002593994	aux_loss: 0.2886784076690674
02:10:39 INFO - main: Train iter. 177700/200000 (88.85%): 	Loss: 5.337778568267822	recon_loss: 0.0024361913092434406	bpp_loss: 4.606921195983887	aux_loss: 0.6846411824226379
02:11:12 INFO - main: Train iter. 177800/200000 (88.9%): 	Loss: 5.318052291870117	recon_loss: 0.0024301784578710794	bpp_loss: 4.588998794555664	aux_loss: 0.5626723170280457
02:11:44 INFO - main: Train iter. 177900/200000 (88.95%): 	Loss: 5.3245930671691895	recon_loss: 0.0024294841568917036	bpp_loss: 4.595747947692871	aux_loss: 0.4614923298358917
02:12:15 INFO - main: Train iter. 178000/200000 (89.0%): 	Loss: 5.329041957855225	recon_loss: 0.0024310285225510597	bpp_loss: 4.599733352661133	aux_loss: 0.3155288100242615
02:12:47 INFO - main: Train iter. 178100/200000 (89.05%): 	Loss: 5.342576026916504	recon_loss: 0.002438671188428998	bpp_loss: 4.6109747886657715	aux_loss: 0.7138285040855408
02:13:19 INFO - main: Train iter. 178200/200000 (89.1%): 	Loss: 5.328484535217285	recon_loss: 0.002424398437142372	bpp_loss: 4.601164817810059	aux_loss: 0.8880234956741333
02:13:50 INFO - main: Train iter. 178300/200000 (89.15%): 	Loss: 5.330389022827148	recon_loss: 0.002434689085930586	bpp_loss: 4.599982261657715	aux_loss: 1.1279301643371582
02:14:22 INFO - main: Train iter. 178400/200000 (89.2%): 	Loss: 5.322066307067871	recon_loss: 0.002432473935186863	bpp_loss: 4.592324256896973	aux_loss: 0.3253890872001648
02:14:54 INFO - main: Train iter. 178500/200000 (89.25%): 	Loss: 5.336736679077148	recon_loss: 0.0024271055590361357	bpp_loss: 4.608604907989502	aux_loss: 0.2989284098148346
02:15:26 INFO - main: Train iter. 178600/200000 (89.3%): 	Loss: 5.342503547668457	recon_loss: 0.0024283200036734343	bpp_loss: 4.614007472991943	aux_loss: 0.34271448850631714
02:15:57 INFO - main: Train iter. 178700/200000 (89.35%): 	Loss: 5.322267532348633	recon_loss: 0.002436812501400709	bpp_loss: 4.59122371673584	aux_loss: 0.5297632813453674
02:16:29 INFO - main: Train iter. 178800/200000 (89.4%): 	Loss: 5.332962512969971	recon_loss: 0.0024294499307870865	bpp_loss: 4.604127407073975	aux_loss: 0.23390686511993408
02:17:01 INFO - main: Train iter. 178900/200000 (89.45%): 	Loss: 5.325469970703125	recon_loss: 0.0024255162570625544	bpp_loss: 4.597815036773682	aux_loss: 0.9355591535568237
02:17:32 INFO - main: Train iter. 179000/200000 (89.5%): 	Loss: 5.336341381072998	recon_loss: 0.002427214290946722	bpp_loss: 4.608177185058594	aux_loss: 0.4526401162147522
02:18:05 INFO - main: Train iter. 179100/200000 (89.55%): 	Loss: 5.323399543762207	recon_loss: 0.002426046645268798	bpp_loss: 4.595585346221924	aux_loss: 0.5360923409461975
02:18:37 INFO - main: Train iter. 179200/200000 (89.6%): 	Loss: 5.326119422912598	recon_loss: 0.002424266654998064	bpp_loss: 4.598839282989502	aux_loss: 0.7687017917633057
02:19:09 INFO - main: Train iter. 179300/200000 (89.65%): 	Loss: 5.322714805603027	recon_loss: 0.002434640657156706	bpp_loss: 4.59232234954834	aux_loss: 0.25409066677093506
02:19:41 INFO - main: Train iter. 179400/200000 (89.7%): 	Loss: 5.332645893096924	recon_loss: 0.0024257402401417494	bpp_loss: 4.604923725128174	aux_loss: 1.2796516418457031
02:20:12 INFO - main: Train iter. 179500/200000 (89.75%): 	Loss: 5.323571681976318	recon_loss: 0.0024267612025141716	bpp_loss: 4.595543384552002	aux_loss: 0.20129476487636566
02:20:44 INFO - main: Train iter. 179600/200000 (89.8%): 	Loss: 5.328945159912109	recon_loss: 0.002424029866233468	bpp_loss: 4.601736068725586	aux_loss: 0.47228431701660156
02:21:16 INFO - main: Train iter. 179700/200000 (89.85%): 	Loss: 5.335082054138184	recon_loss: 0.002427628729492426	bpp_loss: 4.606793403625488	aux_loss: 1.1553092002868652
02:21:47 INFO - main: Train iter. 179800/200000 (89.9%): 	Loss: 5.3272199630737305	recon_loss: 0.002428589155897498	bpp_loss: 4.5986433029174805	aux_loss: 0.3547668755054474
02:22:19 INFO - main: Train iter. 179900/200000 (89.95%): 	Loss: 5.323643684387207	recon_loss: 0.0024252005387097597	bpp_loss: 4.596083641052246	aux_loss: 0.35206836462020874
02:22:51 INFO - main: Train iter. 180000/200000 (90.0%): 	Loss: 5.336434364318848	recon_loss: 0.0024250373244285583	bpp_loss: 4.608923435211182	aux_loss: 0.45010820031166077
02:23:01 INFO - main: {'TEST MSE': 0.0024208382411779455, 'TEST BPP': 4.617046875, 'TEST loss': 5.328851010322571, 'TEST recon_loss': 0.002420838319929317, 'TEST bpp_loss': 4.602599511623382}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
02:23:32 INFO - main: Train iter. 180100/200000 (90.05%): 	Loss: 5.337642669677734	recon_loss: 0.002429741667583585	bpp_loss: 4.608720302581787	aux_loss: 0.9480382204055786
02:24:04 INFO - main: Train iter. 180200/200000 (90.1%): 	Loss: 5.3274431228637695	recon_loss: 0.00243322248570621	bpp_loss: 4.597476482391357	aux_loss: 0.2336384356021881
02:24:36 INFO - main: Train iter. 180300/200000 (90.15%): 	Loss: 5.3262481689453125	recon_loss: 0.0024374283384531736	bpp_loss: 4.595019817352295	aux_loss: 0.6230640411376953
02:25:07 INFO - main: Train iter. 180400/200000 (90.2%): 	Loss: 5.33538293838501	recon_loss: 0.0024253763258457184	bpp_loss: 4.607769966125488	aux_loss: 0.27844756841659546
02:25:40 INFO - main: Train iter. 180500/200000 (90.25%): 	Loss: 5.327437400817871	recon_loss: 0.0024310224689543247	bpp_loss: 4.598130702972412	aux_loss: 0.46285828948020935
02:26:12 INFO - main: Train iter. 180600/200000 (90.3%): 	Loss: 5.315309524536133	recon_loss: 0.002428642241284251	bpp_loss: 4.586716651916504	aux_loss: 1.3680059909820557
02:26:44 INFO - main: Train iter. 180700/200000 (90.35%): 	Loss: 5.32546854019165	recon_loss: 0.0024274250026792288	bpp_loss: 4.597240924835205	aux_loss: 0.48922744393348694
02:27:15 INFO - main: Train iter. 180800/200000 (90.4%): 	Loss: 5.3334059715271	recon_loss: 0.002429555170238018	bpp_loss: 4.604539394378662	aux_loss: 1.0883092880249023
02:27:47 INFO - main: Train iter. 180900/200000 (90.45%): 	Loss: 5.324496746063232	recon_loss: 0.0024226107634603977	bpp_loss: 4.597713470458984	aux_loss: 0.3484676480293274
02:28:19 INFO - main: Train iter. 181000/200000 (90.5%): 	Loss: 5.33345890045166	recon_loss: 0.002438523806631565	bpp_loss: 4.601901531219482	aux_loss: 0.4505968689918518
02:28:50 INFO - main: Train iter. 181100/200000 (90.55%): 	Loss: 5.333230972290039	recon_loss: 0.0024311328306794167	bpp_loss: 4.603891372680664	aux_loss: 0.21937698125839233
02:29:22 INFO - main: Train iter. 181200/200000 (90.6%): 	Loss: 5.333996772766113	recon_loss: 0.0024538999423384666	bpp_loss: 4.597826957702637	aux_loss: 0.503842294216156
02:29:54 INFO - main: Train iter. 181300/200000 (90.65%): 	Loss: 5.328454494476318	recon_loss: 0.0024367920123040676	bpp_loss: 4.597416877746582	aux_loss: 0.33673542737960815
02:30:25 INFO - main: Train iter. 181400/200000 (90.7%): 	Loss: 5.331712245941162	recon_loss: 0.0024373929481953382	bpp_loss: 4.600494384765625	aux_loss: 1.0290615558624268
02:30:57 INFO - main: Train iter. 181500/200000 (90.75%): 	Loss: 5.32504415512085	recon_loss: 0.0024428400211036205	bpp_loss: 4.59219217300415	aux_loss: 0.30138570070266724
02:31:29 INFO - main: Train iter. 181600/200000 (90.8%): 	Loss: 5.333977699279785	recon_loss: 0.0024408474564552307	bpp_loss: 4.601723670959473	aux_loss: 0.3881354331970215
02:32:00 INFO - main: Train iter. 181700/200000 (90.85%): 	Loss: 5.331579685211182	recon_loss: 0.002428018720820546	bpp_loss: 4.603174209594727	aux_loss: 0.7972630858421326
02:32:32 INFO - main: Train iter. 181800/200000 (90.9%): 	Loss: 5.3334174156188965	recon_loss: 0.0024333051405847073	bpp_loss: 4.603425979614258	aux_loss: 0.571770429611206
02:33:05 INFO - main: Train iter. 181900/200000 (90.95%): 	Loss: 5.328034400939941	recon_loss: 0.00243670423515141	bpp_loss: 4.597023010253906	aux_loss: 0.32081523537635803
02:33:37 INFO - main: Train iter. 182000/200000 (91.0%): 	Loss: 5.323307991027832	recon_loss: 0.002432358218356967	bpp_loss: 4.593600749969482	aux_loss: 0.8781415820121765
02:34:08 INFO - main: Train iter. 182100/200000 (91.05%): 	Loss: 5.326131343841553	recon_loss: 0.002429430140182376	bpp_loss: 4.597302436828613	aux_loss: 1.7008106708526611
02:34:40 INFO - main: Train iter. 182200/200000 (91.1%): 	Loss: 5.33243465423584	recon_loss: 0.002431048545986414	bpp_loss: 4.603119850158691	aux_loss: 0.40984243154525757
02:35:12 INFO - main: Train iter. 182300/200000 (91.15%): 	Loss: 5.328267574310303	recon_loss: 0.002428605919703841	bpp_loss: 4.5996856689453125	aux_loss: 0.2307146191596985
02:35:43 INFO - main: Train iter. 182400/200000 (91.2%): 	Loss: 5.3234992027282715	recon_loss: 0.0024291069712489843	bpp_loss: 4.594767093658447	aux_loss: 1.165773630142212
02:36:15 INFO - main: Train iter. 182500/200000 (91.25%): 	Loss: 5.317954063415527	recon_loss: 0.002430067164823413	bpp_loss: 4.588933944702148	aux_loss: 0.9737981557846069
02:36:47 INFO - main: Train iter. 182600/200000 (91.3%): 	Loss: 5.32611083984375	recon_loss: 0.0024234328884631395	bpp_loss: 4.599081039428711	aux_loss: 0.4860096573829651
02:37:18 INFO - main: Train iter. 182700/200000 (91.35%): 	Loss: 5.329916000366211	recon_loss: 0.0024327589198946953	bpp_loss: 4.600088119506836	aux_loss: 0.27132534980773926
02:37:50 INFO - main: Train iter. 182800/200000 (91.4%): 	Loss: 5.328056335449219	recon_loss: 0.002430353546515107	bpp_loss: 4.598950386047363	aux_loss: 0.43727514147758484
02:38:22 INFO - main: Train iter. 182900/200000 (91.45%): 	Loss: 5.331725120544434	recon_loss: 0.0024267975240945816	bpp_loss: 4.6036858558654785	aux_loss: 0.45562148094177246
02:38:53 INFO - main: Train iter. 183000/200000 (91.5%): 	Loss: 5.320993423461914	recon_loss: 0.002424306236207485	bpp_loss: 4.593701362609863	aux_loss: 0.3289265036582947
02:39:25 INFO - main: Train iter. 183100/200000 (91.55%): 	Loss: 5.317009449005127	recon_loss: 0.0024253004230558872	bpp_loss: 4.589419364929199	aux_loss: 0.6725728511810303
02:39:58 INFO - main: Train iter. 183200/200000 (91.6%): 	Loss: 5.31596565246582	recon_loss: 0.002429828979074955	bpp_loss: 4.587017059326172	aux_loss: 0.5322098731994629
02:40:30 INFO - main: Train iter. 183300/200000 (91.65%): 	Loss: 5.325795650482178	recon_loss: 0.0024216051679104567	bpp_loss: 4.599314212799072	aux_loss: 0.2725514769554138
02:41:02 INFO - main: Train iter. 183400/200000 (91.7%): 	Loss: 5.327141284942627	recon_loss: 0.002449122490361333	bpp_loss: 4.592404365539551	aux_loss: 0.2149209827184677
02:41:33 INFO - main: Train iter. 183500/200000 (91.75%): 	Loss: 5.320805549621582	recon_loss: 0.002424090402200818	bpp_loss: 4.593578338623047	aux_loss: 0.3894774317741394
02:42:05 INFO - main: Train iter. 183600/200000 (91.8%): 	Loss: 5.32411003112793	recon_loss: 0.002427709521725774	bpp_loss: 4.595797061920166	aux_loss: 0.8121576905250549
02:42:37 INFO - main: Train iter. 183700/200000 (91.85%): 	Loss: 5.330841541290283	recon_loss: 0.002427102765068412	bpp_loss: 4.602710723876953	aux_loss: 0.7748273015022278
02:43:08 INFO - main: Train iter. 183800/200000 (91.9%): 	Loss: 5.322680950164795	recon_loss: 0.0024215560406446457	bpp_loss: 4.596214294433594	aux_loss: 0.3006504774093628
02:43:40 INFO - main: Train iter. 183900/200000 (91.95%): 	Loss: 5.322272777557373	recon_loss: 0.0024313898757100105	bpp_loss: 4.592855930328369	aux_loss: 0.2826045751571655
02:44:12 INFO - main: Train iter. 184000/200000 (92.0%): 	Loss: 5.327001571655273	recon_loss: 0.002455100417137146	bpp_loss: 4.590471267700195	aux_loss: 0.8289661407470703
02:44:43 INFO - main: Train iter. 184100/200000 (92.05%): 	Loss: 5.3346452713012695	recon_loss: 0.0024504854809492826	bpp_loss: 4.599499702453613	aux_loss: 0.27690035104751587
02:45:15 INFO - main: Train iter. 184200/200000 (92.1%): 	Loss: 5.332598686218262	recon_loss: 0.0024313065223395824	bpp_loss: 4.603206634521484	aux_loss: 0.4098891317844391
02:45:47 INFO - main: Train iter. 184300/200000 (92.15%): 	Loss: 5.3257646560668945	recon_loss: 0.0024389473255723715	bpp_loss: 4.594080448150635	aux_loss: 0.598389744758606
02:46:18 INFO - main: Train iter. 184400/200000 (92.2%): 	Loss: 5.322281837463379	recon_loss: 0.0024289428256452084	bpp_loss: 4.59359884262085	aux_loss: 0.5795254111289978
02:46:50 INFO - main: Train iter. 184500/200000 (92.25%): 	Loss: 5.323428630828857	recon_loss: 0.002430583583191037	bpp_loss: 4.5942535400390625	aux_loss: 0.9117640852928162
02:47:23 INFO - main: Train iter. 184600/200000 (92.3%): 	Loss: 5.332461357116699	recon_loss: 0.002437487943097949	bpp_loss: 4.60121488571167	aux_loss: 0.37236130237579346
02:47:55 INFO - main: Train iter. 184700/200000 (92.35%): 	Loss: 5.327049732208252	recon_loss: 0.0024322704412043095	bpp_loss: 4.5973687171936035	aux_loss: 1.050931453704834
02:48:26 INFO - main: Train iter. 184800/200000 (92.4%): 	Loss: 5.334123611450195	recon_loss: 0.0024312192108482122	bpp_loss: 4.604757785797119	aux_loss: 0.29948675632476807
02:48:58 INFO - main: Train iter. 184900/200000 (92.45%): 	Loss: 5.320327281951904	recon_loss: 0.002423974685370922	bpp_loss: 4.593134880065918	aux_loss: 0.24154438078403473
02:49:30 INFO - main: Train iter. 185000/200000 (92.5%): 	Loss: 5.328199863433838	recon_loss: 0.0024277004413306713	bpp_loss: 4.599889755249023	aux_loss: 0.5954872369766235
02:49:40 INFO - main: {'TEST MSE': 0.002425315972527357, 'TEST BPP': 4.61625, 'TEST loss': 5.329777875900269, 'TEST recon_loss': 0.002425316053442657, 'TEST bpp_loss': 4.602183055877686}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
02:50:12 INFO - main: Train iter. 185100/200000 (92.55%): 	Loss: 5.320653915405273	recon_loss: 0.002428006613627076	bpp_loss: 4.592251777648926	aux_loss: 0.6212279796600342
02:50:43 INFO - main: Train iter. 185200/200000 (92.6%): 	Loss: 5.322352886199951	recon_loss: 0.0024250096175819635	bpp_loss: 4.594850063323975	aux_loss: 0.6346378326416016
02:51:15 INFO - main: Train iter. 185300/200000 (92.65%): 	Loss: 5.332221031188965	recon_loss: 0.0024323626421391964	bpp_loss: 4.602512359619141	aux_loss: 0.26771706342697144
02:51:47 INFO - main: Train iter. 185400/200000 (92.7%): 	Loss: 5.340719699859619	recon_loss: 0.0024273290764540434	bpp_loss: 4.612521171569824	aux_loss: 0.3290640711784363
02:52:18 INFO - main: Train iter. 185500/200000 (92.75%): 	Loss: 5.330481052398682	recon_loss: 0.002427453873679042	bpp_loss: 4.602244853973389	aux_loss: 0.7271303534507751
02:52:50 INFO - main: Train iter. 185600/200000 (92.8%): 	Loss: 5.329028606414795	recon_loss: 0.002425377955660224	bpp_loss: 4.601415157318115	aux_loss: 0.17572233080863953
02:53:22 INFO - main: Train iter. 185700/200000 (92.85%): 	Loss: 5.32078742980957	recon_loss: 0.002427379135042429	bpp_loss: 4.592573642730713	aux_loss: 0.6258759498596191
02:53:53 INFO - main: Train iter. 185800/200000 (92.9%): 	Loss: 5.331173419952393	recon_loss: 0.002426678081974387	bpp_loss: 4.603169918060303	aux_loss: 0.35711193084716797
02:54:25 INFO - main: Train iter. 185900/200000 (92.95%): 	Loss: 5.329503536224365	recon_loss: 0.002427318599075079	bpp_loss: 4.6013078689575195	aux_loss: 0.27292829751968384
02:54:58 INFO - main: Train iter. 186000/200000 (93.0%): 	Loss: 5.328787803649902	recon_loss: 0.0024259015917778015	bpp_loss: 4.601017475128174	aux_loss: 0.314755380153656
02:55:30 INFO - main: Train iter. 186100/200000 (93.05%): 	Loss: 5.331684112548828	recon_loss: 0.0024279861245304346	bpp_loss: 4.603288173675537	aux_loss: 0.4071900546550751
02:56:02 INFO - main: Train iter. 186200/200000 (93.1%): 	Loss: 5.338033676147461	recon_loss: 0.0024264075327664614	bpp_loss: 4.610111236572266	aux_loss: 0.31513768434524536
02:56:34 INFO - main: Train iter. 186300/200000 (93.15%): 	Loss: 5.33898401260376	recon_loss: 0.002426363527774811	bpp_loss: 4.611074924468994	aux_loss: 0.2214515060186386
02:57:05 INFO - main: Train iter. 186400/200000 (93.2%): 	Loss: 5.323986530303955	recon_loss: 0.0024242850486189127	bpp_loss: 4.596701145172119	aux_loss: 0.23515143990516663
02:57:37 INFO - main: Train iter. 186500/200000 (93.25%): 	Loss: 5.338413715362549	recon_loss: 0.0024256298784166574	bpp_loss: 4.610724925994873	aux_loss: 0.27352026104927063
02:58:09 INFO - main: Train iter. 186600/200000 (93.3%): 	Loss: 5.321639537811279	recon_loss: 0.0024337994400411844	bpp_loss: 4.5914998054504395	aux_loss: 1.2267324924468994
02:58:40 INFO - main: Train iter. 186700/200000 (93.35%): 	Loss: 5.337128639221191	recon_loss: 0.0024278333876281977	bpp_loss: 4.608778476715088	aux_loss: 0.2289096564054489
02:59:12 INFO - main: Train iter. 186800/200000 (93.4%): 	Loss: 5.317845821380615	recon_loss: 0.002427566796541214	bpp_loss: 4.58957576751709	aux_loss: 0.28180408477783203
02:59:44 INFO - main: Train iter. 186900/200000 (93.45%): 	Loss: 5.328763008117676	recon_loss: 0.0024246685206890106	bpp_loss: 4.601362705230713	aux_loss: 0.5623903870582581
03:00:15 INFO - main: Train iter. 187000/200000 (93.5%): 	Loss: 5.328406810760498	recon_loss: 0.0024239677004516125	bpp_loss: 4.6012163162231445	aux_loss: 0.5644627213478088
03:00:47 INFO - main: Train iter. 187100/200000 (93.55%): 	Loss: 5.340282917022705	recon_loss: 0.0024294957984238863	bpp_loss: 4.611433982849121	aux_loss: 1.0603975057601929
03:01:19 INFO - main: Train iter. 187200/200000 (93.6%): 	Loss: 5.3306355476379395	recon_loss: 0.002436748007312417	bpp_loss: 4.599611282348633	aux_loss: 1.05220627784729
03:01:52 INFO - main: Train iter. 187300/200000 (93.65%): 	Loss: 5.3312225341796875	recon_loss: 0.002428851556032896	bpp_loss: 4.602567195892334	aux_loss: 0.9540355205535889
03:02:23 INFO - main: Train iter. 187400/200000 (93.7%): 	Loss: 5.3287858963012695	recon_loss: 0.002435149857774377	bpp_loss: 4.598240852355957	aux_loss: 0.2623547315597534
03:02:55 INFO - main: Train iter. 187500/200000 (93.75%): 	Loss: 5.331175804138184	recon_loss: 0.0024289500433951616	bpp_loss: 4.6024909019470215	aux_loss: 0.8318233489990234
03:03:27 INFO - main: Train iter. 187600/200000 (93.8%): 	Loss: 5.331702709197998	recon_loss: 0.0024267546832561493	bpp_loss: 4.6036763191223145	aux_loss: 0.2566370368003845
03:03:58 INFO - main: Train iter. 187700/200000 (93.85%): 	Loss: 5.332590579986572	recon_loss: 0.0024425089359283447	bpp_loss: 4.599837779998779	aux_loss: 0.6906781196594238
03:04:30 INFO - main: Train iter. 187800/200000 (93.9%): 	Loss: 5.322693824768066	recon_loss: 0.002422478049993515	bpp_loss: 4.595950603485107	aux_loss: 0.8437356352806091
03:05:02 INFO - main: Train iter. 187900/200000 (93.95%): 	Loss: 5.338395595550537	recon_loss: 0.0024324459955096245	bpp_loss: 4.608661651611328	aux_loss: 0.3411582112312317
03:05:33 INFO - main: Train iter. 188000/200000 (94.0%): 	Loss: 5.320557594299316	recon_loss: 0.0024238117039203644	bpp_loss: 4.593413829803467	aux_loss: 0.2215859740972519
03:06:05 INFO - main: Train iter. 188100/200000 (94.05%): 	Loss: 5.3209943771362305	recon_loss: 0.002430924214422703	bpp_loss: 4.59171724319458	aux_loss: 0.2850775122642517
03:06:37 INFO - main: Train iter. 188200/200000 (94.1%): 	Loss: 5.32181978225708	recon_loss: 0.0024288094136863947	bpp_loss: 4.59317684173584	aux_loss: 0.832112193107605
03:07:08 INFO - main: Train iter. 188300/200000 (94.15%): 	Loss: 5.327435493469238	recon_loss: 0.0024295307230204344	bpp_loss: 4.598576068878174	aux_loss: 0.3270535171031952
03:07:40 INFO - main: Train iter. 188400/200000 (94.2%): 	Loss: 5.315291881561279	recon_loss: 0.0024299456272274256	bpp_loss: 4.586308002471924	aux_loss: 1.0735969543457031
03:08:12 INFO - main: Train iter. 188500/200000 (94.25%): 	Loss: 5.318204402923584	recon_loss: 0.0024271265137940645	bpp_loss: 4.590066432952881	aux_loss: 0.7926642894744873
03:08:43 INFO - main: Train iter. 188600/200000 (94.3%): 	Loss: 5.32757568359375	recon_loss: 0.0024262384977191687	bpp_loss: 4.599704265594482	aux_loss: 0.2194397747516632
03:09:16 INFO - main: Train iter. 188700/200000 (94.35%): 	Loss: 5.33803653717041	recon_loss: 0.0024266219697892666	bpp_loss: 4.610049724578857	aux_loss: 0.25981199741363525
03:09:48 INFO - main: Train iter. 188800/200000 (94.4%): 	Loss: 5.3177170753479	recon_loss: 0.002431731903925538	bpp_loss: 4.588197708129883	aux_loss: 0.2746610641479492
03:10:20 INFO - main: Train iter. 188900/200000 (94.45%): 	Loss: 5.327536582946777	recon_loss: 0.002427646890282631	bpp_loss: 4.599242687225342	aux_loss: 0.44175615906715393
03:10:52 INFO - main: Train iter. 189000/200000 (94.5%): 	Loss: 5.31243896484375	recon_loss: 0.0024214747827500105	bpp_loss: 4.585996627807617	aux_loss: 0.21426019072532654
03:11:23 INFO - main: Train iter. 189100/200000 (94.55%): 	Loss: 5.338381767272949	recon_loss: 0.0024239011108875275	bpp_loss: 4.61121129989624	aux_loss: 0.24813143908977509
03:11:55 INFO - main: Train iter. 189200/200000 (94.6%): 	Loss: 5.324514389038086	recon_loss: 0.002425320679321885	bpp_loss: 4.596918106079102	aux_loss: 0.21348735690116882
03:12:27 INFO - main: Train iter. 189300/200000 (94.65%): 	Loss: 5.344500541687012	recon_loss: 0.0024383303243666887	bpp_loss: 4.613001346588135	aux_loss: 0.34480130672454834
03:12:58 INFO - main: Train iter. 189400/200000 (94.7%): 	Loss: 5.3282575607299805	recon_loss: 0.0024366844445466995	bpp_loss: 4.597252368927002	aux_loss: 0.7712836861610413
03:13:30 INFO - main: Train iter. 189500/200000 (94.75%): 	Loss: 5.323903560638428	recon_loss: 0.002424087841063738	bpp_loss: 4.596677303314209	aux_loss: 0.25923240184783936
03:14:02 INFO - main: Train iter. 189600/200000 (94.8%): 	Loss: 5.319655418395996	recon_loss: 0.0024281092919409275	bpp_loss: 4.591222763061523	aux_loss: 0.821846067905426
03:14:34 INFO - main: Train iter. 189700/200000 (94.85%): 	Loss: 5.323363780975342	recon_loss: 0.002427701372653246	bpp_loss: 4.595053195953369	aux_loss: 0.49794891476631165
03:15:05 INFO - main: Train iter. 189800/200000 (94.9%): 	Loss: 5.322659969329834	recon_loss: 0.002427896950393915	bpp_loss: 4.594290733337402	aux_loss: 0.5667476654052734
03:15:37 INFO - main: Train iter. 189900/200000 (94.95%): 	Loss: 5.328343391418457	recon_loss: 0.0024384032003581524	bpp_loss: 4.596822261810303	aux_loss: 0.4770357608795166
03:16:09 INFO - main: Train iter. 190000/200000 (95.0%): 	Loss: 5.3364763259887695	recon_loss: 0.00243182061240077	bpp_loss: 4.606930255889893	aux_loss: 0.45306167006492615
03:16:19 INFO - main: {'TEST MSE': 0.002435414629670852, 'TEST BPP': 4.6157734375, 'TEST loss': 5.332100246906281, 'TEST recon_loss': 0.0024354147114790978, 'TEST bpp_loss': 4.6014758310318}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
03:16:52 INFO - main: Train iter. 190100/200000 (95.05%): 	Loss: 5.330810546875	recon_loss: 0.0024309500586241484	bpp_loss: 4.601525783538818	aux_loss: 0.34214410185813904
03:17:24 INFO - main: Train iter. 190200/200000 (95.1%): 	Loss: 5.328918933868408	recon_loss: 0.0024322255048900843	bpp_loss: 4.5992512702941895	aux_loss: 0.6751678586006165
03:17:55 INFO - main: Train iter. 190300/200000 (95.15%): 	Loss: 5.332458019256592	recon_loss: 0.0024305761326104403	bpp_loss: 4.603285312652588	aux_loss: 0.2643105685710907
03:18:27 INFO - main: Train iter. 190400/200000 (95.2%): 	Loss: 5.3344011306762695	recon_loss: 0.0024375608190894127	bpp_loss: 4.603132724761963	aux_loss: 0.6166969537734985
03:18:59 INFO - main: Train iter. 190500/200000 (95.25%): 	Loss: 5.327060222625732	recon_loss: 0.002427486702799797	bpp_loss: 4.598814010620117	aux_loss: 0.24171531200408936
03:19:30 INFO - main: Train iter. 190600/200000 (95.3%): 	Loss: 5.338519096374512	recon_loss: 0.002428601263090968	bpp_loss: 4.609938621520996	aux_loss: 0.3436175286769867
03:20:02 INFO - main: Train iter. 190700/200000 (95.35%): 	Loss: 5.339922904968262	recon_loss: 0.0024293935857713223	bpp_loss: 4.611104965209961	aux_loss: 0.47069045901298523
03:20:34 INFO - main: Train iter. 190800/200000 (95.4%): 	Loss: 5.331884384155273	recon_loss: 0.002434616908431053	bpp_loss: 4.601499557495117	aux_loss: 0.4591550827026367
03:21:05 INFO - main: Train iter. 190900/200000 (95.45%): 	Loss: 5.326714515686035	recon_loss: 0.0024252936709672213	bpp_loss: 4.59912633895874	aux_loss: 0.20855577290058136
03:21:37 INFO - main: Train iter. 191000/200000 (95.5%): 	Loss: 5.329786777496338	recon_loss: 0.0024273479357361794	bpp_loss: 4.6015825271606445	aux_loss: 0.24080686271190643
03:22:09 INFO - main: Train iter. 191100/200000 (95.55%): 	Loss: 5.3274149894714355	recon_loss: 0.0024261947255581617	bpp_loss: 4.5995564460754395	aux_loss: 0.833174467086792
03:22:40 INFO - main: Train iter. 191200/200000 (95.6%): 	Loss: 5.331860542297363	recon_loss: 0.002434847643598914	bpp_loss: 4.601406097412109	aux_loss: 0.38397130370140076
03:23:12 INFO - main: Train iter. 191300/200000 (95.65%): 	Loss: 5.312114715576172	recon_loss: 0.0024215010926127434	bpp_loss: 4.58566427230835	aux_loss: 0.36166438460350037
03:23:45 INFO - main: Train iter. 191400/200000 (95.7%): 	Loss: 5.337167739868164	recon_loss: 0.002421349985525012	bpp_loss: 4.610762596130371	aux_loss: 0.2080659419298172
03:24:17 INFO - main: Train iter. 191500/200000 (95.75%): 	Loss: 5.335033416748047	recon_loss: 0.002431610133498907	bpp_loss: 4.605550289154053	aux_loss: 0.23569291830062866
03:24:48 INFO - main: Train iter. 191600/200000 (95.8%): 	Loss: 5.325775623321533	recon_loss: 0.0024230489507317543	bpp_loss: 4.598860740661621	aux_loss: 0.2885660231113434
03:25:20 INFO - main: Train iter. 191700/200000 (95.85%): 	Loss: 5.34146785736084	recon_loss: 0.0024274548050016165	bpp_loss: 4.613231658935547	aux_loss: 0.3301800787448883
03:25:52 INFO - main: Train iter. 191800/200000 (95.9%): 	Loss: 5.329464912414551	recon_loss: 0.0024325100239366293	bpp_loss: 4.599711894989014	aux_loss: 0.9991681575775146
03:26:24 INFO - main: Train iter. 191900/200000 (95.95%): 	Loss: 5.32595157623291	recon_loss: 0.002428625011816621	bpp_loss: 4.5973639488220215	aux_loss: 0.7406715154647827
03:26:55 INFO - main: Train iter. 192000/200000 (96.0%): 	Loss: 5.328988552093506	recon_loss: 0.002429054118692875	bpp_loss: 4.600272178649902	aux_loss: 0.5768005847930908
03:27:27 INFO - main: Train iter. 192100/200000 (96.05%): 	Loss: 5.332516193389893	recon_loss: 0.002422360237687826	bpp_loss: 4.605808258056641	aux_loss: 0.594344973564148
03:27:59 INFO - main: Train iter. 192200/200000 (96.1%): 	Loss: 5.323494911193848	recon_loss: 0.0024259586352854967	bpp_loss: 4.595707416534424	aux_loss: 0.20451787114143372
03:28:30 INFO - main: Train iter. 192300/200000 (96.15%): 	Loss: 5.339574813842773	recon_loss: 0.0024291162844747305	bpp_loss: 4.61083984375	aux_loss: 0.47679218649864197
03:29:02 INFO - main: Train iter. 192400/200000 (96.2%): 	Loss: 5.329409599304199	recon_loss: 0.002433519344776869	bpp_loss: 4.599353790283203	aux_loss: 0.45332279801368713
03:29:34 INFO - main: Train iter. 192500/200000 (96.25%): 	Loss: 5.30645227432251	recon_loss: 0.002420133911073208	bpp_loss: 4.580411911010742	aux_loss: 1.2176849842071533
03:30:05 INFO - main: Train iter. 192600/200000 (96.3%): 	Loss: 5.332568168640137	recon_loss: 0.002429025247693062	bpp_loss: 4.603860855102539	aux_loss: 1.3909536600112915
03:30:37 INFO - main: Train iter. 192700/200000 (96.35%): 	Loss: 5.325132846832275	recon_loss: 0.00242518144659698	bpp_loss: 4.597578525543213	aux_loss: 0.4866136610507965
03:31:10 INFO - main: Train iter. 192800/200000 (96.4%): 	Loss: 5.319534778594971	recon_loss: 0.0024259588681161404	bpp_loss: 4.591747283935547	aux_loss: 0.3917231857776642
03:31:42 INFO - main: Train iter. 192900/200000 (96.45%): 	Loss: 5.318577766418457	recon_loss: 0.0024254790041595697	bpp_loss: 4.590933799743652	aux_loss: 0.30614757537841797
03:32:13 INFO - main: Train iter. 193000/200000 (96.5%): 	Loss: 5.330737113952637	recon_loss: 0.00241820327937603	bpp_loss: 4.605276107788086	aux_loss: 0.5943440198898315
03:32:45 INFO - main: Train iter. 193100/200000 (96.55%): 	Loss: 5.333024978637695	recon_loss: 0.002430441789329052	bpp_loss: 4.6038923263549805	aux_loss: 1.2738730907440186
03:33:17 INFO - main: Train iter. 193200/200000 (96.6%): 	Loss: 5.3250532150268555	recon_loss: 0.002420472213998437	bpp_loss: 4.598911762237549	aux_loss: 0.17105460166931152
03:33:48 INFO - main: Train iter. 193300/200000 (96.65%): 	Loss: 5.334898471832275	recon_loss: 0.0024261921644210815	bpp_loss: 4.607040882110596	aux_loss: 0.26542171835899353
03:34:20 INFO - main: Train iter. 193400/200000 (96.7%): 	Loss: 5.31828498840332	recon_loss: 0.002422700636088848	bpp_loss: 4.591475009918213	aux_loss: 0.37984544038772583
03:34:52 INFO - main: Train iter. 193500/200000 (96.75%): 	Loss: 5.320257186889648	recon_loss: 0.002425502985715866	bpp_loss: 4.592606067657471	aux_loss: 0.27641016244888306
03:35:24 INFO - main: Train iter. 193600/200000 (96.8%): 	Loss: 5.331330299377441	recon_loss: 0.0024257057812064886	bpp_loss: 4.603618621826172	aux_loss: 0.19875434041023254
03:35:55 INFO - main: Train iter. 193700/200000 (96.85%): 	Loss: 5.322775363922119	recon_loss: 0.0024266797117888927	bpp_loss: 4.594771385192871	aux_loss: 0.45033901929855347
03:36:27 INFO - main: Train iter. 193800/200000 (96.9%): 	Loss: 5.32356071472168	recon_loss: 0.0024253339506685734	bpp_loss: 4.59596061706543	aux_loss: 0.7006145715713501
03:36:59 INFO - main: Train iter. 193900/200000 (96.95%): 	Loss: 5.320339202880859	recon_loss: 0.0024255358148366213	bpp_loss: 4.592678546905518	aux_loss: 0.27442046999931335
03:37:31 INFO - main: Train iter. 194000/200000 (97.0%): 	Loss: 5.319820404052734	recon_loss: 0.002424198668450117	bpp_loss: 4.592560768127441	aux_loss: 0.43485701084136963
03:38:03 INFO - main: Train iter. 194100/200000 (97.05%): 	Loss: 5.316436767578125	recon_loss: 0.0024197439197450876	bpp_loss: 4.590513706207275	aux_loss: 0.9302977323532104
03:38:36 INFO - main: Train iter. 194200/200000 (97.1%): 	Loss: 5.334282398223877	recon_loss: 0.0024270841386169195	bpp_loss: 4.606157302856445	aux_loss: 1.357338786125183
03:39:07 INFO - main: Train iter. 194300/200000 (97.15%): 	Loss: 5.331902980804443	recon_loss: 0.0024304939433932304	bpp_loss: 4.602754592895508	aux_loss: 0.5108422040939331
03:39:39 INFO - main: Train iter. 194400/200000 (97.2%): 	Loss: 5.33573579788208	recon_loss: 0.0024286513216793537	bpp_loss: 4.60714054107666	aux_loss: 0.8663857579231262
03:40:11 INFO - main: Train iter. 194500/200000 (97.25%): 	Loss: 5.325666904449463	recon_loss: 0.0024223048239946365	bpp_loss: 4.598975658416748	aux_loss: 2.073564052581787
03:40:43 INFO - main: Train iter. 194600/200000 (97.3%): 	Loss: 5.327232360839844	recon_loss: 0.0024249409325420856	bpp_loss: 4.59975004196167	aux_loss: 0.7501131296157837
03:41:14 INFO - main: Train iter. 194700/200000 (97.35%): 	Loss: 5.3327131271362305	recon_loss: 0.0024330306332558393	bpp_loss: 4.602804183959961	aux_loss: 0.3301261365413666
03:41:46 INFO - main: Train iter. 194800/200000 (97.4%): 	Loss: 5.3171515464782715	recon_loss: 0.002428322797641158	bpp_loss: 4.588654518127441	aux_loss: 0.7928897738456726
03:42:18 INFO - main: Train iter. 194900/200000 (97.45%): 	Loss: 5.335775852203369	recon_loss: 0.002435705391690135	bpp_loss: 4.605064392089844	aux_loss: 0.7284331321716309
03:42:49 INFO - main: Train iter. 195000/200000 (97.5%): 	Loss: 5.322047710418701	recon_loss: 0.0024316799826920033	bpp_loss: 4.592543601989746	aux_loss: 0.6147772073745728
03:43:00 INFO - main: {'TEST MSE': 0.0024366277748197837, 'TEST BPP': 4.61678125, 'TEST loss': 5.333259178638459, 'TEST recon_loss': 0.0024366278564557434, 'TEST bpp_loss': 4.60227081823349}
/workspace/Weight_compression/NWC/train_nwc.py:242: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
03:43:31 INFO - main: Train iter. 195100/200000 (97.55%): 	Loss: 5.322850227355957	recon_loss: 0.002419658238068223	bpp_loss: 4.59695291519165	aux_loss: 0.578743577003479
03:44:03 INFO - main: Train iter. 195200/200000 (97.6%): 	Loss: 5.328179836273193	recon_loss: 0.002428464824333787	bpp_loss: 4.599640369415283	aux_loss: 0.37501412630081177
03:44:35 INFO - main: Train iter. 195300/200000 (97.65%): 	Loss: 5.3281049728393555	recon_loss: 0.0024373275227844715	bpp_loss: 4.596906661987305	aux_loss: 0.3281572163105011
03:45:06 INFO - main: Train iter. 195400/200000 (97.7%): 	Loss: 5.335116863250732	recon_loss: 0.0024305034894496202	bpp_loss: 4.605965614318848	aux_loss: 0.29410773515701294
03:45:39 INFO - main: Train iter. 195500/200000 (97.75%): 	Loss: 5.334088325500488	recon_loss: 0.0024370248429477215	bpp_loss: 4.602980613708496	aux_loss: 0.4009378254413605
03:46:11 INFO - main: Train iter. 195600/200000 (97.8%): 	Loss: 5.331555366516113	recon_loss: 0.00242915702983737	bpp_loss: 4.602807998657227	aux_loss: 0.47499310970306396
03:46:43 INFO - main: Train iter. 195700/200000 (97.85%): 	Loss: 5.3256378173828125	recon_loss: 0.0024300601799041033	bpp_loss: 4.596619606018066	aux_loss: 0.5493881702423096
03:47:14 INFO - main: Train iter. 195800/200000 (97.9%): 	Loss: 5.323160648345947	recon_loss: 0.002423267113044858	bpp_loss: 4.596180438995361	aux_loss: 0.2803340554237366
03:47:46 INFO - main: Train iter. 195900/200000 (97.95%): 	Loss: 5.329485893249512	recon_loss: 0.0024223036598414183	bpp_loss: 4.602794647216797	aux_loss: 0.28342604637145996
03:48:18 INFO - main: Train iter. 196000/200000 (98.0%): 	Loss: 5.326770305633545	recon_loss: 0.002437633229419589	bpp_loss: 4.595480442047119	aux_loss: 0.9678780436515808
03:48:49 INFO - main: Train iter. 196100/200000 (98.05%): 	Loss: 5.336841106414795	recon_loss: 0.002432019915431738	bpp_loss: 4.607234954833984	aux_loss: 0.352786123752594
03:49:21 INFO - main: Train iter. 196200/200000 (98.1%): 	Loss: 5.320590496063232	recon_loss: 0.0024360287934541702	bpp_loss: 4.589781761169434	aux_loss: 0.18567690253257751
03:49:53 INFO - main: Train iter. 196300/200000 (98.15%): 	Loss: 5.330657958984375	recon_loss: 0.0024292231537401676	bpp_loss: 4.601891040802002	aux_loss: 0.9392217397689819
03:50:24 INFO - main: Train iter. 196400/200000 (98.2%): 	Loss: 5.3285698890686035	recon_loss: 0.0024300573859363794	bpp_loss: 4.599552631378174	aux_loss: 1.5934743881225586
03:50:56 INFO - main: Train iter. 196500/200000 (98.25%): 	Loss: 5.335031509399414	recon_loss: 0.0024316804483532906	bpp_loss: 4.605527400970459	aux_loss: 0.2621384263038635
03:51:28 INFO - main: Train iter. 196600/200000 (98.3%): 	Loss: 5.318072319030762	recon_loss: 0.0024304199032485485	bpp_loss: 4.588946342468262	aux_loss: 0.4949173629283905
03:52:00 INFO - main: Train iter. 196700/200000 (98.35%): 	Loss: 5.321249961853027	recon_loss: 0.0024278280325233936	bpp_loss: 4.592901706695557	aux_loss: 0.41015252470970154
03:52:31 INFO - main: Train iter. 196800/200000 (98.4%): 	Loss: 5.325930118560791	recon_loss: 0.0024359039962291718	bpp_loss: 4.59515905380249	aux_loss: 0.21344800293445587
03:53:04 INFO - main: Train iter. 196900/200000 (98.45%): 	Loss: 5.333810329437256	recon_loss: 0.0024327372666448355	bpp_loss: 4.603989124298096	aux_loss: 0.5060476064682007
03:53:36 INFO - main: Train iter. 197000/200000 (98.5%): 	Loss: 5.322815418243408	recon_loss: 0.0024272804148495197	bpp_loss: 4.594631195068359	aux_loss: 0.2729690670967102
03:54:08 INFO - main: Train iter. 197100/200000 (98.55%): 	Loss: 5.3263654708862305	recon_loss: 0.002428873674944043	bpp_loss: 4.597703456878662	aux_loss: 0.2405351996421814
03:54:40 INFO - main: Train iter. 197200/200000 (98.6%): 	Loss: 5.326982021331787	recon_loss: 0.002428284380584955	bpp_loss: 4.598496913909912	aux_loss: 0.3413960933685303
03:55:11 INFO - main: Train iter. 197300/200000 (98.65%): 	Loss: 5.329939842224121	recon_loss: 0.002429570537060499	bpp_loss: 4.601068496704102	aux_loss: 0.32812419533729553
03:55:43 INFO - main: Train iter. 197400/200000 (98.7%): 	Loss: 5.336188316345215	recon_loss: 0.0024330082815140486	bpp_loss: 4.60628604888916	aux_loss: 0.24383503198623657
03:56:15 INFO - main: Train iter. 197500/200000 (98.75%): 	Loss: 5.332394123077393	recon_loss: 0.002430353546515107	bpp_loss: 4.603288173675537	aux_loss: 0.26611095666885376
03:56:46 INFO - main: Train iter. 197600/200000 (98.8%): 	Loss: 5.33070182800293	recon_loss: 0.0024260589852929115	bpp_loss: 4.602884292602539	aux_loss: 0.3057219684123993
03:57:18 INFO - main: Train iter. 197700/200000 (98.85%): 	Loss: 5.330306053161621	recon_loss: 0.0024238612968474627	bpp_loss: 4.603147506713867	aux_loss: 0.8252092003822327
03:57:50 INFO - main: Train iter. 197800/200000 (98.9%): 	Loss: 5.328093528747559	recon_loss: 0.0024238438345491886	bpp_loss: 4.600940227508545	aux_loss: 0.9361803531646729
03:58:21 INFO - main: Train iter. 197900/200000 (98.95%): 	Loss: 5.334455490112305	recon_loss: 0.0024292138405144215	bpp_loss: 4.605691432952881	aux_loss: 0.26155105233192444
03:58:53 INFO - main: Train iter. 198000/200000 (99.0%): 	Loss: 5.325079917907715	recon_loss: 0.002427241764962673	bpp_loss: 4.596907615661621	aux_loss: 0.25502610206604004
03:59:25 INFO - main: Train iter. 198100/200000 (99.05%): 	Loss: 5.3189377784729	recon_loss: 0.0024231558199971914	bpp_loss: 4.591990947723389	aux_loss: 0.6233327388763428
03:59:56 INFO - main: Train iter. 198200/200000 (99.1%): 	Loss: 5.319129467010498	recon_loss: 0.0024270708672702312	bpp_loss: 4.591008186340332	aux_loss: 0.2151806801557541
04:00:29 INFO - main: Train iter. 198300/200000 (99.15%): 	Loss: 5.321964263916016	recon_loss: 0.0024271730799227953	bpp_loss: 4.593812465667725	aux_loss: 0.28081968426704407
04:01:01 INFO - main: Train iter. 198400/200000 (99.2%): 	Loss: 5.320937633514404	recon_loss: 0.0024249888956546783	bpp_loss: 4.593441009521484	aux_loss: 0.43524590134620667
04:01:33 INFO - main: Train iter. 198500/200000 (99.25%): 	Loss: 5.329829216003418	recon_loss: 0.002428954467177391	bpp_loss: 4.601142883300781	aux_loss: 0.26668766140937805
04:02:04 INFO - main: Train iter. 198600/200000 (99.3%): 	Loss: 5.333425998687744	recon_loss: 0.0024258613120764494	bpp_loss: 4.605667591094971	aux_loss: 0.4124971926212311
04:02:36 INFO - main: Train iter. 198700/200000 (99.35%): 	Loss: 5.332672595977783	recon_loss: 0.0024326604325324297	bpp_loss: 4.602874279022217	aux_loss: 0.5434744358062744
04:03:08 INFO - main: Train iter. 198800/200000 (99.4%): 	Loss: 5.33164644241333	recon_loss: 0.002426126739010215	bpp_loss: 4.603808403015137	aux_loss: 0.6650655269622803
04:03:40 INFO - main: Train iter. 198900/200000 (99.45%): 	Loss: 5.312560558319092	recon_loss: 0.0024224850349128246	bpp_loss: 4.585814952850342	aux_loss: 0.2526320815086365
04:04:11 INFO - main: Train iter. 199000/200000 (99.5%): 	Loss: 5.326298236846924	recon_loss: 0.0024219851475208998	bpp_loss: 4.599702835083008	aux_loss: 0.4148242175579071
04:04:43 INFO - main: Train iter. 199100/200000 (99.55%): 	Loss: 5.32926082611084	recon_loss: 0.0024207625538110733	bpp_loss: 4.603032112121582	aux_loss: 0.2387920320034027
04:05:15 INFO - main: Train iter. 199200/200000 (99.6%): 	Loss: 5.32792854309082	recon_loss: 0.0024240254424512386	bpp_loss: 4.6007208824157715	aux_loss: 1.3893020153045654
04:05:46 INFO - main: Train iter. 199300/200000 (99.65%): 	Loss: 5.324513912200928	recon_loss: 0.002428774954751134	bpp_loss: 4.595881462097168	aux_loss: 0.6859179735183716
04:06:18 INFO - main: Train iter. 199400/200000 (99.7%): 	Loss: 5.322402000427246	recon_loss: 0.002427895087748766	bpp_loss: 4.594033718109131	aux_loss: 0.2602904438972473
04:06:50 INFO - main: Train iter. 199500/200000 (99.75%): 	Loss: 5.3209919929504395	recon_loss: 0.0024224601220339537	bpp_loss: 4.594254016876221	aux_loss: 0.5034387111663818
04:07:23 INFO - main: Train iter. 199600/200000 (99.8%): 	Loss: 5.337479591369629	recon_loss: 0.002430628053843975	bpp_loss: 4.608291149139404	aux_loss: 0.3882039785385132
04:07:55 INFO - main: Train iter. 199700/200000 (99.85%): 	Loss: 5.335666179656982	recon_loss: 0.002424937905743718	bpp_loss: 4.608184814453125	aux_loss: 0.4253405034542084
04:08:26 INFO - main: Train iter. 199800/200000 (99.9%): 	Loss: 5.327154636383057	recon_loss: 0.0024299451615661383	bpp_loss: 4.598171234130859	aux_loss: 0.7282319664955139
04:08:58 INFO - main: Train iter. 199900/200000 (99.95%): 	Loss: 5.314749717712402	recon_loss: 0.002426239661872387	bpp_loss: 4.586877822875977	aux_loss: 0.7786537408828735
04:09:30 INFO - main: Train iter. 200000/200000 (100.0%): 	Loss: 5.320547103881836	recon_loss: 0.0024258182384073734	bpp_loss: 4.592801570892334	aux_loss: 0.23250135779380798
04:09:40 INFO - main: {'TEST MSE': 0.0024224099161957503, 'TEST BPP': 4.6166875, 'TEST loss': 5.329190011024475, 'TEST recon_loss': 0.0024224100005812944, 'TEST bpp_loss': 4.6024670081138614}
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:        TEST BPP ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        TEST MSE ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   TEST bpp_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       TEST loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: TEST recon_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        bpp_loss ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:            loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      recon_loss ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:        TEST BPP 4.61669
wandb:        TEST MSE 0.00242
wandb:   TEST bpp_loss 4.60247
wandb:       TEST loss 5.32919
wandb: TEST recon_loss 0.00242
wandb:        bpp_loss 4.5928
wandb:            loss 5.32055
wandb:      recon_loss 0.00243
wandb: 
wandb: üöÄ View run nwc at: https://wandb.ai/maskedkd/NWC_VQVAE/runs/wpel4dfr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/maskedkd/NWC_VQVAE
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250401_101831-wpel4dfr/logs
