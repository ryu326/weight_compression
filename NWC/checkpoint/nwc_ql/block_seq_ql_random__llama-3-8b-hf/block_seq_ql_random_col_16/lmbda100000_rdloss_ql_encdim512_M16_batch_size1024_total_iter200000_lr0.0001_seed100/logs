00:30:15 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
00:30:15 INFO - ddp_or_single_process: Create new exp folder!
00:30:15 INFO - ddp_or_single_process: seed : 100
00:30:15 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
00:30:16 INFO - main: Create experiment save folder
00:30:29 INFO - main: Training mode : scratch!
00:30:29 INFO - main: batch_size : 1024
00:30:29 INFO - main: num of gpus: 1
00:30:29 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=100000, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
00:30:31 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 17700266.0	recon_loss: 177.00259399414062	bpp_loss: 5.481707572937012	aux_loss: 659.393310546875
00:30:38 INFO - main: {'TEST MSE': 155.9381691218744, 'TEST BPP': 5.5785, 'TEST loss': 15593823.2545, 'TEST recon_loss': 155.9381644859314, 'TEST bpp_loss': 5.479994880676269}
00:30:38 INFO - main: can not find prev_mse_best_model!
00:30:38 INFO - main: can not find prev_bpp_best_model!
00:30:38 INFO - main: can not find prev_bpp_best_model!
00:30:38 INFO - main: can not find recent_saved_model!
00:35:27 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 2830.989501953125	recon_loss: 0.02825011871755123	bpp_loss: 5.141595840454102	aux_loss: 638.7802124023438
00:40:18 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 1914.193603515625	recon_loss: 0.019081760197877884	bpp_loss: 5.1401262283325195	aux_loss: 623.3939208984375
00:45:08 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 1621.81298828125	recon_loss: 0.016158046200871468	bpp_loss: 5.221225261688232	aux_loss: 610.6175537109375
00:50:00 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 1388.644775390625	recon_loss: 0.013828164897859097	bpp_loss: 5.367011070251465	aux_loss: 600.0667724609375
00:54:51 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 1192.8157958984375	recon_loss: 0.011868782341480255	bpp_loss: 5.491898536682129	aux_loss: 592.5244140625
00:54:58 INFO - main: {'TEST MSE': 0.011629565402396385, 'TEST BPP': 6.023890625, 'TEST loss': 1168.7995930786133, 'TEST recon_loss': 0.011629565057344735, 'TEST bpp_loss': 5.499306862831116}
00:59:48 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 1081.5498046875	recon_loss: 0.010759360156953335	bpp_loss: 5.595737457275391	aux_loss: 582.7938842773438
01:04:40 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 895.0744018554688	recon_loss: 0.008891130797564983	bpp_loss: 5.6342692375183105	aux_loss: 577.660400390625
01:09:30 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 777.6928100585938	recon_loss: 0.007715919055044651	bpp_loss: 5.701455116271973	aux_loss: 572.418212890625
01:14:20 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 849.2980346679688	recon_loss: 0.008434812538325787	bpp_loss: 5.73112154006958	aux_loss: 566.8475952148438
01:19:11 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 689.064697265625	recon_loss: 0.0068299658596515656	bpp_loss: 5.744048595428467	aux_loss: 564.2003173828125
01:19:18 INFO - main: {'TEST MSE': 0.006824628300413123, 'TEST BPP': 6.101125, 'TEST loss': 688.2678476867676, 'TEST recon_loss': 0.006824628111440688, 'TEST bpp_loss': 5.772214299678803}
01:24:08 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 531.2769775390625	recon_loss: 0.005251368507742882	bpp_loss: 5.734720706939697	aux_loss: 557.7385864257812
01:28:59 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 511.02947998046875	recon_loss: 0.005051541607826948	bpp_loss: 5.7683916091918945	aux_loss: 555.3360595703125
01:33:49 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 482.69952392578125	recon_loss: 0.004764535930007696	bpp_loss: 5.748595714569092	aux_loss: 549.7925415039062
01:38:40 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 439.4343566894531	recon_loss: 0.004332359880208969	bpp_loss: 5.76677131652832	aux_loss: 545.0830688476562
01:43:30 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 373.6195983886719	recon_loss: 0.003673086641356349	bpp_loss: 5.785574913024902	aux_loss: 541.66796875
01:43:38 INFO - main: {'TEST MSE': 0.004442636585427403, 'TEST BPP': 5.972703125, 'TEST loss': 450.39568478393556, 'TEST recon_loss': 0.004442636450054124, 'TEST bpp_loss': 5.792200196266174}
01:48:27 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 417.1077575683594	recon_loss: 0.004106230568140745	bpp_loss: 5.793102264404297	aux_loss: 539.6570434570312
01:53:18 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 298.92816162109375	recon_loss: 0.0029263694304972887	bpp_loss: 5.795632839202881	aux_loss: 535.5571899414062
01:58:08 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 449.2200622558594	recon_loss: 0.0044287326745688915	bpp_loss: 5.761420249938965	aux_loss: 528.6240844726562
02:02:58 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 329.2199401855469	recon_loss: 0.0032270043157041073	bpp_loss: 5.75481653213501	aux_loss: 524.9454345703125
02:07:49 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 314.0891418457031	recon_loss: 0.00308038922958076	bpp_loss: 5.801680564880371	aux_loss: 522.7642822265625
02:07:56 INFO - main: {'TEST MSE': 0.0031524510631422676, 'TEST BPP': 5.888484375, 'TEST loss': 321.6800700073242, 'TEST recon_loss': 0.003152450968744233, 'TEST bpp_loss': 5.782034812927246}
02:12:46 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 277.5950012207031	recon_loss: 0.002710646251216531	bpp_loss: 5.798443794250488	aux_loss: 520.0587158203125
02:17:36 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 237.35919189453125	recon_loss: 0.0023079891689121723	bpp_loss: 5.781743049621582	aux_loss: 514.1671752929688
02:22:25 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 272.58636474609375	recon_loss: 0.002655773889273405	bpp_loss: 5.753181457519531	aux_loss: 509.7250671386719
02:27:17 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 247.96713256835938	recon_loss: 0.0024165285285562277	bpp_loss: 5.784834384918213	aux_loss: 506.8358154296875
02:32:07 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 375.58251953125	recon_loss: 0.0036886981688439846	bpp_loss: 5.785803318023682	aux_loss: 503.75665283203125
02:32:15 INFO - main: {'TEST MSE': 0.0032031525164247752, 'TEST BPP': 5.869875, 'TEST loss': 326.82113133239744, 'TEST recon_loss': 0.0032031524170888586, 'TEST bpp_loss': 5.810191504478454}
02:37:04 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 281.3592224121094	recon_loss: 0.0027458646800369024	bpp_loss: 5.788479804992676	aux_loss: 500.5806884765625
02:41:55 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 186.91189575195312	recon_loss: 0.0017984412843361497	bpp_loss: 5.796019077301025	aux_loss: 496.9419860839844
02:46:45 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 202.21246337890625	recon_loss: 0.0019590130541473627	bpp_loss: 5.837212085723877	aux_loss: 494.9739990234375
02:51:35 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 162.272705078125	recon_loss: 0.0015538620064035058	bpp_loss: 5.822568893432617	aux_loss: 493.63763427734375
02:56:26 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 156.67633056640625	recon_loss: 0.0014985931338742375	bpp_loss: 5.826752185821533	aux_loss: 489.9263610839844
02:56:33 INFO - main: {'TEST MSE': 0.001828466885178163, 'TEST BPP': 5.89253125, 'TEST loss': 189.580321685791, 'TEST recon_loss': 0.001828466831240803, 'TEST bpp_loss': 5.846592221736908}
03:01:23 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 163.03944396972656	recon_loss: 0.0015618772013112903	bpp_loss: 5.826662540435791	aux_loss: 487.21478271484375
03:06:14 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 158.94174194335938	recon_loss: 0.001519516110420227	bpp_loss: 5.87566614151001	aux_loss: 487.7954406738281
03:11:04 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 159.90576171875	recon_loss: 0.0015336403157562017	bpp_loss: 5.8719635009765625	aux_loss: 484.8575134277344
03:15:55 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 166.4461212158203	recon_loss: 0.0015978803858160973	bpp_loss: 5.895664215087891	aux_loss: 484.0838623046875
03:20:44 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 126.7744369506836	recon_loss: 0.0012008401099592447	bpp_loss: 5.920072078704834	aux_loss: 481.23785400390625
03:20:52 INFO - main: {'TEST MSE': 0.0011860039961471807, 'TEST BPP': 5.95265625, 'TEST loss': 125.52098011016845, 'TEST recon_loss': 0.0011860039609018712, 'TEST bpp_loss': 5.914024781703949}
03:25:42 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 112.99249267578125	recon_loss: 0.0010631467448547482	bpp_loss: 5.951964378356934	aux_loss: 482.030517578125
03:30:33 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 137.4709930419922	recon_loss: 0.001304474426433444	bpp_loss: 5.963679313659668	aux_loss: 480.48455810546875
03:35:23 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 108.67088317871094	recon_loss: 0.0010210234904661775	bpp_loss: 5.967679500579834	aux_loss: 477.28155517578125
03:40:13 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 128.27444458007812	recon_loss: 0.0012100926833227277	bpp_loss: 5.988061428070068	aux_loss: 478.9172058105469
03:45:04 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 94.65479278564453	recon_loss: 0.0008712580311112106	bpp_loss: 6.017286777496338	aux_loss: 477.1244812011719
03:45:11 INFO - main: {'TEST MSE': 0.0009907193773314186, 'TEST BPP': 6.0691875, 'TEST loss': 106.41148026657105, 'TEST recon_loss': 0.000990719346969854, 'TEST bpp_loss': 6.030560698032379}
03:50:00 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 110.36711120605469	recon_loss: 0.0010340488515794277	bpp_loss: 6.0391011238098145	aux_loss: 474.1939697265625
03:54:50 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 111.65957641601562	recon_loss: 0.0010461698984727263	bpp_loss: 6.031431674957275	aux_loss: 471.4295959472656
03:59:39 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 110.88701629638672	recon_loss: 0.0010318689746782184	bpp_loss: 6.036146640777588	aux_loss: 469.1683349609375
04:04:31 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 87.24832153320312	recon_loss: 0.0008031087345443666	bpp_loss: 6.074941635131836	aux_loss: 467.89227294921875
04:09:22 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 107.85205078125	recon_loss: 0.00100674235727638	bpp_loss: 6.0688276290893555	aux_loss: 465.8618469238281
04:09:29 INFO - main: {'TEST MSE': 0.0011457412470359876, 'TEST BPP': 6.108328125, 'TEST loss': 121.64462133026123, 'TEST recon_loss': 0.0011457412107847632, 'TEST bpp_loss': 6.074286836624146}
04:14:18 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 83.62797546386719	recon_loss: 0.0007652181084267795	bpp_loss: 6.0754852294921875	aux_loss: 464.18359375
04:19:09 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 76.35076904296875	recon_loss: 0.0006907251081429422	bpp_loss: 6.0803046226501465	aux_loss: 462.91363525390625
04:23:59 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 102.28846740722656	recon_loss: 0.0009542566258460283	bpp_loss: 6.1430535316467285	aux_loss: 460.95770263671875
04:28:49 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 142.87937927246094	recon_loss: 0.0013599040685221553	bpp_loss: 6.112411975860596	aux_loss: 458.2870178222656
04:33:40 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 103.17594909667969	recon_loss: 0.0009616878814995289	bpp_loss: 6.12403678894043	aux_loss: 454.354736328125
04:33:47 INFO - main: {'TEST MSE': 0.000984559040847028, 'TEST BPP': 6.151640625, 'TEST loss': 105.75922645187379, 'TEST recon_loss': 0.0009845590103650466, 'TEST bpp_loss': 6.120105236053467}
04:38:37 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 111.53131103515625	recon_loss: 0.0010401722975075245	bpp_loss: 6.110463619232178	aux_loss: 451.1442565917969
04:43:26 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 101.23684692382812	recon_loss: 0.0009425621246919036	bpp_loss: 6.150524616241455	aux_loss: 449.71734619140625
04:48:16 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 81.7153549194336	recon_loss: 0.0007406214717775583	bpp_loss: 6.130385398864746	aux_loss: 446.7406921386719
04:53:08 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 102.09140014648438	recon_loss: 0.0009500011801719666	bpp_loss: 6.132842063903809	aux_loss: 445.6158752441406
04:57:57 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 95.96704864501953	recon_loss: 0.0008851166348904371	bpp_loss: 6.138984680175781	aux_loss: 442.1156921386719
04:58:05 INFO - main: {'TEST MSE': 0.0008125017711270821, 'TEST BPP': 6.18225, 'TEST loss': 88.22056804656982, 'TEST recon_loss': 0.0008125017476268112, 'TEST bpp_loss': 6.152247797012329}
05:02:54 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 92.05354309082031	recon_loss: 0.0008476003422401845	bpp_loss: 6.1737236976623535	aux_loss: 440.9759826660156
05:07:45 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 80.5081558227539	recon_loss: 0.000734978704713285	bpp_loss: 6.161699295043945	aux_loss: 438.0413513183594
05:12:35 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 83.73407745361328	recon_loss: 0.000765272241551429	bpp_loss: 6.190445899963379	aux_loss: 433.9283447265625
05:17:26 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 84.52130126953125	recon_loss: 0.0007690201164223254	bpp_loss: 6.169296741485596	aux_loss: 431.92236328125
05:22:18 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 89.94358825683594	recon_loss: 0.0008256644941866398	bpp_loss: 6.203337669372559	aux_loss: 431.5657958984375
05:22:25 INFO - main: {'TEST MSE': 0.0009674878584258749, 'TEST BPP': 6.228515625, 'TEST loss': 104.12572330093384, 'TEST recon_loss': 0.0009674878293008078, 'TEST bpp_loss': 6.200017796516418}
05:27:15 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 84.47721862792969	recon_loss: 0.0007694375817663968	bpp_loss: 6.178548336029053	aux_loss: 428.0701599121094
05:32:05 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 98.38143920898438	recon_loss: 0.0009136610315181315	bpp_loss: 6.1996002197265625	aux_loss: 425.87518310546875
05:36:55 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 75.34275817871094	recon_loss: 0.0006816956447437406	bpp_loss: 6.200129985809326	aux_loss: 421.74810791015625
05:41:46 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 72.08414459228516	recon_loss: 0.0006511597894132137	bpp_loss: 6.205407619476318	aux_loss: 419.8157043457031
05:46:36 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 78.05403137207031	recon_loss: 0.0007070345454849303	bpp_loss: 6.216941833496094	aux_loss: 418.96563720703125
05:46:43 INFO - main: {'TEST MSE': 0.0006104067515572337, 'TEST BPP': 6.257765625, 'TEST loss': 68.27414960098267, 'TEST recon_loss': 0.0006104067336709704, 'TEST bpp_loss': 6.229825077533722}
05:51:32 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 71.58567810058594	recon_loss: 0.0006399776902981102	bpp_loss: 6.234001636505127	aux_loss: 415.98040771484375
05:56:24 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 83.12004852294922	recon_loss: 0.0007618318195454776	bpp_loss: 6.243480682373047	aux_loss: 411.6634521484375
06:01:13 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 82.37184143066406	recon_loss: 0.0007475519669242203	bpp_loss: 6.233955383300781	aux_loss: 409.6031188964844
06:06:03 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 72.04930114746094	recon_loss: 0.0006418623961508274	bpp_loss: 6.211797714233398	aux_loss: 406.24908447265625
06:10:54 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 74.70147705078125	recon_loss: 0.000670150329824537	bpp_loss: 6.237964153289795	aux_loss: 402.5167236328125
06:11:01 INFO - main: {'TEST MSE': 0.0008464627036176452, 'TEST BPP': 6.25765625, 'TEST loss': 91.63004982757569, 'TEST recon_loss': 0.0008464626781351399, 'TEST bpp_loss': 6.230400072097778}
06:15:52 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 75.37902069091797	recon_loss: 0.0006785450386814773	bpp_loss: 6.239762783050537	aux_loss: 398.77777099609375
06:20:41 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 80.38777160644531	recon_loss: 0.0007273214869201183	bpp_loss: 6.207983493804932	aux_loss: 395.8614807128906
06:25:31 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 70.65687561035156	recon_loss: 0.0006314613856375217	bpp_loss: 6.234296798706055	aux_loss: 395.32171630859375
06:30:22 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 88.80010986328125	recon_loss: 0.0008164666360244155	bpp_loss: 6.231202602386475	aux_loss: 391.4256286621094
06:35:12 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 76.401123046875	recon_loss: 0.000693034497089684	bpp_loss: 6.238158702850342	aux_loss: 389.26763916015625
06:35:20 INFO - main: {'TEST MSE': 0.0007093400291590154, 'TEST BPP': 6.280296875, 'TEST loss': 78.03404607009888, 'TEST recon_loss': 0.0007093400062003638, 'TEST bpp_loss': 6.2531010475158695}
06:40:09 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 69.90741729736328	recon_loss: 0.0006251002778299153	bpp_loss: 6.246534824371338	aux_loss: 386.98883056640625
06:45:00 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 68.08435821533203	recon_loss: 0.0006097344448789954	bpp_loss: 6.248298645019531	aux_loss: 382.5826721191406
06:49:50 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 68.84429931640625	recon_loss: 0.0006159000331535935	bpp_loss: 6.278857231140137	aux_loss: 379.5302734375
06:54:39 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 75.73999786376953	recon_loss: 0.0006835859385319054	bpp_loss: 6.2444987297058105	aux_loss: 377.1727294921875
06:59:31 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 95.0431137084961	recon_loss: 0.0008757080649957061	bpp_loss: 6.263486385345459	aux_loss: 373.3076171875
06:59:38 INFO - main: {'TEST MSE': 0.0008937779410692377, 'TEST BPP': 6.288640625, 'TEST loss': 96.3733888015747, 'TEST recon_loss': 0.0008937779141124338, 'TEST bpp_loss': 6.262289554595947}
07:04:28 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 59.32120895385742	recon_loss: 0.00052316312212497	bpp_loss: 6.255328178405762	aux_loss: 371.54296875
07:09:18 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 94.01962280273438	recon_loss: 0.0008675857679918408	bpp_loss: 6.246817588806152	aux_loss: 367.8415222167969
07:14:08 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 74.82568359375	recon_loss: 0.000677029718644917	bpp_loss: 6.265827178955078	aux_loss: 363.2891540527344
07:19:00 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 63.27244567871094	recon_loss: 0.000559984939172864	bpp_loss: 6.265868663787842	aux_loss: 359.5221862792969
07:23:50 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 72.69210815429688	recon_loss: 0.0006504268967546523	bpp_loss: 6.263199329376221	aux_loss: 356.6691589355469
07:23:58 INFO - main: {'TEST MSE': 0.000553134085858624, 'TEST BPP': 6.28509375, 'TEST loss': 62.98132781219483, 'TEST recon_loss': 0.0005531340695451945, 'TEST bpp_loss': 6.2581893177032475}
07:28:47 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 83.74221801757812	recon_loss: 0.0007655297522433102	bpp_loss: 6.245524883270264	aux_loss: 353.42120361328125
07:33:38 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 74.09615325927734	recon_loss: 0.0006684070103801787	bpp_loss: 6.251026630401611	aux_loss: 350.2778015136719
07:38:28 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 103.2696533203125	recon_loss: 0.0009624131489545107	bpp_loss: 6.271329402923584	aux_loss: 347.68353271484375
07:43:18 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 65.57054901123047	recon_loss: 0.000583115965127945	bpp_loss: 6.280877113342285	aux_loss: 344.8927001953125
07:48:10 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 100.08674621582031	recon_loss: 0.0009249974391423166	bpp_loss: 6.274140357971191	aux_loss: 341.6512451171875
07:48:18 INFO - main: {'TEST MSE': 0.000673305982719342, 'TEST BPP': 6.29484375, 'TEST loss': 74.71419150924683, 'TEST recon_loss': 0.0006733059634862002, 'TEST bpp_loss': 6.270053151607513}
07:53:08 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 67.0680160522461	recon_loss: 0.0005934587097726762	bpp_loss: 6.275496959686279	aux_loss: 337.3378601074219
07:57:57 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 59.79658126831055	recon_loss: 0.000523605733178556	bpp_loss: 6.27011251449585	aux_loss: 334.75335693359375
08:02:46 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 77.07624816894531	recon_loss: 0.0006977009470574558	bpp_loss: 6.253556251525879	aux_loss: 330.52862548828125
08:07:38 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 82.2708511352539	recon_loss: 0.000745604163967073	bpp_loss: 6.262893199920654	aux_loss: 327.61468505859375
08:12:28 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 63.62607192993164	recon_loss: 0.0005644602933898568	bpp_loss: 6.2393798828125	aux_loss: 325.1824645996094
08:12:36 INFO - main: {'TEST MSE': 0.0007022482052000834, 'TEST BPP': 6.301203125, 'TEST loss': 76.98246858215332, 'TEST recon_loss': 0.0007022481843596324, 'TEST bpp_loss': 6.275865602016449}
08:17:25 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 78.9732437133789	recon_loss: 0.0007150705787353218	bpp_loss: 6.2808308601379395	aux_loss: 322.0643005371094
08:22:17 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 84.89813232421875	recon_loss: 0.0007782445172779262	bpp_loss: 6.246016502380371	aux_loss: 318.45855712890625
08:27:06 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 67.635009765625	recon_loss: 0.0006063412292860448	bpp_loss: 6.26384973526001	aux_loss: 312.52191162109375
08:31:56 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 68.83160400390625	recon_loss: 0.0006146166706457734	bpp_loss: 6.245936393737793	aux_loss: 310.4329528808594
08:36:47 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 58.22760772705078	recon_loss: 0.0005076363449916244	bpp_loss: 6.26653528213501	aux_loss: 306.7381591796875
08:36:55 INFO - main: {'TEST MSE': 0.0006630517376410614, 'TEST BPP': 6.29184375, 'TEST loss': 73.16947662734985, 'TEST recon_loss': 0.0006630517179437447, 'TEST bpp_loss': 6.266831647396088}
08:41:45 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 58.488277435302734	recon_loss: 0.0005098716355860233	bpp_loss: 6.268683433532715	aux_loss: 302.82000732421875
08:46:35 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 83.85275268554688	recon_loss: 0.0007633788627572358	bpp_loss: 6.269063472747803	aux_loss: 302.2584228515625
08:51:25 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 68.89436340332031	recon_loss: 0.0006150404224172235	bpp_loss: 6.281958103179932	aux_loss: 298.630615234375
08:56:16 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 71.94449615478516	recon_loss: 0.0006439589196816087	bpp_loss: 6.2853922843933105	aux_loss: 298.044921875
09:01:06 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 63.33443069458008	recon_loss: 0.000562588800676167	bpp_loss: 6.267082214355469	aux_loss: 292.85333251953125
09:01:13 INFO - main: {'TEST MSE': 0.0006086806738556576, 'TEST BPP': 6.30753125, 'TEST loss': 67.89040604591369, 'TEST recon_loss': 0.0006086806545499712, 'TEST bpp_loss': 6.282183500289917}
09:06:03 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 81.7695541381836	recon_loss: 0.0007461982313543558	bpp_loss: 6.265926361083984	aux_loss: 288.92041015625
09:10:55 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 85.8187255859375	recon_loss: 0.0007835203432478011	bpp_loss: 6.273890018463135	aux_loss: 286.42913818359375
09:15:44 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 54.202911376953125	recon_loss: 0.0004684055456891656	bpp_loss: 6.284313201904297	aux_loss: 281.51385498046875
09:20:33 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 63.08662796020508	recon_loss: 0.0005561552825383842	bpp_loss: 6.272097110748291	aux_loss: 278.823486328125
09:25:24 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 85.83100128173828	recon_loss: 0.0007831075345166028	bpp_loss: 6.280642509460449	aux_loss: 275.21746826171875
09:25:32 INFO - main: {'TEST MSE': 0.0006881880757130722, 'TEST BPP': 6.29925, 'TEST loss': 76.16090046691895, 'TEST recon_loss': 0.0006881880552100483, 'TEST bpp_loss': 6.273151626586914}
09:30:22 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 61.037132263183594	recon_loss: 0.0005384180112741888	bpp_loss: 6.253460884094238	aux_loss: 270.2492370605469
09:35:12 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 72.98957824707031	recon_loss: 0.0006555801373906434	bpp_loss: 6.263497829437256	aux_loss: 266.51263427734375
09:40:02 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 61.57924270629883	recon_loss: 0.0005464249989017844	bpp_loss: 6.270552635192871	aux_loss: 264.983642578125
09:44:53 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 87.45597076416016	recon_loss: 0.0008007723954506218	bpp_loss: 6.256989002227783	aux_loss: 262.04705810546875
09:49:43 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 69.2744140625	recon_loss: 0.000621895189397037	bpp_loss: 6.270392417907715	aux_loss: 256.68963623046875
09:49:51 INFO - main: {'TEST MSE': 0.0005791500155911345, 'TEST BPP': 6.294203125, 'TEST loss': 65.33876594924926, 'TEST recon_loss': 0.0005791499982005917, 'TEST bpp_loss': 6.268618058204651}
09:54:40 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 67.85385131835938	recon_loss: 0.0006028268253430724	bpp_loss: 6.267399311065674	aux_loss: 250.62200927734375
09:59:32 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 64.66777038574219	recon_loss: 0.0005770243005827069	bpp_loss: 6.272981643676758	aux_loss: 250.58395385742188
10:04:21 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 82.18396759033203	recon_loss: 0.000747960526496172	bpp_loss: 6.247109889984131	aux_loss: 245.89161682128906
10:09:10 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 72.08983612060547	recon_loss: 0.0006457642302848399	bpp_loss: 6.247222900390625	aux_loss: 241.63046264648438
10:14:01 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 60.14750289916992	recon_loss: 0.0005288167158141732	bpp_loss: 6.249436855316162	aux_loss: 236.7618408203125
10:14:09 INFO - main: {'TEST MSE': 0.000587608195873193, 'TEST BPP': 6.293953125, 'TEST loss': 65.65385374069214, 'TEST recon_loss': 0.0005876081777678336, 'TEST bpp_loss': 6.267680718898773}
10:18:59 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 58.10578536987305	recon_loss: 0.0005118284025229514	bpp_loss: 6.260630130767822	aux_loss: 235.66795349121094
10:23:48 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 59.1141357421875	recon_loss: 0.000513981154654175	bpp_loss: 6.265510082244873	aux_loss: 233.0748748779297
10:28:38 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 62.22383499145508	recon_loss: 0.0005527394823729992	bpp_loss: 6.243076801300049	aux_loss: 227.1636962890625
10:33:31 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 52.754310607910156	recon_loss: 0.00045142369344830513	bpp_loss: 6.24329137802124	aux_loss: 225.27333068847656
10:38:21 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 64.99728393554688	recon_loss: 0.0005720886401832104	bpp_loss: 6.2764811515808105	aux_loss: 223.8483428955078
10:38:28 INFO - main: {'TEST MSE': 0.00052469303990549, 'TEST BPP': 6.29771875, 'TEST loss': 59.92385765075684, 'TEST recon_loss': 0.0005246930243156385, 'TEST bpp_loss': 6.2712722344398495}
10:43:18 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 69.5413589477539	recon_loss: 0.0006235146429389715	bpp_loss: 6.247941017150879	aux_loss: 220.76437377929688
10:48:09 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 57.91461181640625	recon_loss: 0.0005083719152025878	bpp_loss: 6.272972106933594	aux_loss: 217.53187561035156
10:52:59 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 86.13090515136719	recon_loss: 0.000790697056800127	bpp_loss: 6.264942646026611	aux_loss: 213.428466796875
10:57:50 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 67.2035140991211	recon_loss: 0.0005994391394779086	bpp_loss: 6.258790969848633	aux_loss: 210.206298828125
11:02:41 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 70.66519165039062	recon_loss: 0.0006352051859721541	bpp_loss: 6.244272232055664	aux_loss: 207.5977020263672
11:02:49 INFO - main: {'TEST MSE': 0.0005462185595420236, 'TEST BPP': 6.300296875, 'TEST loss': 61.944023181915284, 'TEST recon_loss': 0.00054621854290599, 'TEST bpp_loss': 6.272983815193176}
11:07:39 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 49.0791130065918	recon_loss: 0.0004138546355534345	bpp_loss: 6.243183612823486	aux_loss: 201.2279052734375
11:12:29 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 69.639892578125	recon_loss: 0.0006262747338041663	bpp_loss: 6.25492000579834	aux_loss: 199.78912353515625
11:17:19 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 53.68344497680664	recon_loss: 0.00046471855603158474	bpp_loss: 6.268368721008301	aux_loss: 196.01284790039062
11:22:11 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 87.55519104003906	recon_loss: 0.0008017747313715518	bpp_loss: 6.251974582672119	aux_loss: 192.97003173828125
11:27:01 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 84.75643157958984	recon_loss: 0.0007720604189671576	bpp_loss: 6.262932300567627	aux_loss: 188.6380615234375
11:27:09 INFO - main: {'TEST MSE': 0.0005966977926612193, 'TEST BPP': 6.296546875, 'TEST loss': 66.98089619255066, 'TEST recon_loss': 0.0005966977748903446, 'TEST bpp_loss': 6.268280254364013}
11:31:59 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 80.80803680419922	recon_loss: 0.0007337562856264412	bpp_loss: 6.240989685058594	aux_loss: 181.68077087402344
11:36:50 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 57.573699951171875	recon_loss: 0.0005036367219872773	bpp_loss: 6.232659339904785	aux_loss: 179.63296508789062
11:41:40 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 64.74983215332031	recon_loss: 0.0005779128987342119	bpp_loss: 6.282304763793945	aux_loss: 176.53416442871094
11:46:30 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 66.57280731201172	recon_loss: 0.0005941367126069963	bpp_loss: 6.287027359008789	aux_loss: 173.6524658203125
11:51:21 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 58.74775695800781	recon_loss: 0.0005153701640665531	bpp_loss: 6.2616472244262695	aux_loss: 174.0618896484375
11:51:29 INFO - main: {'TEST MSE': 0.00042490147124733607, 'TEST BPP': 6.30559375, 'TEST loss': 49.72731258583069, 'TEST recon_loss': 0.00042490145878400654, 'TEST bpp_loss': 6.277249004840851}
11:56:19 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 74.15988159179688	recon_loss: 0.0006663504173047841	bpp_loss: 6.260021209716797	aux_loss: 169.3194122314453
12:01:09 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 59.741127014160156	recon_loss: 0.0005240887403488159	bpp_loss: 6.2484540939331055	aux_loss: 165.63528442382812
12:05:58 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 78.34050750732422	recon_loss: 0.0007083052769303322	bpp_loss: 6.250876426696777	aux_loss: 163.1436767578125
12:10:49 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 50.70158767700195	recon_loss: 0.000427085644332692	bpp_loss: 6.242613792419434	aux_loss: 159.6431884765625
12:15:39 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 58.32986831665039	recon_loss: 0.0005100906710140407	bpp_loss: 6.246609210968018	aux_loss: 155.90286254882812
12:15:47 INFO - main: {'TEST MSE': 0.0007595022598686908, 'TEST BPP': 6.2915, 'TEST loss': 83.03152938461304, 'TEST recon_loss': 0.0007595022366731428, 'TEST bpp_loss': 6.262858248233795}
12:20:36 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 60.56947326660156	recon_loss: 0.0005298564792610705	bpp_loss: 6.250133514404297	aux_loss: 154.47608947753906
12:25:28 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 69.25764465332031	recon_loss: 0.0006171630811877549	bpp_loss: 6.28568696975708	aux_loss: 153.06680297851562
12:30:18 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 67.42171478271484	recon_loss: 0.0005998131819069386	bpp_loss: 6.267803192138672	aux_loss: 150.56521606445312
12:35:08 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 60.074440002441406	recon_loss: 0.0005214542034082115	bpp_loss: 6.267483711242676	aux_loss: 143.89927673339844
12:39:59 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 64.2831039428711	recon_loss: 0.000572008138988167	bpp_loss: 6.276732444763184	aux_loss: 141.80038452148438
12:40:07 INFO - main: {'TEST MSE': 0.0007667549443198437, 'TEST BPP': 6.30071875, 'TEST loss': 84.23364624595642, 'TEST recon_loss': 0.000766754921656684, 'TEST bpp_loss': 6.271423765659332}
12:44:57 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 63.182376861572266	recon_loss: 0.0005559082492254674	bpp_loss: 6.25622034072876	aux_loss: 138.1593475341797
12:49:47 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 75.15685272216797	recon_loss: 0.0006767345475964248	bpp_loss: 6.2573628425598145	aux_loss: 132.9940185546875
12:54:37 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 48.55731201171875	recon_loss: 0.0004149853775743395	bpp_loss: 6.252890586853027	aux_loss: 128.61233520507812
12:59:29 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 59.062435150146484	recon_loss: 0.0005188722279854119	bpp_loss: 6.273658752441406	aux_loss: 125.92340087890625
13:04:18 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 64.56940460205078	recon_loss: 0.0005751887219958007	bpp_loss: 6.249312877655029	aux_loss: 122.9848861694336
13:04:26 INFO - main: {'TEST MSE': 0.0005294573089332742, 'TEST BPP': 6.29653125, 'TEST loss': 60.09855080986023, 'TEST recon_loss': 0.000529457292810548, 'TEST bpp_loss': 6.2660849318504335}
13:09:16 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 62.10112380981445	recon_loss: 0.0005477999220602214	bpp_loss: 6.252462863922119	aux_loss: 119.36431884765625
13:14:08 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 63.49346160888672	recon_loss: 0.000563029432669282	bpp_loss: 6.251272678375244	aux_loss: 114.1141586303711
13:18:58 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 48.8385009765625	recon_loss: 0.0004069886635988951	bpp_loss: 6.229495048522949	aux_loss: 113.1259765625
13:23:48 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 86.71503448486328	recon_loss: 0.0007943974924273789	bpp_loss: 6.273192405700684	aux_loss: 109.42559051513672
13:28:39 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 64.39663696289062	recon_loss: 0.0005701332702301443	bpp_loss: 6.26539945602417	aux_loss: 107.40313720703125
13:28:47 INFO - main: {'TEST MSE': 0.0004964763780104897, 'TEST BPP': 6.298171875, 'TEST loss': 57.12891121482849, 'TEST recon_loss': 0.0004964763628086075, 'TEST bpp_loss': 6.267598385334015}
13:33:37 INFO - main: Train iter. 161000/200000 (80.5%): 	Loss: 59.01129913330078	recon_loss: 0.000514638377353549	bpp_loss: 6.269171237945557	aux_loss: 107.2632064819336
13:38:26 INFO - main: Train iter. 162000/200000 (81.0%): 	Loss: 71.77265167236328	recon_loss: 0.0006443187594413757	bpp_loss: 6.236414909362793	aux_loss: 101.23512268066406
13:43:16 INFO - main: Train iter. 163000/200000 (81.5%): 	Loss: 52.27262878417969	recon_loss: 0.00044459712808020413	bpp_loss: 6.236722946166992	aux_loss: 97.4454345703125
13:48:08 INFO - main: Train iter. 164000/200000 (82.0%): 	Loss: 57.24205017089844	recon_loss: 0.0005022652330808342	bpp_loss: 6.263854503631592	aux_loss: 96.05366516113281
13:52:57 INFO - main: Train iter. 165000/200000 (82.5%): 	Loss: 80.5107650756836	recon_loss: 0.000734741217456758	bpp_loss: 6.26087760925293	aux_loss: 92.61924743652344
13:53:05 INFO - main: {'TEST MSE': 0.0005325214392716454, 'TEST BPP': 6.292875, 'TEST loss': 61.289939641952515, 'TEST recon_loss': 0.000532521423738217, 'TEST bpp_loss': 6.2621925354003904}
13:57:54 INFO - main: Train iter. 166000/200000 (83.0%): 	Loss: 86.32198333740234	recon_loss: 0.0007879016920924187	bpp_loss: 6.260880470275879	aux_loss: 89.24064636230469
14:02:46 INFO - main: Train iter. 167000/200000 (83.5%): 	Loss: 70.15968322753906	recon_loss: 0.0006280092056840658	bpp_loss: 6.249028205871582	aux_loss: 84.26875305175781
14:07:35 INFO - main: Train iter. 168000/200000 (84.0%): 	Loss: 58.98421096801758	recon_loss: 0.0005225216154940426	bpp_loss: 6.248661994934082	aux_loss: 78.274169921875
14:12:25 INFO - main: Train iter. 169000/200000 (84.5%): 	Loss: 68.58976745605469	recon_loss: 0.0006086722132749856	bpp_loss: 6.257847309112549	aux_loss: 76.20716857910156
14:17:17 INFO - main: Train iter. 170000/200000 (85.0%): 	Loss: 79.79796600341797	recon_loss: 0.0007302398444153368	bpp_loss: 6.2575225830078125	aux_loss: 74.1617660522461
14:17:25 INFO - main: {'TEST MSE': 0.00066485781845451, 'TEST BPP': 6.29415625, 'TEST loss': 74.11439339065552, 'TEST recon_loss': 0.000664857798081357, 'TEST bpp_loss': 6.262155482769012}
14:22:14 INFO - main: Train iter. 171000/200000 (85.5%): 	Loss: 69.65570068359375	recon_loss: 0.0006184198427945375	bpp_loss: 6.234574794769287	aux_loss: 68.9769287109375
14:27:04 INFO - main: Train iter. 172000/200000 (86.0%): 	Loss: 55.02204895019531	recon_loss: 0.00047927419655025005	bpp_loss: 6.25575590133667	aux_loss: 64.4373779296875
14:31:54 INFO - main: Train iter. 173000/200000 (86.5%): 	Loss: 51.80744934082031	recon_loss: 0.00044107629219070077	bpp_loss: 6.253709316253662	aux_loss: 64.78935241699219
14:36:46 INFO - main: Train iter. 174000/200000 (87.0%): 	Loss: 90.46212768554688	recon_loss: 0.0008335832390002906	bpp_loss: 6.268279075622559	aux_loss: 64.5043716430664
14:41:36 INFO - main: Train iter. 175000/200000 (87.5%): 	Loss: 66.88704681396484	recon_loss: 0.0005972779472358525	bpp_loss: 6.265618324279785	aux_loss: 61.07621765136719
14:41:44 INFO - main: {'TEST MSE': 0.0007255829277225033, 'TEST BPP': 6.30046875, 'TEST loss': 79.84024130630493, 'TEST recon_loss': 0.000725582906161435, 'TEST bpp_loss': 6.267142066001892}
14:46:34 INFO - main: Train iter. 176000/200000 (88.0%): 	Loss: 54.579124450683594	recon_loss: 0.00047355660353787243	bpp_loss: 6.258782863616943	aux_loss: 55.485740661621094
14:51:26 INFO - main: Train iter. 177000/200000 (88.5%): 	Loss: 53.389991760253906	recon_loss: 0.00046000845031812787	bpp_loss: 6.273316860198975	aux_loss: 55.59245300292969
14:56:17 INFO - main: Train iter. 178000/200000 (89.0%): 	Loss: 60.948394775390625	recon_loss: 0.0005348019185476005	bpp_loss: 6.2672224044799805	aux_loss: 52.147518157958984
15:01:07 INFO - main: Train iter. 179000/200000 (89.5%): 	Loss: 49.35575866699219	recon_loss: 0.0004240792477503419	bpp_loss: 6.295146942138672	aux_loss: 52.23541259765625
15:05:59 INFO - main: Train iter. 180000/200000 (90.0%): 	Loss: 55.761940002441406	recon_loss: 0.0004773174587171525	bpp_loss: 6.2477030754089355	aux_loss: 45.515052795410156
15:06:07 INFO - main: {'TEST MSE': 0.0004510733519406198, 'TEST BPP': 6.29878125, 'TEST loss': 52.65850490570068, 'TEST recon_loss': 0.0004510733385977801, 'TEST bpp_loss': 6.266109973430633}
15:10:57 INFO - main: Train iter. 181000/200000 (90.5%): 	Loss: 84.81559753417969	recon_loss: 0.0007709154160693288	bpp_loss: 6.306790351867676	aux_loss: 44.47838592529297
15:15:48 INFO - main: Train iter. 182000/200000 (91.0%): 	Loss: 62.19645309448242	recon_loss: 0.0005477122613228858	bpp_loss: 6.285423755645752	aux_loss: 41.09446334838867
15:20:40 INFO - main: Train iter. 183000/200000 (91.5%): 	Loss: 51.1159782409668	recon_loss: 0.00043578314944170415	bpp_loss: 6.230327129364014	aux_loss: 35.76805114746094
15:25:30 INFO - main: Train iter. 184000/200000 (92.0%): 	Loss: 76.62612915039062	recon_loss: 0.0006940326420590281	bpp_loss: 6.252258777618408	aux_loss: 35.04742431640625
15:30:20 INFO - main: Train iter. 185000/200000 (92.5%): 	Loss: 58.4128532409668	recon_loss: 0.0005113439401611686	bpp_loss: 6.2497382164001465	aux_loss: 31.945068359375
15:30:28 INFO - main: {'TEST MSE': 0.0004472327703892915, 'TEST BPP': 6.304203125, 'TEST loss': 52.05072386169434, 'TEST recon_loss': 0.00044723275693831963, 'TEST bpp_loss': 6.269851346492767}
15:35:19 INFO - main: Train iter. 186000/200000 (93.0%): 	Loss: 74.4736328125	recon_loss: 0.0006711265305057168	bpp_loss: 6.270782947540283	aux_loss: 27.716590881347656
15:40:11 INFO - main: Train iter. 187000/200000 (93.5%): 	Loss: 53.27113723754883	recon_loss: 0.0004614533972926438	bpp_loss: 6.2672553062438965	aux_loss: 23.81974220275879
15:45:01 INFO - main: Train iter. 188000/200000 (94.0%): 	Loss: 63.6290283203125	recon_loss: 0.0005613818648271263	bpp_loss: 6.252138137817383	aux_loss: 22.924766540527344
15:49:51 INFO - main: Train iter. 189000/200000 (94.5%): 	Loss: 55.832740783691406	recon_loss: 0.00048120462452061474	bpp_loss: 6.257991790771484	aux_loss: 21.336593627929688
15:54:43 INFO - main: Train iter. 190000/200000 (95.0%): 	Loss: 76.81804656982422	recon_loss: 0.0006916686543263495	bpp_loss: 6.2721076011657715	aux_loss: 21.287330627441406
15:54:51 INFO - main: {'TEST MSE': 0.0005686178885251549, 'TEST BPP': 6.30428125, 'TEST loss': 64.0697348537445, 'TEST recon_loss': 0.0005686178719188319, 'TEST bpp_loss': 6.269974700927734}
15:59:41 INFO - main: Train iter. 191000/200000 (95.5%): 	Loss: 54.09807586669922	recon_loss: 0.0004600337124429643	bpp_loss: 6.280299186706543	aux_loss: 17.873294830322266
16:04:31 INFO - main: Train iter. 192000/200000 (96.0%): 	Loss: 57.22560119628906	recon_loss: 0.0005001960671506822	bpp_loss: 6.252655029296875	aux_loss: 15.000920295715332
16:09:23 INFO - main: Train iter. 193000/200000 (96.5%): 	Loss: 66.36678314208984	recon_loss: 0.0005878961528651416	bpp_loss: 6.254170894622803	aux_loss: 13.037469863891602
16:14:14 INFO - main: Train iter. 194000/200000 (97.0%): 	Loss: 62.035255432128906	recon_loss: 0.0005492513300850987	bpp_loss: 6.2684006690979	aux_loss: 12.110939025878906
16:19:04 INFO - main: Train iter. 195000/200000 (97.5%): 	Loss: 73.7215576171875	recon_loss: 0.000667477201204747	bpp_loss: 6.249466896057129	aux_loss: 11.197883605957031
16:19:12 INFO - main: {'TEST MSE': 0.0006451615452812609, 'TEST BPP': 6.29925, 'TEST loss': 72.04149754714966, 'TEST recon_loss': 0.0006451615255209617, 'TEST bpp_loss': 6.2652984666824345}
16:24:02 INFO - main: Train iter. 196000/200000 (98.0%): 	Loss: 55.40496063232422	recon_loss: 0.0004811467370018363	bpp_loss: 6.271684169769287	aux_loss: 9.602947235107422
16:28:54 INFO - main: Train iter. 197000/200000 (98.5%): 	Loss: 46.67082977294922	recon_loss: 0.0003948346129618585	bpp_loss: 6.276388645172119	aux_loss: 8.46099853515625
16:33:44 INFO - main: Train iter. 198000/200000 (99.0%): 	Loss: 54.06212615966797	recon_loss: 0.00046423153253272176	bpp_loss: 6.24893045425415	aux_loss: 6.67865514755249
16:38:34 INFO - main: Train iter. 199000/200000 (99.5%): 	Loss: 63.07343673706055	recon_loss: 0.000559941167011857	bpp_loss: 6.262449741363525	aux_loss: 5.56049919128418
16:43:26 INFO - main: Train iter. 200000/200000 (100.0%): 	Loss: 53.923583984375	recon_loss: 0.0004662356514018029	bpp_loss: 6.257373809814453	aux_loss: 3.8645548820495605
16:43:34 INFO - main: {'TEST MSE': 0.0004899212704699264, 'TEST BPP': 6.302453125, 'TEST loss': 56.324841911315914, 'TEST recon_loss': 0.0004899212557356805, 'TEST bpp_loss': 6.2682047715187075}
19:50:13 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
19:50:13 INFO - ddp_or_single_process: find checkpoint...
19:50:13 INFO - ddp_or_single_process: checkpoint exist, name: recent_model_loss_56.32484_bpp_6.30245_MSE_0.00049_total_iter_200000.pth.tar
19:50:13 INFO - ddp_or_single_process: seed : 100
19:50:13 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
19:50:14 INFO - main: Create experiment save folder
19:50:26 INFO - main: Training mode : scratch!
19:50:26 INFO - main: batch_size : 1024
19:50:26 INFO - main: num of gpus: 1
19:50:26 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='./checkpoint/nwc_ql/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/recent_model_loss_56.32484_bpp_6.30245_MSE_0.00049_total_iter_200000.pth.tar', block_direction='col', lmbda=100000, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
19:50:26 INFO - main: Loading ./checkpoint/nwc_ql/block_seq_ql_random_col_16/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100/recent_model_loss_56.32484_bpp_6.30245_MSE_0.00049_total_iter_200000.pth.tar
