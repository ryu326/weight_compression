{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgryu/miniconda3/envs/nicc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jgryu/miniconda3/envs/nicc/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "from models import VQ_SEEDLM\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQ_SEEDLM(input_size = 16, K = 16, P = 4, dim_encoder=64, scale = 1, shift = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1020357/1103951652.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt = torch.load('/home/jgryu/Weight_compression/VQ_SEEDLM/checkpoint/Meta-Llama-3-8B/mlp_16_row_dataset.pt/size16_K16_P4_batch_size512_total_iter2000000_lr0.0001_seed100/best_mse_model_MSE_0.34361_total_iter_1450000.pth.tar')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = torch.load('/home/jgryu/Weight_compression/VQ_SEEDLM/checkpoint/Meta-Llama-3-8B/mlp_16_row_dataset.pt/size16_K16_P4_batch_size512_total_iter2000000_lr0.0001_seed100/best_mse_model_MSE_0.34361_total_iter_1450000.pth.tar')\n",
    "model.load_state_dict(pt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7159, -7.4310,  0.6568, -2.5971, -3.7430,  3.8038, -0.7851, -2.7941,\n",
       "          0.9099,  0.7636,  2.3663,  3.8298,  0.2457, -2.9888, -1.2581, -3.5050],\n",
       "        [ 5.8182,  1.2225, -0.5896,  1.2592, -2.0442, -0.2261, -8.7649, -0.7917,\n",
       "         -2.7309,  1.4652,  0.3484,  0.7576, -0.9749,  2.0910,  1.7199, -3.4691],\n",
       "        [-0.9417, -6.7004,  0.3378, -2.4421, -4.2570,  4.0740, -0.9950, -2.5741,\n",
       "         -0.6422,  0.3914,  1.9598,  2.0479,  2.1110, -4.8077, -0.9402, -3.5114],\n",
       "        [-0.5549, -6.0014,  0.4058, -2.7521, -4.3982,  2.9628, -0.3560, -4.6006,\n",
       "         -0.5032, -1.0150,  2.0469,  3.7394,  1.0539, -3.8158, -1.4000, -3.4291],\n",
       "        [-0.0449, -7.0732,  0.1641, -1.7818, -5.2675,  2.7947,  0.7638, -3.4548,\n",
       "         -0.6347,  1.1980,  1.5916,  2.5534,  1.0002, -3.1644, -1.5941, -4.1008],\n",
       "        [ 4.5894,  0.0911, -0.4356,  0.5542, -2.1886, -0.9053, -9.2249, -0.8319,\n",
       "         -2.4466,  0.7982, -2.4203, -0.0691, -1.9848,  1.9871,  1.7897, -3.5394],\n",
       "        [-0.7957, -6.9263, -1.8425, -2.2821, -3.2142,  2.9383, -0.4859, -3.1598,\n",
       "         -0.8401,  0.8774,  1.8764,  3.6066,  0.7625, -4.4026, -2.1007, -3.8135],\n",
       "        [-1.1678, -6.2224, -0.0954, -2.5190, -4.1170,  4.1826, -0.3552, -4.7431,\n",
       "         -0.7346,  1.5867,  2.1734,  2.3604, -0.1809, -4.0396, -0.7903, -3.0199],\n",
       "        [-2.2174, -6.6453, -0.1956, -1.9573, -3.6956,  3.6215, -0.3844, -3.7864,\n",
       "         -0.9529,  0.1752,  2.4387,  2.6508,  1.2410, -2.4898, -1.1258, -5.0135],\n",
       "        [ 5.2324, -1.0888, -0.2265,  1.7048, -1.5692, -1.4602, -9.2650, -1.1715,\n",
       "         -3.3107,  0.5005,  0.1300, -0.5899, -1.6531,  2.2196,  1.5128, -2.1587],\n",
       "        [ 3.7479,  0.4646, -0.3377,  0.5028, -3.1403, -2.3152, -9.6082, -0.4234,\n",
       "         -3.0208,  1.7586,  0.0643,  0.5347, -1.3761,  2.1193,  1.6025, -2.4334],\n",
       "        [ 4.8373,  0.2764, -0.0879,  0.3060, -2.5559, -0.2647, -8.8482,  0.3667,\n",
       "         -4.5537,  0.5851, -0.4266,  0.3440, -2.5091,  2.5388,  0.8455, -2.5679],\n",
       "        [ 4.6432,  0.5065, -0.7165,  0.8460, -2.7610, -0.4090, -9.7535, -1.0628,\n",
       "         -2.4293,  1.0517, -0.5974, -0.5090, -1.1642,  2.8655, -0.5424, -2.2442],\n",
       "        [ 4.6790,  0.3154, -1.7086,  1.4298, -3.5506, -0.6568, -9.0943, -0.1605,\n",
       "         -2.2772, -0.0909,  0.1436, -0.4189, -2.5055,  2.1177,  1.7854, -2.6607],\n",
       "        [-1.6821, -6.3563,  0.7282, -0.2156, -4.2355,  3.7377, -0.6487, -3.5101,\n",
       "         -0.6249,  0.5967,  1.6513,  3.7751,  0.3946, -4.4470, -1.8343, -3.7458],\n",
       "        [ 4.5550, -0.2365, -1.2811,  1.3475, -2.8872, -0.1857, -9.1686, -0.7392,\n",
       "         -3.4376,  0.9617, -1.1922,  1.0086, -0.7566,  3.1883,  2.1437, -1.4369]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['vector_quantization.embedding.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(100, 16)\n",
    "out = model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4086,  0.0747,  0.8433, -0.0920,  1.1594,  0.4795,  0.6943,  0.5996,\n",
      "        -0.5091, -0.0785, -1.5397, -0.3716, -0.6352, -0.8390,  0.8185,  0.2475])\n",
      "tensor([ 0.4692,  0.3023,  0.3288, -0.1461,  0.4714, -0.4177,  0.2513,  0.7993,\n",
      "         0.1904, -0.0969, -1.2876, -0.1565, -0.2613, -0.9735,  1.3754,  0.1996],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out['x'][0])\n",
    "print(out['x_hat'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  2,  5, 12],\n",
       "        [ 3,  4, 12, 11],\n",
       "        [14,  7,  9, 13],\n",
       "        [ 8,  7, 10,  1],\n",
       "        [14,  3,  9, 12],\n",
       "        [ 7,  6, 13, 11],\n",
       "        [ 2,  8, 13, 11],\n",
       "        [ 6,  4, 12,  1],\n",
       "        [ 6,  8, 13, 15],\n",
       "        [ 0,  7,  9, 10],\n",
       "        [ 8,  7, 13,  1],\n",
       "        [ 0,  2,  1,  5],\n",
       "        [ 8,  7, 10, 13],\n",
       "        [ 3,  0, 15, 11],\n",
       "        [ 4,  7, 15,  9],\n",
       "        [ 2,  6, 13, 12],\n",
       "        [ 0,  6, 11,  5],\n",
       "        [ 0,  7,  9,  5],\n",
       "        [ 2, 14, 10, 15],\n",
       "        [ 3, 14, 13,  5],\n",
       "        [ 6,  8,  1, 12],\n",
       "        [ 7,  4, 11, 15],\n",
       "        [ 4,  7, 12, 10],\n",
       "        [ 6,  7, 10,  5],\n",
       "        [14,  0, 10, 11],\n",
       "        [ 2,  4,  5, 11],\n",
       "        [ 8,  3, 10,  5],\n",
       "        [14,  6,  9, 11],\n",
       "        [ 6,  8, 11, 13],\n",
       "        [ 7,  8,  1, 13],\n",
       "        [14,  0,  9, 11],\n",
       "        [ 8,  7,  1, 13],\n",
       "        [ 7,  6, 15,  5],\n",
       "        [ 0,  2, 10, 13],\n",
       "        [ 4,  7,  1,  5],\n",
       "        [ 7,  6, 15, 13],\n",
       "        [ 2,  0, 12,  1],\n",
       "        [ 6,  7,  9, 11],\n",
       "        [ 8,  6,  5, 11],\n",
       "        [ 7,  6, 11,  5],\n",
       "        [ 7,  8,  9, 13],\n",
       "        [ 6,  7, 12, 11],\n",
       "        [ 4,  2, 15, 13],\n",
       "        [ 2,  3, 11,  9],\n",
       "        [ 3,  4,  1, 11],\n",
       "        [14,  2,  9,  5],\n",
       "        [ 6,  2, 15,  5],\n",
       "        [ 4,  2,  1, 11],\n",
       "        [14,  4,  9,  1],\n",
       "        [14,  2,  1, 12],\n",
       "        [14,  6, 10, 12],\n",
       "        [14,  6,  9,  1],\n",
       "        [ 3,  8, 11, 15],\n",
       "        [ 3,  6, 11,  5],\n",
       "        [ 0, 14,  1, 10],\n",
       "        [ 3,  7, 11,  5],\n",
       "        [ 3,  0, 15, 12],\n",
       "        [ 0,  2,  9, 11],\n",
       "        [ 3,  8, 15, 12],\n",
       "        [ 6, 14, 13, 15],\n",
       "        [ 2,  4, 13,  9],\n",
       "        [ 2,  6, 12, 15],\n",
       "        [ 3,  2,  5, 12],\n",
       "        [ 3,  4, 10, 12],\n",
       "        [14,  7,  5, 13],\n",
       "        [ 4,  3,  9, 11],\n",
       "        [ 3,  2,  5, 10],\n",
       "        [ 8,  6,  9, 11],\n",
       "        [ 8,  6, 13,  5],\n",
       "        [ 4,  0, 10, 12],\n",
       "        [14,  3,  9, 12],\n",
       "        [ 2,  3, 12, 13],\n",
       "        [ 2,  3, 10,  9],\n",
       "        [14,  3, 10, 12],\n",
       "        [ 4,  2, 11,  9],\n",
       "        [ 4,  2, 12,  1],\n",
       "        [ 2,  4,  9,  5],\n",
       "        [ 3,  8,  5,  1],\n",
       "        [ 2, 14, 12,  1],\n",
       "        [ 4,  7, 13, 12],\n",
       "        [14,  6, 15,  1],\n",
       "        [ 7,  3, 10, 12],\n",
       "        [ 4,  3,  5, 15],\n",
       "        [ 6,  7, 10, 13],\n",
       "        [14,  2,  1, 15],\n",
       "        [ 7,  4,  5, 10],\n",
       "        [ 6,  8, 11, 10],\n",
       "        [ 3,  2, 13,  9],\n",
       "        [ 2,  0, 12, 15],\n",
       "        [ 7,  3, 11, 10],\n",
       "        [ 2,  7,  9,  5],\n",
       "        [ 8,  3, 11,  9],\n",
       "        [ 7,  2,  9, 11],\n",
       "        [ 6, 14, 11, 12],\n",
       "        [ 3,  4,  1, 11],\n",
       "        [ 0,  6,  5, 10],\n",
       "        [ 3,  2, 10,  5],\n",
       "        [ 6,  0,  5,  9],\n",
       "        [ 7,  3,  9,  1],\n",
       "        [ 3,  2, 10, 15]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['min_encoding_indices'].view(100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.7193)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['perplexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5805316 0.75221896\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = []\n",
    "for i in range(256):\n",
    "    x_shift = torch.randn(100, 12, 1)\n",
    "    z_q = torch.randn(100, 12, 4)\n",
    "    coefficient = torch.matmul(torch.linalg.pinv(z_q), x_shift)\n",
    "    x_hat  = torch.matmul(z_q, coefficient)\n",
    "    l.append(((x_shift - x_hat)**2).mean())\n",
    "print(np.array(l).min(), np.array(l).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  9.6858e-08, -4.3772e-08,  2.9802e-08],\n",
      "        [ 8.5682e-08,  1.0000e+00, -2.6263e-07, -2.0862e-07],\n",
      "        [-1.3271e-07, -6.5193e-08,  1.0000e+00, -1.2480e-07],\n",
      "        [-1.5646e-07, -1.7881e-07,  6.0536e-08,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "z_q = torch.randn(100, 4, 16)  # 랜덤 텐서 생성\n",
    "z_q_pinv = torch.linalg.pinv(z_q)  # 유사 역행렬 계산\n",
    "result = torch.matmul(z_q, z_q_pinv)[0]  # 첫 번째 배치 결과\n",
    "\n",
    "print(result)  # 크기 (16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 16, 1])\n",
      "torch.Size([100, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_shift.shape)\n",
    "print(x_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.pinv(z_q).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9380e-14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x_shift - x_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nicc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
