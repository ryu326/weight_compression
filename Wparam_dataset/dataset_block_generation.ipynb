{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "dtype = np.float32\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from transformers import CLIPVisionModelWithProjection, AutoModelForCausalLM\n",
    "from transformers import AutoModel, AutoTokenizer, OPTForCausalLM, BloomForCausalLM\n",
    "import numpy\n",
    "\n",
    "from huggingface_hub import try_to_load_from_cache, _CACHED_NO_EXIST\n",
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_named_linears(module):\n",
    "    return {name: m for name, m in module.named_modules() if isinstance(m, nn.Linear)}\n",
    "\n",
    "def get_blocks(model):\n",
    "    if model.__class__.__name__ in (\"LlamaForCausalLM\", \"Qwen2ForCausalLM\"):\n",
    "        layers = model.model.layers\n",
    "    elif model.__class__.__name__ == \"LlavaLlamaForCausalLM\":\n",
    "        layers = model.model.layers\n",
    "    elif isinstance(model, OPTForCausalLM):\n",
    "        layers = model.model.decoder.layers\n",
    "    elif isinstance(model, BloomForCausalLM):\n",
    "        layers = model.transformer.h\n",
    "    elif \"mpt\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.blocks\n",
    "    elif \"falcon\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.h\n",
    "    elif \"bigcode\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.h\n",
    "    elif \"neox\" in str(model.__class__).lower():\n",
    "        layers = model.gpt_neox.layers\n",
    "    elif model.__class__.__name__ == \"LlavaLlamaModel\":\n",
    "        layers = model.llm.model.layers\n",
    "    elif model.__class__.__name__ in (\"CLIPModel\"):\n",
    "        vision_layers = model.vision_model.encoder.layers\n",
    "        text_layers = model.text_model.encoder.layers\n",
    "        layers = {'vision': vision_layers,\n",
    "                  'text': text_layers}\n",
    "    else:\n",
    "        raise NotImplementedError(type(model))\n",
    "    # if not isinstance(layers, dict):\n",
    "    #     layers = {'': layers}\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dignal Scaled RHT Weight Block\n",
    "\n",
    "많이 수정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_to_sym(V, N):\n",
    "    A = torch.zeros(N, N, dtype=V.dtype, device=V.device)\n",
    "    idxs = torch.tril_indices(N, N, device=V.device)\n",
    "    A[idxs.unbind()] = V\n",
    "    A[idxs[1, :], idxs[0, :]] = V\n",
    "    return A\n",
    "\n",
    "def regularize_H(H, n, sigma_reg):\n",
    "    H.div_(torch.diag(H).mean())\n",
    "    idx = torch.arange(n)\n",
    "    H[idx, idx] += sigma_reg\n",
    "    return H\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/Weight_compression/Wparam_dataset')\n",
    "from utils import *\n",
    "\n",
    "def RHT_H(H, SU):\n",
    "    return matmul_hadUt(matmul_hadUt(H * SU).T * SU)\n",
    "\n",
    "\n",
    "def RHT_W(W, SU, SV):\n",
    "    return matmul_hadUt(matmul_hadUt(W.T * SV).T * SU)\n",
    "\n",
    "\n",
    "def incoherence_preprocess(H, W, args):\n",
    "    # dtype_ = torch.float64 if args.use_fp64 else torch.float32\n",
    "    dtype_ = torch.float32\n",
    "    device = H.device\n",
    "    # device = torch.device('cpu')\n",
    "    (m, n) = H.shape\n",
    "\n",
    "    def _dump(Hr, Lhr, msg=''):\n",
    "        torch.save(Hr, f\"{args.save_pfx}/Hr_debug_fft.pt\")\n",
    "        torch.save(Lhr, f\"{args.save_pfx}/Lhr_debug_fft.pt\")\n",
    "        raise Exception(msg)\n",
    "\n",
    "    # diagonally rescale W,H to minimize proxy loss\n",
    "    scaleWH = None\n",
    "    Wr = W\n",
    "    Hr = H\n",
    "    # if args.rescale_WH:\n",
    "    if False:\n",
    "        Hr = H / H.abs().max()\n",
    "        diagH = torch.diag(Hr)\n",
    "        diagW2 = torch.diag(W.T @ W)\n",
    "        diagH = torch.clamp(diagH, min=1e-8)\n",
    "        diagW2 = torch.clamp(diagW2, min=1e-8)\n",
    "        scaleWH = (diagH / diagW2).sqrt().sqrt().to(torch.float32)\n",
    "        scaleWH = scaleWH.clamp(min=1e-8)\n",
    "        Wr = Wr * scaleWH[None, :]\n",
    "        Hr = Hr / scaleWH[None, :]\n",
    "        Hr = Hr / scaleWH[:, None]\n",
    "        scaleWH = scaleWH.cpu()\n",
    "\n",
    "    # randomized hadamard transformation on H, W\n",
    "    if True:\n",
    "        SU = (torch.randn(n, device=device).sign() + 1e-5).sign().to(dtype_)\n",
    "        SV = (torch.randn(m, device=device).sign() + 1e-5).sign().to(dtype_)\n",
    "        Hr = RHT_H(Hr, SU)\n",
    "        # Wr = RHT_W(Wr, SU, SV)\n",
    "    # randomized kronecker product on H, W\n",
    "    elif args.incoh_mode == \"kron\":\n",
    "        SU = utils.rand_ortho_butterfly_noblock(n).to(dtype_).to(device)\n",
    "        SV = utils.rand_ortho_butterfly_noblock(m).to(dtype_).to(device)\n",
    "        Hr = SU @ Hr @ SU.T\n",
    "        Wr = SV @ Wr @ SU.T\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    SV = SV.cpu()\n",
    "    SU = SU.cpu()\n",
    "\n",
    "    # Lhr = torch.linalg.cholesky(Hr)\n",
    "    Lhr = None\n",
    "    # if not torch.all(torch.isfinite(Lhr)):\n",
    "    #     return None\n",
    "\n",
    "    # Wr = Wr.to(device)\n",
    "\n",
    "    return Lhr, Hr, Wr, SU, SV, scaleWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Meta-Llama-3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  8.03it/s]\n",
      "100%|██████████| 32/32 [01:44<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total weight shape:  torch.Size([6815744, 1024])\n",
      "train:  torch.Size([6814744, 1024]) val:  torch.Size([1000, 1024])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    # 'meta-llama--Llama-2-7b-hf'\n",
    "]\n",
    "\n",
    "quip_hess_path = [\n",
    "    './quip_hess/llama3_8b_6144',\n",
    "    # './quip_hess/Hessians-Llama-2-7b-6144',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    1024,\n",
    "    # 4096\n",
    "]\n",
    "\n",
    "wtype_mapping = {'self_attn.q_proj': 0, \n",
    "                 'self_attn.k_proj': 1, \n",
    "                 'self_attn.v_proj': 2, \n",
    "                 'self_attn.o_proj': 3, \n",
    "                 'mlp.gate_proj': 4, \n",
    "                 'mlp.up_proj': 5, \n",
    "                 'mlp.down_proj': 6}\n",
    "sigma_reg = 1e-4\n",
    "# direction = 'col'\n",
    "direction = 'row'\n",
    "\n",
    "for model_name, size, quip_hess in zip(model_list, size_list, quip_hess_path):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "    \n",
    "    # datas = []\n",
    "    datas = {}\n",
    "    datas['weight'] = []\n",
    "    datas['idx'] = []\n",
    "    datas['layer_type'] = []\n",
    "    datas['scale'] = []\n",
    "    \n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        \n",
    "        hess_dict = {}\n",
    "        hess_dict['qkv'] = torch.load(f'{quip_hess}/{i}_qkv.pt', weights_only=False)\n",
    "        hess_dict['o'] = torch.load(f'{quip_hess}/{i}_o.pt', weights_only=False)\n",
    "        hess_dict['up'] = torch.load(f'{quip_hess}/{i}_up.pt', weights_only=False)\n",
    "        hess_dict['down'] = torch.load(f'{quip_hess}/{i}_down.pt', weights_only=False)\n",
    "        \n",
    "        for n, m in named_linears.items():\n",
    "            \n",
    "            W = m.weight.data.detach().to(device)\n",
    "            \n",
    "            if 'q_proj' in n or 'k_proj' in n or 'v_proj' in n:\n",
    "                H_flat = hess_dict['qkv']\n",
    "            elif 'o_proj' in n:\n",
    "                H_flat = hess_dict['o']\n",
    "            elif 'up_proj' in n or 'gate_proj' in n:\n",
    "                H_flat = hess_dict['up']\n",
    "            elif 'down_proj' in n:\n",
    "                H_flat = hess_dict['down']\n",
    "            else:\n",
    "                raise NotImplementedError(n)\n",
    "            \n",
    "            H = flat_to_sym(H_flat['flatH'], H_flat['n']).to(device)\n",
    "            mu = H_flat['mu'].to(device)\n",
    "            H.add_(mu[None, :] * mu[:, None])\n",
    "            n_h = H_flat['n']\n",
    "\n",
    "            # print('before',torch.diag(H).mean())\n",
    "            H = regularize_H(H, n_h, sigma_reg)\n",
    "            # print('after',torch.diag(H).mean())\n",
    "\n",
    "            ## 1\n",
    "            # diagH = torch.diag(H)\n",
    "            # diagW2 = torch.diag(W.T @ W)\n",
    "            # diagH = torch.clamp(diagH, min=1e-8)\n",
    "            # diagW2 = torch.clamp(diagW2, min=1e-8)\n",
    "            # scaleWH = (diagH / diagW2).sqrt()\n",
    "            # scaleWH = diagH.sqrt()\n",
    "            # scaleWH = scaleWH.clamp(min=1)\n",
    "            # print(scaleWH.numel())\n",
    "            # print((scaleWH>=1).sum() / scaleWH.numel())\n",
    "            # fig = plt.figure()\n",
    "            # ax = fig.add_subplot(111)\n",
    "            # ax.plot(scaleWH.cpu().numpy())\n",
    "            # plt.show\n",
    "            \n",
    "            # (M, N) = W.shape\n",
    "            # SU = (torch.randn(N).sign() + 1e-5).sign().to(device)\n",
    "            # SV = (torch.randn(M).sign() + 1e-5).sign().to(device)\n",
    "            # Wr = RHT_W(Wr, SU, SV)\n",
    "\n",
    "            ## 2\n",
    "            diagH = torch.diag(H)\n",
    "            diagH = torch.clamp(diagH, min=1e-8)\n",
    "            scaleWH = diagH.sqrt()\n",
    "            Wr = W * scaleWH[None, :]\n",
    "            # W_normalized = Wr / Wr.norm(p=2, dim=1, keepdim=True)\n",
    "            W_normalized = Wr / Wr.std(dim=1, keepdim=True)\n",
    "            Wr = W_normalized\n",
    "            \n",
    "            ## 4 invH\n",
    "            # Lhr = torch.linalg.cholesky(H)\n",
    "            # H_inv = torch.cholesky_inverse(Lhr)\n",
    "            # diagH_inv = torch.diag(H_inv)\n",
    "            # scaleWH = 1/diagH_inv\n",
    "            # scaleWH = torch.clamp(scaleWH, min=1e-8)\n",
    "            # scaleWH = scaleWH.sqrt()\n",
    "            # Wr = W * scaleWH[None, :]\n",
    "            # # W_normalized = Wr / Wr.norm(p=2, dim=1, keepdim=True)\n",
    "            # W_normalized = Wr / Wr.std(dim=1, keepdim=True)\n",
    "            # Wr = W_normalized\n",
    "            \n",
    "            ## 3\n",
    "            # W_normalized = W / W.norm(p=2, dim=1, keepdim=True)\n",
    "            # Wr = W_normalized            \n",
    "            \n",
    "            # print(Wr.norm(p=2, dim=1)[:10])\n",
    "            \n",
    "            ## 5 with col std\n",
    "            col_std = Wr.std(dim=0, keepdim=True)\n",
    "            col_std = col_std.expand(Wr.shape[0], Wr.shape[1])\n",
    "            \n",
    "            if direction == 'col':\n",
    "                w = Wr.T.to('cpu')\n",
    "                s = col_std.T.to('cpu')\n",
    "            else:\n",
    "                w = Wr.to('cpu')\n",
    "                s = col_std.to('cpu')\n",
    "            \n",
    "            if w.shape[-1] % size == 0:\n",
    "                w = w.reshape(-1, size)\n",
    "                s = s.reshape(-1, size)\n",
    "            else:\n",
    "                raise\n",
    "                D = w.shape[1]\n",
    "                span = size * (D //size)\n",
    "                if D < span:\n",
    "                    raise ValueError(\"Tensor's second dimension is too small for the requested slice.\")\n",
    "                max_start = D - span\n",
    "                start = random.randint(0, max_start)\n",
    "                sliced = w[:, start : start + span]\n",
    "                w = sliced.reshape(-1, size)\n",
    "\n",
    "            # datas.append(w)\n",
    "\n",
    "            datas['weight'].append(w)\n",
    "            datas['scale'].append(s)\n",
    "            \n",
    "            idx = torch.tensor([i], dtype = torch.int8)\n",
    "            datas['idx'].extend([idx] * w.shape[0])\n",
    "            \n",
    "            layer_type = torch.tensor([wtype_mapping[n]], dtype = torch.int8)\n",
    "            datas['layer_type'].extend([layer_type] * w.shape[0])\n",
    "    \n",
    "    for k in datas.keys():\n",
    "        # if datas[k][0].shape == torch.Size([]):\n",
    "        #     datas[k] = torch.tensor(datas[k])\n",
    "        # else:\n",
    "        datas[k] = torch.cat(datas[k], dim = 0)\n",
    "    \n",
    "    print('total weight shape: ', datas['weight'].shape)\n",
    "    \n",
    "    indices = torch.randperm(len(datas['weight']))\n",
    "    split_index = int(len(datas['weight']) - 1000)\n",
    "    train_indices = indices[:split_index]\n",
    "    val_indices = indices[split_index:]\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train'] = {}\n",
    "    dataset['val'] = {}\n",
    "    for k in datas.keys():\n",
    "        dataset['train'][k] = datas[k][train_indices]\n",
    "        dataset['val'][k] = datas[k][val_indices]\n",
    "        \n",
    "    print('train: ', dataset['train']['weight'].shape, 'val: ', dataset['val']['weight'].shape)\n",
    "\n",
    "    dataset_stats = {}\n",
    "    for split in ['train', 'val']:\n",
    "        data = dataset[split]\n",
    "        \n",
    "        # mean_dim0 = data['weight'].mean(dim=0)\n",
    "        # std_dim0 = data['weight'].std(dim=0)\n",
    "        \n",
    "        mean_all = data['weight'].mean()\n",
    "        std_all = data['weight'].std()\n",
    "        \n",
    "        dataset_stats[split] = {\n",
    "            'mean': mean_all.item(),\n",
    "            'std': std_all.item(),\n",
    "            'mean_channel': None,\n",
    "            'std_channel': None\n",
    "        }\n",
    "    \n",
    "    # datas = torch.cat(datas, dim = 0)\n",
    "    # print('total dataset shape: ', datas.shape)\n",
    "    \n",
    "    # indices = torch.randperm(len(datas))\n",
    "    # split_index = int(len(datas) - 1000)\n",
    "    # train_indices = indices[:split_index]\n",
    "    # val_indices = indices[split_index:]\n",
    "\n",
    "    # dataset = {}\n",
    "    # dataset['train'] = datas[train_indices]\n",
    "    # dataset['val'] = datas[val_indices]\n",
    "    # print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "    # dataset_stats = {}\n",
    "    # for split in ['train', 'val']:\n",
    "    #     data = dataset[split]\n",
    "        \n",
    "    #     # mean_dim0 = data.mean(dim=0)\n",
    "    #     # std_dim0 = data.std(dim=0)\n",
    "        \n",
    "    #     mean_all = data.mean()\n",
    "    #     std_all = data.std()\n",
    "        \n",
    "    #     dataset_stats[split] = {\n",
    "    #         'mean': mean_all.item(),\n",
    "    #         'std': std_all.item(),\n",
    "    #         # 'mean_channel': mean_dim0.tolist(),\n",
    "    #         # 'std_channel': std_dim0.tolist(),\n",
    "    #         'mean_channel': None,\n",
    "    #         'std_channel': None,\n",
    "    #     }\n",
    "\n",
    "    os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    ## 1\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/scaled3_RHT_sig{sigma_reg}_{direction}_{size}.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/scaled3_RHT_sig{sigma_reg}_{direction}_{size}_dataset_stats.json'\n",
    "    ## 2\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/scaleH_sig{sigma_reg}_std_rnormed_lidx_{direction}_{size}.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/scaleH_sig{sigma_reg}_std_rnormed_lidx_{direction}_{size}_dataset_stats.json'\n",
    "    ## 3\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/rnormed_{direction}_{size}.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/rnormed_{direction}_{size}_dataset_stats.json'\n",
    "    ## 4\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/scaleHinv_sig{sigma_reg}_std_rnormed_lidx_{direction}_{size}.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/scaleHinv_sig{sigma_reg}_std_rnormed_lidx_{direction}_{size}_dataset_stats.json'\n",
    "    ## 5\n",
    "    torch.save(dataset, f'./block_pt/{model_name}/scaleH_sig{sigma_reg}_std_rnormed_with_col_std_lidx_{direction}_{size}.pt')\n",
    "    json_path = f'./block_pt/{model_name}/scaleH_sig{sigma_reg}_std_rnormed_with_col_std_lidx_{direction}_{size}_dataset_stats.json'\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'scale' column:\n",
      "  - Minimum value: 0.000052\n",
      "  - Maximum value: 31.643507\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "dataset = torch.load('/workspace/Weight_compression/Wparam_dataset/block_pt/meta-llama--Meta-Llama-3-8B/scaleH_sig0.0001_std_rnormed_with_col_std_lidx_row_1024.pt')\n",
    "\n",
    "scale_data = np.array(dataset['train']['scale'].flatten())\n",
    "\n",
    "\n",
    "WEIGHT_SAMPLE_SIZE = 1000000 # Number of weights to sample from each matrix\n",
    "scale_data = np.random.choice(scale_data, WEIGHT_SAMPLE_SIZE, replace=False)\n",
    "\n",
    "# 2. Calculate min and max values\n",
    "min_val = scale_data.min()\n",
    "max_val = scale_data.max()\n",
    "\n",
    "# 3. Print the results\n",
    "print(f\"Statistics for 'scale' column:\")\n",
    "print(f\"  - Minimum value: {min_val:.6f}\")\n",
    "print(f\"  - Maximum value: {max_val:.6f}\")\n",
    "\n",
    "# 4. Plot the distribution\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Using seaborn's histplot which is great for distributions\n",
    "sns.histplot(scale_data, kde=True, ax=ax, bins=50)\n",
    "\n",
    "ax.set_title(\"Distribution of 'scale' values\", fontsize=16)\n",
    "ax.set_xlabel(\"Scale Value\", fontsize=12)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Add vertical lines for min and max for better visualization\n",
    "ax.axvline(min_val, color='red', linestyle='--', label=f'Min: {min_val:.4f}')\n",
    "ax.axvline(max_val, color='green', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Meta-Llama-3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  7.39it/s]\n",
      "  0%|          | 0/32 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m named_linears\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     58\u001b[0m     W \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mdescribe_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     61\u001b[0m         stats[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m v\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mdescribe_distribution\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     22\u001b[0m kurtosis \u001b[38;5;241m=\u001b[39m ((x \u001b[38;5;241m-\u001b[39m mean)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m/\u001b[39m (std_dev\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Fisher's definition\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m: median\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m: std_dev\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m\"\u001b[39m: value_range\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miqr\u001b[39m\u001b[38;5;124m\"\u001b[39m: iqr\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskewness\u001b[39m\u001b[38;5;124m\"\u001b[39m: skewness\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkurtosis\u001b[39m\u001b[38;5;124m\"\u001b[39m: kurtosis\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     33\u001b[0m }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def describe_distribution(x):\n",
    "    assert isinstance(x, torch.Tensor), \"Input must be a PyTorch tensor\"\n",
    "    x = x.flatten().float()\n",
    "    n = x.numel()\n",
    "    \n",
    "    # 중심 경향\n",
    "    mean = x.mean()\n",
    "    median = x.median()\n",
    "\n",
    "    # 산포도\n",
    "    std_dev = x.std(unbiased=False)\n",
    "    value_range = x.max() - x.min()\n",
    "    q1 = x.kthvalue(int(0.25 * n + 1)).values\n",
    "    q3 = x.kthvalue(int(0.75 * n + 1)).values\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # 모양\n",
    "    skewness = ((x - mean)**3).mean() / (std_dev**3)\n",
    "    kurtosis = ((x - mean)**4).mean() / (std_dev**4) - 3  # Fisher's definition\n",
    "\n",
    "    del x\n",
    "    return {\n",
    "        \"mean\": mean.item(),\n",
    "        \"median\": median.item(),\n",
    "        \"std\": std_dev.item(),\n",
    "        \"range\": value_range.item(),\n",
    "        \"iqr\": iqr.item(),\n",
    "        \"skewness\": skewness.item(),\n",
    "        \"kurtosis\": kurtosis.item()\n",
    "    }\n",
    "\n",
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "    # 'meta-llama--Llama-2-13b-hf',\n",
    "]\n",
    "\n",
    "\n",
    "for model_name in model_list:\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "\n",
    "    # std = defaultdict(list)\n",
    "    # mean = defaultdict(list)\n",
    "    stats = {}\n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            W = m.weight.data.to('cuda:0')\n",
    "            r = describe_distribution(W)\n",
    "            for k,v in r.items():\n",
    "                stats[f'{i}_{n}_{k}'] = v\n",
    "            \n",
    "    fig, ax = plt.subplots(1, len(r), figsize=(15, 3))\n",
    "    \n",
    "    for idx, k in enumerate(r.keys()):\n",
    "        ax[idx].set_title(k)\n",
    "        for n, m in named_linears.items():\n",
    "            list = []\n",
    "            for i in range(len(layers)):\n",
    "                list.append(stats[f'{i}_{n}_{k}'])\n",
    "            ax[idx].plot(list, label=n)\n",
    "        # ax[idx].legend()\n",
    "        ax[idx].set_xlabel('Layer')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block with idx ltype stats\n",
    "droplast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.61it/s]\n",
      "100%|██████████| 32/32 [06:46<00:00, 12.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total weight shape:  torch.Size([6127616, 1024])\n",
      "train:  torch.Size([6126616, 1024]) val:  torch.Size([1000, 1024])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    # 'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "#     'meta-llama--Llama-2-13b-hf',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    1024\n",
    "]\n",
    "\n",
    "wtype_mapping = {'self_attn.q_proj': 0, \n",
    "                 'self_attn.k_proj': 1, \n",
    "                 'self_attn.v_proj': 2, \n",
    "                 'self_attn.o_proj': 3, \n",
    "                 'mlp.gate_proj': 4, \n",
    "                 'mlp.up_proj': 5, \n",
    "                 'mlp.down_proj': 6}\n",
    "\n",
    "direction = 'col'\n",
    "shuffle = False\n",
    "drop_last = True\n",
    "\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "    \n",
    "    datas = {}\n",
    "    datas['weight'] = []\n",
    "    datas['idx'] = []\n",
    "    datas['layer_type'] = []\n",
    "    datas['mean'] = []\n",
    "    datas['median'] = []\n",
    "    datas['std'] = []\n",
    "    datas['range'] = []\n",
    "    datas['iqr'] = []\n",
    "    datas['skewness'] = []\n",
    "    datas['kurtosis'] = []\n",
    "    \n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            w = m.weight.data.detach()\n",
    "            \n",
    "            stats = describe_distribution(w)\n",
    "            \n",
    "            if direction == 'col':\n",
    "                w = w.T\n",
    "\n",
    "            if shuffle:\n",
    "                w = w.reshape(-1, 16)  # (num_rows, 16)\n",
    "                indices = torch.randperm(w.size(0))  # row 인덱스 섞기\n",
    "                w = w[indices]  # 섞인 순서대로 row 재배열\n",
    "                \n",
    "            if drop_last:\n",
    "                (r, c) = w.shape\n",
    "                d = (c // size) * size\n",
    "                w = w[:, :d]\n",
    "\n",
    "            w = w.reshape(-1, size)\n",
    "            \n",
    "            if drop_last:\n",
    "                assert w.shape[0] % r == 0\n",
    "                \n",
    "            # if w.size(0) % size == 0:\n",
    "            #     w = w.T    \n",
    "            #     w = w.reshape(-1, size)\n",
    "            # else:\n",
    "            #     w = w.reshape(-1, size)\n",
    "                \n",
    "            datas['weight'].append(w)\n",
    "            \n",
    "            idx = torch.tensor([i], dtype = torch.int8)\n",
    "            datas['idx'].extend([idx] * w.shape[0])\n",
    "            \n",
    "            layer_type = torch.tensor([wtype_mapping[n]], dtype = torch.int8)\n",
    "            datas['layer_type'].extend([layer_type] * w.shape[0])\n",
    "            \n",
    "            for k, v in stats.items():\n",
    "                val_tensor = torch.tensor([v], dtype=torch.float32)\n",
    "                datas[k].extend([val_tensor] * w.shape[0])\n",
    "    \n",
    "    for k in datas.keys():\n",
    "        # if datas[k][0].shape == torch.Size([]):\n",
    "        #     datas[k] = torch.tensor(datas[k])\n",
    "        # else:\n",
    "        datas[k] = torch.cat(datas[k], dim = 0)\n",
    "    \n",
    "    print('total weight shape: ', datas['weight'].shape)\n",
    "    \n",
    "    indices = torch.randperm(len(datas['weight']))\n",
    "    split_index = int(len(datas['weight']) - 1000)\n",
    "    train_indices = indices[:split_index]\n",
    "    val_indices = indices[split_index:]\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train'] = {}\n",
    "    dataset['val'] = {}\n",
    "    for k in datas.keys():\n",
    "        dataset['train'][k] = datas[k][train_indices]\n",
    "        dataset['val'][k] = datas[k][val_indices]\n",
    "        \n",
    "    print('train: ', dataset['train']['weight'].shape, 'val: ', dataset['val']['weight'].shape)\n",
    "\n",
    "    dataset_stats = {}\n",
    "    for split in ['train', 'val']:\n",
    "        data = dataset[split]\n",
    "        \n",
    "        mean_dim0 = data['weight'].mean(dim=0)\n",
    "        std_dim0 = data['weight'].std(dim=0)\n",
    "        \n",
    "        mean_all = data['weight'].mean()\n",
    "        std_all = data['weight'].std()\n",
    "        \n",
    "        dataset_stats[split] = {\n",
    "            'mean': mean_all.item(),\n",
    "            'std': std_all.item(),\n",
    "            'mean_channel': mean_dim0.tolist(),\n",
    "            'std_channel': std_dim0.tolist(),\n",
    "        }\n",
    "\n",
    "    # os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/{direction}_{size}_layerwise_stats.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/{direction}_{size}_layerwise_stats_dataset_stats.json'\n",
    "    # with open(json_path, 'w') as f:\n",
    "    #     json.dump(dataset_stats, f)\n",
    "        \n",
    "    sub = ''\n",
    "    if shuffle:\n",
    "        sub += 'shuffled_'\n",
    "    if drop_last:\n",
    "        sub += 'droplast_'\n",
    "    os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    torch.save(dataset, f'./block_pt/{model_name}/{sub}{direction}_{size}_idx_ltype_stats.pt')\n",
    "    json_path = f'./block_pt/{model_name}/{sub}{direction}_{size}_idx_ltype_stats_dataset_stats.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5469,  2.6361, -0.1016],\n",
      "        [ 1.1328,  2.3082,  2.6023],\n",
      "        [ 0.4617,  1.7054, -1.7808],\n",
      "        ...,\n",
      "        [-0.0045,  1.9968,  1.9926],\n",
      "        [ 0.7723,  2.4261, -2.2338],\n",
      "        [ 1.5540,  3.0081, -0.6574]])\n",
      "tensor([-0.0077,  2.0123, -0.9304])\n",
      "tensor([1.0347, 0.5134, 2.0589])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 크기 설정 (예: 5x3 행렬)\n",
    "rows, cols = 1000, 3\n",
    "\n",
    "# 열별 평균과 표준편차 정의\n",
    "mean = torch.tensor([0.0, 2.0, -1.0])  # 열별 평균값\n",
    "std = torch.tensor([1.0, 0.5, 2.0])    # 열별 표준편차\n",
    "\n",
    "# 가우시안 랜덤 행렬 생성 (브로드캐스팅 활용)\n",
    "random_matrix = torch.normal(mean.expand(rows, cols), std.expand(rows, cols))\n",
    "\n",
    "print(random_matrix)\n",
    "print(random_matrix.mean(0))\n",
    "print(random_matrix.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Meta-Llama-3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.self_attn.q_proj torch.Size([4096, 4096])\n",
      "0.self_attn.k_proj torch.Size([1024, 4096])\n",
      "0.self_attn.v_proj torch.Size([1024, 4096])\n",
      "0.self_attn.o_proj torch.Size([4096, 4096])\n",
      "0.mlp.gate_proj torch.Size([14336, 4096])\n",
      "0.mlp.up_proj torch.Size([14336, 4096])\n",
      "0.mlp.down_proj torch.Size([4096, 14336])\n",
      "model_name:  meta-llama--Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.self_attn.q_proj torch.Size([4096, 4096])\n",
      "0.self_attn.k_proj torch.Size([4096, 4096])\n",
      "0.self_attn.v_proj torch.Size([4096, 4096])\n",
      "0.self_attn.o_proj torch.Size([4096, 4096])\n",
      "0.mlp.gate_proj torch.Size([11008, 4096])\n",
      "0.mlp.up_proj torch.Size([11008, 4096])\n",
      "0.mlp.down_proj torch.Size([4096, 11008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "    # 'meta-llama--Llama-2-13b-hf',\n",
    "    # 'openai/clip-vit-large-patch14',\n",
    "    \n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    1024,\n",
    "    4096,\n",
    "    # 5120//4,\n",
    "]\n",
    "\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    # model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)[0:1]\n",
    "\n",
    "    if not isinstance(layers, dict):\n",
    "        layers = {'': layers}\n",
    "\n",
    "    for k, v in layers.items():\n",
    "        print(k)\n",
    "        named_linears = get_named_linears(v)\n",
    "        for n, m in named_linears.items():\n",
    "            print(n, m.weight.data.shape)\n",
    "            W = m.weight.data\n",
    "            r, c = W.shape\n",
    "\n",
    "        # mean_c = W.mean(0)\n",
    "        # std_c = W.std(0)\n",
    "        # if r % size != 0:\n",
    "        #     padding_size = size - r % size\n",
    "        #     g = torch.normal(mean_c.expand(padding_size, c), std_c.expand(padding_size, c))\n",
    "        #     W = torch.cat([W, g], dim=0)\n",
    "        #     print('padding')\n",
    "        #     print(n, W.shape)\n",
    "        #     print(mean_c[:5], std_c[:5])\n",
    "        #     print(W.mean(0)[:5], W.std(0)[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block\n",
    "### layerwise suffle\n",
    "레이어 안에서 16 block으로 섞음\n",
    "### drop last\n",
    "### 8b + 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Meta-Llama-3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 144.67it/s]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Llama-2-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 128.87it/s]\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset shape:  torch.Size([12943360, 1024])\n",
      "train:  torch.Size([12942360, 1024]) val:  torch.Size([1000, 1024])\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "    # 'meta-llama--Llama-2-13b-hf',\n",
    "    # 'openai--clip-vit-large-patch14',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    1024,\n",
    "    1024,\n",
    "    # 4096,\n",
    "    # 256,\n",
    "]\n",
    "\n",
    "direction = 'col'\n",
    "shuffle = False\n",
    "drop_last = True\n",
    "modelwise_norm = True\n",
    "\n",
    "model_datas = []\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    # model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "    # layers_ = get_blocks(model)    \n",
    "    layers = get_blocks(model)    \n",
    "\n",
    "    # datas = []    \n",
    "    # for sub in layers_:\n",
    "        # layers = layers_[sub]\n",
    "    # if sub == 'vision':\n",
    "    #     size = 1024\n",
    "    # elif sub == 'text':\n",
    "    #     size = 768\n",
    "    # else:\n",
    "    #     raise\n",
    "    \n",
    "    datas = []\n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            w = m.weight.data.detach()\n",
    "            \n",
    "            # if w.size(0) % size == 0:\n",
    "            #     w = w.T    \n",
    "            #     w = w.reshape(-1, size)\n",
    "            # else:\n",
    "            #     w = w.reshape(-1, size)\n",
    "            \n",
    "            if direction == 'col':\n",
    "                w = w.T\n",
    "\n",
    "            if shuffle:\n",
    "                w = w.reshape(-1, 16)  # (num_rows, 16)\n",
    "                indices = torch.randperm(w.size(0))  # row 인덱스 섞기\n",
    "                w = w[indices]  # 섞인 순서대로 row 재배열\n",
    "                \n",
    "            if drop_last:\n",
    "                (r, c) = w.shape\n",
    "                d = (c // size) * size\n",
    "                w = w[:, :d]\n",
    "\n",
    "            w = w.reshape(-1, size)\n",
    "            \n",
    "            if drop_last:\n",
    "                assert w.shape[0] % r == 0\n",
    "\n",
    "            datas.append(w)\n",
    "        \n",
    "    datas = torch.cat(datas, dim = 0)\n",
    "    if modelwise_norm:\n",
    "        mu = datas.mean()\n",
    "        std = datas.std()\n",
    "        datas = (datas - mu) / std\n",
    "        \n",
    "    model_datas.append(datas)\n",
    "    \n",
    "model_name = 'llama8b+7b'\n",
    "model_datas = torch.cat(model_datas, dim = 0)\n",
    "print('total dataset shape: ', model_datas.shape)\n",
    "datas = model_datas\n",
    "\n",
    "indices = torch.randperm(len(datas))\n",
    "split_index = int(len(datas) - 1000)\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = datas[train_indices]\n",
    "dataset['val'] = datas[val_indices]\n",
    "print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "dataset_stats = {}\n",
    "for split in ['train', 'val']:\n",
    "    data = dataset[split]\n",
    "    \n",
    "    dataset_stats[split] = {\n",
    "        'mean': data.mean().item(),\n",
    "        'std': data.std().item(),\n",
    "        # 'mean_channel': data.mean(dim=0).tolist(),\n",
    "        # 'std_channel': data.std(dim=0).tolist(),\n",
    "    }\n",
    "\n",
    "# if sub != '':\n",
    "#     sub = sub+ '_'\n",
    "# sub = 'vision_text_'\n",
    "sub = ''\n",
    "if shuffle:\n",
    "    sub += 'shuffled_'\n",
    "if drop_last:\n",
    "    sub += 'droplast_'\n",
    "if modelwise_norm:\n",
    "    sub += 'modelwise_norm2_'\n",
    "os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "torch.save(dataset, f'./block_pt/{model_name}/{sub}{direction}_{size}.pt')\n",
    "json_path = f'./block_pt/{model_name}/{sub}{direction}_{size}_dataset_stats.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gaussian block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6814744, 1024])\n",
      "torch.Size([1000, 1024])\n"
     ]
    }
   ],
   "source": [
    "d = torch.load('/workspace/Weight_compression/Wparam_dataset/block_pt/meta-llama--Meta-Llama-3-8B/col_1024_gaussian_padding.pt')\n",
    "print(d['train'].shape)\n",
    "print(d['val'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['train'] = torch.normal(mean=0.0, std=1.0, size=d['train'].shape)\n",
    "dataset['val'] = torch.normal(mean=0.0, std=1.0, size=d['val'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  torch.Size([6814744, 1024]) val:  torch.Size([1000, 1024])\n"
     ]
    }
   ],
   "source": [
    "print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "dataset_stats = {}\n",
    "for split in ['train', 'val']:\n",
    "    data = dataset[split]\n",
    "    \n",
    "    mean_all = data.mean()\n",
    "    std_all = data.std()\n",
    "    \n",
    "    dataset_stats[split] = {\n",
    "        'mean': mean_all.item(),\n",
    "        'std': std_all.item(),\n",
    "    }\n",
    "\n",
    "sub = 'llama8b_'\n",
    "direction = 'col'\n",
    "size = 1024\n",
    "os.makedirs(f'./block_pt/gaussian', exist_ok = True)\n",
    "torch.save(dataset, f'./block_pt/gaussian/{sub}{direction}_{size}.pt')\n",
    "json_path = f'./block_pt/gaussian/{sub}{direction}_{size}_dataset_stats.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layerwise, channelwise normalized Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name:  meta-llama--Meta-Llama-3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 128.67it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset shape:  torch.Size([6815744, 1024])\n",
      "train:  torch.Size([6814744, 1024]) val:  torch.Size([1000, 1024])\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    # 'meta-llama--Llama-2-7b-hf',\n",
    "    # 'meta-llama--Llama-2-13b-hf',\n",
    "    # 'openai--clip-vit-large-patch14',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    1024,\n",
    "    # 4096,\n",
    "    # 4096,\n",
    "    # 256,\n",
    "]\n",
    "\n",
    "# direction = 'adapt'\n",
    "direction = 'col'\n",
    "\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    # model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "\n",
    "        \n",
    "    datas = []\n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            W = m.weight.data.detach().cuda()\n",
    "\n",
    "            W = (W - W.mean(dim=0, keepdim=True)) / W.std(dim=0, keepdim=True)\n",
    "            # W = (W - W.mean()) / W.std()\n",
    "            \n",
    "            if direction == 'col':\n",
    "                W = W.T    \n",
    "            W = W.reshape(-1, size).cpu()\n",
    "                \n",
    "            datas.append(W)\n",
    "        \n",
    "    datas = torch.cat(datas, dim = 0)\n",
    "    print('total dataset shape: ', datas.shape)\n",
    "    \n",
    "    indices = torch.randperm(len(datas))\n",
    "    split_index = int(len(datas) - 1000)\n",
    "    train_indices = indices[:split_index]\n",
    "    val_indices = indices[split_index:]\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train'] = datas[train_indices]\n",
    "    dataset['val'] = datas[val_indices]\n",
    "    print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "    dataset_stats = {}\n",
    "    for split in ['train', 'val']:\n",
    "        data = dataset[split]\n",
    "        \n",
    "        # mean_dim0 = data.mean(dim=0)\n",
    "        # std_dim0 = data.std(dim=0)        \n",
    "        # mean_all = data.mean()\n",
    "        # std_all = data.std()\n",
    "        \n",
    "        # dataset_stats[split] = {\n",
    "        #     'mean': mean_all.item(),\n",
    "        #     'std': std_all.item(),\n",
    "        #     'mean_channel': mean_dim0.tolist(),\n",
    "        #     'std_channel': std_dim0.tolist(),\n",
    "        # }\n",
    "        dataset_stats[split] = {\n",
    "            'mean': 0,\n",
    "            'std': 1,\n",
    "            'mean_channel': None,\n",
    "            'std_channel': None,\n",
    "        }\n",
    "        \n",
    "\n",
    "\n",
    "    os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    torch.save(dataset, f'./block_pt/{model_name}/{direction}_{size}_colwise_normed.pt')\n",
    "    json_path = f'./block_pt/{model_name}/{direction}_{size}_colwise_normed_dataset_stats.json'\n",
    "    # torch.save(dataset, f'./block_pt/{model_name}/{direction}_{size}_layerwise_normed.pt')\n",
    "    # json_path = f'./block_pt/{model_name}/{direction}_{size}_layerwise_normed_dataset_stats.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': ModuleList(\n",
       "   (0-31): 32 x LlamaDecoderLayer(\n",
       "     (self_attn): LlamaAttention(\n",
       "       (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "       (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "       (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "       (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "     )\n",
       "     (mlp): LlamaMLP(\n",
       "       (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "       (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "       (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "       (act_fn): SiLU()\n",
       "     )\n",
       "     (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "     (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gaussian padding\n",
    "\n",
    "size가 안 맞으면 같은 row 나 col의 mean, std를 갖는 가우시안으로 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # 'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "    'meta-llama--Llama-2-13b-hf',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    # 1024,\n",
    "    1024,\n",
    "    1280,\n",
    "]\n",
    "\n",
    "# direction = 'adapt'\n",
    "direction = 'col'\n",
    "\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "    \n",
    "    datas = []\n",
    "    \n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            W = m.weight.data.detach()\n",
    "\n",
    "            r, c = W.shape\n",
    "\n",
    "            if direction == 'col':\n",
    "                if r % size != 0:\n",
    "                    padding_size = size - r % size\n",
    "                    mean_c = W.mean(0)\n",
    "                    std_c = W.std(0)\n",
    "\n",
    "                    g = torch.normal(mean_c.expand(padding_size, c), std_c.expand(padding_size, c))\n",
    "                    W = torch.cat([W, g], dim=0)\n",
    "            elif direction =='row':\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                raise KeyError\n",
    "            \n",
    "            if direction == 'col':\n",
    "                W = W.T\n",
    "            \n",
    "            assert W.shape[1] % size == 0\n",
    "            assert W.shape[1] >= size\n",
    "\n",
    "            W = W.reshape(-1, size)\n",
    "                \n",
    "            datas.append(W)\n",
    "    \n",
    "    datas = torch.cat(datas, dim = 0)\n",
    "    print('total dataset shape: ', datas.shape)\n",
    "    \n",
    "    indices = torch.randperm(len(datas))\n",
    "    split_index = int(len(datas) - 1000)\n",
    "    train_indices = indices[:split_index]\n",
    "    val_indices = indices[split_index:]\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train'] = datas[train_indices]\n",
    "    dataset['val'] = datas[val_indices]\n",
    "    print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "    dataset_stats = {}\n",
    "    for split in ['train', 'val']:\n",
    "        data = dataset[split]\n",
    "        \n",
    "        mean_dim0 = data.mean(dim=0)\n",
    "        std_dim0 = data.std(dim=0)\n",
    "        \n",
    "        mean_all = data.mean()\n",
    "        std_all = data.std()\n",
    "        \n",
    "        dataset_stats[split] = {\n",
    "            'mean': mean_all.item(),\n",
    "            'std': std_all.item(),\n",
    "            'mean_channel': mean_dim0.tolist(),\n",
    "            'std_channel': std_dim0.tolist(),\n",
    "        }\n",
    "\n",
    "    os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    torch.save(dataset, f'./block_pt/{model_name}/{direction}_{size}_gaussian_padding.pt')\n",
    "    json_path = f'./block_pt/{model_name}/{direction}_{size}_gaussian_padding_dataset_stats.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RHT smoothed Weight Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Weight_compression/Wparam_dataset')\n",
    "from utils import *\n",
    "\n",
    "def RHT_H(H, SU):\n",
    "    return matmul_hadUt(matmul_hadUt(H * SU).T * SU)\n",
    "\n",
    "\n",
    "def RHT_W(W, SU, SV):\n",
    "    return matmul_hadUt(matmul_hadUt(W.T * SV).T * SU)\n",
    "\n",
    "\n",
    "def incoherence_preprocess(H, W, args):\n",
    "    # dtype_ = torch.float64 if args.use_fp64 else torch.float32\n",
    "    dtype_ = torch.float32\n",
    "    device = W.device\n",
    "    # device = torch.device('cpu')\n",
    "    (m, n) = W.shape\n",
    "\n",
    "    def _dump(Hr, Lhr, msg=''):\n",
    "        torch.save(Hr, f\"{args.save_pfx}/Hr_debug_fft.pt\")\n",
    "        torch.save(Lhr, f\"{args.save_pfx}/Lhr_debug_fft.pt\")\n",
    "        raise Exception(msg)\n",
    "\n",
    "    # diagonally rescale W,H to minimize proxy loss\n",
    "    scaleWH = None\n",
    "    Wr = W\n",
    "    Hr = H\n",
    "    # if args.rescale_WH:\n",
    "    if False:\n",
    "        Hr = H / H.abs().max()\n",
    "        diagH = torch.diag(Hr)\n",
    "        diagW2 = torch.diag(W.T @ W)\n",
    "        diagH = torch.clamp(diagH, min=1e-8)\n",
    "        diagW2 = torch.clamp(diagW2, min=1e-8)\n",
    "        scaleWH = (diagH / diagW2).sqrt().sqrt().to(torch.float32)\n",
    "        scaleWH = scaleWH.clamp(min=1e-8)\n",
    "        Wr = Wr * scaleWH[None, :]\n",
    "        Hr = Hr / scaleWH[None, :]\n",
    "        Hr = Hr / scaleWH[:, None]\n",
    "        scaleWH = scaleWH.cpu()\n",
    "\n",
    "    # randomized hadamard transformation on H, W\n",
    "    if True:\n",
    "        SU = (torch.randn(n, device=device).sign() + 1e-5).sign().to(dtype_)\n",
    "        SV = (torch.randn(m, device=device).sign() + 1e-5).sign().to(dtype_)\n",
    "        # Hr = RHT_H(Hr, SU)\n",
    "        Wr = RHT_W(Wr, SU, SV)\n",
    "    # randomized kronecker product on H, W\n",
    "    elif args.incoh_mode == \"kron\":\n",
    "        SU = utils.rand_ortho_butterfly_noblock(n).to(dtype_).to(device)\n",
    "        SV = utils.rand_ortho_butterfly_noblock(m).to(dtype_).to(device)\n",
    "        Hr = SU @ Hr @ SU.T\n",
    "        Wr = SV @ Wr @ SU.T\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    SV = SV.cpu()\n",
    "    SU = SU.cpu()\n",
    "\n",
    "    # Lhr = torch.linalg.cholesky(Hr)\n",
    "    Lhr = None\n",
    "    # if not torch.all(torch.isfinite(Lhr)):\n",
    "    #     return None\n",
    "\n",
    "    Wr = Wr.to(device)\n",
    "\n",
    "    return Lhr, Hr, Wr, SU, SV, scaleWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    'meta-llama/Meta-Llama-3-8B',\n",
    "    'meta-llama--Llama-2-7b-hf',\n",
    "    # 'meta-llama--Llama-2-13b-hf',\n",
    "]\n",
    "\n",
    "size_list = [\n",
    "    4096,\n",
    "    # 4096,\n",
    "    # 4096,\n",
    "]\n",
    "\n",
    "# direction = 'adapt'\n",
    "direction = 'col'\n",
    "\n",
    "for model_name, size in zip(model_list, size_list):\n",
    "    \n",
    "    model_name = model_name.replace('/', '--')\n",
    "    print('model_name: ', model_name)\n",
    "    \n",
    "    model_path = f\"./hf_model/{model_name}\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True)\n",
    "    layers = get_blocks(model)\n",
    "    \n",
    "    datas = []\n",
    "    \n",
    "    for i in tqdm(range(len(layers))):\n",
    "        named_linears = get_named_linears(layers[i])\n",
    "        for n, m in named_linears.items():\n",
    "            w = m.weight.data.detach()\n",
    "            \n",
    "            Lhr, H, w, SU, SV, scaleWH = incoherence_preprocess(None, w, None) \n",
    "            \n",
    "            if direction == 'col':\n",
    "                w = w.T\n",
    "            \n",
    "            # if w.size(0) % size == 0:\n",
    "            #     w = w.T    \n",
    "            #     w = w.reshape(-1, size)\n",
    "            # else:\n",
    "            #     w = w.reshape(-1, size)\n",
    "                \n",
    "            w = w.reshape(-1, size)\n",
    "            \n",
    "            datas.append(w)\n",
    "    \n",
    "    datas = torch.cat(datas, dim = 0)\n",
    "    print('total dataset shape: ', datas.shape)\n",
    "    \n",
    "    indices = torch.randperm(len(datas))\n",
    "    split_index = int(len(datas) - 1000)\n",
    "    train_indices = indices[:split_index]\n",
    "    val_indices = indices[split_index:]\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train'] = datas[train_indices]\n",
    "    dataset['val'] = datas[val_indices]\n",
    "    print('train: ', dataset['train'].shape, 'val: ', dataset['val'].shape)\n",
    "\n",
    "    dataset_stats = {}\n",
    "    for split in ['train', 'val']:\n",
    "        data = dataset[split]\n",
    "        \n",
    "        mean_dim0 = data.mean(dim=0)\n",
    "        std_dim0 = data.std(dim=0)\n",
    "        \n",
    "        mean_all = data.mean()\n",
    "        std_all = data.std()\n",
    "        \n",
    "        dataset_stats[split] = {\n",
    "            'mean': mean_all.item(),\n",
    "            'std': std_all.item(),\n",
    "            'mean_channel': mean_dim0.tolist(),\n",
    "            'std_channel': std_dim0.tolist(),\n",
    "        }\n",
    "\n",
    "    os.makedirs(f'./block_pt/{model_name}', exist_ok = True)\n",
    "    torch.save(dataset, f'./block_pt/{model_name}/{direction}_{size}_RHT.pt')\n",
    "    json_path = f'./block_pt/{model_name}/{direction}_{size}_RHT_dataset_stats.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
