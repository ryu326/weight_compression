{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "dtype = np.float32\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from transformers import CLIPVisionModelWithProjection, AutoModelForCausalLM, LlamaForCausalLM\n",
    "from transformers import AutoModel, AutoTokenizer, OPTForCausalLM, BloomForCausalLM\n",
    "import numpy\n",
    "\n",
    "from huggingface_hub import try_to_load_from_cache, _CACHED_NO_EXIST\n",
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import functools\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from tinychat.models import LlavaLlamaForCausalLM\n",
    "from transformers.models.bloom.modeling_bloom import BloomForCausalLM\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from transformers.models.opt.modeling_opt import OPTForCausalLM\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def topk_eigenvectors(A, device):\n",
    "    A = A.to(device)\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(A)\n",
    "    eigenvalues = eigenvalues\n",
    "    eigenvectors = eigenvectors\n",
    "\n",
    "    # 고유값 행렬 (대각행렬)\n",
    "    Lambda = torch.diag(eigenvalues)\n",
    "\n",
    "    # 원래 행렬 복원 검증: A @ V ≈ V @ Lambda\n",
    "    A_reconstructed = eigenvectors @ Lambda @ eigenvectors.T\n",
    "    error = torch.norm(A - A_reconstructed)\n",
    "    \n",
    "    # assert error < 1e-4, f\"Error: {error.item()}\"\n",
    "    print(f\"재구성 오차 (||A - VΛV^T||): {error.item()}\")\n",
    "    return eigenvalues.cpu(), eigenvectors.cpu()\n",
    "\n",
    "def get_named_linears(module):\n",
    "    return {name: m for name, m in module.named_modules() if isinstance(m, nn.Linear)}\n",
    "\n",
    "def get_blocks(model):\n",
    "    if model.__class__.__name__ in (\"LlamaForCausalLM\", \"Qwen2ForCausalLM\"):\n",
    "        layers = model.model.layers\n",
    "    elif model.__class__.__name__ == \"LlavaLlamaForCausalLM\":\n",
    "        # layers = [model.model.layers, model.model.vision_tower.vision_tower.vision_model.encoder.layers]\n",
    "        layers = model.model.layers\n",
    "    elif isinstance(model, OPTForCausalLM):\n",
    "        layers = model.model.decoder.layers\n",
    "    elif isinstance(model, BloomForCausalLM):\n",
    "        layers = model.transformer.h\n",
    "    elif \"mpt\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.blocks\n",
    "    elif \"falcon\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.h\n",
    "    elif \"bigcode\" in str(model.__class__).lower():\n",
    "        layers = model.transformer.h\n",
    "    elif \"neox\" in str(model.__class__).lower():\n",
    "        layers = model.gpt_neox.layers\n",
    "    elif model.__class__.__name__ == \"LlavaLlamaModel\":\n",
    "        layers = model.llm.model.layers\n",
    "    else:\n",
    "        raise NotImplementedError(type(model))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_to_sym(V, N):\n",
    "    A = torch.zeros(N, N, dtype=V.dtype, device=V.device)\n",
    "    idxs = torch.tril_indices(N, N, device=V.device)\n",
    "    A[idxs.unbind()] = V\n",
    "    A[idxs[1, :], idxs[0, :]] = V\n",
    "    return A\n",
    "\n",
    "def regularize_H(H, n, sigma_reg):\n",
    "    H.div_(torch.diag(H).mean())\n",
    "    idx = torch.arange(n)\n",
    "    H[idx, idx] += sigma_reg\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quip_hess_base_path = '/home/jgryu/Weight_compression/Wparam_dataset/quip_hess'\n",
    "\n",
    "model_list = os.listdir(quip_hess_base_path)\n",
    "quip_hess_path = [os.path.join(quip_hess_base_path, model_name) for model_name in model_list]\n",
    "\n",
    "sigma_reg = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jgryu/Weight_compression/Wparam_dataset/quip_hess/llama3_8b_6144',\n",
       " '/home/jgryu/Weight_compression/Wparam_dataset/quip_hess/Hessians-Llama-2-13b-6144',\n",
       " '/home/jgryu/Weight_compression/Wparam_dataset/quip_hess/Hessians-Llama-2-7b-6144',\n",
       " '/home/jgryu/Weight_compression/Wparam_dataset/quip_hess/llama3.1_8b_6144']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quip_hess_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for quip_hess in quip_hess_path:\n",
    "#     save_path = quip_hess.replace('quip_hess', f'quip_hess_eig_reg{sigma_reg}')\n",
    "#     os.makedirs(save_path, exist_ok=True)\n",
    "#     print(f'##### {quip_hess.split(\"/\")[-1]} #####')\n",
    "#     for i in tqdm(range(40)):\n",
    "#         try:\n",
    "#             hess_dict = {}\n",
    "#             hess_dict['qkv'] = torch.load(f'{quip_hess}/{i}_qkv.pt', weights_only=False)\n",
    "#             hess_dict['o'] = torch.load(f'{quip_hess}/{i}_o.pt', weights_only=False)\n",
    "#             hess_dict['up'] = torch.load(f'{quip_hess}/{i}_up.pt', weights_only=False)\n",
    "#             hess_dict['down'] = torch.load(f'{quip_hess}/{i}_down.pt', weights_only=False)\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "#         for k, h in hess_dict.items():\n",
    "#             print(f'## layer{i}, {k} ##')\n",
    "            \n",
    "#             H = flat_to_sym(h['flatH'], h['n']).to(device)\n",
    "#             mu = h['mu'].to(device)\n",
    "#             H.add_(mu[None, :] * mu[:, None])\n",
    "#             n_h = h['n']\n",
    "#             H = regularize_H(H, n_h, sigma_reg)\n",
    "\n",
    "#             eig = {}\n",
    "#             s, q = topk_eigenvectors(H, device)\n",
    "#             eig['eigenvalues'], eig['eigenvectors'] = s, q\n",
    "#             torch.save(eig, f'{save_path}/{i}_{k}_eig.pt')\n",
    "#             print(f\"{(s[0]/s.sum()).item():.3f}, {(s[-1]/s.sum()).item():.3f}\")\n",
    "#             print(f\"{q[-1].max().item():.3f}, {q[-1].min().item():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Hessians-Llama-2-7b-6144 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:14,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer0, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 97.85%\n",
      "## layer0, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 95.16%\n",
      "## layer0, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 50.61%\n",
      "## layer0, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 53.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:16,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer1, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 90.70%\n",
      "## layer1, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 62.09%\n",
      "## layer1, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 30.62%\n",
      "## layer1, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 99.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:01<00:14,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer2, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 74.62%\n",
      "## layer2, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 28.79%\n",
      "## layer2, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.78%\n",
      "## layer2, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:01<00:13,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer3, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 57.17%\n",
      "## layer3, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 40.79%\n",
      "## layer3, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.36%\n",
      "## layer3, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:01<00:12,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer4, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 58.83%\n",
      "## layer4, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 28.86%\n",
      "## layer4, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.66%\n",
      "## layer4, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:02<00:13,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer5, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 55.73%\n",
      "## layer5, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 46.84%\n",
      "## layer5, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.65%\n",
      "## layer5, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:02<00:11,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer6, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 50.91%\n",
      "## layer6, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 34.25%\n",
      "## layer6, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.67%\n",
      "## layer6, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [00:02<00:10,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer7, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 50.20%\n",
      "## layer7, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 38.32%\n",
      "## layer7, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.26%\n",
      "## layer7, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [00:03<00:10,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer8, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 52.32%\n",
      "## layer8, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 39.14%\n",
      "## layer8, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.82%\n",
      "## layer8, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [00:03<00:09,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer9, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 49.64%\n",
      "## layer9, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 36.55%\n",
      "## layer9, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.96%\n",
      "## layer9, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [00:03<00:09,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer10, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 49.39%\n",
      "## layer10, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 37.12%\n",
      "## layer10, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 25.01%\n",
      "## layer10, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [00:04<00:09,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer11, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 46.24%\n",
      "## layer11, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 38.68%\n",
      "## layer11, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 23.75%\n",
      "## layer11, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [00:04<00:09,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer12, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 45.20%\n",
      "## layer12, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 36.44%\n",
      "## layer12, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 23.21%\n",
      "## layer12, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [00:05<00:09,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer13, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 42.17%\n",
      "## layer13, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 35.70%\n",
      "## layer13, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 23.92%\n",
      "## layer13, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [00:05<00:08,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer14, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 42.88%\n",
      "## layer14, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 34.01%\n",
      "## layer14, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.33%\n",
      "## layer14, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [00:05<00:07,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer15, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 43.79%\n",
      "## layer15, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 34.26%\n",
      "## layer15, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 23.38%\n",
      "## layer15, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [00:05<00:07,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer16, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 41.76%\n",
      "## layer16, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 28.59%\n",
      "## layer16, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.89%\n",
      "## layer16, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [00:06<00:07,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer17, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 37.80%\n",
      "## layer17, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 25.79%\n",
      "## layer17, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.59%\n",
      "## layer17, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [00:06<00:07,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer18, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 34.71%\n",
      "## layer18, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 25.50%\n",
      "## layer18, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.97%\n",
      "## layer18, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [00:07<00:08,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer19, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 34.16%\n",
      "## layer19, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.47%\n",
      "## layer19, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.67%\n",
      "## layer19, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [00:07<00:07,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer20, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 32.99%\n",
      "## layer20, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.21%\n",
      "## layer20, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.56%\n",
      "## layer20, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [00:07<00:07,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer21, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 31.55%\n",
      "## layer21, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.36%\n",
      "## layer21, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.76%\n",
      "## layer21, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [00:08<00:07,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer22, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 31.90%\n",
      "## layer22, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.24%\n",
      "## layer22, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.46%\n",
      "## layer22, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:09<00:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer23, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 28.71%\n",
      "## layer23, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.48%\n",
      "## layer23, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.05%\n",
      "## layer23, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 16.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [00:09<00:07,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer24, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 30.92%\n",
      "## layer24, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.36%\n",
      "## layer24, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 16.80%\n",
      "## layer24, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [00:10<00:07,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer25, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.88%\n",
      "## layer25, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.47%\n",
      "## layer25, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.02%\n",
      "## layer25, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:10<00:06,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer26, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 28.90%\n",
      "## layer26, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 25.61%\n",
      "## layer26, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 17.46%\n",
      "## layer26, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:11<00:06,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer27, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.72%\n",
      "## layer27, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 27.26%\n",
      "## layer27, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 18.32%\n",
      "## layer27, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [00:11<00:05,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer28, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 25.33%\n",
      "## layer28, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.14%\n",
      "## layer28, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 19.31%\n",
      "## layer28, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 33.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [00:12<00:05,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer29, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.84%\n",
      "## layer29, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 21.09%\n",
      "## layer29, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 20.43%\n",
      "## layer29, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 40.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:12<00:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer30, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 24.46%\n",
      "## layer30, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 31.86%\n",
      "## layer30, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 22.73%\n",
      "## layer30, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 69.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:13<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer31, qkv ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.98%\n",
      "## layer31, o ##\n",
      "상위 10개의 고유값이 차지하는 비율: 43.09%\n",
      "## layer31, up ##\n",
      "상위 10개의 고유값이 차지하는 비율: 26.78%\n",
      "## layer31, down ##\n",
      "상위 10개의 고유값이 차지하는 비율: 85.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for quip_hess in quip_hess_path:\n",
    "    if '2-7b' not in quip_hess: continue\n",
    "    save_path = quip_hess.replace('quip_hess', f'quip_hess_eig_reg{sigma_reg}')\n",
    "    # os.makedirs(save_path, exist_ok=True)\n",
    "    print(f'##### {quip_hess.split(\"/\")[-1]} #####')\n",
    "    for i in tqdm(range(40)):\n",
    "        try:\n",
    "            hess_dict = {}\n",
    "            hess_dict['qkv'] = torch.load(f'{save_path}/{i}_qkv_eig.pt', weights_only=False)\n",
    "            hess_dict['o'] = torch.load(f'{save_path}/{i}_o_eig.pt', weights_only=False)\n",
    "            hess_dict['up'] = torch.load(f'{save_path}/{i}_up_eig.pt', weights_only=False)\n",
    "            hess_dict['down'] = torch.load(f'{save_path}/{i}_down_eig.pt', weights_only=False)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        for k, h in hess_dict.items():\n",
    "            print(f'## layer{i}, {k} ##')\n",
    "            s, q = h['eigenvalues'], h['eigenvectors']\n",
    "            # print(f\"{(s[0]/s.sum()).item():.3f}, {(s[-1]/s.sum()).item():.3f}\")\n",
    "            \n",
    "            sorted_s = torch.sort(s, descending=True).values  # 내림차순 정렬\n",
    "            cumsum_s = torch.cumsum(sorted_s, dim=0)  # 누적 합\n",
    "            \n",
    "            total_sum = sorted_s.sum()\n",
    "            k = int(0.025 * len(s))\n",
    "            topk_sum = sorted_s[:k].sum()\n",
    "            percentage = (topk_sum / total_sum) * 100\n",
    "            \n",
    "            print(f\"상위 10개의 고유값이 차지하는 비율: {percentage:.2f}%\")\n",
    "            \n",
    "            # threshold = 0.5 * sorted_s.sum()  # 전체 합의 90%\n",
    "\n",
    "            # count = torch.searchsorted(cumsum_s, threshold, right=True).item() + 1  # 개수 찾기\n",
    "            # print(f\"90%를 차지하는 eigenvalue 개수: {count}/{len(s)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.linalg' has no attribute 'ldl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1000.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], \n\u001b[1;32m      5\u001b[0m                   [\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m4.0\u001b[39m], \n\u001b[1;32m      6\u001b[0m                   [\u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m4.0\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m]])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# LDL 분해 수행\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m L, D, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mldl\u001b[49m(A)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL 행렬:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, L)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD 행렬:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, D)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.linalg' has no attribute 'ldl'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 값의 편차가 큰 대칭 행렬 생성\n",
    "A = torch.tensor([[1000.0, 2.0, 3.0], \n",
    "                  [2.0, 0.01, 4.0], \n",
    "                  [3.0, 4.0, 0.0001]])\n",
    "\n",
    "# LDL 분해 수행\n",
    "L, D, _ = torch.linalg.ldl(A)\n",
    "\n",
    "print(\"L 행렬:\\n\", L)\n",
    "print(\"D 행렬:\\n\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L 행렬:\n",
      " [[1.    0.    0.   ]\n",
      " [0.002 1.    0.   ]\n",
      " [0.003 0.    1.   ]]\n",
      "D 행렬:\n",
      " [[ 1.000e+03  0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  6.000e-03  3.994e+00]\n",
      " [ 0.000e+00  3.994e+00 -8.900e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "# 값의 편차가 큰 대칭 행렬 생성\n",
    "A = np.array([[1000.0, 2.0, 3.0], \n",
    "              [2.0, 0.01, 4.0], \n",
    "              [3.0, 4.0, 0.0001]])\n",
    "\n",
    "# LDL 분해 수행\n",
    "L, D, perm = scipy.linalg.ldl(A, lower=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"L 행렬:\\n\", L)\n",
    "print(\"D 행렬:\\n\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L 행렬:\n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.6387, 1.0000, 0.0000],\n",
      "        [1.0338, 1.0112, 1.0000]])\n",
      "D 행렬:\n",
      " tensor([[1.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.1029e+05, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.0875e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def ldl_decomposition(A):\n",
    "    # Cholesky 분해 수행 (A = L L^T)\n",
    "    L_cholesky = torch.linalg.cholesky(A)\n",
    "\n",
    "    # D 행렬: Cholesky 분해에서 얻은 L의 대각 원소의 제곱\n",
    "    D = torch.diag(torch.diag(L_cholesky)**2)\n",
    "\n",
    "    # L 행렬: Cholesky 행렬을 정규화하여 얻음\n",
    "    L = L_cholesky / torch.diag(L_cholesky).reshape(-1, 1)\n",
    "\n",
    "    return L, D\n",
    "\n",
    "# 대칭 행렬 (값의 편차가 큰 경우)\n",
    "A = torch.tensor([[1.0, 2.0, 3.0], \n",
    "                  [2.0, 1000, 4.0], \n",
    "                  [3.0, 4.0, 0.0001]])\n",
    "\n",
    "# LDL 분해 수행\n",
    "L, D = ldl_decomposition(A@A.T)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"L 행렬:\\n\", L)\n",
    "print(\"D 행렬:\\n\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
