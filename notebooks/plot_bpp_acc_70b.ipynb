{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mse_from_json(result):\n",
    "    sum_mse = 0\n",
    "    total_n = 0\n",
    "    for k,v in result.items():\n",
    "        if not k.endswith('.pt'): continue\n",
    "        sum_mse += v['mse'] * v['num_pixels']\n",
    "        total_n += v['num_pixels']\n",
    "        # print(k, v['mse'])\n",
    "    return sum_mse / total_n\n",
    "\n",
    "def cal_proxy_loss_from_json(result):\n",
    "    sum = 0\n",
    "    total_n = 0\n",
    "    for k,v in result.items():\n",
    "        if not k.endswith('.pt'): continue\n",
    "        sum += v['proxy_err']\n",
    "        total_n += 1\n",
    "    return sum / total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama--Meta-Llama-3-8B/ql_ldlq128_rnorm_ablation_v2\n",
      "['/workspace/Weight_compression/hf_model_comp_results/meta-llama--Meta-Llama-3-8B/ql_ldlq128_rnorm_ablation_v2/lmbda1_result.json']\n",
      "'bpp' :  [] ,\n",
      "    'bpp' :  [2.6043475755633643, 3.4031814775214744, 3.7472894648806405, 4.228176577733113, 4.971889252559497, 5.290831287606404, 5.692742304160045, 6.0232284619258] ,\n",
      "    'ppl_wikitext2' :  [13.770977973937988, 7.340230941772461, 6.830478191375732, 6.558233737945557, 6.27704381942749, 6.23903751373291, 6.196274757385254, 6.1714768409729] ,\n",
      "    'ppl_c4' :  [17.450172424316406, 10.430622100830078, 9.752036094665527, 9.375121116638184, 9.043634414672852, 8.990034103393555, 8.937968254089355, 8.9231595993042] ,\n",
      "    'ppl_ptb' :  [] ,\n",
      "    'mse' :  [] ,\n",
      "    'proxy_err' :  [] ,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PPL\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "path_list = [\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/quip-sharp/llama3_8b_/ft1'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/awq/meta-llama--Meta-Llama-3-8B'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/quip-sharp/llama3_8b/ft1'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/quip-sharp/llama2_7b/ft1',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/quip-sharp/llama2_13b/ft1',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Meta-Llama-3-8B/ql_gaussian_rnorm'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Meta-Llama-3-8B/uniform_ql_rnorm/ql2',\n",
    "    # \"/workspace/Weight_compression/hf_model_comp_results/qtip/llama2_7b/ft1\"\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-13b-hf/uniform_ql_rnorm/ql0',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-13b-hf/uniform_ql_rnorm/ql1',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-7b-hf/uniform_ql_rnorm/ql2',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-7b-hf/uniform_ql_rnorm/ql3',\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results_sv3/llama3.2_1b_inst/ft1'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results_sv3/meta-llama--Llama-3.2-3B-Instruct/ql_ldlq128_rnorm_ft'\n",
    "    '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Meta-Llama-3-8B/ql_ldlq128_rnorm_ablation_v2'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/qtip/llama2_13b/ft1'\n",
    "]\n",
    "for path in path_list:\n",
    "    print('/'.join(path.split('/')[-2:]))\n",
    "    listdir = glob.glob(f'{path}/*.json')\n",
    "    # listdir = [l for l in listdir if 'ppl' in l]\n",
    "    listdir = [l for l in listdir if 'zeroshot' not in l]\n",
    "    print(listdir[:1])\n",
    "    c4ppl = []\n",
    "    wikippl = []\n",
    "    ptbppl = []\n",
    "    bits = []\n",
    "    bpp = []\n",
    "    mse, proxy_err = [], []\n",
    "    for file in listdir:        \n",
    "        with open(file, 'r') as f:\n",
    "            results = json.load(f)            \n",
    "            try:\n",
    "                bpp.append(results['bpp_loss'])\n",
    "                # bpp.append(results['bpp'])\n",
    "            except:\n",
    "                # bit = re.search(r'w(\\d+)', file.lower()).group(1) \n",
    "                # bit = re.search(r'qtip-(\\d+)', file.lower()).group(1)\n",
    "                # bit = re.search(r'8b_(\\d+)', file.lower()).group(1)\n",
    "                # bit = re.search(r'8b_(\\d+)', file.lower()).group(1)\n",
    "                bit = re.search(r'(\\d+)\\s*bit', file.lower()).group(1)\n",
    "                bits.append(int(bit))\n",
    "            \n",
    "            try:\n",
    "                if 'ppl' in results.keys(): wikippl.append(results['ppl']['wikitext2'])\n",
    "                else: wikippl.append(results['wikitext2'])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if 'ppl' in results.keys(): c4ppl.append(results['ppl']['c4'])\n",
    "                else: c4ppl.append(results['c4'])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if 'ppl' in results.keys(): ptbppl.append(results['ppl']['ptb'])\n",
    "                else: ptbppl.append(results['ptb'])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # mse.append(cal_mse_from_json(results))\n",
    "            # proxy_err.append(cal_proxy_loss_from_json(results))\n",
    "            \n",
    "    if bpp != []:\n",
    "        sorted_indices = sorted(range(len(bpp)), key=lambda i: bpp[i])\n",
    "        bpp = [bpp[i] for i in sorted_indices]\n",
    "    elif bits != []:\n",
    "        sorted_indices = sorted(range(len(bits)), key=lambda i: bits[i])\n",
    "        bits = [bits[i] for i in sorted_indices]\n",
    "        \n",
    "    if wikippl != []:\n",
    "        wikippl = [wikippl[i] for i in sorted_indices]\n",
    "    if c4ppl != []:\n",
    "        c4ppl = [c4ppl[i] for i in sorted_indices]\n",
    "    if mse != []:\n",
    "        mse = [mse[i] for i in sorted_indices]\n",
    "    if proxy_err != []:\n",
    "        proxy_err = [proxy_err[i] for i in sorted_indices]\n",
    "    # if ptbppl != []:\n",
    "    #     ptbppl = [ptbppl[i] for i in sorted_indices]\n",
    "    print(\"'bpp' : \", bits, ',')\n",
    "    print(\"    'bpp' : \", bpp, ',')\n",
    "    print(\"    'ppl_wikitext2' : \", wikippl, ',')\n",
    "    print(\"    'ppl_c4' : \", c4ppl, ',')\n",
    "    print(\"    'ppl_ptb' : \", ptbppl, ',')\n",
    "    print(\"    'mse' : \", mse, ',')\n",
    "    print(\"    'proxy_err' : \", proxy_err, ',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama--Llama-2-70b-hf_/ql_ldlq128_rnorm_ft_ft_rnorm\n",
      "/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-70b-hf_/ql_ldlq128_rnorm_ft_ft_rnorm/lmbda75_zeroshot_results0.4.4.json\n",
      "'bpp' :  [] ,\n",
      "    'zeroshot' :  [] ,\n",
      "'bpp' :  [70, 75] ,\n",
      "    'commonsense' :  [0.7635322744081228, 0.7619079100829811] ,\n",
      "'bpp' :  [] ,\n",
      "    'average9' :  [] ,\n",
      "'bpp' :  [] ,\n",
      "    'mmlu' :  [] ,\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "path_list_zeroshot = [\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Meta-Llama-3-8B/ql_ldlq128_rnorm'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/qtip/llama3_8b/noft'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-7b-hf/scaleH_rnorm_ldlq128_scale_cond(col_std)/(7B_trained)size128_encdim1024_M256'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/spinquant/8B'\n",
    "    # '/workspace/Weight_compression/hf_model_comp_results/quip-sharp/llama2_7b/ft1'\n",
    "    '/workspace/Weight_compression/hf_model_comp_results/meta-llama--Llama-2-70b-hf_/ql_ldlq128_rnorm_ft_ft_rnorm'\n",
    "]\n",
    "if len(path_list_zeroshot):\n",
    "    path_list = path_list_zeroshot\n",
    "\n",
    "tasks = ['arc_challenge', 'arc_easy', 'boolq', 'piqa', 'winogrande', 'hellaswag', 'mmlu', 'mathqa', 'openbookqa', 'pubmedqa', 'sciq']\n",
    "for path in path_list:\n",
    "    print('/'.join(path.split('/')[-2:]))\n",
    "    zeroshot_files = [f for f in glob.glob(f'{path}/*.json') if 'zeroshot' in f]\n",
    "    print(zeroshot_files[-1])\n",
    "    zeroshot_results = {}\n",
    "    for file in zeroshot_files:\n",
    "        with open(file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            \n",
    "        m_lambda = re.search(r'lmbda(\\d+)', file)\n",
    "        if m_lambda:\n",
    "            key = int(m_lambda.group(1))\n",
    "        else:\n",
    "            m_bit = re.search(r'(\\d+)\\s*bit', file.lower())\n",
    "            if m_bit:\n",
    "                key = int(m_bit.group(1))\n",
    "            else:\n",
    "                bit = re.search(r'w(\\d+)', file.lower())\n",
    "                key = int(bit.group(1))\n",
    "            \n",
    "        # key = 0\n",
    "\n",
    "        if key not in zeroshot_results:\n",
    "            zeroshot_results[key] = {}\n",
    "        for task in tasks:\n",
    "            try:\n",
    "                # task_accs = {task: results['results'][task]['acc,none'] for task in tasks}\n",
    "                try:\n",
    "                    # r = results['results'][task]['acc,none']\n",
    "                    r1 = results['results'][task]['acc,none'] ## 70B\n",
    "                    r2 = results['results'][task]['acc_norm,none'] ## 70B\n",
    "                except:\n",
    "                    # r = results['results'][task]['acc']\n",
    "                    r1 = results['results'][task]['acc,none'] ## 70B\n",
    "                    r2 = 0\n",
    "\n",
    "                r = r2 if r2 > r1 else r1\n",
    "                zeroshot_results[key][task] = r\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    tasksets = {\n",
    "        'zeroshot': ['arc_challenge', 'arc_easy', 'boolq', 'piqa', 'winogrande'], ## zeroshot\n",
    "        # 'commonsense': ['arc_challenge', 'arc_easy', 'boolq', 'piqa', 'winogrande', 'hellaswag',], ## commonsense\n",
    "        'commonsense': ['arc_challenge', 'arc_easy', 'piqa', 'winogrande', 'hellaswag',], ## 70B\n",
    "        'average9': ['arc_challenge', 'arc_easy', 'boolq', 'piqa', 'winogrande', 'hellaswag', 'mmlu', 'mathqa', 'openbookqa'],\n",
    "        'mmlu': ['mmlu'],\n",
    "    }\n",
    "    for tlabel, tasks in tasksets.items():\n",
    "        num_tasks = len(tasks)\n",
    "        bpp_keys = []\n",
    "        avg_accuracies = []\n",
    "        for key in sorted(zeroshot_results.keys()):\n",
    "            \n",
    "            accuracies_for_this_key = []\n",
    "            for task in tasks:\n",
    "                if task in zeroshot_results[key]:\n",
    "                    accuracies_for_this_key.append(zeroshot_results[key][task])\n",
    "                    \n",
    "            if len(accuracies_for_this_key) == num_tasks:\n",
    "                average = sum(accuracies_for_this_key) / num_tasks\n",
    "                bpp_keys.append(key)\n",
    "                avg_accuracies.append(average)\n",
    "\n",
    "        print(\"'bpp' : \", bpp_keys, ',')\n",
    "        print(f\"    '{tlabel}' : \", avg_accuracies, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{75: {'arc_challenge': 0.560580204778157,\n",
       "  'arc_easy': 0.8257575757575758,\n",
       "  'piqa': 0.8264417845484222,\n",
       "  'hellaswag': 0.8272256522605059}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bpp' :  [100] ,\n",
    "'zeroshot' :  [0.7247428955461601] ,\n",
    "'bpp' :  [100] ,\n",
    "'commonsense' :  [0.7032852151857648] ,\n",
    "\n",
    "'bpp' :  [100] ,\n",
    "'zeroshot' :  [0.72350621191611] ,\n",
    "'bpp' :  [100] ,\n",
    "'commonsense' :  [0.7022380485346194] ,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
