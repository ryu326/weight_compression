23:27:15 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
23:27:15 INFO - ddp_or_single_process: Create new exp folder!
23:27:15 INFO - ddp_or_single_process: seed : 100
23:27:15 INFO - ddp_or_single_process: exp name : gaussian_seq_row_16/lmbda50_rdloss_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100
23:27:17 INFO - main: Create experiment save folder
23:28:17 INFO - main: Training mode : scratch!
23:28:17 INFO - main: batch_size : 2048
23:28:17 INFO - main: num of gpus: 1
23:28:17 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='gaussian_seq', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=2048, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, clip_max_norm=1.0, save_dir='nwc', architecture='nwc', loss='rdloss', checkpoint='None', block_direction='row', lmbda=50, save_path='./checkpoint/nwc/gaussian_seq_row_16/lmbda50_rdloss_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
23:28:19 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 202.99603271484375	recon_loss: 3.951594591140747	bpp_loss: 5.416300296783447	aux_loss: 660.4324340820312
23:28:45 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
23:28:45 INFO - ddp_or_single_process: find checkpoint...
23:28:45 INFO - ddp_or_single_process: no checkpoint is here
23:28:45 INFO - ddp_or_single_process: seed : 100
23:28:45 INFO - ddp_or_single_process: exp name : gaussian_seq_row_16/lmbda50_rdloss_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100
23:28:47 INFO - main: Create experiment save folder
23:29:46 INFO - main: Training mode : scratch!
23:29:46 INFO - main: batch_size : 2048
23:29:46 INFO - main: num of gpus: 1
23:29:46 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='gaussian_seq', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=2048, seed=100, input_size=16, dim_encoder=512, n_resblock=4, M=16, clip_max_norm=1.0, save_dir='nwc', architecture='nwc', loss='rdloss', checkpoint='None', block_direction='row', lmbda=50, save_path='./checkpoint/nwc/gaussian_seq_row_16/lmbda50_rdloss_encdim512_M16_batch_size2048_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
23:29:48 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 202.99603271484375	recon_loss: 3.951594591140747	bpp_loss: 5.416300296783447	aux_loss: 660.4324340820312
23:29:55 INFO - main: {'TEST MSE': 2.593660568511314, 'TEST BPP': 5.4375, 'TEST loss': 135.0996729736328, 'TEST recon_loss': 2.5936604959964753, 'TEST bpp_loss': 5.416648327350616}
23:29:55 INFO - main: can not find prev_mse_best_model!
23:29:55 INFO - main: can not find prev_bpp_best_model!
23:29:55 INFO - main: can not find prev_bpp_best_model!
23:29:55 INFO - main: can not find recent_saved_model!
23:38:19 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 4.872471809387207	recon_loss: 0.007985005155205727	bpp_loss: 4.473221302032471	aux_loss: 621.7879028320312
23:46:41 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 4.311239242553711	recon_loss: 0.00973981898277998	bpp_loss: 3.8242480754852295	aux_loss: 563.1400146484375
23:55:16 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 4.134302139282227	recon_loss: 0.013043825514614582	bpp_loss: 3.4821107387542725	aux_loss: 504.11541748046875
00:03:46 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 4.108023643493652	recon_loss: 0.014529126696288586	bpp_loss: 3.3815674781799316	aux_loss: 466.43994140625
00:12:28 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 4.0994873046875	recon_loss: 0.014762703329324722	bpp_loss: 3.36135196685791	aux_loss: 441.58538818359375
00:12:36 INFO - main: {'TEST MSE': 0.014728135687645938, 'TEST BPP': 3.41271875, 'TEST loss': 4.12576190328598, 'TEST recon_loss': 0.014728135264478625, 'TEST bpp_loss': 3.3893551416397094}
00:21:09 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 4.088935852050781	recon_loss: 0.01473637018352747	bpp_loss: 3.3521173000335693	aux_loss: 413.833740234375
00:29:57 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 4.075706958770752	recon_loss: 0.014636954292654991	bpp_loss: 3.3438594341278076	aux_loss: 378.5262756347656
00:38:28 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 4.068481922149658	recon_loss: 0.014655940234661102	bpp_loss: 3.3356850147247314	aux_loss: 330.52349853515625
00:47:23 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 4.0663838386535645	recon_loss: 0.014765889383852482	bpp_loss: 3.3280892372131348	aux_loss: 267.8951110839844
00:56:06 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 4.059558391571045	recon_loss: 0.014757383614778519	bpp_loss: 3.3216891288757324	aux_loss: 182.75347900390625
00:56:13 INFO - main: {'TEST MSE': 0.01473810499592028, 'TEST BPP': 3.37309375, 'TEST loss': 4.086501867771148, 'TEST recon_loss': 0.014738104574382306, 'TEST bpp_loss': 3.3495966398715975}
01:04:53 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 4.042912006378174	recon_loss: 0.014546185731887817	bpp_loss: 3.3156025409698486	aux_loss: 91.31012725830078
01:13:48 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 4.041770935058594	recon_loss: 0.014582076109945774	bpp_loss: 3.31266713142395	aux_loss: 39.07923126220703
01:22:30 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 4.04055118560791	recon_loss: 0.014581327326595783	bpp_loss: 3.3114845752716064	aux_loss: 19.27796173095703
01:31:40 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 4.044234752655029	recon_loss: 0.01464405283331871	bpp_loss: 3.3120322227478027	aux_loss: 9.12728214263916
01:40:02 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 4.038403034210205	recon_loss: 0.014555742032825947	bpp_loss: 3.3106157779693604	aux_loss: 2.703030586242676
01:40:09 INFO - main: {'TEST MSE': 0.01460970052934855, 'TEST BPP': 3.363046875, 'TEST loss': 4.0696059560775755, 'TEST recon_loss': 0.014609700098633766, 'TEST bpp_loss': 3.339120949983597}
01:48:29 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 4.039035320281982	recon_loss: 0.01453770138323307	bpp_loss: 3.312150239944458	aux_loss: 0.8249033093452454
01:56:51 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 4.042074680328369	recon_loss: 0.014614831656217575	bpp_loss: 3.311333179473877	aux_loss: 0.35099509358406067
02:05:46 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 4.043173789978027	recon_loss: 0.014627612195909023	bpp_loss: 3.311793088912964	aux_loss: 0.28012698888778687
02:14:37 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 4.064219951629639	recon_loss: 0.01504685077816248	bpp_loss: 3.311877489089966	aux_loss: 0.4654976725578308
02:22:59 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 4.0399699211120605	recon_loss: 0.01456890907138586	bpp_loss: 3.3115246295928955	aux_loss: 0.4391915202140808
02:23:06 INFO - main: {'TEST MSE': 0.014507467522052004, 'TEST BPP': 3.363203125, 'TEST loss': 4.064573388338089, 'TEST recon_loss': 0.014507467092946171, 'TEST bpp_loss': 3.339200023889542}
02:31:26 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 4.0380449295043945	recon_loss: 0.014528048224747181	bpp_loss: 3.3116424083709717	aux_loss: 0.19941674172878265
02:39:48 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 4.057408809661865	recon_loss: 0.014869378879666328	bpp_loss: 3.3139398097991943	aux_loss: 0.30792558193206787
02:48:08 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 4.038942337036133	recon_loss: 0.014546772465109825	bpp_loss: 3.311603546142578	aux_loss: 0.27016937732696533
02:56:30 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 4.037392616271973	recon_loss: 0.014523549005389214	bpp_loss: 3.3112149238586426	aux_loss: 0.3489932715892792
03:04:52 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 4.039252281188965	recon_loss: 0.014552670530974865	bpp_loss: 3.3116188049316406	aux_loss: 0.2790454626083374
03:04:59 INFO - main: {'TEST MSE': 0.01455593750691441, 'TEST BPP': 3.363796875, 'TEST loss': 4.067347958803177, 'TEST recon_loss': 0.014555937079712748, 'TEST bpp_loss': 3.339551115512848}
03:13:19 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 4.037319660186768	recon_loss: 0.01449846476316452	bpp_loss: 3.31239652633667	aux_loss: 0.2607343792915344
03:22:29 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 4.037841796875	recon_loss: 0.014517896808683872	bpp_loss: 3.3119468688964844	aux_loss: 0.35513734817504883
03:33:55 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 4.0363030433654785	recon_loss: 0.014477204531431198	bpp_loss: 3.3124430179595947	aux_loss: 0.23406170308589935
03:42:17 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 4.041012287139893	recon_loss: 0.014581630006432533	bpp_loss: 3.3119306564331055	aux_loss: 0.2930322289466858
03:50:39 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 4.035987377166748	recon_loss: 0.014484196901321411	bpp_loss: 3.3117775917053223	aux_loss: 0.3474346995353699
03:50:46 INFO - main: {'TEST MSE': 0.01451911584720152, 'TEST BPP': 3.363984375, 'TEST loss': 4.065484257459641, 'TEST recon_loss': 0.014519115424714983, 'TEST bpp_loss': 3.339528482437134}
03:59:05 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 4.037025451660156	recon_loss: 0.01449770200997591	bpp_loss: 3.3121402263641357	aux_loss: 0.32134830951690674
04:07:27 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 4.0357842445373535	recon_loss: 0.014489883556962013	bpp_loss: 3.3112900257110596	aux_loss: 0.34690433740615845
04:15:46 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 4.037120342254639	recon_loss: 0.01449879352003336	bpp_loss: 3.312180757522583	aux_loss: 0.4253060817718506
04:24:07 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 4.03759241104126	recon_loss: 0.014507906511425972	bpp_loss: 3.312196969985962	aux_loss: 0.23768439888954163
04:32:28 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 4.035687446594238	recon_loss: 0.01448090560734272	bpp_loss: 3.3116421699523926	aux_loss: 0.3356715440750122
04:32:36 INFO - main: {'TEST MSE': 0.014577084132526986, 'TEST BPP': 3.364546875, 'TEST loss': 4.0688132526874545, 'TEST recon_loss': 0.014577083707787096, 'TEST bpp_loss': 3.3399590594768522}
04:40:55 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 4.036502361297607	recon_loss: 0.014471749775111675	bpp_loss: 3.3129148483276367	aux_loss: 0.3547351360321045
04:49:17 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 4.036693572998047	recon_loss: 0.014498871751129627	bpp_loss: 3.3117501735687256	aux_loss: 0.24833102524280548
04:57:36 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 4.041685104370117	recon_loss: 0.014596416614949703	bpp_loss: 3.3118643760681152	aux_loss: 0.36421212553977966
05:05:58 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 4.03630256652832	recon_loss: 0.014491465874016285	bpp_loss: 3.3117294311523438	aux_loss: 0.36047035455703735
05:14:19 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 4.036452770233154	recon_loss: 0.014479801058769226	bpp_loss: 3.31246280670166	aux_loss: 0.47445356845855713
05:14:26 INFO - main: {'TEST MSE': 0.014507479492763597, 'TEST BPP': 3.36453125, 'TEST loss': 4.065238977432251, 'TEST recon_loss': 0.01450747908744961, 'TEST bpp_loss': 3.339865021467209}
05:22:45 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 4.036248683929443	recon_loss: 0.0144861014559865	bpp_loss: 3.311943769454956	aux_loss: 0.35208919644355774
05:31:06 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 4.036848545074463	recon_loss: 0.0144897336140275	bpp_loss: 3.312361717224121	aux_loss: 0.36657431721687317
05:39:25 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 4.042877197265625	recon_loss: 0.01461718138307333	bpp_loss: 3.312018394470215	aux_loss: 0.26242661476135254
05:47:46 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 4.042915344238281	recon_loss: 0.014625686220824718	bpp_loss: 3.311631202697754	aux_loss: 0.29992711544036865
05:56:07 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 4.035529613494873	recon_loss: 0.014470179565250874	bpp_loss: 3.312020778656006	aux_loss: 0.31967103481292725
05:56:14 INFO - main: {'TEST MSE': 0.014488063128927456, 'TEST BPP': 3.36465625, 'TEST loss': 4.064383396863938, 'TEST recon_loss': 0.014488062699325384, 'TEST bpp_loss': 3.339980260372162}
06:04:33 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 4.03615665435791	recon_loss: 0.014489972032606602	bpp_loss: 3.3116579055786133	aux_loss: 0.3140428364276886
06:12:55 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 4.0371174812316895	recon_loss: 0.014479593373835087	bpp_loss: 3.313138008117676	aux_loss: 0.35242199897766113
06:21:15 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 4.034942626953125	recon_loss: 0.014459902420639992	bpp_loss: 3.3119473457336426	aux_loss: 0.32242584228515625
06:29:37 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 4.0361714363098145	recon_loss: 0.014487887732684612	bpp_loss: 3.311776876449585	aux_loss: 0.2800184488296509
06:37:58 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 4.036053657531738	recon_loss: 0.014475582167506218	bpp_loss: 3.31227445602417	aux_loss: 0.27573925256729126
06:38:06 INFO - main: {'TEST MSE': 0.014481178751541448, 'TEST BPP': 3.36453125, 'TEST loss': 4.0639170007705685, 'TEST recon_loss': 0.014481178342364728, 'TEST bpp_loss': 3.339858090877533}
06:46:25 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 4.033997058868408	recon_loss: 0.014453530311584473	bpp_loss: 3.3113205432891846	aux_loss: 0.3014686703681946
06:54:47 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 4.034843444824219	recon_loss: 0.014461765997111797	bpp_loss: 3.3117549419403076	aux_loss: 0.3247557282447815
07:03:06 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 4.035558700561523	recon_loss: 0.014476641081273556	bpp_loss: 3.3117268085479736	aux_loss: 0.3506351709365845
07:11:28 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 4.0360331535339355	recon_loss: 0.014471706002950668	bpp_loss: 3.3124477863311768	aux_loss: 0.31726759672164917
07:19:50 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 4.035455703735352	recon_loss: 0.01446745079010725	bpp_loss: 3.3120830059051514	aux_loss: 0.3313545882701874
07:19:57 INFO - main: {'TEST MSE': 0.014474336651162774, 'TEST BPP': 3.3649375, 'TEST loss': 4.063825780153275, 'TEST recon_loss': 0.01447433623019606, 'TEST bpp_loss': 3.340108973026276}
07:28:17 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 4.036776542663574	recon_loss: 0.014461133629083633	bpp_loss: 3.3137199878692627	aux_loss: 0.3379288911819458
07:36:38 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 4.034512042999268	recon_loss: 0.01445701252669096	bpp_loss: 3.3116614818573	aux_loss: 0.3492696285247803
07:44:57 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 4.035811424255371	recon_loss: 0.014472008682787418	bpp_loss: 3.31221079826355	aux_loss: 0.2774403691291809
07:53:19 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 4.037684917449951	recon_loss: 0.014506143517792225	bpp_loss: 3.3123779296875	aux_loss: 0.3740594983100891
08:01:40 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 4.035044193267822	recon_loss: 0.014462822116911411	bpp_loss: 3.3119029998779297	aux_loss: 0.3107004761695862
08:01:48 INFO - main: {'TEST MSE': 0.014483258251296233, 'TEST BPP': 3.36459375, 'TEST loss': 4.064333762407303, 'TEST recon_loss': 0.014483257838524877, 'TEST bpp_loss': 3.3401708607673646}
08:10:07 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 4.035022735595703	recon_loss: 0.01446734368801117	bpp_loss: 3.3116555213928223	aux_loss: 0.2994801998138428
08:18:28 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 4.034823417663574	recon_loss: 0.014443679712712765	bpp_loss: 3.3126392364501953	aux_loss: 0.2213253378868103
08:26:47 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 4.034469127655029	recon_loss: 0.01447757426649332	bpp_loss: 3.3105902671813965	aux_loss: 0.31211331486701965
08:35:08 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 4.035349369049072	recon_loss: 0.014456352218985558	bpp_loss: 3.3125317096710205	aux_loss: 0.47613221406936646
08:43:30 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 4.035702228546143	recon_loss: 0.01447612140327692	bpp_loss: 3.311896324157715	aux_loss: 0.2773544192314148
08:43:37 INFO - main: {'TEST MSE': 0.014494534833993142, 'TEST BPP': 3.3641875, 'TEST loss': 4.064303939819336, 'TEST recon_loss': 0.014494534420780837, 'TEST bpp_loss': 3.3395772178173067}
08:51:56 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 4.034013271331787	recon_loss: 0.014473823830485344	bpp_loss: 3.3103220462799072	aux_loss: 0.37267613410949707
09:00:17 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 4.036767482757568	recon_loss: 0.014492885209619999	bpp_loss: 3.3121230602264404	aux_loss: 0.30662715435028076
09:08:37 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 4.0344953536987305	recon_loss: 0.014453660696744919	bpp_loss: 3.311812162399292	aux_loss: 0.31912797689437866
09:16:57 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 4.035728931427002	recon_loss: 0.014470617286860943	bpp_loss: 3.3121979236602783	aux_loss: 0.3621068298816681
09:25:19 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 4.03488826751709	recon_loss: 0.014481110498309135	bpp_loss: 3.3108327388763428	aux_loss: 0.40425053238868713
09:25:26 INFO - main: {'TEST MSE': 0.014478465797768751, 'TEST BPP': 3.3648125, 'TEST loss': 4.06399221777916, 'TEST recon_loss': 0.014478465378284453, 'TEST bpp_loss': 3.3400689499378204}
09:33:46 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 4.03540563583374	recon_loss: 0.01446112897247076	bpp_loss: 3.312349319458008	aux_loss: 0.44479992985725403
09:42:08 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 4.03397798538208	recon_loss: 0.014443634077906609	bpp_loss: 3.311796188354492	aux_loss: 0.23249784111976624
09:50:26 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 4.035294055938721	recon_loss: 0.014460885897278786	bpp_loss: 3.3122496604919434	aux_loss: 0.3420308828353882
09:58:48 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 4.035113334655762	recon_loss: 0.014462755993008614	bpp_loss: 3.3119757175445557	aux_loss: 0.32777175307273865
10:07:10 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 4.033834457397461	recon_loss: 0.014451694674789906	bpp_loss: 3.3112497329711914	aux_loss: 0.3466191291809082
10:07:17 INFO - main: {'TEST MSE': 0.014476775741591414, 'TEST BPP': 3.364796875, 'TEST loss': 4.06380456328392, 'TEST recon_loss': 0.014476775326766073, 'TEST bpp_loss': 3.3399658026695254}
10:15:58 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 4.034243583679199	recon_loss: 0.014455646276473999	bpp_loss: 3.3114612102508545	aux_loss: 0.29284417629241943
10:24:20 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 4.034886360168457	recon_loss: 0.014462785795331001	bpp_loss: 3.311746835708618	aux_loss: 0.28265637159347534
10:32:39 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 4.0348968505859375	recon_loss: 0.014456340111792088	bpp_loss: 3.312079668045044	aux_loss: 0.24968253076076508
10:41:01 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 4.034910678863525	recon_loss: 0.014459634199738503	bpp_loss: 3.3119289875030518	aux_loss: 0.39546477794647217
10:49:44 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 4.034411907196045	recon_loss: 0.014454104006290436	bpp_loss: 3.311706781387329	aux_loss: 0.3556743860244751
10:49:54 INFO - main: {'TEST MSE': 0.014479406366302629, 'TEST BPP': 3.364765625, 'TEST loss': 4.0639764342308045, 'TEST recon_loss': 0.0144794059433043, 'TEST bpp_loss': 3.340006129026413}
10:59:11 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 4.034278869628906	recon_loss: 0.014455404132604599	bpp_loss: 3.3115086555480957	aux_loss: 0.3667232096195221
11:08:40 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 4.034595012664795	recon_loss: 0.01444277074187994	bpp_loss: 3.3124566078186035	aux_loss: 0.33679771423339844
11:17:10 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 4.03464412689209	recon_loss: 0.014455385506153107	bpp_loss: 3.3118746280670166	aux_loss: 0.31570833921432495
11:25:37 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 4.034915447235107	recon_loss: 0.014445226639509201	bpp_loss: 3.3126540184020996	aux_loss: 0.36496803164482117
11:33:58 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 4.034549713134766	recon_loss: 0.014445073902606964	bpp_loss: 3.312296152114868	aux_loss: 0.30508995056152344
11:34:05 INFO - main: {'TEST MSE': 0.014474222429657296, 'TEST BPP': 3.3646875, 'TEST loss': 4.06367049908638, 'TEST recon_loss': 0.014474222019314765, 'TEST bpp_loss': 3.339959394454956}
11:42:25 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 4.0337300300598145	recon_loss: 0.014444476924836636	bpp_loss: 3.3115062713623047	aux_loss: 0.43530142307281494
11:50:47 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 4.033998966217041	recon_loss: 0.014446433633565903	bpp_loss: 3.3116772174835205	aux_loss: 0.3260955512523651
11:59:06 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 4.034580230712891	recon_loss: 0.014455531723797321	bpp_loss: 3.3118035793304443	aux_loss: 0.2684367895126343
12:07:28 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 4.035093307495117	recon_loss: 0.014453032054007053	bpp_loss: 3.31244158744812	aux_loss: 0.3203299641609192
12:15:50 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 4.0345916748046875	recon_loss: 0.014459967613220215	bpp_loss: 3.3115932941436768	aux_loss: 0.29104581475257874
12:15:57 INFO - main: {'TEST MSE': 0.014478449923249346, 'TEST BPP': 3.364375, 'TEST loss': 4.063716985940934, 'TEST recon_loss': 0.01447844950389117, 'TEST bpp_loss': 3.3397945075035094}
12:24:16 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 4.033900260925293	recon_loss: 0.014452153816819191	bpp_loss: 3.3112924098968506	aux_loss: 0.30501243472099304
12:32:38 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 4.033968925476074	recon_loss: 0.014443090185523033	bpp_loss: 3.311814546585083	aux_loss: 0.3902173936367035
12:40:58 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 4.033515453338623	recon_loss: 0.014437730424106121	bpp_loss: 3.311629056930542	aux_loss: 0.2506580948829651
12:49:19 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 4.033864498138428	recon_loss: 0.014441295526921749	bpp_loss: 3.3117997646331787	aux_loss: 0.3399488925933838
12:57:40 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 4.035492420196533	recon_loss: 0.014467041939496994	bpp_loss: 3.3121402263641357	aux_loss: 0.4723761975765228
12:57:48 INFO - main: {'TEST MSE': 0.014472273128773536, 'TEST BPP': 3.36490625, 'TEST loss': 4.063663884878158, 'TEST recon_loss': 0.014472272706218064, 'TEST bpp_loss': 3.3400502424240113}
13:06:07 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 4.034149169921875	recon_loss: 0.014441060833632946	bpp_loss: 3.312095880508423	aux_loss: 0.388005793094635
13:14:27 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 4.034014701843262	recon_loss: 0.014446397311985493	bpp_loss: 3.311695098876953	aux_loss: 0.3064464330673218
13:22:46 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 4.034807205200195	recon_loss: 0.01445430051535368	bpp_loss: 3.3120920658111572	aux_loss: 0.4457809329032898
13:31:07 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 4.033630847930908	recon_loss: 0.014439839869737625	bpp_loss: 3.311638832092285	aux_loss: 0.36369630694389343
13:39:28 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 4.035451889038086	recon_loss: 0.014460239559412003	bpp_loss: 3.3124401569366455	aux_loss: 0.37412789463996887
13:39:35 INFO - main: {'TEST MSE': 0.014469692300426367, 'TEST BPP': 3.3644375, 'TEST loss': 4.063429690122605, 'TEST recon_loss': 0.014469691887497901, 'TEST bpp_loss': 3.3399450969696045}
13:47:55 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 4.034728050231934	recon_loss: 0.014453403651714325	bpp_loss: 3.3120577335357666	aux_loss: 0.3392981290817261
13:56:17 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 4.034395217895508	recon_loss: 0.014460140839219093	bpp_loss: 3.3113880157470703	aux_loss: 0.3159235417842865
14:04:35 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 4.034623146057129	recon_loss: 0.014459180645644665	bpp_loss: 3.311663866043091	aux_loss: 0.24901461601257324
14:12:55 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 4.033294200897217	recon_loss: 0.014449380338191986	bpp_loss: 3.3108253479003906	aux_loss: 0.26726919412612915
14:21:16 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 4.035507678985596	recon_loss: 0.014467285014688969	bpp_loss: 3.312143564224243	aux_loss: 0.3257373869419098
14:21:23 INFO - main: {'TEST MSE': 0.014480596303416155, 'TEST BPP': 3.364203125, 'TEST loss': 4.063784788370133, 'TEST recon_loss': 0.014480595875531434, 'TEST bpp_loss': 3.3397549958229065}
14:29:42 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 4.034230709075928	recon_loss: 0.014452078379690647	bpp_loss: 3.31162691116333	aux_loss: 0.37618157267570496
14:38:03 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 4.033317565917969	recon_loss: 0.014448929578065872	bpp_loss: 3.310870885848999	aux_loss: 0.3677866458892822
14:46:22 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 4.034496307373047	recon_loss: 0.0144411101937294	bpp_loss: 3.312440872192383	aux_loss: 0.3504065275192261
14:54:44 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 4.034189701080322	recon_loss: 0.014442364685237408	bpp_loss: 3.3120713233947754	aux_loss: 0.4227951169013977
15:03:05 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 4.034739017486572	recon_loss: 0.014457696117460728	bpp_loss: 3.311854124069214	aux_loss: 0.4093143939971924
15:03:12 INFO - main: {'TEST MSE': 0.014470654782431322, 'TEST BPP': 3.3644375, 'TEST loss': 4.063572972536087, 'TEST recon_loss': 0.014470654358156025, 'TEST bpp_loss': 3.34004024887085}
15:11:33 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 4.033568382263184	recon_loss: 0.014437323436141014	bpp_loss: 3.311702251434326	aux_loss: 0.283135324716568
15:19:54 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 4.033868789672852	recon_loss: 0.014442075043916702	bpp_loss: 3.31176495552063	aux_loss: 0.3789774179458618
15:28:14 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 4.033961296081543	recon_loss: 0.014447923749685287	bpp_loss: 3.3115651607513428	aux_loss: 0.272591233253479
15:36:36 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 4.033627510070801	recon_loss: 0.014439763501286507	bpp_loss: 3.3116393089294434	aux_loss: 0.3610970973968506
15:44:59 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 4.033886432647705	recon_loss: 0.014449777081608772	bpp_loss: 3.3113975524902344	aux_loss: 0.4126250743865967
15:45:06 INFO - main: {'TEST MSE': 0.014470074137734866, 'TEST BPP': 3.36425, 'TEST loss': 4.063398368120193, 'TEST recon_loss': 0.014470073711127043, 'TEST bpp_loss': 3.339894679784775}
15:53:25 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 4.0324015617370605	recon_loss: 0.01442614383995533	bpp_loss: 3.3110945224761963	aux_loss: 0.38100534677505493
16:01:46 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 4.0326666831970215	recon_loss: 0.014434896409511566	bpp_loss: 3.3109216690063477	aux_loss: 0.2754283547401428
16:10:06 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 4.034098148345947	recon_loss: 0.01444832980632782	bpp_loss: 3.3116817474365234	aux_loss: 0.26210153102874756
16:18:28 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 4.034376621246338	recon_loss: 0.014450539834797382	bpp_loss: 3.31184983253479	aux_loss: 0.44996172189712524
16:26:50 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 4.0336408615112305	recon_loss: 0.014436422847211361	bpp_loss: 3.311819553375244	aux_loss: 0.3941477835178375
16:26:57 INFO - main: {'TEST MSE': 0.014470996928371432, 'TEST BPP': 3.364265625, 'TEST loss': 4.0633822548389436, 'TEST recon_loss': 0.014470996502786874, 'TEST bpp_loss': 3.339832434177399}
16:35:17 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 4.034557342529297	recon_loss: 0.014449297450482845	bpp_loss: 3.3120923042297363	aux_loss: 0.4200727939605713
16:43:39 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 4.034698486328125	recon_loss: 0.014445768669247627	bpp_loss: 3.3124101161956787	aux_loss: 0.34653007984161377
16:51:58 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 4.034579753875732	recon_loss: 0.014447120018303394	bpp_loss: 3.3122239112854004	aux_loss: 0.35264989733695984
17:00:19 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 4.034177303314209	recon_loss: 0.014442593790590763	bpp_loss: 3.3120477199554443	aux_loss: 0.3669229745864868
17:08:41 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 4.033909797668457	recon_loss: 0.014432933181524277	bpp_loss: 3.312263250350952	aux_loss: 0.32321056723594666
17:08:48 INFO - main: {'TEST MSE': 0.01446361879969124, 'TEST BPP': 3.364484375, 'TEST loss': 4.06328261423111, 'TEST recon_loss': 0.014463618375360966, 'TEST bpp_loss': 3.3401016907691954}
17:17:07 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 4.03395938873291	recon_loss: 0.01445032563060522	bpp_loss: 3.311443328857422	aux_loss: 0.33850622177124023
17:25:28 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 4.0342864990234375	recon_loss: 0.014447278343141079	bpp_loss: 3.311922550201416	aux_loss: 0.34917712211608887
17:33:47 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 4.033331871032715	recon_loss: 0.01444990187883377	bpp_loss: 3.3108365535736084	aux_loss: 0.39987069368362427
17:42:08 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 4.034820556640625	recon_loss: 0.014451446942985058	bpp_loss: 3.3122479915618896	aux_loss: 0.3531267046928406
17:50:29 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 4.032927989959717	recon_loss: 0.014440261758863926	bpp_loss: 3.3109147548675537	aux_loss: 0.32184165716171265
17:50:36 INFO - main: {'TEST MSE': 0.014465379989185881, 'TEST BPP': 3.3643125, 'TEST loss': 4.063251365900039, 'TEST recon_loss': 0.014465379563160241, 'TEST bpp_loss': 3.3399823782444}
17:58:54 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 4.0337982177734375	recon_loss: 0.014446930959820747	bpp_loss: 3.3114516735076904	aux_loss: 0.32707396149635315
18:07:15 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 4.035222053527832	recon_loss: 0.014444936998188496	bpp_loss: 3.3129754066467285	aux_loss: 0.27002251148223877
18:15:34 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 4.033974647521973	recon_loss: 0.01444205455482006	bpp_loss: 3.3118720054626465	aux_loss: 0.41005176305770874
18:23:56 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 4.034496307373047	recon_loss: 0.014443921856582165	bpp_loss: 3.312300443649292	aux_loss: 0.25692659616470337
18:32:17 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 4.033959865570068	recon_loss: 0.014438880607485771	bpp_loss: 3.312016010284424	aux_loss: 0.3349909782409668
18:32:25 INFO - main: {'TEST MSE': 0.014466676418410276, 'TEST BPP': 3.36428125, 'TEST loss': 4.063278625965118, 'TEST recon_loss': 0.014466675988398492, 'TEST bpp_loss': 3.339944829940796}
18:40:44 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 4.034598350524902	recon_loss: 0.01445140689611435	bpp_loss: 3.312028169631958	aux_loss: 0.3787488639354706
18:49:05 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 4.034651279449463	recon_loss: 0.0144491046667099	bpp_loss: 3.3121960163116455	aux_loss: 0.30969715118408203
18:57:24 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 4.032999038696289	recon_loss: 0.01444187480956316	bpp_loss: 3.3109054565429688	aux_loss: 0.38328635692596436
19:05:44 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 4.033985137939453	recon_loss: 0.014433720149099827	bpp_loss: 3.3122990131378174	aux_loss: 0.36150336265563965
19:14:06 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 4.033769607543945	recon_loss: 0.014452139846980572	bpp_loss: 3.3111627101898193	aux_loss: 0.2937282621860504
19:14:13 INFO - main: {'TEST MSE': 0.014464094610851944, 'TEST BPP': 3.3645625, 'TEST loss': 4.063301773071289, 'TEST recon_loss': 0.014464094177819789, 'TEST bpp_loss': 3.3400970680713655}
19:22:32 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 4.034029006958008	recon_loss: 0.014438251033425331	bpp_loss: 3.3121163845062256	aux_loss: 0.40405672788619995
19:30:53 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 4.033327579498291	recon_loss: 0.014439928345382214	bpp_loss: 3.311331272125244	aux_loss: 0.29232257604599
19:39:12 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 4.03359842300415	recon_loss: 0.014451606199145317	bpp_loss: 3.311018228530884	aux_loss: 0.34360140562057495
19:47:34 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 4.033915996551514	recon_loss: 0.014434252865612507	bpp_loss: 3.3122034072875977	aux_loss: 0.33912593126296997
19:55:55 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 4.034063339233398	recon_loss: 0.014440624043345451	bpp_loss: 3.3120319843292236	aux_loss: 0.31783756613731384
19:56:03 INFO - main: {'TEST MSE': 0.014464022808310443, 'TEST BPP': 3.36440625, 'TEST loss': 4.063234492540359, 'TEST recon_loss': 0.01446402239613235, 'TEST bpp_loss': 3.340033369064331}
20:04:22 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 4.0351104736328125	recon_loss: 0.014448605477809906	bpp_loss: 3.312680244445801	aux_loss: 0.31512969732284546
20:12:43 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 4.034471035003662	recon_loss: 0.014443233609199524	bpp_loss: 3.312309503555298	aux_loss: 0.320715069770813
20:21:02 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 4.0338134765625	recon_loss: 0.014437523670494556	bpp_loss: 3.3119373321533203	aux_loss: 0.4596976637840271
20:29:24 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 4.033620357513428	recon_loss: 0.01444721594452858	bpp_loss: 3.3112597465515137	aux_loss: 0.4683796465396881
20:37:45 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 4.0340776443481445	recon_loss: 0.0144388722255826	bpp_loss: 3.3121337890625	aux_loss: 0.37810108065605164
20:37:53 INFO - main: {'TEST MSE': 0.014462885777570373, 'TEST BPP': 3.36446875, 'TEST loss': 4.063260791301727, 'TEST recon_loss': 0.014462885373272002, 'TEST bpp_loss': 3.34011652135849}
20:46:12 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 4.034398078918457	recon_loss: 0.014435257762670517	bpp_loss: 3.3126349449157715	aux_loss: 0.3358348608016968
20:54:34 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 4.034238815307617	recon_loss: 0.01444942969828844	bpp_loss: 3.311767101287842	aux_loss: 0.2809636890888214
21:02:54 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 4.034509658813477	recon_loss: 0.01444924995303154	bpp_loss: 3.312047243118286	aux_loss: 0.3418733477592468
21:11:14 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 4.034331321716309	recon_loss: 0.014445073902606964	bpp_loss: 3.312077522277832	aux_loss: 0.28438836336135864
21:19:35 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 4.034399032592773	recon_loss: 0.014447174035012722	bpp_loss: 3.312040090560913	aux_loss: 0.37209945917129517
21:19:43 INFO - main: {'TEST MSE': 0.014467855704429617, 'TEST BPP': 3.364578125, 'TEST loss': 4.063624149560928, 'TEST recon_loss': 0.01446785528678447, 'TEST bpp_loss': 3.3402313890457154}
21:28:02 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 4.032980918884277	recon_loss: 0.014433535747230053	bpp_loss: 3.3113040924072266	aux_loss: 0.36446645855903625
21:36:23 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 4.034102916717529	recon_loss: 0.014441877603530884	bpp_loss: 3.312008857727051	aux_loss: 0.3423006534576416
21:44:44 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 4.033749580383301	recon_loss: 0.014436349272727966	bpp_loss: 3.311931848526001	aux_loss: 0.31580328941345215
21:53:04 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 4.03378963470459	recon_loss: 0.014440168626606464	bpp_loss: 3.311781406402588	aux_loss: 0.33301419019699097
22:01:24 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 4.032825946807861	recon_loss: 0.01442824024707079	bpp_loss: 3.3114137649536133	aux_loss: 0.38504061102867126
22:01:32 INFO - main: {'TEST MSE': 0.014466348569532536, 'TEST BPP': 3.364375, 'TEST loss': 4.063329678058624, 'TEST recon_loss': 0.014466348166577518, 'TEST bpp_loss': 3.340012267589569}
22:09:51 INFO - main: Train iter. 161000/200000 (80.5%): 	Loss: 4.034072399139404	recon_loss: 0.014446988701820374	bpp_loss: 3.311722993850708	aux_loss: 0.2893677353858948
22:18:13 INFO - main: Train iter. 162000/200000 (81.0%): 	Loss: 4.034772872924805	recon_loss: 0.014442434534430504	bpp_loss: 3.3126513957977295	aux_loss: 0.3711967170238495
22:26:34 INFO - main: Train iter. 163000/200000 (81.5%): 	Loss: 4.033336162567139	recon_loss: 0.01444124337285757	bpp_loss: 3.3112738132476807	aux_loss: 0.40978091955184937
22:34:54 INFO - main: Train iter. 164000/200000 (82.0%): 	Loss: 4.033968925476074	recon_loss: 0.014432225376367569	bpp_loss: 3.3123576641082764	aux_loss: 0.3330247402191162
22:43:14 INFO - main: Train iter. 165000/200000 (82.5%): 	Loss: 4.033570766448975	recon_loss: 0.014444057829678059	bpp_loss: 3.3113677501678467	aux_loss: 0.3638753294944763
22:43:21 INFO - main: {'TEST MSE': 0.014465517739281439, 'TEST BPP': 3.36434375, 'TEST loss': 4.0632571396827695, 'TEST recon_loss': 0.014465517309494316, 'TEST bpp_loss': 3.3399812672138216}
22:51:40 INFO - main: Train iter. 166000/200000 (83.0%): 	Loss: 4.034209728240967	recon_loss: 0.014445505104959011	bpp_loss: 3.311934471130371	aux_loss: 0.427051305770874
23:00:01 INFO - main: Train iter. 167000/200000 (83.5%): 	Loss: 4.033588886260986	recon_loss: 0.014448614791035652	bpp_loss: 3.3111581802368164	aux_loss: 0.30054664611816406
23:08:21 INFO - main: Train iter. 168000/200000 (84.0%): 	Loss: 4.033578872680664	recon_loss: 0.014429052360355854	bpp_loss: 3.3121261596679688	aux_loss: 0.29740047454833984
23:16:41 INFO - main: Train iter. 169000/200000 (84.5%): 	Loss: 4.034181118011475	recon_loss: 0.014440363273024559	bpp_loss: 3.3121628761291504	aux_loss: 0.32442474365234375
23:25:01 INFO - main: Train iter. 170000/200000 (85.0%): 	Loss: 4.034079551696777	recon_loss: 0.014446152374148369	bpp_loss: 3.311771869659424	aux_loss: 0.3191445767879486
23:25:09 INFO - main: {'TEST MSE': 0.014464207036171269, 'TEST BPP': 3.364484375, 'TEST loss': 4.063264743804932, 'TEST recon_loss': 0.014464206612668931, 'TEST bpp_loss': 3.340054410934448}
23:33:28 INFO - main: Train iter. 171000/200000 (85.5%): 	Loss: 4.033030033111572	recon_loss: 0.014445231296122074	bpp_loss: 3.3107686042785645	aux_loss: 0.35805773735046387
23:41:49 INFO - main: Train iter. 172000/200000 (86.0%): 	Loss: 4.03299617767334	recon_loss: 0.014427286572754383	bpp_loss: 3.311631917953491	aux_loss: 0.26967528462409973
23:50:11 INFO - main: Train iter. 173000/200000 (86.5%): 	Loss: 4.03346061706543	recon_loss: 0.014439545571804047	bpp_loss: 3.311483144760132	aux_loss: 0.3730083107948303
23:58:30 INFO - main: Train iter. 174000/200000 (87.0%): 	Loss: 4.034143447875977	recon_loss: 0.014450416900217533	bpp_loss: 3.3116228580474854	aux_loss: 0.3025020956993103
00:06:52 INFO - main: Train iter. 175000/200000 (87.5%): 	Loss: 4.035764694213867	recon_loss: 0.014462443999946117	bpp_loss: 3.3126423358917236	aux_loss: 0.30700767040252686
00:06:59 INFO - main: {'TEST MSE': 0.014475318001813568, 'TEST BPP': 3.36428125, 'TEST loss': 4.063790907144546, 'TEST recon_loss': 0.01447531759366393, 'TEST bpp_loss': 3.340025026321411}
00:15:19 INFO - main: Train iter. 176000/200000 (88.0%): 	Loss: 4.034711837768555	recon_loss: 0.014433450065553188	bpp_loss: 3.3130393028259277	aux_loss: 0.28548771142959595
00:23:40 INFO - main: Train iter. 177000/200000 (88.5%): 	Loss: 4.034318447113037	recon_loss: 0.014437815174460411	bpp_loss: 3.3124277591705322	aux_loss: 0.37050509452819824
00:32:01 INFO - main: Train iter. 178000/200000 (89.0%): 	Loss: 4.033466815948486	recon_loss: 0.014436367899179459	bpp_loss: 3.311648368835449	aux_loss: 0.30927854776382446
00:40:21 INFO - main: Train iter. 179000/200000 (89.5%): 	Loss: 4.035014629364014	recon_loss: 0.014434815384447575	bpp_loss: 3.3132739067077637	aux_loss: 0.4232906103134155
00:48:42 INFO - main: Train iter. 180000/200000 (90.0%): 	Loss: 4.033648490905762	recon_loss: 0.014441055245697498	bpp_loss: 3.3115956783294678	aux_loss: 0.3653474450111389
00:48:50 INFO - main: {'TEST MSE': 0.014466095712875257, 'TEST BPP': 3.3643125, 'TEST loss': 4.063300756931305, 'TEST recon_loss': 0.014466095315292478, 'TEST bpp_loss': 3.33999599480629}
00:57:09 INFO - main: Train iter. 181000/200000 (90.5%): 	Loss: 4.033896446228027	recon_loss: 0.014437234029173851	bpp_loss: 3.3120346069335938	aux_loss: 0.21796032786369324
01:05:30 INFO - main: Train iter. 182000/200000 (91.0%): 	Loss: 4.033053398132324	recon_loss: 0.0144430510699749	bpp_loss: 3.3109006881713867	aux_loss: 0.33835771679878235
01:13:51 INFO - main: Train iter. 183000/200000 (91.5%): 	Loss: 4.033388137817383	recon_loss: 0.014439024031162262	bpp_loss: 3.3114371299743652	aux_loss: 0.1994168758392334
01:22:11 INFO - main: Train iter. 184000/200000 (92.0%): 	Loss: 4.035088539123535	recon_loss: 0.014442304149270058	bpp_loss: 3.3129732608795166	aux_loss: 0.36518627405166626
01:30:33 INFO - main: Train iter. 185000/200000 (92.5%): 	Loss: 4.034109592437744	recon_loss: 0.014446068555116653	bpp_loss: 3.3118059635162354	aux_loss: 0.29113906621932983
01:30:40 INFO - main: {'TEST MSE': 0.014465669890734046, 'TEST BPP': 3.36434375, 'TEST loss': 4.063230173587799, 'TEST recon_loss': 0.014465669482946395, 'TEST bpp_loss': 3.339946696519852}
01:39:00 INFO - main: Train iter. 186000/200000 (93.0%): 	Loss: 4.034397125244141	recon_loss: 0.01443743146955967	bpp_loss: 3.312525510787964	aux_loss: 0.30374541878700256
01:47:20 INFO - main: Train iter. 187000/200000 (93.5%): 	Loss: 4.033804416656494	recon_loss: 0.014424959197640419	bpp_loss: 3.312556505203247	aux_loss: 0.29706284403800964
01:55:42 INFO - main: Train iter. 188000/200000 (94.0%): 	Loss: 4.034032344818115	recon_loss: 0.01442836131900549	bpp_loss: 3.3126144409179688	aux_loss: 0.5322690606117249
02:04:02 INFO - main: Train iter. 189000/200000 (94.5%): 	Loss: 4.034348487854004	recon_loss: 0.014441307634115219	bpp_loss: 3.3122832775115967	aux_loss: 0.3499211072921753
02:12:23 INFO - main: Train iter. 190000/200000 (95.0%): 	Loss: 4.0343146324157715	recon_loss: 0.014434116892516613	bpp_loss: 3.3126089572906494	aux_loss: 0.3402179777622223
02:12:30 INFO - main: {'TEST MSE': 0.014462259593760766, 'TEST BPP': 3.364515625, 'TEST loss': 4.063265655040741, 'TEST recon_loss': 0.014462259188294411, 'TEST bpp_loss': 3.34015269780159}
02:20:50 INFO - main: Train iter. 191000/200000 (95.5%): 	Loss: 4.034582138061523	recon_loss: 0.014440027065575123	bpp_loss: 3.3125805854797363	aux_loss: 0.32569268345832825
02:29:12 INFO - main: Train iter. 192000/200000 (96.0%): 	Loss: 4.033587455749512	recon_loss: 0.014449936337769032	bpp_loss: 3.3110904693603516	aux_loss: 0.3129674196243286
02:37:33 INFO - main: Train iter. 193000/200000 (96.5%): 	Loss: 4.0337934494018555	recon_loss: 0.014453496783971786	bpp_loss: 3.3111183643341064	aux_loss: 0.32151171565055847
02:45:52 INFO - main: Train iter. 194000/200000 (97.0%): 	Loss: 4.033012390136719	recon_loss: 0.014428689144551754	bpp_loss: 3.311577796936035	aux_loss: 0.2722066044807434
02:54:14 INFO - main: Train iter. 195000/200000 (97.5%): 	Loss: 4.034400939941406	recon_loss: 0.014438984915614128	bpp_loss: 3.3124518394470215	aux_loss: 0.41492316126823425
02:54:22 INFO - main: {'TEST MSE': 0.014463857159388013, 'TEST BPP': 3.364421875, 'TEST loss': 4.063227441310882, 'TEST recon_loss': 0.01446385674085468, 'TEST bpp_loss': 3.3400345973968504}
03:02:41 INFO - main: Train iter. 196000/200000 (98.0%): 	Loss: 4.033796787261963	recon_loss: 0.0144368140026927	bpp_loss: 3.3119561672210693	aux_loss: 0.32117220759391785
03:11:02 INFO - main: Train iter. 197000/200000 (98.5%): 	Loss: 4.033280372619629	recon_loss: 0.014429631642997265	bpp_loss: 3.3117990493774414	aux_loss: 0.36971211433410645
03:19:22 INFO - main: Train iter. 198000/200000 (99.0%): 	Loss: 4.033602237701416	recon_loss: 0.014436277560889721	bpp_loss: 3.311788320541382	aux_loss: 0.4356999099254608
03:27:42 INFO - main: Train iter. 199000/200000 (99.5%): 	Loss: 4.034409046173096	recon_loss: 0.014439424499869347	bpp_loss: 3.3124380111694336	aux_loss: 0.3551769256591797
03:36:03 INFO - main: Train iter. 200000/200000 (100.0%): 	Loss: 4.033658981323242	recon_loss: 0.014441336505115032	bpp_loss: 3.3115923404693604	aux_loss: 0.3675740957260132
03:36:10 INFO - main: {'TEST MSE': 0.014461420276530091, 'TEST BPP': 3.364421875, 'TEST loss': 4.06322124505043, 'TEST recon_loss': 0.014461419867351652, 'TEST bpp_loss': 3.3401502540111543}
