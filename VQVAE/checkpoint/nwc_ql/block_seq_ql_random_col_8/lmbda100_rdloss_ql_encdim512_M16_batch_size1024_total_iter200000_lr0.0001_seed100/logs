20:00:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:00:30 INFO - ddp_or_single_process: Create new exp folder!
20:00:30 INFO - ddp_or_single_process: seed : 100
20:00:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:00:31 INFO - main: Create experiment save folder
20:00:43 INFO - main: Training mode : scratch!
20:00:43 INFO - main: batch_size : 1024
20:00:43 INFO - main: num of gpus: 1
20:00:43 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=100, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:00:45 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 15747.6181640625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9310302734375
20:01:44 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:01:44 INFO - ddp_or_single_process: find checkpoint...
20:01:44 INFO - ddp_or_single_process: no checkpoint is here
20:01:44 INFO - ddp_or_single_process: seed : 100
20:01:44 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:01:46 INFO - main: Create experiment save folder
20:01:57 INFO - main: Training mode : scratch!
20:01:57 INFO - main: batch_size : 1024
20:01:57 INFO - main: num of gpus: 1
20:01:57 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=100, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:01:59 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 15747.6181640625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9310302734375
20:05:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:05:30 INFO - ddp_or_single_process: find checkpoint...
20:05:30 INFO - ddp_or_single_process: no checkpoint is here
20:05:30 INFO - ddp_or_single_process: seed : 100
20:05:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:05:36 INFO - main: Create experiment save folder
20:05:47 INFO - main: Training mode : scratch!
20:05:47 INFO - main: batch_size : 1024
20:05:47 INFO - main: num of gpus: 1
20:05:47 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=100, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda100_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:05:49 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 15747.6181640625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9310302734375
20:05:57 INFO - main: {'TEST MSE': 124.07179014787383, 'TEST BPP': 5.565984375, 'TEST loss': 12414.03781665039, 'TEST recon_loss': 124.07178649044037, 'TEST bpp_loss': 5.444817252635956}
20:05:57 INFO - main: can not find prev_mse_best_model!
20:05:57 INFO - main: can not find prev_bpp_best_model!
20:05:57 INFO - main: can not find prev_bpp_best_model!
20:05:57 INFO - main: can not find recent_saved_model!
20:14:48 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 8.466111183166504	recon_loss: 0.024216050282120705	bpp_loss: 4.989450454711914	aux_loss: 316.1630859375
20:23:41 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 6.49188756942749	recon_loss: 0.016531186178326607	bpp_loss: 4.783604621887207	aux_loss: 300.866455078125
20:32:35 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 5.857132434844971	recon_loss: 0.013999839313328266	bpp_loss: 4.745454788208008	aux_loss: 274.0551452636719
20:41:31 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 5.279432773590088	recon_loss: 0.012907647527754307	bpp_loss: 4.899566173553467	aux_loss: 241.99835205078125
20:50:24 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 5.222921848297119	recon_loss: 0.012676628306508064	bpp_loss: 4.914818286895752	aux_loss: 218.69338989257812
20:50:32 INFO - main: {'TEST MSE': 0.012889462090787002, 'TEST BPP': 5.09078125, 'TEST loss': 5.205215395510197, 'TEST recon_loss': 0.01288946169335395, 'TEST bpp_loss': 4.940850827693939}
20:59:25 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 5.098139762878418	recon_loss: 0.012158038094639778	bpp_loss: 4.839908123016357	aux_loss: 205.65818786621094
21:08:21 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 5.052101135253906	recon_loss: 0.011303093284368515	bpp_loss: 4.779532432556152	aux_loss: 196.6015167236328
21:17:15 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 4.802822113037109	recon_loss: 0.01059035211801529	bpp_loss: 4.761734485626221	aux_loss: 187.07962036132812
21:26:08 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 4.872002601623535	recon_loss: 0.010545686818659306	bpp_loss: 4.70244836807251	aux_loss: 176.79286193847656
21:35:03 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 4.708357810974121	recon_loss: 0.010045397095382214	bpp_loss: 4.716320037841797	aux_loss: 165.90257263183594
21:35:11 INFO - main: {'TEST MSE': 0.009649140545272996, 'TEST BPP': 4.780515625, 'TEST loss': 4.68368788844347, 'TEST recon_loss': 0.009649140250869095, 'TEST bpp_loss': 4.738487772941589}
21:44:05 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 4.586525917053223	recon_loss: 0.009645258076488972	bpp_loss: 4.827378273010254	aux_loss: 155.96652221679688
21:52:58 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 4.969898223876953	recon_loss: 0.010317590087652206	bpp_loss: 4.626446723937988	aux_loss: 148.1582794189453
22:01:51 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 5.047276020050049	recon_loss: 0.009998418390750885	bpp_loss: 4.703005790710449	aux_loss: 140.4700469970703
22:10:46 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 4.819269180297852	recon_loss: 0.00998237170279026	bpp_loss: 4.7088847160339355	aux_loss: 134.03135681152344
22:19:39 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 4.875255584716797	recon_loss: 0.009795584715902805	bpp_loss: 4.688840866088867	aux_loss: 127.64216613769531
22:19:47 INFO - main: {'TEST MSE': 0.00947075840004351, 'TEST BPP': 4.770296875, 'TEST loss': 4.724270551145077, 'TEST recon_loss': 0.009470758110284805, 'TEST bpp_loss': 4.73840345287323}
22:28:40 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 4.8997416496276855	recon_loss: 0.01017325185239315	bpp_loss: 4.745082378387451	aux_loss: 121.81747436523438
22:37:35 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 4.948479175567627	recon_loss: 0.009574362076818943	bpp_loss: 4.690163612365723	aux_loss: 117.27774810791016
22:46:29 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 4.805529594421387	recon_loss: 0.009615933522582054	bpp_loss: 4.779325485229492	aux_loss: 112.3409652709961
22:55:22 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 4.599860668182373	recon_loss: 0.009082836098968983	bpp_loss: 4.787110328674316	aux_loss: 107.84001159667969
23:04:17 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 4.678389072418213	recon_loss: 0.009209925308823586	bpp_loss: 4.775317668914795	aux_loss: 103.6396713256836
23:04:25 INFO - main: {'TEST MSE': 0.00921725345905913, 'TEST BPP': 4.82996875, 'TEST loss': 4.76112704589963, 'TEST recon_loss': 0.009217253154376522, 'TEST bpp_loss': 4.791489750623703}
23:13:18 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 5.018651962280273	recon_loss: 0.00960646104067564	bpp_loss: 4.698184013366699	aux_loss: 99.70093536376953
23:22:11 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 4.895242691040039	recon_loss: 0.009445443749427795	bpp_loss: 4.702121257781982	aux_loss: 95.45745849609375
23:31:05 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 4.87069845199585	recon_loss: 0.009523293934762478	bpp_loss: 4.706002712249756	aux_loss: 91.80986022949219
23:40:00 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 5.009139060974121	recon_loss: 0.009524726308882236	bpp_loss: 4.681851863861084	aux_loss: 88.31938171386719
23:48:54 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 4.772785663604736	recon_loss: 0.009192332625389099	bpp_loss: 4.786768436431885	aux_loss: 84.51463317871094
23:49:02 INFO - main: {'TEST MSE': 0.00901769200052552, 'TEST BPP': 4.839875, 'TEST loss': 4.712511120051145, 'TEST recon_loss': 0.009017691746295896, 'TEST bpp_loss': 4.7936697473526}
23:57:55 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 4.863154888153076	recon_loss: 0.009295140393078327	bpp_loss: 4.6889967918396	aux_loss: 81.05826568603516
00:06:51 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 4.782760143280029	recon_loss: 0.009158574044704437	bpp_loss: 4.719558238983154	aux_loss: 77.1937026977539
00:15:44 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 4.772624969482422	recon_loss: 0.009113404899835587	bpp_loss: 4.754037857055664	aux_loss: 73.97596740722656
00:24:38 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 4.615297794342041	recon_loss: 0.008731425739824772	bpp_loss: 4.8140645027160645	aux_loss: 70.88299560546875
00:33:33 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 4.599442005157471	recon_loss: 0.008707036264240742	bpp_loss: 4.835668087005615	aux_loss: 68.28570556640625
00:33:41 INFO - main: {'TEST MSE': 0.009164655672711849, 'TEST BPP': 4.800828125, 'TEST loss': 4.784711022019386, 'TEST recon_loss': 0.009164655411208514, 'TEST bpp_loss': 4.749037370681763}
00:42:35 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 4.8548712730407715	recon_loss: 0.009307663887739182	bpp_loss: 4.740286350250244	aux_loss: 64.57575225830078
00:51:29 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 4.7716169357299805	recon_loss: 0.00906011089682579	bpp_loss: 4.790503978729248	aux_loss: 61.789878845214844
01:00:22 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 4.600109100341797	recon_loss: 0.008900527842342854	bpp_loss: 4.824641704559326	aux_loss: 59.231658935546875
01:09:18 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 4.649706840515137	recon_loss: 0.008853143081068993	bpp_loss: 4.801540374755859	aux_loss: 55.90378189086914
01:18:12 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 4.729643821716309	recon_loss: 0.009025580249726772	bpp_loss: 4.755069255828857	aux_loss: 53.517311096191406
01:18:20 INFO - main: {'TEST MSE': 0.00911144177215995, 'TEST BPP': 4.84609375, 'TEST loss': 4.807385128110647, 'TEST recon_loss': 0.009111441497690975, 'TEST bpp_loss': 4.788198798894882}
01:27:14 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 4.663280487060547	recon_loss: 0.008766098879277706	bpp_loss: 4.82845401763916	aux_loss: 50.60468292236328
01:36:09 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 4.891242504119873	recon_loss: 0.009333375841379166	bpp_loss: 4.698302268981934	aux_loss: 47.11990737915039
01:45:03 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 4.882599353790283	recon_loss: 0.009032576344907284	bpp_loss: 4.788780212402344	aux_loss: 44.55131912231445
01:53:56 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 4.944631576538086	recon_loss: 0.009221638552844524	bpp_loss: 4.738529682159424	aux_loss: 41.57035446166992
02:02:52 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 4.698713302612305	recon_loss: 0.00882876105606556	bpp_loss: 4.852229595184326	aux_loss: 38.90415954589844
02:03:00 INFO - main: {'TEST MSE': 0.009305666897671167, 'TEST BPP': 4.83971875, 'TEST loss': 4.9639757591784, 'TEST recon_loss': 0.00930566662363708, 'TEST bpp_loss': 4.768472438335419}
02:11:56 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 4.767973899841309	recon_loss: 0.008971096016466618	bpp_loss: 4.838750839233398	aux_loss: 35.930580139160156
02:20:50 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 4.691412925720215	recon_loss: 0.008829834870994091	bpp_loss: 4.824647903442383	aux_loss: 32.60825729370117
02:29:43 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 4.774784564971924	recon_loss: 0.009005171246826649	bpp_loss: 4.7824625968933105	aux_loss: 29.555856704711914
02:38:39 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 4.712769508361816	recon_loss: 0.008912311866879463	bpp_loss: 4.819939136505127	aux_loss: 26.709564208984375
02:47:33 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 4.752315521240234	recon_loss: 0.008968573994934559	bpp_loss: 4.757378578186035	aux_loss: 23.370609283447266
02:47:41 INFO - main: {'TEST MSE': 0.008808034203611446, 'TEST BPP': 4.89865625, 'TEST loss': 4.732900902539492, 'TEST recon_loss': 0.008808033943816554, 'TEST bpp_loss': 4.825105751276016}
02:56:34 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 4.809826374053955	recon_loss: 0.009082619100809097	bpp_loss: 4.744546890258789	aux_loss: 20.876693725585938
03:05:30 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 4.615434169769287	recon_loss: 0.00858687050640583	bpp_loss: 4.900860786437988	aux_loss: 19.154598236083984
03:14:23 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 4.766386032104492	recon_loss: 0.008841156028211117	bpp_loss: 4.8020195960998535	aux_loss: 16.29183006286621
03:23:17 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 4.695545196533203	recon_loss: 0.008724870160222054	bpp_loss: 4.776848316192627	aux_loss: 12.671693801879883
03:32:12 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 4.581456661224365	recon_loss: 0.008642270229756832	bpp_loss: 4.797342300415039	aux_loss: 10.057624816894531
03:32:20 INFO - main: {'TEST MSE': 0.008937582612123051, 'TEST BPP': 4.922171875, 'TEST loss': 4.830672114610672, 'TEST recon_loss': 0.008937582338112406, 'TEST bpp_loss': 4.835014769554138}
03:41:14 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 4.76588773727417	recon_loss: 0.00891280360519886	bpp_loss: 4.764430999755859	aux_loss: 8.649789810180664
03:50:07 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 4.78094482421875	recon_loss: 0.008876134641468525	bpp_loss: 4.804832458496094	aux_loss: 6.059199333190918
03:59:00 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 4.697575092315674	recon_loss: 0.008701755665242672	bpp_loss: 4.8908281326293945	aux_loss: 4.895264625549316
04:07:56 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 4.982863426208496	recon_loss: 0.009248409420251846	bpp_loss: 4.7702107429504395	aux_loss: 3.0397658348083496
04:16:49 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 4.754878520965576	recon_loss: 0.00880228541791439	bpp_loss: 4.834662914276123	aux_loss: 2.8033695220947266
04:16:57 INFO - main: {'TEST MSE': 0.008579611598953905, 'TEST BPP': 4.96459375, 'TEST loss': 4.6079687578678135, 'TEST recon_loss': 0.008579611349734478, 'TEST bpp_loss': 4.872941831350326}
04:25:51 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 4.8801679611206055	recon_loss: 0.009087793529033661	bpp_loss: 4.7699408531188965	aux_loss: 1.670828938484192
04:34:47 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 4.635201454162598	recon_loss: 0.008698727004230022	bpp_loss: 4.836928844451904	aux_loss: 0.9706606268882751
04:43:41 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 4.784177303314209	recon_loss: 0.00904554221779108	bpp_loss: 4.76706600189209	aux_loss: 0.7099517583847046
04:52:35 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 4.759024620056152	recon_loss: 0.00889523234218359	bpp_loss: 4.743206024169922	aux_loss: 0.1260043978691101
05:01:30 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 4.860152244567871	recon_loss: 0.008987217210233212	bpp_loss: 4.818861961364746	aux_loss: 0.8911473155021667
05:01:38 INFO - main: {'TEST MSE': 0.008964925870417294, 'TEST BPP': 4.9004375, 'TEST loss': 4.831013910591603, 'TEST recon_loss': 0.008964925596490503, 'TEST bpp_loss': 4.7990923817157745}
05:10:32 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 4.790412902832031	recon_loss: 0.008926424197852612	bpp_loss: 4.811227798461914	aux_loss: 0.10774293541908264
05:19:26 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 4.820254325866699	recon_loss: 0.0089674461632967	bpp_loss: 4.7229485511779785	aux_loss: 0.3059018850326538
05:28:19 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 5.005895137786865	recon_loss: 0.009231981821358204	bpp_loss: 4.722064971923828	aux_loss: 0.13330544531345367
05:37:14 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 4.645764350891113	recon_loss: 0.008588986471295357	bpp_loss: 4.88439416885376	aux_loss: 0.21493563055992126
05:46:07 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 5.015085697174072	recon_loss: 0.009240565821528435	bpp_loss: 4.785045146942139	aux_loss: 0.46369993686676025
05:46:15 INFO - main: {'TEST MSE': 0.008812018957521227, 'TEST BPP': 4.946609375, 'TEST loss': 4.71135340449214, 'TEST recon_loss': 0.008812018696131418, 'TEST bpp_loss': 4.854047828912735}
05:55:08 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 4.5428900718688965	recon_loss: 0.00850093923509121	bpp_loss: 4.879709720611572	aux_loss: 0.6404728889465332
06:04:03 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 4.773178577423096	recon_loss: 0.008815063163638115	bpp_loss: 4.806405067443848	aux_loss: 1.577773094177246
06:12:55 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 4.986266613006592	recon_loss: 0.009321145713329315	bpp_loss: 4.714986324310303	aux_loss: 0.41303882002830505
06:21:48 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 4.690325736999512	recon_loss: 0.008707956410944462	bpp_loss: 4.828851222991943	aux_loss: 0.3066626191139221
06:30:43 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 4.711566925048828	recon_loss: 0.008743653073906898	bpp_loss: 4.788761615753174	aux_loss: 0.16071884334087372
06:30:51 INFO - main: {'TEST MSE': 0.008529384373812869, 'TEST BPP': 4.9979375, 'TEST loss': 4.562644128024578, 'TEST recon_loss': 0.008529384121939074, 'TEST bpp_loss': 4.898115782499313}
06:39:44 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 4.814054489135742	recon_loss: 0.00891832821071148	bpp_loss: 4.76811408996582	aux_loss: 0.1279684156179428
06:48:37 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 5.090054988861084	recon_loss: 0.0093932980671525	bpp_loss: 4.790811061859131	aux_loss: 0.5592010021209717
06:57:30 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 4.8844757080078125	recon_loss: 0.008938995189964771	bpp_loss: 4.785996913909912	aux_loss: 0.48188304901123047
07:06:25 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 4.6735453605651855	recon_loss: 0.008651548065245152	bpp_loss: 4.894044399261475	aux_loss: 0.30947476625442505
07:15:18 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 4.61658239364624	recon_loss: 0.008637819439172745	bpp_loss: 4.783159255981445	aux_loss: 0.8229442834854126
07:15:26 INFO - main: {'TEST MSE': 0.008590168462664556, 'TEST BPP': 4.9088125, 'TEST loss': 4.629006649762392, 'TEST recon_loss': 0.008590168215931044, 'TEST bpp_loss': 4.817311527967453}
07:24:19 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 4.690202713012695	recon_loss: 0.00889311172068119	bpp_loss: 4.830601215362549	aux_loss: 0.5475589036941528
07:33:14 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 4.620730400085449	recon_loss: 0.008651544339954853	bpp_loss: 4.82343864440918	aux_loss: 0.18022798001766205
07:42:07 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 4.624621391296387	recon_loss: 0.008636410348117352	bpp_loss: 4.85851526260376	aux_loss: 0.14742010831832886
07:51:01 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 4.7401442527771	recon_loss: 0.008777021430432796	bpp_loss: 4.794967174530029	aux_loss: 0.28579896688461304
07:59:56 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 5.0005598068237305	recon_loss: 0.00914737582206726	bpp_loss: 4.7828049659729	aux_loss: 0.1623905450105667
08:00:04 INFO - main: {'TEST MSE': 0.008456773019416273, 'TEST BPP': 4.9760625, 'TEST loss': 4.549878623127937, 'TEST recon_loss': 0.008456772780627944, 'TEST bpp_loss': 4.8803334770202635}
08:08:57 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 4.875917434692383	recon_loss: 0.009093491360545158	bpp_loss: 4.800062656402588	aux_loss: 0.3661026656627655
08:17:51 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 4.855462074279785	recon_loss: 0.00897559430450201	bpp_loss: 4.770205497741699	aux_loss: 0.08845396339893341
08:26:45 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 4.782642841339111	recon_loss: 0.00889176968485117	bpp_loss: 4.8225178718566895	aux_loss: 0.1052003800868988
08:35:40 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 4.756659030914307	recon_loss: 0.008841244503855705	bpp_loss: 4.801433086395264	aux_loss: 0.11825187504291534
08:44:33 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 4.636040210723877	recon_loss: 0.008696358650922775	bpp_loss: 4.822903156280518	aux_loss: 0.24506905674934387
08:44:41 INFO - main: {'TEST MSE': 0.009045732972231336, 'TEST BPP': 4.89878125, 'TEST loss': 4.9245553008914, 'TEST recon_loss': 0.009045732693193713, 'TEST bpp_loss': 4.80588894200325}
08:53:34 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 4.727511405944824	recon_loss: 0.008809882216155529	bpp_loss: 4.764913558959961	aux_loss: 0.14152386784553528
09:02:28 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 4.569272994995117	recon_loss: 0.00853989738970995	bpp_loss: 4.857661724090576	aux_loss: 0.20207737386226654
09:11:21 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 4.751534461975098	recon_loss: 0.008951365947723389	bpp_loss: 4.802309513092041	aux_loss: 0.5229061841964722
09:20:14 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 4.899240970611572	recon_loss: 0.009024498052895069	bpp_loss: 4.747328758239746	aux_loss: 0.1787402182817459
09:29:08 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 4.595700263977051	recon_loss: 0.008586428128182888	bpp_loss: 4.811818599700928	aux_loss: 0.1126316636800766
09:29:17 INFO - main: {'TEST MSE': 0.008783861377398935, 'TEST BPP': 4.921140625, 'TEST loss': 4.764516159594059, 'TEST recon_loss': 0.008783861121803056, 'TEST bpp_loss': 4.820278049468994}
09:38:09 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 5.049783229827881	recon_loss: 0.00930793583393097	bpp_loss: 4.675696849822998	aux_loss: 0.9723193049430847
09:47:02 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 4.726617336273193	recon_loss: 0.008745831437408924	bpp_loss: 4.799216270446777	aux_loss: 0.34790071845054626
09:55:55 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 4.810182571411133	recon_loss: 0.00897514820098877	bpp_loss: 4.75971794128418	aux_loss: 0.12233124673366547
10:04:50 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 4.629154682159424	recon_loss: 0.00853082537651062	bpp_loss: 4.929020881652832	aux_loss: 0.13641363382339478
10:13:42 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 4.814055442810059	recon_loss: 0.008919628337025642	bpp_loss: 4.775382995605469	aux_loss: 0.09482905268669128
10:13:50 INFO - main: {'TEST MSE': 0.008290572312574832, 'TEST BPP': 5.0216875, 'TEST loss': 4.408084759801627, 'TEST recon_loss': 0.008290572077210527, 'TEST bpp_loss': 4.9227012958526615}
10:22:43 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 4.6559295654296875	recon_loss: 0.008622813038527966	bpp_loss: 4.822044372558594	aux_loss: 0.19783928990364075
10:31:38 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 5.083216667175293	recon_loss: 0.009346049278974533	bpp_loss: 4.686898708343506	aux_loss: 0.17650960385799408
10:40:31 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 4.65677547454834	recon_loss: 0.008629185147583485	bpp_loss: 4.866761684417725	aux_loss: 0.6345490217208862
10:49:24 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 4.648967742919922	recon_loss: 0.008647405542433262	bpp_loss: 4.840856075286865	aux_loss: 0.1900736391544342
10:58:19 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 4.618284225463867	recon_loss: 0.00854970421642065	bpp_loss: 4.831452369689941	aux_loss: 0.4707026779651642
10:58:27 INFO - main: {'TEST MSE': 0.008267473313831984, 'TEST BPP': 5.033359375, 'TEST loss': 4.459319622308016, 'TEST recon_loss': 0.008267473056912422, 'TEST bpp_loss': 4.932838742494583}
11:07:20 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 5.086734294891357	recon_loss: 0.0092990817502141	bpp_loss: 4.756473064422607	aux_loss: 0.638780951499939
11:16:13 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 4.671192646026611	recon_loss: 0.008634773083031178	bpp_loss: 4.8708038330078125	aux_loss: 0.21266162395477295
11:25:07 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 4.762574672698975	recon_loss: 0.008835011161863804	bpp_loss: 4.784372806549072	aux_loss: 0.2888195514678955
11:34:02 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 4.810539245605469	recon_loss: 0.008904802612960339	bpp_loss: 4.785187244415283	aux_loss: 0.3751302659511566
11:42:54 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 4.780025482177734	recon_loss: 0.008792093023657799	bpp_loss: 4.7844085693359375	aux_loss: 0.30936315655708313
11:43:03 INFO - main: {'TEST MSE': 0.008455044681606032, 'TEST BPP': 4.9783125, 'TEST loss': 4.545543732225895, 'TEST recon_loss': 0.00845504443626851, 'TEST bpp_loss': 4.884887128353119}
11:51:55 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 4.77237606048584	recon_loss: 0.00886418018490076	bpp_loss: 4.850407600402832	aux_loss: 0.10945107042789459
12:00:50 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 4.573283672332764	recon_loss: 0.008617708459496498	bpp_loss: 4.757214546203613	aux_loss: 0.241620734333992
12:09:44 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 4.524023056030273	recon_loss: 0.008485124446451664	bpp_loss: 4.8868794441223145	aux_loss: 0.4079713225364685
12:18:37 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 4.777389049530029	recon_loss: 0.008903787471354008	bpp_loss: 4.831404209136963	aux_loss: 0.45146065950393677
12:27:32 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 4.615702152252197	recon_loss: 0.008568753488361835	bpp_loss: 4.797651290893555	aux_loss: 0.2509831488132477
12:27:41 INFO - main: {'TEST MSE': 0.008709834779703583, 'TEST BPP': 4.932421875, 'TEST loss': 4.729814181178808, 'TEST recon_loss': 0.00870983450966014, 'TEST bpp_loss': 4.836933822631836}
12:36:33 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 4.5060343742370605	recon_loss: 0.008438427932560444	bpp_loss: 4.873215675354004	aux_loss: 0.4162886142730713
12:45:27 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 4.870903968811035	recon_loss: 0.008940871804952621	bpp_loss: 4.8465681076049805	aux_loss: 0.9326608180999756
12:54:20 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 4.695557594299316	recon_loss: 0.008696706034243107	bpp_loss: 4.80568790435791	aux_loss: 0.6032828092575073
13:03:15 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 4.724889278411865	recon_loss: 0.008656193502247334	bpp_loss: 4.895043849945068	aux_loss: 0.3237447738647461
13:12:07 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 4.6327667236328125	recon_loss: 0.008611832745373249	bpp_loss: 4.8389692306518555	aux_loss: 0.12652704119682312
13:12:15 INFO - main: {'TEST MSE': 0.00882579569439588, 'TEST BPP': 4.89653125, 'TEST loss': 4.788912880644202, 'TEST recon_loss': 0.008825795437791386, 'TEST bpp_loss': 4.800996976137161}
13:21:07 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 4.690894603729248	recon_loss: 0.008695121854543686	bpp_loss: 4.793696880340576	aux_loss: 0.10171543061733246
13:30:02 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 4.672238349914551	recon_loss: 0.008663957938551903	bpp_loss: 4.822935104370117	aux_loss: 0.10546720027923584
13:38:54 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 4.735402584075928	recon_loss: 0.008643983863294125	bpp_loss: 4.9105095863342285	aux_loss: 0.2328386902809143
13:47:47 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 4.766863822937012	recon_loss: 0.008781153708696365	bpp_loss: 4.810969829559326	aux_loss: 0.05791369080543518
