20:00:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:00:30 INFO - ddp_or_single_process: Create new exp folder!
20:00:30 INFO - ddp_or_single_process: seed : 100
20:00:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:00:31 INFO - main: Create experiment save folder
20:00:43 INFO - main: Training mode : scratch!
20:00:43 INFO - main: batch_size : 1024
20:00:43 INFO - main: num of gpus: 1
20:00:43 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=50, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:00:44 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 7877.14599609375	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9303894042969
20:01:45 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:01:45 INFO - ddp_or_single_process: find checkpoint...
20:01:45 INFO - ddp_or_single_process: no checkpoint is here
20:01:45 INFO - ddp_or_single_process: seed : 100
20:01:45 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:01:46 INFO - main: Create experiment save folder
20:01:57 INFO - main: Training mode : scratch!
20:01:57 INFO - main: batch_size : 1024
20:01:57 INFO - main: num of gpus: 1
20:01:57 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=50, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:01:59 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 7877.14599609375	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9303894042969
20:05:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:05:30 INFO - ddp_or_single_process: find checkpoint...
20:05:30 INFO - ddp_or_single_process: no checkpoint is here
20:05:30 INFO - ddp_or_single_process: seed : 100
20:05:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:05:37 INFO - main: Create experiment save folder
20:05:48 INFO - main: Training mode : scratch!
20:05:48 INFO - main: batch_size : 1024
20:05:48 INFO - main: num of gpus: 1
20:05:48 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=50, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda50_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:05:50 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 7877.14599609375	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9303894042969
20:05:58 INFO - main: {'TEST MSE': 124.07181401254415, 'TEST BPP': 5.56596875, 'TEST loss': 6210.449642700195, 'TEST recon_loss': 124.07181039237976, 'TEST bpp_loss': 5.4447771692276}
20:05:58 INFO - main: can not find prev_mse_best_model!
20:05:58 INFO - main: can not find prev_bpp_best_model!
20:05:58 INFO - main: can not find prev_bpp_best_model!
20:05:58 INFO - main: can not find recent_saved_model!
20:14:53 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 7.240963935852051	recon_loss: 0.02704721875488758	bpp_loss: 4.89617395401001	aux_loss: 315.0736389160156
20:23:49 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 5.582275390625	recon_loss: 0.02282538078725338	bpp_loss: 4.583633899688721	aux_loss: 294.13995361328125
20:32:48 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 4.829254150390625	recon_loss: 0.017131265252828598	bpp_loss: 4.57511043548584	aux_loss: 258.0323486328125
20:41:46 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 4.415644645690918	recon_loss: 0.018998125568032265	bpp_loss: 4.555816173553467	aux_loss: 220.325439453125
20:50:43 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 4.437860012054443	recon_loss: 0.021128013730049133	bpp_loss: 4.424891471862793	aux_loss: 193.1331024169922
20:50:50 INFO - main: {'TEST MSE': 0.019997267359252432, 'TEST BPP': 4.515546875, 'TEST loss': 4.341336265563965, 'TEST recon_loss': 0.019997266757301985, 'TEST bpp_loss': 4.444491585731506}
20:59:47 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 4.267483711242676	recon_loss: 0.019347811117768288	bpp_loss: 4.3522491455078125	aux_loss: 178.79522705078125
21:08:46 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 4.299942970275879	recon_loss: 0.01939341239631176	bpp_loss: 4.309197425842285	aux_loss: 168.580078125
21:17:42 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 4.09865665435791	recon_loss: 0.018164269626140594	bpp_loss: 4.307698726654053	aux_loss: 158.1094512939453
21:26:38 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 4.168971538543701	recon_loss: 0.01839952915906906	bpp_loss: 4.268302917480469	aux_loss: 146.99551391601562
21:35:37 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 4.050003528594971	recon_loss: 0.01814195327460766	bpp_loss: 4.285006046295166	aux_loss: 135.34524536132812
21:35:44 INFO - main: {'TEST MSE': 0.017673538798547758, 'TEST BPP': 4.342953125, 'TEST loss': 4.05178446778655, 'TEST recon_loss': 0.017673538285074755, 'TEST bpp_loss': 4.310819475531578}
21:44:42 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 3.9484267234802246	recon_loss: 0.017205750569701195	bpp_loss: 4.420332908630371	aux_loss: 124.98231506347656
21:53:39 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 4.260585308074951	recon_loss: 0.018383463844656944	bpp_loss: 4.198724269866943	aux_loss: 115.90904235839844
22:02:36 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 4.370033264160156	recon_loss: 0.018608558923006058	bpp_loss: 4.292862415313721	aux_loss: 107.70960998535156
22:11:35 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 4.135141372680664	recon_loss: 0.017808062955737114	bpp_loss: 4.294208526611328	aux_loss: 100.21601104736328
22:20:32 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 4.211717128753662	recon_loss: 0.018130837008357048	bpp_loss: 4.282228469848633	aux_loss: 92.78437805175781
22:20:40 INFO - main: {'TEST MSE': 0.0176088455783052, 'TEST BPP': 4.370171875, 'TEST loss': 4.090295120865107, 'TEST recon_loss': 0.017608845072682015, 'TEST bpp_loss': 4.332655361890793}
22:29:36 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 4.197540283203125	recon_loss: 0.01794263906776905	bpp_loss: 4.334718227386475	aux_loss: 86.20577239990234
22:38:35 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 4.301493167877197	recon_loss: 0.018345165997743607	bpp_loss: 4.267871856689453	aux_loss: 80.73968505859375
22:47:33 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 4.146543502807617	recon_loss: 0.01769855059683323	bpp_loss: 4.361712455749512	aux_loss: 75.10414123535156
22:56:30 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 3.994615316390991	recon_loss: 0.017215047031641006	bpp_loss: 4.3781352043151855	aux_loss: 69.75445556640625
23:05:29 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 4.062413692474365	recon_loss: 0.017343789339065552	bpp_loss: 4.3618927001953125	aux_loss: 64.55333709716797
23:05:37 INFO - main: {'TEST MSE': 0.017588437340709733, 'TEST BPP': 4.42846875, 'TEST loss': 4.133610480725765, 'TEST recon_loss': 0.017588436817750335, 'TEST bpp_loss': 4.379797306656838}
23:14:34 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 4.369960308074951	recon_loss: 0.018637066707015038	bpp_loss: 4.285442352294922	aux_loss: 60.12860107421875
23:23:31 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 4.247946262359619	recon_loss: 0.017987363040447235	bpp_loss: 4.269208908081055	aux_loss: 55.139549255371094
23:32:28 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 4.2256622314453125	recon_loss: 0.01816386729478836	bpp_loss: 4.27398681640625	aux_loss: 50.3717041015625
23:41:26 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 4.3607635498046875	recon_loss: 0.018612481653690338	bpp_loss: 4.249389171600342	aux_loss: 46.13026428222656
23:50:24 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 4.1441569328308105	recon_loss: 0.017509398981928825	bpp_loss: 4.368124961853027	aux_loss: 41.477378845214844
23:50:32 INFO - main: {'TEST MSE': 0.017302520334088634, 'TEST BPP': 4.433953125, 'TEST loss': 4.099436912149191, 'TEST recon_loss': 0.0173025198118703, 'TEST bpp_loss': 4.372135889291763}
23:59:28 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 4.225107192993164	recon_loss: 0.017796112224459648	bpp_loss: 4.263513088226318	aux_loss: 37.36943054199219
00:08:27 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 4.153953552246094	recon_loss: 0.017585409805178642	bpp_loss: 4.310932636260986	aux_loss: 32.72156524658203
00:17:24 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 4.151663780212402	recon_loss: 0.01747073419392109	bpp_loss: 4.335566997528076	aux_loss: 29.56846046447754
00:26:22 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 4.024682521820068	recon_loss: 0.016946209594607353	bpp_loss: 4.415268421173096	aux_loss: 26.09009552001953
00:35:20 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 4.006788730621338	recon_loss: 0.016811944544315338	bpp_loss: 4.4188456535339355	aux_loss: 22.96569061279297
00:35:28 INFO - main: {'TEST MSE': 0.01752339663264152, 'TEST BPP': 4.3936875, 'TEST loss': 4.15652108052373, 'TEST recon_loss': 0.017523396129356116, 'TEST bpp_loss': 4.325734755992889}
00:44:26 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 4.214125156402588	recon_loss: 0.017730996012687683	bpp_loss: 4.316701412200928	aux_loss: 18.87563133239746
00:53:23 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 4.155096530914307	recon_loss: 0.017523325979709625	bpp_loss: 4.3617329597473145	aux_loss: 15.91629409790039
01:02:20 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 3.991440773010254	recon_loss: 0.01694340445101261	bpp_loss: 4.400052070617676	aux_loss: 13.263288497924805
01:11:20 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 4.049560070037842	recon_loss: 0.01707541011273861	bpp_loss: 4.375629425048828	aux_loss: 10.288427352905273
01:20:17 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 4.1201605796813965	recon_loss: 0.01759140007197857	bpp_loss: 4.320371150970459	aux_loss: 7.827420711517334
01:20:25 INFO - main: {'TEST MSE': 0.017567886078826193, 'TEST BPP': 4.4303125, 'TEST loss': 4.184079038977623, 'TEST recon_loss': 0.017567885574389947, 'TEST bpp_loss': 4.356768270850181}
01:29:22 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 4.062409400939941	recon_loss: 0.017078666016459465	bpp_loss: 4.406887531280518	aux_loss: 5.706555366516113
01:38:21 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 4.245080947875977	recon_loss: 0.01791180670261383	bpp_loss: 4.275396347045898	aux_loss: 3.421963691711426
01:47:18 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 4.262886047363281	recon_loss: 0.017855988815426826	bpp_loss: 4.349925994873047	aux_loss: 2.3514981269836426
01:56:14 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 4.306707382202148	recon_loss: 0.018010197207331657	bpp_loss: 4.294376373291016	aux_loss: 1.6313328742980957
02:05:15 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 4.094403266906738	recon_loss: 0.017293622717261314	bpp_loss: 4.4182915687561035	aux_loss: 1.395988941192627
02:05:23 INFO - main: {'TEST MSE': 0.017957494281487917, 'TEST BPP': 4.41078125, 'TEST loss': 4.317579695880413, 'TEST recon_loss': 0.017957493762485684, 'TEST bpp_loss': 4.331931537032127}
02:14:21 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 4.151411056518555	recon_loss: 0.017430555075407028	bpp_loss: 4.400833606719971	aux_loss: 0.4119642376899719
02:23:18 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 4.086089134216309	recon_loss: 0.01709109917283058	bpp_loss: 4.389266490936279	aux_loss: 0.0760323703289032
02:32:15 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 4.155126571655273	recon_loss: 0.017452672123908997	bpp_loss: 4.345510482788086	aux_loss: 0.5287675857543945
02:41:14 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 4.103882789611816	recon_loss: 0.01731947623193264	bpp_loss: 4.380805492401123	aux_loss: 0.1229809820652008
02:50:10 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 4.136494159698486	recon_loss: 0.017424052581191063	bpp_loss: 4.310319423675537	aux_loss: 0.10264132916927338
02:50:18 INFO - main: {'TEST MSE': 0.017326311648761895, 'TEST BPP': 4.46153125, 'TEST loss': 4.130418752163648, 'TEST recon_loss': 0.017326311148237437, 'TEST bpp_loss': 4.377887102365494}
02:59:15 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 4.1945576667785645	recon_loss: 0.01769682951271534	bpp_loss: 4.301131248474121	aux_loss: 0.3358422517776489
03:08:13 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 4.026062488555908	recon_loss: 0.016792388632893562	bpp_loss: 4.463327884674072	aux_loss: 1.1852668523788452
03:17:10 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 4.154537200927734	recon_loss: 0.017220893874764442	bpp_loss: 4.358688831329346	aux_loss: 0.6476525068283081
03:26:07 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 4.102003574371338	recon_loss: 0.017222560942173004	bpp_loss: 4.338639736175537	aux_loss: 0.22855070233345032
03:35:05 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 3.9970531463623047	recon_loss: 0.016915882006287575	bpp_loss: 4.355310440063477	aux_loss: 0.2927757203578949
03:35:13 INFO - main: {'TEST MSE': 0.017502026487565398, 'TEST BPP': 4.477484375, 'TEST loss': 4.209578350365162, 'TEST recon_loss': 0.017502025960653554, 'TEST bpp_loss': 4.394744110107422}
03:44:10 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 4.158107757568359	recon_loss: 0.017470428720116615	bpp_loss: 4.318173408508301	aux_loss: 0.28870126605033875
03:53:07 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 4.171202659606934	recon_loss: 0.01744808256626129	bpp_loss: 4.36454963684082	aux_loss: 0.5166577696800232
04:02:03 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 4.0999064445495605	recon_loss: 0.0171083752065897	bpp_loss: 4.453452110290527	aux_loss: 0.5301374197006226
04:11:02 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 4.341251373291016	recon_loss: 0.018086515367031097	bpp_loss: 4.326259136199951	aux_loss: 0.1175534576177597
04:19:59 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 4.148773670196533	recon_loss: 0.017331738024950027	bpp_loss: 4.387694835662842	aux_loss: 0.6433753371238708
04:20:07 INFO - main: {'TEST MSE': 0.016904273490663826, 'TEST BPP': 4.5193125, 'TEST loss': 4.024241829365492, 'TEST recon_loss': 0.01690427295200061, 'TEST bpp_loss': 4.426750625252724}
04:29:03 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 4.2524003982543945	recon_loss: 0.017677901312708855	bpp_loss: 4.329040050506592	aux_loss: 0.4952407479286194
04:38:02 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 4.040882110595703	recon_loss: 0.01686220057308674	bpp_loss: 4.396039009094238	aux_loss: 0.31435394287109375
04:46:58 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 4.1604390144348145	recon_loss: 0.01750769466161728	bpp_loss: 4.32550048828125	aux_loss: 0.42340102791786194
04:55:55 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 4.147359371185303	recon_loss: 0.01751704514026642	bpp_loss: 4.299912929534912	aux_loss: 0.25146156549453735
05:04:54 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 4.233827114105225	recon_loss: 0.017527978867292404	bpp_loss: 4.370995044708252	aux_loss: 0.8155375719070435
05:05:02 INFO - main: {'TEST MSE': 0.01754626888788034, 'TEST BPP': 4.43478125, 'TEST loss': 4.214054826185107, 'TEST recon_loss': 0.017546268334030175, 'TEST bpp_loss': 4.348430554986}
05:13:58 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 4.170994758605957	recon_loss: 0.01746744103729725	bpp_loss: 4.370682239532471	aux_loss: 0.1725982278585434
05:22:55 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 4.207996368408203	recon_loss: 0.01768561080098152	bpp_loss: 4.2785797119140625	aux_loss: 0.24082428216934204
05:31:51 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 4.372655868530273	recon_loss: 0.01829693093895912	bpp_loss: 4.271085739135742	aux_loss: 0.12469097226858139
05:40:50 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 4.054404258728027	recon_loss: 0.016865871846675873	bpp_loss: 4.439578056335449	aux_loss: 0.07738947868347168
05:49:47 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 4.372164726257324	recon_loss: 0.018235690891742706	bpp_loss: 4.336508274078369	aux_loss: 0.4258229732513428
05:49:55 INFO - main: {'TEST MSE': 0.017228393222169465, 'TEST BPP': 4.509921875, 'TEST loss': 4.104791169941425, 'TEST recon_loss': 0.017228392719945987, 'TEST bpp_loss': 4.409488649725914}
05:58:52 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 3.96539306640625	recon_loss: 0.016672275960445404	bpp_loss: 4.437446594238281	aux_loss: 0.9855406284332275
06:07:51 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 4.169470310211182	recon_loss: 0.01749483495950699	bpp_loss: 4.354162693023682	aux_loss: 1.3965907096862793
06:16:47 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 4.336741924285889	recon_loss: 0.01817888393998146	bpp_loss: 4.263469219207764	aux_loss: 0.5318490862846375
06:25:44 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 4.093255043029785	recon_loss: 0.017049524933099747	bpp_loss: 4.389375686645508	aux_loss: 0.3100401759147644
06:34:43 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 4.116148471832275	recon_loss: 0.017278144136071205	bpp_loss: 4.342096328735352	aux_loss: 0.17455026507377625
06:34:51 INFO - main: {'TEST MSE': 0.016599622949238488, 'TEST BPP': 4.54625, 'TEST loss': 3.976661463201046, 'TEST recon_loss': 0.016599622470210306, 'TEST bpp_loss': 4.456981642961502}
06:43:48 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 4.200431823730469	recon_loss: 0.017592130228877068	bpp_loss: 4.314727306365967	aux_loss: 0.06309383362531662
06:52:45 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 4.432029724121094	recon_loss: 0.01842750981450081	bpp_loss: 4.3446807861328125	aux_loss: 0.5278751850128174
07:01:42 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 4.2694573402404785	recon_loss: 0.017792439088225365	bpp_loss: 4.331977844238281	aux_loss: 0.32104024291038513
07:10:41 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 4.084103584289551	recon_loss: 0.017093710601329803	bpp_loss: 4.447780132293701	aux_loss: 0.1780628263950348
07:19:38 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 4.030298709869385	recon_loss: 0.01691020093858242	bpp_loss: 4.33047342300415	aux_loss: 0.6177958250045776
07:19:46 INFO - main: {'TEST MSE': 0.016945317457341635, 'TEST BPP': 4.454859375, 'TEST loss': 4.048299895554781, 'TEST recon_loss': 0.016945316938799807, 'TEST bpp_loss': 4.366051469445228}
07:28:42 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 4.073101997375488	recon_loss: 0.01711893081665039	bpp_loss: 4.384894847869873	aux_loss: 0.44179385900497437
07:37:42 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 4.030208587646484	recon_loss: 0.016944775357842445	bpp_loss: 4.3777689933776855	aux_loss: 0.09057823568582535
07:46:39 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 4.036418914794922	recon_loss: 0.01696131005883217	bpp_loss: 4.411922931671143	aux_loss: 0.15843237936496735
07:55:35 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 4.138597011566162	recon_loss: 0.01731584221124649	bpp_loss: 4.349992752075195	aux_loss: 0.36261260509490967
08:04:34 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 4.361695289611816	recon_loss: 0.018105890601873398	bpp_loss: 4.331895351409912	aux_loss: 0.23610186576843262
08:04:42 INFO - main: {'TEST MSE': 0.016615966877248544, 'TEST BPP': 4.521625, 'TEST loss': 3.972166194871068, 'TEST recon_loss': 0.01661596636089962, 'TEST bpp_loss': 4.431536842346191}
08:13:39 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 4.248292922973633	recon_loss: 0.017690902575850487	bpp_loss: 4.352312088012695	aux_loss: 0.39251384139060974
08:22:35 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 4.236571788787842	recon_loss: 0.01767914369702339	bpp_loss: 4.3207807540893555	aux_loss: 0.27638208866119385
08:31:32 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 4.1678595542907715	recon_loss: 0.017363063991069794	bpp_loss: 4.374382019042969	aux_loss: 0.11441048234701157
08:40:31 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 4.148325443267822	recon_loss: 0.017329363152384758	bpp_loss: 4.352168560028076	aux_loss: 0.3279886245727539
08:49:27 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 4.042695045471191	recon_loss: 0.017068054527044296	bpp_loss: 4.374557018280029	aux_loss: 0.2481028437614441
08:49:35 INFO - main: {'TEST MSE': 0.01785206869551246, 'TEST BPP': 4.444859375, 'TEST loss': 4.295107553631067, 'TEST recon_loss': 0.01785206814853882, 'TEST bpp_loss': 4.357436358571053}
08:58:32 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 4.125583171844482	recon_loss: 0.017323492094874382	bpp_loss: 4.31047248840332	aux_loss: 0.11224439740180969
09:07:31 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 3.988298177719116	recon_loss: 0.01675623282790184	bpp_loss: 4.409148693084717	aux_loss: 0.1267981231212616
09:16:28 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 4.138775825500488	recon_loss: 0.017260165885090828	bpp_loss: 4.352484703063965	aux_loss: 0.3295067250728607
09:25:25 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 4.272014141082764	recon_loss: 0.017814870923757553	bpp_loss: 4.297868251800537	aux_loss: 0.14005878567695618
09:34:24 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 4.008571624755859	recon_loss: 0.016858091577887535	bpp_loss: 4.367529392242432	aux_loss: 0.07523396611213684
09:34:32 INFO - main: {'TEST MSE': 0.017285220680976727, 'TEST BPP': 4.469515625, 'TEST loss': 4.158552943080664, 'TEST recon_loss': 0.017285220147823566, 'TEST bpp_loss': 4.3768716937303545}
09:43:28 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 4.405825614929199	recon_loss: 0.01839440129697323	bpp_loss: 4.2245893478393555	aux_loss: 0.8399648666381836
09:52:25 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 4.133746147155762	recon_loss: 0.01734502799808979	bpp_loss: 4.352850437164307	aux_loss: 0.20441414415836334
10:01:22 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 4.188835620880127	recon_loss: 0.017542049288749695	bpp_loss: 4.304927349090576	aux_loss: 0.23390714824199677
10:10:21 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 4.044215202331543	recon_loss: 0.01679670438170433	bpp_loss: 4.484694004058838	aux_loss: 0.08158274739980698
10:19:18 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 4.200039863586426	recon_loss: 0.017513956874608994	bpp_loss: 4.329169750213623	aux_loss: 0.0917416512966156
10:19:26 INFO - main: {'TEST MSE': 0.016145956127538746, 'TEST BPP': 4.579546875, 'TEST loss': 3.845633615255356, 'TEST recon_loss': 0.016145955637752195, 'TEST bpp_loss': 4.48228601205349}
10:28:23 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 4.06567907333374	recon_loss: 0.01696777157485485	bpp_loss: 4.369068145751953	aux_loss: 0.07708150893449783
10:37:21 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 4.433224201202393	recon_loss: 0.018440302461385727	bpp_loss: 4.240077495574951	aux_loss: 0.2829616665840149
10:46:18 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 4.0631608963012695	recon_loss: 0.017017723992466927	bpp_loss: 4.4072489738464355	aux_loss: 0.49727919697761536
10:55:15 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 4.056919097900391	recon_loss: 0.016953419893980026	bpp_loss: 4.394019603729248	aux_loss: 0.3586322069168091
11:04:13 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 4.03087043762207	recon_loss: 0.016782864928245544	bpp_loss: 4.385050296783447	aux_loss: 0.4355747401714325
11:04:21 INFO - main: {'TEST MSE': 0.01613467985171658, 'TEST BPP': 4.597828125, 'TEST loss': 3.8910106167942287, 'TEST recon_loss': 0.01613467938906979, 'TEST bpp_loss': 4.487858036518097}
11:13:17 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 4.433621406555176	recon_loss: 0.018299631774425507	bpp_loss: 4.304135799407959	aux_loss: 0.6571731567382812
11:22:14 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 4.0769829750061035	recon_loss: 0.016926728188991547	bpp_loss: 4.428560256958008	aux_loss: 0.1005164384841919
11:31:11 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 4.154993057250977	recon_loss: 0.017445245757699013	bpp_loss: 4.331938743591309	aux_loss: 0.4717755913734436
11:40:09 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 4.202934265136719	recon_loss: 0.017590761184692383	bpp_loss: 4.336924076080322	aux_loss: 0.24634361267089844
11:49:06 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 4.1797709465026855	recon_loss: 0.01753128692507744	bpp_loss: 4.325135707855225	aux_loss: 0.3066706359386444
11:49:14 INFO - main: {'TEST MSE': 0.016605025072782012, 'TEST BPP': 4.5168125, 'TEST loss': 3.966893434524536, 'TEST recon_loss': 0.016605024574440904, 'TEST bpp_loss': 4.427513044953346}
11:58:11 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 4.158194541931152	recon_loss: 0.01733045093715191	bpp_loss: 4.399421215057373	aux_loss: 0.08345018327236176
12:07:10 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 3.9926702976226807	recon_loss: 0.01691354811191559	bpp_loss: 4.306764602661133	aux_loss: 0.26022449135780334
12:16:07 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 3.9436073303222656	recon_loss: 0.01657235622406006	bpp_loss: 4.438310623168945	aux_loss: 0.27494972944259644
12:25:04 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 4.1573567390441895	recon_loss: 0.01728641800582409	bpp_loss: 4.388813495635986	aux_loss: 0.348701536655426
12:34:03 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 4.027097702026367	recon_loss: 0.016915546730160713	bpp_loss: 4.338979244232178	aux_loss: 0.3463548719882965
12:34:11 INFO - main: {'TEST MSE': 0.017215151612702297, 'TEST BPP': 4.479203125, 'TEST loss': 4.1303363471031185, 'TEST recon_loss': 0.01721515108598396, 'TEST bpp_loss': 4.378187887907028}
12:43:07 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 3.9388012886047363	recon_loss: 0.016654957085847855	bpp_loss: 4.419558048248291	aux_loss: 0.36214298009872437
12:52:04 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 4.249026298522949	recon_loss: 0.01764984056353569	bpp_loss: 4.386749744415283	aux_loss: 0.7026256322860718
13:01:01 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 4.10233211517334	recon_loss: 0.017241111025214195	bpp_loss: 4.3506011962890625	aux_loss: 0.5542253851890564
13:10:00 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 4.12578010559082	recon_loss: 0.017132453620433807	bpp_loss: 4.4381537437438965	aux_loss: 0.32169967889785767
13:18:57 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 4.045747756958008	recon_loss: 0.016907762736082077	bpp_loss: 4.393577575683594	aux_loss: 0.1317363828420639
13:19:05 INFO - main: {'TEST MSE': 0.017423820319654122, 'TEST BPP': 4.453765625, 'TEST loss': 4.184334103867411, 'TEST recon_loss': 0.01742381977767218, 'TEST bpp_loss': 4.355548199892044}
13:28:02 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 4.093226432800293	recon_loss: 0.01714046485722065	bpp_loss: 4.344599723815918	aux_loss: 0.1744634509086609
13:37:00 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 4.078580379486084	recon_loss: 0.017052525654435158	bpp_loss: 4.379955768585205	aux_loss: 0.13135842978954315
13:45:57 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 4.13598108291626	recon_loss: 0.01714680902659893	bpp_loss: 4.461472511291504	aux_loss: 0.16989672183990479
