20:00:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:00:30 INFO - ddp_or_single_process: Create new exp folder!
20:00:30 INFO - ddp_or_single_process: seed : 100
20:00:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:00:31 INFO - main: Create experiment save folder
20:00:43 INFO - main: Training mode : scratch!
20:00:43 INFO - main: batch_size : 1024
20:00:43 INFO - main: num of gpus: 1
20:00:43 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=200, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:00:45 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 31488.5625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9320373535156
20:01:44 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:01:44 INFO - ddp_or_single_process: find checkpoint...
20:01:44 INFO - ddp_or_single_process: no checkpoint is here
20:01:44 INFO - ddp_or_single_process: seed : 100
20:01:44 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:01:46 INFO - main: Create experiment save folder
20:01:57 INFO - main: Training mode : scratch!
20:01:57 INFO - main: batch_size : 1024
20:01:57 INFO - main: num of gpus: 1
20:01:57 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=200, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:01:59 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 31488.5625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9320373535156
20:05:30 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
20:05:30 INFO - ddp_or_single_process: find checkpoint...
20:05:30 INFO - ddp_or_single_process: no checkpoint is here
20:05:30 INFO - ddp_or_single_process: seed : 100
20:05:30 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
20:05:36 INFO - main: Create experiment save folder
20:05:47 INFO - main: Training mode : scratch!
20:05:47 INFO - main: batch_size : 1024
20:05:47 INFO - main: num of gpus: 1
20:05:47 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=200, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda200_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
20:05:49 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 31488.5625	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9320373535156
20:05:57 INFO - main: {'TEST MSE': 124.07184504892686, 'TEST BPP': 5.565765625, 'TEST loss': 24821.22746923828, 'TEST recon_loss': 124.07184134483337, 'TEST bpp_loss': 5.444886408805847}
20:05:57 INFO - main: can not find prev_mse_best_model!
20:05:57 INFO - main: can not find prev_bpp_best_model!
20:05:57 INFO - main: can not find prev_bpp_best_model!
20:05:57 INFO - main: can not find recent_saved_model!
20:14:51 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 11.13509464263916	recon_loss: 0.025180233642458916	bpp_loss: 5.0229105949401855	aux_loss: 316.4118957519531
20:23:47 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 8.266948699951172	recon_loss: 0.015926610678434372	bpp_loss: 4.941647052764893	aux_loss: 303.8562927246094
20:32:45 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 7.616678237915039	recon_loss: 0.01331869326531887	bpp_loss: 4.88646936416626	aux_loss: 287.0937805175781
20:41:44 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 6.716433525085449	recon_loss: 0.011186648160219193	bpp_loss: 5.007348537445068	aux_loss: 263.1075134277344
20:50:41 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 6.4045023918151855	recon_loss: 0.00978828500956297	bpp_loss: 5.094635963439941	aux_loss: 243.3214569091797
20:50:49 INFO - main: {'TEST MSE': 0.00922759226736899, 'TEST BPP': 5.35071875, 'TEST loss': 6.252496230483055, 'TEST recon_loss': 0.009227591983275487, 'TEST bpp_loss': 5.1152919385433195}
20:59:46 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 6.137456893920898	recon_loss: 0.008701019920408726	bpp_loss: 5.16273832321167	aux_loss: 230.55392456054688
21:08:45 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 6.024186134338379	recon_loss: 0.007852175273001194	bpp_loss: 5.138835906982422	aux_loss: 221.5446014404297
21:17:42 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 5.525954246520996	recon_loss: 0.006360641680657864	bpp_loss: 5.083095073699951	aux_loss: 212.51954650878906
21:26:39 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 5.759208679199219	recon_loss: 0.0070357550866901875	bpp_loss: 5.058306694030762	aux_loss: 202.62911987304688
21:35:38 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 5.5679545402526855	recon_loss: 0.006699088495224714	bpp_loss: 5.0223164558410645	aux_loss: 193.29714965820312
21:35:46 INFO - main: {'TEST MSE': 0.0066662055981819655, 'TEST BPP': 5.104484375, 'TEST loss': 5.566892114162445, 'TEST recon_loss': 0.0066662054006010295, 'TEST bpp_loss': 5.043626121520996}
21:44:43 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 5.367542743682861	recon_loss: 0.0061743734404444695	bpp_loss: 5.134778022766113	aux_loss: 184.8717041015625
21:53:41 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 5.716122150421143	recon_loss: 0.0060174125246703625	bpp_loss: 4.991694450378418	aux_loss: 178.63259887695312
22:02:38 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 5.904089450836182	recon_loss: 0.006348309572786093	bpp_loss: 5.039994716644287	aux_loss: 172.89306640625
22:11:37 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 5.5459699630737305	recon_loss: 0.005863210652023554	bpp_loss: 5.04451847076416	aux_loss: 167.57354736328125
22:20:35 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 5.652551174163818	recon_loss: 0.005924209952354431	bpp_loss: 5.0477705001831055	aux_loss: 162.44540405273438
22:20:43 INFO - main: {'TEST MSE': 0.005650942138303941, 'TEST BPP': 5.131390625, 'TEST loss': 5.45551404261589, 'TEST recon_loss': 0.005650941960862838, 'TEST bpp_loss': 5.091858938694}
22:29:40 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 5.555853843688965	recon_loss: 0.005573478527367115	bpp_loss: 5.091682434082031	aux_loss: 157.51580810546875
22:38:39 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 5.727572441101074	recon_loss: 0.005761224310845137	bpp_loss: 5.053133010864258	aux_loss: 153.61270141601562
22:47:36 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 5.534274101257324	recon_loss: 0.0056320358999073505	bpp_loss: 5.1273016929626465	aux_loss: 149.74058532714844
22:56:33 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 5.262564659118652	recon_loss: 0.005147176794707775	bpp_loss: 5.125733852386475	aux_loss: 145.59860229492188
23:05:32 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 5.333501815795898	recon_loss: 0.005140446126461029	bpp_loss: 5.144885063171387	aux_loss: 141.63771057128906
23:05:40 INFO - main: {'TEST MSE': 0.005426391343368434, 'TEST BPP': 5.196140625, 'TEST loss': 5.496012923032046, 'TEST recon_loss': 0.005426391184097156, 'TEST bpp_loss': 5.160503319501877}
23:14:37 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 5.771154403686523	recon_loss: 0.0055533237755298615	bpp_loss: 5.062954425811768	aux_loss: 138.01390075683594
23:23:34 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 5.584134578704834	recon_loss: 0.005207905545830727	bpp_loss: 5.0460920333862305	aux_loss: 134.93768310546875
23:32:31 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 5.537924289703369	recon_loss: 0.005169260315597057	bpp_loss: 5.0570387840271	aux_loss: 130.9676513671875
23:41:30 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 5.750894546508789	recon_loss: 0.005415376741439104	bpp_loss: 5.051109790802002	aux_loss: 127.90496826171875
23:50:28 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 5.477786540985107	recon_loss: 0.005258754827082157	bpp_loss: 5.127481937408447	aux_loss: 124.34256744384766
23:50:36 INFO - main: {'TEST MSE': 0.005067924779748422, 'TEST BPP': 5.174671875, 'TEST loss': 5.3883417628407475, 'TEST recon_loss': 0.0050679246358340604, 'TEST bpp_loss': 5.137262215852737}
23:59:34 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 5.519815921783447	recon_loss: 0.005003543104976416	bpp_loss: 5.059054851531982	aux_loss: 120.98705291748047
00:08:33 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 5.435802936553955	recon_loss: 0.004938045982271433	bpp_loss: 5.060568809509277	aux_loss: 117.63111877441406
00:17:31 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 5.425926208496094	recon_loss: 0.0049524069763720036	bpp_loss: 5.10029935836792	aux_loss: 114.63362121582031
00:26:28 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 5.2553629875183105	recon_loss: 0.004803037736564875	bpp_loss: 5.1637396812438965	aux_loss: 111.48323822021484
00:35:27 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 5.244170188903809	recon_loss: 0.0048312535509467125	bpp_loss: 5.169312000274658	aux_loss: 108.56317901611328
00:35:35 INFO - main: {'TEST MSE': 0.004996182218836082, 'TEST BPP': 5.132453125, 'TEST loss': 5.4415079046189785, 'TEST recon_loss': 0.0049961820667376745, 'TEST bpp_loss': 5.091098088741303}
00:44:33 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 5.486542224884033	recon_loss: 0.004850930534303188	bpp_loss: 5.086215496063232	aux_loss: 105.26158905029297
00:53:30 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 5.44267463684082	recon_loss: 0.0050060926005244255	bpp_loss: 5.132531642913818	aux_loss: 101.98629760742188
01:02:28 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 5.270666599273682	recon_loss: 0.005023190286010504	bpp_loss: 5.168571949005127	aux_loss: 99.61619567871094
01:11:27 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 5.2631916999816895	recon_loss: 0.004676729906350374	bpp_loss: 5.139183044433594	aux_loss: 96.50079345703125
01:20:25 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 5.373091220855713	recon_loss: 0.004841880407184362	bpp_loss: 5.091980934143066	aux_loss: 94.0
01:20:33 INFO - main: {'TEST MSE': 0.004824580328918233, 'TEST BPP': 5.164484375, 'TEST loss': 5.444199351072311, 'TEST recon_loss': 0.004824580178712495, 'TEST bpp_loss': 5.119871535778046}
01:29:30 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 5.331875801086426	recon_loss: 0.004879303742200136	bpp_loss: 5.1568074226379395	aux_loss: 90.96434020996094
01:38:30 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 5.513786792755127	recon_loss: 0.004779333248734474	bpp_loss: 5.053950786590576	aux_loss: 87.73129272460938
01:47:27 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 5.589118480682373	recon_loss: 0.005059234332293272	bpp_loss: 5.126203536987305	aux_loss: 85.0711669921875
01:56:24 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 5.622674465179443	recon_loss: 0.00495990552008152	bpp_loss: 5.092807769775391	aux_loss: 82.34822082519531
02:05:25 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 5.329372406005859	recon_loss: 0.004670668859034777	bpp_loss: 5.214969158172607	aux_loss: 80.36918640136719
02:05:33 INFO - main: {'TEST MSE': 0.004840596995284899, 'TEST BPP': 5.188296875, 'TEST loss': 5.608542227417231, 'TEST recon_loss': 0.004840596856724005, 'TEST bpp_loss': 5.138079411745071}
02:14:31 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 5.402203559875488	recon_loss: 0.004743685480207205	bpp_loss: 5.1886138916015625	aux_loss: 77.52964782714844
02:23:29 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 5.2988505363464355	recon_loss: 0.004599131643772125	bpp_loss: 5.1776885986328125	aux_loss: 74.77335357666016
02:32:26 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 5.467068672180176	recon_loss: 0.005045845173299313	bpp_loss: 5.135267734527588	aux_loss: 71.77412414550781
02:41:26 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 5.31973934173584	recon_loss: 0.004613395780324936	bpp_loss: 5.1705780029296875	aux_loss: 69.068359375
02:50:23 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 5.366646766662598	recon_loss: 0.004645118024200201	bpp_loss: 5.107232570648193	aux_loss: 66.43040466308594
02:50:31 INFO - main: {'TEST MSE': 0.004864508723879956, 'TEST BPP': 5.230421875, 'TEST loss': 5.403003744810819, 'TEST recon_loss': 0.004864508578029927, 'TEST bpp_loss': 5.172481338977814}
02:59:29 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 5.448619365692139	recon_loss: 0.0048105111345648766	bpp_loss: 5.102647304534912	aux_loss: 64.17534637451172
03:08:28 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 5.224664211273193	recon_loss: 0.004531084559857845	bpp_loss: 5.253239154815674	aux_loss: 62.194496154785156
03:17:26 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 5.434783935546875	recon_loss: 0.004849840421229601	bpp_loss: 5.158185958862305	aux_loss: 59.2271842956543
03:26:24 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 5.318504333496094	recon_loss: 0.00460401363670826	bpp_loss: 5.13040018081665	aux_loss: 55.60823059082031
03:35:23 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 5.19394063949585	recon_loss: 0.0045999265275895596	bpp_loss: 5.142608165740967	aux_loss: 52.92656326293945
03:35:31 INFO - main: {'TEST MSE': 0.004751050958003614, 'TEST BPP': 5.2443125, 'TEST loss': 5.481002965152264, 'TEST recon_loss': 0.004751050814229529, 'TEST bpp_loss': 5.177202150583267}
03:44:29 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 5.399002552032471	recon_loss: 0.004707091487944126	bpp_loss: 5.119162082672119	aux_loss: 50.996986389160156
03:53:27 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 5.421346187591553	recon_loss: 0.004713745787739754	bpp_loss: 5.154577732086182	aux_loss: 47.22483444213867
04:02:24 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 5.350568771362305	recon_loss: 0.004747217986732721	bpp_loss: 5.2368597984313965	aux_loss: 45.193031311035156
04:11:24 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 5.651424884796143	recon_loss: 0.00491313124075532	bpp_loss: 5.121726036071777	aux_loss: 41.8923454284668
04:20:21 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 5.392190933227539	recon_loss: 0.0046709515154361725	bpp_loss: 5.1761322021484375	aux_loss: 39.82514572143555
04:20:29 INFO - main: {'TEST MSE': 0.004654822313770187, 'TEST BPP': 5.285109375, 'TEST loss': 5.243439376860857, 'TEST recon_loss': 0.004654822176555172, 'TEST bpp_loss': 5.213993938446045}
04:29:27 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 5.533702850341797	recon_loss: 0.0048331040889024734	bpp_loss: 5.1187944412231445	aux_loss: 36.77718734741211
04:38:26 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 5.228458404541016	recon_loss: 0.004506268072873354	bpp_loss: 5.18984317779541	aux_loss: 34.480560302734375
04:47:24 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 5.385951519012451	recon_loss: 0.004603453446179628	bpp_loss: 5.114752292633057	aux_loss: 31.715957641601562
04:56:22 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 5.415088176727295	recon_loss: 0.004774169996380806	bpp_loss: 5.099996089935303	aux_loss: 28.983308792114258
05:05:21 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 5.519684791564941	recon_loss: 0.0048108408227562904	bpp_loss: 5.167420387268066	aux_loss: 24.84311866760254
05:05:29 INFO - main: {'TEST MSE': 0.004776808871949232, 'TEST BPP': 5.231125, 'TEST loss': 5.478932464659214, 'TEST recon_loss': 0.004776808724564034, 'TEST bpp_loss': 5.151250534296036}
05:14:27 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 5.424158096313477	recon_loss: 0.004677407443523407	bpp_loss: 5.162354469299316	aux_loss: 22.816043853759766
05:23:24 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 5.439769268035889	recon_loss: 0.004614498000591993	bpp_loss: 5.0873494148254395	aux_loss: 20.552799224853516
05:32:22 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 5.674398422241211	recon_loss: 0.004884158261120319	bpp_loss: 5.078313827514648	aux_loss: 18.303768157958984
05:41:21 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 5.277292728424072	recon_loss: 0.0046224347315728664	bpp_loss: 5.222872734069824	aux_loss: 16.10785675048828
05:50:19 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 5.687991619110107	recon_loss: 0.004879153333604336	bpp_loss: 5.1426005363464355	aux_loss: 13.495560646057129
05:50:27 INFO - main: {'TEST MSE': 0.0046764340729681724, 'TEST BPP': 5.290328125, 'TEST loss': 5.342219598680734, 'TEST recon_loss': 0.004676433934422675, 'TEST bpp_loss': 5.201305295467376}
05:59:23 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 5.1246867179870605	recon_loss: 0.004396314267069101	bpp_loss: 5.220882892608643	aux_loss: 12.468408584594727
06:08:23 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 5.414087295532227	recon_loss: 0.004683555103838444	bpp_loss: 5.154385566711426	aux_loss: 11.271132469177246
06:17:20 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 5.645238876342773	recon_loss: 0.004864445887506008	bpp_loss: 5.086373329162598	aux_loss: 7.980307579040527
06:26:18 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 5.325700283050537	recon_loss: 0.004693985916674137	bpp_loss: 5.170302867889404	aux_loss: 7.039515018463135
06:35:17 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 5.344385623931885	recon_loss: 0.004652141593396664	bpp_loss: 5.144073963165283	aux_loss: 5.308484077453613
06:35:25 INFO - main: {'TEST MSE': 0.0044566981882921495, 'TEST BPP': 5.336109375, 'TEST loss': 5.156180711299181, 'TEST recon_loss': 0.0044566980530362345, 'TEST bpp_loss': 5.243123816728592}
06:44:22 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 5.464258193969727	recon_loss: 0.004759840667247772	bpp_loss: 5.122818470001221	aux_loss: 4.172429084777832
06:53:20 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 5.761188507080078	recon_loss: 0.004892775323241949	bpp_loss: 5.141144752502441	aux_loss: 3.777635335922241
07:02:18 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 5.548529624938965	recon_loss: 0.004782382398843765	bpp_loss: 5.132694721221924	aux_loss: 2.74293851852417
07:11:17 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 5.3126959800720215	recon_loss: 0.0046717217192053795	bpp_loss: 5.237714767456055	aux_loss: 1.865265130996704
07:20:14 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 5.225735664367676	recon_loss: 0.004564243834465742	bpp_loss: 5.1432719230651855	aux_loss: 2.068370819091797
07:20:22 INFO - main: {'TEST MSE': 0.004450712049607298, 'TEST BPP': 5.266546875, 'TEST loss': 5.220314766585827, 'TEST recon_loss': 0.004450711920158937, 'TEST bpp_loss': 5.17506232380867}
07:29:20 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 5.297363758087158	recon_loss: 0.004616163671016693	bpp_loss: 5.170740604400635	aux_loss: 1.0976935625076294
07:38:19 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 5.232709884643555	recon_loss: 0.004561420530080795	bpp_loss: 5.177639961242676	aux_loss: 0.4738047420978546
07:47:17 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 5.251774787902832	recon_loss: 0.004672293085604906	bpp_loss: 5.193975925445557	aux_loss: 0.2958771586418152
07:56:14 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 5.374109745025635	recon_loss: 0.004659485537558794	bpp_loss: 5.148804187774658	aux_loss: 0.2446955293416977
08:05:14 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 5.670551776885986	recon_loss: 0.004835651721805334	bpp_loss: 5.141014575958252	aux_loss: 0.21454814076423645
08:05:22 INFO - main: {'TEST MSE': 0.00443653617285279, 'TEST BPP': 5.325921875, 'TEST loss': 5.1431973198652265, 'TEST recon_loss': 0.0044365360438823696, 'TEST bpp_loss': 5.2312026951313015}
08:14:19 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 5.498156547546387	recon_loss: 0.004683251027017832	bpp_loss: 5.151082515716553	aux_loss: 0.6143590211868286
08:23:17 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 5.480104446411133	recon_loss: 0.004635126795619726	bpp_loss: 5.1257734298706055	aux_loss: 0.15764707326889038
08:32:15 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 5.396209239959717	recon_loss: 0.004577159881591797	bpp_loss: 5.183405876159668	aux_loss: 0.38800230622291565
08:41:14 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 5.384161949157715	recon_loss: 0.0046479785814881325	bpp_loss: 5.159315586090088	aux_loss: 0.21506798267364502
08:50:11 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 5.247225761413574	recon_loss: 0.004576724022626877	bpp_loss: 5.167647361755371	aux_loss: 0.43512699007987976
08:50:20 INFO - main: {'TEST MSE': 0.004769853660421293, 'TEST BPP': 5.241484375, 'TEST loss': 5.579813409298659, 'TEST recon_loss': 0.004769853516554576, 'TEST bpp_loss': 5.150369781017304}
08:59:17 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 5.34096097946167	recon_loss: 0.00458722747862339	bpp_loss: 5.116649627685547	aux_loss: 0.29383525252342224
09:08:16 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 5.161266326904297	recon_loss: 0.0044566430151462555	bpp_loss: 5.201267719268799	aux_loss: 0.16132178902626038
09:17:14 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 5.335209846496582	recon_loss: 0.004526121076196432	bpp_loss: 5.158679485321045	aux_loss: 0.9042983651161194
09:26:12 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 5.53271484375	recon_loss: 0.004645343869924545	bpp_loss: 5.1139984130859375	aux_loss: 0.423423707485199
09:35:11 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 5.196402549743652	recon_loss: 0.004496769048273563	bpp_loss: 5.173299789428711	aux_loss: 0.14263883233070374
09:35:19 INFO - main: {'TEST MSE': 0.004546286960114024, 'TEST BPP': 5.27859375, 'TEST loss': 5.376410591244698, 'TEST recon_loss': 0.004546286817771033, 'TEST bpp_loss': 5.18157825922966}
09:44:16 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 5.698200702667236	recon_loss: 0.004765298217535019	bpp_loss: 5.047883987426758	aux_loss: 0.6755421757698059
09:53:14 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 5.346423625946045	recon_loss: 0.004588749725371599	bpp_loss: 5.16296911239624	aux_loss: 0.22878900170326233
10:02:11 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 5.441487789154053	recon_loss: 0.004691330716013908	bpp_loss: 5.121095657348633	aux_loss: 0.3411513566970825
10:11:10 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 5.230847358703613	recon_loss: 0.0044637396931648254	bpp_loss: 5.2741618156433105	aux_loss: 0.2237531840801239
10:20:07 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 5.441073894500732	recon_loss: 0.004647466819733381	bpp_loss: 5.130317687988281	aux_loss: 0.18656079471111298
10:20:16 INFO - main: {'TEST MSE': 0.004369901552062485, 'TEST BPP': 5.36578125, 'TEST loss': 4.984894661277533, 'TEST recon_loss': 0.004369901424695854, 'TEST bpp_loss': 5.263093123912811}
10:29:12 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 5.249671936035156	recon_loss: 0.00445209676399827	bpp_loss: 5.164412975311279	aux_loss: 0.21135511994361877
10:38:11 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 5.7470011711120605	recon_loss: 0.004829383920878172	bpp_loss: 5.055360317230225	aux_loss: 0.22901049256324768
10:47:09 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 5.32589864730835	recon_loss: 0.0048219566233456135	bpp_loss: 5.198633670806885	aux_loss: 0.775337278842926
10:56:06 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 5.249738693237305	recon_loss: 0.004510089289397001	bpp_loss: 5.185910224914551	aux_loss: 0.2193211317062378
11:05:05 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 5.231891632080078	recon_loss: 0.004543397109955549	bpp_loss: 5.171950817108154	aux_loss: 0.34929966926574707
11:05:13 INFO - main: {'TEST MSE': 0.004373178807153402, 'TEST BPP': 5.36959375, 'TEST loss': 5.045355442047119, 'TEST recon_loss': 0.004373178673151415, 'TEST bpp_loss': 5.268689738035202}
11:14:11 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 5.752557277679443	recon_loss: 0.0048330118879675865	bpp_loss: 5.1152544021606445	aux_loss: 0.6081079244613647
11:23:08 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 5.2720794677734375	recon_loss: 0.004478498362004757	bpp_loss: 5.23032808303833	aux_loss: 0.059929706156253815
11:32:05 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 5.384392738342285	recon_loss: 0.004588023293763399	bpp_loss: 5.140707492828369	aux_loss: 0.4178610146045685
11:41:05 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 5.437710285186768	recon_loss: 0.004654268734157085	bpp_loss: 5.1516242027282715	aux_loss: 0.36239194869995117
11:50:02 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 5.406409740447998	recon_loss: 0.004591054283082485	bpp_loss: 5.1399970054626465	aux_loss: 0.40424901247024536
11:50:10 INFO - main: {'TEST MSE': 0.004419395590714467, 'TEST BPP': 5.334578125, 'TEST loss': 5.138684464156627, 'TEST recon_loss': 0.004419395450371667, 'TEST bpp_loss': 5.236911579608917}
11:59:07 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 5.381528854370117	recon_loss: 0.004557195119559765	bpp_loss: 5.198126792907715	aux_loss: 0.2193596512079239
12:08:06 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 5.17771577835083	recon_loss: 0.004556184634566307	bpp_loss: 5.111678123474121	aux_loss: 0.37256693840026855
12:17:03 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 5.096731662750244	recon_loss: 0.004337908234447241	bpp_loss: 5.227076053619385	aux_loss: 0.13734251260757446
12:26:01 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 5.389418125152588	recon_loss: 0.004575091879814863	bpp_loss: 5.178030490875244	aux_loss: 0.5983006358146667
12:35:00 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 5.2354736328125	recon_loss: 0.00454332260414958	bpp_loss: 5.152027130126953	aux_loss: 0.4015597105026245
12:35:08 INFO - main: {'TEST MSE': 0.004623978109627869, 'TEST BPP': 5.2930625, 'TEST loss': 5.363150805979967, 'TEST recon_loss': 0.004623977979339543, 'TEST bpp_loss': 5.192278362989426}
12:44:05 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 5.0990214347839355	recon_loss: 0.0044532460160553455	bpp_loss: 5.22036075592041	aux_loss: 0.5132899284362793
12:53:03 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 5.5189971923828125	recon_loss: 0.004712974186986685	bpp_loss: 5.1896233558654785	aux_loss: 0.7182475328445435
13:02:00 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 5.309844970703125	recon_loss: 0.00453994981944561	bpp_loss: 5.146555423736572	aux_loss: 0.6449355483055115
13:10:59 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 5.3481125831604	recon_loss: 0.004548988770693541	bpp_loss: 5.225998878479004	aux_loss: 0.3015260696411133
13:19:56 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 5.242507457733154	recon_loss: 0.004538567271083593	bpp_loss: 5.191824436187744	aux_loss: 0.12332186847925186
13:20:04 INFO - main: {'TEST MSE': 0.004626906093236501, 'TEST BPP': 5.25559375, 'TEST loss': 5.417951841980219, 'TEST recon_loss': 0.004626905956538394, 'TEST bpp_loss': 5.155698948144913}
13:29:01 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 5.29467248916626	recon_loss: 0.004484194330871105	bpp_loss: 5.164892673492432	aux_loss: 0.24663357436656952
13:38:00 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 5.277692794799805	recon_loss: 0.004502803087234497	bpp_loss: 5.180796146392822	aux_loss: 0.1411256492137909
13:46:57 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 5.37149715423584	recon_loss: 0.004590701777487993	bpp_loss: 5.2489800453186035	aux_loss: 0.15604239702224731
