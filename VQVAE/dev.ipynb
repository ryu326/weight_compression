{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(4, 512, 512)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.MaxPool2d((1, 512//4), stride=(1, 512//4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(out).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.randn(5, 10)\n",
    "\n",
    "t[2:5, 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[3, 2:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self, input_size, dim_encoder, n_resblock, n_embeddings, P, dim_embeddings, beta, scale, shift):\n",
    "model = models.VQVAE_MAG(16, 256, 4, 256, 10, 16, 0.25, torch.Tensor([1]), torch.Tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_loss': tensor(5398.3618, grad_fn=<AddBackward0>),\n",
       " 'x': tensor([[-0.3091,  0.1600,  0.1806, -1.7467,  0.2467, -0.4230,  0.3471,  0.0759,\n",
       "          -0.1051, -1.0116,  0.5251, -0.9295,  0.7107, -0.6312, -0.7392,  0.2895],\n",
       "         [-0.9600,  0.1721,  0.1506,  0.5345,  1.5426, -0.9470,  1.4513,  2.4723,\n",
       "           0.4642, -0.5035, -1.7013,  0.3632,  1.9129, -0.1742, -1.6596,  0.0596],\n",
       "         [ 0.1662, -0.9073, -0.3516,  1.0436, -1.3646, -0.1447, -1.4639,  1.3596,\n",
       "           0.6527,  1.2156, -1.0190, -1.0121, -1.5129,  1.7236, -0.1561,  2.2090],\n",
       "         [ 0.6786, -3.2570, -0.1244, -1.0416,  0.1727, -0.8412, -0.8372, -1.9843,\n",
       "          -2.6146,  0.3779,  0.9957,  0.9620, -2.6132,  0.1369,  0.3735, -1.0396],\n",
       "         [-0.5831, -1.4023, -0.2776, -0.6681, -1.8187,  1.0736,  0.2318, -0.3845,\n",
       "          -0.9328,  0.1531, -0.9577, -0.3571, -0.0278, -0.6672, -0.7935, -0.1733],\n",
       "         [-0.0713,  0.6842,  1.5445, -2.3324, -0.0271,  0.1475,  0.4695,  0.5459,\n",
       "           1.6024, -0.3298, -1.0917, -0.0508, -2.2326,  0.5237, -0.0301,  1.0940],\n",
       "         [-0.6234, -1.1920,  0.7609,  0.3895, -1.7342, -0.1870,  0.5955,  0.1579,\n",
       "           1.3866, -0.5510,  0.1019, -0.1742, -1.4259, -1.6143,  0.3096, -0.9418],\n",
       "         [-0.0844, -0.4707, -0.9684, -1.3641,  2.1258,  0.8763,  1.3367, -0.2735,\n",
       "          -1.0615,  0.0294,  0.8561,  0.4310, -0.2955, -1.2079,  0.2133, -0.1889],\n",
       "         [-0.0453, -0.4211, -0.4079, -1.4680, -0.7274,  0.3636, -0.4789,  0.1592,\n",
       "          -1.9272,  1.3214, -0.0777, -0.5258,  0.3984,  0.7513,  1.5731,  1.2742],\n",
       "         [ 1.4908,  0.3857, -0.6742,  0.7801,  1.1179, -0.8138, -0.3416, -1.3367,\n",
       "           0.6609,  0.2087,  0.9300,  0.6596,  0.6077,  0.5551,  1.3131,  2.4610]]),\n",
       " 'x_hat': tensor([[-0.7868, -0.3451,  0.9409,  1.5542, -0.3454,  1.9752,  1.2677, -0.2567,\n",
       "          -0.8061,  0.7346,  1.2072,  0.0645,  1.9699, -1.3316,  0.6802, -1.3738],\n",
       "         [-0.7932, -0.3382,  0.9594,  1.5319, -0.3839,  1.9557,  1.2734, -0.2622,\n",
       "          -0.7604,  0.7089,  1.1965,  0.0970,  1.9338, -1.2992,  0.6674, -1.3616],\n",
       "         [-0.8044, -0.3305,  0.9513,  1.5141, -0.3835,  1.9794,  1.2889, -0.2684,\n",
       "          -0.7907,  0.7329,  1.1548,  0.0809,  1.9527, -1.3214,  0.6658, -1.3592],\n",
       "         [-0.7854, -0.3570,  0.9537,  1.4947, -0.4126,  1.9601,  1.2918, -0.2672,\n",
       "          -0.7976,  0.7416,  1.1316,  0.0869,  1.9434, -1.3097,  0.6661, -1.3694],\n",
       "         [-0.7997, -0.3362,  0.9652,  1.5274, -0.3564,  1.9627,  1.2984, -0.2615,\n",
       "          -0.7847,  0.7386,  1.1961,  0.0799,  1.9747, -1.3166,  0.6472, -1.3591],\n",
       "         [-0.7981, -0.3254,  0.9579,  1.5410, -0.3523,  1.9754,  1.2677, -0.2672,\n",
       "          -0.7854,  0.7314,  1.1468,  0.0907,  1.9766, -1.3161,  0.6655, -1.3322],\n",
       "         [-0.7750, -0.2932,  0.9886,  1.5271, -0.4032,  1.9539,  1.2778, -0.2557,\n",
       "          -0.7987,  0.7105,  1.1885,  0.0728,  1.9362, -1.3042,  0.6582, -1.4031],\n",
       "         [-0.7327, -0.3067,  0.9610,  1.5577, -0.3925,  1.9443,  1.2914, -0.2731,\n",
       "          -0.7994,  0.7272,  1.1653,  0.1004,  1.9591, -1.3377,  0.6547, -1.3970],\n",
       "         [-0.7811, -0.3615,  0.9777,  1.5187, -0.4123,  1.9516,  1.2720, -0.2691,\n",
       "          -0.8135,  0.7128,  1.1813,  0.0932,  1.9115, -1.2685,  0.6629, -1.3298],\n",
       "         [-0.7657, -0.3265,  0.9866,  1.5165, -0.3953,  1.9442,  1.2643, -0.2976,\n",
       "          -0.8064,  0.7162,  1.1802,  0.0583,  1.9528, -1.3376,  0.6651, -1.3807]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " 'perplexity': tensor(55.5193),\n",
       " 'z_q': tensor([[-3.8548e-03,  2.6379e-03, -3.2477e-03,  ..., -3.5095e-03,\n",
       "          -3.2864e-03,  3.6621e-03],\n",
       "         [ 1.3733e-03,  4.5776e-05,  1.3885e-03,  ...,  2.4414e-04,\n",
       "           1.2817e-03, -1.0910e-03],\n",
       "         [-3.3326e-03, -2.0599e-04,  2.6550e-03,  ...,  2.9097e-03,\n",
       "           3.6697e-03,  3.7270e-03],\n",
       "         ...,\n",
       "         [ 3.8767e-03, -3.8834e-03, -2.3537e-03,  ..., -2.0027e-03,\n",
       "           2.3842e-03,  2.0199e-03],\n",
       "         [ 2.4719e-03,  2.0103e-03, -3.5362e-03,  ...,  3.2730e-03,\n",
       "           1.6174e-03,  2.7237e-03],\n",
       "         [ 2.5864e-03, -3.0518e-04,  3.2387e-03,  ..., -2.3651e-04,\n",
       "          -8.6832e-04,  6.2561e-04]], grad_fn=<AddBackward0>),\n",
       " 'min_encodings': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'min_encoding_indices': tensor([[130],\n",
       "         [108],\n",
       "         [120],\n",
       "         [120],\n",
       "         [155],\n",
       "         [ 71],\n",
       "         [241],\n",
       "         [113],\n",
       "         [153],\n",
       "         [109],\n",
       "         [155],\n",
       "         [  4],\n",
       "         [  2],\n",
       "         [146],\n",
       "         [236],\n",
       "         [  9],\n",
       "         [ 71],\n",
       "         [128],\n",
       "         [ 76],\n",
       "         [210],\n",
       "         [  9],\n",
       "         [239],\n",
       "         [160],\n",
       "         [144],\n",
       "         [146],\n",
       "         [ 75],\n",
       "         [177],\n",
       "         [ 90],\n",
       "         [169],\n",
       "         [143],\n",
       "         [113],\n",
       "         [  0],\n",
       "         [110],\n",
       "         [ 44],\n",
       "         [185],\n",
       "         [ 53],\n",
       "         [212],\n",
       "         [241],\n",
       "         [ 51],\n",
       "         [ 55],\n",
       "         [ 68],\n",
       "         [142],\n",
       "         [155],\n",
       "         [ 70],\n",
       "         [ 18],\n",
       "         [135],\n",
       "         [110],\n",
       "         [ 22],\n",
       "         [243],\n",
       "         [145],\n",
       "         [250],\n",
       "         [ 55],\n",
       "         [155],\n",
       "         [143],\n",
       "         [ 55],\n",
       "         [ 27],\n",
       "         [156],\n",
       "         [ 43],\n",
       "         [128],\n",
       "         [ 85],\n",
       "         [ 70],\n",
       "         [ 33],\n",
       "         [ 29],\n",
       "         [128],\n",
       "         [ 14],\n",
       "         [  9],\n",
       "         [  9],\n",
       "         [139],\n",
       "         [  9],\n",
       "         [155],\n",
       "         [ 85],\n",
       "         [ 58],\n",
       "         [ 61],\n",
       "         [224],\n",
       "         [120],\n",
       "         [162],\n",
       "         [143],\n",
       "         [207],\n",
       "         [ 68],\n",
       "         [177],\n",
       "         [167],\n",
       "         [  9],\n",
       "         [170],\n",
       "         [254],\n",
       "         [220],\n",
       "         [108],\n",
       "         [ 33],\n",
       "         [104],\n",
       "         [146],\n",
       "         [246],\n",
       "         [210],\n",
       "         [173],\n",
       "         [130],\n",
       "         [ 89],\n",
       "         [212],\n",
       "         [ 14],\n",
       "         [135],\n",
       "         [220],\n",
       "         [254],\n",
       "         [188]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 16)\n",
    "a = torch.randn(10, 16)\n",
    "        # {'block_idx': block_idx, \n",
    "        # 'tensor_block_idx': t_block_idx,\n",
    "        # 'weight_block': weight_block,\n",
    "        # 'input_block': input_block }\n",
    "model({'weight_block': x, 'input_block': a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
