/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
22:44:16 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
22:44:16 INFO - ddp_or_single_process: Create new exp folder!
22:44:16 INFO - ddp_or_single_process: seed : 100
22:44:16 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /home/jgryu/Weight_compression/VQVAE/wandb/run-20250210_224417-9h4pld5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run nwc_ql
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/NWC_VQVAE
wandb: üöÄ View run at https://wandb.ai/maskedkd/NWC_VQVAE/runs/9h4pld5g
22:44:18 INFO - main: Create experiment save folder
/home/jgryu/Weight_compression/VQVAE/datasets/datasets_weight_block_seq_qlevel_random.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(dataset_folder_path)
{'entropy_bottleneck.quantiles'}
22:44:28 INFO - main: Training mode : scratch!
22:44:28 INFO - main: batch_size : 1024
22:44:28 INFO - main: num of gpus: 1
22:44:28 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=100000, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda100000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
/home/jgryu/Weight_compression/VQVAE/train_nwc.py:260: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
22:44:29 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 15740951.0	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.943603515625
22:44:37 INFO - main: {'TEST MSE': 124.07185801363262, 'TEST BPP': 5.56653125, 'TEST loss': 12407192.29825, 'TEST recon_loss': 124.07185436820984, 'TEST bpp_loss': 5.445773605823517}
22:44:37 INFO - main: can not find prev_mse_best_model!
22:44:37 INFO - main: can not find prev_bpp_best_model!
22:44:37 INFO - main: can not find prev_bpp_best_model!
22:44:37 INFO - main: can not find recent_saved_model!
22:53:29 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 2373.457275390625	recon_loss: 0.023670107126235962	bpp_loss: 5.226837635040283	aux_loss: 319.7098693847656
23:02:23 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 1816.2689208984375	recon_loss: 0.018106095492839813	bpp_loss: 5.237475872039795	aux_loss: 312.751220703125
23:11:16 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 1558.1290283203125	recon_loss: 0.015521748922765255	bpp_loss: 5.281200885772705	aux_loss: 306.862548828125
23:20:11 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 1161.67919921875	recon_loss: 0.011558666825294495	bpp_loss: 5.3541412353515625	aux_loss: 302.2835693359375
23:29:04 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 1010.7003173828125	recon_loss: 0.01004755962640047	bpp_loss: 5.400065898895264	aux_loss: 298.89495849609375
23:29:11 INFO - main: {'TEST MSE': 0.010011107991096453, 'TEST BPP': 6.224671875, 'TEST loss': 1007.0071859130859, 'TEST recon_loss': 0.0100111076827161, 'TEST bpp_loss': 5.39541194152832}
23:38:03 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 672.3087158203125	recon_loss: 0.006664160173386335	bpp_loss: 5.377425670623779	aux_loss: 294.1461181640625
23:46:58 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 613.3695068359375	recon_loss: 0.006073479540646076	bpp_loss: 5.422541618347168	aux_loss: 290.8652648925781
23:55:51 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 543.7776489257812	recon_loss: 0.005380177404731512	bpp_loss: 5.461277484893799	aux_loss: 286.98175048828125
00:04:44 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 451.5641784667969	recon_loss: 0.004456039052456617	bpp_loss: 5.478885173797607	aux_loss: 283.3399963378906
00:13:38 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 403.8432922363281	recon_loss: 0.003979714121669531	bpp_loss: 5.473881721496582	aux_loss: 281.3971862792969
00:13:45 INFO - main: {'TEST MSE': 0.004325547854059078, 'TEST BPP': 5.81334375, 'TEST loss': 438.38121267700194, 'TEST recon_loss': 0.004325547722168267, 'TEST bpp_loss': 5.486318594455719}
00:22:38 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 369.19647216796875	recon_loss: 0.003634718246757984	bpp_loss: 5.52974271774292	aux_loss: 278.0975646972656
00:31:32 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 320.4342956542969	recon_loss: 0.003140657674521208	bpp_loss: 5.478455543518066	aux_loss: 276.6353759765625
00:40:25 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 450.9742431640625	recon_loss: 0.004444132559001446	bpp_loss: 5.4999680519104	aux_loss: 274.2379455566406
00:49:20 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 295.08624267578125	recon_loss: 0.002888507442548871	bpp_loss: 5.527793884277344	aux_loss: 272.2543029785156
00:58:12 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 311.5068054199219	recon_loss: 0.00305068283341825	bpp_loss: 5.543123245239258	aux_loss: 271.6814880371094
00:58:19 INFO - main: {'TEST MSE': 0.002740584552812896, 'TEST BPP': 5.70265625, 'TEST loss': 280.26600678253175, 'TEST recon_loss': 0.002740584471030161, 'TEST bpp_loss': 5.5548711061477665}
01:07:12 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 214.3636932373047	recon_loss: 0.0020797820761799812	bpp_loss: 5.578210830688477	aux_loss: 269.1497497558594
01:16:06 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 224.8483428955078	recon_loss: 0.002181608695536852	bpp_loss: 5.585939407348633	aux_loss: 267.6260070800781
01:24:59 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 236.53042602539062	recon_loss: 0.002300392370671034	bpp_loss: 5.659251689910889	aux_loss: 266.68341064453125
01:33:52 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 230.4961395263672	recon_loss: 0.00224270555190742	bpp_loss: 5.646987438201904	aux_loss: 264.4170227050781
01:42:47 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 218.48435974121094	recon_loss: 0.002121309284120798	bpp_loss: 5.693872928619385	aux_loss: 263.3227844238281
01:42:54 INFO - main: {'TEST MSE': 0.0018942988474717213, 'TEST BPP': 5.784, 'TEST loss': 195.9892685546875, 'TEST recon_loss': 0.0018942987903719768, 'TEST bpp_loss': 5.68435346698761}
01:51:47 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 180.531005859375	recon_loss: 0.0017358032055199146	bpp_loss: 5.694482326507568	aux_loss: 262.2041015625
02:00:40 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 182.9452362060547	recon_loss: 0.0017615071265026927	bpp_loss: 5.694531440734863	aux_loss: 259.73223876953125
02:09:33 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 198.20770263671875	recon_loss: 0.0019144684774801135	bpp_loss: 5.691117286682129	aux_loss: 257.8148498535156
02:18:28 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 209.52528381347656	recon_loss: 0.0020249830558896065	bpp_loss: 5.713620185852051	aux_loss: 256.02972412109375
02:27:21 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 162.03282165527344	recon_loss: 0.001553504029288888	bpp_loss: 5.7802734375	aux_loss: 255.61331176757812
02:27:28 INFO - main: {'TEST MSE': 0.001380087643355448, 'TEST BPP': 5.856421875, 'TEST loss': 144.59800870513916, 'TEST recon_loss': 0.0013800876016030088, 'TEST bpp_loss': 5.7845740442276}
02:36:21 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 153.51988220214844	recon_loss: 0.0014665002236142755	bpp_loss: 5.807487964630127	aux_loss: 254.81124877929688
02:45:16 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 140.7928924560547	recon_loss: 0.001340160146355629	bpp_loss: 5.7942094802856445	aux_loss: 252.50790405273438
02:54:09 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 152.58749389648438	recon_loss: 0.0014584792079403996	bpp_loss: 5.8200764656066895	aux_loss: 250.66282653808594
03:03:02 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 124.2706527709961	recon_loss: 0.0011773102451115847	bpp_loss: 5.833939552307129	aux_loss: 248.61978149414062
03:11:57 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 124.33365631103516	recon_loss: 0.0011779762571677566	bpp_loss: 5.873827934265137	aux_loss: 248.5027618408203
03:12:04 INFO - main: {'TEST MSE': 0.0013229126549189631, 'TEST BPP': 5.91515625, 'TEST loss': 139.09618737792968, 'TEST recon_loss': 0.0013229126133956015, 'TEST bpp_loss': 5.863629289627076}
03:20:57 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 146.65736389160156	recon_loss: 0.0013974697794765234	bpp_loss: 5.839926719665527	aux_loss: 245.53314208984375
03:29:50 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 122.86798095703125	recon_loss: 0.001160154934041202	bpp_loss: 5.911192417144775	aux_loss: 245.68492126464844
03:38:44 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 117.166259765625	recon_loss: 0.0011057970114052296	bpp_loss: 5.896700859069824	aux_loss: 244.11932373046875
03:47:39 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 155.7503662109375	recon_loss: 0.001490866532549262	bpp_loss: 5.876199722290039	aux_loss: 240.68661499023438
03:56:32 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 142.30877685546875	recon_loss: 0.0013546539703384042	bpp_loss: 5.906362056732178	aux_loss: 240.07159423828125
03:56:39 INFO - main: {'TEST MSE': 0.0014749721697002206, 'TEST BPP': 5.96584375, 'TEST loss': 154.43764709472657, 'TEST recon_loss': 0.0014749721242696978, 'TEST bpp_loss': 5.925221004009247}
04:05:32 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 98.20861053466797	recon_loss: 0.000914291013032198	bpp_loss: 5.914294719696045	aux_loss: 238.3753662109375
04:14:28 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 160.99778747558594	recon_loss: 0.0015389363979920745	bpp_loss: 5.907889366149902	aux_loss: 236.9842071533203
04:23:21 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 84.39154815673828	recon_loss: 0.0007726854528300464	bpp_loss: 5.9265851974487305	aux_loss: 234.21731567382812
04:32:14 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 101.4267349243164	recon_loss: 0.0009420207352377474	bpp_loss: 5.924184322357178	aux_loss: 232.1691131591797
04:41:09 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 97.9745101928711	recon_loss: 0.0009113415726460516	bpp_loss: 5.909215927124023	aux_loss: 229.66665649414062
04:41:16 INFO - main: {'TEST MSE': 0.0010053476484523705, 'TEST BPP': 5.942875, 'TEST loss': 107.75359629058838, 'TEST recon_loss': 0.0010053476178145501, 'TEST bpp_loss': 5.908536511421204}
04:50:08 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 114.51824951171875	recon_loss: 0.0010759198339655995	bpp_loss: 5.923405647277832	aux_loss: 228.34579467773438
04:59:02 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 97.86024475097656	recon_loss: 0.0009103468619287014	bpp_loss: 5.9535675048828125	aux_loss: 227.40504455566406
05:07:55 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 101.49066162109375	recon_loss: 0.0009453709935769439	bpp_loss: 5.92938232421875	aux_loss: 224.67897033691406
05:16:49 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 116.28913116455078	recon_loss: 0.0010945562971755862	bpp_loss: 5.926309585571289	aux_loss: 221.73289489746094
05:25:42 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 100.13719940185547	recon_loss: 0.000932331895455718	bpp_loss: 5.892289161682129	aux_loss: 218.1965789794922
05:25:49 INFO - main: {'TEST MSE': 0.000938247605995599, 'TEST BPP': 5.938, 'TEST loss': 100.7081501083374, 'TEST recon_loss': 0.0009382475782185793, 'TEST bpp_loss': 5.908428096771241}
05:34:42 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 93.0988540649414	recon_loss: 0.0008614406688138843	bpp_loss: 5.886872291564941	aux_loss: 215.22634887695312
05:43:37 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 141.479736328125	recon_loss: 0.001347915269434452	bpp_loss: 5.911239147186279	aux_loss: 212.53033447265625
05:52:30 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 124.86949157714844	recon_loss: 0.001179638085886836	bpp_loss: 5.8854498863220215	aux_loss: 209.70193481445312
06:01:23 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 111.31497955322266	recon_loss: 0.0010448108660057187	bpp_loss: 5.905057907104492	aux_loss: 209.04608154296875
06:10:18 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 81.50709533691406	recon_loss: 0.0007485756068490446	bpp_loss: 5.911942005157471	aux_loss: 207.81752014160156
06:10:25 INFO - main: {'TEST MSE': 0.0009574138404800619, 'TEST BPP': 5.9585, 'TEST loss': 102.825214427948, 'TEST recon_loss': 0.0009574138114112429, 'TEST bpp_loss': 5.9311079483032225}
06:19:17 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 92.04228210449219	recon_loss: 0.000850960030220449	bpp_loss: 5.921824932098389	aux_loss: 205.97994995117188
06:28:10 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 94.2686538696289	recon_loss: 0.0008728312095627189	bpp_loss: 5.9107255935668945	aux_loss: 203.19564819335938
06:37:03 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 119.41374969482422	recon_loss: 0.0011254975106567144	bpp_loss: 5.925079345703125	aux_loss: 201.3408203125
06:45:58 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 112.3045883178711	recon_loss: 0.0010499785421416163	bpp_loss: 5.927011966705322	aux_loss: 199.52960205078125
06:54:51 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 113.37454986572266	recon_loss: 0.001064255484379828	bpp_loss: 5.883225917816162	aux_loss: 195.96778869628906
06:54:58 INFO - main: {'TEST MSE': 0.0013120404049695462, 'TEST BPP': 5.92315625, 'TEST loss': 137.9007906036377, 'TEST recon_loss': 0.0013120403669890947, 'TEST bpp_loss': 5.895924386501313}
07:03:51 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 122.1794662475586	recon_loss: 0.001150726224295795	bpp_loss: 5.892894744873047	aux_loss: 193.47128295898438
07:12:46 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 152.13328552246094	recon_loss: 0.0014541648561134934	bpp_loss: 5.895349025726318	aux_loss: 191.44818115234375
07:21:39 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 80.4590835571289	recon_loss: 0.000734783592633903	bpp_loss: 5.893611431121826	aux_loss: 189.86856079101562
07:30:32 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 97.25679016113281	recon_loss: 0.0009026978514157236	bpp_loss: 5.861178398132324	aux_loss: 187.5629119873047
07:39:26 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 96.29287719726562	recon_loss: 0.0008917864761315286	bpp_loss: 5.896553039550781	aux_loss: 184.47494506835938
07:39:34 INFO - main: {'TEST MSE': 0.0007368962579603693, 'TEST BPP': 5.927375, 'TEST loss': 80.73451090431213, 'TEST recon_loss': 0.000736896235612221, 'TEST bpp_loss': 5.900763668060303}
07:48:27 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 82.69711303710938	recon_loss: 0.0007565456908196211	bpp_loss: 5.893119812011719	aux_loss: 183.25827026367188
07:57:19 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 80.16068267822266	recon_loss: 0.0007311349036172032	bpp_loss: 5.885385036468506	aux_loss: 180.47390747070312
08:06:13 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 123.28721618652344	recon_loss: 0.0011594699462875724	bpp_loss: 5.887099742889404	aux_loss: 178.0324249267578
08:15:07 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 79.77296447753906	recon_loss: 0.000729669991414994	bpp_loss: 5.916773319244385	aux_loss: 177.87228393554688
08:24:01 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 77.40364837646484	recon_loss: 0.0007000926998443902	bpp_loss: 5.9045820236206055	aux_loss: 175.60345458984375
08:24:08 INFO - main: {'TEST MSE': 0.0011129791080896976, 'TEST BPP': 5.929875, 'TEST loss': 118.18636033630371, 'TEST recon_loss': 0.00111297907482367, 'TEST bpp_loss': 5.903728409767151}
08:33:01 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 87.3960952758789	recon_loss: 0.0008076776866801083	bpp_loss: 5.909003257751465	aux_loss: 174.5032958984375
08:41:56 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 108.06878662109375	recon_loss: 0.001010584062896669	bpp_loss: 5.902094841003418	aux_loss: 172.0991973876953
08:50:49 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 91.51834869384766	recon_loss: 0.0008416729979217052	bpp_loss: 5.8940043449401855	aux_loss: 169.56788635253906
08:59:42 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 105.51170349121094	recon_loss: 0.0009864808525890112	bpp_loss: 5.909045696258545	aux_loss: 167.60147094726562
09:08:37 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 72.51089477539062	recon_loss: 0.0006559922476299107	bpp_loss: 5.902822971343994	aux_loss: 165.5347900390625
09:08:44 INFO - main: {'TEST MSE': 0.0009188326680518467, 'TEST BPP': 5.93896875, 'TEST loss': 98.54864296722413, 'TEST recon_loss': 0.0009188326410658192, 'TEST bpp_loss': 5.914245450019837}
09:17:37 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 113.0636215209961	recon_loss: 0.0010600194800645113	bpp_loss: 5.903780460357666	aux_loss: 163.456298828125
09:26:29 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 96.53856658935547	recon_loss: 0.0008901573019102216	bpp_loss: 5.896641254425049	aux_loss: 159.81927490234375
09:35:22 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 83.19942474365234	recon_loss: 0.0007599559612572193	bpp_loss: 5.887368679046631	aux_loss: 158.148681640625
09:44:17 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 107.97538757324219	recon_loss: 0.0010111668379977345	bpp_loss: 5.921021461486816	aux_loss: 158.18634033203125
09:53:10 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 86.59341430664062	recon_loss: 0.000798641936853528	bpp_loss: 5.912408351898193	aux_loss: 154.94085693359375
09:53:17 INFO - main: {'TEST MSE': 0.000768371298609611, 'TEST BPP': 5.9456875, 'TEST loss': 83.58828544425964, 'TEST recon_loss': 0.0007683712751459098, 'TEST bpp_loss': 5.921203378677368}
10:02:09 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 164.5308380126953	recon_loss: 0.0015765323769301176	bpp_loss: 5.901756763458252	aux_loss: 153.78091430664062
10:11:04 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 130.37628173828125	recon_loss: 0.001236093114130199	bpp_loss: 5.890275478363037	aux_loss: 151.1804962158203
10:19:57 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 116.86600494384766	recon_loss: 0.0011009677546098828	bpp_loss: 5.909020900726318	aux_loss: 149.35906982421875
10:28:50 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 89.67405700683594	recon_loss: 0.000827203446533531	bpp_loss: 5.900397777557373	aux_loss: 146.46617126464844
10:37:45 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 96.78496551513672	recon_loss: 0.0008938992978073657	bpp_loss: 5.908353805541992	aux_loss: 143.77658081054688
10:37:52 INFO - main: {'TEST MSE': 0.0007721681352505162, 'TEST BPP': 5.929859375, 'TEST loss': 83.85274601364135, 'TEST recon_loss': 0.0007721681120165158, 'TEST bpp_loss': 5.905300736904144}
10:46:44 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 101.11380767822266	recon_loss: 0.000939614197704941	bpp_loss: 5.918214797973633	aux_loss: 142.20623779296875
10:55:37 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 87.01371765136719	recon_loss: 0.0007985631818883121	bpp_loss: 5.912317752838135	aux_loss: 141.43063354492188
11:04:30 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 116.762451171875	recon_loss: 0.001097141532227397	bpp_loss: 5.926188945770264	aux_loss: 140.0481719970703
11:13:24 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 101.3214340209961	recon_loss: 0.0009433958912268281	bpp_loss: 5.918301105499268	aux_loss: 136.95626831054688
11:22:17 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 90.18956756591797	recon_loss: 0.0008340703789144754	bpp_loss: 5.8928751945495605	aux_loss: 133.53392028808594
11:22:24 INFO - main: {'TEST MSE': 0.0010498884874050067, 'TEST BPP': 5.927625, 'TEST loss': 112.25782808685302, 'TEST recon_loss': 0.001049888456123881, 'TEST bpp_loss': 5.902970279216766}
11:31:17 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 87.97975158691406	recon_loss: 0.0008107514586299658	bpp_loss: 5.893699645996094	aux_loss: 130.60955810546875
11:40:11 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 111.00413513183594	recon_loss: 0.0010434117866680026	bpp_loss: 5.898980617523193	aux_loss: 128.95050048828125
11:49:03 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 100.8056869506836	recon_loss: 0.000939150108024478	bpp_loss: 5.914906978607178	aux_loss: 125.88653564453125
11:57:56 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 133.8188934326172	recon_loss: 0.0012657024199143052	bpp_loss: 5.9029221534729	aux_loss: 126.33979797363281
12:06:50 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 147.12451171875	recon_loss: 0.0014040782116353512	bpp_loss: 5.892159938812256	aux_loss: 122.87680053710938
12:06:58 INFO - main: {'TEST MSE': 0.0008830875078516382, 'TEST BPP': 5.932546875, 'TEST loss': 95.30608686447144, 'TEST recon_loss': 0.0008830874803243205, 'TEST bpp_loss': 5.907685831546783}
12:15:51 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 130.30381774902344	recon_loss: 0.0012283817632123828	bpp_loss: 5.890518665313721	aux_loss: 121.0385971069336
12:24:43 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 97.17314910888672	recon_loss: 0.0009024464525282383	bpp_loss: 5.90304708480835	aux_loss: 117.670654296875
12:33:36 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 88.00729370117188	recon_loss: 0.0008092760690487921	bpp_loss: 5.899594306945801	aux_loss: 116.82221984863281
12:42:30 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 148.67454528808594	recon_loss: 0.0014190126676112413	bpp_loss: 5.918288230895996	aux_loss: 114.38389587402344
12:51:23 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 98.51792907714844	recon_loss: 0.0009143776842392981	bpp_loss: 5.917826175689697	aux_loss: 113.37561798095703
12:51:30 INFO - main: {'TEST MSE': 0.0006937767400066248, 'TEST BPP': 5.949765625, 'TEST loss': 75.78728534507752, 'TEST recon_loss': 0.0006937767191120656, 'TEST bpp_loss': 5.9238726677894595}
13:00:22 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 78.52509307861328	recon_loss: 0.0007169391610659659	bpp_loss: 5.913056373596191	aux_loss: 111.75765228271484
13:09:16 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 90.61748504638672	recon_loss: 0.0008306004456244409	bpp_loss: 5.910883903503418	aux_loss: 110.3402099609375
13:18:09 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 92.70652770996094	recon_loss: 0.0008585676550865173	bpp_loss: 5.915250778198242	aux_loss: 107.66292572021484
13:27:01 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 78.96175384521484	recon_loss: 0.0007214350625872612	bpp_loss: 5.936412334442139	aux_loss: 107.01690673828125
13:35:56 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 84.95553588867188	recon_loss: 0.0007814542623236775	bpp_loss: 5.93693733215332	aux_loss: 106.61344909667969
13:36:03 INFO - main: {'TEST MSE': 0.0007326546479449229, 'TEST BPP': 5.97759375, 'TEST loss': 79.81558368110657, 'TEST recon_loss': 0.0007326546255790163, 'TEST bpp_loss': 5.951579093456268}
13:44:55 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 162.96859741210938	recon_loss: 0.001553836278617382	bpp_loss: 5.946685314178467	aux_loss: 103.95114135742188
13:53:48 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 78.83100128173828	recon_loss: 0.000719720555935055	bpp_loss: 5.9471435546875	aux_loss: 101.34323120117188
14:02:41 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 80.8555908203125	recon_loss: 0.0007383127231150866	bpp_loss: 5.912242889404297	aux_loss: 98.09607696533203
14:11:35 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 112.34595489501953	recon_loss: 0.0010526968399062753	bpp_loss: 5.941457271575928	aux_loss: 96.50064849853516
14:20:27 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 73.56620788574219	recon_loss: 0.0006650888826698065	bpp_loss: 5.924563407897949	aux_loss: 94.25883483886719
14:20:35 INFO - main: {'TEST MSE': 0.000741245569561561, 'TEST BPP': 5.96653125, 'TEST loss': 80.79198521995545, 'TEST recon_loss': 0.0007412455477751791, 'TEST bpp_loss': 5.939977147579193}
14:29:27 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 99.31185150146484	recon_loss: 0.0009229184361174703	bpp_loss: 5.922116756439209	aux_loss: 91.22799682617188
14:38:21 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 112.90571594238281	recon_loss: 0.0010625201975926757	bpp_loss: 5.885892391204834	aux_loss: 87.80696105957031
14:47:13 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 72.61811828613281	recon_loss: 0.0006601378554478288	bpp_loss: 5.896287441253662	aux_loss: 84.26104736328125
14:56:06 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 147.8618621826172	recon_loss: 0.001408158103004098	bpp_loss: 5.910330772399902	aux_loss: 83.7822494506836
15:05:00 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 88.61585235595703	recon_loss: 0.0008178872521966696	bpp_loss: 5.914315223693848	aux_loss: 84.45083618164062
15:05:08 INFO - main: {'TEST MSE': 0.0007439039460596082, 'TEST BPP': 5.977, 'TEST loss': 81.38094038009643, 'TEST recon_loss': 0.0007439039235323435, 'TEST bpp_loss': 5.949027122497559}
15:14:00 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 94.18840789794922	recon_loss: 0.0008760554483160377	bpp_loss: 5.929434776306152	aux_loss: 82.567138671875
15:22:53 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 107.26701354980469	recon_loss: 0.0010006387019529939	bpp_loss: 5.938432216644287	aux_loss: 78.51724243164062
15:31:46 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 81.21040344238281	recon_loss: 0.0007427878445014358	bpp_loss: 5.917178630828857	aux_loss: 77.61866760253906
15:40:40 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 81.53128814697266	recon_loss: 0.0007452087011188269	bpp_loss: 5.957068920135498	aux_loss: 77.83738708496094
15:49:32 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 104.4786376953125	recon_loss: 0.0009767869487404823	bpp_loss: 5.94186544418335	aux_loss: 74.45655822753906
15:49:40 INFO - main: {'TEST MSE': 0.001034873937870578, 'TEST BPP': 5.97065625, 'TEST loss': 110.5521887626648, 'TEST recon_loss': 0.0010348739058099455, 'TEST bpp_loss': 5.942427832603455}
15:58:32 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 113.86965942382812	recon_loss: 0.0010696683311834931	bpp_loss: 5.899231910705566	aux_loss: 69.62776184082031
16:07:26 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 117.6841812133789	recon_loss: 0.0011081811971962452	bpp_loss: 5.916697025299072	aux_loss: 67.88540649414062
16:16:19 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 91.89154052734375	recon_loss: 0.0008488069870509207	bpp_loss: 5.928204536437988	aux_loss: 65.94063568115234
16:25:12 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 105.83444213867188	recon_loss: 0.0009882081067189574	bpp_loss: 5.934414863586426	aux_loss: 64.8638916015625
16:34:06 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 71.99491882324219	recon_loss: 0.0006457099807448685	bpp_loss: 5.931805610656738	aux_loss: 62.336063385009766
16:34:13 INFO - main: {'TEST MSE': 0.0007459981786303937, 'TEST BPP': 5.96425, 'TEST loss': 81.15544355773926, 'TEST recon_loss': 0.0007459981570282253, 'TEST bpp_loss': 5.936222146034241}
16:43:06 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 105.62039184570312	recon_loss: 0.0009809875627979636	bpp_loss: 5.921101093292236	aux_loss: 60.093414306640625
16:51:58 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 111.00794219970703	recon_loss: 0.0010415053693577647	bpp_loss: 5.9164814949035645	aux_loss: 58.43471908569336
17:00:51 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 74.77677154541016	recon_loss: 0.0006792244967073202	bpp_loss: 5.93398904800415	aux_loss: 56.84852600097656
17:09:45 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 77.789794921875	recon_loss: 0.0007098275818862021	bpp_loss: 5.933840751647949	aux_loss: 54.08509063720703
17:18:37 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 112.57740783691406	recon_loss: 0.001056316657923162	bpp_loss: 5.941558837890625	aux_loss: 53.30584716796875
17:18:45 INFO - main: {'TEST MSE': 0.0009080837673725525, 'TEST BPP': 5.967703125, 'TEST loss': 97.89219849586487, 'TEST recon_loss': 0.0009080837404471823, 'TEST bpp_loss': 5.938967529296875}
17:27:37 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 103.35448455810547	recon_loss: 0.0009613318252377212	bpp_loss: 5.93868350982666	aux_loss: 52.23863983154297
17:36:31 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 66.25236511230469	recon_loss: 0.0005959094851277769	bpp_loss: 5.926429748535156	aux_loss: 49.19230651855469
17:45:24 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 109.14069366455078	recon_loss: 0.0010209160391241312	bpp_loss: 5.936441898345947	aux_loss: 46.86461639404297
17:54:16 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 81.11785888671875	recon_loss: 0.0007419907487928867	bpp_loss: 5.939133167266846	aux_loss: 46.281429290771484
18:03:10 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 77.89552307128906	recon_loss: 0.0007067334954626858	bpp_loss: 5.900742530822754	aux_loss: 41.1627197265625
18:03:18 INFO - main: {'TEST MSE': 0.000816140737056999, 'TEST BPP': 5.962171875, 'TEST loss': 88.5611287021637, 'TEST recon_loss': 0.0008161407118313945, 'TEST bpp_loss': 5.932733922958374}
18:12:10 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 203.88906860351562	recon_loss: 0.001964267110452056	bpp_loss: 5.923593044281006	aux_loss: 39.46338653564453
18:21:03 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 81.92198181152344	recon_loss: 0.0007430483819916844	bpp_loss: 5.92193078994751	aux_loss: 37.60657501220703
18:29:55 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 79.9169921875	recon_loss: 0.0007275749230757356	bpp_loss: 5.914517879486084	aux_loss: 34.564754486083984
18:38:49 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 87.31945037841797	recon_loss: 0.0008028637967072427	bpp_loss: 5.911099910736084	aux_loss: 32.67949676513672
18:47:42 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 81.8514175415039	recon_loss: 0.0007480595959350467	bpp_loss: 5.942520618438721	aux_loss: 31.26972198486328
18:47:49 INFO - main: {'TEST MSE': 0.0009969431368901992, 'TEST BPP': 5.9664375, 'TEST loss': 106.63842768859864, 'TEST recon_loss': 0.0009969431087956764, 'TEST bpp_loss': 5.936261058807373}
18:56:41 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 90.41838836669922	recon_loss: 0.0008347241091541946	bpp_loss: 5.91187858581543	aux_loss: 29.216716766357422
19:05:35 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 113.71497344970703	recon_loss: 0.0010642309207469225	bpp_loss: 5.928163528442383	aux_loss: 28.707958221435547
19:14:28 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 116.27191162109375	recon_loss: 0.0010958673665300012	bpp_loss: 5.938811779022217	aux_loss: 24.865310668945312
19:23:21 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 77.5873794555664	recon_loss: 0.0007068957202136517	bpp_loss: 5.913138389587402	aux_loss: 22.440404891967773
19:32:15 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 116.93820190429688	recon_loss: 0.001097017084248364	bpp_loss: 5.907482147216797	aux_loss: 20.19152069091797
19:32:23 INFO - main: {'TEST MSE': 0.0009500687620859565, 'TEST BPP': 5.96109375, 'TEST loss': 101.86278011703492, 'TEST recon_loss': 0.000950068734906381, 'TEST bpp_loss': 5.930372901916504}
19:41:15 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 97.9967041015625	recon_loss: 0.0009097487200051546	bpp_loss: 5.930801868438721	aux_loss: 17.776546478271484
19:50:08 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 78.37919616699219	recon_loss: 0.0007150981109589338	bpp_loss: 5.902111530303955	aux_loss: 16.114822387695312
19:59:00 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 102.9860610961914	recon_loss: 0.0009573189890943468	bpp_loss: 5.9342427253723145	aux_loss: 13.486597061157227
20:07:55 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 73.6275634765625	recon_loss: 0.0006620007916353643	bpp_loss: 5.9214582443237305	aux_loss: 10.714078903198242
20:16:48 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 83.39842987060547	recon_loss: 0.0007637895760126412	bpp_loss: 5.944520473480225	aux_loss: 11.130691528320312
20:16:55 INFO - main: {'TEST MSE': 0.0007604452841321687, 'TEST BPP': 5.970046875, 'TEST loss': 82.77416658401489, 'TEST recon_loss': 0.0007604452621162636, 'TEST bpp_loss': 5.937823568820954}
20:25:48 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 90.54450988769531	recon_loss: 0.0008354260353371501	bpp_loss: 5.90181303024292	aux_loss: 8.404051780700684
20:34:42 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 125.9749526977539	recon_loss: 0.0011905556311830878	bpp_loss: 5.935022354125977	aux_loss: 7.711920738220215
20:43:35 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 72.35575866699219	recon_loss: 0.0006565080839209259	bpp_loss: 5.947532653808594	aux_loss: 7.467242240905762
20:52:28 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 104.29401397705078	recon_loss: 0.0009768781019374728	bpp_loss: 5.9599528312683105	aux_loss: 7.949532985687256
21:01:22 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 82.70162963867188	recon_loss: 0.0007586569408886135	bpp_loss: 5.92520809173584	aux_loss: 5.728416442871094
21:01:29 INFO - main: {'TEST MSE': 0.0008240217095817456, 'TEST BPP': 5.966921875, 'TEST loss': 89.57621669101715, 'TEST recon_loss': 0.0008240216851700097, 'TEST bpp_loss': 5.935680247783661}
21:10:22 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 95.62120819091797	recon_loss: 0.0008839911315590143	bpp_loss: 5.937607288360596	aux_loss: 6.425786972045898
21:19:15 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 78.24747467041016	recon_loss: 0.0007096947520039976	bpp_loss: 5.909744739532471	aux_loss: 6.428732395172119
21:28:09 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 108.16068267822266	recon_loss: 0.0010132178431376815	bpp_loss: 5.954450607299805	aux_loss: 3.837432861328125
21:37:03 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 104.771484375	recon_loss: 0.000974401249550283	bpp_loss: 5.964537143707275	aux_loss: 3.2266740798950195
21:45:56 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 90.94818115234375	recon_loss: 0.000840700464323163	bpp_loss: 5.943719863891602	aux_loss: 3.120828866958618
21:46:04 INFO - main: {'TEST MSE': 0.001012828951955075, 'TEST BPP': 5.980453125, 'TEST loss': 108.08782911109924, 'TEST recon_loss': 0.0010128289215645054, 'TEST bpp_loss': 5.948634640216827}
21:54:57 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 98.66390228271484	recon_loss: 0.0009183749789372087	bpp_loss: 5.9578633308410645	aux_loss: 3.460360050201416
22:03:51 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 128.86512756347656	recon_loss: 0.00121481460519135	bpp_loss: 5.927282810211182	aux_loss: 3.3101019859313965
22:12:44 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 86.757568359375	recon_loss: 0.0007975216140039265	bpp_loss: 5.929213047027588	aux_loss: 2.3035385608673096
22:21:36 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 69.22654724121094	recon_loss: 0.0006232158048078418	bpp_loss: 5.9323859214782715	aux_loss: 1.908643364906311
22:30:30 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 83.74883270263672	recon_loss: 0.0007638075039722025	bpp_loss: 5.916330337524414	aux_loss: 2.384690284729004
22:30:38 INFO - main: {'TEST MSE': 0.0007015846880351855, 'TEST BPP': 5.96315625, 'TEST loss': 77.25374195098877, 'TEST recon_loss': 0.0007015846662543481, 'TEST bpp_loss': 5.931189564704895}
Traceback (most recent call last):
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 652, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 866, in _save
    zip_file.write_record('data.pkl', data_value, len(data_value))
RuntimeError: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data.pkl: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 586, in <module>
    ddp_or_single_process(sys.argv[1:])
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 581, in ddp_or_single_process
    main(opts)
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 432, in main
    torch.save(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 651, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 499, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:603] . unexpected pos 128 vs 0
[1;34mwandb[0m: üöÄ View run [33mnwc_ql[0m at: [34mhttps://wandb.ai/maskedkd/NWC_VQVAE/runs/9h4pld5g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250210_224417-9h4pld5g/logs[0m
