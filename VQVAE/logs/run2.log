/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @amp.autocast(enabled=False)
22:44:16 INFO - logger_setup: /home/jgryu/Weight_compression/VQVAE/utils/util.py
22:44:16 INFO - ddp_or_single_process: Create new exp folder!
22:44:16 INFO - ddp_or_single_process: seed : 100
22:44:16 INFO - ddp_or_single_process: exp name : block_seq_ql_random_col_8/lmbda10000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ryu326 (maskedkd). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /home/jgryu/Weight_compression/VQVAE/wandb/run-20250210_224417-dyiqaf99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run nwc_ql
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maskedkd/NWC_VQVAE
wandb: üöÄ View run at https://wandb.ai/maskedkd/NWC_VQVAE/runs/dyiqaf99
22:44:18 INFO - main: Create experiment save folder
/home/jgryu/Weight_compression/VQVAE/datasets/datasets_weight_block_seq_qlevel_random.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(dataset_folder_path)
{'entropy_bottleneck.quantiles'}
22:44:28 INFO - main: Training mode : scratch!
22:44:28 INFO - main: batch_size : 1024
22:44:28 INFO - main: num of gpus: 1
22:44:28 INFO - main: Namespace(dist_port=6044, iter=200000, dataset='block_seq_ql_random', learning_rate=0.0001, aux_learning_rate=0.001, num_workers=2, batch_size=1024, seed=100, input_size=8, dim_encoder=512, n_resblock=4, M=16, N=16, clip_max_norm=1.0, save_dir='nwc_ql', architecture='nwc_ql', loss='rdloss_ql', checkpoint='None', block_direction='col', lmbda=10000, save_path='./checkpoint/nwc_ql/block_seq_ql_random_col_8/lmbda10000_rdloss_ql_encdim512_M16_batch_size1024_total_iter200000_lr0.0001_seed100', logger=<Logger utils.util (INFO)>, **{'dev.num_gpus': 1})
/home/jgryu/Weight_compression/VQVAE/train_nwc.py:260: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly():
22:44:29 INFO - main: Train iter. 1/200000 (0.0005%): 	Loss: 1574101.0	recon_loss: 157.40943908691406	bpp_loss: 5.452269554138184	aux_loss: 328.9421081542969
22:44:36 INFO - main: {'TEST MSE': 124.07188002789731, 'TEST BPP': 5.566421875, 'TEST loss': 1240725.6058359374, 'TEST recon_loss': 124.07187626838684, 'TEST bpp_loss': 5.445654757022858}
22:44:37 INFO - main: can not find prev_mse_best_model!
22:44:37 INFO - main: can not find prev_bpp_best_model!
22:44:37 INFO - main: can not find prev_bpp_best_model!
22:44:37 INFO - main: can not find recent_saved_model!
22:53:30 INFO - main: Train iter. 1000/200000 (0.5%): 	Loss: 271.2324523925781	recon_loss: 0.026495007798075676	bpp_loss: 5.1216349601745605	aux_loss: 318.0832214355469
23:02:24 INFO - main: Train iter. 2000/200000 (1.0%): 	Loss: 171.3166046142578	recon_loss: 0.016582408919930458	bpp_loss: 5.140340328216553	aux_loss: 309.58447265625
23:11:19 INFO - main: Train iter. 3000/200000 (1.5%): 	Loss: 125.32324981689453	recon_loss: 0.0119584109634161	bpp_loss: 5.229170799255371	aux_loss: 302.2049255371094
23:20:16 INFO - main: Train iter. 4000/200000 (2.0%): 	Loss: 116.01154327392578	recon_loss: 0.01104237511754036	bpp_loss: 5.313248634338379	aux_loss: 297.5615234375
23:29:11 INFO - main: Train iter. 5000/200000 (2.5%): 	Loss: 103.1811752319336	recon_loss: 0.009744234383106232	bpp_loss: 5.369857311248779	aux_loss: 293.8133850097656
23:29:18 INFO - main: {'TEST MSE': 0.008905037086682636, 'TEST BPP': 6.08146875, 'TEST loss': 94.74009112548828, 'TEST recon_loss': 0.008905036821728572, 'TEST bpp_loss': 5.36655028963089}
23:38:14 INFO - main: Train iter. 6000/200000 (3.0%): 	Loss: 90.42919921875	recon_loss: 0.008464740589261055	bpp_loss: 5.4119367599487305	aux_loss: 290.68609619140625
23:47:11 INFO - main: Train iter. 7000/200000 (3.5%): 	Loss: 82.0879135131836	recon_loss: 0.00762066850438714	bpp_loss: 5.390670299530029	aux_loss: 286.8863525390625
23:56:06 INFO - main: Train iter. 8000/200000 (4.0%): 	Loss: 66.5872573852539	recon_loss: 0.006088883616030216	bpp_loss: 5.4663920402526855	aux_loss: 282.23388671875
00:05:02 INFO - main: Train iter. 9000/200000 (4.5%): 	Loss: 64.1605224609375	recon_loss: 0.0058281756937503815	bpp_loss: 5.457725524902344	aux_loss: 278.2361755371094
00:14:00 INFO - main: Train iter. 10000/200000 (5.0%): 	Loss: 46.88772201538086	recon_loss: 0.004109443165361881	bpp_loss: 5.454614639282227	aux_loss: 274.47576904296875
00:14:07 INFO - main: {'TEST MSE': 0.0042253082196162875, 'TEST BPP': 5.76259375, 'TEST loss': 48.00547853851318, 'TEST recon_loss': 0.004225308095454238, 'TEST bpp_loss': 5.470629793167114}
00:23:02 INFO - main: Train iter. 11000/200000 (5.5%): 	Loss: 39.49122619628906	recon_loss: 0.0033849687315523624	bpp_loss: 5.4587907791137695	aux_loss: 271.8206481933594
00:31:58 INFO - main: Train iter. 12000/200000 (6.0%): 	Loss: 44.47418212890625	recon_loss: 0.0038192339707165956	bpp_loss: 5.454281806945801	aux_loss: 268.82012939453125
00:40:53 INFO - main: Train iter. 13000/200000 (6.5%): 	Loss: 50.461463928222656	recon_loss: 0.004402384161949158	bpp_loss: 5.465420246124268	aux_loss: 265.3424987792969
00:49:50 INFO - main: Train iter. 14000/200000 (7.0%): 	Loss: 27.005531311035156	recon_loss: 0.0020889383740723133	bpp_loss: 5.4878973960876465	aux_loss: 263.6510009765625
00:58:45 INFO - main: Train iter. 15000/200000 (7.5%): 	Loss: 37.2148323059082	recon_loss: 0.003090430283918977	bpp_loss: 5.494688987731934	aux_loss: 261.6981201171875
00:58:53 INFO - main: {'TEST MSE': 0.0029668439608381315, 'TEST BPP': 5.651140625, 'TEST loss': 35.75395066070557, 'TEST recon_loss': 0.0029668438668595627, 'TEST bpp_loss': 5.50974623632431}
01:07:48 INFO - main: Train iter. 16000/200000 (8.0%): 	Loss: 29.54745864868164	recon_loss: 0.002324869157746434	bpp_loss: 5.547244071960449	aux_loss: 260.43145751953125
01:16:45 INFO - main: Train iter. 17000/200000 (8.5%): 	Loss: 29.545696258544922	recon_loss: 0.002298810752108693	bpp_loss: 5.547528266906738	aux_loss: 258.19635009765625
01:25:41 INFO - main: Train iter. 18000/200000 (9.0%): 	Loss: 29.65658950805664	recon_loss: 0.002331280615180731	bpp_loss: 5.603867530822754	aux_loss: 256.4804382324219
01:34:36 INFO - main: Train iter. 19000/200000 (9.5%): 	Loss: 28.03139305114746	recon_loss: 0.002192840911448002	bpp_loss: 5.602813720703125	aux_loss: 255.241455078125
01:43:33 INFO - main: Train iter. 20000/200000 (10.0%): 	Loss: 28.245086669921875	recon_loss: 0.0022038226015865803	bpp_loss: 5.648537635803223	aux_loss: 252.91929626464844
01:43:41 INFO - main: {'TEST MSE': 0.0019502071815476877, 'TEST BPP': 5.72559375, 'TEST loss': 25.905782423973083, 'TEST recon_loss': 0.0019502071248134597, 'TEST bpp_loss': 5.639664398193359}
01:52:36 INFO - main: Train iter. 21000/200000 (10.5%): 	Loss: 21.180950164794922	recon_loss: 0.001435117213986814	bpp_loss: 5.691073417663574	aux_loss: 253.7804718017578
02:01:32 INFO - main: Train iter. 22000/200000 (11.0%): 	Loss: 28.38759422302246	recon_loss: 0.002174579305574298	bpp_loss: 5.655606269836426	aux_loss: 250.50439453125
02:10:28 INFO - main: Train iter. 23000/200000 (11.5%): 	Loss: 20.277050018310547	recon_loss: 0.0013649379834532738	bpp_loss: 5.659895420074463	aux_loss: 248.70208740234375
02:19:25 INFO - main: Train iter. 24000/200000 (12.0%): 	Loss: 23.321125030517578	recon_loss: 0.0016431189142167568	bpp_loss: 5.679537296295166	aux_loss: 247.42930603027344
02:28:20 INFO - main: Train iter. 25000/200000 (12.5%): 	Loss: 22.863197326660156	recon_loss: 0.0016328769270330667	bpp_loss: 5.717033386230469	aux_loss: 245.98419189453125
02:28:27 INFO - main: {'TEST MSE': 0.0014981358151828124, 'TEST BPP': 5.78153125, 'TEST loss': 21.42600903224945, 'TEST recon_loss': 0.001498135769739747, 'TEST bpp_loss': 5.723308575630188}
02:37:23 INFO - main: Train iter. 26000/200000 (13.0%): 	Loss: 21.353572845458984	recon_loss: 0.0014670542441308498	bpp_loss: 5.713217258453369	aux_loss: 243.68511962890625
02:46:21 INFO - main: Train iter. 27000/200000 (13.5%): 	Loss: 17.732025146484375	recon_loss: 0.001110689714550972	bpp_loss: 5.750415325164795	aux_loss: 242.5708465576172
02:55:16 INFO - main: Train iter. 28000/200000 (14.0%): 	Loss: 20.001018524169922	recon_loss: 0.0013420608593150973	bpp_loss: 5.767637729644775	aux_loss: 240.28565979003906
03:04:11 INFO - main: Train iter. 29000/200000 (14.5%): 	Loss: 21.49396324157715	recon_loss: 0.0015121451579034328	bpp_loss: 5.756333827972412	aux_loss: 237.7855224609375
03:13:08 INFO - main: Train iter. 30000/200000 (15.0%): 	Loss: 19.82915687561035	recon_loss: 0.0013461201451718807	bpp_loss: 5.818017482757568	aux_loss: 237.48193359375
03:13:16 INFO - main: {'TEST MSE': 0.0012790142761058736, 'TEST BPP': 5.852578125, 'TEST loss': 19.41979668521881, 'TEST recon_loss': 0.0012790142376325093, 'TEST bpp_loss': 5.804434665203095}
03:22:11 INFO - main: Train iter. 31000/200000 (15.5%): 	Loss: 16.556503295898438	recon_loss: 0.0009794017532840371	bpp_loss: 5.8090291023254395	aux_loss: 235.17733764648438
03:31:07 INFO - main: Train iter. 32000/200000 (16.0%): 	Loss: 16.805458068847656	recon_loss: 0.0010124373948201537	bpp_loss: 5.8552141189575195	aux_loss: 234.60089111328125
03:40:03 INFO - main: Train iter. 33000/200000 (16.5%): 	Loss: 20.184646606445312	recon_loss: 0.001378165907226503	bpp_loss: 5.807849884033203	aux_loss: 231.23001098632812
03:49:01 INFO - main: Train iter. 34000/200000 (17.0%): 	Loss: 17.059167861938477	recon_loss: 0.0010568567086011171	bpp_loss: 5.81385612487793	aux_loss: 228.66070556640625
03:57:56 INFO - main: Train iter. 35000/200000 (17.5%): 	Loss: 19.946683883666992	recon_loss: 0.0013330788351595402	bpp_loss: 5.795778274536133	aux_loss: 226.06240844726562
03:58:03 INFO - main: {'TEST MSE': 0.0014831738688865317, 'TEST BPP': 5.850671875, 'TEST loss': 21.543299021720888, 'TEST recon_loss': 0.001483173823740799, 'TEST bpp_loss': 5.814412226200104}
04:06:59 INFO - main: Train iter. 36000/200000 (18.0%): 	Loss: 21.021835327148438	recon_loss: 0.0014484586426988244	bpp_loss: 5.803632736206055	aux_loss: 222.27102661132812
04:15:57 INFO - main: Train iter. 37000/200000 (18.5%): 	Loss: 17.315704345703125	recon_loss: 0.001044676755554974	bpp_loss: 5.799376010894775	aux_loss: 220.92593383789062
04:24:52 INFO - main: Train iter. 38000/200000 (19.0%): 	Loss: 18.819320678710938	recon_loss: 0.001194775803014636	bpp_loss: 5.801090240478516	aux_loss: 217.220947265625
04:33:49 INFO - main: Train iter. 39000/200000 (19.5%): 	Loss: 24.29692268371582	recon_loss: 0.0017322887433692813	bpp_loss: 5.806323528289795	aux_loss: 216.04827880859375
04:42:46 INFO - main: Train iter. 40000/200000 (20.0%): 	Loss: 16.132732391357422	recon_loss: 0.0009492515819147229	bpp_loss: 5.837377071380615	aux_loss: 215.07981872558594
04:42:54 INFO - main: {'TEST MSE': 0.0009751971721010901, 'TEST BPP': 5.861296875, 'TEST loss': 16.76018775653839, 'TEST recon_loss': 0.0009751971436489839, 'TEST bpp_loss': 5.8309004640579225}
04:51:49 INFO - main: Train iter. 41000/200000 (20.5%): 	Loss: 18.95454216003418	recon_loss: 0.001223518280312419	bpp_loss: 5.851540565490723	aux_loss: 212.35174560546875
05:00:45 INFO - main: Train iter. 42000/200000 (21.0%): 	Loss: 28.972204208374023	recon_loss: 0.0022387756034731865	bpp_loss: 5.828833103179932	aux_loss: 210.6739501953125
05:09:41 INFO - main: Train iter. 43000/200000 (21.5%): 	Loss: 20.227163314819336	recon_loss: 0.00135064497590065	bpp_loss: 5.819473743438721	aux_loss: 206.64797973632812
05:18:38 INFO - main: Train iter. 44000/200000 (22.0%): 	Loss: 17.6086483001709	recon_loss: 0.0010975066106766462	bpp_loss: 5.844843864440918	aux_loss: 205.38070678710938
05:27:34 INFO - main: Train iter. 45000/200000 (22.5%): 	Loss: 15.810380935668945	recon_loss: 0.0009091250249184668	bpp_loss: 5.838428497314453	aux_loss: 203.80450439453125
05:27:42 INFO - main: {'TEST MSE': 0.0010932399406984516, 'TEST BPP': 5.88596875, 'TEST loss': 17.63049410200119, 'TEST recon_loss': 0.0010932399082230404, 'TEST bpp_loss': 5.857405452728272}
05:36:37 INFO - main: Train iter. 46000/200000 (23.0%): 	Loss: 16.919424057006836	recon_loss: 0.0010152427712455392	bpp_loss: 5.817378997802734	aux_loss: 200.50807189941406
05:45:35 INFO - main: Train iter. 47000/200000 (23.5%): 	Loss: 17.72620964050293	recon_loss: 0.0011219375301152468	bpp_loss: 5.850706577301025	aux_loss: 197.65631103515625
05:54:30 INFO - main: Train iter. 48000/200000 (24.0%): 	Loss: 16.67886734008789	recon_loss: 0.0009957858128473163	bpp_loss: 5.832860469818115	aux_loss: 194.8647003173828
06:03:25 INFO - main: Train iter. 49000/200000 (24.5%): 	Loss: 15.582867622375488	recon_loss: 0.0008941998239606619	bpp_loss: 5.829712867736816	aux_loss: 193.160888671875
06:12:22 INFO - main: Train iter. 50000/200000 (25.0%): 	Loss: 14.901549339294434	recon_loss: 0.0008443900151178241	bpp_loss: 5.841225624084473	aux_loss: 191.91506958007812
06:12:29 INFO - main: {'TEST MSE': 0.0011764240242217098, 'TEST BPP': 5.88784375, 'TEST loss': 18.639150676727294, 'TEST recon_loss': 0.0011764239877520594, 'TEST bpp_loss': 5.860539754390716}
06:21:24 INFO - main: Train iter. 51000/200000 (25.5%): 	Loss: 15.554275512695312	recon_loss: 0.000880389881785959	bpp_loss: 5.850012302398682	aux_loss: 190.1446075439453
06:30:19 INFO - main: Train iter. 52000/200000 (26.0%): 	Loss: 15.069833755493164	recon_loss: 0.0008292435086332262	bpp_loss: 5.8314595222473145	aux_loss: 186.25479125976562
06:39:14 INFO - main: Train iter. 53000/200000 (26.5%): 	Loss: 18.769573211669922	recon_loss: 0.0012102964101359248	bpp_loss: 5.850664138793945	aux_loss: 184.5749969482422
06:48:10 INFO - main: Train iter. 54000/200000 (27.0%): 	Loss: 17.80483627319336	recon_loss: 0.0010721299331635237	bpp_loss: 5.8343186378479	aux_loss: 181.64231872558594
06:57:05 INFO - main: Train iter. 55000/200000 (27.5%): 	Loss: 16.046098709106445	recon_loss: 0.0009278343059122562	bpp_loss: 5.840911865234375	aux_loss: 180.07867431640625
06:57:12 INFO - main: {'TEST MSE': 0.0008384035390948315, 'TEST BPP': 5.884859375, 'TEST loss': 14.910609436511994, 'TEST recon_loss': 0.0008384035142371431, 'TEST bpp_loss': 5.85810185289383}
07:06:07 INFO - main: Train iter. 56000/200000 (28.0%): 	Loss: 19.503963470458984	recon_loss: 0.0012591296108439565	bpp_loss: 5.823208808898926	aux_loss: 177.27178955078125
07:15:03 INFO - main: Train iter. 57000/200000 (28.5%): 	Loss: 16.075254440307617	recon_loss: 0.0009556030854582787	bpp_loss: 5.824545383453369	aux_loss: 174.04696655273438
07:23:58 INFO - main: Train iter. 58000/200000 (29.0%): 	Loss: 16.166339874267578	recon_loss: 0.0009392216452397406	bpp_loss: 5.8128767013549805	aux_loss: 172.14825439453125
07:32:53 INFO - main: Train iter. 59000/200000 (29.5%): 	Loss: 15.484176635742188	recon_loss: 0.0008690321119502187	bpp_loss: 5.7981791496276855	aux_loss: 170.72177124023438
07:41:50 INFO - main: Train iter. 60000/200000 (30.0%): 	Loss: 16.13559341430664	recon_loss: 0.0009215907193720341	bpp_loss: 5.830051422119141	aux_loss: 167.80030822753906
07:41:57 INFO - main: {'TEST MSE': 0.0011620197695500377, 'TEST BPP': 5.859734375, 'TEST loss': 18.474278121471404, 'TEST recon_loss': 0.0011620197359006853, 'TEST bpp_loss': 5.834221127033234}
07:50:51 INFO - main: Train iter. 61000/200000 (30.5%): 	Loss: 17.695648193359375	recon_loss: 0.0010860948823392391	bpp_loss: 5.813624382019043	aux_loss: 165.89459228515625
07:59:46 INFO - main: Train iter. 62000/200000 (31.0%): 	Loss: 22.637407302856445	recon_loss: 0.001577715971507132	bpp_loss: 5.822003364562988	aux_loss: 164.34361267089844
08:08:41 INFO - main: Train iter. 63000/200000 (31.5%): 	Loss: 18.670278549194336	recon_loss: 0.0011512985220178962	bpp_loss: 5.83546257019043	aux_loss: 162.68934631347656
08:17:37 INFO - main: Train iter. 64000/200000 (32.0%): 	Loss: 14.48373031616211	recon_loss: 0.0007870523259043694	bpp_loss: 5.850504398345947	aux_loss: 160.4395751953125
08:26:32 INFO - main: Train iter. 65000/200000 (32.5%): 	Loss: 15.08338737487793	recon_loss: 0.0007896228926256299	bpp_loss: 5.84290885925293	aux_loss: 157.6393280029297
08:26:39 INFO - main: {'TEST MSE': 0.0008493236791847159, 'TEST BPP': 5.870671875, 'TEST loss': 15.192492539405823, 'TEST recon_loss': 0.0008493236537324265, 'TEST bpp_loss': 5.846017075061798}
08:35:33 INFO - main: Train iter. 66000/200000 (33.0%): 	Loss: 15.413185119628906	recon_loss: 0.0008963769068941474	bpp_loss: 5.8554487228393555	aux_loss: 156.90679931640625
08:44:30 INFO - main: Train iter. 67000/200000 (33.5%): 	Loss: 14.191800117492676	recon_loss: 0.0007377028814516962	bpp_loss: 5.8352131843566895	aux_loss: 153.88526916503906
08:53:25 INFO - main: Train iter. 68000/200000 (34.0%): 	Loss: 16.798744201660156	recon_loss: 0.0009665920515544713	bpp_loss: 5.812778472900391	aux_loss: 150.428955078125
09:02:20 INFO - main: Train iter. 69000/200000 (34.5%): 	Loss: 15.497943878173828	recon_loss: 0.0008848057477734983	bpp_loss: 5.823572635650635	aux_loss: 147.30551147460938
09:11:16 INFO - main: Train iter. 70000/200000 (35.0%): 	Loss: 14.457208633422852	recon_loss: 0.0007759126019664109	bpp_loss: 5.8169636726379395	aux_loss: 145.26455688476562
09:11:23 INFO - main: {'TEST MSE': 0.0009044071037001234, 'TEST BPP': 5.858203125, 'TEST loss': 15.50406739282608, 'TEST recon_loss': 0.0009044070754316635, 'TEST bpp_loss': 5.833319474220276}
09:20:17 INFO - main: Train iter. 71000/200000 (35.5%): 	Loss: 14.630711555480957	recon_loss: 0.0007779797888360918	bpp_loss: 5.825517177581787	aux_loss: 142.77276611328125
09:29:12 INFO - main: Train iter. 72000/200000 (36.0%): 	Loss: 19.04543685913086	recon_loss: 0.0011719438480213284	bpp_loss: 5.842587471008301	aux_loss: 142.5104217529297
09:38:06 INFO - main: Train iter. 73000/200000 (36.5%): 	Loss: 15.279024124145508	recon_loss: 0.0008276633452624083	bpp_loss: 5.821976661682129	aux_loss: 139.9037628173828
09:47:03 INFO - main: Train iter. 74000/200000 (37.0%): 	Loss: 17.541019439697266	recon_loss: 0.001089395023882389	bpp_loss: 5.844101905822754	aux_loss: 136.7016143798828
09:55:57 INFO - main: Train iter. 75000/200000 (37.5%): 	Loss: 17.442777633666992	recon_loss: 0.0010901307687163353	bpp_loss: 5.83758020401001	aux_loss: 135.59912109375
09:56:05 INFO - main: {'TEST MSE': 0.000846086491376623, 'TEST BPP': 5.87328125, 'TEST loss': 15.022817320346832, 'TEST recon_loss': 0.0008460864666267298, 'TEST bpp_loss': 5.847574338436127}
10:04:59 INFO - main: Train iter. 76000/200000 (38.0%): 	Loss: 17.70499038696289	recon_loss: 0.0011044963030144572	bpp_loss: 5.812551021575928	aux_loss: 132.24656677246094
10:13:55 INFO - main: Train iter. 77000/200000 (38.5%): 	Loss: 16.301979064941406	recon_loss: 0.0009738249937072396	bpp_loss: 5.809906959533691	aux_loss: 129.71722412109375
10:22:50 INFO - main: Train iter. 78000/200000 (39.0%): 	Loss: 15.62187385559082	recon_loss: 0.0009061691234819591	bpp_loss: 5.8277201652526855	aux_loss: 127.60884094238281
10:31:44 INFO - main: Train iter. 79000/200000 (39.5%): 	Loss: 17.772083282470703	recon_loss: 0.0011023010592907667	bpp_loss: 5.824161529541016	aux_loss: 125.1136703491211
10:40:41 INFO - main: Train iter. 80000/200000 (40.0%): 	Loss: 16.834392547607422	recon_loss: 0.0009655377361923456	bpp_loss: 5.836119651794434	aux_loss: 123.13926696777344
10:40:48 INFO - main: {'TEST MSE': 0.0007300828950602191, 'TEST BPP': 5.865296875, 'TEST loss': 13.747742542743683, 'TEST recon_loss': 0.000730082871959894, 'TEST bpp_loss': 5.840051025867462}
10:49:43 INFO - main: Train iter. 81000/200000 (40.5%): 	Loss: 16.31298065185547	recon_loss: 0.0009370763436891139	bpp_loss: 5.843704700469971	aux_loss: 121.67191314697266
10:58:38 INFO - main: Train iter. 82000/200000 (41.0%): 	Loss: 16.948413848876953	recon_loss: 0.0010008448734879494	bpp_loss: 5.826230525970459	aux_loss: 119.94938659667969
11:07:32 INFO - main: Train iter. 83000/200000 (41.5%): 	Loss: 18.333539962768555	recon_loss: 0.001151686767116189	bpp_loss: 5.824069976806641	aux_loss: 116.82974243164062
11:16:28 INFO - main: Train iter. 84000/200000 (42.0%): 	Loss: 15.435084342956543	recon_loss: 0.0008663234766572714	bpp_loss: 5.838534832000732	aux_loss: 114.71192932128906
11:25:22 INFO - main: Train iter. 85000/200000 (42.5%): 	Loss: 13.271886825561523	recon_loss: 0.0006652784068137407	bpp_loss: 5.851931095123291	aux_loss: 115.67887115478516
11:25:30 INFO - main: {'TEST MSE': 0.0006787448816674749, 'TEST BPP': 5.884078125, 'TEST loss': 13.877046298980712, 'TEST recon_loss': 0.0006787448613613378, 'TEST bpp_loss': 5.858406859874726}
11:34:24 INFO - main: Train iter. 86000/200000 (43.0%): 	Loss: 15.973810195922852	recon_loss: 0.0009236221085302532	bpp_loss: 5.846209526062012	aux_loss: 112.69752502441406
11:43:20 INFO - main: Train iter. 87000/200000 (43.5%): 	Loss: 12.926547050476074	recon_loss: 0.0006433044327422976	bpp_loss: 5.846436023712158	aux_loss: 109.8031234741211
11:52:14 INFO - main: Train iter. 88000/200000 (44.0%): 	Loss: 17.728296279907227	recon_loss: 0.0011009664740413427	bpp_loss: 5.863425254821777	aux_loss: 107.85828399658203
12:01:09 INFO - main: Train iter. 89000/200000 (44.5%): 	Loss: 18.657690048217773	recon_loss: 0.001163109322078526	bpp_loss: 5.820620536804199	aux_loss: 103.80403137207031
12:10:05 INFO - main: Train iter. 90000/200000 (45.0%): 	Loss: 15.35310173034668	recon_loss: 0.0008816588087938726	bpp_loss: 5.833594799041748	aux_loss: 102.34110260009766
12:10:13 INFO - main: {'TEST MSE': 0.0008653427544735066, 'TEST BPP': 5.874, 'TEST loss': 15.459360941886901, 'TEST recon_loss': 0.0008653427293756977, 'TEST bpp_loss': 5.847539463043213}
12:19:07 INFO - main: Train iter. 91000/200000 (45.5%): 	Loss: 14.39633560180664	recon_loss: 0.0007144790142774582	bpp_loss: 5.816564083099365	aux_loss: 99.37496185302734
12:28:02 INFO - main: Train iter. 92000/200000 (46.0%): 	Loss: 17.242977142333984	recon_loss: 0.0010489781852811575	bpp_loss: 5.854558944702148	aux_loss: 99.11221313476562
12:36:57 INFO - main: Train iter. 93000/200000 (46.5%): 	Loss: 15.048677444458008	recon_loss: 0.0008168256608769298	bpp_loss: 5.83116340637207	aux_loss: 96.35343933105469
12:45:53 INFO - main: Train iter. 94000/200000 (47.0%): 	Loss: 13.239622116088867	recon_loss: 0.0006649197894148529	bpp_loss: 5.865947246551514	aux_loss: 93.85865020751953
12:54:47 INFO - main: Train iter. 95000/200000 (47.5%): 	Loss: 17.81079864501953	recon_loss: 0.001093480852432549	bpp_loss: 5.841332912445068	aux_loss: 91.68167114257812
12:54:55 INFO - main: {'TEST MSE': 0.0010846499563463285, 'TEST BPP': 5.882984375, 'TEST loss': 17.074811104297638, 'TEST recon_loss': 0.0010846499236358796, 'TEST bpp_loss': 5.855190427780151}
13:03:49 INFO - main: Train iter. 96000/200000 (48.0%): 	Loss: 17.32042694091797	recon_loss: 0.0010683332802727818	bpp_loss: 5.846482753753662	aux_loss: 89.48277282714844
13:12:44 INFO - main: Train iter. 97000/200000 (48.5%): 	Loss: 15.89402961730957	recon_loss: 0.0008548393379896879	bpp_loss: 5.838717460632324	aux_loss: 88.33392333984375
13:21:38 INFO - main: Train iter. 98000/200000 (49.0%): 	Loss: 14.206193923950195	recon_loss: 0.0007558067445643246	bpp_loss: 5.834847927093506	aux_loss: 84.30397033691406
13:30:32 INFO - main: Train iter. 99000/200000 (49.5%): 	Loss: 14.635005950927734	recon_loss: 0.0008027736912481487	bpp_loss: 5.851241588592529	aux_loss: 82.28570556640625
13:39:28 INFO - main: Train iter. 100000/200000 (50.0%): 	Loss: 13.79817008972168	recon_loss: 0.000720925978384912	bpp_loss: 5.836939811706543	aux_loss: 81.11360168457031
13:39:36 INFO - main: {'TEST MSE': 0.0007883981788659951, 'TEST BPP': 5.885015625, 'TEST loss': 14.221253019571304, 'TEST recon_loss': 0.0007883981555060018, 'TEST bpp_loss': 5.8571237616539005}
13:48:30 INFO - main: Train iter. 101000/200000 (50.5%): 	Loss: 19.255691528320312	recon_loss: 0.0011911222245544195	bpp_loss: 5.85656213760376	aux_loss: 79.31654357910156
13:57:25 INFO - main: Train iter. 102000/200000 (51.0%): 	Loss: 17.448551177978516	recon_loss: 0.0010784099576994777	bpp_loss: 5.878939151763916	aux_loss: 78.17008972167969
14:06:19 INFO - main: Train iter. 103000/200000 (51.5%): 	Loss: 14.402740478515625	recon_loss: 0.0007575079216621816	bpp_loss: 5.843997955322266	aux_loss: 75.02778625488281
14:15:15 INFO - main: Train iter. 104000/200000 (52.0%): 	Loss: 18.252962112426758	recon_loss: 0.00113889470230788	bpp_loss: 5.854866981506348	aux_loss: 71.58077239990234
14:24:09 INFO - main: Train iter. 105000/200000 (52.5%): 	Loss: 14.87109375	recon_loss: 0.0008030560566112399	bpp_loss: 5.831608295440674	aux_loss: 68.37535095214844
14:24:16 INFO - main: {'TEST MSE': 0.0007467575720976873, 'TEST BPP': 5.882671875, 'TEST loss': 13.931312193870545, 'TEST recon_loss': 0.0007467575503251283, 'TEST bpp_loss': 5.853213923454285}
14:33:11 INFO - main: Train iter. 106000/200000 (53.0%): 	Loss: 16.632915496826172	recon_loss: 0.0009818673133850098	bpp_loss: 5.845273494720459	aux_loss: 66.3237533569336
14:42:07 INFO - main: Train iter. 107000/200000 (53.5%): 	Loss: 15.038180351257324	recon_loss: 0.0008555727545171976	bpp_loss: 5.825309753417969	aux_loss: 64.53907012939453
14:51:02 INFO - main: Train iter. 108000/200000 (54.0%): 	Loss: 14.175628662109375	recon_loss: 0.000774721906054765	bpp_loss: 5.83504581451416	aux_loss: 61.69554138183594
14:59:56 INFO - main: Train iter. 109000/200000 (54.5%): 	Loss: 17.839107513427734	recon_loss: 0.0011002240935340524	bpp_loss: 5.826138019561768	aux_loss: 60.154232025146484
15:08:53 INFO - main: Train iter. 110000/200000 (55.0%): 	Loss: 13.999942779541016	recon_loss: 0.0007396729197353125	bpp_loss: 5.813492298126221	aux_loss: 57.35270690917969
15:09:00 INFO - main: {'TEST MSE': 0.0010142571519381935, 'TEST BPP': 5.880625, 'TEST loss': 16.904977521419525, 'TEST recon_loss': 0.0010142571229516761, 'TEST bpp_loss': 5.850890960693359}
15:17:54 INFO - main: Train iter. 111000/200000 (55.5%): 	Loss: 15.635147094726562	recon_loss: 0.0009237499907612801	bpp_loss: 5.865455627441406	aux_loss: 56.978271484375
15:26:49 INFO - main: Train iter. 112000/200000 (56.0%): 	Loss: 15.181310653686523	recon_loss: 0.0008176587289199233	bpp_loss: 5.878058910369873	aux_loss: 55.918312072753906
15:35:44 INFO - main: Train iter. 113000/200000 (56.5%): 	Loss: 14.469002723693848	recon_loss: 0.000774752872530371	bpp_loss: 5.8341827392578125	aux_loss: 52.325401306152344
15:44:40 INFO - main: Train iter. 114000/200000 (57.0%): 	Loss: 14.933088302612305	recon_loss: 0.0008152214577421546	bpp_loss: 5.867809772491455	aux_loss: 50.187225341796875
15:53:35 INFO - main: Train iter. 115000/200000 (57.5%): 	Loss: 18.55144691467285	recon_loss: 0.0011964169098064303	bpp_loss: 5.851654529571533	aux_loss: 46.94977569580078
15:53:42 INFO - main: {'TEST MSE': 0.0011636616362382943, 'TEST BPP': 5.878953125, 'TEST loss': 18.478748512983323, 'TEST recon_loss': 0.0011636616016039625, 'TEST bpp_loss': 5.849079597949982}
16:02:36 INFO - main: Train iter. 116000/200000 (58.0%): 	Loss: 15.828367233276367	recon_loss: 0.000910865084733814	bpp_loss: 5.840083599090576	aux_loss: 46.57982635498047
16:11:33 INFO - main: Train iter. 117000/200000 (58.5%): 	Loss: 16.205320358276367	recon_loss: 0.0009537984151393175	bpp_loss: 5.8433427810668945	aux_loss: 43.45062255859375
16:20:27 INFO - main: Train iter. 118000/200000 (59.0%): 	Loss: 14.906538963317871	recon_loss: 0.0008089335751719773	bpp_loss: 5.871240139007568	aux_loss: 42.162452697753906
16:29:22 INFO - main: Train iter. 119000/200000 (59.5%): 	Loss: 15.98431396484375	recon_loss: 0.000917632773052901	bpp_loss: 5.86345100402832	aux_loss: 39.12886047363281
16:38:18 INFO - main: Train iter. 120000/200000 (60.0%): 	Loss: 18.17542839050293	recon_loss: 0.001096544903703034	bpp_loss: 5.860969066619873	aux_loss: 37.56690979003906
16:38:25 INFO - main: {'TEST MSE': 0.001078676997577342, 'TEST BPP': 5.90721875, 'TEST loss': 17.159310015678408, 'TEST recon_loss': 0.0010786769655678654, 'TEST bpp_loss': 5.875642302513122}
16:47:19 INFO - main: Train iter. 121000/200000 (60.5%): 	Loss: 14.763611793518066	recon_loss: 0.0007453912985511124	bpp_loss: 5.855082035064697	aux_loss: 35.310813903808594
16:56:13 INFO - main: Train iter. 122000/200000 (61.0%): 	Loss: 13.458244323730469	recon_loss: 0.0006788363098166883	bpp_loss: 5.853289604187012	aux_loss: 34.57886505126953
17:05:07 INFO - main: Train iter. 123000/200000 (61.5%): 	Loss: 12.850912094116211	recon_loss: 0.0006194784073159099	bpp_loss: 5.862530708312988	aux_loss: 30.57819366455078
17:14:03 INFO - main: Train iter. 124000/200000 (62.0%): 	Loss: 15.305890083312988	recon_loss: 0.0008708940003998578	bpp_loss: 5.845691680908203	aux_loss: 26.438915252685547
17:22:57 INFO - main: Train iter. 125000/200000 (62.5%): 	Loss: 16.84855842590332	recon_loss: 0.0010122522944584489	bpp_loss: 5.841953277587891	aux_loss: 23.969507217407227
17:23:05 INFO - main: {'TEST MSE': 0.0008582832807274528, 'TEST BPP': 5.872125, 'TEST loss': 15.439981762886047, 'TEST recon_loss': 0.0008582832538377261, 'TEST bpp_loss': 5.840195977210999}
17:31:59 INFO - main: Train iter. 126000/200000 (63.0%): 	Loss: 18.25857925415039	recon_loss: 0.0011263652704656124	bpp_loss: 5.849208354949951	aux_loss: 24.113313674926758
17:40:55 INFO - main: Train iter. 127000/200000 (63.5%): 	Loss: 14.012870788574219	recon_loss: 0.0007533436873927712	bpp_loss: 5.867467403411865	aux_loss: 24.184711456298828
17:49:49 INFO - main: Train iter. 128000/200000 (64.0%): 	Loss: 15.781591415405273	recon_loss: 0.0008951287600211799	bpp_loss: 5.852865219116211	aux_loss: 19.57018280029297
17:58:43 INFO - main: Train iter. 129000/200000 (64.5%): 	Loss: 14.298395156860352	recon_loss: 0.0007594089838676155	bpp_loss: 5.851531982421875	aux_loss: 16.59075927734375
18:07:40 INFO - main: Train iter. 130000/200000 (65.0%): 	Loss: 14.190245628356934	recon_loss: 0.0007166867144405842	bpp_loss: 5.834794998168945	aux_loss: 16.298431396484375
18:07:47 INFO - main: {'TEST MSE': 0.000790272457436522, 'TEST BPP': 5.906453125, 'TEST loss': 14.66155594921112, 'TEST recon_loss': 0.0007902724334271625, 'TEST bpp_loss': 5.87295112991333}
18:16:41 INFO - main: Train iter. 131000/200000 (65.5%): 	Loss: 13.90434455871582	recon_loss: 0.0006662468076683581	bpp_loss: 5.846285343170166	aux_loss: 14.598794937133789
18:25:35 INFO - main: Train iter. 132000/200000 (66.0%): 	Loss: 15.25233268737793	recon_loss: 0.000784972682595253	bpp_loss: 5.849489212036133	aux_loss: 13.603071212768555
18:34:30 INFO - main: Train iter. 133000/200000 (66.5%): 	Loss: 16.197898864746094	recon_loss: 0.0009242406813427806	bpp_loss: 5.847766876220703	aux_loss: 11.795480728149414
18:43:26 INFO - main: Train iter. 134000/200000 (67.0%): 	Loss: 14.473188400268555	recon_loss: 0.0007649781764484942	bpp_loss: 5.829204559326172	aux_loss: 9.773329734802246
18:52:20 INFO - main: Train iter. 135000/200000 (67.5%): 	Loss: 13.26419734954834	recon_loss: 0.0006425970350392163	bpp_loss: 5.865508079528809	aux_loss: 9.589470863342285
18:52:27 INFO - main: {'TEST MSE': 0.0013577741489348247, 'TEST BPP': 5.89115625, 'TEST loss': 20.319665665626527, 'TEST recon_loss': 0.0013577741070330376, 'TEST bpp_loss': 5.858168726921082}
19:01:21 INFO - main: Train iter. 136000/200000 (68.0%): 	Loss: 15.125836372375488	recon_loss: 0.0008374300668947399	bpp_loss: 5.846773147583008	aux_loss: 8.90041732788086
19:10:17 INFO - main: Train iter. 137000/200000 (68.5%): 	Loss: 13.815258026123047	recon_loss: 0.0006754074711352587	bpp_loss: 5.834582805633545	aux_loss: 5.525515556335449
19:19:11 INFO - main: Train iter. 138000/200000 (69.0%): 	Loss: 14.625475883483887	recon_loss: 0.0008135306416079402	bpp_loss: 5.86962890625	aux_loss: 6.044410705566406
19:28:06 INFO - main: Train iter. 139000/200000 (69.5%): 	Loss: 12.870593070983887	recon_loss: 0.0006163981161080301	bpp_loss: 5.850243091583252	aux_loss: 4.231276512145996
19:37:02 INFO - main: Train iter. 140000/200000 (70.0%): 	Loss: 15.206738471984863	recon_loss: 0.0008176772971637547	bpp_loss: 5.834453582763672	aux_loss: 5.462162017822266
19:37:09 INFO - main: {'TEST MSE': 0.0007151262004192277, 'TEST BPP': 5.896390625, 'TEST loss': 13.817212697029113, 'TEST recon_loss': 0.0007151261787512339, 'TEST bpp_loss': 5.8629018235206605}
19:46:03 INFO - main: Train iter. 141000/200000 (70.5%): 	Loss: 17.663715362548828	recon_loss: 0.001083487761206925	bpp_loss: 5.8683671951293945	aux_loss: 4.810479640960693
19:54:57 INFO - main: Train iter. 142000/200000 (71.0%): 	Loss: 14.317852973937988	recon_loss: 0.0007657428504899144	bpp_loss: 5.816801071166992	aux_loss: 3.703397035598755
20:03:51 INFO - main: Train iter. 143000/200000 (71.5%): 	Loss: 13.693026542663574	recon_loss: 0.0006660440121777356	bpp_loss: 5.854977130889893	aux_loss: 3.0783214569091797
20:12:47 INFO - main: Train iter. 144000/200000 (72.0%): 	Loss: 13.625926971435547	recon_loss: 0.000641469843685627	bpp_loss: 5.84337043762207	aux_loss: 2.7418909072875977
20:21:41 INFO - main: Train iter. 145000/200000 (72.5%): 	Loss: 15.27267074584961	recon_loss: 0.0008468955638818443	bpp_loss: 5.860960960388184	aux_loss: 2.117326021194458
20:21:49 INFO - main: {'TEST MSE': 0.0008351215655421593, 'TEST BPP': 5.890109375, 'TEST loss': 14.87714044046402, 'TEST recon_loss': 0.0008351215404545655, 'TEST bpp_loss': 5.855513696193695}
20:30:43 INFO - main: Train iter. 146000/200000 (73.0%): 	Loss: 14.563273429870605	recon_loss: 0.0007768622599542141	bpp_loss: 5.816259384155273	aux_loss: 2.0364489555358887
20:39:39 INFO - main: Train iter. 147000/200000 (73.5%): 	Loss: 13.358834266662598	recon_loss: 0.0006646792171522975	bpp_loss: 5.859381198883057	aux_loss: 1.9951083660125732
20:48:34 INFO - main: Train iter. 148000/200000 (74.0%): 	Loss: 17.133337020874023	recon_loss: 0.0010636824881657958	bpp_loss: 5.863458633422852	aux_loss: 2.1897494792938232
20:57:28 INFO - main: Train iter. 149000/200000 (74.5%): 	Loss: 16.224430084228516	recon_loss: 0.000983758014626801	bpp_loss: 5.8603515625	aux_loss: 2.233065366744995
21:06:24 INFO - main: Train iter. 150000/200000 (75.0%): 	Loss: 15.947023391723633	recon_loss: 0.0009330328903160989	bpp_loss: 5.83528470993042	aux_loss: 2.9420366287231445
21:06:32 INFO - main: {'TEST MSE': 0.0008100422323275236, 'TEST BPP': 5.87596875, 'TEST loss': 15.042460701942444, 'TEST recon_loss': 0.0008100422080315184, 'TEST bpp_loss': 5.842570049762726}
21:15:26 INFO - main: Train iter. 151000/200000 (75.5%): 	Loss: 16.381778717041016	recon_loss: 0.000940478581469506	bpp_loss: 5.832608699798584	aux_loss: 1.8988107442855835
21:24:21 INFO - main: Train iter. 152000/200000 (76.0%): 	Loss: 15.661548614501953	recon_loss: 0.0008615751867182553	bpp_loss: 5.815066814422607	aux_loss: 1.4862953424453735
21:33:16 INFO - main: Train iter. 153000/200000 (76.5%): 	Loss: 13.168909072875977	recon_loss: 0.0006544897914864123	bpp_loss: 5.864619255065918	aux_loss: 2.739330768585205
21:42:13 INFO - main: Train iter. 154000/200000 (77.0%): 	Loss: 15.900986671447754	recon_loss: 0.0008806737023405731	bpp_loss: 5.867932319641113	aux_loss: 1.2790324687957764
21:51:08 INFO - main: Train iter. 155000/200000 (77.5%): 	Loss: 14.250045776367188	recon_loss: 0.0007580803357996047	bpp_loss: 5.8611040115356445	aux_loss: 2.5604190826416016
21:51:15 INFO - main: {'TEST MSE': 0.0008571036812224462, 'TEST BPP': 5.90525, 'TEST loss': 15.165470219135285, 'TEST recon_loss': 0.0008571036561043001, 'TEST bpp_loss': 5.870940062522888}
22:00:09 INFO - main: Train iter. 156000/200000 (78.0%): 	Loss: 16.29892921447754	recon_loss: 0.0009695434710010886	bpp_loss: 5.8665289878845215	aux_loss: 1.716076135635376
22:09:05 INFO - main: Train iter. 157000/200000 (78.5%): 	Loss: 14.840494155883789	recon_loss: 0.0007709150086157024	bpp_loss: 5.825554370880127	aux_loss: 1.894875168800354
22:18:00 INFO - main: Train iter. 158000/200000 (79.0%): 	Loss: 12.86181354522705	recon_loss: 0.0006075148703530431	bpp_loss: 5.842352867126465	aux_loss: 2.131338596343994
22:26:54 INFO - main: Train iter. 159000/200000 (79.5%): 	Loss: 17.68853759765625	recon_loss: 0.0011005443520843983	bpp_loss: 5.843600273132324	aux_loss: 1.9580764770507812
22:35:50 INFO - main: Train iter. 160000/200000 (80.0%): 	Loss: 12.95547866821289	recon_loss: 0.0005790727445855737	bpp_loss: 5.845152854919434	aux_loss: 2.814974308013916
22:35:57 INFO - main: {'TEST MSE': 0.0008396937254692123, 'TEST BPP': 5.8986875, 'TEST loss': 15.298879838824272, 'TEST recon_loss': 0.0008396937000943581, 'TEST bpp_loss': 5.864758289813995}
Traceback (most recent call last):
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 652, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 866, in _save
    zip_file.write_record('data.pkl', data_value, len(data_value))
RuntimeError: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data.pkl: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 586, in <module>
    ddp_or_single_process(sys.argv[1:])
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 581, in ddp_or_single_process
    main(opts)
  File "/home/jgryu/Weight_compression/VQVAE/train_nwc.py", line 432, in main
    torch.save(
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 651, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/jgryu/miniconda3/envs/nic/lib/python3.10/site-packages/torch/serialization.py", line 499, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:603] . unexpected pos 128 vs 0
[1;34mwandb[0m: üöÄ View run [33mnwc_ql[0m at: [34mhttps://wandb.ai/maskedkd/NWC_VQVAE/runs/dyiqaf99[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250210_224417-dyiqaf99/logs[0m
